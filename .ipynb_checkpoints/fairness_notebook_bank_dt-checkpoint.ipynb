{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8c9f6b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "151964f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aa3557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset, BankDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f6016af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import StandardDataset\n",
    "StandardDataset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f57d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from data_utils import DatasetBuilder\n",
    "from metrics_utils import compute_metrics, describe_metrics, get_test_metrics, test\n",
    "from plot_utils import plot\n",
    "from mitigators import NullMitigator, SyntheticMitigator, DIRMitigator, ReweighMitigator, EGRMitigator, PRMitigator, CPPMitigator, ROMitigator \n",
    "from test_algorithms import TestAlgorithms\n",
    "from plot_utils import plot_algo_lr, plot_algo\n",
    "\n",
    "# Metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "\n",
    "# Bias insertion\n",
    "from oversample import label_bias, selection_bias \n",
    "from metrics_utils import get_orig_model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180b2a8",
   "metadata": {},
   "source": [
    "## Arguments & Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564c7837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-o', '--os'], dest='os', nargs=None, const=None, default=2, type=None, choices=None, required=False, help='oversample mode: 1: privi unfav 2: unpriv fav', metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct argument parser\n",
    "import argparse\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--data\", choices=['adult', 'compas', 'german', 'bank', 'meps19', 'grade'], default='compas', help=\"dataset: adult, compas, german, bank, meps19, grade \")\n",
    "ap.add_argument(\"-c\", \"--classifier\", choices=['lr', 'rf', 'svm', 'nn', 'nb'], default='lr', help=\"baseline model: lr, rf, svm, nn, nb, dt\")\n",
    "ap.add_argument(\"-m\", \"--mitigator\", choices=['dir', 'rew', 'egr', 'pr', 'cpp', 'ro'], required=False, help=\"mitigators: dir, rew, egr, pr, cpp, ro\")\n",
    "ap.add_argument(\"-b\", \"--bias\", default=0., help=\"amount of bias: o-1\")\n",
    "ap.add_argument(\"-t\", \"--biastype\", choices=['label', 'selection', 'none'], default='none', help=\"amount of bias: o-1\")\n",
    "ap.add_argument(\"-o\", \"--os\", default=2, help=\"oversample mode: 1: privi unfav 2: unpriv fav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4f8856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['']\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19b063bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 'compas',\n",
       " 'classifier': 'lr',\n",
       " 'mitigator': None,\n",
       " 'bias': 0.0,\n",
       " 'biastype': 'none',\n",
       " 'os': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0dd1c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"bank\"#args[\"data\"]\n",
    "BASELINE = \"dt\" #args[\"classifier\"]\n",
    "MITIGATOR = args[\"mitigator\"]\n",
    "BIAS = float(args[\"bias\"])\n",
    "BIAS_TYPE = args[\"biastype\"]\n",
    "OS_MODE = int(args[\"os\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b16266c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# global constants\n",
    "if BASELINE == 'svm' or BASELINE == 'nn':\n",
    "    SCALER = False \n",
    "else:\n",
    "    SCALER = False \n",
    "DISPLAY = False \n",
    "THRESH_ARR = 0.5\n",
    "\n",
    "# loop ten times \n",
    "N = 3 \n",
    "\n",
    "# percentage of favor and unfavor\n",
    "priv_metric_orig = defaultdict(float)\n",
    "favor_metric_orig = defaultdict(float)\n",
    "favor_metric_transf = defaultdict(float)\n",
    "\n",
    "# for each pre-processing approach, we create a mia_metric_results\n",
    "orig_metrics = defaultdict(list)\n",
    "orig_mia_metrics = defaultdict(list)\n",
    "\n",
    "transf_metrics = defaultdict(list) \n",
    "transf_mia_metrics = defaultdict(list) \n",
    "\n",
    "reweigh_metrics = defaultdict(list) \n",
    "reweigh_mia_metrics = defaultdict(list) \n",
    "\n",
    "dir_metrics = defaultdict(list) \n",
    "dir_mia_metrics = defaultdict(list) \n",
    "\n",
    "egr_metrics = defaultdict(list) \n",
    "egr_mia_metrics = defaultdict(list) \n",
    "\n",
    "\n",
    "pr_orig_metrics = defaultdict(list) \n",
    "cpp_metrics = defaultdict(list) \n",
    "ro_metrics = defaultdict(list) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a48a7",
   "metadata": {},
   "source": [
    "## Loading & Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da867c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:[1.0] listed but not observed for feature age\n"
     ]
    }
   ],
   "source": [
    "# load dataset and set the groups\n",
    "dataset_builder =  DatasetBuilder(DATASET)\n",
    "dataset_orig = dataset_builder.load_data()\n",
    "sens_attr = dataset_orig.protected_attribute_names[0]\n",
    "unprivileged_groups = dataset_builder.unprivileged_groups\n",
    "privileged_groups = dataset_builder.privileged_groups\n",
    "\n",
    "# training data split ratio\n",
    "p = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aabd2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25836, 58)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb84777c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'age': 1}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "privileged_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fb1ad08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.1932e+04 0.0000e+00 2.9800e+02 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [1.2674e+04 0.0000e+00 3.1700e+02 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [3.4912e+04 0.0000e+00 2.7000e+02 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [3.7272e+04 0.0000e+00 3.2800e+02 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [3.1882e+04 0.0000e+00 6.4300e+02 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [1.8340e+03 0.0000e+00 2.8600e+02 ... 0.0000e+00 1.0000e+00 0.0000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# split dataset into train, validation, and test\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([p], shuffle=True)\n",
    "dataset_orig_val = dataset_orig_test\n",
    "print(dataset_orig_train.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a15c69f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no bias type specified\n"
     ]
    }
   ],
   "source": [
    "# favorable and unfavorable labels and feature_names\n",
    "f_label = dataset_orig_train.favorable_label\n",
    "uf_label = dataset_orig_train.unfavorable_label\n",
    "feature_names = dataset_orig_train.feature_names\n",
    "\n",
    "# introduce label or selection biases, assuming the original data is fair\n",
    "if BIAS_TYPE == 'label':\n",
    "    dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "elif BIAS_TYPE == 'selection':\n",
    "    dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "else:\n",
    "    print('no bias type specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "494296e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               instance weights   features                               \\\n",
       "                                           protected attribute            \n",
       "                                Unnamed: 0                 age duration   \n",
       "instance names                                                            \n",
       "7572                        1.0    11932.0                 0.0    298.0   \n",
       "8088                        1.0    12674.0                 0.0    317.0   \n",
       "22686                       1.0    34912.0                 0.0    270.0   \n",
       "10488                       1.0    16065.0                 0.0    176.0   \n",
       "6159                        1.0     9694.0                 0.0    316.0   \n",
       "...                         ...        ...                 ...      ...   \n",
       "980                         1.0     1580.0                 0.0    144.0   \n",
       "16051                       1.0    23856.0                 0.0     35.0   \n",
       "24172                       1.0    37272.0                 0.0    328.0   \n",
       "21121                       1.0    31882.0                 0.0    643.0   \n",
       "1158                        1.0     1834.0                 0.0    286.0   \n",
       "\n",
       "                                                                     \\\n",
       "                                                                      \n",
       "               campaign  pdays previous emp.var.rate cons.price.idx   \n",
       "instance names                                                        \n",
       "7572                4.0  999.0      0.0          1.4         94.465   \n",
       "8088                3.0  999.0      0.0          1.4         93.918   \n",
       "22686               1.0  999.0      0.0         -1.8         92.893   \n",
       "10488               1.0  999.0      0.0          1.4         93.918   \n",
       "6159                2.0  999.0      0.0          1.4         94.465   \n",
       "...                 ...    ...      ...          ...            ...   \n",
       "980                 2.0  999.0      0.0          1.1         93.994   \n",
       "16051              10.0  999.0      0.0          1.4         93.444   \n",
       "24172               1.0  999.0      0.0         -2.9         92.201   \n",
       "21121               1.0  999.0      0.0         -1.8         92.893   \n",
       "1158                5.0  999.0      0.0          1.1         93.994   \n",
       "\n",
       "                              ...                                            \\\n",
       "                              ...                                             \n",
       "               cons.conf.idx  ... month=sep day_of_week=fri day_of_week=mon   \n",
       "instance names                ...                                             \n",
       "7572                   -41.8  ...       0.0             1.0             0.0   \n",
       "8088                   -42.7  ...       0.0             0.0             1.0   \n",
       "22686                  -46.2  ...       0.0             1.0             0.0   \n",
       "10488                  -42.7  ...       0.0             0.0             0.0   \n",
       "6159                   -41.8  ...       0.0             0.0             1.0   \n",
       "...                      ...  ...       ...             ...             ...   \n",
       "980                    -36.4  ...       0.0             1.0             0.0   \n",
       "16051                  -36.1  ...       0.0             1.0             0.0   \n",
       "24172                  -31.4  ...       0.0             0.0             1.0   \n",
       "21121                  -46.2  ...       0.0             0.0             0.0   \n",
       "1158                   -36.4  ...       0.0             1.0             0.0   \n",
       "\n",
       "                                                                \\\n",
       "                                                                 \n",
       "               day_of_week=thu day_of_week=tue day_of_week=wed   \n",
       "instance names                                                   \n",
       "7572                       0.0             0.0             0.0   \n",
       "8088                       0.0             0.0             0.0   \n",
       "22686                      0.0             0.0             0.0   \n",
       "10488                      0.0             1.0             0.0   \n",
       "6159                       0.0             0.0             0.0   \n",
       "...                        ...             ...             ...   \n",
       "980                        0.0             0.0             0.0   \n",
       "16051                      0.0             0.0             0.0   \n",
       "24172                      0.0             0.0             0.0   \n",
       "21121                      1.0             0.0             0.0   \n",
       "1158                       0.0             0.0             0.0   \n",
       "\n",
       "                                                                      labels  \n",
       "                                                                              \n",
       "               poutcome=failure poutcome=nonexistent poutcome=success         \n",
       "instance names                                                                \n",
       "7572                        0.0                  1.0              0.0    0.0  \n",
       "8088                        0.0                  1.0              0.0    0.0  \n",
       "22686                       0.0                  1.0              0.0    0.0  \n",
       "10488                       0.0                  1.0              0.0    0.0  \n",
       "6159                        0.0                  1.0              0.0    0.0  \n",
       "...                         ...                  ...              ...    ...  \n",
       "980                         0.0                  1.0              0.0    0.0  \n",
       "16051                       0.0                  1.0              0.0    0.0  \n",
       "24172                       0.0                  1.0              0.0    1.0  \n",
       "21121                       0.0                  1.0              0.0    0.0  \n",
       "1158                        0.0                  1.0              0.0    0.0  \n",
       "\n",
       "[12918 rows x 60 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4446244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig_train?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cfd5f8",
   "metadata": {},
   "source": [
    "## Run Mitigating Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eea401f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Train dataset's features are as below:\n",
      "[[3.2215e+04 0.0000e+00 2.0300e+02 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [2.8694e+04 0.0000e+00 3.4000e+01 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [1.6000e+02 0.0000e+00 1.6500e+02 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [2.3915e+04 0.0000e+00 9.6100e+02 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [2.3370e+03 0.0000e+00 2.0500e+02 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [3.1340e+03 0.0000e+00 1.8200e+02 ... 0.0000e+00 1.0000e+00 0.0000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(12918, 58)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['Unnamed: 0', 'age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'job=admin.', 'job=blue-collar', 'job=entrepreneur', 'job=housemaid', 'job=management', 'job=retired', 'job=self-employed', 'job=services', 'job=student', 'job=technician', 'job=unemployed', 'marital=divorced', 'marital=married', 'marital=single', 'education=basic.4y', 'education=basic.6y', 'education=basic.9y', 'education=high.school', 'education=illiterate', 'education=professional.course', 'education=university.degree', 'default=no', 'default=yes', 'housing=no', 'housing=yes', 'loan=no', 'loan=yes', 'contact=cellular', 'contact=telephone', 'month=apr', 'month=aug', 'month=dec', 'month=jul', 'month=jun', 'month=mar', 'month=may', 'month=nov', 'month=oct', 'month=sep', 'day_of_week=fri', 'day_of_week=mon', 'day_of_week=thu', 'day_of_week=tue', 'day_of_week=wed', 'poutcome=failure', 'poutcome=nonexistent', 'poutcome=success']\n",
      "privileged vs. unprivileged:  0.0 12918.0\n",
      "base_pos unpriv:  0.10063477318470351\n",
      "base_pos priv:  nan\n",
      "number of favorable labels:  1300\n",
      "Difference in mean outcomes between unprivileged and privileged groups = nan\n",
      "#### Train shape, validation shape, test shape\n",
      "(12918, 58) (12918, 58) (12918, 58)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\aif360\\metrics\\binary_label_dataset_metric.py:105: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return (self.num_positives(privileged=privileged)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.97     11618\n",
      "         1.0       0.77      0.72      0.74      1300\n",
      "\n",
      "    accuracy                           0.95     12918\n",
      "   macro avg       0.87      0.85      0.86     12918\n",
      "weighted avg       0.95      0.95      0.95     12918\n",
      "\n",
      "Train accuracy:  0.9498374361356247\n",
      "Validating Original ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\aif360\\metrics\\classification_metric.py:278: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TPR=TP / P, TNR=TN / N, FPR=FP / N, FNR=FN / P,\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\aif360\\metrics\\classification_metric.py:279: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  GTPR=GTP / P, GTNR=GTN / N, GFPR=GFP / N, GFNR=GFN / P,\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\aif360\\metrics\\classification_metric.py:673: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return (self.num_pred_positives(privileged=privileged)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for threshold: 0.01  is: 0.8115033286886515\n",
      "Balanced accuracy is:  0.8159739436003617\n",
      "Accuracy for threshold: 0.02  is: 0.8259792537544511\n",
      "Balanced accuracy is:  0.8194505198967011\n",
      "Accuracy for threshold: 0.03  is: 0.8259792537544511\n",
      "Balanced accuracy is:  0.8194505198967011\n",
      "Accuracy for threshold: 0.04  is: 0.8577179129896269\n",
      "Balanced accuracy is:  0.8240976333278249\n",
      "Accuracy for threshold: 0.05  is: 0.8577179129896269\n",
      "Balanced accuracy is:  0.8240976333278249\n",
      "Accuracy for threshold: 0.060000000000000005  is: 0.8580275584455798\n",
      "Balanced accuracy is:  0.8221684747212583\n",
      "Accuracy for threshold: 0.06999999999999999  is: 0.8580275584455798\n",
      "Balanced accuracy is:  0.8221684747212583\n",
      "Accuracy for threshold: 0.08  is: 0.8606595448211798\n",
      "Balanced accuracy is:  0.8208270148629864\n",
      "Accuracy for threshold: 0.09  is: 0.8790834494503793\n",
      "Balanced accuracy is:  0.8173893214610896\n",
      "Accuracy for threshold: 0.09999999999999999  is: 0.8799349744542498\n",
      "Balanced accuracy is:  0.8178615866165078\n",
      "Accuracy for threshold: 0.11  is: 0.8814057903700263\n",
      "Balanced accuracy is:  0.8176268716443251\n",
      "Accuracy for threshold: 0.12  is: 0.8845796562935438\n",
      "Balanced accuracy is:  0.8169360927227423\n",
      "Accuracy for threshold: 0.13  is: 0.8845796562935438\n",
      "Balanced accuracy is:  0.8169360927227423\n",
      "Accuracy for threshold: 0.14  is: 0.8845022449295556\n",
      "Balanced accuracy is:  0.8147922681364401\n",
      "Accuracy for threshold: 0.15000000000000002  is: 0.8845022449295556\n",
      "Balanced accuracy is:  0.8147922681364401\n",
      "Accuracy for threshold: 0.16  is: 0.8849667131134851\n",
      "Balanced accuracy is:  0.8139994216169452\n",
      "Accuracy for threshold: 0.17  is: 0.8869019972131909\n",
      "Balanced accuracy is:  0.813672157255386\n",
      "Accuracy for threshold: 0.18000000000000002  is: 0.8872116426691439\n",
      "Balanced accuracy is:  0.8103424043885827\n",
      "Accuracy for threshold: 0.19  is: 0.8872116426691439\n",
      "Balanced accuracy is:  0.8103424043885827\n",
      "Accuracy for threshold: 0.2  is: 0.8872116426691439\n",
      "Balanced accuracy is:  0.8096421072584643\n",
      "Accuracy for threshold: 0.21000000000000002  is: 0.8872116426691439\n",
      "Balanced accuracy is:  0.8096421072584643\n",
      "Accuracy for threshold: 0.22  is: 0.8973525313516024\n",
      "Balanced accuracy is:  0.7981090762396352\n",
      "Accuracy for threshold: 0.23  is: 0.8973525313516024\n",
      "Balanced accuracy is:  0.7981090762396352\n",
      "Accuracy for threshold: 0.24000000000000002  is: 0.8973525313516024\n",
      "Balanced accuracy is:  0.7981090762396352\n",
      "Accuracy for threshold: 0.25  is: 0.8975847654435671\n",
      "Balanced accuracy is:  0.7982378758274766\n",
      "Accuracy for threshold: 0.26  is: 0.8975847654435671\n",
      "Balanced accuracy is:  0.7982378758274766\n",
      "Accuracy for threshold: 0.27  is: 0.8998296949992259\n",
      "Balanced accuracy is:  0.7945808585991141\n",
      "Accuracy for threshold: 0.28  is: 0.8998296949992259\n",
      "Balanced accuracy is:  0.7945808585991141\n",
      "Accuracy for threshold: 0.29000000000000004  is: 0.8997522836352376\n",
      "Balanced accuracy is:  0.792437034012812\n",
      "Accuracy for threshold: 0.3  is: 0.8997522836352376\n",
      "Balanced accuracy is:  0.792437034012812\n",
      "Accuracy for threshold: 0.31  is: 0.8997522836352376\n",
      "Balanced accuracy is:  0.792437034012812\n",
      "Accuracy for threshold: 0.32  is: 0.8997522836352376\n",
      "Balanced accuracy is:  0.792437034012812\n",
      "Accuracy for threshold: 0.33  is: 0.9004489859111318\n",
      "Balanced accuracy is:  0.7903723928209216\n",
      "Accuracy for threshold: 0.34  is: 0.8999845177272023\n",
      "Balanced accuracy is:  0.7666548397862737\n",
      "Accuracy for threshold: 0.35000000000000003  is: 0.9012230995510141\n",
      "Balanced accuracy is:  0.7634901367057764\n",
      "Accuracy for threshold: 0.36000000000000004  is: 0.9058677813903081\n",
      "Balanced accuracy is:  0.756962265771064\n",
      "Accuracy for threshold: 0.37  is: 0.9058677813903081\n",
      "Balanced accuracy is:  0.756962265771064\n",
      "Accuracy for threshold: 0.38  is: 0.9058677813903081\n",
      "Balanced accuracy is:  0.756962265771064\n",
      "Accuracy for threshold: 0.39  is: 0.9058677813903081\n",
      "Balanced accuracy is:  0.7489088487747028\n",
      "Accuracy for threshold: 0.4  is: 0.9060226041182846\n",
      "Balanced accuracy is:  0.7482944180364787\n",
      "Accuracy for threshold: 0.41000000000000003  is: 0.9060226041182846\n",
      "Balanced accuracy is:  0.7482944180364787\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.9060226041182846\n",
      "Balanced accuracy is:  0.7482944180364787\n",
      "Accuracy for threshold: 0.43  is: 0.9060226041182846\n",
      "Balanced accuracy is:  0.7482944180364787\n",
      "Accuracy for threshold: 0.44  is: 0.9060226041182846\n",
      "Balanced accuracy is:  0.7482944180364787\n",
      "Accuracy for threshold: 0.45  is: 0.9060226041182846\n",
      "Balanced accuracy is:  0.7482944180364787\n",
      "Accuracy for threshold: 0.46  is: 0.9060226041182846\n",
      "Balanced accuracy is:  0.7482944180364787\n",
      "Accuracy for threshold: 0.47000000000000003  is: 0.9042421427465552\n",
      "Balanced accuracy is:  0.725947892061085\n",
      "Accuracy for threshold: 0.48000000000000004  is: 0.9049388450224493\n",
      "Balanced accuracy is:  0.7256339936944907\n",
      "Accuracy for threshold: 0.49  is: 0.9049388450224493\n",
      "Balanced accuracy is:  0.7256339936944907\n",
      "Accuracy for threshold: 0.5  is: 0.9054033132063787\n",
      "Balanced accuracy is:  0.723440552914759\n",
      "Best thresh:  0.04\n",
      "Best balanced accuracy: 0.7234\n",
      "Corresponding 1-min(DI, 1/DI) value:    nan\n",
      "Corresponding average odds difference value:    nan\n",
      "Corresponding statistical parity difference value:    nan\n",
      "Corresponding equal opportunity difference value:    nan\n",
      "Corresponding Theil index value: 0.0672\n",
      "Corresponding false positive_rate for privileged:    nan\n",
      "Corresponding false negative_rate for privileged:    nan\n",
      "Corresponding false positive_rate for unpribileged: 0.0500\n",
      "Corresponding false negative_rate for unprivileged: 0.5031\n",
      "Testing Original ...\n",
      "True positive rate is:  0.7822327044025157\n",
      "True negative rate is:  0.8659625622531342\n",
      "Balanced accuracy is:  0.8240976333278249\n",
      "Test Accuracy is:  0.8577179129896269\n",
      "Best balanced accuracy: 0.8241\n",
      "Corresponding 1-min(DI, 1/DI) value:    nan\n",
      "Corresponding average odds difference value:    nan\n",
      "Corresponding statistical parity difference value:    nan\n",
      "Corresponding equal opportunity difference value:    nan\n",
      "Corresponding Theil index value: 0.0576\n",
      "Corresponding false positive_rate for privileged:    nan\n",
      "Corresponding false negative_rate for privileged:    nan\n",
      "Corresponding false positive_rate for unpribileged: 0.1340\n",
      "Corresponding false negative_rate for unprivileged: 0.2178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\aif360\\metrics\\classification_metric.py:278: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TPR=TP / P, TNR=TN / N, FPR=FP / N, FNR=FN / P,\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\aif360\\metrics\\classification_metric.py:279: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  GTPR=GTP / P, GTNR=GTN / N, GFPR=GFP / N, GFNR=GFN / P,\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\aif360\\metrics\\classification_metric.py:673: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return (self.num_pred_positives(privileged=privileged)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 11618\n",
      "Number of test samples (ntest): 11646\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1300\n",
      "Number of test samples (ntest): 1272\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 12918, Test = 12918\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.7472144018302211\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 11618, Test = 11646\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.4289956055183584\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 1300, Test = 1272\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.7472144018302211\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 11618, Test = 11646\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.4289956055183584\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1300, Test = 1272\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.7472144018302211\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m orig_metrics, orig_mia_metrics \u001b[38;5;241m=\u001b[39m test_cases\u001b[38;5;241m.\u001b[39mrun_original(dataset_orig_train, dataset_orig_val, dataset_orig_test, BASELINE, orig_metrics, orig_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, THRESH_ARR, DISPLAY, SCALER) \n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# synthetic data mitigator\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m metric_transf_train, transf_metrics, transf_mia_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtest_cases\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_oversample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_orig_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_orig_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_orig_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivileged_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munprivileged_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_rate_privileged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_rate_unprivileged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBASELINE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransf_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransf_mia_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTHRESH_ARR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDISPLAY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOS_MODE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCALER\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# statistics of favored/positive class AFTER transf\u001b[39;00m\n\u001b[0;32m     71\u001b[0m favor_metric_transf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_favor\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m metric_transf_train\u001b[38;5;241m.\u001b[39mbase_rate()\n",
      "File \u001b[1;32m~\\OneDrive - ADA University\\Desktop\\Senior Design Project\\Membership Inference Attacks\\Codes\\MIA_Fairness_Privacy\\test_algorithms.py:28\u001b[0m, in \u001b[0;36mTestAlgorithms.run_oversample\u001b[1;34m(self, dataset_orig_train, dataset_orig_val, dataset_orig_test, privileged_groups, unprivileged_groups, base_rate_privileged, base_rate_unprivileged, model_type, transf_metrics, transf_mia_metrics, f_label, uf_label, THRESH_ARR, DISPLAY, OS_MODE, SCALER)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m------------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m synth_mitigator \u001b[38;5;241m=\u001b[39m SyntheticMitigator()\n\u001b[1;32m---> 28\u001b[0m metric_transf_train, transf_metrics, transf_mia_metrics \u001b[38;5;241m=\u001b[39m \u001b[43msynth_mitigator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_mitigator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_orig_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_orig_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_orig_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivileged_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munprivileged_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_rate_privileged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_rate_unprivileged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransf_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransf_mia_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTHRESH_ARR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDISPLAY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOS_MODE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCALER\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#synth_mitigator.run_explainer(dataset_orig_train, dataset_orig_val, dataset_orig_test, privileged_groups, unprivileged_groups, base_rate_privileged, base_rate_unprivileged, model_type, transf_metrics, f_label, uf_label, THRESH_ARR, DISPLAY, OS_MODE, SCALER)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metric_transf_train, transf_metrics, transf_mia_metrics\n",
      "File \u001b[1;32m~\\OneDrive - ADA University\\Desktop\\Senior Design Project\\Membership Inference Attacks\\Codes\\MIA_Fairness_Privacy\\mitigators.py:79\u001b[0m, in \u001b[0;36mSyntheticMitigator.run_mitigator\u001b[1;34m(self, dataset_orig_train, dataset_orig_val, dataset_orig_test, privileged_groups, unprivileged_groups, base_rate_privileged, base_rate_unprivileged, model_type, transf_metrics, transf_mia_metrics, f_label, uf_label, THRESH_ARR, DISPLAY, OS_MODE, SCALER)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_mitigator\u001b[39m (\u001b[38;5;28mself\u001b[39m, dataset_orig_train, dataset_orig_val, dataset_orig_test, \n\u001b[0;32m     73\u001b[0m                    privileged_groups, unprivileged_groups, \n\u001b[0;32m     74\u001b[0m                    base_rate_privileged, base_rate_unprivileged, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m                    THRESH_ARR, DISPLAY, OS_MODE, SCALER):\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# generating synthetic data\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     dataset_transf_train \u001b[38;5;241m=\u001b[39m \u001b[43msynthetic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_orig_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munprivileged_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_rate_privileged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_rate_unprivileged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mOS_MODE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morigin, transf: \u001b[39m\u001b[38;5;124m'\u001b[39m, dataset_orig_train\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dataset_transf_train\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     82\u001b[0m     metric_transf_train \u001b[38;5;241m=\u001b[39m BinaryLabelDatasetMetric(dataset_transf_train,\n\u001b[0;32m     83\u001b[0m                                                    unprivileged_groups\u001b[38;5;241m=\u001b[39munprivileged_groups,\n\u001b[0;32m     84\u001b[0m                                                    privileged_groups\u001b[38;5;241m=\u001b[39mprivileged_groups)\n",
      "File \u001b[1;32m~\\OneDrive - ADA University\\Desktop\\Senior Design Project\\Membership Inference Attacks\\Codes\\MIA_Fairness_Privacy\\oversample.py:140\u001b[0m, in \u001b[0;36msynthetic\u001b[1;34m(dataset, unprivileged_groups, bp, bnp, f_label, uf_label, os_mode, sampling_strategy)\u001b[0m\n\u001b[0;32m    137\u001b[0m     dataset_transf_train\u001b[38;5;241m.\u001b[39mprotected_attributes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((dataset_transf_train\u001b[38;5;241m.\u001b[39mprotected_attributes, sample_unfavor_priv\u001b[38;5;241m.\u001b[39mprotected_attributes))\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# [Method 2] inflate unprivileged favored class\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     _, sample_favor_unpriv \u001b[38;5;241m=\u001b[39m \u001b[43msynthetic_favor_unpriv\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munprivileged_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbnp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     dataset_transf_train\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((dataset_transf_train\u001b[38;5;241m.\u001b[39mfeatures, sample_favor_unpriv\u001b[38;5;241m.\u001b[39mfeatures))\n\u001b[0;32m    142\u001b[0m     dataset_transf_train\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((dataset_transf_train\u001b[38;5;241m.\u001b[39mlabels, sample_favor_unpriv\u001b[38;5;241m.\u001b[39mlabels))\n",
      "File \u001b[1;32m~\\OneDrive - ADA University\\Desktop\\Senior Design Project\\Membership Inference Attacks\\Codes\\MIA_Fairness_Privacy\\oversample.py:110\u001b[0m, in \u001b[0;36msynthetic_favor_unpriv\u001b[1;34m(dataset, unprivileged_groups, bp, bnp, f_label, uf_label, sampling_strategy)\u001b[0m\n\u001b[0;32m    108\u001b[0m     inflate_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(((n_extra_sample\u001b[38;5;241m+\u001b[39mn_unpriv_favor)\u001b[38;5;241m/\u001b[39mn_unpriv_unfavor)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     inflate_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_extra_sample\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mn_unpriv_favor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mn_unpriv_unfavor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m dataset_transf_refprivileged_train, extra_favored_unpriv  \u001b[38;5;241m=\u001b[39m balance(unprivileged_dataset, n_extra_sample, inflate_rate, f_label, uf_label)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset_transf_refprivileged_train, extra_favored_unpriv\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "# run mitigating algorithms\n",
    "for i in range(N):\n",
    "    # split dataset into train, validation, and test\n",
    "    dataset_orig_train, dataset_orig_test = dataset_orig.split([p], shuffle=True)\n",
    "    dataset_orig_val = dataset_orig_test\n",
    "    print(\"#### Train dataset's features are as below:\")\n",
    "    print(dataset_orig_train.features)\n",
    "\n",
    "    # favorable and unfavorable labels and feature_names\n",
    "    f_label = dataset_orig_train.favorable_label\n",
    "    uf_label = dataset_orig_train.unfavorable_label\n",
    "    feature_names = dataset_orig_train.feature_names\n",
    "\n",
    "    # introduce label or selection biases, assuming the original data is fair\n",
    "    if BIAS_TYPE == 'label':\n",
    "        dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    elif BIAS_TYPE == 'selection':\n",
    "        dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    else:\n",
    "        print('no bias type specified')\n",
    "\n",
    "    # show data info\n",
    "    print(\"#### Training Dataset shape\")\n",
    "    print(dataset_orig_train.features.shape)\n",
    "    print(\"#### Favorable and unfavorable labels\")\n",
    "    print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "    print(\"#### Protected attribute names\")\n",
    "    print(dataset_orig_train.protected_attribute_names)\n",
    "    print(\"#### Privileged and unprivileged protected groups\")\n",
    "    print(privileged_groups, unprivileged_groups)\n",
    "    print(\"#### Privileged and unprivileged protected attribute values\")\n",
    "    print(dataset_orig_train.privileged_protected_attributes, dataset_orig_train.unprivileged_protected_attributes)\n",
    "    print(\"#### Dataset feature names\")\n",
    "    print(dataset_orig_train.feature_names)\n",
    "\n",
    "    # check fairness on the original data\n",
    "    metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    print(\"privileged vs. unprivileged: \", metric_orig_train.num_positives(privileged=True) + metric_orig_train.num_negatives(privileged=True), metric_orig_train.num_positives(privileged=False) + metric_orig_train.num_negatives(privileged=False)) \n",
    "    base_rate_unprivileged = metric_orig_train.base_rate(privileged=False)\n",
    "    base_rate_privileged = metric_orig_train.base_rate(privileged=True)\n",
    "    print('base_pos unpriv: ', base_rate_unprivileged)\n",
    "    print('base_pos priv: ', base_rate_privileged)\n",
    "    print('number of favorable labels: ', np.count_nonzero(dataset_orig_train.labels==f_label))\n",
    "    print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "    # statistics of favored/positive class BEFORE transf \n",
    "    priv_metric_orig['total_priv'] += metric_orig_train.num_instances(privileged = True) \n",
    "    priv_metric_orig['total_unpriv'] += metric_orig_train.num_instances(privileged = False) \n",
    "    favor_metric_orig['total_favor'] += metric_orig_train.base_rate()\n",
    "    favor_metric_orig['total_unfavor'] += 1 - metric_orig_train.base_rate()\n",
    "    favor_metric_orig['priv_favor'] += metric_orig_train.base_rate(privileged = True)\n",
    "    favor_metric_orig['priv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = True)\n",
    "    favor_metric_orig['unpriv_favor'] += metric_orig_train.base_rate(privileged = False)\n",
    "    favor_metric_orig['unpriv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = False)\n",
    "\n",
    "    print(\"#### Train shape, validation shape, test shape\")\n",
    "    print(dataset_orig_train.features.shape, dataset_orig_val.features.shape, dataset_orig_test.features.shape)\n",
    "\n",
    "    # testing mitigation methods \n",
    "    test_cases = TestAlgorithms(BASELINE)\n",
    "\n",
    "    # null mitigator\n",
    "    orig_metrics, orig_mia_metrics = test_cases.run_original(dataset_orig_train, dataset_orig_val, dataset_orig_test, BASELINE, orig_metrics, orig_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, THRESH_ARR, DISPLAY, SCALER) \n",
    "\n",
    "    # synthetic data mitigator\n",
    "    metric_transf_train, transf_metrics, transf_mia_metrics = test_cases.run_oversample(dataset_orig_train, dataset_orig_val, dataset_orig_test, privileged_groups, unprivileged_groups, base_rate_privileged, base_rate_unprivileged, BASELINE, transf_metrics, transf_mia_metrics, f_label, uf_label, THRESH_ARR, DISPLAY, OS_MODE, SCALER)\n",
    "    \n",
    "    # statistics of favored/positive class AFTER transf\n",
    "    favor_metric_transf['total_favor'] += metric_transf_train.base_rate()\n",
    "    favor_metric_transf['total_unfavor'] += 1 - metric_transf_train.base_rate()\n",
    "    favor_metric_transf['priv_favor'] += metric_transf_train.base_rate(privileged = True)\n",
    "    favor_metric_transf['priv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = True)\n",
    "    favor_metric_transf['unpriv_favor'] += metric_transf_train.base_rate(privileged = False)\n",
    "    favor_metric_transf['unpriv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = False)\n",
    "\n",
    "    # dir mitigator\n",
    "    dir_metrics, dir_mia_metrics = test_cases.run_dir(dataset_orig_train, dataset_orig_val, dataset_orig_test,  sens_attr, BASELINE, dir_metrics, dir_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, THRESH_ARR, DISPLAY, SCALER) \n",
    "    \n",
    "    # reweigh mitigator\n",
    "    reweigh_metrics, reweigh_mia_metrics = test_cases.run_rew(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, reweigh_metrics, reweigh_mia_metrics, THRESH_ARR, DISPLAY, SCALER)\n",
    "\n",
    "    # egr mitigator, in-processing\n",
    "    train_test_egr, egr_metrics, egr_mia_metrics = test_cases.run_egr(dataset_orig_train, dataset_orig_val, dataset_orig_test, egr_metrics, egr_mia_metrics, BASELINE, f_label, uf_label, unprivileged_groups, privileged_groups,THRESH_ARR, DISPLAY, SCALER)\n",
    "    # egr gave error so I replaced it with reweigh\n",
    "#     egr_metrics, egr_mia_metrics = test_cases.run_rew(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, egr_metrics, egr_mia_metrics, THRESH_ARR, DISPLAY, SCALER)\n",
    "\n",
    "    # cpp mitigator\n",
    "    cpp_metrics = test_cases.run_cpp(dataset_orig_train, dataset_orig_val, dataset_orig_test, cpp_metrics, BASELINE, unprivileged_groups, privileged_groups, THRESH_ARR, SCALER)\n",
    "\n",
    "    # ro mitigator\n",
    "    # ro_metrics = test_cases.run_ro(dataset_orig_train, dataset_orig_val, dataset_orig_test, ro_metrics, BASELINE, unprivileged_groups, privileged_groups, THRESH_ARR, SCALER)\n",
    "\n",
    "    if (BASELINE == 'lr'):\n",
    "        pr_orig_metrics = test_cases.run_pr(dataset_orig_train, dataset_orig_val, dataset_orig_test, pr_orig_metrics, sens_attr, f_label, uf_label, unprivileged_groups, privileged_groups, THRESH_ARR, DISPLAY, SCALER) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f7847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_orig.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90de2a9",
   "metadata": {},
   "source": [
    "## Display Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a3d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(X, pd.DataFrame):\n",
    "    A = X[[0]]  # For DataFrame, use column names\n",
    "    print(\"For dataframe, A: \", A)\n",
    "else:\n",
    "    A = X[:, [0]]  # For NumPy array, use column indices\n",
    "    print(len(A))\n",
    "    print(\"For non-dataframe, A: \", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72632350",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig_copy = priv_metric_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8530a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b736dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73a4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig = priv_metric_orig_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf623751",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "print('1)\\n')\n",
    "print(DATASET)\n",
    "print(dataset_orig_train.features.shape[0])\n",
    "\n",
    "print('2)\\n')\n",
    "priv_metric_orig = {k: [v/N] for (k,v) in priv_metric_orig.items()}\n",
    "results = [priv_metric_orig]\n",
    "tr = pd.Series(['orig'], name='num_instance')\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis = 0).set_index([tr])\n",
    "print(df)\n",
    "\n",
    "print('3)\\n')\n",
    "favor_metric_orig = {k: [v/N] for (k,v) in favor_metric_orig.items()}\n",
    "favor_metric_transf = {k: [v/N] for (k,v) in favor_metric_transf.items()}\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "results = [favor_metric_orig, favor_metric_transf]\n",
    "tr = pd.Series(['orig'] + ['transf'], name='dataset')\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis = 0).set_index([tr])\n",
    "print(df)\n",
    "\n",
    "print('4)\\n')\n",
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_error_metrics = {k: [statistics.stdev(v)] for (k,v) in orig_metrics.items()}\n",
    "transf_error_metrics = {k: [statistics.stdev(v)] for (k,v) in transf_metrics.items()}\n",
    "reweigh_error_metrics = {k: [statistics.stdev(v)] for (k,v) in reweigh_metrics.items()}\n",
    "dir_error_metrics = {k: [statistics.stdev(v)] for (k,v) in dir_metrics.items()}\n",
    "egr_error_metrics = {k: [statistics.stdev(v)] for (k,v) in egr_metrics.items()}\n",
    "pr_orig_error_metrics = {k: [statistics.stdev(v)] for (k,v) in pr_orig_metrics.items()}\n",
    "cpp_error_metrics = {k: [statistics.stdev(v)] for (k,v) in cpp_metrics.items()}\n",
    "ro_error_metrics = {k: [statistics.stdev(v)] for (k,v) in ro_metrics.items()}\n",
    "\n",
    "# mean value metrics\n",
    "orig_metrics_mean = {k: [sum(v)/N] for (k,v) in orig_metrics.items()}\n",
    "transf_metrics_mean = {k: [sum(v)/N] for (k,v) in transf_metrics.items()}\n",
    "reweigh_metrics_mean = {k:[sum(v)/N] for (k,v) in reweigh_metrics.items()}\n",
    "dir_metrics_mean = {k:[sum(v)/N] for (k,v) in dir_metrics.items()}\n",
    "egr_metrics_mean = {k:[sum(v)/N] for (k,v) in egr_metrics.items()}\n",
    "pr_orig_metrics_mean = {k: [sum(v)/N] for (k,v) in pr_orig_metrics.items()}\n",
    "cpp_metrics_mean = {k: [sum(v)/N] for (k,v) in cpp_metrics.items()}\n",
    "ro_metrics_mean = {k: [sum(v)/N] for (k,v) in ro_metrics.items()}\n",
    "\n",
    "# Python paired sample t-test\n",
    "from scipy.stats import ttest_rel\n",
    "def paired_t (a, b):\n",
    "    np_a = np.array(a)\n",
    "    np_b = np.array(b)\n",
    "    s, p = ttest_rel(np.absolute(np_a), np.absolute(np_b))\n",
    "    return p\n",
    "\n",
    "def acc_diff (a, b):\n",
    "    np_a = np.array(a)\n",
    "    np_b = np.array(b)\n",
    "    delta = np_a - np_b\n",
    "    m = statistics.mean(delta)\n",
    "    s = statistics.stdev(delta)\n",
    "    return [m, s]\n",
    "\n",
    "if BASELINE == 'lr':\n",
    "    plot_algo_lr(orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, egr_metrics_mean, pr_orig_metrics_mean, cpp_metrics_mean, ro_metrics_mean, orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, egr_error_metrics, pr_orig_error_metrics, cpp_error_metrics, ro_error_metrics, BASELINE)\n",
    "    stat =  {k: [paired_t(transf_metrics[k], v)] for (k,v) in orig_metrics.items()}\n",
    "    print(\"5)\")\n",
    "    print(stat)\n",
    "else:\n",
    "    plot_algo(orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, egr_metrics_mean, cpp_metrics_mean, ro_metrics_mean, orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, egr_error_metrics, cpp_error_metrics, ro_error_metrics, BASELINE)\n",
    "    stat =  {k: [paired_t(transf_metrics[k], v)] for (k,v) in orig_metrics.items()}\n",
    "    print(stat)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1627a85",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f14ab",
   "metadata": {},
   "source": [
    "### Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c6d438",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = BASELINE\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_metrics_mean,\n",
    "        transf_metrics_mean,\n",
    "        dir_metrics_mean,\n",
    "        reweigh_metrics_mean,\n",
    "        egr_metrics_mean,\n",
    "        pr_orig_metrics_mean,\n",
    "        cpp_metrics_mean,\n",
    "        ro_metrics_mean]\n",
    "\n",
    "\n",
    "errors = [orig_error_metrics,\n",
    "        transf_error_metrics,\n",
    "        dir_error_metrics,\n",
    "        reweigh_error_metrics,\n",
    "        egr_error_metrics,\n",
    "        pr_orig_error_metrics,\n",
    "        cpp_error_metrics,\n",
    "        ro_error_metrics]\n",
    "\n",
    "index = pd.Series([model_type+'_orig']+ [model_type+'_syn']+ [model_type+'_dir']+ [model_type+'_rew']+ [model_type+'_egr'] + [model_type+'_cpp'], name='Classifier Bias Mitigator')\n",
    "\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis=0).set_index(index)\n",
    "df_error = pd.concat([pd.DataFrame(metrics) for metrics in errors], axis=0).set_index(index)\n",
    "ax = df.plot.bar(yerr=df_error, capsize=4, rot=0, subplots=True, title=['','','','','', '', '', '', '', ''], fontsize = 12, figsize=(10,10))\n",
    "plot1 = ax[0]\n",
    "plot1.set_ylim=([0, 0.8])\n",
    "plot2 = ax[1]\n",
    "plot2.set_ylim=([-0.5, 0])\n",
    "plot3 = ax[2]\n",
    "plot3.set_ylim=([0, 1])\n",
    "plot4 = ax[3]\n",
    "plot4.set_ylim=([-0.5, 0])\n",
    "plot5 = ax[4]\n",
    "plot5.set_ylim=([-0.5, 0])\n",
    "plot5 = ax[5]\n",
    "plot5.set_ylim=([0, 0.2])\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.5, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6be0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7aff8d",
   "metadata": {},
   "source": [
    "## Visualization of MIA results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588cc377",
   "metadata": {},
   "source": [
    "### Visualization of MIA Attacks against various Fairness Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a42bd",
   "metadata": {},
   "source": [
    "#### Privacy risk subpopulations vs Fairness with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dddfde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "%matplotlib inline\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "egr_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in egr_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "# cpp_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in cpp_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "egr_mia_metrics_mean = {k:sum(v)/N for (k,v) in egr_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "# cpp_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6882740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "           transf_mia_metrics_mean,\n",
    "           dir_mia_metrics_mean,\n",
    "           reweigh_mia_metrics_mean,\n",
    "           egr_mia_metrics_mean\n",
    "          ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "          transf_mia_error_metrics,\n",
    "          dir_mia_error_metrics,\n",
    "          reweigh_mia_error_metrics,\n",
    "          egr_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn']+ ['dir']+ ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df1431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = df[['subpopulation_0.0_label_0.0_mia_privacy_risk',\n",
    "       'subpopulation_0.0_label_1.0_mia_privacy_risk',\n",
    "       'subpopulation_1.0_label_0.0_mia_privacy_risk',\n",
    "       'subpopulation_1.0_label_1.0_mia_privacy_risk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d711e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f230c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabular Format\n",
    "# importing the modules\n",
    "from tabulate import tabulate\n",
    "\n",
    " \n",
    "# displaying the DataFrame\n",
    "print(tabulate(df_groups.T, headers = 'keys', tablefmt = 'simple'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a2e6d",
   "metadata": {},
   "source": [
    "### Visualizing using novel technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faed82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_error_metrics = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "egr_mia_error_metrics = {k: v for (k,v) in egr_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "#orig_mia_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_error_metrics.keys():\n",
    "    for val in orig_mia_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in egr_mia_error_metrics.keys():\n",
    "    for val in egr_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"egr\", key.replace(\"_mia_attacker_advantage\", \"\"), val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b110698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"Privacy Risk\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8a5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only subgroups\n",
    "df_subgroups = df[~((df[\"MIA\"] == \"entire_dataset_label_0.0_mia_privacy_risk\") | (df[\"MIA\"] == \"entire_dataset_label_1.0_mia_privacy_risk\")) ]\n",
    "df_subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df3d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15,8))\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df_subgroups, x=\"MIA\", y=\"Privacy Risk\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Privacy Risk\" )\n",
    "g.set(ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359dc0bf",
   "metadata": {},
   "source": [
    "### ROC curves and AUC scores with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7b52ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb5d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for orig dataset with different subpopulations\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for key in [\"entire_dataset_mia_result\", \"subpopulation_0.0_label_0.0_mia_result\",\n",
    "            \"subpopulation_0.0_label_1.0_mia_result\", \"subpopulation_1.0_label_0.0_mia_result\", \"subpopulation_1.0_label_1.0_mia_result\"]:\n",
    "     # fprs = [mia_res.fpr for mia_res in orig_mia_metrics[key]]\n",
    "    # tprs = [mia_res.tpr for mia_res in orig_mia_metrics[key]]\n",
    "    tprs = []\n",
    "    \n",
    "    # aucs = [mia_res.get_auc() for mia_res in orig_mia_metrics[key]]\n",
    "    aucs = []\n",
    "\n",
    "    # mean_fpr = np.mean(fprs, axis=0)\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "    for mia_res in orig_mia_metrics[key]:\n",
    "        interp_tpr = np.interp(mean_fpr, mia_res.fpr, mia_res.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(mia_res.get_auc())\n",
    "    \n",
    "    #print(mean_fpr)\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    \n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    \n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        #color=\"b\",\n",
    "        label=r\"Mean ROC for %s $\\pm$ 1 std. dev. (AUC = %0.2f $\\pm$ %0.2f)\" % ( key ,mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        #label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve with variability\",\n",
    ")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ff10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entire dataset with different subpopulations\n",
    "# fig, ax = plt.subplots(figsize=(12, 10))\n",
    "fig, ax = plt.subplots(figsize=(24, 18))\n",
    "\n",
    "for mia_metrics, name in zip([orig_mia_metrics, transf_mia_metrics, dir_mia_metrics, reweigh_mia_metrics], [\"orig\", \"syn\", \"dir\", \"reweigh\"] ):\n",
    "    for key in [\"entire_dataset_mia_result\", \"subpopulation_0.0_label_0.0_mia_result\",\n",
    "            \"subpopulation_0.0_label_1.0_mia_result\", \"subpopulation_1.0_label_0.0_mia_result\",\n",
    "                \"subpopulation_1.0_label_1.0_mia_result\"]:\n",
    "   \n",
    "        # fprs = [mia_res.fpr for mia_res in orig_mia_metrics[key]]\n",
    "        # tprs = [mia_res.tpr for mia_res in orig_mia_metrics[key]]\n",
    "        tprs = []\n",
    "        # aucs = [mia_res.get_auc() for mia_res in orig_mia_metrics[key]]\n",
    "        aucs = []\n",
    "\n",
    "        # mean_fpr = np.mean(fprs, axis=0)\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "        for mia_res in mia_metrics[key]:\n",
    "            interp_tpr = np.interp(mean_fpr, mia_res.fpr, mia_res.tpr)\n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "            aucs.append(mia_res.get_auc())\n",
    "\n",
    "        #print(mean_fpr)\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std(aucs)\n",
    "\n",
    "        ax.plot(\n",
    "            mean_fpr,\n",
    "            mean_tpr,\n",
    "            #color=\"b\",\n",
    "            label=r\"%s Mean ROC for %s $\\pm$ 1 std. dev. (AUC = %0.2f $\\pm$ %0.2f)\" % (name, key ,mean_auc, std_auc),\n",
    "            lw=2,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        std_tpr = np.std(tprs, axis=0)\n",
    "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        ax.fill_between(\n",
    "            mean_fpr,\n",
    "            tprs_lower,\n",
    "            tprs_upper,\n",
    "            color=\"grey\",\n",
    "            alpha=0.2,\n",
    "            #label=r\"$\\pm$ 1 std. dev.\",\n",
    "        )\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve for MIA attacks against Fairness Approaches\",\n",
    ")\n",
    "ax.legend(loc=\"lower right\")\n",
    "# ax.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entire dataset\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "for mia_res in orig_mia_metrics[\"entire_dataset_mia_result\"]:\n",
    "    plt.plot(mia_res.fpr,mia_res.tpr,label=f\"{mia_res.get_name()} auc={mia_res.get_auc()}\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e701aad9",
   "metadata": {},
   "source": [
    "## MIA Attacks AUC vs Fairness Bar Chart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f18425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "egr_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in egr_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "egr_mia_metrics_mean = {k:sum(v)/N for (k,v) in egr_mia_metrics.items() if k.endswith(\"mia_auc\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a025ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b078a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuazlization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "        transf_mia_metrics_mean,\n",
    "        dir_mia_metrics_mean,\n",
    "        reweigh_mia_metrics_mean,\n",
    "        egr_mia_metrics_mean\n",
    "        ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "        transf_mia_error_metrics,\n",
    "        dir_mia_error_metrics,\n",
    "        reweigh_mia_error_metrics,\n",
    "          egr_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn']+ ['dir']+ ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2233661a",
   "metadata": {},
   "source": [
    "###  MIA Attackers Advantage Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f09191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data structures to plot point categorical plot from seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ef741",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "egr_mia_error_metrics = {k: v for (k,v) in egr_mia_metrics.items() if k.endswith(\"attacker_advantage\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87375802",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_metrics_att_ad.keys():\n",
    "    for val in orig_mia_metrics_att_ad[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in egr_mia_error_metrics.keys():\n",
    "    for val in egr_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"egr\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "advantage_metrics_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105df8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"attacker_advantage\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac8578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting without scaling y limis to 1\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"attacker_advantage\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's Advantage\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf746e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15,8))\n",
    "\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"attacker_advantage\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's Advantage\" )\n",
    "g.set(ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b0356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(orig_mia_metrics_att_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "egr_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in egr_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "egr_mia_metrics_mean = {k:sum(v)/N for (k,v) in egr_mia_metrics.items() if k.endswith(\"attacker_advantage\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e9be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuazlization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "        transf_mia_metrics_mean,\n",
    "        dir_mia_metrics_mean,\n",
    "        reweigh_mia_metrics_mean,\n",
    "           egr_mia_metrics_mean\n",
    "        ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "        transf_mia_error_metrics,\n",
    "        dir_mia_error_metrics,\n",
    "        reweigh_mia_error_metrics,\n",
    "          egr_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn']+ ['dir']+ ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1309a4",
   "metadata": {},
   "source": [
    "## PPV Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "egr_mia_error_metrics = {k: v for (k,v) in egr_mia_metrics.items() if k.endswith(\"mia_ppv\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14018577",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_metrics_att_ad.keys():\n",
    "    for val in orig_mia_metrics_att_ad[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in egr_mia_error_metrics.keys():\n",
    "    for val in egr_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"egr\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "advantage_metrics_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95980069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"PPV\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff9b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting without scaling y limis to 1\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"PPV\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's PPV\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38297706",
   "metadata": {},
   "source": [
    "# Dataset Exploration for comparison with Shokri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c85d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame([dataset_orig.features, dataset_orig.labels]).drop_duplicates()\n",
    "\n",
    "df = pd.DataFrame(dataset_orig.features, columns=dataset_orig.feature_names)\n",
    "\n",
    "df[\"labels\"] = dataset_orig.labels\n",
    "df\n",
    "#df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d14528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"age\", \"labels\"]].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f7423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352b318b",
   "metadata": {},
   "source": [
    "## DT Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd7c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_orig_model_metrics(dataset_orig_train, dataset_orig_test, unprivileged_groups, f_label, uf_label, BASELINE, SCALER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feceb031",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_egr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
