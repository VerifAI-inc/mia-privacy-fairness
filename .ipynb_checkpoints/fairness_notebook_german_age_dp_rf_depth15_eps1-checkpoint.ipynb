{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8c9f6b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "151964f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f57d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from data_utils import DatasetBuilder\n",
    "from metrics_utils import compute_metrics, describe_metrics, get_test_metrics, test\n",
    "from plot_utils import plot\n",
    "from mitigators import NullMitigator, SyntheticMitigator, DIRMitigator, ReweighMitigator, EGMitigator, PRMitigator, CPPMitigator, ROMitigator \n",
    "from test_algorithms import TestAlgorithms\n",
    "from plot_utils import plot_algo_lr, plot_algo\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from oversample import label_bias, selection_bias \n",
    "from sklearn import preprocessing\n",
    "from privacy_meter.dataset import Dataset\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180b2a8",
   "metadata": {},
   "source": [
    "## Arguments & Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "564c7837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-a', '--attack'], dest='attack', nargs=None, const=None, default='mia1', type=None, choices=['mia1', 'mia2'], required=False, help='attacks: our implementation, their implementation', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct argument parser\n",
    "import argparse\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--data\", choices=['adult', 'compas', 'german', 'bank', 'meps19', 'grade', 'law_sex', 'law_race', 'law_aif_gender', 'law_aif_race'], default='compas', help=\"dataset: adult, compas, german, bank, meps19, grade\")\n",
    "ap.add_argument(\"-c\", \"--classifier\", choices=['lr', 'rf', 'svm', 'nn', 'nb'], default='lr', help=\"baseline model: lr, rf, svm, nn, nb, dt\")\n",
    "ap.add_argument(\"-m\", \"--mitigator\", choices=['dir', 'rew', 'egr', 'pr', 'cpp', 'ro'], required=False, help=\"mitigators: dir, rew, egr, pr, cpp, ro\")\n",
    "ap.add_argument(\"-b\", \"--bias\", default=0., help=\"amount of bias: o-1\")\n",
    "ap.add_argument(\"-t\", \"--biastype\", choices=['label', 'selection', 'none'], default='none', help=\"amount of bias: o-1\")\n",
    "ap.add_argument(\"-o\", \"--os\", default=2, help=\"oversample mode: 1: privi unfav 2: unpriv fav\")\n",
    "ap.add_argument(\"-a\", \"--attack\", choices=['mia1', 'mia2'], default='mia1', help=\"attacks: our implementation, their implementation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4f8856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['']\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b063bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 'compas',\n",
       " 'classifier': 'lr',\n",
       " 'mitigator': None,\n",
       " 'bias': 0.0,\n",
       " 'biastype': 'none',\n",
       " 'os': 2,\n",
       " 'attack': 'mia1'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0dd1c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"german_age\"\n",
    "BASELINE = \"dprf\" \n",
    "MITIGATOR = args[\"mitigator\"]\n",
    "BIAS = float(args[\"bias\"])\n",
    "BIAS_TYPE = args[\"biastype\"]\n",
    "OS_MODE = 2\n",
    "ATTACK = \"mia2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16266c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# global constants\n",
    "if BASELINE == 'svm' or BASELINE == 'nn':\n",
    "    SCALER = False \n",
    "else:\n",
    "    SCALER = False \n",
    "DISPLAY = False \n",
    "THRESH_ARR = 0.5\n",
    "\n",
    "# loop ten times \n",
    "N = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49502a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of favor and unfavor\n",
    "priv_metric_orig = defaultdict(float)\n",
    "favor_metric_orig = defaultdict(float)\n",
    "favor_metric_transf = defaultdict(float)\n",
    "\n",
    "# for each pre-processing approach, we create a mia_metric_results\n",
    "orig_metrics = defaultdict(list)\n",
    "orig_mia_metrics = defaultdict(list)\n",
    "\n",
    "transf_metrics = defaultdict(list) \n",
    "transf_mia_metrics = defaultdict(list) \n",
    "\n",
    "reweigh_metrics = defaultdict(list) \n",
    "reweigh_mia_metrics = defaultdict(list) \n",
    "\n",
    "dir_metrics = defaultdict(list) \n",
    "dir_mia_metrics = defaultdict(list) \n",
    "\n",
    "eg_metrics = defaultdict(list) \n",
    "eg_mia_metrics = defaultdict(list) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a48a7",
   "metadata": {},
   "source": [
    "## Loading & Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52a31333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'german_age'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da867c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside load_data(), self.DATASET = german_age\n"
     ]
    }
   ],
   "source": [
    "# load dataset and set the groups\n",
    "dataset_builder =  DatasetBuilder(DATASET)\n",
    "dataset_orig = dataset_builder.load_data()\n",
    "sens_attr = dataset_orig.protected_attribute_names[0]\n",
    "unprivileged_groups = dataset_builder.unprivileged_groups\n",
    "privileged_groups = dataset_builder.privileged_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9aabd2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 57)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb84777c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'age': 1}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "privileged_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a78a2150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'age'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fedd14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# favorable and unfavorable labels and feature_names\n",
    "f_label = dataset_orig.favorable_label\n",
    "uf_label = dataset_orig.unfavorable_label\n",
    "feature_names = dataset_orig.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fb1ad08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if ATTACK == \"mia1\":\n",
    "    # training data split ratio\n",
    "    p = 0.5\n",
    "    # split dataset into train, validation, and test\n",
    "    dataset_orig_train, dataset_orig_test = dataset_orig.split([p], shuffle=True)\n",
    "    dataset_orig_val = dataset_orig_test\n",
    "    print(dataset_orig_train.features)\n",
    "\n",
    "    # introduce label or selection biases, assuming the original data is fair\n",
    "    if BIAS_TYPE == 'label':\n",
    "        dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    elif BIAS_TYPE == 'selection':\n",
    "        dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    else:\n",
    "        print('no bias type specified')\n",
    "        \n",
    "    dataset_orig_train\n",
    "    dataset_orig_train?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cfd5f8",
   "metadata": {},
   "source": [
    "## Run Mitigating Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3ae7f8",
   "metadata": {},
   "source": [
    "### Setup for MIA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad51a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14350dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ATTACK == \"mia2\":\n",
    "    # prepare data format\n",
    "    X = dataset_orig.features\n",
    "    y_true = dataset_orig.labels.ravel()\n",
    "    sens_attr = dataset_orig.protected_attribute_names[0]\n",
    "    sens_attr_index = dataset_orig.feature_names.index(sens_attr)\n",
    "    sensitive_features = dataset_orig.features[:, sens_attr_index]\n",
    "\n",
    "    X_other_features = np.delete(X, sens_attr_index, axis=1)\n",
    "    X_other_features_normalized = preprocessing.normalize(X_other_features, norm='l2')\n",
    "\n",
    "    # Reconstruct X by combining the sensitive attribute and the normalized features\n",
    "    # Insert the sensitive attribute back into its original position\n",
    "    X_normalized = np.insert(X_other_features_normalized, sens_attr_index, sensitive_features, axis=1)\n",
    "    X = X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89c1ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_indices_reference():\n",
    "    # Determine split sizes proportionally (to sum up to the full dataset size)\n",
    "    num_train_points = int(X.shape[0] * 0.12)\n",
    "    num_test_points = int(X.shape[0] * 0.12)\n",
    "    num_population_points = int(X.shape[0] * 0.3)  # Reduced from 30000\n",
    "\n",
    "    # Start with all indices\n",
    "    all_indices = np.arange(X.shape[0])\n",
    "\n",
    "    # Select train indices without replacement\n",
    "    train_index = np.random.choice(all_indices, num_train_points, replace=False)\n",
    "    # Remove train indices from available indices\n",
    "    remaining_indices = np.setdiff1d(all_indices, train_index)\n",
    "\n",
    "    # Select test indices from the remaining indices without replacement\n",
    "    test_index = np.random.choice(remaining_indices, num_test_points, replace=False)\n",
    "    # Remove test indices from available indices\n",
    "    remaining_indices = np.setdiff1d(remaining_indices, test_index)\n",
    "\n",
    "    # Select population indices from the remaining indices (can also choose all remaining points)\n",
    "    population_index = np.random.choice(remaining_indices, min(num_population_points, len(remaining_indices)), replace=False)\n",
    "    \n",
    "    # Summary of counts\n",
    "    print(\"==============================================================\")\n",
    "    print(\"GET UNIQUE INDICES REFERENCE\")\n",
    "    print(f\"Number of train points: {len(train_index)}\")\n",
    "    print(f\"Number of test points: {len(test_index)}\")\n",
    "    print(f\"Number of population points: {len(population_index)}\")\n",
    "    print(\"==============================================================\")\n",
    "    \n",
    "    return train_index, test_index, population_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "414d335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(train_index, test_index, population_index, g_train, g_test, g_pop_train):\n",
    "    # create the target model's dataset\n",
    "    train_ds = {'x': X[train_index], 'y': y_true[train_index],'g':g_train}\n",
    "    test_ds = {'x': X[test_index], 'y': y_true[test_index], 'g':g_test}\n",
    "    target_dataset = Dataset(\n",
    "        data_dict={'train': train_ds, 'test': test_ds},\n",
    "        default_input='x', default_output='y', default_group='g'\n",
    "    )\n",
    "\n",
    "    # create the reference dataset\n",
    "    population_ds = {'x': X[population_index], 'y': y_true[population_index], 'g': g_pop_train}\n",
    "    reference_dataset = Dataset(\n",
    "        data_dict={'train': population_ds},\n",
    "        default_input='x', default_output='y', default_group='g'\n",
    "    )\n",
    "    \n",
    "    return target_dataset, reference_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e23be8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features, labels, and protected attributes into a DataFrame\n",
    "def create_binary_label_dataset(dataset_orig, X, y, sensitive_features, sens_attr_name, privileged_value, unprivileged_value):\n",
    "    print(\"=====================================================\")\n",
    "    print(\"CREATE BINARY LABEL DATASET\")\n",
    "    # Extract the feature names from the original dataset\n",
    "    feature_names = dataset_orig.feature_names\n",
    "\n",
    "    # Create a DataFrame with features, labels, and sensitive attribute\n",
    "    df = pd.DataFrame(X, columns=feature_names)\n",
    "    df[dataset_orig.label_names[0]] = y\n",
    "#     print(df.head())\n",
    "    # print(dataset_orig.feature_names)\n",
    "    # print(dataset_orig.features.shape)\n",
    "    \n",
    "    # df_orig, _ = dataset_orig.convert_to_dataframe()\n",
    "\n",
    "    # # Display the first few rows\n",
    "    # print(\"Original df's head:\", df_orig.head())\n",
    "    \n",
    "    # Get the unique labels and their counts\n",
    "    # unique_labels, counts = np.unique(dataset_orig.labels, return_counts=True)\n",
    "\n",
    "    # # Print the value counts\n",
    "    # for label, count in zip(unique_labels, counts):\n",
    "    #     print(f\"Label {label}: {count} instances\")\n",
    "\n",
    "    # Create the BinaryLabelDataset\n",
    "    dataset = BinaryLabelDataset(\n",
    "        favorable_label=1.0,  # Adjust as per your dataset\n",
    "        unfavorable_label=0.0,  # Adjust as per your dataset\n",
    "        df=df,  # DataFrame containing features, labels, and protected attribute\n",
    "        label_names=dataset_orig.label_names,  # Column name of labels in DataFrame\n",
    "        protected_attribute_names=[sens_attr_name],  # Protected attribute column\n",
    "        privileged_protected_attributes=[privileged_value],  # Privileged group values\n",
    "        unprivileged_protected_attributes=[unprivileged_value]  # Unprivileged group values\n",
    "    )\n",
    "    \n",
    "    # print(dataset.feature_names)\n",
    "    # print(dataset.features.shape)\n",
    "    # # Get the unique labels and their counts\n",
    "    # unique_labels, counts = np.unique(dataset.labels, return_counts=True)\n",
    "\n",
    "    # Print the value counts\n",
    "    # for label, count in zip(unique_labels, counts):\n",
    "    #     print(f\"Label {label}: {count} instances\")\n",
    "    \n",
    "    print(\"=====================================================\")\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22a3f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_logs():\n",
    "    # Search for directories ending with _group or _pop\n",
    "    for pattern in [\"*_group\", \"*_pop\"]:\n",
    "        # Find matching directories\n",
    "        for log_dir in glob.glob(pattern):\n",
    "            if os.path.exists(log_dir) and os.path.isdir(log_dir):  # Ensure it's a directory\n",
    "                shutil.rmtree(log_dir)\n",
    "                print(f\"{log_dir} deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31097df4",
   "metadata": {},
   "source": [
    "### Calling Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69a3e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = dataset_orig.convert_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b3d0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_dataset = None\n",
    "# reference_dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cc3b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e67badb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets():\n",
    "    target_dataset = None\n",
    "    reference_dataset = None\n",
    "    \n",
    "    if ATTACK == \"mia1\":\n",
    "        # split dataset into train, validation, and test\n",
    "        dataset_orig_train, dataset_orig_test = dataset_orig.split([p], shuffle=True)\n",
    "        dataset_orig_val = dataset_orig_test\n",
    "\n",
    "    elif ATTACK == \"mia2\":\n",
    "        train_index, test_index, population_index = get_unique_indices_reference()\n",
    "\n",
    "        g_train = y_true[train_index] + (sensitive_features[train_index] + 1) * 2 # 2, 4, 3, 5\n",
    "        g_test = y_true[test_index] + (sensitive_features[test_index] + 1) * 2\n",
    "        g_pop_train = y_true[population_index] + (sensitive_features[population_index] + 1) * 2\n",
    "\n",
    "        # for Audit\n",
    "        target_dataset, reference_dataset = create_datasets(train_index, test_index, population_index, g_train, g_test, g_pop_train)\n",
    "\n",
    "        # for mitigators\n",
    "        privileged_value = [1]\n",
    "        unprivileged_value = [0]\n",
    "        # Convert train dataset\n",
    "        dataset_orig_train = create_binary_label_dataset(\n",
    "            dataset_orig=dataset_orig,\n",
    "            X=X[train_index],\n",
    "            y=y_true[train_index],\n",
    "            sensitive_features=sensitive_features[train_index],\n",
    "            sens_attr_name=sens_attr,\n",
    "            privileged_value=privileged_value,\n",
    "            unprivileged_value=unprivileged_value\n",
    "        )\n",
    "        \n",
    "#         dataset_orig_val = create_binary_label_dataset(\n",
    "#             dataset_orig=dataset_orig,\n",
    "#             X=X[valid_index],\n",
    "#             y=y_true[valid_index],\n",
    "#             sensitive_features=sensitive_features[valid_index],\n",
    "#             sens_attr_name=sens_attr,\n",
    "#             privileged_value=privileged_value,\n",
    "#             unprivileged_value=unprivileged_value\n",
    "#         )\n",
    "\n",
    "        # Convert test dataset\n",
    "        dataset_orig_test = create_binary_label_dataset(\n",
    "            dataset_orig=dataset_orig,\n",
    "            X=X[test_index],\n",
    "            y=y_true[test_index],\n",
    "            sensitive_features=sensitive_features[test_index],\n",
    "            sens_attr_name=sens_attr,\n",
    "            privileged_value=privileged_value,\n",
    "            unprivileged_value=unprivileged_value\n",
    "        )\n",
    "        \n",
    "        dataset_orig_val = dataset_orig_test\n",
    "        \n",
    "    return dataset_orig_train, dataset_orig_val, dataset_orig_test, target_dataset, reference_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eea401f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION  0\n",
      "==============================================================\n",
      "GET UNIQUE INDICES REFERENCE\n",
      "Number of train points: 120\n",
      "Number of test points: 120\n",
      "Number of population points: 300\n",
      "==============================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "privileged vs. unprivileged:  97.0 23.0\n",
      "base_pos unpriv:  0.43478260869565216\n",
      "base_pos priv:  0.7010309278350515\n",
      "DIFFERENCE IS GOOD\n",
      "base_pos unpriv:  0.43478260869565216\n",
      "base_pos priv:  0.7010309278350515\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(120, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[[1]] [[0]]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "number of favorable labels:  78\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.266248\n",
      "#### Train shape, validation shape, test shape\n",
      "(120, 57) (120, 57) (120, 57)\n",
      "#######################################################################\n",
      "                    dprf\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training differentially private random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['un_log_group']\n",
      "Results are stored in: ['un_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "Checking predict proba\n",
      "=======================================================================\n",
      "Best thresh:  [0.10526052]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "Checking predict proba\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 120, Test = 120\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: [0.69314718]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 13, Test = 12\n",
      "  AUC: 0.47\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: [1.36056962]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 10, Test = 13\n",
      "  AUC: 0.47\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.00\n",
      "  Test Accuracy (TNR): 1.00\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.44\n",
      "  Optimal thershold: [0.41208483]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 29, Test = 29\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: [1.60943791]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 68, Test = 66\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: [0.63658936]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  120 140\n",
      "after transf priv:  0.7010309278350515\n",
      "after transf unpriv:  0.6976744186046512\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.003357\n",
      "[INFO]: training differentially private random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['syn_log_group']\n",
      "Results are stored in: ['syn_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "Checking predict proba\n",
      "=======================================================================\n",
      "Best thresh:  [0.51082562]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "Checking predict proba\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 120, Test = 120\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.27\n",
      "  Test Accuracy (TNR): 0.79\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: [0.35667494]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 13, Test = 12\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.38\n",
      "  Test Accuracy (TNR): 0.83\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [1.05021691]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 10, Test = 13\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.20\n",
      "  Test Accuracy (TNR): 0.92\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: [0.23067717]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 29, Test = 29\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.45\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: [1.2039728]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 68, Test = 66\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.44\n",
      "  Test Accuracy (TNR): 0.64\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: [0.35667494]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM         month  credit_amount  investment_as_income_percentage  \\\n",
      "0    0.031413       0.029810                         0.267011   \n",
      "1    0.032297       0.050074                         0.091507   \n",
      "2    0.032470       0.015672                         0.091998   \n",
      "3    0.032028       0.050436                         0.000000   \n",
      "4    0.146991       0.045504                         0.263037   \n",
      "..        ...            ...                              ...   \n",
      "115  0.046208       0.024016                         0.095217   \n",
      "116  0.024342       0.039437                         0.000000   \n",
      "117  0.078354       0.016432                         0.266403   \n",
      "118  0.091576       0.108132                         0.172978   \n",
      "119  0.033176       0.021258                         0.093999   \n",
      "\n",
      "     residence_since  age  number_of_credits  people_liable_for  status=A11  \\\n",
      "0           0.267011  1.0           0.000000           0.000000    0.000000   \n",
      "1           0.000000  1.0           0.091507           0.274521    0.000000   \n",
      "2           0.275993  0.0           0.000000           0.000000    0.275993   \n",
      "3           0.272240  1.0           0.181493           0.000000    0.000000   \n",
      "4           0.263037  1.0           0.087679           0.000000    0.263037   \n",
      "..               ...  ...                ...                ...         ...   \n",
      "115         0.000000  1.0           0.095217           0.000000    0.000000   \n",
      "116         0.091959  1.0           0.000000           0.275876    0.000000   \n",
      "117         0.266403  0.0           0.000000           0.000000    0.266403   \n",
      "118         0.259466  1.0           0.086489           0.259466    0.000000   \n",
      "119         0.187998  1.0           0.000000           0.000000    0.281997   \n",
      "\n",
      "     status=A12  status=A13  ...  housing=A153  skill_level=A171  \\\n",
      "0      0.000000         0.0  ...      0.267011          0.000000   \n",
      "1      0.000000         0.0  ...      0.000000          0.000000   \n",
      "2      0.000000         0.0  ...      0.000000          0.000000   \n",
      "3      0.272240         0.0  ...      0.000000          0.000000   \n",
      "4      0.000000         0.0  ...      0.000000          0.263037   \n",
      "..          ...         ...  ...           ...               ...   \n",
      "115    0.285651         0.0  ...      0.000000          0.285651   \n",
      "116    0.000000         0.0  ...      0.000000          0.000000   \n",
      "117    0.000000         0.0  ...      0.000000          0.000000   \n",
      "118    0.000000         0.0  ...      0.000000          0.000000   \n",
      "119    0.000000         0.0  ...      0.000000          0.000000   \n",
      "\n",
      "     skill_level=A172  skill_level=A173  skill_level=A174  telephone=A191  \\\n",
      "0            0.000000          0.267011               0.0        0.000000   \n",
      "1            0.274521          0.000000               0.0        0.274521   \n",
      "2            0.000000          0.275993               0.0        0.275993   \n",
      "3            0.000000          0.272240               0.0        0.000000   \n",
      "4            0.000000          0.000000               0.0        0.263037   \n",
      "..                ...               ...               ...             ...   \n",
      "115          0.000000          0.000000               0.0        0.285651   \n",
      "116          0.000000          0.275876               0.0        0.275876   \n",
      "117          0.000000          0.266403               0.0        0.266403   \n",
      "118          0.000000          0.259466               0.0        0.000000   \n",
      "119          0.000000          0.281997               0.0        0.281997   \n",
      "\n",
      "     telephone=A192  foreign_worker=A201  foreign_worker=A202  credit  \n",
      "0          0.267011             0.267011                  0.0     1.0  \n",
      "1          0.000000             0.274521                  0.0     1.0  \n",
      "2          0.000000             0.275993                  0.0     0.0  \n",
      "3          0.272240             0.272240                  0.0     1.0  \n",
      "4          0.000000             0.263037                  0.0     1.0  \n",
      "..              ...                  ...                  ...     ...  \n",
      "115        0.000000             0.285651                  0.0     0.0  \n",
      "116        0.000000             0.275876                  0.0     1.0  \n",
      "117        0.000000             0.266403                  0.0     0.0  \n",
      "118        0.259466             0.259466                  0.0     1.0  \n",
      "119        0.000000             0.281997                  0.0     1.0  \n",
      "\n",
      "[120 rows x 58 columns]\n",
      "DATAFRAME BEFORE DIR TRANSFORM         month  credit_amount  investment_as_income_percentage  \\\n",
      "0    0.056061       0.002742                         0.181532   \n",
      "1    0.064496       0.048792                         0.091370   \n",
      "2    0.032296       0.050450                         0.091505   \n",
      "3    0.161928       0.063927                         0.179042   \n",
      "4    0.078345       0.022059                         0.266375   \n",
      "..        ...            ...                              ...   \n",
      "115  0.007860       0.001735                         0.267253   \n",
      "116  0.057234       0.025438                         0.185331   \n",
      "117  0.033178       0.018047                         0.188010   \n",
      "118  0.032606       0.018666                         0.277154   \n",
      "119  0.055623       0.086518                         0.180111   \n",
      "\n",
      "     residence_since  age  number_of_credits  people_liable_for  status=A11  \\\n",
      "0           0.272297  0.0           0.000000           0.000000    0.000000   \n",
      "1           0.274109  1.0           0.091370           0.000000    0.000000   \n",
      "2           0.091505  1.0           0.000000           0.274516    0.274516   \n",
      "3           0.268563  1.0           0.000000           0.000000    0.000000   \n",
      "4           0.266375  1.0           0.000000           0.000000    0.266375   \n",
      "..               ...  ...                ...                ...         ...   \n",
      "115         0.267253  1.0           0.000000           0.000000    0.000000   \n",
      "116         0.185331  1.0           0.000000           0.000000    0.000000   \n",
      "117         0.094005  1.0           0.000000           0.000000    0.000000   \n",
      "118         0.000000  1.0           0.000000           0.000000    0.000000   \n",
      "119         0.270167  1.0           0.090056           0.000000    0.000000   \n",
      "\n",
      "     status=A12  status=A13  ...  housing=A153  skill_level=A171  \\\n",
      "0      0.000000    0.000000  ...           0.0               0.0   \n",
      "1      0.000000    0.000000  ...           0.0               0.0   \n",
      "2      0.000000    0.000000  ...           0.0               0.0   \n",
      "3      0.268563    0.000000  ...           0.0               0.0   \n",
      "4      0.000000    0.000000  ...           0.0               0.0   \n",
      "..          ...         ...  ...           ...               ...   \n",
      "115    0.267253    0.000000  ...           0.0               0.0   \n",
      "116    0.277996    0.000000  ...           0.0               0.0   \n",
      "117    0.000000    0.000000  ...           0.0               0.0   \n",
      "118    0.000000    0.277154  ...           0.0               0.0   \n",
      "119    0.000000    0.000000  ...           0.0               0.0   \n",
      "\n",
      "     skill_level=A172  skill_level=A173  skill_level=A174  telephone=A191  \\\n",
      "0            0.000000          0.272297          0.000000        0.272297   \n",
      "1            0.000000          0.274109          0.000000        0.000000   \n",
      "2            0.274516          0.000000          0.000000        0.274516   \n",
      "3            0.000000          0.268563          0.000000        0.268563   \n",
      "4            0.266375          0.000000          0.000000        0.000000   \n",
      "..                ...               ...               ...             ...   \n",
      "115          0.000000          0.267253          0.000000        0.267253   \n",
      "116          0.000000          0.277996          0.000000        0.000000   \n",
      "117          0.000000          0.282015          0.000000        0.282015   \n",
      "118          0.000000          0.000000          0.277154        0.000000   \n",
      "119          0.000000          0.270167          0.000000        0.000000   \n",
      "\n",
      "     telephone=A192  foreign_worker=A201  foreign_worker=A202  credit  \n",
      "0          0.000000             0.272297             0.000000     0.0  \n",
      "1          0.274109             0.274109             0.000000     1.0  \n",
      "2          0.000000             0.274516             0.000000     1.0  \n",
      "3          0.000000             0.268563             0.000000     1.0  \n",
      "4          0.266375             0.266375             0.000000     1.0  \n",
      "..              ...                  ...                  ...     ...  \n",
      "115        0.000000             0.267253             0.000000     1.0  \n",
      "116        0.277996             0.277996             0.000000     1.0  \n",
      "117        0.000000             0.000000             0.282015     1.0  \n",
      "118        0.277154             0.277154             0.000000     1.0  \n",
      "119        0.270167             0.270167             0.000000     1.0  \n",
      "\n",
      "[120 rows x 58 columns]\n",
      "=====================================================================================\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM         month  credit_amount  investment_as_income_percentage  \\\n",
      "0    0.079947       0.015869                         0.271820   \n",
      "1    0.065585       0.179425                         0.262339   \n",
      "2    0.075406       0.032277                         0.256381   \n",
      "3    0.044813       0.018200                         0.277025   \n",
      "4    0.079798       0.168843                         0.000000   \n",
      "..        ...            ...                              ...   \n",
      "295  0.056258       0.097895                         0.091084   \n",
      "296  0.020049       0.006061                         0.272667   \n",
      "297  0.008409       0.029355                         0.095302   \n",
      "298  0.020738       0.029268                         0.188023   \n",
      "299  0.044067       0.019216                         0.272412   \n",
      "\n",
      "     residence_since  age  number_of_credits  people_liable_for  status=A11  \\\n",
      "0           0.181213  1.0           0.000000           0.000000    0.000000   \n",
      "1           0.262339  1.0           0.000000           0.000000    0.000000   \n",
      "2           0.256381  1.0           0.085460           0.256381    0.000000   \n",
      "3           0.000000  0.0           0.000000           0.000000    0.000000   \n",
      "4           0.271314  0.0           0.090438           0.000000    0.000000   \n",
      "..               ...  ...                ...                ...         ...   \n",
      "295         0.273251  1.0           0.091084           0.000000    0.000000   \n",
      "296         0.181778  1.0           0.000000           0.000000    0.272667   \n",
      "297         0.095302  1.0           0.000000           0.000000    0.000000   \n",
      "298         0.094012  0.0           0.000000           0.000000    0.282035   \n",
      "299         0.181608  1.0           0.000000           0.000000    0.000000   \n",
      "\n",
      "     status=A12  status=A13  ...  housing=A153  skill_level=A171  \\\n",
      "0      0.000000    0.000000  ...      0.000000               0.0   \n",
      "1      0.000000    0.000000  ...      0.262339               0.0   \n",
      "2      0.000000    0.000000  ...      0.000000               0.0   \n",
      "3      0.277025    0.000000  ...      0.000000               0.0   \n",
      "4      0.271314    0.000000  ...      0.000000               0.0   \n",
      "..          ...         ...  ...           ...               ...   \n",
      "295    0.000000    0.000000  ...      0.000000               0.0   \n",
      "296    0.000000    0.000000  ...      0.000000               0.0   \n",
      "297    0.000000    0.285905  ...      0.000000               0.0   \n",
      "298    0.000000    0.000000  ...      0.000000               0.0   \n",
      "299    0.000000    0.000000  ...      0.000000               0.0   \n",
      "\n",
      "     skill_level=A172  skill_level=A173  skill_level=A174  telephone=A191  \\\n",
      "0            0.000000          0.271820          0.000000        0.000000   \n",
      "1            0.000000          0.000000          0.262339        0.000000   \n",
      "2            0.256381          0.000000          0.000000        0.256381   \n",
      "3            0.000000          0.277025          0.000000        0.277025   \n",
      "4            0.000000          0.000000          0.271314        0.271314   \n",
      "..                ...               ...               ...             ...   \n",
      "295          0.000000          0.273251          0.000000        0.273251   \n",
      "296          0.272667          0.000000          0.000000        0.272667   \n",
      "297          0.000000          0.285905          0.000000        0.000000   \n",
      "298          0.000000          0.282035          0.000000        0.282035   \n",
      "299          0.000000          0.272412          0.000000        0.272412   \n",
      "\n",
      "     telephone=A192  foreign_worker=A201  foreign_worker=A202  credit  \n",
      "0          0.271820             0.271820                  0.0     1.0  \n",
      "1          0.262339             0.262339                  0.0     0.0  \n",
      "2          0.000000             0.256381                  0.0     0.0  \n",
      "3          0.000000             0.277025                  0.0     1.0  \n",
      "4          0.000000             0.271314                  0.0     0.0  \n",
      "..              ...                  ...                  ...     ...  \n",
      "295        0.000000             0.273251                  0.0     0.0  \n",
      "296        0.000000             0.272667                  0.0     0.0  \n",
      "297        0.285905             0.285905                  0.0     1.0  \n",
      "298        0.000000             0.282035                  0.0     1.0  \n",
      "299        0.000000             0.272412                  0.0     1.0  \n",
      "\n",
      "[300 rows x 58 columns]\n",
      "=====================================================================================\n",
      "[INFO]: training differentially private random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['dir_log_group']\n",
      "Results are stored in: ['dir_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "Checking predict proba\n",
      "=======================================================================\n",
      "Best thresh:  [0.69314718]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "Checking predict proba\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 120, Test = 120\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: [1.2039728]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 13, Test = 12\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.15\n",
      "  Test Accuracy (TNR): 1.00\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.6965604]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 10, Test = 13\n",
      "  AUC: 0.36\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.00\n",
      "  Test Accuracy (TNR): 1.00\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.45\n",
      "  Optimal thershold: [0.69324718]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 29, Test = 29\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: [1.60943791]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 68, Test = 66\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.22\n",
      "  Test Accuracy (TNR): 0.85\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.35667494]\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training differentially private random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['rew_log_group']\n",
      "Results are stored in: ['rew_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "Checking predict proba\n",
      "=======================================================================\n",
      "Best thresh:  [0.10526052]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "Checking predict proba\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 120, Test = 120\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: [0.69314718]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 13, Test = 12\n",
      "  AUC: 0.47\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: [1.36056962]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 10, Test = 13\n",
      "  AUC: 0.47\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.00\n",
      "  Test Accuracy (TNR): 1.00\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.44\n",
      "  Optimal thershold: [0.41208483]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 29, Test = 29\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: [1.60943791]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 68, Test = 66\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: [0.63658936]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 93\u001b[0m\n\u001b[1;32m     90\u001b[0m     reweigh_metrics, reweigh_mia_metrics \u001b[38;5;241m=\u001b[39m test_cases\u001b[38;5;241m.\u001b[39mrun_rew(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, reweigh_metrics, reweigh_mia_metrics, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# eg mitigator, in-processing\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     eg_metrics, eg_mia_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtest_cases\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_eg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATASET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_orig_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_orig_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_orig_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meg_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meg_mia_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBASELINE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munprivileged_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivileged_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mATTACK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTHRESH_ARR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDISPLAY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCALER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# cpp mitigator\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m#     cpp_metrics, cpp_mia_metrics = test_cases.run_cpp(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, cpp_metrics, cpp_mia_metrics, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     delete_logs()\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/test_algorithms.py:60\u001b[0m, in \u001b[0;36mTestAlgorithms.run_eg\u001b[0;34m(self, DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, eg_metrics, eg_mia_metrics, model_type, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m------------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     59\u001b[0m eg_mitigator \u001b[38;5;241m=\u001b[39m EGMitigator()\n\u001b[0;32m---> 60\u001b[0m eg_metrics \u001b[38;5;241m=\u001b[39m \u001b[43meg_mitigator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_mitigator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATASET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_orig_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_orig_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_orig_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meg_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meg_mia_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munprivileged_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivileged_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mATTACK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTHRESH_ARR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDISPLAY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCALER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m eg_metrics\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/mitigators.py:338\u001b[0m, in \u001b[0;36mEGMitigator.run_mitigator\u001b[0;34m(self, DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, eg_metrics, eg_mia_metrics, model_type, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_mitigator\u001b[39m(\u001b[38;5;28mself\u001b[39m, DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test,\n\u001b[1;32m    331\u001b[0m                   eg_metrics, eg_mia_metrics, model_type, \n\u001b[1;32m    332\u001b[0m                   f_label, uf_label, \n\u001b[1;32m    333\u001b[0m                   unprivileged_groups, privileged_groups, \n\u001b[1;32m    334\u001b[0m                   ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset):\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;66;03m# set up dataset\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset_orig_train\n\u001b[0;32m--> 338\u001b[0m     eg_metrics, eg_mia_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mget_test_metrics_for_eg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATASET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_orig_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_orig_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meg_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meg_mia_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mATTACK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meg_log\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munprivileged_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivileged_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTHRESH_ARR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDISPLAY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCALER\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m eg_metrics, eg_mia_metrics\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/metrics_utils.py:301\u001b[0m, in \u001b[0;36mget_test_metrics_for_eg\u001b[0;34m(DATASET, target_dataset, reference_dataset, dataset_orig_train, dataset_orig_val, dataset_orig_test, model_type, test_metrics, mia_metrics, ATTACK, log_type, f_label, uf_label, unprivileged_groups, privileged_groups, THRESH_ARR, DISPLAY, SCALER)\u001b[0m\n\u001b[1;32m    299\u001b[0m     classifier \u001b[38;5;241m=\u001b[39m MLPClassifierWithWeightWrapper()\n\u001b[1;32m    300\u001b[0m mitigator \u001b[38;5;241m=\u001b[39m ExponentiatedGradient(classifier, constraint)\n\u001b[0;32m--> 301\u001b[0m \u001b[43mmitigator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msensitive_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msensitive_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ATTACK \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmia1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    304\u001b[0m     thresh_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.01\u001b[39m, THRESH_ARR, \u001b[38;5;241m50\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/fairlearn/reductions/_exponentiated_gradient/exponentiated_gradient.py:172\u001b[0m, in \u001b[0;36mExponentiatedGradient.fit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m lambda_EG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_vecs_EG_\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# select classifier according to best_h method\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m h, h_idx \u001b[38;5;241m=\u001b[39m \u001b[43mlagrangian\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_h\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlambda_vec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:234\u001b[0m, in \u001b[0;36m_Lagrangian.best_h\u001b[0;34m(self, lambda_vec)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbest_h\u001b[39m(\u001b[38;5;28mself\u001b[39m, lambda_vec):\n\u001b[1;32m    229\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Solve the best-response problem.\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m    Returns the classifier that solves the best-response problem for\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m    the vector of Lagrange multipliers `lambda_vec`.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     classifier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_oracle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlambda_vec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     h \u001b[38;5;241m=\u001b[39m _PredictorAsCallable(classifier)\n\u001b[1;32m    238\u001b[0m     h_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mgamma(h)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:222\u001b[0m, in \u001b[0;36m_Lagrangian._call_oracle\u001b[0;34m(self, lambda_vec)\u001b[0m\n\u001b[1;32m    219\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m clone(estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    221\u001b[0m oracle_call_start_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 222\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mredY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_weight_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mredW\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle_execution_times\u001b[38;5;241m.\u001b[39mappend(time() \u001b[38;5;241m-\u001b[39m oracle_call_start_time)\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_oracle_calls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/diffprivlib/models/forest.py:263\u001b[0m, in \u001b[0;36mRandomForestClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Todo: Remove when scikit-learn v1.1 is a min requirement\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 263\u001b[0m     trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtree_idxs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtree_idxs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtree_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trees\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     trees \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\n\u001b[1;32m    278\u001b[0m         delayed(_parallel_build_trees)(\n\u001b[1;32m    279\u001b[0m             tree\u001b[38;5;241m=\u001b[39mt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    289\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:197\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    190\u001b[0m         X,\n\u001b[1;32m    191\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    195\u001b[0m     )\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/diffprivlib/models/forest.py:455\u001b[0m, in \u001b[0;36mDecisionTreeClassifier._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/diffprivlib/models/forest.py:441\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# Build and fit the _FittingTree\u001b[39;00m\n\u001b[1;32m    439\u001b[0m fitting_tree \u001b[38;5;241m=\u001b[39m _FittingTree(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbounds,\n\u001b[1;32m    440\u001b[0m                             random_state)\n\u001b[0;32m--> 441\u001b[0m \u001b[43mfitting_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m fitting_tree\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# Load params from _FittingTree into sklearn.Tree\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/diffprivlib/models/forest.py:526\u001b[0m, in \u001b[0;36m_FittingTree.build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m parent, is_left, depth, bounds \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m    525\u001b[0m node_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_count\n\u001b[0;32m--> 526\u001b[0m bounds_lower, bounds_upper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_bounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;66;03m# Update parent node with its child\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parent \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_TREE_UNDEFINED:\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/diffprivlib/validation.py:120\u001b[0m, in \u001b[0;36mcheck_bounds\u001b[0;34m(bounds, shape, min_separation, dtype)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _lower \u001b[38;5;241m>\u001b[39m _upper:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor each bound, lower bound must be smaller than upper bound, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlower\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mupper\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_upper\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_lower\u001b[49m \u001b[38;5;241m<\u001b[39m min_separation:\n\u001b[1;32m    121\u001b[0m     mid \u001b[38;5;241m=\u001b[39m (_upper \u001b[38;5;241m+\u001b[39m _lower) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    122\u001b[0m     lower[i] \u001b[38;5;241m=\u001b[39m mid \u001b[38;5;241m-\u001b[39m min_separation \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.052335  0.000000  0.261567  0.000000      0.261567   \n",
      "1     1.0  0.007442  0.000000  0.295150  0.000000      0.098383   \n",
      "2     1.0  0.007775  0.000000  0.261910  0.000000      0.261910   \n",
      "3     1.0  0.008556  0.007006  0.294261  0.000000      0.098087   \n",
      "4     1.0  0.004600  0.000000  0.275872  0.000000      0.189662   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.042678  0.021418  0.000900  0.171341      0.099949   \n",
      "3649  1.0  0.019961  0.000000  0.294794  0.000000      0.098265   \n",
      "3650  1.0  0.020451  0.034406  0.289012  0.082575      0.102358   \n",
      "3651  1.0  0.018796  0.000000  0.261868  0.000000      0.261868   \n",
      "3652  1.0  0.012246  0.012469  0.261858  0.000000      0.261858   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.126706       0.160880   0.256705     0.261567  ...        0.0   \n",
      "1           0.073845       0.009880   0.060020     0.151202  ...        0.0   \n",
      "2           0.126872       0.161091   0.257160     0.261910  ...        0.0   \n",
      "3           0.100228       0.045555   0.054102     0.150746  ...        0.0   \n",
      "4           0.107403       0.101576   0.215269     0.242183  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.195730       0.135495   0.003399     0.051127  ...        0.0   \n",
      "3649        0.079500       0.056739   0.040767     0.151019  ...        0.0   \n",
      "3650        0.208818       0.133018   0.007862     0.030595  ...        0.0   \n",
      "3651        0.126852       0.161065   0.257178     0.261868  ...        0.0   \n",
      "3652        0.126847       0.161059   0.257406     0.261858  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.000000         0.261567         0.000000              0.0   \n",
      "1            0.295150         0.000000         0.000000              0.0   \n",
      "2            0.000000         0.261910         0.000000              0.0   \n",
      "3            0.000000         0.000000         0.000000              0.0   \n",
      "4            0.000000         0.000000         0.275872              0.0   \n",
      "...               ...              ...              ...              ...   \n",
      "3648         0.299846         0.000000         0.000000              0.0   \n",
      "3649         0.000000         0.294794         0.000000              0.0   \n",
      "3650         0.000000         0.289012         0.000000              0.0   \n",
      "3651         0.261868         0.000000         0.000000              0.0   \n",
      "3652         0.000000         0.261858         0.000000              0.0   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000          0.000000              0.261567   \n",
      "1            0.000000          0.000000              0.295150   \n",
      "2            0.000000          0.000000              0.261910   \n",
      "3            0.294261          0.000000              0.294261   \n",
      "4            0.000000          0.000000              0.275872   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.000000          0.000000              0.000000   \n",
      "3649         0.000000          0.000000              0.294794   \n",
      "3650         0.000000          0.289012              0.000000   \n",
      "3651         0.000000          0.000000              0.261868   \n",
      "3652         0.000000          0.000000              0.261858   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0             0.000000  0.0  \n",
      "1             0.000000  0.0  \n",
      "2             0.000000  0.0  \n",
      "3             0.000000  1.0  \n",
      "4             0.000000  0.0  \n",
      "...                ...  ...  \n",
      "3648          0.299846  1.0  \n",
      "3649          0.000000  0.0  \n",
      "3650          0.000000  0.0  \n",
      "3651          0.000000  0.0  \n",
      "3652          0.000000  0.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n",
      "=====================================================================================\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.014419  0.006276  0.263612       0.0      0.247136   \n",
      "1     1.0  0.005647  0.012360  0.259564       0.0      0.259564   \n",
      "2     0.0  0.031995  0.000000  0.262254       0.0      0.262254   \n",
      "3     1.0  0.006231  0.006236  0.261904       0.0      0.261904   \n",
      "4     1.0  0.005112  0.000000  0.261895       0.0      0.261895   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "9129  1.0  0.030738  0.000000  0.287938       0.0      0.000000   \n",
      "9130  1.0  0.012001  0.021078  0.295094       0.0      0.030739   \n",
      "9131  1.0  0.008748  0.018738  0.262328       0.0      0.262328   \n",
      "9132  1.0  0.015819  0.014033  0.294690       0.0      0.098230   \n",
      "9133  1.0  0.007600  0.006180  0.259572       0.0      0.259572   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.184199       0.158829   0.252496     0.226636  ...        0.0   \n",
      "1           0.229015       0.097744   0.248913     0.259564  ...        0.0   \n",
      "2           0.175483       0.088881   0.257259     0.262254  ...        0.0   \n",
      "3           0.126869       0.161087   0.257213     0.261904  ...        0.0   \n",
      "4           0.126865       0.161082   0.257442     0.261895  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "9129        0.025809       0.287938   0.006919     0.058676  ...        0.0   \n",
      "9130        0.087631       0.123470   0.043284     0.125624  ...        0.0   \n",
      "9131        0.175533       0.088906   0.257392     0.262328  ...        0.0   \n",
      "9132        0.079472       0.056719   0.048102     0.150966  ...        0.0   \n",
      "9133        0.229022       0.097747   0.248979     0.259572  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.263612         0.000000              0.0         0.000000   \n",
      "1            0.000000         0.000000              0.0         0.259564   \n",
      "2            0.000000         0.000000              0.0         0.262254   \n",
      "3            0.000000         0.000000              0.0         0.261904   \n",
      "4            0.000000         0.261895              0.0         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "9129         0.000000         0.000000              0.0         0.000000   \n",
      "9130         0.000000         0.295094              0.0         0.000000   \n",
      "9131         0.262328         0.000000              0.0         0.000000   \n",
      "9132         0.000000         0.294690              0.0         0.000000   \n",
      "9133         0.000000         0.259572              0.0         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000               0.0              0.263612   \n",
      "1            0.000000               0.0              0.259564   \n",
      "2            0.000000               0.0              0.262254   \n",
      "3            0.000000               0.0              0.261904   \n",
      "4            0.000000               0.0              0.261895   \n",
      "...               ...               ...                   ...   \n",
      "9129         0.287938               0.0              0.287938   \n",
      "9130         0.000000               0.0              0.295094   \n",
      "9131         0.000000               0.0              0.262328   \n",
      "9132         0.000000               0.0              0.294690   \n",
      "9133         0.000000               0.0              0.259572   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  0.0  \n",
      "2                  0.0  1.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  0.0  \n",
      "...                ...  ...  \n",
      "9129               0.0  0.0  \n",
      "9130               0.0  1.0  \n",
      "9131               0.0  0.0  \n",
      "9132               0.0  0.0  \n",
      "9133               0.0  0.0  \n",
      "\n",
      "[9134 rows x 58 columns]\n",
      "=====================================================================================\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['dir_log_group']\n",
      "Results are stored in: ['dir_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  [0.11312205]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: [0.0977594]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 137, Test = 144\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: [0.26785626]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 63, Test = 58\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [1.10147878]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3045, Test = 3058\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: [0.08949346]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 408, Test = 393\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.93\n",
      "  Optimal thershold: [1.1130629]\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['rew_log_group']\n",
      "Results are stored in: ['rew_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.18003045]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: [0.27442222]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 137, Test = 144\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.14\n",
      "  Test Accuracy (TNR): 0.90\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.2276334]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 63, Test = 58\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.40\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: [0.86036956]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3045, Test = 3058\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: [0.05683396]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 408, Test = 393\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [1.10677184]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['eg_log_group']\n",
      "Results are stored in: ['eg_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: [0.30110509]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 137, Test = 144\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: [0.31471074]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 63, Test = 58\n",
      "  AUC: 0.90\n",
      "  Privacy Risk: 0.86\n",
      "  Accuracy: 0.86\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.81\n",
      "  Attacker advantage: 0.72\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.35667494]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3045, Test = 3058\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: [0.09431068]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 408, Test = 393\n",
      "  AUC: 0.90\n",
      "  Privacy Risk: 0.86\n",
      "  Accuracy: 0.86\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.76\n",
      "  Attacker advantage: 0.72\n",
      "  Positive predictive value: 0.95\n",
      "  Optimal thershold: [0.4462871]\n",
      ")\n",
      "dir_log_group deleted.\n",
      "eg_log_group deleted.\n",
      "rew_log_group deleted.\n",
      "syn_log_group deleted.\n",
      "un_log_group deleted.\n",
      "dir_log_pop deleted.\n",
      "eg_log_pop deleted.\n",
      "rew_log_pop deleted.\n",
      "syn_log_pop deleted.\n",
      "un_log_pop deleted.\n",
      "ITERATION  3\n",
      "==============================================================\n",
      "GET UNIQUE INDICES REFERENCE\n",
      "Number of train points: 3653\n",
      "Number of test points: 3653\n",
      "Number of population points: 9134\n",
      "==============================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "privileged vs. unprivileged:  3437.0 216.0\n",
      "base_pos unpriv:  0.35648148148148145\n",
      "base_pos priv:  0.11230724469013675\n",
      "DIFFERENCE IS GOOD\n",
      "base_pos unpriv:  0.35648148148148145\n",
      "base_pos priv:  0.11230724469013675\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(3653, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[[1]] [[0]]\n",
      "#### Dataset feature names\n",
      "['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'job=admin.', 'job=blue-collar', 'job=entrepreneur', 'job=housemaid', 'job=management', 'job=retired', 'job=self-employed', 'job=services', 'job=student', 'job=technician', 'job=unemployed', 'marital=divorced', 'marital=married', 'marital=single', 'education=basic.4y', 'education=basic.6y', 'education=basic.9y', 'education=high.school', 'education=illiterate', 'education=professional.course', 'education=university.degree', 'default=no', 'default=yes', 'housing=no', 'housing=yes', 'loan=no', 'loan=yes', 'contact=cellular', 'contact=telephone', 'month=apr', 'month=aug', 'month=dec', 'month=jul', 'month=jun', 'month=mar', 'month=may', 'month=nov', 'month=oct', 'month=sep', 'day_of_week=fri', 'day_of_week=mon', 'day_of_week=thu', 'day_of_week=tue', 'day_of_week=wed', 'poutcome=failure', 'poutcome=nonexistent', 'poutcome=success']\n",
      "number of favorable labels:  463\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.244174\n",
      "#### Train shape, validation shape, test shape\n",
      "(3653, 57) (3653, 57) (3653, 57)\n",
      "#######################################################################\n",
      "                    rf\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['un_log_group']\n",
      "Results are stored in: ['un_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.13285844]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: [0.27220608]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 139, Test = 129\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: [0.53621616]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 77, Test = 78\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.23\n",
      "  Test Accuracy (TNR): 0.97\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.26325682]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3051, Test = 3049\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.45\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: [0.03387242]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 386, Test = 397\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.32\n",
      "  Test Accuracy (TNR): 0.81\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.88\n",
      "  Optimal thershold: [0.77400767]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  3653 6874\n",
      "after transf priv:  0.11230724469013675\n",
      "after transf unpriv:  0.11230724469013675\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['syn_log_group']\n",
      "Results are stored in: ['syn_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.11929447]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: [0.74684305]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 139, Test = 129\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.33472588]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 77, Test = 78\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.35\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.49078827]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3051, Test = 3049\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.29\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: [0.03621263]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 386, Test = 397\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.25\n",
      "  Test Accuracy (TNR): 0.83\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.81\n",
      "  Optimal thershold: [1.31350045]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.027519  0.000000  0.262280  0.000000      0.262280   \n",
      "1     1.0  0.012316  0.000000  0.289813  0.082804      0.000000   \n",
      "2     1.0  0.006935  0.006247  0.262368  0.000000      0.262368   \n",
      "3     1.0  0.009266  0.000000  0.261911  0.000000      0.261911   \n",
      "4     1.0  0.007066  0.007012  0.294490  0.042070      0.098163   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.009603  0.000000  0.262368  0.000000      0.262368   \n",
      "3649  1.0  0.010723  0.000000  0.262369  0.000000      0.262369   \n",
      "3650  1.0  0.011980  0.018704  0.261858  0.000000      0.261858   \n",
      "3651  1.0  0.006724  0.006561  0.275574  0.000000      0.189457   \n",
      "3652  1.0  0.009220  0.000000  0.263641  0.000000      0.247163   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.175501       0.088890   0.257405     0.262280  ...        0.0   \n",
      "1           0.050599       0.251010   0.005322     0.059058  ...        0.0   \n",
      "2           0.175560       0.088920   0.257491     0.262368  ...        0.0   \n",
      "3           0.126873       0.161092   0.257101     0.261911  ...        0.0   \n",
      "4           0.079418       0.056680   0.047401     0.150864  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.175559       0.088920   0.257490     0.262368  ...        0.0   \n",
      "3649        0.175560       0.088920   0.257432     0.262369  ...        0.0   \n",
      "3650        0.126847       0.161059   0.257049     0.261858  ...        0.0   \n",
      "3651        0.107287       0.101467   0.219847     0.241922  ...        0.0   \n",
      "3652        0.184220       0.158846   0.252404     0.226662  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.000000         0.000000              0.0         0.000000   \n",
      "1            0.000000         0.000000              0.0         0.289813   \n",
      "2            0.262368         0.000000              0.0         0.000000   \n",
      "3            0.000000         0.000000              0.0         0.000000   \n",
      "4            0.000000         0.000000              0.0         0.294490   \n",
      "...               ...              ...              ...              ...   \n",
      "3648         0.000000         0.000000              0.0         0.000000   \n",
      "3649         0.000000         0.000000              0.0         0.262369   \n",
      "3650         0.000000         0.000000              0.0         0.000000   \n",
      "3651         0.000000         0.000000              0.0         0.275574   \n",
      "3652         0.000000         0.263641              0.0         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.262280          0.000000              0.262280   \n",
      "1            0.000000          0.289813              0.000000   \n",
      "2            0.000000          0.000000              0.262368   \n",
      "3            0.261911          0.000000              0.261911   \n",
      "4            0.000000          0.294490              0.000000   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.262368          0.000000              0.262368   \n",
      "3649         0.000000          0.000000              0.262369   \n",
      "3650         0.261858          0.000000              0.261858   \n",
      "3651         0.000000          0.000000              0.275574   \n",
      "3652         0.000000          0.000000              0.263641   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  1.0  \n",
      "2                  0.0  0.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  0.0  \n",
      "...                ...  ...  \n",
      "3648               0.0  0.0  \n",
      "3649               0.0  0.0  \n",
      "3650               0.0  0.0  \n",
      "3651               0.0  0.0  \n",
      "3652               0.0  0.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.008307  0.012471  0.261897  0.000000      0.261897   \n",
      "1     1.0  0.018628  0.006179  0.259530  0.000000      0.259530   \n",
      "2     1.0  0.001320  0.000000  0.259588  0.000000      0.259588   \n",
      "3     1.0  0.032634  0.000000  0.295026  0.000000      0.098342   \n",
      "4     1.0  0.002667  0.006247  0.262374  0.000000      0.262374   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.018590  0.031367  0.263481  0.000000      0.247013   \n",
      "3649  1.0  0.019419  0.007219  0.001214  0.043312      0.031582   \n",
      "3650  1.0  0.010456  0.006247  0.262360  0.000000      0.262360   \n",
      "3651  1.0  0.056247  0.014013  0.294279  0.000000      0.098093   \n",
      "3652  1.0  0.028000  0.006245  0.262296  0.000000      0.262296   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.126866       0.161083   0.257028     0.261897  ...        0.0   \n",
      "1           0.228986       0.097731   0.248999     0.259530  ...        0.0   \n",
      "2           0.229036       0.097753   0.248936     0.259588  ...        0.0   \n",
      "3           0.073814       0.009875   0.058590     0.151138  ...        0.0   \n",
      "4           0.175563       0.088922   0.257496     0.262374  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.184108       0.158750   0.252191     0.226524  ...        0.0   \n",
      "3649        0.000000       0.246099   0.016427     0.129068  ...        0.0   \n",
      "3650        0.175554       0.088917   0.257483     0.262360  ...        0.0   \n",
      "3651        0.079361       0.056640   0.046700     0.150756  ...        0.0   \n",
      "3652        0.175511       0.088895   0.257063     0.262296  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0             0.00000              0.0         0.261897         0.000000   \n",
      "1             0.00000              0.0         0.259530         0.000000   \n",
      "2             0.00000              0.0         0.000000         0.259588   \n",
      "3             0.00000              0.0         0.000000         0.295026   \n",
      "4             0.00000              0.0         0.000000         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "3648          0.00000              0.0         0.000000         0.263481   \n",
      "3649          0.00000              0.0         0.303184         0.000000   \n",
      "3650          0.26236              0.0         0.000000         0.000000   \n",
      "3651          0.00000              0.0         0.000000         0.000000   \n",
      "3652          0.00000              0.0         0.000000         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000               0.0              0.261897   \n",
      "1            0.000000               0.0              0.259530   \n",
      "2            0.000000               0.0              0.259588   \n",
      "3            0.000000               0.0              0.295026   \n",
      "4            0.262374               0.0              0.262374   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.000000               0.0              0.263481   \n",
      "3649         0.000000               0.0              0.000000   \n",
      "3650         0.000000               0.0              0.262360   \n",
      "3651         0.294279               0.0              0.294279   \n",
      "3652         0.262296               0.0              0.262296   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0             0.000000  0.0  \n",
      "1             0.000000  0.0  \n",
      "2             0.000000  0.0  \n",
      "3             0.000000  0.0  \n",
      "4             0.000000  0.0  \n",
      "...                ...  ...  \n",
      "3648          0.000000  0.0  \n",
      "3649          0.303184  1.0  \n",
      "3650          0.000000  0.0  \n",
      "3651          0.000000  0.0  \n",
      "3652          0.000000  0.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n",
      "=====================================================================================\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.003354  0.007013  0.294564  0.042081      0.098188   \n",
      "1     1.0  0.007030  0.000000  0.261912  0.000000      0.261912   \n",
      "2     1.0  0.041838  0.027994  0.293942  0.000000      0.097981   \n",
      "3     0.0  0.004374  0.012493  0.262357  0.000000      0.262357   \n",
      "4     1.0  0.056811  0.000000  0.275266  0.000000      0.189245   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "9129  1.0  0.009752  0.012345  0.259238  0.000000      0.259238   \n",
      "9130  1.0  0.005851  0.000000  0.259219  0.000000      0.259219   \n",
      "9131  1.0  0.008899  0.000000  0.263646  0.000000      0.247168   \n",
      "9132  1.0  0.023046  0.000000  0.263582  0.000000      0.247108   \n",
      "9133  1.0  0.015644  0.000000  0.294786  0.000000      0.098262   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.079438       0.056694   0.042205     0.150902  ...        0.0   \n",
      "1           0.126873       0.161092   0.257162     0.261912  ...        0.0   \n",
      "2           0.100119       0.045506   0.051711     0.150583  ...        0.0   \n",
      "3           0.175552       0.088916   0.257480     0.262357  ...        0.0   \n",
      "4           0.107167       0.101353   0.217542     0.241651  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "9129        0.228727       0.097621   0.253478     0.259238  ...        0.0   \n",
      "9130        0.228711       0.097614   0.254165     0.259219  ...        0.0   \n",
      "9131        0.184223       0.158849   0.252349     0.226666  ...        0.0   \n",
      "9132        0.184179       0.158811   0.252348     0.226611  ...        0.0   \n",
      "9133        0.079498       0.056737   0.043239     0.151015  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.000000              0.0         0.294564         0.000000   \n",
      "1            0.000000              0.0         0.000000         0.000000   \n",
      "2            0.000000              0.0         0.293942         0.000000   \n",
      "3            0.000000              0.0         0.000000         0.000000   \n",
      "4            0.000000              0.0         0.000000         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "9129         0.259238              0.0         0.000000         0.000000   \n",
      "9130         0.259219              0.0         0.000000         0.000000   \n",
      "9131         0.000000              0.0         0.000000         0.263646   \n",
      "9132         0.000000              0.0         0.000000         0.000000   \n",
      "9133         0.000000              0.0         0.000000         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000          0.294564              0.000000   \n",
      "1            0.261912          0.000000              0.261912   \n",
      "2            0.000000          0.000000              0.293942   \n",
      "3            0.262357          0.000000              0.262357   \n",
      "4            0.275266          0.000000              0.275266   \n",
      "...               ...               ...                   ...   \n",
      "9129         0.000000          0.000000              0.259238   \n",
      "9130         0.000000          0.000000              0.259219   \n",
      "9131         0.000000          0.000000              0.263646   \n",
      "9132         0.263582          0.000000              0.263582   \n",
      "9133         0.294786          0.000000              0.294786   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  0.0  \n",
      "2                  0.0  1.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  1.0  \n",
      "...                ...  ...  \n",
      "9129               0.0  0.0  \n",
      "9130               0.0  0.0  \n",
      "9131               0.0  0.0  \n",
      "9132               0.0  0.0  \n",
      "9133               0.0  0.0  \n",
      "\n",
      "[9134 rows x 58 columns]\n",
      "=====================================================================================\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['dir_log_group']\n",
      "Results are stored in: ['dir_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  [0.10021593]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.45\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: [0.04185206]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 139, Test = 129\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: [0.36644935]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 77, Test = 78\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.35\n",
      "  Test Accuracy (TNR): 0.86\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 0.88\n",
      "  Optimal thershold: [1.30932316]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3051, Test = 3049\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.50\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: [0.0396121]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 386, Test = 397\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [1.04910153]\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['rew_log_group']\n",
      "Results are stored in: ['rew_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.13989504]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: [0.71251589]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 139, Test = 129\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: [0.44042404]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 77, Test = 78\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.91\n",
      "  Optimal thershold: [1.03545181]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3051, Test = 3049\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: [0.25809306]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 386, Test = 397\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.40\n",
      "  Test Accuracy (TNR): 0.75\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.90074715]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['eg_log_group']\n",
      "Results are stored in: ['eg_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: [0.27443685]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 139, Test = 129\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.68\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: [0.28768207]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 77, Test = 78\n",
      "  AUC: 0.93\n",
      "  Privacy Risk: 0.85\n",
      "  Accuracy: 0.85\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.83\n",
      "  Attacker advantage: 0.69\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.29188155]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3051, Test = 3049\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: [0.09431068]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 386, Test = 397\n",
      "  AUC: 0.92\n",
      "  Privacy Risk: 0.86\n",
      "  Accuracy: 0.86\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.79\n",
      "  Attacker advantage: 0.73\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.45065221]\n",
      ")\n",
      "dir_log_group deleted.\n",
      "eg_log_group deleted.\n",
      "rew_log_group deleted.\n",
      "syn_log_group deleted.\n",
      "un_log_group deleted.\n",
      "dir_log_pop deleted.\n",
      "eg_log_pop deleted.\n",
      "rew_log_pop deleted.\n",
      "syn_log_pop deleted.\n",
      "un_log_pop deleted.\n",
      "ITERATION  4\n",
      "==============================================================\n",
      "GET UNIQUE INDICES REFERENCE\n",
      "Number of train points: 3653\n",
      "Number of test points: 3653\n",
      "Number of population points: 9134\n",
      "==============================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "privileged vs. unprivileged:  3440.0 213.0\n",
      "base_pos unpriv:  0.3051643192488263\n",
      "base_pos priv:  0.11395348837209303\n",
      "DIFFERENCE IS GOOD\n",
      "base_pos unpriv:  0.3051643192488263\n",
      "base_pos priv:  0.11395348837209303\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(3653, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[[1]] [[0]]\n",
      "#### Dataset feature names\n",
      "['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'job=admin.', 'job=blue-collar', 'job=entrepreneur', 'job=housemaid', 'job=management', 'job=retired', 'job=self-employed', 'job=services', 'job=student', 'job=technician', 'job=unemployed', 'marital=divorced', 'marital=married', 'marital=single', 'education=basic.4y', 'education=basic.6y', 'education=basic.9y', 'education=high.school', 'education=illiterate', 'education=professional.course', 'education=university.degree', 'default=no', 'default=yes', 'housing=no', 'housing=yes', 'loan=no', 'loan=yes', 'contact=cellular', 'contact=telephone', 'month=apr', 'month=aug', 'month=dec', 'month=jul', 'month=jun', 'month=mar', 'month=may', 'month=nov', 'month=oct', 'month=sep', 'day_of_week=fri', 'day_of_week=mon', 'day_of_week=thu', 'day_of_week=tue', 'day_of_week=wed', 'poutcome=failure', 'poutcome=nonexistent', 'poutcome=success']\n",
      "number of favorable labels:  457\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.191211\n",
      "#### Train shape, validation shape, test shape\n",
      "(3653, 57) (3653, 57) (3653, 57)\n",
      "#######################################################################\n",
      "                    rf\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['un_log_group']\n",
      "Results are stored in: ['un_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.16796808]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: [0.28506741]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 137\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.28917659]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 65, Test = 75\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.26\n",
      "  Test Accuracy (TNR): 0.89\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.37979795]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3048, Test = 3059\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.35\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: [0.04140839]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 392, Test = 382\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.61\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.83\n",
      "  Optimal thershold: [1.21385888]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  3653 6880\n",
      "after transf priv:  0.11395348837209303\n",
      "after transf unpriv:  0.11395348837209303\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['syn_log_group']\n",
      "Results are stored in: ['syn_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.11553233]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.32\n",
      "  Test Accuracy (TNR): 0.70\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: [0.04257391]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 137\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.80\n",
      "  Optimal thershold: [0.22720917]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 65, Test = 75\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.15\n",
      "  Test Accuracy (TNR): 0.99\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.91\n",
      "  Optimal thershold: [1.21285305]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3048, Test = 3059\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.37\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: [0.04257391]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 392, Test = 382\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: [1.3778363]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.003117  0.000000  0.294793       0.0      0.098264   \n",
      "1     1.0  0.030918  0.000000  0.294681       0.0      0.098227   \n",
      "2     1.0  0.008202  0.000000  0.263643       0.0      0.247166   \n",
      "3     1.0  0.023581  0.000000  0.292860       0.0      0.024405   \n",
      "4     1.0  0.014251  0.031368  0.263488       0.0      0.247020   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.002929  0.012471  0.261897       0.0      0.261897   \n",
      "3649  1.0  0.020313  0.000000  0.263590       0.0      0.247116   \n",
      "3650  1.0  0.008470  0.000000  0.275865       0.0      0.189657   \n",
      "3651  1.0  0.019541  0.006235  0.261863       0.0      0.261863   \n",
      "3652  1.0  0.003355  0.006236  0.261908       0.0      0.261908   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.079500       0.056738   0.045378     0.151018  ...        0.0   \n",
      "1           0.079470       0.056717   0.043223     0.150961  ...        0.0   \n",
      "2           0.184222       0.158848   0.252407     0.226664  ...        0.0   \n",
      "3           0.058435       0.218113   0.004913     0.066323  ...        0.0   \n",
      "4           0.184113       0.158754   0.252377     0.226530  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.126866       0.161083   0.257147     0.261897  ...        0.0   \n",
      "3649        0.184184       0.158816   0.252475     0.226618  ...        0.0   \n",
      "3650        0.107400       0.101574   0.215264     0.242177  ...        0.0   \n",
      "3651        0.126850       0.161062   0.257114     0.261863  ...        0.0   \n",
      "3652        0.126871       0.161090   0.257217     0.261908  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.294793         0.000000         0.000000          0.00000   \n",
      "1            0.000000         0.000000         0.000000          0.00000   \n",
      "2            0.000000         0.263643         0.000000          0.00000   \n",
      "3            0.000000         0.000000         0.000000          0.29286   \n",
      "4            0.263488         0.000000         0.000000          0.00000   \n",
      "...               ...              ...              ...              ...   \n",
      "3648         0.000000         0.261897         0.000000          0.00000   \n",
      "3649         0.263590         0.000000         0.000000          0.00000   \n",
      "3650         0.000000         0.000000         0.275865          0.00000   \n",
      "3651         0.000000         0.261863         0.000000          0.00000   \n",
      "3652         0.261908         0.000000         0.000000          0.00000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000               0.0              0.294793   \n",
      "1            0.294681               0.0              0.294681   \n",
      "2            0.000000               0.0              0.263643   \n",
      "3            0.000000               0.0              0.292860   \n",
      "4            0.000000               0.0              0.263488   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.000000               0.0              0.261897   \n",
      "3649         0.000000               0.0              0.263590   \n",
      "3650         0.000000               0.0              0.275865   \n",
      "3651         0.000000               0.0              0.261863   \n",
      "3652         0.000000               0.0              0.261908   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  1.0  \n",
      "2                  0.0  0.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  0.0  \n",
      "...                ...  ...  \n",
      "3648               0.0  0.0  \n",
      "3649               0.0  0.0  \n",
      "3650               0.0  0.0  \n",
      "3651               0.0  0.0  \n",
      "3652               0.0  0.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.014205  0.000000  0.263618  0.000000      0.247142   \n",
      "1     1.0  0.005092  0.012554  0.263628  0.000000      0.247151   \n",
      "2     1.0  0.043127  0.000000  0.275454  0.000000      0.189375   \n",
      "3     1.0  0.010752  0.006171  0.259196  0.000000      0.259196   \n",
      "4     1.0  0.004986  0.000000  0.263657  0.000000      0.247178   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.043701  0.012542  0.263384  0.000000      0.246922   \n",
      "3649  1.0  0.010291  0.012553  0.263606  0.000000      0.247130   \n",
      "3650  1.0  0.004432  0.000000  0.294570  0.042081      0.098190   \n",
      "3651  1.0  0.015602  0.006235  0.261873  0.000000      0.261873   \n",
      "3652  1.0  0.001558  0.000000  0.294775  0.000000      0.098258   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.184204       0.158832   0.252502     0.226641  ...        0.0   \n",
      "1           0.184211       0.158839   0.252392     0.226650  ...        0.0   \n",
      "2           0.107240       0.101422   0.217691     0.241817  ...        0.0   \n",
      "3           0.228690       0.097605   0.254260     0.259196  ...        0.0   \n",
      "4           0.184231       0.158856   0.252300     0.226675  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.184040       0.158691   0.252098     0.226440  ...        0.0   \n",
      "3649        0.184195       0.158825   0.252550     0.226631  ...        0.0   \n",
      "3650        0.079440       0.056696   0.042206     0.150905  ...        0.0   \n",
      "3651        0.126854       0.161068   0.257243     0.261873  ...        0.0   \n",
      "3652        0.079495       0.056735   0.046779     0.151009  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.263618              0.0         0.000000         0.000000   \n",
      "1            0.000000              0.0         0.000000         0.263628   \n",
      "2            0.000000              0.0         0.000000         0.000000   \n",
      "3            0.000000              0.0         0.000000         0.259196   \n",
      "4            0.000000              0.0         0.263657         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "3648         0.000000              0.0         0.000000         0.263384   \n",
      "3649         0.000000              0.0         0.263606         0.000000   \n",
      "3650         0.000000              0.0         0.294570         0.000000   \n",
      "3651         0.000000              0.0         0.000000         0.000000   \n",
      "3652         0.000000              0.0         0.000000         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000           0.00000              0.263618   \n",
      "1            0.000000           0.00000              0.263628   \n",
      "2            0.275454           0.00000              0.275454   \n",
      "3            0.000000           0.00000              0.259196   \n",
      "4            0.000000           0.00000              0.263657   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.000000           0.00000              0.263384   \n",
      "3649         0.000000           0.00000              0.263606   \n",
      "3650         0.000000           0.29457              0.000000   \n",
      "3651         0.261873           0.00000              0.261873   \n",
      "3652         0.294775           0.00000              0.294775   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  0.0  \n",
      "2                  0.0  0.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  0.0  \n",
      "...                ...  ...  \n",
      "3648               0.0  0.0  \n",
      "3649               0.0  0.0  \n",
      "3650               0.0  0.0  \n",
      "3651               0.0  0.0  \n",
      "3652               0.0  0.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n",
      "=====================================================================================\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.051032  0.013119  0.275492  0.000000      0.189401   \n",
      "1     0.0  0.009641  0.000000  0.289101  0.000000      0.096367   \n",
      "2     1.0  0.009698  0.000000  0.289057  0.041294      0.102374   \n",
      "3     1.0  0.001447  0.006277  0.263643  0.000000      0.247165   \n",
      "4     1.0  0.010577  0.021857  0.001838  0.043714      0.025500   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "9129  1.0  0.004428  0.006247  0.262384  0.000000      0.262384   \n",
      "9130  1.0  0.018604  0.000000  0.295146  0.000000      0.030744   \n",
      "9131  1.0  0.004686  0.000000  0.261903  0.000000      0.261903   \n",
      "9132  1.0  0.010671  0.007020  0.294824  0.000000      0.098275   \n",
      "9133  1.0  0.021439  0.000000  0.294519  0.042074      0.098173   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.107255       0.101436   0.214972     0.241850  ...        0.0   \n",
      "1           0.174407       0.195960   0.000721     0.049295  ...        0.0   \n",
      "2           0.226875       0.126991   0.009699     0.030600  ...        0.0   \n",
      "3           0.184221       0.158848   0.252466     0.226663  ...        0.0   \n",
      "4           0.061057       0.227898   0.005272     0.069298  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "9129        0.175570       0.088925   0.257328     0.262384  ...        0.0   \n",
      "9130        0.087647       0.123492   0.042020     0.125646  ...        0.0   \n",
      "9131        0.126869       0.161087   0.257331     0.261903  ...        0.0   \n",
      "9132        0.079508       0.056744   0.041172     0.151034  ...        0.0   \n",
      "9133        0.079426       0.056686   0.041130     0.150878  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.000000         0.000000         0.275492         0.000000   \n",
      "1            0.289101         0.000000         0.000000         0.000000   \n",
      "2            0.000000         0.000000         0.289057         0.000000   \n",
      "3            0.000000         0.000000         0.000000         0.000000   \n",
      "4            0.305998         0.000000         0.000000         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "9129         0.000000         0.262384         0.000000         0.000000   \n",
      "9130         0.000000         0.000000         0.000000         0.295146   \n",
      "9131         0.000000         0.000000         0.000000         0.261903   \n",
      "9132         0.294824         0.000000         0.000000         0.000000   \n",
      "9133         0.294519         0.000000         0.000000         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000          0.000000              0.275492   \n",
      "1            0.000000          0.000000              0.289101   \n",
      "2            0.000000          0.289057              0.000000   \n",
      "3            0.263643          0.000000              0.263643   \n",
      "4            0.000000          0.000000              0.000000   \n",
      "...               ...               ...                   ...   \n",
      "9129         0.000000          0.000000              0.262384   \n",
      "9130         0.000000          0.000000              0.295146   \n",
      "9131         0.000000          0.000000              0.261903   \n",
      "9132         0.000000          0.000000              0.294824   \n",
      "9133         0.000000          0.294519              0.000000   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0             0.000000  0.0  \n",
      "1             0.000000  0.0  \n",
      "2             0.000000  0.0  \n",
      "3             0.000000  0.0  \n",
      "4             0.305998  1.0  \n",
      "...                ...  ...  \n",
      "9129          0.000000  0.0  \n",
      "9130          0.000000  0.0  \n",
      "9131          0.000000  0.0  \n",
      "9132          0.000000  0.0  \n",
      "9133          0.000000  0.0  \n",
      "\n",
      "[9134 rows x 58 columns]\n",
      "=====================================================================================\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['dir_log_group']\n",
      "Results are stored in: ['dir_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  [0.10201871]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: [0.06578876]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 137\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: [0.13186467]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 65, Test = 75\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.17\n",
      "  Test Accuracy (TNR): 0.97\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [1.38642596]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3048, Test = 3059\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: [0.08122537]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 392, Test = 382\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.36\n",
      "  Test Accuracy (TNR): 0.72\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.89250403]\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['rew_log_group']\n",
      "Results are stored in: ['rew_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.1576533]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: [0.28992665]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 137\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.80\n",
      "  Optimal thershold: [0.34884462]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 65, Test = 75\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.28\n",
      "  Test Accuracy (TNR): 0.85\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: [0.47891531]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3048, Test = 3059\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: [0.0772245]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 392, Test = 382\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.92\n",
      "  Optimal thershold: [1.07688755]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['eg_log_group']\n",
      "Results are stored in: ['eg_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: [0.31471074]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 137\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.68\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.35\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: [0.27195577]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 65, Test = 75\n",
      "  AUC: 0.89\n",
      "  Privacy Risk: 0.83\n",
      "  Accuracy: 0.81\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.65\n",
      "  Positive predictive value: 0.89\n",
      "  Optimal thershold: [0.46203546]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3048, Test = 3059\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: [0.09431068]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 392, Test = 382\n",
      "  AUC: 0.90\n",
      "  Privacy Risk: 0.86\n",
      "  Accuracy: 0.86\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.72\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.49429632]\n",
      ")\n",
      "dir_log_group deleted.\n",
      "eg_log_group deleted.\n",
      "rew_log_group deleted.\n",
      "syn_log_group deleted.\n",
      "un_log_group deleted.\n",
      "dir_log_pop deleted.\n",
      "eg_log_pop deleted.\n",
      "rew_log_pop deleted.\n",
      "syn_log_pop deleted.\n",
      "un_log_pop deleted.\n"
     ]
    }
   ],
   "source": [
    "# favorable and unfavorable labels and feature_names\n",
    "f_label = dataset_orig.favorable_label\n",
    "uf_label = dataset_orig.unfavorable_label\n",
    "feature_names = dataset_orig.feature_names\n",
    "\n",
    "try:\n",
    "    # run mitigating algorithms\n",
    "    for i in range(N):\n",
    "        print('ITERATION ', i)\n",
    "        dataset_orig_train, dataset_orig_val, dataset_orig_test, target_dataset, reference_dataset = prepare_datasets()\n",
    "\n",
    "        # check fairness on the original data\n",
    "        metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                                     unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "        print(\"privileged vs. unprivileged: \", metric_orig_train.num_positives(privileged=True) + metric_orig_train.num_negatives(privileged=True), metric_orig_train.num_positives(privileged=False) + metric_orig_train.num_negatives(privileged=False)) \n",
    "        base_rate_unprivileged = metric_orig_train.base_rate(privileged=False)\n",
    "        base_rate_privileged = metric_orig_train.base_rate(privileged=True)\n",
    "\n",
    "        print('base_pos unpriv: ', base_rate_unprivileged)\n",
    "        print('base_pos priv: ', base_rate_privileged)\n",
    "\n",
    "        print(\"DIFFERENCE IS GOOD\")\n",
    "        print('base_pos unpriv: ', base_rate_unprivileged)\n",
    "        print('base_pos priv: ', base_rate_privileged)\n",
    "\n",
    "        # favorable and unfavorable labels and feature_names\n",
    "        f_label = dataset_orig.favorable_label\n",
    "        uf_label = dataset_orig.unfavorable_label\n",
    "        feature_names = dataset_orig.feature_names\n",
    "\n",
    "        # introduce label or selection biases, assuming the original data is fair\n",
    "        if BIAS_TYPE == 'label':\n",
    "            dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "        elif BIAS_TYPE == 'selection':\n",
    "            dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "        else:\n",
    "            print('no bias type specified')\n",
    "\n",
    "        # show data info\n",
    "        print(\"#### Training Dataset shape\")\n",
    "        print(dataset_orig_train.features.shape)\n",
    "        print(\"#### Favorable and unfavorable labels\")\n",
    "        print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "        print(\"#### Protected attribute names\")\n",
    "        print(dataset_orig_train.protected_attribute_names)\n",
    "        print(\"#### Privileged and unprivileged protected groups\")\n",
    "        print(privileged_groups, unprivileged_groups)\n",
    "        print(\"#### Privileged and unprivileged protected attribute values\")\n",
    "        print(dataset_orig_train.privileged_protected_attributes, dataset_orig_train.unprivileged_protected_attributes)\n",
    "        print(\"#### Dataset feature names\")\n",
    "        print(dataset_orig_train.feature_names)\n",
    "        print('number of favorable labels: ', np.count_nonzero(dataset_orig_train.labels==f_label))\n",
    "        print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "        # statistics of favored/positive class BEFORE transf \n",
    "        priv_metric_orig['total_priv'] += metric_orig_train.num_instances(privileged = True) \n",
    "        priv_metric_orig['total_unpriv'] += metric_orig_train.num_instances(privileged = False) \n",
    "        favor_metric_orig['total_favor'] += metric_orig_train.base_rate()\n",
    "        favor_metric_orig['total_unfavor'] += 1 - metric_orig_train.base_rate()\n",
    "        favor_metric_orig['priv_favor'] += metric_orig_train.base_rate(privileged = True)\n",
    "        favor_metric_orig['priv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = True)\n",
    "        favor_metric_orig['unpriv_favor'] += metric_orig_train.base_rate(privileged = False)\n",
    "        favor_metric_orig['unpriv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = False)\n",
    "\n",
    "        print(\"#### Train shape, validation shape, test shape\")\n",
    "        print(dataset_orig_train.features.shape, dataset_orig_val.features.shape, dataset_orig_test.features.shape)\n",
    "\n",
    "        # testing mitigation methods \n",
    "        test_cases = TestAlgorithms(BASELINE)\n",
    "\n",
    "        # null mitigator\n",
    "        orig_metrics, orig_mia_metrics = test_cases.run_original(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, BASELINE, orig_metrics, orig_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset) \n",
    "\n",
    "        # synthetic data mitigator\n",
    "        metric_transf_train, transf_metrics, transf_mia_metrics = test_cases.run_oversample(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, privileged_groups, unprivileged_groups, base_rate_privileged, base_rate_unprivileged, BASELINE, transf_metrics, transf_mia_metrics, f_label, uf_label, ATTACK, THRESH_ARR, DISPLAY, OS_MODE, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        # statistics of favored/positive class AFTER transf\n",
    "        favor_metric_transf['total_favor'] += metric_transf_train.base_rate()\n",
    "        favor_metric_transf['total_unfavor'] += 1 - metric_transf_train.base_rate()\n",
    "        favor_metric_transf['priv_favor'] += metric_transf_train.base_rate(privileged = True)\n",
    "        favor_metric_transf['priv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = True)\n",
    "        favor_metric_transf['unpriv_favor'] += metric_transf_train.base_rate(privileged = False)\n",
    "        favor_metric_transf['unpriv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = False)\n",
    "\n",
    "        # dir mitigator\n",
    "        dir_metrics, dir_mia_metrics = test_cases.run_dir(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test,  sens_attr, BASELINE, dir_metrics, dir_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset) \n",
    "\n",
    "        # reweigh mitigator\n",
    "        reweigh_metrics, reweigh_mia_metrics = test_cases.run_rew(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, reweigh_metrics, reweigh_mia_metrics, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        # eg mitigator, in-processing\n",
    "        eg_metrics, eg_mia_metrics = test_cases.run_eg(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, eg_metrics, eg_mia_metrics, BASELINE, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        # cpp mitigator\n",
    "    #     cpp_metrics, cpp_mia_metrics = test_cases.run_cpp(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, cpp_metrics, cpp_mia_metrics, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        delete_logs()\n",
    "except ValueError as e:\n",
    "    print(\"Error detected: No samples generated. Adjusting datasets...\")\n",
    "    delete_logs()\n",
    "    # percentage of favor and unfavor\n",
    "    priv_metric_orig = defaultdict(float)\n",
    "    favor_metric_orig = defaultdict(float)\n",
    "    favor_metric_transf = defaultdict(float)\n",
    "\n",
    "    # for each pre-processing approach, we create a mia_metric_results\n",
    "    orig_metrics = defaultdict(list)\n",
    "    orig_mia_metrics = defaultdict(list)\n",
    "\n",
    "    transf_metrics = defaultdict(list) \n",
    "    transf_mia_metrics = defaultdict(list) \n",
    "\n",
    "    reweigh_metrics = defaultdict(list) \n",
    "    reweigh_mia_metrics = defaultdict(list) \n",
    "\n",
    "    dir_metrics = defaultdict(list) \n",
    "    dir_mia_metrics = defaultdict(list) \n",
    "\n",
    "    eg_metrics = defaultdict(list) \n",
    "    eg_mia_metrics = defaultdict(list) \n",
    "    # run mitigating algorithms\n",
    "    for i in range(N):\n",
    "        print('ITERATION ', i)\n",
    "        dataset_orig_train, dataset_orig_val, dataset_orig_test, target_dataset, reference_dataset = prepare_datasets()\n",
    "\n",
    "        # check fairness on the original data\n",
    "        metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                                     unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "        print(\"privileged vs. unprivileged: \", metric_orig_train.num_positives(privileged=True) + metric_orig_train.num_negatives(privileged=True), metric_orig_train.num_positives(privileged=False) + metric_orig_train.num_negatives(privileged=False)) \n",
    "        base_rate_unprivileged = metric_orig_train.base_rate(privileged=False)\n",
    "        base_rate_privileged = metric_orig_train.base_rate(privileged=True)\n",
    "\n",
    "        print('base_pos unpriv: ', base_rate_unprivileged)\n",
    "        print('base_pos priv: ', base_rate_privileged)\n",
    "\n",
    "        while(base_rate_privileged >= base_rate_unprivileged and (base_rate_privileged - base_rate_unprivileged) <= 0.05):\n",
    "            print(\"DIFFERENCE IS TOO LOW, GETTING DATASETS AGAIN\")\n",
    "            dataset_orig_train, dataset_orig_val, dataset_orig_test, target_dataset, reference_dataset = prepare_datasets()\n",
    "             # check fairness on the original data\n",
    "            metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                                         unprivileged_groups=unprivileged_groups,\n",
    "                                                         privileged_groups=privileged_groups)\n",
    "            print(\"privileged vs. unprivileged: \", metric_orig_train.num_positives(privileged=True) + metric_orig_train.num_negatives(privileged=True), metric_orig_train.num_positives(privileged=False) + metric_orig_train.num_negatives(privileged=False)) \n",
    "            base_rate_unprivileged = metric_orig_train.base_rate(privileged=False)\n",
    "            base_rate_privileged = metric_orig_train.base_rate(privileged=True)\n",
    "\n",
    "        print(\"DIFFERENCE IS GOOD\")\n",
    "        print('base_pos unpriv: ', base_rate_unprivileged)\n",
    "        print('base_pos priv: ', base_rate_privileged)\n",
    "\n",
    "        # favorable and unfavorable labels and feature_names\n",
    "        f_label = dataset_orig.favorable_label\n",
    "        uf_label = dataset_orig.unfavorable_label\n",
    "        feature_names = dataset_orig.feature_names\n",
    "\n",
    "        # introduce label or selection biases, assuming the original data is fair\n",
    "        if BIAS_TYPE == 'label':\n",
    "            dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "        elif BIAS_TYPE == 'selection':\n",
    "            dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "        else:\n",
    "            print('no bias type specified')\n",
    "\n",
    "        # show data info\n",
    "        print(\"#### Training Dataset shape\")\n",
    "        print(dataset_orig_train.features.shape)\n",
    "        print(\"#### Favorable and unfavorable labels\")\n",
    "        print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "        print(\"#### Protected attribute names\")\n",
    "        print(dataset_orig_train.protected_attribute_names)\n",
    "        print(\"#### Privileged and unprivileged protected groups\")\n",
    "        print(privileged_groups, unprivileged_groups)\n",
    "        print(\"#### Privileged and unprivileged protected attribute values\")\n",
    "        print(dataset_orig_train.privileged_protected_attributes, dataset_orig_train.unprivileged_protected_attributes)\n",
    "        print(\"#### Dataset feature names\")\n",
    "        print(dataset_orig_train.feature_names)\n",
    "        print('number of favorable labels: ', np.count_nonzero(dataset_orig_train.labels==f_label))\n",
    "        print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "        # statistics of favored/positive class BEFORE transf \n",
    "        priv_metric_orig['total_priv'] += metric_orig_train.num_instances(privileged = True) \n",
    "        priv_metric_orig['total_unpriv'] += metric_orig_train.num_instances(privileged = False) \n",
    "        favor_metric_orig['total_favor'] += metric_orig_train.base_rate()\n",
    "        favor_metric_orig['total_unfavor'] += 1 - metric_orig_train.base_rate()\n",
    "        favor_metric_orig['priv_favor'] += metric_orig_train.base_rate(privileged = True)\n",
    "        favor_metric_orig['priv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = True)\n",
    "        favor_metric_orig['unpriv_favor'] += metric_orig_train.base_rate(privileged = False)\n",
    "        favor_metric_orig['unpriv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = False)\n",
    "\n",
    "        print(\"#### Train shape, validation shape, test shape\")\n",
    "        print(dataset_orig_train.features.shape, dataset_orig_val.features.shape, dataset_orig_test.features.shape)\n",
    "\n",
    "        # testing mitigation methods \n",
    "        test_cases = TestAlgorithms(BASELINE)\n",
    "\n",
    "        # null mitigator\n",
    "        orig_metrics, orig_mia_metrics = test_cases.run_original(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, BASELINE, orig_metrics, orig_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset) \n",
    "        print(\"ORIG MIA METRICS \", orig_mia_metrics)\n",
    "        \n",
    "        # synthetic data mitigator\n",
    "        metric_transf_train, transf_metrics, transf_mia_metrics = test_cases.run_oversample(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, privileged_groups, unprivileged_groups, base_rate_privileged, base_rate_unprivileged, BASELINE, transf_metrics, transf_mia_metrics, f_label, uf_label, ATTACK, THRESH_ARR, DISPLAY, OS_MODE, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        # statistics of favored/positive class AFTER transf\n",
    "        favor_metric_transf['total_favor'] += metric_transf_train.base_rate()\n",
    "        favor_metric_transf['total_unfavor'] += 1 - metric_transf_train.base_rate()\n",
    "        favor_metric_transf['priv_favor'] += metric_transf_train.base_rate(privileged = True)\n",
    "        favor_metric_transf['priv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = True)\n",
    "        favor_metric_transf['unpriv_favor'] += metric_transf_train.base_rate(privileged = False)\n",
    "        favor_metric_transf['unpriv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = False)\n",
    "\n",
    "        # dir mitigator\n",
    "        dir_metrics, dir_mia_metrics = test_cases.run_dir(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test,  sens_attr, BASELINE, dir_metrics, dir_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset) \n",
    "\n",
    "        # reweigh mitigator\n",
    "        reweigh_metrics, reweigh_mia_metrics = test_cases.run_rew(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, reweigh_metrics, reweigh_mia_metrics, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        # eg mitigator, in-processing\n",
    "        eg_metrics, eg_mia_metrics = test_cases.run_eg(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, eg_metrics, eg_mia_metrics, BASELINE, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        # cpp mitigator\n",
    "    #     cpp_metrics, cpp_mia_metrics = test_cases.run_cpp(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, cpp_metrics, cpp_mia_metrics, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        delete_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a163caa5",
   "metadata": {},
   "source": [
    "## Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47b50fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dictionary to store SHAP values\n",
    "# shap_results = {\n",
    "#     \"orig\": orig_metrics['shap_values'],\n",
    "#     \"transf\": transf_metrics['shap_values'],\n",
    "#     \"dir\": dir_metrics['shap_values'],\n",
    "#     \"reweigh\": reweigh_metrics['shap_values'],\n",
    "#     \"eg\": eg_metrics['shap_values']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2293e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_results = pd.DataFrame.from_dict(shap_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # File path\n",
    "# today = datetime.now().strftime('%Y-%m-%d')\n",
    "# file_path = f\"./mia2_results/rf_{ATTACK}_{DATASET}_shap_values_{today}.csv\"\n",
    "\n",
    "# # Save to CSV\n",
    "# shap_results.to_csv(file_path, index=True)\n",
    "\n",
    "# file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90de2a9",
   "metadata": {},
   "source": [
    "## Display Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5297f75-7e94-4c41-ae69-97b4e11bdcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38506977-5981-4c45-a7d0-38613da7edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig_copy = priv_metric_orig\n",
    "\n",
    "priv_metric_orig_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b736dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c736a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73a4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig = priv_metric_orig_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf623751",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "print('1)\\n')\n",
    "print(DATASET)\n",
    "print(dataset_orig_train.features.shape[0])\n",
    "\n",
    "print('2)\\n')\n",
    "priv_metric_orig = {k: [v/N] for (k,v) in priv_metric_orig.items()}\n",
    "results = [priv_metric_orig]\n",
    "tr = pd.Series(['orig'], name='num_instance')\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis = 0).set_index([tr])\n",
    "print(df)\n",
    "\n",
    "print('3)\\n')\n",
    "favor_metric_orig = {k: [v/N] for (k,v) in favor_metric_orig.items()}\n",
    "favor_metric_transf = {k: [v/N] for (k,v) in favor_metric_transf.items()}\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "results = [favor_metric_orig, favor_metric_transf]\n",
    "tr = pd.Series(['orig'] + ['transf'], name='dataset')\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis = 0).set_index([tr])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5039b1e0",
   "metadata": {},
   "source": [
    "# Train/Test Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef1ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_metrics(metrics):\n",
    "    accuracy_metrics = defaultdict(list)\n",
    "\n",
    "    # List of accuracy-related keys\n",
    "    accuracy_keys = [\n",
    "        'accuracy_train_0_-', 'accuracy_train_0_+',\n",
    "        'accuracy_train_1_-', 'accuracy_train_1_+',\n",
    "        'accuracy_test_0_-', 'accuracy_test_0_+',\n",
    "        'accuracy_test_1_-', 'accuracy_test_1_+',\n",
    "        'accuracy_train', 'accuracy_test'\n",
    "    ]\n",
    "\n",
    "    # Separate accuracy metrics into a new dictionary\n",
    "    for key in accuracy_keys:\n",
    "        if key in metrics:\n",
    "            accuracy_metrics[key] = metrics.pop(key)\n",
    "\n",
    "    return metrics, accuracy_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e982d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_metrics, orig_acc = separate_metrics(orig_metrics)\n",
    "transf_metrics, transf_acc = separate_metrics(transf_metrics)\n",
    "reweigh_metrics, reweigh_acc = separate_metrics(reweigh_metrics)\n",
    "dir_metrics, dir_acc = separate_metrics(dir_metrics)\n",
    "eg_metrics, eg_acc = separate_metrics(eg_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8cc8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std_accuracy(acc_metrics):\n",
    "    mean_std_accuracies = {\n",
    "        key: {\n",
    "            \"mean\": sum(values) / len(values),\n",
    "            \"std\": statistics.stdev(values) if len(values) > 1 else 0  # Avoid error if only one value\n",
    "        }\n",
    "        for key, values in acc_metrics.items()\n",
    "    }\n",
    "    return mean_std_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_acc_stats = calculate_mean_std_accuracy(orig_acc)\n",
    "transf_acc_stats = calculate_mean_std_accuracy(transf_acc)\n",
    "reweigh_acc_stats = calculate_mean_std_accuracy(reweigh_acc)\n",
    "dir_acc_stats = calculate_mean_std_accuracy(dir_acc)\n",
    "eg_acc_stats = calculate_mean_std_accuracy(eg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae83fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary to DataFrame with mean and std\n",
    "train_test_data = {\n",
    "    \"orig_acc_mean\": {key: value[\"mean\"] for key, value in orig_acc_stats.items()},\n",
    "    \"orig_acc_std\": {key: value[\"std\"] for key, value in orig_acc_stats.items()},\n",
    "    \"transf_acc_mean\": {key: value[\"mean\"] for key, value in transf_acc_stats.items()},\n",
    "    \"transf_acc_std\": {key: value[\"std\"] for key, value in transf_acc_stats.items()},\n",
    "    \"reweigh_acc_mean\": {key: value[\"mean\"] for key, value in reweigh_acc_stats.items()},\n",
    "    \"reweigh_acc_std\": {key: value[\"std\"] for key, value in reweigh_acc_stats.items()},\n",
    "    \"dir_acc_mean\": {key: value[\"mean\"] for key, value in dir_acc_stats.items()},\n",
    "    \"dir_acc_std\": {key: value[\"std\"] for key, value in dir_acc_stats.items()},\n",
    "    \"eg_acc_mean\": {key: value[\"mean\"] for key, value in eg_acc_stats.items()},\n",
    "    \"eg_acc_std\": {key: value[\"std\"] for key, value in eg_acc_stats.items()},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063eb6e5",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ba9d2a-6816-41ae-865e-8e3b9bf5e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir \"../rf_mia2_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccdbe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary to DataFrame\n",
    "train_test_df = pd.DataFrame(train_test_data)\n",
    "\n",
    "# File path\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "file_path = f\"./dprf_new_mia2_results/{BASELINE}_{ATTACK}_{DATASET}_train_test_accuracies_{today}_depth15_eps1.csv\"\n",
    "\n",
    "# Save to CSV\n",
    "train_test_df.to_csv(file_path, index=True)\n",
    "\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd3105",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8158ae75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb16e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance_df = pd.DataFrame(orig_metrics[\"feature_importances\"])  # Extract feature importance across runs\n",
    "# feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a78a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "print('4)\\n')\n",
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_error_metrics = {k: [statistics.stdev(v)] for (k,v) in orig_metrics.items()}\n",
    "transf_error_metrics = {k: [statistics.stdev(v)] for (k,v) in transf_metrics.items()}\n",
    "reweigh_error_metrics = {k: [statistics.stdev(v)] for (k,v) in reweigh_metrics.items()}\n",
    "dir_error_metrics = {k: [statistics.stdev(v)] for (k,v) in dir_metrics.items()}\n",
    "eg_error_metrics = {k: [statistics.stdev(v)] for (k,v) in eg_metrics.items()}\n",
    "# pr_orig_error_metrics = {k: [statistics.stdev(v)] for (k,v) in pr_orig_metrics.items()}\n",
    "# cpp_error_metrics = {k: [statistics.stdev(v)] for (k,v) in cpp_metrics.items()}\n",
    "# ro_error_metrics = {k: [statistics.stdev(v)] for (k,v) in ro_metrics.items()}\n",
    "\n",
    "# mean value metrics\n",
    "orig_metrics_mean = {k: [sum(v)/N] for (k,v) in orig_metrics.items()}\n",
    "transf_metrics_mean = {k: [sum(v)/N] for (k,v) in transf_metrics.items()}\n",
    "reweigh_metrics_mean = {k:[sum(v)/N] for (k,v) in reweigh_metrics.items()}\n",
    "dir_metrics_mean = {k:[sum(v)/N] for (k,v) in dir_metrics.items()}\n",
    "eg_metrics_mean = {k:[sum(v)/N] for (k,v) in eg_metrics.items()}\n",
    "# pr_orig_metrics_mean = {k: [sum(v)/N] for (k,v) in pr_orig_metrics.items()}\n",
    "# cpp_metrics_mean = {k: [sum(v)/N] for (k,v) in cpp_metrics.items()}\n",
    "# ro_metrics_mean = {k: [sum(v)/N] for (k,v) in ro_metrics.items()}\n",
    "\n",
    "# Python paired sample t-test\n",
    "# from scipy.stats import ttest_rel\n",
    "# def paired_t (a, b):\n",
    "#     np_a = np.array(a)\n",
    "#     np_b = np.array(b)\n",
    "#     s, p = ttest_rel(np.absolute(np_a), np.absolute(np_b))\n",
    "#     return p\n",
    "\n",
    "# def acc_diff (a, b):\n",
    "#     np_a = np.array(a)\n",
    "#     np_b = np.array(b)\n",
    "#     delta = np_a - np_b\n",
    "#     m = statistics.mean(delta)\n",
    "#     s = statistics.stdev(delta)\n",
    "#     return [m, s]\n",
    "\n",
    "# if BASELINE == 'lr':\n",
    "#     plot_algo_lr(orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, eg_metrics_mean, pr_orig_metrics_mean, orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, eg_error_metrics, BASELINE)\n",
    "#     stat =  {k: [paired_t(transf_metrics[k], v)] for (k,v) in orig_metrics.items()}\n",
    "#     print(\"5)\")\n",
    "#     print(stat)\n",
    "# else:\n",
    "#     plot_algo(orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, eg_metrics_mean, orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, eg_error_metrics, BASELINE)\n",
    "#     stat =  {k: [paired_t(transf_metrics[k], v)] for (k,v) in orig_metrics.items()}\n",
    "#     print(stat)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1627a85",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f14ab",
   "metadata": {},
   "source": [
    "### Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b83d225-b984-4107-997e-a7be4f183a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type=BASELINE\n",
    "# Set up plotting options\n",
    "plt.rcParams.update({'font.size': 8})  # Set global font size\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "\n",
    "# Metrics and errors as lists of dictionaries\n",
    "results = [orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, eg_metrics_mean]\n",
    "errors = [orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, eg_error_metrics]\n",
    "\n",
    "# Classifier bias mitigators (for labels)\n",
    "index = pd.Series(\n",
    "    [model_type+'_orig', model_type+'_syn', model_type+'_dir', model_type+'_rew', model_type+'_eg'])\n",
    "\n",
    "# Create DataFrame for metrics and error bars\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis=0).set_index(index)\n",
    "df_error = pd.concat([pd.DataFrame(metrics) for metrics in errors], axis=0).set_index(index)\n",
    "\n",
    "# Dynamically generate titles for all metrics in df\n",
    "titles = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149148b8-21fc-4cad-bfab-dc793d2d6293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fairness metrics with error bars\n",
    "ax = df.plot.bar(\n",
    "    yerr=df_error, \n",
    "    capsize=2, \n",
    "    rot=0, \n",
    "    subplots=True, \n",
    "    title=titles, \n",
    "    fontsize=8, \n",
    "    figsize=(7, 10),  \n",
    "    legend=True,\n",
    "    width=0.7  \n",
    ")\n",
    "\n",
    "# Adjust Y-axis limits dynamically\n",
    "for i, subplot in enumerate(ax):\n",
    "    metric = titles[i]\n",
    "    y_values = df[metric]\n",
    "    y_errors = df_error[metric]\n",
    "\n",
    "    # Compute min and max with error bars included\n",
    "    y_min = (y_values - y_errors).min()\n",
    "    y_max = (y_values + y_errors).max()\n",
    "\n",
    "    # Add padding\n",
    "    y_range = y_max - y_min\n",
    "    padding = 0.1 * y_range if y_range > 0 else 0.05  # ensure some space even for flat values\n",
    "\n",
    "    lower = max(0, y_min - padding)\n",
    "    upper = y_max + padding\n",
    "\n",
    "    # Print min and max to check them\n",
    "    print(f\"Metric: {metric:20} | Min: {y_min:.4f} | Max: {y_max:.4f} | Range: ({lower:.4f}, {upper:.4f})\")\n",
    "\n",
    "    # Set Y-axis limits\n",
    "    subplot.set_ylim([lower, upper])\n",
    "\n",
    "    # Optional: force specific bounds if needed\n",
    "    if \"fpr\" in metric or \"fnr\" in metric:\n",
    "        subplot.set_ylim([0, 1])  # Keep 01 if needed for these metrics\n",
    "\n",
    "    # Move legend inside the plot\n",
    "    subplot.legend(loc='upper left', fontsize=8, frameon=True)\n",
    "\n",
    "# Better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a118582a",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c52e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of method names corresponding to results/errors\n",
    "method_names = [\"orig\", \"transf\", \"dir\", \"rew\", \"eg\"]\n",
    "\n",
    "# Initialize a list to hold data for the DataFrame\n",
    "fairness_data = []\n",
    "\n",
    "# Populate the data list with metrics and errors\n",
    "for method, metric, error in zip(method_names, results, errors):\n",
    "    for key in metric.keys():\n",
    "        fairness_data.append({\n",
    "            \"Method\": method,\n",
    "            \"Metric\": key,\n",
    "            \"Mean\": metric[key][0],  # Assuming the metric values are single-item lists\n",
    "            \"Error\": error[key][0]   # Assuming the error values are single-item lists\n",
    "        })\n",
    "\n",
    "# Create DataFrame from the data list\n",
    "fairness_df = pd.DataFrame(fairness_data)\n",
    "\n",
    "# File path with today's date\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "file_path = f\"./dprf_new_mia2_results/{BASELINE}_{ATTACK}_{DATASET}_fairness_metrics_{today}_depth15_eps1.csv\"\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "fairness_df.to_csv(file_path, index=True)\n",
    "\n",
    "print(f\"File saved at: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7aff8d",
   "metadata": {},
   "source": [
    "## Visualization of MIA results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588cc377",
   "metadata": {},
   "source": [
    "\n",
    "### Visualization of MIA Attacks against various Fairness Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a42bd",
   "metadata": {},
   "source": [
    "#### Privacy risk subpopulations vs Fairness with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dddfde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "%matplotlib inline\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "eg_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in eg_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "# cpp_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in cpp_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "eg_mia_metrics_mean = {k:sum(v)/N for (k,v) in eg_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "# cpp_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6882740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "           orig_mia_error_metrics,\n",
    "           transf_mia_metrics_mean,\n",
    "           transf_mia_error_metrics,\n",
    "           dir_mia_metrics_mean,\n",
    "           dir_mia_error_metrics,\n",
    "           reweigh_mia_metrics_mean,\n",
    "           reweigh_mia_error_metrics,\n",
    "           eg_mia_metrics_mean,\n",
    "           eg_mia_error_metrics\n",
    "          ]\n",
    "\n",
    "index = pd.Series(['orig'] + ['orig_std'] + ['syn'] + ['syn_std'] + ['dir'] + ['dir_std'] + ['rew'] + \n",
    "                  ['rew_std'] + ['eg'] + ['eg_std'], name='Classifier MIA Attacks')\n",
    "#                   + ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0aab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [orig_mia_metrics_mean,\n",
    "           transf_mia_metrics_mean,\n",
    "           dir_mia_metrics_mean,\n",
    "           reweigh_mia_metrics_mean,\n",
    "           eg_mia_metrics_mean,\n",
    "          ]\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "          transf_mia_error_metrics,\n",
    "          dir_mia_error_metrics,\n",
    "          reweigh_mia_error_metrics,\n",
    "          eg_mia_error_metrics\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df1431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = df[['subpopulation_0.0_label_0.0_mia_privacy_risk',\n",
    "       'subpopulation_1.0_label_0.0_mia_privacy_risk',\n",
    "                       'subpopulation_0.0_label_1.0_mia_privacy_risk',\n",
    "       'subpopulation_1.0_label_1.0_mia_privacy_risk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e94927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = df_groups.rename(columns={'subpopulation_0.0_label_0.0_mia_privacy_risk': 'G0-',\n",
    "                           'subpopulation_1.0_label_0.0_mia_privacy_risk': 'G1-',\n",
    "                           'subpopulation_0.0_label_1.0_mia_privacy_risk': 'G0+',\n",
    "                           'subpopulation_1.0_label_1.0_mia_privacy_risk': 'G1+'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d711e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f230c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225fcad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tabular Format\n",
    "# importing the modules\n",
    "from tabulate import tabulate\n",
    "\n",
    " \n",
    "# displaying the DataFrame\n",
    "print(tabulate(df_groups.T, headers = 'keys', tablefmt = 'simple'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7040e9bb",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696b6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7b42a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of method names corresponding to results/errors\n",
    "method_names = [\"orig\", \"transf\", \"dir\", \"rew\", \"eg\"]\n",
    "\n",
    "# Initialize a list to hold data for the DataFrame\n",
    "pr_data = []\n",
    "\n",
    "# Populate the data list with metrics and errors\n",
    "for method, metric, error in zip(method_names, results, errors):\n",
    "    for key in metric.keys():\n",
    "        pr_data.append({\n",
    "            \"Method\": method,\n",
    "            \"Metric\": key,\n",
    "            \"Mean Privacy Risk\": metric[key],  # Privacy risk mean\n",
    "            \"Error\": error[key]               # Privacy risk error\n",
    "        })\n",
    "\n",
    "# Create DataFrame from the data list\n",
    "pr_df = pd.DataFrame(pr_data)\n",
    "\n",
    "# File path with today's date\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "file_path = f\"./dprf_new_mia2_results/{BASELINE}_{ATTACK}_{DATASET}_mia_privacy_risks_metrics_{today}_depth15_eps1.csv\"\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "pr_df.to_csv(file_path, index=True)\n",
    "\n",
    "print(f\"File saved at: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f69948e",
   "metadata": {},
   "source": [
    "# Main Bar Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99444ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subpopulations and fairness methods\n",
    "subpopulations = {\n",
    "    'subpopulation_0.0_label_0.0_mia_privacy_risk': \"Unprivileged Unfavorable\", \n",
    "    'subpopulation_0.0_label_1.0_mia_privacy_risk': \"Unprivileged Favorable\", \n",
    "    'subpopulation_1.0_label_0.0_mia_privacy_risk': \"Privileged Unfavorable\",\n",
    "    'subpopulation_1.0_label_1.0_mia_privacy_risk': \"Privileged Favorable\"\n",
    "}\n",
    "\n",
    "fairness_methods = [\"syn\", \"dir\", \"rew\", \"eg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84957cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine results into a list\n",
    "all_results = [\n",
    "    transf_mia_metrics_mean,\n",
    "    dir_mia_metrics_mean,\n",
    "    reweigh_mia_metrics_mean,\n",
    "    eg_mia_metrics_mean\n",
    "]\n",
    "\n",
    "# Organize data for plotting\n",
    "data = {subpopulations[key]: [results[key] for results in all_results] for key in subpopulations.keys()}\n",
    "orig_values = orig_mia_metrics_mean\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "idx = 0\n",
    "\n",
    "for key, value in subpopulations.items():\n",
    "    accuracies = data[value]\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot bar chart (excluding 'orig')\n",
    "    ax.bar(fairness_methods, accuracies, color='skyblue', edgecolor='black')\n",
    "    \n",
    "    # Add dashed line for 'orig' MIA accuracy\n",
    "    ax.axhline(orig_values[key], color='red', linestyle='--', label='Orig MIA')\n",
    "    \n",
    "    # Title and labels\n",
    "    ax.set_title(f\"MIA Accuracies - {value}\", fontsize=10)\n",
    "    ax.set_ylabel(\"MIA Accuracy\")\n",
    "    ax.set_xticks(np.arange(len(fairness_methods)))\n",
    "    ax.set_xticklabels(fairness_methods, rotation=45)\n",
    "    ax.legend()\n",
    "    \n",
    "    idx = idx + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a2e6d",
   "metadata": {},
   "source": [
    "### Visualizing using novel technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faed82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_error_metrics = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "eg_mia_error_metrics = {k: v for (k,v) in eg_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "#orig_mia_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_error_metrics.keys():\n",
    "    for val in orig_mia_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in eg_mia_error_metrics.keys():\n",
    "    for val in eg_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"eg\", key.replace(\"_mia_attacker_advantage\", \"\"), val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b110698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"Privacy Risk\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8a5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only subgroups\n",
    "df_subgroups = df[~((df[\"MIA\"] == \"entire_dataset_label_0.0_mia_privacy_risk\") | (df[\"MIA\"] == \"entire_dataset_label_1.0_mia_privacy_risk\")) ]\n",
    "df_subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df3d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15,8))\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df_subgroups, x=\"MIA\", y=\"Privacy Risk\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Privacy Risk\" )\n",
    "g.set(ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359dc0bf",
   "metadata": {},
   "source": [
    "### ROC curves and AUC scores with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7b52ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for orig dataset with different subpopulations\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for key in [\"entire_dataset_mia_result\", \n",
    "            \"subpopulation_0.0_label_0.0_mia_result\",\n",
    "            \"subpopulation_0.0_label_1.0_mia_result\", \n",
    "            \"subpopulation_1.0_label_0.0_mia_result\",\n",
    "            \"subpopulation_1.0_label_1.0_mia_result\"]:\n",
    "     # fprs = [mia_res.fpr for mia_res in orig_mia_metrics[key]]\n",
    "    # tprs = [mia_res.tpr for mia_res in orig_mia_metrics[key]]\n",
    "    tprs = []\n",
    "    \n",
    "    # aucs = [mia_res.get_auc() for mia_res in orig_mia_metrics[key]]\n",
    "    aucs = []\n",
    "\n",
    "    # mean_fpr = np.mean(fprs, axis=0)\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "    for mia_res in orig_mia_metrics[key]:\n",
    "        interp_tpr = np.interp(mean_fpr, mia_res.fpr, mia_res.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(mia_res.get_auc())\n",
    "    \n",
    "    #print(mean_fpr)\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    \n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    \n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        #color=\"b\",\n",
    "        label=r\"Mean ROC for %s $\\pm$ 1 std. dev. (AUC = %0.2f $\\pm$ %0.2f)\" % ( key ,mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        #label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve with variability\",\n",
    ")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ff10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entire dataset with different subpopulations\n",
    "# fig, ax = plt.subplots(figsize=(12, 10))\n",
    "fig, ax = plt.subplots(figsize=(24, 18))\n",
    "\n",
    "for mia_metrics, name in zip([orig_mia_metrics, transf_mia_metrics], [\"orig\", \"syn\"]): \n",
    "#                               dir_mia_metrics, reweigh_mia_metrics], [\"orig\", \"syn\", \"dir\", \"reweigh\"] ):\n",
    "    for key in [\"entire_dataset_mia_result\", \n",
    "                \"subpopulation_0.0_label_0.0_mia_result\",\n",
    "                \"subpopulation_0.0_label_1.0_mia_result\", \n",
    "                \"subpopulation_1.0_label_0.0_mia_result\",\n",
    "                \"subpopulation_1.0_label_1.0_mia_result\"]:\n",
    "   \n",
    "        # fprs = [mia_res.fpr for mia_res in orig_mia_metrics[key]]\n",
    "        # tprs = [mia_res.tpr for mia_res in orig_mia_metrics[key]]\n",
    "        tprs = []\n",
    "        # aucs = [mia_res.get_auc() for mia_res in orig_mia_metrics[key]]\n",
    "        aucs = []\n",
    "\n",
    "        # mean_fpr = np.mean(fprs, axis=0)\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "        for mia_res in mia_metrics[key]:\n",
    "            print(mia_res)\n",
    "            interp_tpr = np.interp(mean_fpr, mia_res.fpr, mia_res.tpr)\n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "            aucs.append(mia_res.get_auc())\n",
    "\n",
    "        #print(mean_fpr)\n",
    "        print(tprs)\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std(aucs)\n",
    "\n",
    "        ax.plot(\n",
    "            mean_fpr,\n",
    "            mean_tpr,\n",
    "            #color=\"b\",\n",
    "            label=r\"%s Mean ROC for %s $\\pm$ 1 std. dev. (AUC = %0.2f $\\pm$ %0.2f)\" % (name, key ,mean_auc, std_auc),\n",
    "            lw=2,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        std_tpr = np.std(tprs, axis=0)\n",
    "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        ax.fill_between(\n",
    "            mean_fpr,\n",
    "            tprs_lower,\n",
    "            tprs_upper,\n",
    "            color=\"grey\",\n",
    "            alpha=0.2,\n",
    "            #label=r\"$\\pm$ 1 std. dev.\",\n",
    "        )\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve for MIA attacks against Fairness Approaches\",\n",
    ")\n",
    "ax.legend(loc=\"lower right\")\n",
    "# ax.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entire dataset\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "for mia_res in orig_mia_metrics[\"entire_dataset_mia_result\"]:\n",
    "    plt.plot(mia_res.fpr,mia_res.tpr,label=f\"{mia_res.get_name()} auc={mia_res.get_auc()}\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e701aad9",
   "metadata": {},
   "source": [
    "## MIA Attacks AUC vs Fairness Bar Chart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f18425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "egr_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in eg_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "eg_mia_metrics_mean = {k:sum(v)/N for (k,v) in eg_mia_metrics.items() if k.endswith(\"mia_auc\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b078a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuazlization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "        transf_mia_metrics_mean,\n",
    "        dir_mia_metrics_mean,\n",
    "        reweigh_mia_metrics_mean,\n",
    "        eg_mia_metrics_mean\n",
    "        ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "        transf_mia_error_metrics,\n",
    "        dir_mia_error_metrics,\n",
    "        reweigh_mia_error_metrics,\n",
    "          egr_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn']+ ['dir']+ ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2233661a",
   "metadata": {},
   "source": [
    "###  MIA Attackers Advantage Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f09191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data structures to plot point categorical plot from seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ef741",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "egr_mia_error_metrics = {k: v for (k,v) in eg_mia_metrics.items() if k.endswith(\"attacker_advantage\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_metrics_att_ad.keys():\n",
    "    for val in orig_mia_metrics_att_ad[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in egr_mia_error_metrics.keys():\n",
    "    for val in egr_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"egr\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "advantage_metrics_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105df8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"attacker_advantage\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac8578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting without scaling y limis to 1\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"attacker_advantage\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's Advantage\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf746e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15,8))\n",
    "\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"attacker_advantage\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's Advantage\" )\n",
    "g.set(ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b0356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(orig_mia_metrics_att_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "egr_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in eg_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "eg_mia_metrics_mean = {k:sum(v)/N for (k,v) in eg_mia_metrics.items() if k.endswith(\"attacker_advantage\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuazlization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "        transf_mia_metrics_mean,\n",
    "        dir_mia_metrics_mean,\n",
    "        reweigh_mia_metrics_mean,\n",
    "           eg_mia_metrics_mean\n",
    "        ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "        transf_mia_error_metrics,\n",
    "        dir_mia_error_metrics,\n",
    "        reweigh_mia_error_metrics,\n",
    "          egr_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn']+ ['dir']+ ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1309a4",
   "metadata": {},
   "source": [
    "## PPV Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "egr_mia_error_metrics = {k: v for (k,v) in eg_mia_metrics.items() if k.endswith(\"mia_ppv\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14018577",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_metrics_att_ad.keys():\n",
    "    for val in orig_mia_metrics_att_ad[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in egr_mia_error_metrics.keys():\n",
    "    for val in egr_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"egr\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "advantage_metrics_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95980069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"PPV\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff9b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting without scaling y limis to 1\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"PPV\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's PPV\" )\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
