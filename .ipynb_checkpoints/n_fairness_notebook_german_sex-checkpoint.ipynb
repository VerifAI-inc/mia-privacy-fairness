{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8c9f6b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "151964f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4aa3557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset, BankDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f6016af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import StandardDataset\n",
    "StandardDataset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f57d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from data_utils import DatasetBuilder\n",
    "from metrics_utils import compute_metrics, describe_metrics, get_test_metrics, test\n",
    "from plot_utils import plot\n",
    "from mitigators import NullMitigator, SyntheticMitigator, DIRMitigator, ReweighMitigator, EGMitigator, PRMitigator, CPPMitigator, ROMitigator \n",
    "from test_algorithms import TestAlgorithms\n",
    "from plot_utils import plot_algo_lr, plot_algo\n",
    "\n",
    "# Metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "\n",
    "# Bias insertion\n",
    "from oversample import label_bias, selection_bias \n",
    "from metrics_utils import get_orig_model_metrics\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Privacy Meter\n",
    "from privacy_meter.dataset import Dataset\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "696bb6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180b2a8",
   "metadata": {},
   "source": [
    "## Arguments & Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "564c7837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-a', '--attack'], dest='attack', nargs=None, const=None, default='mia1', type=None, choices=['mia1', 'mia2'], required=False, help='attacks: our implementation, their implementation', metavar=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct argument parser\n",
    "import argparse\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--data\", choices=['adult', 'compas', 'german', 'bank', 'meps19', 'grade', 'law_sex'], default='compas', help=\"dataset: adult, compas, german, bank, meps19, grade\")\n",
    "ap.add_argument(\"-c\", \"--classifier\", choices=['lr', 'rf', 'svm', 'nn', 'nb'], default='lr', help=\"baseline model: lr, rf, svm, nn, nb, dt\")\n",
    "ap.add_argument(\"-m\", \"--mitigator\", choices=['dir', 'rew', 'egr', 'pr', 'cpp', 'ro'], required=False, help=\"mitigators: dir, rew, egr, pr, cpp, ro\")\n",
    "ap.add_argument(\"-b\", \"--bias\", default=0., help=\"amount of bias: o-1\")\n",
    "ap.add_argument(\"-t\", \"--biastype\", choices=['label', 'selection', 'none'], default='none', help=\"amount of bias: o-1\")\n",
    "ap.add_argument(\"-o\", \"--os\", default=2, help=\"oversample mode: 1: privi unfav 2: unpriv fav\")\n",
    "ap.add_argument(\"-a\", \"--attack\", choices=['mia1', 'mia2'], default='mia1', help=\"attacks: our implementation, their implementation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4f8856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['']\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "19b063bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 'compas',\n",
       " 'classifier': 'lr',\n",
       " 'mitigator': None,\n",
       " 'bias': 0.0,\n",
       " 'biastype': 'none',\n",
       " 'os': 2,\n",
       " 'attack': 'mia1'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0dd1c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"german_age\"#args[\"data\"]\n",
    "BASELINE = \"dt\" #args[\"classifier\"]\n",
    "MITIGATOR = args[\"mitigator\"]\n",
    "BIAS = float(args[\"bias\"])\n",
    "BIAS_TYPE = args[\"biastype\"]\n",
    "OS_MODE = int(args[\"os\"])\n",
    "ATTACK = \"mia1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b16266c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# global constants\n",
    "if BASELINE == 'svm' or BASELINE == 'nn':\n",
    "    SCALER = False \n",
    "else:\n",
    "    SCALER = False \n",
    "DISPLAY = False \n",
    "THRESH_ARR = 0.5\n",
    "\n",
    "# loop ten times \n",
    "N = 20\n",
    "\n",
    "# percentage of favor and unfavor\n",
    "priv_metric_orig = defaultdict(float)\n",
    "favor_metric_orig = defaultdict(float)\n",
    "favor_metric_transf = defaultdict(float)\n",
    "\n",
    "# for each pre-processing approach, we create a mia_metric_results\n",
    "orig_metrics = defaultdict(list)\n",
    "orig_mia_metrics = defaultdict(list)\n",
    "\n",
    "transf_metrics = defaultdict(list) \n",
    "transf_mia_metrics = defaultdict(list) \n",
    "\n",
    "reweigh_metrics = defaultdict(list) \n",
    "reweigh_mia_metrics = defaultdict(list) \n",
    "\n",
    "dir_metrics = defaultdict(list) \n",
    "dir_mia_metrics = defaultdict(list) \n",
    "\n",
    "eg_metrics = defaultdict(list) \n",
    "eg_mia_metrics = defaultdict(list) \n",
    "\n",
    "\n",
    "pr_orig_metrics = defaultdict(list) \n",
    "cpp_metrics = defaultdict(list) \n",
    "ro_metrics = defaultdict(list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "42c45e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mia1'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATTACK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a48a7",
   "metadata": {},
   "source": [
    "## Loading & Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da867c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and set the groups\n",
    "dataset_builder =  DatasetBuilder(DATASET)\n",
    "dataset_orig = dataset_builder.load_data()\n",
    "sens_attr = dataset_orig.protected_attribute_names[0]\n",
    "unprivileged_groups = dataset_builder.unprivileged_groups\n",
    "privileged_groups = dataset_builder.privileged_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9aabd2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 57)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb84777c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'age': 1}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "privileged_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a78a2150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'age'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5fedd14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# favorable and unfavorable labels and feature_names\n",
    "f_label = dataset_orig.favorable_label\n",
    "uf_label = dataset_orig.unfavorable_label\n",
    "feature_names = dataset_orig.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1fb1ad08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.500e+01 2.631e+03 3.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.800e+01 4.297e+03 4.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [1.200e+01 2.073e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " ...\n",
      " [1.200e+01 1.037e+03 3.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [9.000e+00 2.301e+03 2.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.800e+01 2.864e+03 2.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]]\n",
      "no bias type specified\n"
     ]
    }
   ],
   "source": [
    "if ATTACK == \"mia1\":\n",
    "    # training data split ratio\n",
    "    p = 0.5\n",
    "    # split dataset into train, validation, and test\n",
    "    dataset_orig_train, dataset_orig_test = dataset_orig.split([p], shuffle=True)\n",
    "    dataset_orig_val = dataset_orig_test\n",
    "    print(dataset_orig_train.features)\n",
    "\n",
    "    # introduce label or selection biases, assuming the original data is fair\n",
    "    if BIAS_TYPE == 'label':\n",
    "        dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    elif BIAS_TYPE == 'selection':\n",
    "        dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    else:\n",
    "        print('no bias type specified')\n",
    "        \n",
    "    dataset_orig_train\n",
    "    dataset_orig_train?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cfd5f8",
   "metadata": {},
   "source": [
    "## Run Mitigating Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3ae7f8",
   "metadata": {},
   "source": [
    "### Setup for MIA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ad51a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "14350dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ATTACK == \"mia2\":\n",
    "    # prepare data format\n",
    "    X = dataset_orig.features\n",
    "    y_true = dataset_orig.labels.ravel()\n",
    "    sens_attr = dataset_orig.protected_attribute_names[0]\n",
    "    sens_attr_index = dataset_orig.feature_names.index(sens_attr)\n",
    "    sensitive_features = dataset_orig.features[:, sens_attr_index]\n",
    "\n",
    "    X_other_features = np.delete(X, sens_attr_index, axis=1)\n",
    "    X_other_features_normalized = preprocessing.normalize(X_other_features, norm='l2')\n",
    "\n",
    "    # Reconstruct X by combining the sensitive attribute and the normalized features\n",
    "    # Insert the sensitive attribute back into its original position\n",
    "    X_normalized = np.insert(X_other_features_normalized, sens_attr_index, sensitive_features, axis=1)\n",
    "    X = X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "89c1ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_indices_reference():\n",
    "    # Determine split sizes proportionally (to sum up to the full dataset size)\n",
    "    num_train_points = int(X.shape[0] * 0.12)\n",
    "    num_test_points = int(X.shape[0] * 0.12)\n",
    "    num_population_points = int(X.shape[0] * 0.3)  # Reduced from 30000\n",
    "\n",
    "    # Start with all indices\n",
    "    all_indices = np.arange(X.shape[0])\n",
    "\n",
    "    # Select train indices without replacement\n",
    "    train_index = np.random.choice(all_indices, num_train_points, replace=False)\n",
    "    # Remove train indices from available indices\n",
    "    remaining_indices = np.setdiff1d(all_indices, train_index)\n",
    "\n",
    "    # Select test indices from the remaining indices without replacement\n",
    "    test_index = np.random.choice(remaining_indices, num_test_points, replace=False)\n",
    "    # Remove test indices from available indices\n",
    "    remaining_indices = np.setdiff1d(remaining_indices, test_index)\n",
    "\n",
    "    # Select population indices from the remaining indices (can also choose all remaining points)\n",
    "    population_index = np.random.choice(remaining_indices, min(num_population_points, len(remaining_indices)), replace=False)\n",
    "\n",
    "    # Summary of counts\n",
    "    print(\"==============================================================\")\n",
    "    print(\"GET UNIQUE INDICES REFERENCE\")\n",
    "    print(f\"Number of train points: {len(train_index)}\")\n",
    "    print(f\"Number of test points: {len(test_index)}\")\n",
    "    print(f\"Number of population points: {len(population_index)}\")\n",
    "    print(\"==============================================================\")\n",
    "    \n",
    "    return train_index, test_index, population_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "414d335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(train_index, test_index, population_index, g_train, g_test, g_pop_train):\n",
    "    # create the target model's dataset\n",
    "    train_ds = {'x': X[train_index], 'y': y_true[train_index],'g':g_train}\n",
    "    test_ds = {'x': X[test_index], 'y': y_true[test_index], 'g':g_test}\n",
    "    target_dataset = Dataset(\n",
    "        data_dict={'train': train_ds, 'test': test_ds},\n",
    "        default_input='x', default_output='y', default_group='g'\n",
    "    )\n",
    "\n",
    "    # create the reference dataset\n",
    "    population_ds = {'x': X[population_index], 'y': y_true[population_index], 'g': g_pop_train}\n",
    "    reference_dataset = Dataset(\n",
    "        data_dict={'train': population_ds},\n",
    "        default_input='x', default_output='y', default_group='g'\n",
    "    )\n",
    "    \n",
    "    return target_dataset, reference_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e23be8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features, labels, and protected attributes into a DataFrame\n",
    "def create_binary_label_dataset(dataset_orig, X, y, sensitive_features, sens_attr_name, privileged_value, unprivileged_value):\n",
    "    print(\"=====================================================\")\n",
    "    print(\"CREATE BINARY LABEL DATASET\")\n",
    "    # Extract the feature names from the original dataset\n",
    "    feature_names = dataset_orig.feature_names\n",
    "\n",
    "    # Create a DataFrame with features, labels, and sensitive attribute\n",
    "    df = pd.DataFrame(X, columns=feature_names)\n",
    "    df[dataset_orig.label_names[0]] = y\n",
    "#     df[sens_attr_name] = sensitive_features\n",
    "\n",
    "    print(df.head())\n",
    "    # print(dataset_orig.feature_names)\n",
    "    # print(dataset_orig.features.shape)\n",
    "    \n",
    "    # df_orig, _ = dataset_orig.convert_to_dataframe()\n",
    "\n",
    "    # # Display the first few rows\n",
    "    # print(\"Original df's head:\", df_orig.head())\n",
    "    \n",
    "    # Get the unique labels and their counts\n",
    "    # unique_labels, counts = np.unique(dataset_orig.labels, return_counts=True)\n",
    "\n",
    "    # # Print the value counts\n",
    "    # for label, count in zip(unique_labels, counts):\n",
    "    #     print(f\"Label {label}: {count} instances\")\n",
    "\n",
    "    # Create the BinaryLabelDataset\n",
    "    dataset = BinaryLabelDataset(\n",
    "        favorable_label=1.0,  # Adjust as per your dataset\n",
    "        unfavorable_label=0.0,  # Adjust as per your dataset\n",
    "        df=df,  # DataFrame containing features, labels, and protected attribute\n",
    "        label_names=dataset_orig.label_names,  # Column name of labels in DataFrame\n",
    "        protected_attribute_names=[sens_attr_name],  # Protected attribute column\n",
    "        privileged_protected_attributes=[privileged_value],  # Privileged group values\n",
    "        unprivileged_protected_attributes=[unprivileged_value]  # Unprivileged group values\n",
    "    )\n",
    "    \n",
    "    # print(dataset.feature_names)\n",
    "    # print(dataset.features.shape)\n",
    "    # # Get the unique labels and their counts\n",
    "    # unique_labels, counts = np.unique(dataset.labels, return_counts=True)\n",
    "\n",
    "    # Print the value counts\n",
    "    # for label, count in zip(unique_labels, counts):\n",
    "    #     print(f\"Label {label}: {count} instances\")\n",
    "    \n",
    "    print(\"=====================================================\")\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "22a3f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_logs():\n",
    "    # Search for directories ending with _group or _pop\n",
    "    for pattern in [\"*_group\", \"*_pop\"]:\n",
    "        # Find matching directories\n",
    "        for log_dir in glob.glob(pattern):\n",
    "            if os.path.exists(log_dir) and os.path.isdir(log_dir):  # Ensure it's a directory\n",
    "                shutil.rmtree(log_dir)\n",
    "                print(f\"{log_dir} deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31097df4",
   "metadata": {},
   "source": [
    "### Calling Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3b3d0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = None\n",
    "reference_dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eea401f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Train dataset's features are as below:\n",
      "[[1.200e+01 2.279e+03 4.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [1.200e+01 3.565e+03 2.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.200e+01 1.282e+03 2.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " ...\n",
      " [3.600e+01 2.273e+03 3.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.500e+01 1.512e+03 3.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.000e+01 1.275e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  412.0 88.0\n",
      "base_pos unpriv:  0.5681818181818182\n",
      "base_pos priv:  0.7087378640776699\n",
      "number of favorable labels:  342\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.140556\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 38\n",
      "Number of test samples (ntest): 42\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 120\n",
      "Number of test samples (ntest): 100\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 292\n",
      "Number of test samples (ntest): 298\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.92       158\n",
      "         1.0       0.97      0.96      0.96       342\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.94      0.95      0.94       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "Train accuracy:  0.95\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.5\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.46262352194811296\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 158, Test = 142\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.2809338454620642\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 342, Test = 358\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.13353139262452263\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 38, Test = 42\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.1941560144409575\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.71\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.42\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.13353139262452263\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 120, Test = 100\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.48\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.2809338454620642\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 292, Test = 298\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.9932517730102834\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 542\n",
      "after transf priv:  0.7087378640776699\n",
      "after transf unpriv:  0.7076923076923077\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.001046\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 38\n",
      "Number of test samples (ntest): 42\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 120\n",
      "Number of test samples (ntest): 100\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 292\n",
      "Number of test samples (ntest): 298\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.94      0.93       158\n",
      "         1.0       0.98      0.97      0.97       384\n",
      "\n",
      "    accuracy                           0.96       542\n",
      "   macro avg       0.95      0.95      0.95       542\n",
      "weighted avg       0.96      0.96      0.96       542\n",
      "\n",
      "Train accuracy:  0.959409594095941\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.5\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -1.5040773967762742\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 158, Test = 142\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.49\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.5040773967762742\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 342, Test = 358\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.0296194171811581\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 38, Test = 42\n",
      "  AUC: 0.71\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.47\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.4700036292457356\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 120, Test = 100\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.52\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.5040773967762742\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 292, Test = 298\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.6094379124341003\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 38\n",
      "Number of test samples (ntest): 42\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 120\n",
      "Number of test samples (ntest): 100\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 292\n",
      "Number of test samples (ntest): 298\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.98      0.93       158\n",
      "         1.0       0.99      0.94      0.97       342\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.94      0.96      0.95       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "Train accuracy:  0.956\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.31\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.31\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.3677247801253174\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 158, Test = 142\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.49\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 342, Test = 358\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.2876820724517809\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 38, Test = 42\n",
      "  AUC: 0.71\n",
      "  Privacy Risk: 0.70\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.40\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.49\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 120, Test = 100\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.52\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 292, Test = 298\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.2876820724517809\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 38\n",
      "Number of test samples (ntest): 42\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 120\n",
      "Number of test samples (ntest): 100\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 292\n",
      "Number of test samples (ntest): 298\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.94      0.93       158\n",
      "         1.0       0.97      0.96      0.97       342\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.95      0.95      0.95       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "Train accuracy:  0.956\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.36000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -1.2720087640573128\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 158, Test = 142\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.52\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.2720087640573128\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 342, Test = 358\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.4460219602688147\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 38, Test = 42\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.2720087640573128\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.70\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.38\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.1983643928655158\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 120, Test = 100\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.54\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -1.7151927873684871\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 292, Test = 298\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.2921712927358004\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 38\n",
      "Number of test samples (ntest): 42\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 120\n",
      "Number of test samples (ntest): 100\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 292\n",
      "Number of test samples (ntest): 298\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.61      0.68       158\n",
      "         1.0       0.84      0.91      0.87       342\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.79      0.76      0.77       500\n",
      "weighted avg       0.81      0.81      0.81       500\n",
      "\n",
      "Train accuracy:  0.814\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.15000000000000002\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 158, Test = 142\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.79\n",
      "  Optimal thershold: -0.1622453903624342\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 342, Test = 358\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 38, Test = 42\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.68\n",
      "  Accuracy: 0.68\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.64\n",
      "  Attacker advantage: 0.35\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.1622453903624342\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.0033741362311410176\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 120, Test = 100\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.38\n",
      "  Test Accuracy (TNR): 0.88\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.79\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 292, Test = 298\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "un_log_group deleted.\n",
      "un_log_pop deleted.\n",
      "#### Train dataset's features are as below:\n",
      "[[2.400e+01 3.430e+03 3.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [1.200e+01 1.680e+03 3.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [2.100e+01 3.976e+03 2.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " ...\n",
      " [1.800e+01 2.389e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.200e+01 3.331e+03 2.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [2.100e+01 1.602e+03 4.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  403.0 97.0\n",
      "base_pos unpriv:  0.5979381443298969\n",
      "base_pos priv:  0.7196029776674938\n",
      "number of favorable labels:  348\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.121665\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 39\n",
      "Number of test samples (ntest): 41\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 113\n",
      "Number of test samples (ntest): 107\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 290\n",
      "Number of test samples (ntest): 300\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.91      0.95       152\n",
      "         1.0       0.96      1.00      0.98       348\n",
      "\n",
      "    accuracy                           0.97       500\n",
      "   macro avg       0.98      0.96      0.97       500\n",
      "weighted avg       0.97      0.97      0.97       500\n",
      "\n",
      "Train accuracy:  0.972\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.34\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 152, Test = 148\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.53\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.78845736036427\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 348, Test = 352\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 39, Test = 41\n",
      "  AUC: 0.71\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.39\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -0.78845736036427\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 113, Test = 107\n",
      "  AUC: 0.81\n",
      "  Privacy Risk: 0.80\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.59\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -0.8472978603872036\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 290, Test = 300\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 542\n",
      "after transf priv:  0.7196029776674938\n",
      "after transf unpriv:  0.7194244604316546\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000179\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 39\n",
      "Number of test samples (ntest): 41\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 113\n",
      "Number of test samples (ntest): 107\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 290\n",
      "Number of test samples (ntest): 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97       152\n",
      "         1.0       0.99      0.99      0.99       390\n",
      "\n",
      "    accuracy                           0.99       542\n",
      "   macro avg       0.98      0.98      0.98       542\n",
      "weighted avg       0.99      0.99      0.99       542\n",
      "\n",
      "Train accuracy:  0.985239852398524\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.9808292530117262\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 152, Test = 148\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.53\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -0.4700036292457356\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 348, Test = 352\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.9808292530117262\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 39, Test = 41\n",
      "  AUC: 0.70\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.41\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -0.4700036292457356\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.38\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.014815085785140587\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 113, Test = 107\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.58\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.4700036292457356\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 290, Test = 300\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.9808292530117262\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 39\n",
      "Number of test samples (ntest): 41\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 113\n",
      "Number of test samples (ntest): 107\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 290\n",
      "Number of test samples (ntest): 300\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.92      0.95       152\n",
      "         1.0       0.97      0.99      0.98       348\n",
      "\n",
      "    accuracy                           0.97       500\n",
      "   macro avg       0.98      0.96      0.97       500\n",
      "weighted avg       0.97      0.97      0.97       500\n",
      "\n",
      "Train accuracy:  0.972\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.23\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.916290731874155\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 152, Test = 148\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.52\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -0.916290731874155\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 348, Test = 352\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.16\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.5040773967762742\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 39, Test = 41\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.53\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -0.916290731874155\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.24\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -0.05001042057466142\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 113, Test = 107\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.53\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 290, Test = 300\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.5040773967762742\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 39\n",
      "Number of test samples (ntest): 41\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 113\n",
      "Number of test samples (ntest): 107\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 290\n",
      "Number of test samples (ntest): 300\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.95      0.97       152\n",
      "         1.0       0.98      0.99      0.99       348\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.98      0.97      0.98       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "Train accuracy:  0.98\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.27479156949548145\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 152, Test = 148\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.6376901050006152\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 348, Test = 352\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.17128082504897155\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 39, Test = 41\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.31\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.718398000789185\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 113, Test = 107\n",
      "  AUC: 0.80\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.58\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -0.6376901050006152\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 290, Test = 300\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.17128082504897155\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 39\n",
      "Number of test samples (ntest): 41\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 113\n",
      "Number of test samples (ntest): 107\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 290\n",
      "Number of test samples (ntest): 300\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.67      0.70       152\n",
      "         1.0       0.86      0.89      0.87       348\n",
      "\n",
      "    accuracy                           0.82       500\n",
      "   macro avg       0.79      0.78      0.79       500\n",
      "weighted avg       0.82      0.82      0.82       500\n",
      "\n",
      "Train accuracy:  0.822\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.09850267066424878\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 152, Test = 148\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.6959371177103206\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 348, Test = 352\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.09850267066424878\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 39, Test = 41\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.68\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.2026392774977723\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 113, Test = 107\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.6959371177103206\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 290, Test = 300\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.09850267066424878\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.8000e+01 6.4580e+03 2.0000e+00 ... 1.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [1.8000e+01 1.4420e+03 4.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [1.2000e+01 7.6300e+02 4.0000e+00 ... 1.0000e+00 1.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [2.4000e+01 9.4700e+02 4.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [3.6000e+01 1.0477e+04 2.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [9.0000e+00 2.3010e+03 2.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  412.0 88.0\n",
      "base_pos unpriv:  0.6590909090909091\n",
      "base_pos priv:  0.720873786407767\n",
      "number of favorable labels:  355\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.061783\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 30\n",
      "Number of test samples (ntest): 50\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 115\n",
      "Number of test samples (ntest): 105\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 297\n",
      "Number of test samples (ntest): 293\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.90      0.94       145\n",
      "         1.0       0.96      0.99      0.98       355\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.97      0.95      0.96       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "Train accuracy:  0.964\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.4700036292457356\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 145, Test = 155\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.45\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -0.9808292530117262\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 355, Test = 345\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.4700036292457356\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 30, Test = 50\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.35\n",
      "  Positive predictive value: 0.48\n",
      "  Optimal thershold: -2.3353749158170363\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.33\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.10178269430994236\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 115, Test = 105\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.52\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.9808292530117262\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 297, Test = 293\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.4700036292457356\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin, transf:  500 519\n",
      "after transf priv:  0.720873786407767\n",
      "after transf unpriv:  0.719626168224299\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.001248\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 30\n",
      "Number of test samples (ntest): 50\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 115\n",
      "Number of test samples (ntest): 105\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 297\n",
      "Number of test samples (ntest): 293\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.92      0.92       145\n",
      "         1.0       0.97      0.97      0.97       374\n",
      "\n",
      "    accuracy                           0.96       519\n",
      "   macro avg       0.95      0.95      0.95       519\n",
      "weighted avg       0.96      0.96      0.96       519\n",
      "\n",
      "Train accuracy:  0.9576107899807321\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.4700036292457356\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 145, Test = 155\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.48\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.3862943611198906\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 355, Test = 345\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.4700036292457356\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 30, Test = 50\n",
      "  AUC: 0.69\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -2.3353749158170363\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -0.10178269430994236\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 115, Test = 105\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.53\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -1.3862943611198906\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 297, Test = 293\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.4700036292457356\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 30\n",
      "Number of test samples (ntest): 50\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 115\n",
      "Number of test samples (ntest): 105\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 297\n",
      "Number of test samples (ntest): 293\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.88      0.92       145\n",
      "         1.0       0.95      0.99      0.97       355\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.96      0.94      0.95       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "Train accuracy:  0.958\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.34\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.16251892949777494\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 145, Test = 155\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.47\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 355, Test = 345\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.16251892949777494\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 30, Test = 50\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.52\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -1.897119984885881\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.05129329438755058\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 115, Test = 105\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.49\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.2876820724517809\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 297, Test = 293\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.16251892949777494\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 30\n",
      "Number of test samples (ntest): 50\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 115\n",
      "Number of test samples (ntest): 105\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 297\n",
      "Number of test samples (ntest): 293\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.94      0.96       145\n",
      "         1.0       0.98      1.00      0.99       355\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.98      0.97      0.98       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "Train accuracy:  0.98\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.35000000000000003\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -1.0710914166004395\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 145, Test = 155\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.53\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.7596756222680332\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 355, Test = 345\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.21052743789407144\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 30, Test = 50\n",
      "  AUC: 0.80\n",
      "  Privacy Risk: 0.78\n",
      "  Accuracy: 0.78\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.57\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -1.6615569468680786\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.31\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -0.05708933562256621\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 115, Test = 105\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.52\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -0.7596756222680332\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 297, Test = 293\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.21052743789407144\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 30\n",
      "Number of test samples (ntest): 50\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 115\n",
      "Number of test samples (ntest): 105\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 297\n",
      "Number of test samples (ntest): 293\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.64      0.70       145\n",
      "         1.0       0.86      0.92      0.89       355\n",
      "\n",
      "    accuracy                           0.84       500\n",
      "   macro avg       0.81      0.78      0.79       500\n",
      "weighted avg       0.83      0.84      0.83       500\n",
      "\n",
      "Train accuracy:  0.838\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.24000000000000002\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.26586423933461045\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 145, Test = 155\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.0606196447629719\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 355, Test = 345\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.26586423933461045\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 30, Test = 50\n",
      "  AUC: 0.69\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.37\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -1.0606196447629719\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.69\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.33\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.26586423933461045\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 115, Test = 105\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.0606196447629719\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 297, Test = 293\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.11966724182804984\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.8000e+01 3.2130e+03 1.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [3.9000e+01 1.4179e+04 4.0000e+00 ... 1.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [4.2000e+01 7.1660e+03 2.0000e+00 ... 1.0000e+00 1.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [4.8000e+01 7.5820e+03 2.0000e+00 ... 1.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [2.0000e+01 2.2350e+03 4.0000e+00 ... 0.0000e+00 0.0000e+00 1.0000e+00]\n",
      " [3.6000e+01 4.4730e+03 4.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  411.0 89.0\n",
      "base_pos unpriv:  0.651685393258427\n",
      "base_pos priv:  0.754257907542579\n",
      "number of favorable labels:  368\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.102573\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 31\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 101\n",
      "Number of test samples (ntest): 119\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 310\n",
      "Number of test samples (ntest): 280\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.92      0.92       132\n",
      "         1.0       0.97      0.97      0.97       368\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.95      0.94      0.95       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "Train accuracy:  0.958\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.4\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.4418327522790392\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 132, Test = 168\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -1.0296194171811583\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 368, Test = 332\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.4418327522790392\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 31, Test = 49\n",
      "  AUC: 0.69\n",
      "  Privacy Risk: 0.70\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.40\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 101, Test = 119\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 310, Test = 280\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.4418327522790392\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 537\n",
      "after transf priv:  0.754257907542579\n",
      "after transf unpriv:  0.753968253968254\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000290\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 31\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 101\n",
      "Number of test samples (ntest): 119\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 310\n",
      "Number of test samples (ntest): 280\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.89      0.93       132\n",
      "         1.0       0.97      0.99      0.98       405\n",
      "\n",
      "    accuracy                           0.97       537\n",
      "   macro avg       0.97      0.94      0.95       537\n",
      "weighted avg       0.97      0.97      0.97       537\n",
      "\n",
      "Train accuracy:  0.9664804469273743\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -1.5841201044498103\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 132, Test = 168\n",
      "  AUC: 0.83\n",
      "  Privacy Risk: 0.81\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.62\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.5841201044498103\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 368, Test = 332\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.2231435513142097\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 31, Test = 49\n",
      "  AUC: 0.83\n",
      "  Privacy Risk: 0.85\n",
      "  Accuracy: 0.85\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.69\n",
      "  Attacker advantage: 0.69\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.6094379124341005\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -1.3862943611198906\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 101, Test = 119\n",
      "  AUC: 0.83\n",
      "  Privacy Risk: 0.81\n",
      "  Accuracy: 0.81\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.69\n",
      "  Attacker advantage: 0.62\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -1.3862943611198906\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 310, Test = 280\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.2231435513142097\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 31\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 101\n",
      "Number of test samples (ntest): 119\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 310\n",
      "Number of test samples (ntest): 280\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.89      0.90       132\n",
      "         1.0       0.96      0.97      0.97       368\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.94      0.93      0.94       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "Train accuracy:  0.95\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.4\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -1.0296194171811583\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 132, Test = 168\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.0296194171811583\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 368, Test = 332\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.16\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 31, Test = 49\n",
      "  AUC: 0.70\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -2.3223877202902257\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -1.0986122886681098\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 101, Test = 119\n",
      "  AUC: 0.80\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.55\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.0296194171811583\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 310, Test = 280\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 31\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 101\n",
      "Number of test samples (ntest): 119\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 310\n",
      "Number of test samples (ntest): 280\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94       132\n",
      "         1.0       0.97      0.99      0.98       368\n",
      "\n",
      "    accuracy                           0.97       500\n",
      "   macro avg       0.97      0.95      0.96       500\n",
      "weighted avg       0.97      0.97      0.97       500\n",
      "\n",
      "Train accuracy:  0.968\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.43\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.31\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.26032144468737645\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 132, Test = 168\n",
      "  AUC: 0.80\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.68\n",
      "  Attacker advantage: 0.53\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 368, Test = 332\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.8586021112383669\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 31, Test = 49\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.49\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.69\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.33\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -0.26032144468737645\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 101, Test = 119\n",
      "  AUC: 0.81\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.58\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.4731767654746368\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 310, Test = 280\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.8586021112383669\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 31\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 101\n",
      "Number of test samples (ntest): 119\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 310\n",
      "Number of test samples (ntest): 280\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.61      0.66       132\n",
      "         1.0       0.87      0.91      0.89       368\n",
      "\n",
      "    accuracy                           0.83       500\n",
      "   macro avg       0.79      0.76      0.77       500\n",
      "weighted avg       0.83      0.83      0.83       500\n",
      "\n",
      "Train accuracy:  0.832\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.19\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 132, Test = 168\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -1.6813162989504093\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 368, Test = 332\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 31, Test = 49\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -1.6813162989504093\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.2623084138947284\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 101, Test = 119\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.6813162989504093\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 310, Test = 280\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.8000e+01 3.2130e+03 1.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [3.6000e+01 1.0477e+04 2.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [3.0000e+01 3.0170e+03 4.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [2.0000e+01 2.2120e+03 4.0000e+00 ... 1.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [2.8000e+01 2.7430e+03 4.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [1.2000e+01 1.5740e+03 4.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  405.0 95.0\n",
      "base_pos unpriv:  0.5684210526315789\n",
      "base_pos priv:  0.7432098765432099\n",
      "number of favorable labels:  355\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.174789\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 41\n",
      "Number of test samples (ntest): 39\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 104\n",
      "Number of test samples (ntest): 116\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 301\n",
      "Number of test samples (ntest): 289\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.90      0.90       145\n",
      "         1.0       0.96      0.96      0.96       355\n",
      "\n",
      "    accuracy                           0.94       500\n",
      "   macro avg       0.93      0.93      0.93       500\n",
      "weighted avg       0.94      0.94      0.94       500\n",
      "\n",
      "Train accuracy:  0.944\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.5\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.33024168687057687\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 145, Test = 155\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.2231435513142097\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 355, Test = 345\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.33024168687057687\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 41, Test = 39\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.70\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.64\n",
      "  Attacker advantage: 0.40\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.70\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.45\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 104, Test = 116\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.45\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 301, Test = 289\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.05715841383994864\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 564\n",
      "after transf priv:  0.7432098765432099\n",
      "after transf unpriv:  0.7421383647798742\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.001072\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 41\n",
      "Number of test samples (ntest): 39\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 104\n",
      "Number of test samples (ntest): 116\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 301\n",
      "Number of test samples (ntest): 289\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.94      0.91       145\n",
      "         1.0       0.98      0.96      0.97       419\n",
      "\n",
      "    accuracy                           0.95       564\n",
      "   macro avg       0.93      0.95      0.94       564\n",
      "weighted avg       0.95      0.95      0.95       564\n",
      "\n",
      "Train accuracy:  0.9521276595744681\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.43\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 145, Test = 155\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.69\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 355, Test = 345\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.11778303565638351\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 41, Test = 39\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.64\n",
      "  Attacker advantage: 0.52\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.69\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -1.0986122886681098\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 104, Test = 116\n",
      "  AUC: 0.80\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 301, Test = 289\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.11778303565638351\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 41\n",
      "Number of test samples (ntest): 39\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 104\n",
      "Number of test samples (ntest): 116\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 301\n",
      "Number of test samples (ntest): 289\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.97      0.95       145\n",
      "         1.0       0.99      0.97      0.98       355\n",
      "\n",
      "    accuracy                           0.97       500\n",
      "   macro avg       0.96      0.97      0.96       500\n",
      "weighted avg       0.97      0.97      0.97       500\n",
      "\n",
      "Train accuracy:  0.97\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.5\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 145, Test = 155\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 355, Test = 345\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 41, Test = 39\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.11778303565638351\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.69\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.41\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 104, Test = 116\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 301, Test = 289\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 41\n",
      "Number of test samples (ntest): 39\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 104\n",
      "Number of test samples (ntest): 116\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 301\n",
      "Number of test samples (ntest): 289\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.81      0.88       145\n",
      "         1.0       0.93      0.98      0.95       355\n",
      "\n",
      "    accuracy                           0.93       500\n",
      "   macro avg       0.94      0.90      0.92       500\n",
      "weighted avg       0.93      0.93      0.93       500\n",
      "\n",
      "Train accuracy:  0.934\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.9295172242029005\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 145, Test = 155\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.42\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -0.9295172242029005\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 355, Test = 345\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.6757470937345418\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 41, Test = 39\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.7108553998503345\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.502104162087161\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 104, Test = 116\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.49\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.2634902922987201\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 301, Test = 289\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.6757470937345418\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 41\n",
      "Number of test samples (ntest): 39\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 104\n",
      "Number of test samples (ntest): 116\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 301\n",
      "Number of test samples (ntest): 289\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.63      0.67       145\n",
      "         1.0       0.86      0.90      0.88       355\n",
      "\n",
      "    accuracy                           0.82       500\n",
      "   macro avg       0.79      0.76      0.77       500\n",
      "weighted avg       0.82      0.82      0.82       500\n",
      "\n",
      "Train accuracy:  0.822\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.31\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.3702313970759192\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 145, Test = 155\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.68\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.06578015261781589\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 355, Test = 345\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3702313970759192\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 41, Test = 39\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.1730379758581782\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.4669503623164116\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 104, Test = 116\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.06578015261781589\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 301, Test = 289\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3702313970759192\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[2.400e+01 1.258e+03 3.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [6.000e+00 2.116e+03 2.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [3.600e+01 7.127e+03 2.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " ...\n",
      " [1.200e+01 2.759e+03 2.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.200e+01 3.386e+03 3.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [3.600e+01 1.953e+03 4.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  399.0 101.0\n",
      "base_pos unpriv:  0.5643564356435643\n",
      "base_pos priv:  0.7368421052631579\n",
      "number of favorable labels:  351\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.172486\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 44\n",
      "Number of test samples (ntest): 36\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 105\n",
      "Number of test samples (ntest): 115\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 294\n",
      "Number of test samples (ntest): 296\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.86      0.91       149\n",
      "         1.0       0.94      0.99      0.97       351\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.96      0.93      0.94       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "Train accuracy:  0.952\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.2\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.7672551527136672\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 149, Test = 151\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.42\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.7672551527136672\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 351, Test = 349\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.6241543090729939\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 44, Test = 36\n",
      "  AUC: 0.70\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.39\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -2.197224577336219\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.6241543090729939\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 105, Test = 115\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -0.7672551527136672\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 294, Test = 296\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.6241543090729939\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 566\n",
      "after transf priv:  0.7368421052631579\n",
      "after transf unpriv:  0.7365269461077845\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000315\n",
      "[INFO]: training decision tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 44\n",
      "Number of test samples (ntest): 36\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 105\n",
      "Number of test samples (ntest): 115\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 294\n",
      "Number of test samples (ntest): 296\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.94      0.87       149\n",
      "         1.0       0.98      0.92      0.95       417\n",
      "\n",
      "    accuracy                           0.93       566\n",
      "   macro avg       0.89      0.93      0.91       566\n",
      "weighted avg       0.93      0.93      0.93       566\n",
      "\n",
      "Train accuracy:  0.9257950530035336\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.5\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.5978370007556204\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 149, Test = 151\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.68\n",
      "  Attacker advantage: 0.49\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -0.5978370007556204\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 351, Test = 349\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.7985076962177716\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 44, Test = 36\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -0.587786664902119\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.7985076962177716\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 105, Test = 115\n",
      "  AUC: 0.80\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.70\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -0.5978370007556204\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 294, Test = 296\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.15415067982725836\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 44\n",
      "Number of test samples (ntest): 36\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 105\n",
      "Number of test samples (ntest): 115\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 294\n",
      "Number of test samples (ntest): 296\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.97      0.91       149\n",
      "         1.0       0.99      0.93      0.96       351\n",
      "\n",
      "    accuracy                           0.94       500\n",
      "   macro avg       0.92      0.95      0.93       500\n",
      "weighted avg       0.95      0.94      0.94       500\n",
      "\n",
      "Train accuracy:  0.942\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.5\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.4228568508200336\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 149, Test = 151\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.4228568508200336\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 351, Test = 349\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 44, Test = 36\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.70\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.40\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -0.4228568508200336\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 105, Test = 115\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -0.4228568508200336\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 294, Test = 296\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.8718021769015913\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 44\n",
      "Number of test samples (ntest): 36\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 105\n",
      "Number of test samples (ntest): 115\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 294\n",
      "Number of test samples (ntest): 296\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95       149\n",
      "         1.0       0.98      0.98      0.98       351\n",
      "\n",
      "    accuracy                           0.97       500\n",
      "   macro avg       0.96      0.97      0.96       500\n",
      "weighted avg       0.97      0.97      0.97       500\n",
      "\n",
      "Train accuracy:  0.97\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.35000000000000003\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.31518087068985307\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 149, Test = 151\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.1811986298054955\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 351, Test = 349\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 44, Test = 36\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -1.1811986298054955\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.33\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 105, Test = 115\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.47\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.31518087068985307\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 294, Test = 296\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.24088247272050956\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 44\n",
      "Number of test samples (ntest): 36\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 105\n",
      "Number of test samples (ntest): 115\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 294\n",
      "Number of test samples (ntest): 296\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.64      0.68       149\n",
      "         1.0       0.86      0.90      0.88       351\n",
      "\n",
      "    accuracy                           0.82       500\n",
      "   macro avg       0.79      0.77      0.78       500\n",
      "weighted avg       0.82      0.82      0.82       500\n",
      "\n",
      "Train accuracy:  0.822\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.02\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -4.197718697941521\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 149, Test = 151\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -4.197718697941521\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 351, Test = 349\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.015143917772511513\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 44, Test = 36\n",
      "  AUC: 0.69\n",
      "  Privacy Risk: 0.68\n",
      "  Accuracy: 0.68\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.37\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -4.355923151591486\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.24\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.0022016576457866968\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 105, Test = 115\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.015143917772511513\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 294, Test = 296\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.01291361247010473\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.500e+01 2.186e+03 1.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.200e+01 1.393e+03 4.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [2.400e+01 4.712e+03 4.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " ...\n",
      " [2.400e+01 1.935e+03 4.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [1.300e+01 1.409e+03 2.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [4.800e+01 6.331e+03 4.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  408.0 92.0\n",
      "base_pos unpriv:  0.5869565217391305\n",
      "base_pos priv:  0.7156862745098039\n",
      "number of favorable labels:  346\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.128730\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 38\n",
      "Number of test samples (ntest): 42\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 116\n",
      "Number of test samples (ntest): 104\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 292\n",
      "Number of test samples (ntest): 298\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.98      0.95       154\n",
      "         1.0       0.99      0.96      0.98       346\n",
      "\n",
      "    accuracy                           0.97       500\n",
      "   macro avg       0.96      0.97      0.96       500\n",
      "weighted avg       0.97      0.97      0.97       500\n",
      "\n",
      "Train accuracy:  0.968\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.31\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.3677247801253174\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 154, Test = 146\n",
      "  AUC: 0.82\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.54\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -0.3677247801253174\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 346, Test = 354\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.2876820724517809\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 38, Test = 42\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.55\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -0.3677247801253174\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.2876820724517809\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 116, Test = 104\n",
      "  AUC: 0.83\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.53\n",
      "  Positive predictive value: 0.80\n",
      "  Optimal thershold: -0.3677247801253174\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 292, Test = 298\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.1823215567939546\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 541\n",
      "after transf priv:  0.7156862745098039\n",
      "after transf unpriv:  0.7142857142857143\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.001401\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 38\n",
      "Number of test samples (ntest): 42\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 116\n",
      "Number of test samples (ntest): 104\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 292\n",
      "Number of test samples (ntest): 298\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.90      0.92       154\n",
      "         1.0       0.96      0.98      0.97       387\n",
      "\n",
      "    accuracy                           0.96       541\n",
      "   macro avg       0.96      0.94      0.95       541\n",
      "weighted avg       0.96      0.96      0.96       541\n",
      "\n",
      "Train accuracy:  0.9574861367837338\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.45198512374305727\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 154, Test = 146\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 346, Test = 354\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.45198512374305727\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 38, Test = 42\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.38\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.5978370007556204\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 116, Test = 104\n",
      "  AUC: 0.80\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.70\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -0.2876820724517809\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 292, Test = 298\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.45198512374305727\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 38\n",
      "Number of test samples (ntest): 42\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 116\n",
      "Number of test samples (ntest): 104\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 292\n",
      "Number of test samples (ntest): 298\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.97      0.93       154\n",
      "         1.0       0.99      0.94      0.96       346\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.94      0.96      0.95       500\n",
      "weighted avg       0.96      0.95      0.95       500\n",
      "\n",
      "Train accuracy:  0.952\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.46\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.6007738604289302\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 154, Test = 146\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.47\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.6007738604289302\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 346, Test = 354\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.2876820724517809\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 38, Test = 42\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.11778303565638351\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 116, Test = 104\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -0.6007738604289302\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 292, Test = 298\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.2876820724517809\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 38\n",
      "Number of test samples (ntest): 42\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 116\n",
      "Number of test samples (ntest): 104\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 292\n",
      "Number of test samples (ntest): 298\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.97      0.93       154\n",
      "         1.0       0.99      0.95      0.97       346\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.94      0.96      0.95       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "Train accuracy:  0.958\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.41000000000000003\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.69\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -0.14680051205662248\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 154, Test = 146\n",
      "  AUC: 0.80\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.69\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 346, Test = 354\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.9054332797528872\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 38, Test = 42\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.42\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.2648297962007309\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -0.9054332797528872\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 116, Test = 104\n",
      "  AUC: 0.81\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.72\n",
      "  Attacker advantage: 0.54\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 292, Test = 298\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 38\n",
      "Number of test samples (ntest): 42\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 116\n",
      "Number of test samples (ntest): 104\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 292\n",
      "Number of test samples (ntest): 298\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.68      0.72       154\n",
      "         1.0       0.87      0.91      0.89       346\n",
      "\n",
      "    accuracy                           0.84       500\n",
      "   macro avg       0.82      0.79      0.80       500\n",
      "weighted avg       0.83      0.84      0.84       500\n",
      "\n",
      "Train accuracy:  0.838\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.5\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.43002395428017265\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 154, Test = 146\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.33\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.6825194133155285\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 346, Test = 354\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.16940817502275188\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 38, Test = 42\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.7038891116336677\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 116, Test = 104\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.31\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.6825194133155285\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 292, Test = 298\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.43002395428017265\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[8.000e+00 3.398e+03 1.000e+00 ... 0.000e+00 0.000e+00 1.000e+00]\n",
      " [1.200e+01 1.291e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.800e+01 1.149e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " ...\n",
      " [2.400e+01 1.823e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [4.800e+01 5.096e+03 2.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [2.400e+01 6.579e+03 4.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  406.0 94.0\n",
      "base_pos unpriv:  0.6063829787234043\n",
      "base_pos priv:  0.7019704433497537\n",
      "number of favorable labels:  342\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.095587\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 121\n",
      "Number of test samples (ntest): 99\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 285\n",
      "Number of test samples (ntest): 305\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96       158\n",
      "         1.0       0.99      0.97      0.98       342\n",
      "\n",
      "    accuracy                           0.97       500\n",
      "   macro avg       0.96      0.98      0.97       500\n",
      "weighted avg       0.98      0.97      0.97       500\n",
      "\n",
      "Train accuracy:  0.974\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.2\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 158, Test = 142\n",
      "  AUC: 0.81\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.52\n",
      "  Positive predictive value: 0.79\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 342, Test = 358\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.81\n",
      "  Privacy Risk: 0.78\n",
      "  Accuracy: 0.78\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.56\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.916290731874155\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 121, Test = 99\n",
      "  AUC: 0.81\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.52\n",
      "  Positive predictive value: 0.82\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 285, Test = 305\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 530\n",
      "after transf priv:  0.7019704433497537\n",
      "after transf unpriv:  0.7016129032258065\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000358\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 121\n",
      "Number of test samples (ntest): 99\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 285\n",
      "Number of test samples (ntest): 305\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98       158\n",
      "         1.0       0.99      0.99      0.99       372\n",
      "\n",
      "    accuracy                           0.99       530\n",
      "   macro avg       0.99      0.99      0.99       530\n",
      "weighted avg       0.99      0.99      0.99       530\n",
      "\n",
      "Train accuracy:  0.9886792452830189\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.17\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -1.252762968495368\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 158, Test = 142\n",
      "  AUC: 0.71\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 342, Test = 358\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.24\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -1.252762968495368\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.78\n",
      "  Accuracy: 0.78\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.56\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.6094379124341005\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.69\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.38\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.2231435513142097\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 121, Test = 99\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.39\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 285, Test = 305\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.252762968495368\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 121\n",
      "Number of test samples (ntest): 99\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 285\n",
      "Number of test samples (ntest): 305\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.96       158\n",
      "         1.0       0.99      0.97      0.98       342\n",
      "\n",
      "    accuracy                           0.97       500\n",
      "   macro avg       0.97      0.97      0.97       500\n",
      "weighted avg       0.97      0.97      0.97       500\n",
      "\n",
      "Train accuracy:  0.974\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.34\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 158, Test = 142\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.78\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.55\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 342, Test = 358\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.80\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.58\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.916290731874155\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 121, Test = 99\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.78\n",
      "  Accuracy: 0.78\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.55\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 285, Test = 305\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 121\n",
      "Number of test samples (ntest): 99\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 285\n",
      "Number of test samples (ntest): 305\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96       158\n",
      "         1.0       0.99      0.98      0.98       342\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.97      0.98      0.97       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "Train accuracy:  0.976\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.2\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.31\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.7362805513775209\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 158, Test = 142\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.78\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.55\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -0.6517976207412497\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 342, Test = 358\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.7362805513775209\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.86\n",
      "  Privacy Risk: 0.84\n",
      "  Accuracy: 0.84\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.70\n",
      "  Attacker advantage: 0.67\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -1.0057206138862027\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.38\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.4553608841768891\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 121, Test = 99\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.6517976207412497\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 285, Test = 305\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 121\n",
      "Number of test samples (ntest): 99\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 285\n",
      "Number of test samples (ntest): 305\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.60      0.68       158\n",
      "         1.0       0.83      0.92      0.88       342\n",
      "\n",
      "    accuracy                           0.82       500\n",
      "   macro avg       0.81      0.76      0.78       500\n",
      "weighted avg       0.82      0.82      0.81       500\n",
      "\n",
      "Train accuracy:  0.82\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.04\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.06022125839528351\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 158, Test = 142\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -2.3749451747462977\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 342, Test = 358\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.06022125839528351\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -2.839689384945491\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -2.374945174746298\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 121, Test = 99\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.50\n",
      "  Test Accuracy (TNR): 0.81\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 285, Test = 305\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.03518765996407079\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.500e+01 3.920e+02 4.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [3.000e+01 7.596e+03 1.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [9.000e+00 1.478e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " ...\n",
      " [4.800e+01 6.110e+03 1.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [9.000e+00 1.449e+03 3.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [2.100e+01 3.763e+03 2.000e+00 ... 0.000e+00 0.000e+00 1.000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  396.0 104.0\n",
      "base_pos unpriv:  0.5673076923076923\n",
      "base_pos priv:  0.6691919191919192\n",
      "number of favorable labels:  324\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.101884\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 45\n",
      "Number of test samples (ntest): 35\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 59\n",
      "Number of test samples (ntest): 51\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 131\n",
      "Number of test samples (ntest): 89\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 265\n",
      "Number of test samples (ntest): 325\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97       176\n",
      "         1.0       0.98      0.99      0.98       324\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.98      0.97      0.98       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "Train accuracy:  0.978\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.4\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.69\n",
      "  Privacy Risk: 0.68\n",
      "  Accuracy: 0.68\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.35\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 176, Test = 124\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 324, Test = 376\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.33\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 45, Test = 35\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 59, Test = 51\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.42\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 131, Test = 89\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -0.9808292530117262\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 265, Test = 325\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.31\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 532\n",
      "after transf priv:  0.6691919191919192\n",
      "after transf unpriv:  0.6691176470588235\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000074\n",
      "[INFO]: training decision tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 45\n",
      "Number of test samples (ntest): 35\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 59\n",
      "Number of test samples (ntest): 51\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 131\n",
      "Number of test samples (ntest): 89\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 265\n",
      "Number of test samples (ntest): 325\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.94       176\n",
      "         1.0       0.96      0.98      0.97       356\n",
      "\n",
      "    accuracy                           0.96       532\n",
      "   macro avg       0.96      0.95      0.95       532\n",
      "weighted avg       0.96      0.96      0.96       532\n",
      "\n",
      "Train accuracy:  0.9605263157894737\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 176, Test = 124\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.42\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 324, Test = 376\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 45, Test = 35\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.33\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 59, Test = 51\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.38\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.1823215567939546\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 131, Test = 89\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 265, Test = 325\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.6061358035703156\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 45\n",
      "Number of test samples (ntest): 35\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 59\n",
      "Number of test samples (ntest): 51\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 131\n",
      "Number of test samples (ntest): 89\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 265\n",
      "Number of test samples (ntest): 325\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96       176\n",
      "         1.0       1.00      0.96      0.98       324\n",
      "\n",
      "    accuracy                           0.97       500\n",
      "   macro avg       0.96      0.98      0.97       500\n",
      "weighted avg       0.97      0.97      0.97       500\n",
      "\n",
      "Train accuracy:  0.972\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.15000000000000002\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.31\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 176, Test = 124\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.41\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 324, Test = 376\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 45, Test = 35\n",
      "  AUC: 0.71\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 59, Test = 51\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 131, Test = 89\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.70\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.40\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 265, Test = 325\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 45\n",
      "Number of test samples (ntest): 35\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 59\n",
      "Number of test samples (ntest): 51\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 131\n",
      "Number of test samples (ntest): 89\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 265\n",
      "Number of test samples (ntest): 325\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.96      0.94       176\n",
      "         1.0       0.98      0.96      0.97       324\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.95      0.96      0.96       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "Train accuracy:  0.96\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.23\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.33\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.5657725245455365\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 176, Test = 124\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.78\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.48\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.8227396722488642\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 324, Test = 376\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.5377840604912846\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 45, Test = 35\n",
      "  AUC: 0.71\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.8227396722488642\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 59, Test = 51\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -0.5377840604912846\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 131, Test = 89\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.49\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -1.3917281370130705\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 265, Test = 325\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.28587735538832243\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 45\n",
      "Number of test samples (ntest): 35\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 59\n",
      "Number of test samples (ntest): 51\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 131\n",
      "Number of test samples (ntest): 89\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 265\n",
      "Number of test samples (ntest): 325\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.66      0.71       176\n",
      "         1.0       0.83      0.89      0.86       324\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.80      0.78      0.79       500\n",
      "weighted avg       0.81      0.81      0.81       500\n",
      "\n",
      "Train accuracy:  0.812\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.42000000000000004\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.0336720690061558\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 176, Test = 124\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.68\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -0.0336720690061558\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 324, Test = 376\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 45, Test = 35\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.35\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -3.407875391092626\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 59, Test = 51\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 131, Test = 89\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -0.0336720690061558\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 265, Test = 325\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.033672069006155686\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.200e+01 1.262e+03 3.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [2.400e+01 6.314e+03 4.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [4.800e+01 3.051e+03 3.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " ...\n",
      " [6.000e+00 1.449e+03 1.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.500e+01 9.500e+02 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [9.000e+00 1.364e+03 3.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  406.0 94.0\n",
      "base_pos unpriv:  0.6063829787234043\n",
      "base_pos priv:  0.7167487684729064\n",
      "number of favorable labels:  348\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.110366\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 115\n",
      "Number of test samples (ntest): 105\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 291\n",
      "Number of test samples (ntest): 299\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.77      0.86       152\n",
      "         1.0       0.91      0.99      0.95       348\n",
      "\n",
      "    accuracy                           0.92       500\n",
      "   macro avg       0.94      0.88      0.90       500\n",
      "weighted avg       0.93      0.92      0.92       500\n",
      "\n",
      "Train accuracy:  0.924\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.17\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.24\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.08701137698962981\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 152, Test = 148\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.70\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.39\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.7777045685880084\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 348, Test = 352\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.08701137698962981\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.70\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.41\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -0.7777045685880084\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.661398482245365\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 115, Test = 105\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.38\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.7777045685880084\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 291, Test = 299\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.08701137698962981\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 536\n",
      "after transf priv:  0.7167487684729064\n",
      "after transf unpriv:  0.7153846153846154\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.001364\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 115\n",
      "Number of test samples (ntest): 105\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 291\n",
      "Number of test samples (ntest): 299\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.80      0.87       152\n",
      "         1.0       0.92      0.99      0.96       384\n",
      "\n",
      "    accuracy                           0.93       536\n",
      "   macro avg       0.95      0.89      0.91       536\n",
      "weighted avg       0.94      0.93      0.93       536\n",
      "\n",
      "Train accuracy:  0.9347014925373134\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.17\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.8472978603872036\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 152, Test = 148\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.42\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.8472978603872036\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 348, Test = 352\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.5596157879354228\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.70\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.40\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -0.8472978603872036\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.5596157879354228\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 115, Test = 105\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.5804503755608479\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 291, Test = 299\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 115\n",
      "Number of test samples (ntest): 105\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 291\n",
      "Number of test samples (ntest): 299\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.86      0.88       152\n",
      "         1.0       0.94      0.96      0.95       348\n",
      "\n",
      "    accuracy                           0.93       500\n",
      "   macro avg       0.92      0.91      0.92       500\n",
      "weighted avg       0.93      0.93      0.93       500\n",
      "\n",
      "Train accuracy:  0.93\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.7985076962177717\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 152, Test = 148\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.47\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.7985076962177717\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 348, Test = 352\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.5978370007556204\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.2411620568168881\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 115, Test = 105\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -0.7985076962177717\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 291, Test = 299\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.5978370007556204\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 115\n",
      "Number of test samples (ntest): 105\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 291\n",
      "Number of test samples (ntest): 299\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.95      0.91       152\n",
      "         1.0       0.98      0.95      0.96       348\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.93      0.95      0.94       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "Train accuracy:  0.946\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.5\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -1.4547349404601613\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 152, Test = 148\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.48\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.4547349404601613\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 348, Test = 352\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.6964542448902913\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -1.4547349404601613\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -1.4991899537399884\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 115, Test = 105\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.4547349404601613\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 291, Test = 299\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.02533112529283428\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 115\n",
      "Number of test samples (ntest): 105\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 291\n",
      "Number of test samples (ntest): 299\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.63      0.69       152\n",
      "         1.0       0.85      0.92      0.88       348\n",
      "\n",
      "    accuracy                           0.83       500\n",
      "   macro avg       0.81      0.77      0.79       500\n",
      "weighted avg       0.83      0.83      0.82       500\n",
      "\n",
      "Train accuracy:  0.83\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.36000000000000004\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.8109702458767803\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 152, Test = 148\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -1.6061300971101828\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 348, Test = 352\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -1.6061300971101828\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -1.6061300971101826\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 115, Test = 105\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -1.6061300971101828\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 291, Test = 299\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.200e+01 9.000e+02 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [5.400e+01 9.436e+03 2.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [2.400e+01 3.617e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " ...\n",
      " [2.400e+01 7.170e+02 4.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [2.400e+01 1.597e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [2.400e+01 1.442e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  396.0 104.0\n",
      "base_pos unpriv:  0.5961538461538461\n",
      "base_pos priv:  0.7272727272727273\n",
      "number of favorable labels:  350\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.131119\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 42\n",
      "Number of test samples (ntest): 38\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 62\n",
      "Number of test samples (ntest): 48\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 108\n",
      "Number of test samples (ntest): 112\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 288\n",
      "Number of test samples (ntest): 302\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.87      0.87       150\n",
      "         1.0       0.94      0.95      0.95       350\n",
      "\n",
      "    accuracy                           0.92       500\n",
      "   macro avg       0.91      0.91      0.91       500\n",
      "weighted avg       0.92      0.92      0.92       500\n",
      "\n",
      "Train accuracy:  0.924\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.44\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 150, Test = 150\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.68\n",
      "  Accuracy: 0.68\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.36\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.2876820724517809\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 350, Test = 350\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 42, Test = 38\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.42\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -1.276293465905562\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 62, Test = 48\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -1.8718021769015913\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 108, Test = 112\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.68\n",
      "  Accuracy: 0.68\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.36\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.2876820724517809\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 288, Test = 302\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 550\n",
      "after transf priv:  0.7272727272727273\n",
      "after transf unpriv:  0.7272727272727273\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n",
      "[INFO]: training decision tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 42\n",
      "Number of test samples (ntest): 38\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 62\n",
      "Number of test samples (ntest): 48\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 108\n",
      "Number of test samples (ntest): 112\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 288\n",
      "Number of test samples (ntest): 302\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.79      0.87       150\n",
      "         1.0       0.93      0.99      0.96       400\n",
      "\n",
      "    accuracy                           0.94       550\n",
      "   macro avg       0.95      0.89      0.91       550\n",
      "weighted avg       0.94      0.94      0.93       550\n",
      "\n",
      "Train accuracy:  0.9363636363636364\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.19\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.21217451994363576\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 150, Test = 150\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.78845736036427\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 350, Test = 350\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.21217451994363576\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 42, Test = 38\n",
      "  AUC: 0.70\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.45\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.0116009116784799\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 62, Test = 48\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -0.45198512374305727\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 108, Test = 112\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.78845736036427\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 288, Test = 302\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.21217451994363576\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 42\n",
      "Number of test samples (ntest): 38\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 62\n",
      "Number of test samples (ntest): 48\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 108\n",
      "Number of test samples (ntest): 112\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 288\n",
      "Number of test samples (ntest): 302\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.87      0.90       150\n",
      "         1.0       0.94      0.98      0.96       350\n",
      "\n",
      "    accuracy                           0.94       500\n",
      "   macro avg       0.94      0.92      0.93       500\n",
      "weighted avg       0.94      0.94      0.94       500\n",
      "\n",
      "Train accuracy:  0.944\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.34\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.31\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -0.1823215567939546\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 150, Test = 150\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.47\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.8472978603872036\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 350, Test = 350\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.04445176257083381\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 42, Test = 38\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.916290731874155\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 62, Test = 48\n",
      "  AUC: 0.69\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -0.5596157879354228\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 108, Test = 112\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.49\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -0.8472978603872036\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 288, Test = 302\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.04445176257083381\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 42\n",
      "Number of test samples (ntest): 38\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 62\n",
      "Number of test samples (ntest): 48\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 108\n",
      "Number of test samples (ntest): 112\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 288\n",
      "Number of test samples (ntest): 302\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.76      0.86       150\n",
      "         1.0       0.91      1.00      0.95       350\n",
      "\n",
      "    accuracy                           0.93       500\n",
      "   macro avg       0.95      0.88      0.91       500\n",
      "weighted avg       0.93      0.93      0.92       500\n",
      "\n",
      "Train accuracy:  0.926\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.22437366943007994\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 150, Test = 150\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -0.19782574332991992\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 350, Test = 350\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.49020633656325513\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 42, Test = 38\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.39\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.9480394301887352\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 62, Test = 48\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -0.6640360951599487\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 108, Test = 112\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.64\n",
      "  Attacker advantage: 0.48\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.19782574332991992\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 288, Test = 302\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.19798212901024886\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 42\n",
      "Number of test samples (ntest): 38\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 62\n",
      "Number of test samples (ntest): 48\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 108\n",
      "Number of test samples (ntest): 112\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 288\n",
      "Number of test samples (ntest): 302\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.61      0.66       150\n",
      "         1.0       0.84      0.90      0.87       350\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.78      0.75      0.76       500\n",
      "weighted avg       0.81      0.81      0.81       500\n",
      "\n",
      "Train accuracy:  0.812\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.48000000000000004\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 150, Test = 150\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.753046167630533\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 350, Test = 350\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 42, Test = 38\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.6366342177186217\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 62, Test = 48\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.24\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 108, Test = 112\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.41\n",
      "  Test Accuracy (TNR): 0.77\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 288, Test = 302\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[3.600e+01 8.133e+03 1.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.200e+01 2.028e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [2.000e+01 4.272e+03 1.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " ...\n",
      " [2.400e+01 1.940e+03 4.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [4.800e+01 6.758e+03 3.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [9.000e+00 5.129e+03 2.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  407.0 93.0\n",
      "base_pos unpriv:  0.6129032258064516\n",
      "base_pos priv:  0.7346437346437347\n",
      "number of favorable labels:  356\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.121741\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 36\n",
      "Number of test samples (ntest): 44\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 108\n",
      "Number of test samples (ntest): 112\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 299\n",
      "Number of test samples (ntest): 291\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.94       144\n",
      "         1.0       0.96      0.99      0.97       356\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.96      0.95      0.96       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "Train accuracy:  0.964\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.17\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 144, Test = 156\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.45\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -1.6094379124341005\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 356, Test = 344\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.2732933349996813\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 36, Test = 44\n",
      "  AUC: 0.81\n",
      "  Privacy Risk: 0.80\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.60\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -0.2732933349996813\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 108, Test = 112\n",
      "  AUC: 0.70\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.42\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -1.6094379124341005\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 299, Test = 291\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.2732933349996813\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 542\n",
      "after transf priv:  0.7346437346437347\n",
      "after transf unpriv:  0.7333333333333333\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.001310\n",
      "[INFO]: training decision tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 36\n",
      "Number of test samples (ntest): 44\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 108\n",
      "Number of test samples (ntest): 112\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 299\n",
      "Number of test samples (ntest): 291\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.93       144\n",
      "         1.0       0.97      0.98      0.98       398\n",
      "\n",
      "    accuracy                           0.96       542\n",
      "   macro avg       0.96      0.95      0.95       542\n",
      "weighted avg       0.96      0.96      0.96       542\n",
      "\n",
      "Train accuracy:  0.9649446494464945\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.5\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 144, Test = 156\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.406913648322626\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 356, Test = 344\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.2809023854664022\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 36, Test = 44\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.78\n",
      "  Accuracy: 0.78\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.64\n",
      "  Attacker advantage: 0.55\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.31\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.2809023854664022\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 108, Test = 112\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -1.406913648322626\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 299, Test = 291\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.2809023854664022\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 36\n",
      "Number of test samples (ntest): 44\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 108\n",
      "Number of test samples (ntest): 112\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 299\n",
      "Number of test samples (ntest): 291\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94       144\n",
      "         1.0       0.97      0.98      0.98       356\n",
      "\n",
      "    accuracy                           0.97       500\n",
      "   macro avg       0.96      0.96      0.96       500\n",
      "weighted avg       0.97      0.97      0.97       500\n",
      "\n",
      "Train accuracy:  0.966\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -1.3862943611198906\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 144, Test = 156\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -1.3862943611198906\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 356, Test = 344\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.24\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.2876820724517809\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 36, Test = 44\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.7346010553881062\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -0.2231435513142097\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 108, Test = 112\n",
      "  AUC: 0.70\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.41\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -1.3862943611198906\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 299, Test = 291\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -1.252762968495368\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 36\n",
      "Number of test samples (ntest): 44\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 108\n",
      "Number of test samples (ntest): 112\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 299\n",
      "Number of test samples (ntest): 291\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.83      0.90       144\n",
      "         1.0       0.94      0.99      0.96       356\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.96      0.91      0.93       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "Train accuracy:  0.948\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.48000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -1.3026218853957758\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 144, Test = 156\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.5579925276830457\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 356, Test = 344\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.7513454198029333\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 36, Test = 44\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.2824092033641565\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.69\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.35\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 108, Test = 112\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.5579925276830457\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 299, Test = 291\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.7513454198029333\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 36\n",
      "Number of test samples (ntest): 44\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 57\n",
      "Number of test samples (ntest): 53\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 108\n",
      "Number of test samples (ntest): 112\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 299\n",
      "Number of test samples (ntest): 291\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.61      0.65       144\n",
      "         1.0       0.85      0.89      0.87       356\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.77      0.75      0.76       500\n",
      "weighted avg       0.80      0.81      0.81       500\n",
      "\n",
      "Train accuracy:  0.81\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.05\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.05039799062988678\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 144, Test = 156\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.02517811767000512\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 356, Test = 344\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.05039799062988678\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 36, Test = 44\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.82\n",
      "  Optimal thershold: -3.717884538275491\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 57, Test = 53\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 108, Test = 112\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.61\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.02458503872119581\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 299, Test = 291\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.05039799062988678\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[4.800e+01 6.110e+03 1.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [9.000e+00 4.580e+02 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [4.800e+01 6.681e+03 4.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " ...\n",
      " [1.500e+01 1.300e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.200e+01 1.922e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [2.700e+01 2.520e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  412.0 88.0\n",
      "base_pos unpriv:  0.5795454545454546\n",
      "base_pos priv:  0.7402912621359223\n",
      "number of favorable labels:  356\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.160746\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 51\n",
      "Number of test samples (ntest): 59\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 107\n",
      "Number of test samples (ntest): 113\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 305\n",
      "Number of test samples (ntest): 285\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92       144\n",
      "         1.0       1.00      0.93      0.96       356\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.93      0.96      0.94       500\n",
      "weighted avg       0.96      0.95      0.95       500\n",
      "\n",
      "Train accuracy:  0.95\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.5\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 144, Test = 156\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.47\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 356, Test = 344\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.37\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 51, Test = 59\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 107, Test = 113\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 305, Test = 285\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 554\n",
      "after transf priv:  0.7402912621359223\n",
      "after transf unpriv:  0.7394366197183099\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000855\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 51\n",
      "Number of test samples (ntest): 59\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 107\n",
      "Number of test samples (ntest): 113\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 305\n",
      "Number of test samples (ntest): 285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.94      0.90       144\n",
      "         1.0       0.98      0.95      0.96       410\n",
      "\n",
      "    accuracy                           0.95       554\n",
      "   macro avg       0.92      0.95      0.93       554\n",
      "weighted avg       0.95      0.95      0.95       554\n",
      "\n",
      "Train accuracy:  0.9458483754512635\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.5\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 144, Test = 156\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.41\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 356, Test = 344\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.16\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.70\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.41\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 51, Test = 59\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 107, Test = 113\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.42\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.325422400434628\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 305, Test = 285\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 51\n",
      "Number of test samples (ntest): 59\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 107\n",
      "Number of test samples (ntest): 113\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 305\n",
      "Number of test samples (ntest): 285\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.96      0.92       144\n",
      "         1.0       0.98      0.95      0.97       356\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.93      0.95      0.94       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "Train accuracy:  0.952\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.48000000000000004\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 144, Test = 156\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.916290731874155\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 356, Test = 344\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.6418538861723946\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 51, Test = 59\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.7472144018302211\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 107, Test = 113\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.3862943611198906\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 305, Test = 285\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 51\n",
      "Number of test samples (ntest): 59\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 107\n",
      "Number of test samples (ntest): 113\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 305\n",
      "Number of test samples (ntest): 285\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.91      0.93       144\n",
      "         1.0       0.96      0.98      0.97       356\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.95      0.94      0.95       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "Train accuracy:  0.958\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.4\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.46234928702578276\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 144, Test = 156\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.47\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.46234928702578276\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 356, Test = 344\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.16\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.9937181450426945\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -1.2419183032320724\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 51, Test = 59\n",
      "  AUC: 0.69\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 107, Test = 113\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.49\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.46234928702578276\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 305, Test = 285\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.9937181450426945\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 51\n",
      "Number of test samples (ntest): 59\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 107\n",
      "Number of test samples (ntest): 113\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 305\n",
      "Number of test samples (ntest): 285\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.65      0.69       144\n",
      "         1.0       0.86      0.91      0.89       356\n",
      "\n",
      "    accuracy                           0.83       500\n",
      "   macro avg       0.80      0.78      0.79       500\n",
      "weighted avg       0.83      0.83      0.83       500\n",
      "\n",
      "Train accuracy:  0.834\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.15468906224082363\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 144, Test = 156\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.72\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.15468906224082363\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 356, Test = 344\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -0.49571657164996835\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 51, Test = 59\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 107, Test = 113\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.72\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 305, Test = 285\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.15468906224082363\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.200e+01 3.386e+03 3.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [2.400e+01 2.303e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.800e+01 1.817e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " ...\n",
      " [1.200e+01 2.292e+03 4.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [2.400e+01 2.684e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [2.700e+01 8.613e+03 2.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  410.0 90.0\n",
      "base_pos unpriv:  0.5222222222222223\n",
      "base_pos priv:  0.7292682926829268\n",
      "number of favorable labels:  346\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.207046\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 43\n",
      "Number of test samples (ntest): 37\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 47\n",
      "Number of test samples (ntest): 63\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 111\n",
      "Number of test samples (ntest): 109\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 299\n",
      "Number of test samples (ntest): 291\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95       154\n",
      "         1.0       0.98      0.98      0.98       346\n",
      "\n",
      "    accuracy                           0.97       500\n",
      "   macro avg       0.97      0.97      0.97       500\n",
      "weighted avg       0.97      0.97      0.97       500\n",
      "\n",
      "Train accuracy:  0.972\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.4\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 154, Test = 146\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.45\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 346, Test = 354\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 43, Test = 37\n",
      "  AUC: 0.71\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.2876820724517809\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 47, Test = 63\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.33\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.3862943611198906\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 111, Test = 109\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.45\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 299, Test = 291\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin, transf:  500 568\n",
      "after transf priv:  0.7292682926829268\n",
      "after transf unpriv:  0.7278481012658228\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.001420\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 43\n",
      "Number of test samples (ntest): 37\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 47\n",
      "Number of test samples (ntest): 63\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 111\n",
      "Number of test samples (ntest): 109\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 299\n",
      "Number of test samples (ntest): 291\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96       154\n",
      "         1.0       0.98      0.99      0.99       414\n",
      "\n",
      "    accuracy                           0.98       568\n",
      "   macro avg       0.98      0.97      0.98       568\n",
      "weighted avg       0.98      0.98      0.98       568\n",
      "\n",
      "Train accuracy:  0.9806338028169014\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.4\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.35\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.1823215567939546\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 154, Test = 146\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.48\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 346, Test = 354\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 43, Test = 37\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -0.060624621816434854\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 47, Test = 63\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.35\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.916290731874155\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 111, Test = 109\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.48\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 299, Test = 291\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.1823215567939546\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 43\n",
      "Number of test samples (ntest): 37\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 47\n",
      "Number of test samples (ntest): 63\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 111\n",
      "Number of test samples (ntest): 109\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 299\n",
      "Number of test samples (ntest): 291\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.95      0.97       154\n",
      "         1.0       0.98      0.99      0.99       346\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.98      0.97      0.98       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "Train accuracy:  0.98\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.33\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -1.4663370687934272\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 154, Test = 146\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.48\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.4663370687934272\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 346, Test = 354\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 43, Test = 37\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 47, Test = 63\n",
      "  AUC: 0.69\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.38\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 111, Test = 109\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.4663370687934272\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 299, Test = 291\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.24\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.262364264467491\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 43\n",
      "Number of test samples (ntest): 37\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 47\n",
      "Number of test samples (ntest): 63\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 111\n",
      "Number of test samples (ntest): 109\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 299\n",
      "Number of test samples (ntest): 291\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94       154\n",
      "         1.0       0.97      0.98      0.97       346\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.96      0.95      0.96       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "Train accuracy:  0.964\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.17\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.33\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.9390513249904759\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 154, Test = 146\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.47\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.9390513249904759\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 346, Test = 354\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.24958092103470192\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 43, Test = 37\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.57\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.510168446849835\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 47, Test = 63\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.49593469610087015\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 111, Test = 109\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -0.9390513249904759\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 299, Test = 291\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.1396453324189139\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 43\n",
      "Number of test samples (ntest): 37\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 47\n",
      "Number of test samples (ntest): 63\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 111\n",
      "Number of test samples (ntest): 109\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 299\n",
      "Number of test samples (ntest): 291\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.65      0.68       154\n",
      "         1.0       0.85      0.89      0.87       346\n",
      "\n",
      "    accuracy                           0.82       500\n",
      "   macro avg       0.79      0.77      0.78       500\n",
      "weighted avg       0.81      0.82      0.81       500\n",
      "\n",
      "Train accuracy:  0.816\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.26\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -1.1070475436055134\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 154, Test = 146\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.1070475436055134\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 346, Test = 354\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.291194782643733\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 43, Test = 37\n",
      "  AUC: 0.70\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.35\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -2.552284443261371\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 47, Test = 63\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.24\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.291194782643733\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 111, Test = 109\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -1.1070475436055134\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 299, Test = 291\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.291194782643733\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.5000e+01 2.6870e+03 2.0000e+00 ... 1.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [1.8000e+01 1.2976e+04 3.0000e+00 ... 1.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [2.1000e+01 3.6520e+03 2.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [4.8000e+01 1.0127e+04 2.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [6.0000e+00 1.0470e+03 2.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [9.0000e+00 9.3600e+02 4.0000e+00 ... 1.0000e+00 1.0000e+00 0.0000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  409.0 91.0\n",
      "base_pos unpriv:  0.6153846153846154\n",
      "base_pos priv:  0.7750611246943765\n",
      "number of favorable labels:  373\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.159677\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 35\n",
      "Number of test samples (ntest): 45\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 56\n",
      "Number of test samples (ntest): 54\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 92\n",
      "Number of test samples (ntest): 128\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 273\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98       127\n",
      "         1.0       0.99      0.99      0.99       373\n",
      "\n",
      "    accuracy                           0.99       500\n",
      "   macro avg       0.98      0.99      0.98       500\n",
      "weighted avg       0.99      0.99      0.99       500\n",
      "\n",
      "Train accuracy:  0.988\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.68\n",
      "  Accuracy: 0.68\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.36\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 127, Test = 173\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.59\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 373, Test = 327\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 35, Test = 45\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.58\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -0.2876820724517809\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 56, Test = 54\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 92, Test = 128\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.80\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.60\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 273\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 564\n",
      "after transf priv:  0.7750611246943765\n",
      "after transf unpriv:  0.7741935483870968\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000868\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 35\n",
      "Number of test samples (ntest): 45\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 56\n",
      "Number of test samples (ntest): 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 92\n",
      "Number of test samples (ntest): 128\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 273\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.98       127\n",
      "         1.0       1.00      0.99      0.99       437\n",
      "\n",
      "    accuracy                           0.99       564\n",
      "   macro avg       0.98      0.99      0.98       564\n",
      "weighted avg       0.99      0.99      0.99       564\n",
      "\n",
      "Train accuracy:  0.9893617021276596\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.34\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.68\n",
      "  Accuracy: 0.68\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.35\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 127, Test = 173\n",
      "  AUC: 0.82\n",
      "  Privacy Risk: 0.82\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.64\n",
      "  Attacker advantage: 0.64\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 373, Test = 327\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 35, Test = 45\n",
      "  AUC: 0.84\n",
      "  Privacy Risk: 0.83\n",
      "  Accuracy: 0.83\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.67\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 56, Test = 54\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 92, Test = 128\n",
      "  AUC: 0.81\n",
      "  Privacy Risk: 0.81\n",
      "  Accuracy: 0.81\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.62\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 273\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 35\n",
      "Number of test samples (ntest): 45\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 56\n",
      "Number of test samples (ntest): 54\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 92\n",
      "Number of test samples (ntest): 128\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 273\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.96       127\n",
      "         1.0       0.99      0.98      0.99       373\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.96      0.98      0.97       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "Train accuracy:  0.978\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.4\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 127, Test = 173\n",
      "  AUC: 0.80\n",
      "  Privacy Risk: 0.81\n",
      "  Accuracy: 0.78\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.61\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 373, Test = 327\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.9808292530117262\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 35, Test = 45\n",
      "  AUC: 0.83\n",
      "  Privacy Risk: 0.82\n",
      "  Accuracy: 0.82\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.64\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 56, Test = 54\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 92, Test = 128\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.80\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.61\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 273\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.9808292530117262\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 35\n",
      "Number of test samples (ntest): 45\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 56\n",
      "Number of test samples (ntest): 54\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 92\n",
      "Number of test samples (ntest): 128\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 273\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.95      0.97       127\n",
      "         1.0       0.98      0.99      0.99       373\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.98      0.97      0.98       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "Train accuracy:  0.984\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.4\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.35\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.5065301014970813\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 127, Test = 173\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.78\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.57\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.9491507860524797\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 373, Test = 327\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.4895038712144668\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 35, Test = 45\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.53\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -1.3647934622452285\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 56, Test = 54\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.24\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.658290401680705\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 92, Test = 128\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.80\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.59\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.7292629716538686\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 273\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.24\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.4895038712144668\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 35\n",
      "Number of test samples (ntest): 45\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 56\n",
      "Number of test samples (ntest): 54\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 92\n",
      "Number of test samples (ntest): 128\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 273\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.55      0.61       127\n",
      "         1.0       0.86      0.91      0.88       373\n",
      "\n",
      "    accuracy                           0.82       500\n",
      "   macro avg       0.76      0.73      0.74       500\n",
      "weighted avg       0.81      0.82      0.81       500\n",
      "\n",
      "Train accuracy:  0.818\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.11\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.06542723167621119\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 127, Test = 173\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.50\n",
      "  Test Accuracy (TNR): 0.72\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.06542723167621119\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 373, Test = 327\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.0454592517610042\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 35, Test = 45\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.70\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 0.49\n",
      "  Test Accuracy (TNR): 0.91\n",
      "  Attacker advantage: 0.40\n",
      "  Positive predictive value: 0.81\n",
      "  Optimal thershold: -0.06542723167621119\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 56, Test = 54\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 92, Test = 128\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.0454592517610042\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 273\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.55\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.0454592517610042\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[3.0000e+01 2.1810e+03 4.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [1.2000e+01 9.9600e+02 4.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [3.6000e+01 1.5857e+04 2.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [1.8000e+01 7.3740e+03 4.0000e+00 ... 1.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [1.2000e+01 6.1990e+03 4.0000e+00 ... 1.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [1.2000e+01 6.5200e+02 4.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  403.0 97.0\n",
      "base_pos unpriv:  0.6185567010309279\n",
      "base_pos priv:  0.707196029776675\n",
      "number of favorable labels:  345\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.088639\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 60\n",
      "Number of test samples (ntest): 50\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 118\n",
      "Number of test samples (ntest): 102\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 285\n",
      "Number of test samples (ntest): 305\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.88      0.93       155\n",
      "         1.0       0.95      0.99      0.97       345\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.96      0.94      0.95       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "Train accuracy:  0.956\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.34\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -1.252762968495368\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 155, Test = 145\n",
      "  AUC: 0.80\n",
      "  Privacy Risk: 0.78\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.56\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -1.252762968495368\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 345, Test = 355\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.0986122886681098\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -1.252762968495368\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 60, Test = 50\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 118, Test = 102\n",
      "  AUC: 0.82\n",
      "  Privacy Risk: 0.80\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.61\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -1.252762968495368\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 285, Test = 305\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 529\n",
      "after transf priv:  0.707196029776675\n",
      "after transf unpriv:  0.7063492063492064\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000847\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 60\n",
      "Number of test samples (ntest): 50\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 118\n",
      "Number of test samples (ntest): 102\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 285\n",
      "Number of test samples (ntest): 305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.89      0.91       155\n",
      "         1.0       0.96      0.97      0.96       374\n",
      "\n",
      "    accuracy                           0.95       529\n",
      "   macro avg       0.94      0.93      0.94       529\n",
      "weighted avg       0.95      0.95      0.95       529\n",
      "\n",
      "Train accuracy:  0.947069943289225\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.4\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 155, Test = 145\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.48\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 345, Test = 355\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.2006706954621511\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.70\n",
      "  Privacy Risk: 0.68\n",
      "  Accuracy: 0.68\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.36\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -2.0476928433652555\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 60, Test = 50\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -0.9808292530117262\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 118, Test = 102\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.64\n",
      "  Attacker advantage: 0.54\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 285, Test = 305\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.2006706954621511\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 60\n",
      "Number of test samples (ntest): 50\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 118\n",
      "Number of test samples (ntest): 102\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 285\n",
      "Number of test samples (ntest): 305\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94       155\n",
      "         1.0       0.97      0.97      0.97       345\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.96      0.95      0.96       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "Train accuracy:  0.962\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 155, Test = 145\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.45\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 345, Test = 355\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.13353139262452263\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.6094379124341005\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 60, Test = 50\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.31\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -0.2231435513142097\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 118, Test = 102\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.53\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 285, Test = 305\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.13353139262452263\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 60\n",
      "Number of test samples (ntest): 50\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 118\n",
      "Number of test samples (ntest): 102\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 285\n",
      "Number of test samples (ntest): 305\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.87      0.92       155\n",
      "         1.0       0.94      0.99      0.97       345\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.96      0.93      0.94       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "Train accuracy:  0.952\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.2\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -1.1613777644074108\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 155, Test = 145\n",
      "  AUC: 0.80\n",
      "  Privacy Risk: 0.78\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.56\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.1613777644074108\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 345, Test = 355\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.13882161535751572\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.43\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.7620159868601616\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 60, Test = 50\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -0.13882161535751572\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 118, Test = 102\n",
      "  AUC: 0.82\n",
      "  Privacy Risk: 0.81\n",
      "  Accuracy: 0.81\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.62\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -2.043173472682534\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 285, Test = 305\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.13882161535751572\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 37\n",
      "Number of test samples (ntest): 43\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 60\n",
      "Number of test samples (ntest): 50\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 118\n",
      "Number of test samples (ntest): 102\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 285\n",
      "Number of test samples (ntest): 305\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.61      0.66       155\n",
      "         1.0       0.84      0.90      0.86       345\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.78      0.75      0.76       500\n",
      "weighted avg       0.80      0.81      0.80       500\n",
      "\n",
      "Train accuracy:  0.806\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.17\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.7769463218760608\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 155, Test = 145\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -3.6767692533519685\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 345, Test = 355\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -1.7769463218760604\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 37, Test = 43\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -3.6767692533519685\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 60, Test = 50\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.15530887313377043\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 118, Test = 102\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.31\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.7769463218760608\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 285, Test = 305\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -1.7769463218760604\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.200e+01 1.344e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [2.400e+01 1.258e+03 3.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.200e+01 1.620e+03 2.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " ...\n",
      " [3.600e+01 5.742e+03 2.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [3.600e+01 4.210e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.200e+01 1.935e+03 4.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  410.0 90.0\n",
      "base_pos unpriv:  0.5444444444444444\n",
      "base_pos priv:  0.7463414634146341\n",
      "number of favorable labels:  355\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.201897\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 41\n",
      "Number of test samples (ntest): 39\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 49\n",
      "Number of test samples (ntest): 61\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 104\n",
      "Number of test samples (ntest): 116\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 306\n",
      "Number of test samples (ntest): 284\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.90      0.91       145\n",
      "         1.0       0.96      0.97      0.97       355\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.94      0.93      0.94       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "Train accuracy:  0.95\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.8754687373539001\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 145, Test = 155\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.49\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.8754687373539001\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 355, Test = 345\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.03509131981127006\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 41, Test = 39\n",
      "  AUC: 0.83\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.59\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -1.2992829841302609\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 49, Test = 61\n",
      "  AUC: 0.70\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.03509131981127006\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 104, Test = 116\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.8754687373539001\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 306, Test = 284\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.5389965007326869\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 571\n",
      "after transf priv:  0.7463414634146341\n",
      "after transf unpriv:  0.7453416149068323\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.001000\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 41\n",
      "Number of test samples (ntest): 39\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 49\n",
      "Number of test samples (ntest): 61\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 104\n",
      "Number of test samples (ntest): 116\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 306\n",
      "Number of test samples (ntest): 284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.90      0.91       145\n",
      "         1.0       0.97      0.98      0.97       426\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Train accuracy:  0.9562171628721541\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.8754687373539001\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 145, Test = 155\n",
      "  AUC: 0.81\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -0.8754687373539001\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 355, Test = 345\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.02985296314968116\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 41, Test = 39\n",
      "  AUC: 0.83\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.59\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -1.2992829841302609\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 49, Test = 61\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.31\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.02985296314968116\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 104, Test = 116\n",
      "  AUC: 0.80\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.49\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.8754687373539001\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 306, Test = 284\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.5389965007326869\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 41\n",
      "Number of test samples (ntest): 39\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 49\n",
      "Number of test samples (ntest): 61\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 104\n",
      "Number of test samples (ntest): 116\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 306\n",
      "Number of test samples (ntest): 284\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.90      0.91       145\n",
      "         1.0       0.96      0.97      0.96       355\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.94      0.93      0.94       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "Train accuracy:  0.948\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.31\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.03509131981127006\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 145, Test = 155\n",
      "  AUC: 0.81\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -0.9555114450274365\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 355, Test = 345\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.03509131981127006\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 41, Test = 39\n",
      "  AUC: 0.83\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.59\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -1.2992829841302609\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 49, Test = 61\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.03509131981127006\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 104, Test = 116\n",
      "  AUC: 0.80\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.48\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.9555114450274365\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 306, Test = 284\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.03509131981127006\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 41\n",
      "Number of test samples (ntest): 39\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 49\n",
      "Number of test samples (ntest): 61\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 104\n",
      "Number of test samples (ntest): 116\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 306\n",
      "Number of test samples (ntest): 284\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.89      0.91       145\n",
      "         1.0       0.96      0.97      0.96       355\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.94      0.93      0.93       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "Train accuracy:  0.946\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.38\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.8662112258041039\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 145, Test = 155\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.4494140185457125\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 355, Test = 345\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.24\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.5456618756773141\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 41, Test = 39\n",
      "  AUC: 0.71\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.4494140185457125\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 49, Test = 61\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.1097738267856656\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 104, Test = 116\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.8662112258041039\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 306, Test = 284\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.24\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.5456618756773141\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 41\n",
      "Number of test samples (ntest): 39\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 49\n",
      "Number of test samples (ntest): 61\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 104\n",
      "Number of test samples (ntest): 116\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 306\n",
      "Number of test samples (ntest): 284\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.62      0.65       145\n",
      "         1.0       0.85      0.88      0.86       355\n",
      "\n",
      "    accuracy                           0.80       500\n",
      "   macro avg       0.76      0.75      0.76       500\n",
      "weighted avg       0.80      0.80      0.80       500\n",
      "\n",
      "Train accuracy:  0.804\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.47000000000000003\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.5592443839400855\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 145, Test = 155\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.61\n",
      "  Test Accuracy (TNR): 0.68\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -0.5592443839400855\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 355, Test = 345\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.03913778778016879\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 41, Test = 39\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.64\n",
      "  Attacker advantage: 0.35\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.5592443839400855\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 49, Test = 61\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 104, Test = 116\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.78\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.03913778778016879\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 306, Test = 284\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.5592443839400855\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.200e+01 6.199e+03 4.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [1.500e+01 1.053e+03 4.000e+00 ... 0.000e+00 0.000e+00 1.000e+00]\n",
      " [1.800e+01 3.422e+03 4.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " ...\n",
      " [1.200e+01 7.950e+02 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [2.100e+01 3.976e+03 2.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [1.200e+01 1.155e+03 3.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  408.0 92.0\n",
      "base_pos unpriv:  0.5760869565217391\n",
      "base_pos priv:  0.7132352941176471\n",
      "number of favorable labels:  344\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.137148\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 39\n",
      "Number of test samples (ntest): 41\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 53\n",
      "Number of test samples (ntest): 57\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 117\n",
      "Number of test samples (ntest): 103\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 291\n",
      "Number of test samples (ntest): 299\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.99      0.95       156\n",
      "         1.0       1.00      0.96      0.98       344\n",
      "\n",
      "    accuracy                           0.97       500\n",
      "   macro avg       0.95      0.97      0.96       500\n",
      "weighted avg       0.97      0.97      0.97       500\n",
      "\n",
      "Train accuracy:  0.968\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.5\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -1.0986122886681098\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 156, Test = 144\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.42\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 344, Test = 356\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.0986122886681098\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 39, Test = 41\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 53, Test = 57\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.35\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 117, Test = 103\n",
      "  AUC: 0.71\n",
      "  Privacy Risk: 0.70\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.40\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 291, Test = 299\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.0986122886681098\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 544\n",
      "after transf priv:  0.7132352941176471\n",
      "after transf unpriv:  0.7132352941176471\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 39\n",
      "Number of test samples (ntest): 41\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 53\n",
      "Number of test samples (ntest): 57\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 117\n",
      "Number of test samples (ntest): 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 291\n",
      "Number of test samples (ntest): 299\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97       156\n",
      "         1.0       0.99      0.99      0.99       388\n",
      "\n",
      "    accuracy                           0.98       544\n",
      "   macro avg       0.98      0.98      0.98       544\n",
      "weighted avg       0.98      0.98      0.98       544\n",
      "\n",
      "Train accuracy:  0.9834558823529411\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.30\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -1.3862943611198906\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 156, Test = 144\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.49\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 344, Test = 356\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.3862943611198906\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 39, Test = 41\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.2231435513142097\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 53, Test = 57\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 117, Test = 103\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.49\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 291, Test = 299\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.3862943611198906\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 39\n",
      "Number of test samples (ntest): 41\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 53\n",
      "Number of test samples (ntest): 57\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 117\n",
      "Number of test samples (ntest): 103\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 291\n",
      "Number of test samples (ntest): 299\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.97      0.93       156\n",
      "         1.0       0.98      0.95      0.97       344\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.94      0.96      0.95       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "Train accuracy:  0.958\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.5\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.2282586519809802\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 156, Test = 144\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.47\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 344, Test = 356\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.03077165866675366\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 39, Test = 41\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.78\n",
      "  Accuracy: 0.78\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.56\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.3862943611198906\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 53, Test = 57\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -1.589235205116581\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 117, Test = 103\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 291, Test = 299\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.03077165866675366\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 39\n",
      "Number of test samples (ntest): 41\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 53\n",
      "Number of test samples (ntest): 57\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 117\n",
      "Number of test samples (ntest): 103\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 291\n",
      "Number of test samples (ntest): 299\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.98      0.97       156\n",
      "         1.0       0.99      0.98      0.99       344\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.98      0.98      0.98       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "Train accuracy:  0.982\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.13\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.447216902788386\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 156, Test = 144\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.52\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -0.1306396631009927\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 344, Test = 356\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.447216902788386\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 39, Test = 41\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.10742721568404552\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 53, Test = 57\n",
      "  AUC: 0.70\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.39\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.26860592539096717\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 117, Test = 103\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.54\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.1306396631009927\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 291, Test = 299\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.447216902788386\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 39\n",
      "Number of test samples (ntest): 41\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 53\n",
      "Number of test samples (ntest): 57\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 117\n",
      "Number of test samples (ntest): 103\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 291\n",
      "Number of test samples (ntest): 299\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.67      0.66       156\n",
      "         1.0       0.85      0.84      0.84       344\n",
      "\n",
      "    accuracy                           0.79       500\n",
      "   macro avg       0.75      0.75      0.75       500\n",
      "weighted avg       0.79      0.79      0.79       500\n",
      "\n",
      "Train accuracy:  0.786\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.11\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.22309206971766757\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 156, Test = 144\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.6096438653279115\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 344, Test = 356\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.22309206971766743\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 39, Test = 41\n",
      "  AUC: 0.70\n",
      "  Privacy Risk: 0.68\n",
      "  Accuracy: 0.68\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.36\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -2.2278679295699733\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 53, Test = 57\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 117, Test = 103\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -0.11401780753753095\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 291, Test = 299\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.11401780753753095\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.300e+01 8.820e+02 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.800e+01 3.966e+03 1.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [1.200e+01 6.180e+02 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " ...\n",
      " [2.100e+01 5.710e+02 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [2.400e+01 4.151e+03 2.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [2.400e+01 3.552e+03 3.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  405.0 95.0\n",
      "base_pos unpriv:  0.6421052631578947\n",
      "base_pos priv:  0.7012345679012346\n",
      "number of favorable labels:  345\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.059129\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 34\n",
      "Number of test samples (ntest): 46\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 121\n",
      "Number of test samples (ntest): 99\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 284\n",
      "Number of test samples (ntest): 306\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98       155\n",
      "         1.0       0.99      0.99      0.99       345\n",
      "\n",
      "    accuracy                           0.99       500\n",
      "   macro avg       0.99      0.99      0.99       500\n",
      "weighted avg       0.99      0.99      0.99       500\n",
      "\n",
      "Train accuracy:  0.988\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.68\n",
      "  Accuracy: 0.68\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.35\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 155, Test = 145\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.58\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 345, Test = 355\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 34, Test = 46\n",
      "  AUC: 0.83\n",
      "  Privacy Risk: 0.84\n",
      "  Accuracy: 0.84\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.67\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.6094379124341005\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 121, Test = 99\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.54\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 284, Test = 306\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.04255961441879589\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin, transf:  500 518\n",
      "after transf priv:  0.7012345679012346\n",
      "after transf unpriv:  0.6991150442477876\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.002120\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 34\n",
      "Number of test samples (ntest): 46\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 121\n",
      "Number of test samples (ntest): 99\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 284\n",
      "Number of test samples (ntest): 306\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97       155\n",
      "         1.0       0.99      0.99      0.99       363\n",
      "\n",
      "    accuracy                           0.98       518\n",
      "   macro avg       0.98      0.98      0.98       518\n",
      "weighted avg       0.98      0.98      0.98       518\n",
      "\n",
      "Train accuracy:  0.9826254826254827\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 155, Test = 145\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.57\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 345, Test = 355\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 34, Test = 46\n",
      "  AUC: 0.81\n",
      "  Privacy Risk: 0.83\n",
      "  Accuracy: 0.83\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.65\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.6094379124341005\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.69\n",
      "  Privacy Risk: 0.68\n",
      "  Accuracy: 0.68\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.37\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.2231435513142097\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 121, Test = 99\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.54\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -1.0986122886681096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 284, Test = 306\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.24\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 34\n",
      "Number of test samples (ntest): 46\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 121\n",
      "Number of test samples (ntest): 99\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 284\n",
      "Number of test samples (ntest): 306\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.97       155\n",
      "         1.0       1.00      0.97      0.98       345\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.97      0.98      0.97       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "Train accuracy:  0.978\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.24000000000000002\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 155, Test = 145\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.57\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.587786664902119\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 345, Test = 355\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.24\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 34, Test = 46\n",
      "  AUC: 0.81\n",
      "  Privacy Risk: 0.80\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.59\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 121, Test = 99\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.58\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -0.587786664902119\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 284, Test = 306\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.791759469228055\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 34\n",
      "Number of test samples (ntest): 46\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 121\n",
      "Number of test samples (ntest): 99\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 284\n",
      "Number of test samples (ntest): 306\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.96       155\n",
      "         1.0       0.98      0.99      0.98       345\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.98      0.97      0.97       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "Train accuracy:  0.978\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -1.2473847788094194\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 155, Test = 145\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.2473847788094194\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 345, Test = 355\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -1.1342995515424787\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 34, Test = 46\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.80\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.61\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.9210604944795908\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.19484079939427776\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 121, Test = 99\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.48\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.5367654283149921\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 284, Test = 306\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -1.1342995515424787\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 34\n",
      "Number of test samples (ntest): 46\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 121\n",
      "Number of test samples (ntest): 99\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 284\n",
      "Number of test samples (ntest): 306\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.67      0.70       155\n",
      "         1.0       0.86      0.88      0.87       345\n",
      "\n",
      "    accuracy                           0.82       500\n",
      "   macro avg       0.79      0.78      0.78       500\n",
      "weighted avg       0.82      0.82      0.82       500\n",
      "\n",
      "Train accuracy:  0.818\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.47000000000000003\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.2558711088554425\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 155, Test = 145\n",
      "  AUC: 0.71\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.79\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.80\n",
      "  Optimal thershold: -0.36522397758851505\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 345, Test = 355\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.2558711088554425\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 34, Test = 46\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.85\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.89\n",
      "  Optimal thershold: -0.36522397758851505\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.2558711088554425\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 121, Test = 99\n",
      "  AUC: 0.70\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.78\n",
      "  Optimal thershold: -1.1843047736606163\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 284, Test = 306\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[3.6000e+01 1.2389e+04 1.0000e+00 ... 1.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [1.8000e+01 1.5820e+03 4.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [1.2000e+01 2.1710e+03 2.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [1.3000e+01 8.8200e+02 4.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [1.6000e+01 1.1750e+03 2.0000e+00 ... 1.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [2.4000e+01 2.8120e+03 2.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n",
      "privileged vs. unprivileged:  403.0 97.0\n",
      "base_pos unpriv:  0.6288659793814433\n",
      "base_pos priv:  0.7220843672456576\n",
      "number of favorable labels:  352\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.093218\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 57) (500, 57) (500, 57)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 36\n",
      "Number of test samples (ntest): 44\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 112\n",
      "Number of test samples (ntest): 108\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 291\n",
      "Number of test samples (ntest): 299\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94       148\n",
      "         1.0       0.97      0.97      0.97       352\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.96      0.96      0.96       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "Train accuracy:  0.964\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.5\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 152\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.49\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.15415067982725822\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 352, Test = 348\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 36, Test = 44\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.48\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.916290731874155\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 112, Test = 108\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.64\n",
      "  Attacker advantage: 0.53\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.15415067982725822\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 291, Test = 299\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 532\n",
      "after transf priv:  0.7220843672456576\n",
      "after transf unpriv:  0.7209302325581395\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.001154\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 36\n",
      "Number of test samples (ntest): 44\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 112\n",
      "Number of test samples (ntest): 108\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 291\n",
      "Number of test samples (ntest): 299\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.92      0.93       148\n",
      "         1.0       0.97      0.97      0.97       384\n",
      "\n",
      "    accuracy                           0.96       532\n",
      "   macro avg       0.95      0.95      0.95       532\n",
      "weighted avg       0.96      0.96      0.96       532\n",
      "\n",
      "Train accuracy:  0.9586466165413534\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.5\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 152\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.48\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.15415067982725822\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 352, Test = 348\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 36, Test = 44\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.55\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.916290731874155\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 112, Test = 108\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.64\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.15415067982725822\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 291, Test = 299\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 36\n",
      "Number of test samples (ntest): 44\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 112\n",
      "Number of test samples (ntest): 108\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 291\n",
      "Number of test samples (ntest): 299\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.97      0.95       148\n",
      "         1.0       0.99      0.97      0.98       352\n",
      "\n",
      "    accuracy                           0.97       500\n",
      "   macro avg       0.96      0.97      0.96       500\n",
      "weighted avg       0.97      0.97      0.97       500\n",
      "\n",
      "Train accuracy:  0.968\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.5\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 152\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.53\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 352, Test = 348\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 36, Test = 44\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.54\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.35\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.13353139262452263\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 112, Test = 108\n",
      "  AUC: 0.80\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.53\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 291, Test = 299\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.24\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.8472978603872037\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 36\n",
      "Number of test samples (ntest): 44\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 112\n",
      "Number of test samples (ntest): 108\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 291\n",
      "Number of test samples (ntest): 299\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96       148\n",
      "         1.0       0.97      1.00      0.98       352\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.98      0.96      0.97       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "Train accuracy:  0.976\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.5270904671141474\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 152\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.54\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -0.18525550530069707\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 352, Test = 348\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.5270904671141474\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 36, Test = 44\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.54\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.18525550530069707\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.16\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.5270904671141474\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 112, Test = 108\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.78\n",
      "  Accuracy: 0.78\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.56\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.8923789826032467\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 291, Test = 299\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.24\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.5270904671141474\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 36\n",
      "Number of test samples (ntest): 44\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 112\n",
      "Number of test samples (ntest): 108\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 291\n",
      "Number of test samples (ntest): 299\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.55      0.61       148\n",
      "         1.0       0.83      0.90      0.86       352\n",
      "\n",
      "    accuracy                           0.79       500\n",
      "   macro avg       0.76      0.72      0.74       500\n",
      "weighted avg       0.79      0.79      0.79       500\n",
      "\n",
      "Train accuracy:  0.794\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.03\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -0.0271696809716866\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 152\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.70\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.0271696809716866\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 352, Test = 348\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.12\n",
      "  Test Accuracy (TNR): 0.95\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 36, Test = 44\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -3.647876285639956\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.70\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.39\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 112, Test = 108\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.026391599847142035\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 291, Test = 299\n",
      "  AUC: 0.48\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.0271696809716866\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# favorable and unfavorable labels and feature_names\n",
    "f_label = dataset_orig.favorable_label\n",
    "uf_label = dataset_orig.unfavorable_label\n",
    "feature_names = dataset_orig.feature_names\n",
    "\n",
    "# run mitigating algorithms\n",
    "for i in range(N):\n",
    "    if ATTACK == \"mia1\":\n",
    "        # split dataset into train, validation, and test\n",
    "        dataset_orig_train, dataset_orig_test = dataset_orig.split([p], shuffle=True)\n",
    "        dataset_orig_val = dataset_orig_test\n",
    "\n",
    "        print(\"#### Train dataset's features are as below:\")\n",
    "        print(dataset_orig_train.features)\n",
    "    elif ATTACK == \"mia2\":\n",
    "        train_index, test_index, population_index = get_unique_indices_reference()\n",
    "        \n",
    "        g_train = y_true[train_index] + (sensitive_features[train_index] + 1) * 2 # 2, 4, 3, 5\n",
    "        g_test = y_true[test_index] + (sensitive_features[test_index] + 1) * 2\n",
    "        g_pop_train = y_true[population_index] + (sensitive_features[population_index] + 1) * 2\n",
    "        \n",
    "        # for Audit\n",
    "        target_dataset, reference_dataset = create_datasets(train_index, test_index, population_index, g_train, g_test, g_pop_train)\n",
    "        \n",
    "        # for mitigators\n",
    "        privileged_value = [1]\n",
    "        unprivileged_value = [0]\n",
    "        # Convert train dataset\n",
    "        dataset_orig_train = create_binary_label_dataset(\n",
    "            dataset_orig=dataset_orig,\n",
    "            X=X[train_index],\n",
    "            y=y_true[train_index],\n",
    "            sensitive_features=sensitive_features[train_index],\n",
    "            sens_attr_name=sens_attr,\n",
    "            privileged_value=privileged_value,\n",
    "            unprivileged_value=unprivileged_value\n",
    "        )\n",
    "        \n",
    "        # Convert test dataset\n",
    "        dataset_orig_val = create_binary_label_dataset(\n",
    "            dataset_orig=dataset_orig,\n",
    "            X=X[test_index],\n",
    "            y=y_true[test_index],\n",
    "            sensitive_features=sensitive_features[test_index],\n",
    "            sens_attr_name=sens_attr,\n",
    "            privileged_value=privileged_value,\n",
    "            unprivileged_value=unprivileged_value\n",
    "        )\n",
    "        \n",
    "        # Since validation and testing datasets are the same\n",
    "        dataset_orig_test = dataset_orig_val\n",
    "        \n",
    "        # orig_metrics, orig_mia_metrics, priv_metric_orig, favor_metric_orig = run_MIA2(dataset_orig, target_dataset, reference_dataset, privileged_groups, unprivileged_groups, BASELINE, orig_metrics, orig_mia_metrics, f_label, uf_label, THRESH_ARR, DISPLAY, SCALER)\n",
    "        \n",
    "    # favorable and unfavorable labels and feature_names\n",
    "    f_label = dataset_orig.favorable_label\n",
    "    uf_label = dataset_orig.unfavorable_label\n",
    "    feature_names = dataset_orig.feature_names\n",
    "\n",
    "    # introduce label or selection biases, assuming the original data is fair\n",
    "    if BIAS_TYPE == 'label':\n",
    "        dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    elif BIAS_TYPE == 'selection':\n",
    "        dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    else:\n",
    "        print('no bias type specified')\n",
    "\n",
    "    # show data info\n",
    "    print(\"#### Training Dataset shape\")\n",
    "    print(dataset_orig_train.features.shape)\n",
    "    print(\"#### Favorable and unfavorable labels\")\n",
    "    print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "    print(\"#### Protected attribute names\")\n",
    "    print(dataset_orig_train.protected_attribute_names)\n",
    "    print(\"#### Privileged and unprivileged protected groups\")\n",
    "    print(privileged_groups, unprivileged_groups)\n",
    "    print(\"#### Privileged and unprivileged protected attribute values\")\n",
    "    print(dataset_orig_train.privileged_protected_attributes, dataset_orig_train.unprivileged_protected_attributes)\n",
    "    print(\"#### Dataset feature names\")\n",
    "    print(dataset_orig_train.feature_names)\n",
    "\n",
    "    # check fairness on the original data\n",
    "    metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    print(\"privileged vs. unprivileged: \", metric_orig_train.num_positives(privileged=True) + metric_orig_train.num_negatives(privileged=True), metric_orig_train.num_positives(privileged=False) + metric_orig_train.num_negatives(privileged=False)) \n",
    "    base_rate_unprivileged = metric_orig_train.base_rate(privileged=False)\n",
    "    base_rate_privileged = metric_orig_train.base_rate(privileged=True)\n",
    "    print('base_pos unpriv: ', base_rate_unprivileged)\n",
    "    print('base_pos priv: ', base_rate_privileged)\n",
    "    print('number of favorable labels: ', np.count_nonzero(dataset_orig_train.labels==f_label))\n",
    "    print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "    # statistics of favored/positive class BEFORE transf \n",
    "    priv_metric_orig['total_priv'] += metric_orig_train.num_instances(privileged = True) \n",
    "    priv_metric_orig['total_unpriv'] += metric_orig_train.num_instances(privileged = False) \n",
    "    favor_metric_orig['total_favor'] += metric_orig_train.base_rate()\n",
    "    favor_metric_orig['total_unfavor'] += 1 - metric_orig_train.base_rate()\n",
    "    favor_metric_orig['priv_favor'] += metric_orig_train.base_rate(privileged = True)\n",
    "    favor_metric_orig['priv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = True)\n",
    "    favor_metric_orig['unpriv_favor'] += metric_orig_train.base_rate(privileged = False)\n",
    "    favor_metric_orig['unpriv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = False)\n",
    "\n",
    "    print(\"#### Train shape, validation shape, test shape\")\n",
    "    print(dataset_orig_train.features.shape, dataset_orig_val.features.shape, dataset_orig_test.features.shape)\n",
    "\n",
    "    # testing mitigation methods \n",
    "    test_cases = TestAlgorithms(BASELINE)\n",
    "\n",
    "    # null mitigator\n",
    "    orig_metrics, orig_mia_metrics = test_cases.run_original(dataset_orig_train, dataset_orig_val, dataset_orig_test, BASELINE, orig_metrics, orig_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset) \n",
    "\n",
    "    # synthetic data mitigator\n",
    "    metric_transf_train, transf_metrics, transf_mia_metrics = test_cases.run_oversample(dataset_orig_train, dataset_orig_val, dataset_orig_test, privileged_groups, unprivileged_groups, base_rate_privileged, base_rate_unprivileged, BASELINE, transf_metrics, transf_mia_metrics, f_label, uf_label, ATTACK, THRESH_ARR, DISPLAY, OS_MODE, SCALER, target_dataset, reference_dataset)\n",
    "    \n",
    "    # statistics of favored/positive class AFTER transf\n",
    "    favor_metric_transf['total_favor'] += metric_transf_train.base_rate()\n",
    "    favor_metric_transf['total_unfavor'] += 1 - metric_transf_train.base_rate()\n",
    "    favor_metric_transf['priv_favor'] += metric_transf_train.base_rate(privileged = True)\n",
    "    favor_metric_transf['priv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = True)\n",
    "    favor_metric_transf['unpriv_favor'] += metric_transf_train.base_rate(privileged = False)\n",
    "    favor_metric_transf['unpriv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = False)\n",
    "\n",
    "    # dir mitigator\n",
    "    dir_metrics, dir_mia_metrics = test_cases.run_dir(dataset_orig_train, dataset_orig_val, dataset_orig_test,  sens_attr, BASELINE, dir_metrics, dir_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset) \n",
    "    \n",
    "    # reweigh mitigator\n",
    "    reweigh_metrics, reweigh_mia_metrics = test_cases.run_rew(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, reweigh_metrics, reweigh_mia_metrics, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "    # eg mitigator, in-processing\n",
    "    eg_metrics, eg_mia_metrics = test_cases.run_eg(dataset_orig_train, dataset_orig_val, dataset_orig_test, eg_metrics, eg_mia_metrics, BASELINE, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "#     # egr gave error so I replaced it with reweigh\n",
    "# #     eg_metrics, eg_mia_metrics = test_cases.run_rew(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, eg_metrics, eg_mia_metrics, THRESH_ARR, DISPLAY, SCALER)\n",
    "\n",
    "#     # cpp mitigator\n",
    "#     cpp_metrics = test_cases.run_cpp(dataset_orig_train, dataset_orig_val, dataset_orig_test, cpp_metrics, BASELINE, unprivileged_groups, privileged_groups, THRESH_ARR, SCALER)\n",
    "\n",
    "#     # ro mitigator\n",
    "#     # ro_metrics = test_cases.run_ro(dataset_orig_train, dataset_orig_val, dataset_orig_test, ro_metrics, BASELINE, unprivileged_groups, privileged_groups, THRESH_ARR, SCALER)\n",
    "\n",
    "#     if (BASELINE == 'lr'):\n",
    "#         pr_orig_metrics = test_cases.run_pr(dataset_orig_train, dataset_orig_val, dataset_orig_test, pr_orig_metrics, sens_attr, f_label, uf_label, unprivileged_groups, privileged_groups, THRESH_ARR, DISPLAY, SCALER) \n",
    "\n",
    "    delete_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e9f7847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_bank, _ = dataset_orig.convert_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2811a790",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "1.0    810\n",
       "0.0    190\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2bee0ec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the occurrences of privileged and unprivileged values\n",
    "gender_counts = df_bank['gender'].value_counts()\n",
    "\n",
    "# Plot the bar graph\n",
    "plt.figure(figsize=(6, 4))\n",
    "gender_counts.plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('Count of Privileged and Unprivileged Values in Gender')\n",
    "plt.xlabel('Gender Category (1=Privileged, 0=Unprivileged)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f013a728",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'y'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_counts \u001b[38;5;241m=\u001b[39m \u001b[43mdf_bank\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'y'"
     ]
    }
   ],
   "source": [
    "y_counts = df_bank['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3752774e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'y'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Count the occurrences of privileged and unprivileged values\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m label_counts \u001b[38;5;241m=\u001b[39m \u001b[43mdf_bank\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Plot the bar graph\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'y'"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of privileged and unprivileged values\n",
    "label_counts = df_bank['y'].value_counts()\n",
    "\n",
    "# Plot the bar graph\n",
    "plt.figure(figsize=(6, 4))\n",
    "age_counts.plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('Count of Favorable and Unfavorable Values in Dataset')\n",
    "plt.xlabel('Label Category (1=Favorable, 0=Unfavorable)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "900da4ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20798, 14)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90de2a9",
   "metadata": {},
   "source": [
    "## Display Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "72632350",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig_copy = priv_metric_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8530a47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float, {'total_priv': 8121.0, 'total_unpriv': 1879.0})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "priv_metric_orig_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b736dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float, {'total_priv': 8121.0, 'total_unpriv': 1879.0})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priv_metric_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c736a792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('total_priv', 8121.0), ('total_unpriv', 1879.0)])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priv_metric_orig.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c73a4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig = priv_metric_orig_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0ea4ee29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('bal_acc', [0.6201117318435754, 0.6155175061425061, 0.6243571762505844, 0.6268646012621917, 0.6506778868630201, 0.6395567278316476, 0.618082965714728, 0.6185380439058935, 0.6092141386410432, 0.625115171990172, 0.6514285714285715, 0.6203041144901611, 0.649448419797257, 0.6121817196811392, 0.5755687543087448, 0.589800874210782, 0.5897148200093502, 0.6730259051186017, 0.579504613890238, 0.6181941923774954]), ('avg_odds_diff', [-0.13806008309364018, -0.12127483298556924, -0.10773037542662114, -0.0807103610675039, -0.0862855947496802, -0.06861458464206616, -0.05507872999483743, -0.05281321548882101, -0.11796605245382513, 0.017778506413872852, 0.07039172849341893, 0.04731130286104998, -0.1280988337364038, -0.07280112529332242, -0.011626856939356944, -0.14207739977424444, -0.061807051379022426, -0.06482418605227608, 0.10050897829487526, -0.027982541957697282]), ('disp_imp', [0.2692440933970761, 0.20060587902393556, 0.2039477998557282, 0.17315219894082434, 0.22900335946248596, 0.12839496986382914, 0.14940959661456554, 0.16400112233445563, 0.26209472076048224, 0.055822649572649596, 0.01037193096183453, 0.02329535178151565, 0.23059928196630752, 0.15241635687732347, 0.041046507477602856, 0.21415493192183488, 0.1527777777777778, 0.21170745878422548, 0.06833594157537815, 0.10075121520106067]), ('stat_par_diff', [-0.19144743324465463, -0.15920319146125594, -0.15321706572076066, -0.13062358867465695, -0.1594541910331384, -0.09434374914568466, -0.11112803330287335, -0.12056518151815176, -0.1734636557690148, -0.04311056105610567, -0.007190203347938406, -0.01647438029213888, -0.16454823135284258, -0.10250000000000004, -0.028967984080203513, -0.16995587963329895, -0.10999999999999999, -0.14798456696111284, 0.05107212475633527, -0.07228342712213687]), ('eq_opp_diff', [-0.20850111856823272, -0.11923076923076925, -0.05546075085324231, -0.12060439560439562, -0.24573652990608008, -0.03384752677205505, -0.13350910834132312, -0.16176925456232605, -0.18135746606334846, -0.053701015965166854, -0.06222406181015461, -0.07339687479738055, -0.11501635444543568, -0.10047455408280159, 0.008343508343508388, -0.10950819672131151, -0.17865389055645342, -0.18529601595963152, 0.05082032813125248, -0.0004095283598389843]), ('theil_ind', [0.25091138191297885, 0.17452391855464724, 0.1992470631860104, 0.18291135709797163, 0.2259871590434548, 0.1949370874655288, 0.207576075601642, 0.21835473988394768, 0.31057217365750694, 0.16929261907872314, 0.20926844992434512, 0.21335642709188077, 0.21485834654176403, 0.26909774419390786, 0.23069511152068872, 0.19177662184993796, 0.23683381078667684, 0.21945020670712906, 0.2434082524343071, 0.21757972243778947]), ('unpriv_fpr', [0.4523809523809524, 0.5121951219512195, 0.44, 0.5306122448979592, 0.5128205128205128, 0.4444444444444444, 0.5714285714285714, 0.5813953488372093, 0.42857142857142855, 0.6511627906976745, 0.631578947368421, 0.6590909090909091, 0.37209302325581395, 0.4594594594594595, 0.5777777777777777, 0.5116279069767442, 0.6153846153846154, 0.4634146341463415, 0.6956521739130435, 0.5]), ('unpriv_fnr', [0.43333333333333335, 0.2692307692307692, 0.25, 0.28846153846153844, 0.44642857142857145, 0.22641509433962265, 0.32142857142857145, 0.3584905660377358, 0.47058823529411764, 0.20754716981132076, 0.2708333333333333, 0.2830188679245283, 0.3220338983050847, 0.36507936507936506, 0.24074074074074073, 0.28, 0.39344262295081966, 0.38596491228070173, 0.20408163265306123, 0.22448979591836735]), ('priv_fpr', [0.52, 0.6355140186915887, 0.6, 0.5714285714285714, 0.4396551724137931, 0.5478260869565217, 0.5480769230769231, 0.5252525252525253, 0.48314606741573035, 0.5619047619047619, 0.42857142857142855, 0.49107142857142855, 0.5132743362831859, 0.5045871559633027, 0.609375, 0.6862745098039216, 0.5603448275862069, 0.4077669902912621, 0.5454545454545454, 0.5555555555555556]), ('priv_fnr', [0.22483221476510068, 0.15, 0.1945392491467577, 0.16785714285714284, 0.20069204152249134, 0.19256756756756757, 0.18791946308724833, 0.19672131147540983, 0.28923076923076924, 0.15384615384615385, 0.20860927152317882, 0.20962199312714777, 0.20701754385964913, 0.2646048109965636, 0.2490842490842491, 0.17049180327868851, 0.2147887323943662, 0.20066889632107024, 0.2549019607843137, 0.22408026755852842])])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_metrics.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bf623751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)\n",
      "\n",
      "german_age\n",
      "500\n",
      "2)\n",
      "\n",
      "              total_priv  total_unpriv\n",
      "num_instance                          \n",
      "orig              406.05         93.95\n",
      "3)\n",
      "\n",
      "         total_favor  total_unfavor  priv_favor  priv_unfavor  unpriv_favor  \\\n",
      "dataset                                                                       \n",
      "orig        0.700100       0.299900    0.724188      0.275812      0.595649   \n",
      "transf      0.723978       0.276022    0.724188      0.275812      0.723342   \n",
      "\n",
      "         unpriv_unfavor  \n",
      "dataset                  \n",
      "orig           0.404351  \n",
      "transf         0.276658  \n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "print('1)\\n')\n",
    "print(DATASET)\n",
    "print(dataset_orig_train.features.shape[0])\n",
    "\n",
    "print('2)\\n')\n",
    "priv_metric_orig = {k: [v/N] for (k,v) in priv_metric_orig.items()}\n",
    "results = [priv_metric_orig]\n",
    "tr = pd.Series(['orig'], name='num_instance')\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis = 0).set_index([tr])\n",
    "print(df)\n",
    "\n",
    "print('3)\\n')\n",
    "favor_metric_orig = {k: [v/N] for (k,v) in favor_metric_orig.items()}\n",
    "favor_metric_transf = {k: [v/N] for (k,v) in favor_metric_transf.items()}\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "results = [favor_metric_orig, favor_metric_transf]\n",
    "tr = pd.Series(['orig'] + ['transf'], name='dataset')\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis = 0).set_index([tr])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "25a8f1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('bal_acc', [0.6201117318435754, 0.6155175061425061, 0.6243571762505844, 0.6268646012621917, 0.6506778868630201, 0.6395567278316476, 0.618082965714728, 0.6185380439058935, 0.6092141386410432, 0.625115171990172, 0.6514285714285715, 0.6203041144901611, 0.649448419797257, 0.6121817196811392, 0.5755687543087448, 0.589800874210782, 0.5897148200093502, 0.6730259051186017, 0.579504613890238, 0.6181941923774954]), ('avg_odds_diff', [-0.13806008309364018, -0.12127483298556924, -0.10773037542662114, -0.0807103610675039, -0.0862855947496802, -0.06861458464206616, -0.05507872999483743, -0.05281321548882101, -0.11796605245382513, 0.017778506413872852, 0.07039172849341893, 0.04731130286104998, -0.1280988337364038, -0.07280112529332242, -0.011626856939356944, -0.14207739977424444, -0.061807051379022426, -0.06482418605227608, 0.10050897829487526, -0.027982541957697282]), ('disp_imp', [0.2692440933970761, 0.20060587902393556, 0.2039477998557282, 0.17315219894082434, 0.22900335946248596, 0.12839496986382914, 0.14940959661456554, 0.16400112233445563, 0.26209472076048224, 0.055822649572649596, 0.01037193096183453, 0.02329535178151565, 0.23059928196630752, 0.15241635687732347, 0.041046507477602856, 0.21415493192183488, 0.1527777777777778, 0.21170745878422548, 0.06833594157537815, 0.10075121520106067]), ('stat_par_diff', [-0.19144743324465463, -0.15920319146125594, -0.15321706572076066, -0.13062358867465695, -0.1594541910331384, -0.09434374914568466, -0.11112803330287335, -0.12056518151815176, -0.1734636557690148, -0.04311056105610567, -0.007190203347938406, -0.01647438029213888, -0.16454823135284258, -0.10250000000000004, -0.028967984080203513, -0.16995587963329895, -0.10999999999999999, -0.14798456696111284, 0.05107212475633527, -0.07228342712213687]), ('eq_opp_diff', [-0.20850111856823272, -0.11923076923076925, -0.05546075085324231, -0.12060439560439562, -0.24573652990608008, -0.03384752677205505, -0.13350910834132312, -0.16176925456232605, -0.18135746606334846, -0.053701015965166854, -0.06222406181015461, -0.07339687479738055, -0.11501635444543568, -0.10047455408280159, 0.008343508343508388, -0.10950819672131151, -0.17865389055645342, -0.18529601595963152, 0.05082032813125248, -0.0004095283598389843]), ('theil_ind', [0.25091138191297885, 0.17452391855464724, 0.1992470631860104, 0.18291135709797163, 0.2259871590434548, 0.1949370874655288, 0.207576075601642, 0.21835473988394768, 0.31057217365750694, 0.16929261907872314, 0.20926844992434512, 0.21335642709188077, 0.21485834654176403, 0.26909774419390786, 0.23069511152068872, 0.19177662184993796, 0.23683381078667684, 0.21945020670712906, 0.2434082524343071, 0.21757972243778947]), ('unpriv_fpr', [0.4523809523809524, 0.5121951219512195, 0.44, 0.5306122448979592, 0.5128205128205128, 0.4444444444444444, 0.5714285714285714, 0.5813953488372093, 0.42857142857142855, 0.6511627906976745, 0.631578947368421, 0.6590909090909091, 0.37209302325581395, 0.4594594594594595, 0.5777777777777777, 0.5116279069767442, 0.6153846153846154, 0.4634146341463415, 0.6956521739130435, 0.5]), ('unpriv_fnr', [0.43333333333333335, 0.2692307692307692, 0.25, 0.28846153846153844, 0.44642857142857145, 0.22641509433962265, 0.32142857142857145, 0.3584905660377358, 0.47058823529411764, 0.20754716981132076, 0.2708333333333333, 0.2830188679245283, 0.3220338983050847, 0.36507936507936506, 0.24074074074074073, 0.28, 0.39344262295081966, 0.38596491228070173, 0.20408163265306123, 0.22448979591836735]), ('priv_fpr', [0.52, 0.6355140186915887, 0.6, 0.5714285714285714, 0.4396551724137931, 0.5478260869565217, 0.5480769230769231, 0.5252525252525253, 0.48314606741573035, 0.5619047619047619, 0.42857142857142855, 0.49107142857142855, 0.5132743362831859, 0.5045871559633027, 0.609375, 0.6862745098039216, 0.5603448275862069, 0.4077669902912621, 0.5454545454545454, 0.5555555555555556]), ('priv_fnr', [0.22483221476510068, 0.15, 0.1945392491467577, 0.16785714285714284, 0.20069204152249134, 0.19256756756756757, 0.18791946308724833, 0.19672131147540983, 0.28923076923076924, 0.15384615384615385, 0.20860927152317882, 0.20962199312714777, 0.20701754385964913, 0.2646048109965636, 0.2490842490842491, 0.17049180327868851, 0.2147887323943662, 0.20066889632107024, 0.2549019607843137, 0.22408026755852842])])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_metrics.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "23a78a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('4)\\n')\n",
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_error_metrics = {k: [statistics.stdev(v)] for (k,v) in orig_metrics.items()}\n",
    "transf_error_metrics = {k: [statistics.stdev(v)] for (k,v) in transf_metrics.items()}\n",
    "reweigh_error_metrics = {k: [statistics.stdev(v)] for (k,v) in reweigh_metrics.items()}\n",
    "dir_error_metrics = {k: [statistics.stdev(v)] for (k,v) in dir_metrics.items()}\n",
    "eg_error_metrics = {k: [statistics.stdev(v)] for (k,v) in eg_metrics.items()}\n",
    "# pr_orig_error_metrics = {k: [statistics.stdev(v)] for (k,v) in pr_orig_metrics.items()}\n",
    "# cpp_error_metrics = {k: [statistics.stdev(v)] for (k,v) in cpp_metrics.items()}\n",
    "# ro_error_metrics = {k: [statistics.stdev(v)] for (k,v) in ro_metrics.items()}\n",
    "\n",
    "# mean value metrics\n",
    "orig_metrics_mean = {k: [sum(v)/N] for (k,v) in orig_metrics.items()}\n",
    "transf_metrics_mean = {k: [sum(v)/N] for (k,v) in transf_metrics.items()}\n",
    "reweigh_metrics_mean = {k:[sum(v)/N] for (k,v) in reweigh_metrics.items()}\n",
    "dir_metrics_mean = {k:[sum(v)/N] for (k,v) in dir_metrics.items()}\n",
    "eg_metrics_mean = {k:[sum(v)/N] for (k,v) in eg_metrics.items()}\n",
    "# pr_orig_metrics_mean = {k: [sum(v)/N] for (k,v) in pr_orig_metrics.items()}\n",
    "# cpp_metrics_mean = {k: [sum(v)/N] for (k,v) in cpp_metrics.items()}\n",
    "# ro_metrics_mean = {k: [sum(v)/N] for (k,v) in ro_metrics.items()}\n",
    "\n",
    "# Python paired sample t-test\n",
    "from scipy.stats import ttest_rel\n",
    "def paired_t (a, b):\n",
    "    np_a = np.array(a)\n",
    "    np_b = np.array(b)\n",
    "    s, p = ttest_rel(np.absolute(np_a), np.absolute(np_b))\n",
    "    return p\n",
    "\n",
    "def acc_diff (a, b):\n",
    "    np_a = np.array(a)\n",
    "    np_b = np.array(b)\n",
    "    delta = np_a - np_b\n",
    "    m = statistics.mean(delta)\n",
    "    s = statistics.stdev(delta)\n",
    "    return [m, s]\n",
    "\n",
    "# if BASELINE == 'lr':\n",
    "#     plot_algo_lr(orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, eg_metrics_mean, pr_orig_metrics_mean, cpp_metrics_mean, ro_metrics_mean, orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, egr_error_metrics, pr_orig_error_metrics, cpp_error_metrics, ro_error_metrics, BASELINE)\n",
    "#     stat =  {k: [paired_t(transf_metrics[k], v)] for (k,v) in orig_metrics.items()}\n",
    "#     print(\"5)\")\n",
    "#     print(stat)\n",
    "# else:\n",
    "#     plot_algo(orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, eg_metrics_mean, cpp_metrics_mean, ro_metrics_mean, orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, egr_error_metrics, cpp_error_metrics, ro_error_metrics, BASELINE)\n",
    "#     stat =  {k: [paired_t(transf_metrics[k], v)] for (k,v) in orig_metrics.items()}\n",
    "#     print(stat)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1627a85",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f14ab",
   "metadata": {},
   "source": [
    "### Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "25c6d438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x217b5feb290>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMoAAANBCAYAAAARI1KsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAC4BElEQVR4nOzdfXyT1f3/8Xca2rSlNygUTNcoMgroSlcVWm/KnYoibDhdwU20gjhwzP3GnSg4bLuhTKvg/Dpm8YY7dagdc86xDZ2AMJCKUnEKypBKoVGqlKYtbVqS/P5gZJS20JTmStq8no8Hj0euc51znU/rMc31yTnnMnk8Ho8AAAAAAACAEBcW6AAAAAAAAACAYECiDAAAAAAAABCJMgAAAAAAAEASiTIAAAAAAABAEokyAAAAAAAAQBKJMgAAAAAAAEASiTIAAAAAAABAktQl0AEYye12q6ysTLGxsTKZTIEOBwAAAECAeDweVVVVKTExUWFhzB8AABwXUomysrIy2Wy2QIcBAAAAIEiUlpYqKSkp0GEAAIJESCXKYmNjJR3/YxgXFxfgaAAAAAAEisPhkM1m894jAAAghVii7MRyy7i4OBJlAAAAANiSBQDQSEglynB6drtddru91fWtVqusVqsfI0JnxViDURhrAAAAAHxBogxeBQUFysvLa3X9nJwc5ebm+i8gdFqMNRiFsQajkJSFURhrAAD4l8nj8XgCHYRRHA6H4uPjVVlZydLLZpz6wau2tlaZmZmSpM2bNysqKqpRfT54oa0YazAKYw1Gyc3NJSkLQzDW2g/3BgCA5pAoCyK97/9roENoxF1fp9LFWZIk24xChUVEBjiipkp+MybQIaAd1NTUKCYmRpJUXV2trl27BjgitBfe13zH+1rHRFIWRmGstZ9gvzcAAAQGSy/hdaz6sFzVh73HnoZ67+v6rz6XKTyiUX1zzLnqEnOuYfGh/QRj8uKEi+b/neQFAJ8F8/vaj//4ZTPva61fOucvvK+1DWPNd4w1AEBHQqIMXtXFf1Plv/7Q7LmvXprTpCz+qh+rW+YEf4cFAG3GFwAwCmMNRmGsAQDgXyTK4BWTdoOi+ma0ur6ZD11oIz7kwyh8AQCjMNZgFMYaAAD+RaIMXl1IRsAgfMiHUfgCAEZhrMEojDUAAPyLRBkAw/EhH0bhCwAYhbEGozDWAADwrzCjOnI6nbrvvvuUmJioqKgoZWRk6M033zxju9zcXJlMpib/IiODb7NvAK3TJeZcWc7r2+p/3BAAAAAAAIxg2IyyiRMnqrCwUNOnT1dycrKWL1+u0aNHa/369d5HWp/O73//e8XExHiPzWazP8MFAAAAAABAiDEkUVZUVKTVq1crPz9fs2fPliRlZ2crJSVFc+bM0ZYtW854jaysLPXo0cPfoQIAAAAAACBEGbL0srCwUGazWVOmTPGWRUZGavLkydq6datKS0vPeA2PxyOHwyGPx+PPUAEAAAAAABCiDEmU7dixQ/369VNcXFyj8vT0dElScXHxGa/Rp08fxcfHKzY2Vrfddpu++uorf4QKAAAAAACAEGXI0ku73S6r1dqk/ERZWVlZi23POecc3XPPPbriiitksVi0adMm/e53v1NRUZG2b9/eJPl2MqfTKafT6T12OBxn8VMAAAAAAACgMzMkUVZbWyuLxdKk/MSTK2tra1ts+4tf/KLR8Q9/+EOlp6drwoQJWrJkie6///4W2y5cuFB5eXltjBoAAAAAAAChxJCll1FRUY1mdp1QV1fnPe+LW2+9Veedd57eeuut09abO3euKisrvf9asxcaAAAAAAAAQpMhM8qsVqsOHjzYpNxut0uSEhMTfb6mzWbT4cOHT1vHYrE0O5MNAAAAAAAAOJUhM8rS0tL02WefNdkjbNu2bd7zvvB4PCopKVFCQkJ7hQgAAAAAAIAQZ0iiLCsrSy6XS0uXLvWWOZ1OLVu2TBkZGbLZbJKk/fv3a/fu3Y3alpeXN7ne73//e5WXl2vUqFH+DRwAAAAAAAAhw5CllxkZGRo3bpzmzp2rQ4cOqW/fvlqxYoVKSkr03HPPeetlZ2dr48aN8ng83rILLrhAt9xyiwYOHKjIyEht3rxZq1evVlpamqZOnWpE+AAAAAAAAAgBhiTKJGnlypWaP3++Vq1apYqKCqWmpuqNN97Q0KFDT9tuwoQJ2rJli/74xz+qrq5OF1xwgebMmaMHHnhA0dHRBkUPAAAAAACAzs6wRFlkZKTy8/OVn5/fYp0NGzY0KXvmmWf8GBUAAAAAAABwnCF7lAEAAAAAAADBjkQZAAAAAAAAIBJlAAAAAAAAgCQSZQAAAAAAAIAkEmUAAAAAAACAJBJlAAAAAAAAgCQSZQAAAAAAAIAkEmUAAAAAAACAJBJlAAAAAAAAgCQSZQAAAAAAAIAkEmUAAAAAAACAJBJlAAAAAAAAgCQSZQAAAAAAAIAkqUugAwgmbrdb9fX1Aev/W7HmgPV9NtweqbzGpWOeQEcCAAAAAADQdiTK/qu+vl779u2T2+0OWAy5I3oGrO+z41HF0WP6zebDOlwXuN8fAAAAAADA2SBRJsnj8chut8tsNstmsyksLDArUuujHAHp96x5PIo58rV+PLBBS96rFBPLAAAAAABAR0SiTNKxY8d09OhRJSYmKjo6OmBxmLrUBazvsxUVd44G9qpVbIRDjnpSZQAAAAAAoONhM39JLpdLkhQRERHgSDouk7mLzGFh6hrBkAIAAAAAAB0TWY2TmEymQIfQ4YXxKwQAAAAAAB0USy9b0Pv+v/rluiW/GeOX6wIAAAAAAODsMKMsSH3Xdo4clZU+tTlYul+Z37nATxEBAAAAAAB0biTKAAAAAAAAALH0MqitLPg/vfP2OtUePaq7Z8zRmJvGS5Lm/vwnKtn7HzU01Ou8xG8pN///1KNnr1Zdc8+uj7XggVmqq61VvdOpG27M0pRfzJYkNdTX6/8e/bU2r39LZrNZPXqep9+/UChJen7JE/rrmlcUFhYmS2SUnnn5z4qKCtwTQgEAAAAAANobibJgZjLplb+/owNflOjHY0YobdDl+pbtfN2bu1Dndu8hSXrud4v1+8W/0fyFi1t1yUTb+XrmD39WhMWiutpaZd90vS4fMkyplw7Wc79brC8+36vVazcowmLR4W++liS9/uof9Nbav2j5mr8pNi5ejiNHFBFh8duPDQAAAAAAEAgkyoLYzT++XZKUdEFvXZZxpT7YtkXfsp2vv71WqDf++LKczjrVO53qdm73Vl+zrq5ODz0wW59+/JHCwsL0ZdlB7f74I6VeOljvvPUP/WJeriIsx5NgJ5Jx7/zzHxp32yTFxsVLkuK6dWvfHxQAAAAAACAIkCjrSEzSB0Vb9dLzBVr553Xq3iNBG9at1ZLHF7b6Ev/3yK91zjnd9fLf31GXLl004ye3q97p9GPQAAAAAAAAHQOb+QexP7/ykqTjT7P8oGirLk2/Uo7KI+oaE6Nu55yrhvp6Fb643KdrOiqPqKc1UV26dFHJ3j16d9MG77lhI2/QS8897U2cnVh6OWzkKL36wjJVOSr/e41KuVyus/75AAAAAAAAggkzylpQ8psxgQ5BLpdL40cNVe3Ro7rvV7/Rt2znq+d5Vv11zau6cdhgxZ9zri7PHKZDX9pbfc2f/L/ZeuAXU/WXwj8o6YILlX7lEO+5O6f9Qv/36K91y+jhCu/SRQm9ztPvVr6q7//wRyr/6ktl3zRKXcxmRUVHq+APr7GZPwAAAAAA6FRIlAWpD0srJEn33PtAo/Lw8HDl//75RmU/v2++JOlbtvO1+eMvTnvdi1JSteafW5s9Fx4RoZm//LVm/vLXTc7dOW267pw2vbXhAwAAAAAAdDgsvQQAAAAAAADEjLJO6Zuvy/XTCTc3Kb98yPBmZ4sBAAAAAACARFmn1L1Hgl75x6ZAhwEAAAAAANChsPTyJB6PJ9AhdFwejySP3PwKAQAAAABAB8WMMh3fIN9kMqm8vFwJCQkymUwBicNzrD4g/Z41j0fHjjpUVedSRa070NEAAAAAAAC0iWGJMqfTqQcffFCrVq1SRUWFUlNTtWDBAo0cOfKMbQ8ePKgZM2Zo3bp1crvdGjFihBYvXqw+ffq0S2xms1lJSUk6cOCASkpK2uWabXGoojZgfZ8dj6rqXPr99iOqczGlDAAAAAAAdEyGJcomTpyowsJCTZ8+XcnJyVq+fLlGjx6t9evXKzMzs8V21dXVGjFihCorKzVv3jyFh4dr8eLFGjZsmIqLi9W9e/d2iS8mJkbJyclqaGhol+u1xV1rNgSs77Ph9kgVtW6SZAAAAAAAoEMzJFFWVFSk1atXKz8/X7Nnz5YkZWdnKyUlRXPmzNGWLVtabLtkyRLt2bNHRUVFGjx4sCTphhtuUEpKih5//HE9/PDD7Ran2WyW2Wxut+v56mCVK2B9AwAAAAAAhDpDNvMvLCyU2WzWlClTvGWRkZGaPHmytm7dqtLS0tO2HTx4sDdJJkkDBgzQNddco1deecWvcQMAAAAAACB0GJIo27Fjh/r166e4uLhG5enp6ZKk4uLiZtu53W7t3LlTgwYNanIuPT1de/fuVVVVVbvHCwAAAAAAgNBjyNJLu90uq9XapPxEWVlZWbPtDh8+LKfTeca2/fv3b7a90+mU0+n0HldWVkqSHA6Hbz+AQdzOo4EOocMJ1v+WwY6x5jvGWtsw1nzHWGsbxprvGGttw1jzXbCOtRNxeTzsswsA+B9DEmW1tbWyWCxNyiMjI73nW2onqU1tJWnhwoXKy8trUm6z2c4cNDqE+CcCHQFCBWMNRmGswSiMNRgl2MdaVVWV4uPjAx0GACBIGJIoi4qKajSz64S6ujrv+ZbaSWpTW0maO3euZs6c6T12u906fPiwunfvLpPJ1PofIIQ5HA7ZbDaVlpY2WToLtCfGGozCWINRGGswCmOtbTwej6qqqpSYmBjoUAAAQcSQRJnVatXBgweblNvtdklq8Y/TueeeK4vF4q3nS1vp+Ey0U2ejdevWrbVh4yRxcXF88IIhGGswCmMNRmGswSiMNd8xkwwAcCpDNvNPS0vTZ5991mR/gm3btnnPNycsLEwDBw7U9u3bm5zbtm2b+vTpo9jY2HaPFwAAAAAAAKHHkERZVlaWXC6Xli5d6i1zOp1atmyZMjIyvHuG7d+/X7t3727S9r333muULPv000/19ttva9y4cUaEDwAAAAAAgBBgyNLLjIwMjRs3TnPnztWhQ4fUt29frVixQiUlJXruuee89bKzs7Vx48ZGT56ZNm2annnmGY0ZM0azZ89WeHi4Fi1apF69emnWrFlGhB/SLBaLcnJymn2gAtCeGGswCmMNRmGswSiMNQAA2o/JY9DzkOvq6jR//ny98MILqqioUGpqqn7961/r+uuv99YZPnx4k0SZJB04cEAzZszQunXr5Ha7NXz4cC1evFh9+/Y1InQAAAAAAACEAMMSZQAAAAAAAEAwM2SPMgAAAAAAACDYkSgDAAAAAAAARKIMAAAAAAAAkESiDAAAAAAAAJAkdQl0AEZyu90qKytTbGysTCZToMMBAAAAECAej0dVVVVKTExUWBjzBwAAx4VUoqysrEw2my3QYQAAAAAIEqWlpUpKSgp0GACAIBFSibLY2FhJx/8YxsXFBTgaAAAAAIHicDhks9m89wgAAEghlig7sdwyLi6ORBkAAAA6HLvdLrvd3ur6VqtVVqvVjxF1fGzJAgA4WUglygAAAICOrKCgQHl5ea2un5OTo9zcXP8FBABAJ2PyeDyeQAdhFIfDofj4eFVWVjKjDAAAAKfldrtVX18f6DAaOXTokMrLy73HTqdTt956qyTppZdeksViaVQ/ISFBPXv2NDTGYBMREdHsZv3cGwAAmkOiDAAAADhFfX299u3bJ7fbHehQTsvtdqu0tFSSZLPZeHpjM8LCwnThhRcqIiKiUTn3BgCA5rD0EgAAADiJx+OR3W6X2WwO+uSTy+VSbW2tJKl3794ym80Bjii4uN1ulZWVyW636/zzz2c/MgDAGZEoAwAAAE5y7NgxHT16VImJiYqOjg50OKflcrm8ryMjI0mUNSMhIUFlZWU6duyYwsPDAx0OACDIBe/XYwAAAEAAnEg+nbpUDx3Tif+OJycVAQBoCYkyAAAAoBks0+sc+O8IAPAFSy8BAACAM8mN99N1K/1zXQAA0CbMKAMAAADgsx49eqikpKTZc4MGDdKGDRvOuo833nhDw4cPlyRt375dt9xyi/dcQUGBBgwYoLS0NH3zzTdNjgEAaAtmlAEAAAAIeoMGDdLLL7/sPX7iiSe0bNkyXXHFFc0eAwDQFswoAwAAADqACRMmaNCgQUpNTdWYMWP05ZdfaurUqVq1apW3zr59+3TeeeepoaFBVVVVuuWWWzRgwAANGTJEU6dO1cSJE0/bx3/+8x9de+21Sk1NVVpaml577TXvuddff10XXXSRUlNTNWfOnEbttmzZorS0NKWkpGjSpEk6duyY99yCBQt00UUXKS0tTWlpafriiy9a7L+hoUHTpk1TcnKy0tPTtX79eu+5DRs2KC0tTZKUlZWlvXv3auLEicrKympyDABAWzGjDAAAAOgAnnjiCSUkJEiSfvOb3yg3N1d33HGHJk6cqNtvv12StHz5ck2YMEHh4eGaN2+eoqKitGvXLlVXV+vKK6/UZZdddto+JkyYoDvvvFNTp07Vnj17dPnll+uSSy5RVFSUJk2apE2bNuniiy/W0qVLvcsb6+vrdcstt2jZsmW69tprtW7dOi1fvlySVFFRoccee0x2u11RUVE6evSowsJa/q5+6dKl+vTTT/Xxxx9Lkq6//vpm6xUWFqp37956+eWXvcmzU48BAGgLZpQBAAAAHcBLL72kQYMGKSUlRc8++6yKi4t15ZVXyuVy6eOPP5bH49HKlSs1adIkSdI///lPTZo0SSaTSbGxsY3292pOVVWVPvjgA02ePFmSlJycrMzMTG3atEnvvvuuUlNTdfHFF0uSJk+erIiICEnS7t271aVLF1177bWSpOuuu059+vSRJMXFxSk5OVm33XabCgoKdPjwYUVGRrYYwz//+U9lZ2crIiJCERERuvPOO8/ulwYAgI9IlAEAAABBbvPmzXryySe1du1a/fvf/9aiRYtUV1cnSfr+97+vv/zlL9qwYYN69OihlJSUZq9hMpl87relNme61onzZrNZ7777rqZPn65Dhw7p8ssv16ZNm866fwAA/IWllwAAAGfJbrfLbre3ur7VapXVavVjROhsKioqFBsbq+7du6u+vl4FBQXec6NHj9att96qsLCwRjOwrr76aq1YsUJDhw5VTU2NXnnlFV1yySUt9hEbG6tLL71Uy5Yt009+8hP95z//8SboTiy93L17twYMGKDnn39e9fX1kqQBAwbo2LFjWr9+vUaMGKG33npLe/fulXR8llpVVZWGDBmiIUOG6OOPP9aOHTs0ZMiQZmO49tpr9cILL+jWW2+Vx+PRsmXL2uPXBwBAq5EoAwAAOEsFBQXKy8trdf2cnBzl5ub6LyC0v9zKgHY/atQovfDCC+rfv7+6d++ua6+9VgcPHpQkJSQk6Dvf+Y7+8pe/aOnSpd42Dz74oCZPnqyLLrpIPXr00He/+11169bttP28+OKLuvvuu/XUU0/JZDLp2Wef1fnnny9Jev7553XTTTcpIiJCo0aNUvfu3SVJERERevnllzVt2jS5XC4NHjxY3/3udyVJlZWVysrKUk1NjUwmk5KTk3XHHXe02P9PfvIT/fvf/9bFF1+sc845R0OGDNH7779/Nr86AAB8YvJ4PJ5AB2EUh8Oh+Ph4VVZWKi4uLtDhAACATuLUGWW1tbXKzMyUdHzJXFRUVKP6zCgLbnV1ddq3b58uvPDC0+6nFQxcLpd27NghSbrkkktkNpu95xoaGuRyuRQZGamamhpdf/31+vnPf37Gvco6m5b+e3JvAABoDjPKAAAAztKpia+amhrv67S0NHXt2jUQYSHEVVRU6IYbbpDL5VJdXZ1uvPFGjR8/PtBhAQAQ1AzbzN/pdOq+++5TYmKioqKilJGRoTfffLNVbQ8ePKjx48erW7duiouL04033qjPP//czxEDAAAAHVfPnj31/vvvq7i4WLt379YjjzziXU6ZlpbW5J8vm+yfjUOHDjXb/7333mtI/wAAnI5hM8omTpyowsJCTZ8+XcnJyVq+fLlGjx6t9evXe5cmNKe6ulojRoxQZWWl5s2bp/DwcC1evFjDhg1TcXGxd28EnD02IgYAAOj87rrrLt11110B679nz54qLi4OWP8AAJyOIYmyoqIirV69Wvn5+Zo9e7YkKTs7WykpKZozZ462bNnSYtslS5Zoz549Kioq0uDBgyVJN9xwg1JSUvT444/r4YcfNuJHCAlsRAyjkJQFAHQEIbSVb6fGf0cAgC8MSZQVFhbKbDZrypQp3rLIyEhNnjxZ8+bNU2lpqWw2W4ttBw8e7E2SSccfQX3NNdfolVdeIVHWjqZOnaqxY8d6j1uzETHQFiRlAQDBLDw8XCaTSeXl5UpISJDJZAp0SC1yuVze13V1dY0288fxJFl5eblMJpPCw8MDHQ4AoAMwJFG2Y8cO9evXr8nTZNLT0yVJxcXFzSbK3G63du7cqTvvvLPJufT0dK1bt05VVVWKjY31T+Ahho2IYRSSsjAKsxcBtIXZbFZSUpIOHDigkpKSxieP7A9ITC1xe6SvHcdnTJV8uFlhwZjT63Z+QLs3mUxKSkoiiQgAaBVDEmV2u73ZG48TZWVlZc22O3z4sJxO5xnb9u/fv9n2TqdTTqfTe+xwOHyOHUD7IykLozB7EUBbxcTEKDk5WQ0NDY1PPDUuMAG14GiDR2MKjv8d/WBqV0WHB2Gm7J7tAe0+PDycJBkAoNUMSZTV1tbKYrE0KY+MjPSeb6mdpDa1laSFCxf6dIMUcLnxgY6gsfqT9nN4yCpFBOEHr9zKQEfQMTHWfMdYa5sAj7WpVW6NnfK/xGttg0eZy45KkjZPilbUKTeU1qrHpdzFhsbYBGOtbXhf8x1j7YzMZnPTBMvsfwcmmBa4amr0xbwYSZLl/1Urki+bAAA4K4YkyqKiohrN7Dqhrq7Oe76ldpLa1FaS5s6dq5kzZ3qPHQ5Hi3uhAQA6H2tsmKwnrc6vOSl5kXaeWV2DMXkBAAAAIGAMSZRZrVYdPHiwSfmJfWMSExObbXfuuefKYrE0u7/MmdpKx2eiNTcbDQAAAAAAADhVmBGdpKWl6bPPPmuyR9i2bdu855sTFhamgQMHavv2pvsabNu2TX369GEjfwAAAAAAALQLQxJlWVlZcrlcWrp0qbfM6XRq2bJlysjI8C6H3L9/v3bv3t2k7XvvvdcoWfbpp5/q7bff1rhxwbWZKgAAAAAAADouQ5ZeZmRkaNy4cZo7d64OHTqkvn37asWKFSopKdFzzz3nrZedna2NGzfK4/nfHjLTpk3TM888ozFjxmj27NkKDw/XokWL1KtXL82aNcuI8AEAAAAAABACDEmUSdLKlSs1f/58rVq1ShUVFUpNTdUbb7yhoUOHnrZdbGysNmzYoBkzZmjBggVyu90aPny4Fi9erISEBIOiBwAAAAAAQGdnWKIsMjJS+fn5ys/Pb7HOhg0bmi1PSkrSq6++6qfIAAAAAAAAAIP2KAMAAAAAAACCHYkyAAAAAAAAQAYuvQQAAPCb3MpAR9BYTY20MOb46wfsUteugY0HAAAArcKMMgAAAAAAAEAkygAAAAAAAABJLL0EQhNLlAAAAAAAaIIZZQAAAAAAAICYURZcmOUDAAAAAAAQMMwoAwAAAAAAAMSMMgCAPzFTFgAAAEAHwowyAAAAAAAAQCTKAAAAAAAAAEksvQQAAAA6DLvdLrvd7j2ura31vi4uLlZUVFSj+larVVar1bD4AADo6EiUAQAAAB1EQUGB8vLymj2XmZnZpCwnJ0e5ubl+jgoAgM7DsETZkSNHNGfOHP3pT3/S0aNHlZ6erscff1yXXnrpGdsWFRVp+fLl2rZtm3bu3Kljx47J4/EYEDUAAAAQPKZOnaqxY8e2uj6zyQAA8I0hiTK3260xY8boww8/1L333qsePXpoyZIlGj58uN5//30lJyeftv3atWv17LPPKjU1VX369NFnn31mRNgAAABAUGEpJQAA/mXIZv6FhYXasmWLli9frpycHP3sZz/Thg0bZDablZOTc8b2P/3pT1VZWant27dr5MiRBkQMAAAAAACAUGNYoqxXr166+eabvWUJCQkaP368/vznP8vpdJ62fa9evZpsTAoAAAAAAAC0J0MSZTt27NCll16qsLDG3aWnp+vo0aMspQQAAAAAAEDAGZIos9vtze6lcKKsrKzML/06nU45HI5G/wAAAAAAAIDm+LyZv9vtVn19favqWiwWmUwm1dbWymKxNDkfGRkpSaqtrfU1jFZZuHBhi4/PBgAAaC92u112u917fPJnm+Li4iZbSLAhOwAAQHDyOVH2zjvvaMSIEa2qu2vXLg0YMEBRUVHN7kNWV1cnSX7bf2zu3LmaOXOm99jhcMhms/mlLwCtxw0lgM6moKCgxS/nMjMzm5Tl5OQoNzfXz1EBAADAVz4nygYMGKBly5a1qu6JG1ur1dropviEE2WJiYm+htEqFoul2ZlsAAKLG0oAnc3UqVM1duzYVtcn+Q8AABCcfE6UnXfeeZo4caJPbdLS0rRp0ya53e5GG/pv27ZN0dHR6tevn69hAOjAuKEE0Nkw8xUAAKBz8DlR1hZZWVkqLCzUmjVrlJWVJUn6+uuv9eqrr+r73/9+o1lfe/fulSR9+9vfNiI0AAHADSUAAAAAIBgZlii7/PLLNWnSJH3yySfq0aOHlixZIpfL1WT51TXXXCNJKikp8ZZ98cUXWrVqlSRp+/btkqQFCxZIki644ALdfvvtBvwUAAAAAAAA6MwMSZSZzWatXbtW9957r5588knV1tZq8ODBWr58ufr373/G9vv27dP8+fMblZ04HjZsGImydsIG6wA6G97XAAAAAPjC5PF4PIEOwigOh0Px8fGqrKxUXFxcoMMJOrm5uS1usN4cNlgHEOx4XwMAtIR7AwBAc0iUwevUmRdnwswLAMGO9zUAQEu4NwAANCekEmWVlZXq1q2bSktL+WMIAAAAhDCHwyGbzaYjR44oPj4+0OEAAIKEIXuUBYuqqipJks1mC3AkAAAAAIJBVVUViTIAgFdIzShzu90qKytTbGysTCZToMPpEE5808YsPPgbYw1GYazBKIw1GIWx1jYej0dVVVVKTExUWFhYoMMBAASJkJpRFhYWpqSkpECH0SHFxcXxwQuGYKzBKIw1GIWxBqMw1nzHTDIAwKn46gQAAAAAAAAQiTIAAAAAAABAEokynIHFYlFOTo4sFkugQ0Enx1iDURhrMApjDUZhrAEA0H5CajN/AAAAAAAAoCXMKAMAAAAAAABEogwAAAAAAACQRKIMAAAAAAAAkESiDAAAAAAAAJBEogwAAAAAAACQJHUJdABGcrvdKisrU2xsrEwmU6DDAQAAABAgHo9HVVVVSkxMVFgY8wcAAMeFVKKsrKxMNpst0GEAAAAACBKlpaVKSkoKdBgAgCARUomy2NhYScf/GMbFxQU4GgAAAACB4nA4ZLPZvPcIAABIIZYoO7HcMi4ujkRZM+x2u+x2e6vrW61WWa1WP0YEAGeH9zUAwJmwJQsA4GQhlSjD6RUUFCgvL6/V9XNycpSbm+u/gADgLPG+BgAAAMAXJo/H4wl0EEZxOByKj49XZWUlM8qacerMi9raWmVmZkqSNm/erKioqEb1mXkBINjxvgYAaAn3BgCA5pAoQ4tqamoUExMjSaqurlbXrl0DHBEAnB3e1wAEK5fLpYaGhkCH0SmFh4fLbDY3KefeAADQHMOWXjqdTj344INatWqVKioqlJqaqgULFmjkyJGnbbdmzRq9/PLLeu+99/Tll1/KZrPpe9/7nubPn69u3boZEzwAAADgJ9XV1Tpw4IBC6PtrQ5lMJiUlJXm/KAEA4HQMS5RNnDhRhYWFmj59upKTk7V8+XKNHj1a69ev9y6Dac6UKVOUmJio2267Teeff74++ugjPfXUU1q7dq0++OCDJstmAAAAgI7C5XLpwIEDio6OVkJCAhvLtzOPx6Py8nIdOHBAycnJzc4sAwDgZIYkyoqKirR69Wrl5+dr9uzZkqTs7GylpKRozpw52rJlS4ttCwsLNXz48EZll112me644w69+OKLuuuuu/wZOgAAAOA3DQ0N8ng8SkhI4AtgP0lISFBJSYkaGhpIlAEAzijMiE4KCwtlNps1ZcoUb1lkZKQmT56srVu3qrS0tMW2pybJJOmmm26SJO3atavdYwUAAACMxkwy/+F3CwDwhSEzynbs2KF+/fo12SQzPT1dklRcXCybzdbq63355ZeSpB49erRfkAAMc+qTCM+EJxECAELJwBUD/XLdj+74yC/XBQCgMzEkUWa325u9yT1RVlZW5tP1HnnkEZnNZmVlZZ22ntPplNPp9B47HA6f+gHgHwUFBcrLy2t1/ZycHOXm5vovIAA4S3wBAAAA0DkYkiirra2VxWJpUh4ZGek931ovvfSSnnvuOc2ZM0fJycmnrbtw4UKfbsYBGGPq1KkaO3as97i2ttb7UI/Nmzc32aOFm0kAwY4vANDZ9ejRQ9u3b9e0adO0ePFi9e/fv92u/frrr2v9+vVavHhxu10TAIC2MiRRFhUV1Whm1wl1dXXe862xadMmTZ48Wddff70eeuihM9afO3euZs6c6T12OBw+LfEE4B+nzqSoqanxvk5LS1PXrl0DERYAtBlfACBUrF27tt2vOXbs2Eb//wAAEEiGJMqsVqsOHjzYpPzEEoXExMQzXuPDDz/U2LFjlZKSosLCQnXpcubQLRZLszPZAAAA2hNfAKCzef3113XfffcpPDxco0aN8pb37t1br732mtLS0rRgwQK9+OKL3s/bf/7zn3XBBRfIZDLpgQce0F//+lfV1NQoJydHEyZMaLGv5cuX67XXXtNrr72mDRs26J577tGQIUP0r3/9Sx6PRy+++KIWLVqk999/X9HR0VqzZo2+9a1vafny5Vq5cqViYmL0n//8Rz169NDKlSvVu3dvf/96AACdmCFPvUxLS9Nnn33WZI+wbdu2ec+fzt69ezVq1Cj17NlTa9euVUxMjL9CBQAAAELaoUOHNGnSJP3xj3/Uzp071bdvX33zzTeN6lRUVOixxx7TBx98oOLiYm3ZskW9evXynjeZTNqxY4f+/ve/6+c//7lKSkpa3f/u3bt11113aefOnfrBD36gq6++Wvfff78++ugjDRo0SE888YS37r/+9S898sgj+uSTT/S9731PU6ZMOdsfHwAQ4gxJlGVlZcnlcmnp0qXeMqfTqWXLlikjI8O7HHL//v3avXt3o7ZffvmlrrvuOoWFhekf//iHEhISjAgZAAAACEnvvvuuUlNTdfHFF0uSJk+erIiIiEZ14uLilJycrNtuu00FBQU6fPiwd/9hSbrrrrskSX369NHQoUP1zjvvtLr/vn376rLLLpMkDRo0SH379tWAAQMkSenp6dqzZ4+37pVXXqmLLrpIkjRlyhRt2LBBLperDT81AADHGbL0MiMjQ+PGjdPcuXN16NAh9e3bVytWrFBJSYmee+45b73s7Gxt3LhRHo/HWzZq1Ch9/vnnmjNnjjZv3qzNmzd7z/Xq1UsjR4404kcAAAAAQpLJZGpSZjab9e6772rLli3asGGDLr/8cv3hD3/QkCFDWn2NlpyccDObzU2Ojx075kP0AAD4xpBEmSStXLlS8+fP16pVq1RRUaHU1FS98cYbGjp06Gnbffjhh5KkRx99tMm5YcOGkSgDAABAp/LRHR8FtP8rrrhCkyZN0u7duzVgwAA9//zzqq+vb1SnqqpKVVVVGjJkiIYMGaKPP/5YO3bs8CbKli1bptzcXJWUlGjTpk2Nlku2p61bt3rjfPbZZzVixAiZzWa/9AUACA2GJcoiIyOVn5+v/Pz8Futs2LChSdnJs8sAAAAA+FdCQoKef/553XTTTYqIiNCoUaPUvXv3RnUqKyuVlZWlmpoamUwmJScn64477vCed7lcuuSSS1RTU6Mnn3zSbxvsX3nllbrvvvv0n//8R927d9fKlSv90g8AIHSYPCGUiXI4HIqPj1dlZaXi4uICHU7Qq6mp8T44obq6mid2wW8YazAKYw1GYayhterq6rRv3z5deOGFjZYYdmQmk0kVFRXq1q2bX/s5+WmZp9PS75h7AwBAcwzZzB8AAAAAAAAIdoYtvQQAAADQ+TW3YOXQoUO67rrrmpSPHDnytFuznM7EiRM1ceLENrUFAKAlJMoAAACAAOvsu6H07NlTxcXFAem7s/9uAQDti0QZAAAAECDh4eEymUwqLy9XQkKCTCZToEPqVDwej8rLy2UymRQeHh7ocAAAHQCJsiAycMXAQIfQiNvp9r5OfzFdYZbg29Iu0I9PB3B6vK/5jvc1ILSYzWYlJSXpwIEDKikpCXQ4nZLJZFJSUpLMZnOgQwEAdAAkygAAAIAAiomJUXJyshoaGs5Y99ChQyovL2/1tRMSEtSzZ8+zCa/DCw8PJ0kGAGg1EmUAAABAgJnN5lYlc55//nnl5eW1+ro5OTnKzc09i8gAAAgtJMoAAACADmLq1KkaO3as97i2tlaZmZmSpM2bNysqKqpRfavVamh8AAB0dCTKAAAAgA7CarU2Sn7V1NR4X6elpalr166BCAsAgE4j+HYxBgAAAAAAAAKAGWVACOJJhL7jSYQAAAAA0PkF390oAAAAAAAAEAAkygAAAAAAAACRKAMAAAAAAAAksUcZAADoBNh70XfsvQgAANBU8H1qAwAAAAAAAAKARBkAAAAAAAAgEmUAAAAAAACAJBJlAAAAAAAAgCQSZQAAAAAAAIAkEmUAAAAAAACAJBJlAAAAAAAAgCSpS6ADAAAAADqKgSsGBjqERtxOt/d1+ovpCrME3/fgH93xUaBDAACg1YLvLykAAAAAAAAQAMwog1fDkQYdO3LMe+xu+N83lLX7axUW3jiv2qVbF4V3CzcsPgAAAAAAAH8iUQavw+sPq/zP5c2e2/fQviZlCTcmqNdNvfwdFgC0GV8AAAAAAPAFiTJ4nTviXMVdEtfq+l26MXwABDe+AAAAAADgCzId8ArvFs5MCgCdCl8AAAAAAPAFdwQAgE6LLwAAAAAA+IJEGQDDsW8UAAAAACAYkSgDYDj2jQIAAAAABCMSZQAMx75RAAAAAIBgxN0nAMOxbxQAAAAAIBiFnbkKAAAAAAAA0PmRKAMAAAAAAADE0ksAAICzxtN8AQAAOgcSZQAAAGeJp/nCKCRlAQDwLxJlAAAAZ4mn+cIoJGUBAPAvPqUBAACcJZ7mC6OQlAUAwL8M28zf6XTqvvvuU2JioqKiopSRkaE333yzVW0PHjyo8ePHq1u3boqLi9ONN96ozz//3M8RAwAAAMElvFu4onpHtfofCVwAAHxjWKJs4sSJWrRokSZMmKDf/va3MpvNGj16tDZv3nzadtXV1RoxYoQ2btyoefPmKS8vTzt27NCwYcP0zTffGBQ9AAAAAAAAOjtD5mIXFRVp9erVys/P1+zZsyVJ2dnZSklJ0Zw5c7Rly5YW2y5ZskR79uxRUVGRBg8eLEm64YYblJKSoscff1wPP/ywET8CAAAAAAAAOjlDZpQVFhbKbDZrypQp3rLIyEhNnjxZW7duVWlp6WnbDh482Jskk6QBAwbommuu0SuvvOLXuAEAAAAAABA6DJlRtmPHDvXr109xcY03Hk1PT5ckFRcXy2azNWnndru1c+dO3XnnnU3Opaena926daqqqlJsbGyz/TqdTjmdTu9xZWWlJMnhcLT5Z/EnV60r0CF0OMH63zLYMdZ8x1hrG8aa7xhrbcNY8x1jrW0Ya74L1rF2Ii6PxxPgSAAAwcSQRJndbpfVam1SfqKsrKys2XaHDx+W0+k8Y9v+/fs3237hwoXKy8trUt5cUg4dU/xP4wMdAkIEYw1GYazBKIw1GCXYx1pVVZXi44M7RgCAcQxJlNXW1spisTQpj4yM9J5vqZ2kNrWVpLlz52rmzJneY7fbrcOHD6t79+4ymUyt/wFCmMPhkM1mU2lpaZMZgUB7YqzBKIw1GIWxBqMw1trG4/GoqqpKiYmJgQ4FABBEDEmURUVFNVoCeUJdXZ33fEvtJLWprXQ8wXZqkq1bt26tihmNxcXF8cELhmCswSiMNRiFsQajMNZ8x0wyAMCpDNnM32q1ym63Nyk/UdbStzjnnnuuLBZLm9oCAAAAAAAAvjAkUZaWlqbPPvusyUae27Zt855vTlhYmAYOHKjt27c3Obdt2zb16dOnxY38AQAAAAAAAF8YkijLysqSy+XS0qVLvWVOp1PLli1TRkaGd3P9/fv3a/fu3U3avvfee42SZZ9++qnefvttjRs3zojwQ5rFYlFOTk6z+8QB7YmxBqMw1mAUxhqMwlgDAKD9mDwGPQ95/Pjx+tOf/qQZM2aob9++WrFihYqKivTPf/5TQ4cOlSQNHz5cGzdubPSI5qqqKl1yySWqqqrS7NmzFR4erkWLFsnlcqm4uFgJCQlGhA8AAAAAAIBOzpDN/CVp5cqVmj9/vlatWqWKigqlpqbqjTfe8CbJWhIbG6sNGzZoxowZWrBggdxut4YPH67FixeTJAMAAAAAAEC7MWxGGQAAAAAAABDMDNmjDAAAAAAAAAh2JMoAAAAAAAAAkSgDAAAAAAAAJBm4mX8wcLvdKisrU2xsrEwmU6DDAQAAABAgHo9HVVVVSkxMVFgY8wcAAMeFVKKsrKxMNpst0GEAAAAACBKlpaVKSkoKdBgAgCARUomy2NhYScf/GMbFxQU4GgAAAACB4nA4ZLPZvPcIAABIIZYoO7HcMi4ujkQZAAAAOhy73S673d7q+larVVar1Y8RdXxsyQIAOFlIJcoAAACAjqygoEB5eXmtrp+Tk6Pc3Fz/BQQAQCdDogwAAADoIKZOnaqxY8d6j2tra5WZmSlJ2rx5s6KiohrVZzYZAAC+IVEGAAAAdBCnLqWsqanxvk5LS1PXrl0DERYAAJ2GYc9Bdjqduu+++5SYmKioqChlZGTozTffbFXbgwcPavz48erWrZvi4uJ044036vPPP/dzxAAAAAAAAAglhiXKJk6cqEWLFmnChAn67W9/K7PZrNGjR2vz5s2nbVddXa0RI0Zo48aNmjdvnvLy8rRjxw4NGzZM33zzjUHRAwAAAAAAoLMzZOllUVGRVq9erfz8fM2ePVuSlJ2drZSUFM2ZM0dbtmxpse2SJUu0Z88eFRUVafDgwZKkG264QSkpKXr88cf18MMPG/EjAAAAAAAAoJMzZEZZYWGhzGazpkyZ4i2LjIzU5MmTtXXrVpWWlp627eDBg71JMkkaMGCArrnmGr3yyit+jRsAAAAAAAChw5BE2Y4dO9SvXz/FxcU1Kk9PT5ckFRcXN9vO7XZr586dGjRoUJNz6enp2rt3r6qqqto9XgAAAAAAAIQeQxJldru92UdTnygrKytrtt3hw4fldDrb1FY6/gABh8PR6B8AAAAAAADQHEP2KKutrZXFYmlSHhkZ6T3fUjtJbWorSQsXLlReXp7P8QbKrgEXBTqEDuei3bsCHUKHxFjzHWOtbRhrvmOstQ1jzXeMtbYJtrF21O32vt59yaWKDjPsWV2txlgDAHQkhvwljYqKktPpbFJeV1fnPd9SO0ltaitJc+fOVWVlpfff6fZCAwAAAAAAQGgzZEaZ1WrVwYMHm5Tb7XZJUmJiYrPtzj33XFksFm89X9pKx2eiNTcbDQAAAAAAADiVIYmytLQ0rV+/Xg6Ho9GG/tu2bfOeb05YWJgGDhyo7du3Nzm3bds29enTR7GxsX6JGQAAoLXKjx1T+bFjra6f0KWLEroY8jEMAAAAPjDkE1pWVpYee+wxLV26VLNnz5Z0fDnlsmXLlJGRIZvNJknav3+/jh49qgEDBjRqe//992v79u3ep19++umnevvtt73XAgAACKSXj1RoyTfftLr+tO7ddU+PBD9GBAAAgLYwJFGWkZGhcePGae7cuTp06JD69u2rFStWqKSkRM8995y3XnZ2tjZu3CiPx+MtmzZtmp555hmNGTNGs2fPVnh4uBYtWqRevXpp1qxZRoQPAABwWrd0O0dXx/xvlnud263bSvdLkl6wna/IUzZYZzYZAABAcDLsU9rKlSs1f/58rVq1ShUVFUpNTdUbb7yhoUOHnrZdbGysNmzYoBkzZmjBggVyu90aPny4Fi9erIQEvokFAACBd+pSypOfRDggMjIon0QIAACApgxLlEVGRio/P1/5+fkt1tmwYUOz5UlJSXr11Vf9FBkAAAAAAAAg8fUmAAAAAAAAIBJlAAAAAAAAgCQDl14i+PFoewAAAAAAEMrIcsCLR9vDKCRlAQAAAADBiDtPePFoexiFpCyMQlIWQHu7aPeuQIfQSE1NjRQTI0kasOMDde3aNcARAQDQsXE3AC8ebQ+jkJSFUUjKAgAAAPAFd58ADEdSFkYhKQsAAADAF9wRAAA6LZKyAAAAAHzBHQIAAAAAAAAgEmUAAAAAAACAJBJlAAAAAAAAgCQSZQAAAAAAAIAkEmUAAAAAAACAJBJlAAAAAAAAgCQSZQAAAAAAAIAkqUugAwAAADhbF+3eFegQGqmpqZFiYiRJA3Z8oK5duwY4IgAAALSGYTPKjhw5oilTpighIUFdu3bViBEj9MEHH7SqbVFRkaZNm6bLLrtM4eHhMplMfo4WAAAAAAAAocaQRJnb7daYMWP00ksv6Z577tGjjz6qQ4cOafjw4dqzZ88Z269du1bPPvusTCaT+vTpY0DEAAAAAAAACDWGJMoKCwu1ZcsWLV++XDk5OfrZz36mDRs2yGw2Kycn54ztf/rTn6qyslLbt2/XyJEjDYgYAAAAAAAAocaQPcoKCwvVq1cv3Xzzzd6yhIQEjR8/Xi+88IKcTqcsFkuL7Xv16mVEmHK5XGpoaDCkr+a4rdaA9d0sj0cX1DuPv05MlDtYlrx6PDJVVMjkdAY6EgAAAAAA0IkYkijbsWOHLr30UoWFNZ7Alp6erqVLl+qzzz7TwIED271fp9Mp50nJFIfD0WLd6upqHThwQB6Pp93jaC3XLx8IWN/N6eLx6Oljx46/7tJFriBKlLmrq9Xl2WcDHUmHxabXAAAAAAA0ZUiizG63a+jQoU3Krf+dQVVWVuaXRNnChQuVl5d3xnoul0sHDhxQdHS0EhISAvawgLoAzmZrjltSQ329JMkWEWHckx/OwCOp4pxz5LjrLrlcLpnN5kCHBAAAAAAAOgGfE2Vut1v1/02enInFYpHJZFJtbW2zSysjIyMlSbW1tb6G0Spz587VzJkzvccOh0M2m61JvYaGBnk8HiUkJCgqKsovsbSGJyxYUlHHuU+aXGcxhSksSCaUSdI54eGqjolRQ0MDiTIAAAAAANAufE6UvfPOOxoxYkSr6u7atUsDBgxQVFRUoyWQJ9TV1UmS35JTFovltHufnSpQM8lOiEpJCWj/p3K5XNKOHZKkyIsvCqqElKmuTuHh4YEOAwAAAAAAdCI+J8oGDBigZcuWtaruiaWVVqtVdru9yfkTZYmJib6GAQDoANgPDwAAAEBH4nOi7LzzztPEiRN9apOWlqZNmzbJ7XY32tB/27Ztio6OVr9+/XwNw+92DbjIL9cNtptGAAAAdBx2u73RF9Anb2FSXFzcZKWG1Wr1fnkNAADOzJBNsbKysvTVV19pzZo13rKvv/5ar776qr7//e83Wh65d+9e7d2714iwOpySkhI9/fTTra6fm5vrXd4aTAYNGqQNGzZIku666y6tX79eknT48GFdddVVSktL00MPPdTkGAAAINQVFBTosssu8/7LzMz0nsvMzGx07rLLLlNBQUEAowUAoOMx5KmXWVlZuvzyyzVp0iR98skn6tGjh5YsWSKXy9XkqZTXXHONpONJoRO++OILrVq1SpK0fft2SdKCBQskSRdccIFuv/12A36KwDuRKLv77rtbVT8vL0/Tp0/3PjTBn44dO6YuXXwfTs8++6z39ZtvvqmYmBj961//kiS9/PLLjY4BAABC3dSpUzV27NhW12c2GQAAvjEkUWY2m7V27Vrde++9evLJJ1VbW6vBgwdr+fLl6t+//xnb79u3T/Pnz29UduJ42LBhnTJRVltbq4kTJ+qjjz5SeHi4evXqpf379+uLL75QWlqazj//fL3++uuaPXu2Nm7cqIaGBsXFxemZZ55R//79vcm0IUOGyGw2a926derZs2ezfZlMJj3wwAP661//qpqaGuXk5GjChAmSpF/+8pfav3+/unTpIpvNpueee07nnXeeSkpKlJaWpqlTp+rNN99Udna2pk+f3uz1t2zZomnTpunYsWMaPHiwjh075j03fPhwTZ8+XTExMbr33ntVWVmptLQ0PfbYY02Or7322vb9JQMAAHQwLKUEAMC/DEmUSdI555yjZ599ttEMouacPJPshOHDh8vj8fgpsuD097//XUeOHNEnn3wi6fiyxJ07d2r69OkqLi721rvvvvv02GOPSZJWr16tX/ziF/r73/+up59+WgUFBdq0aZO6det2xv5MJpN27Nihzz//XIMGDdJVV10lm82mWbNm6ZxzztEll1yi/Px85ebmepd/VlZW6jvf+Y4eeeSRFq9bX1+vW265RcuWLdO1116rdevWafny5U3qXXvttfrVr36l1157Ta+99pokNTkGAAAAAADwJ8MSZfDNd7/7Xe3atUvTpk3TsGHDNHr06Gbrvfnmm/q///s/VVVVye126/Dhw23q76677pIk9enTR0OHDtU777yjCRMm6O9//7v+9re/KSwsTHV1derRo4e3TXh4uG677bbTXnf37t3q0qWLdzbYddddpz59+rQpRgAAAAAAAH8yZDN/+K5Pnz765JNPNGrUKP3rX/9SSkqKKioqGtXZv3+/7rnnHr3wwgv697//rdWrV7fb5v0mk0mbN2/Wyy+/rCeeeEIffvihFi1a1Oj60dHRjZ5i6su1AQAAAAAAgg2JsiB14MABmUwmjR07Vo899pg8Ho+6d++uyspKb53KykqFh4fLarXK4/HoqaeeanSN2NjYRvVPZ9myZZKOL33dtGmThgwZooqKCkVHRys+Pl719fVtemrSgAEDdOzYMe+TLd966y2eagoAAAAAAIISSy9bcNHuXQHt/6OPPtLcuXPl8Xh07Ngx3X777bryyiv1ne98RykpKerTp49ef/11/ehHP9J3vvMdde/eXT/4wQ8aXWPWrFkaOXKkoqOjT7uZvyS5XC5dcsklqqmp0ZNPPqnevXvrvPPO0+9+9ztlZWXJarVq5MiROnjwoE8/R0REhF5++WVNmzZNLpdLgwcP1ne/+922/EoAAAAAAAD8yuQJoV3yHQ6H4uPjVVlZqbi4OG95XV2d9u3bpwsvvFCRkZEBjDAwTCaTKioqmmz673K5tGPHDknSJZdcIrPZHIDomhfq/806OrvdLrvd7j2ura1VZmamJGnz5s2KiopqVJ8nfKG91NTUKCYmRpJUXV2trl27BjgidBa8rwEdT0v3BgCA0MaMMgCGKygoUF5eXrPnTtxYniwnJ0e5ubl+jgoA2o73NQAAgM6BRFmIuPvuu/Xuu+82Kd+6davaY1Lhr371K61Zs6ZJ+R//+Ed9+9vfPuvro3OZOnWqxo4d2+r6zLoAEOx4XwMAAOgcWHoplvG1hKWXADobll4CAE5g6SUAoDk89fIkIZQz7PD4bwUAAAAAANobSy8lhYeHy2Qyqby8XAkJCTKZTIEOKSi4XC7v67q6uqCZUebxeFReXi6TyaTw8PBAhwMAAAAAADoJEmWSzGazkpKSdODAAZWUlAQ6nKDhdrv19ddfS5JKSkoUFhY8ExBNJpOSkpKCJnkHAAAAAAA6PhJl/xUTE6Pk5GQ1NDQEOpSAOXTokMrLy73HTqdTd999tyTppZdeksViaVQ/ISFBPXv2NDTGE8LDw0mSAQAAAACAdkWi7CRmszmkky/PP/98i4+2v+qqq5qU8Wh7AMHObrfLbrd7j2tra72vi4uLFRUV1ai+1WrlaYQAAABACOOpl/A69YbyTLihBBDscnNzW/wCoDl8AQAAoYN7AwBAc0iUAQA6Lb4AAAC0hHsDAEBzQmrp5YmcoMPhCHAkAAAjdO3aVX379vWpDX8jACA0nHi/D6F5AwCAVgipRFlVVZUkyWazBTgSAAAAAMGgqqpK8fHxgQ4DABAkQmrppdvtVllZmWJjY2UymQIdTofgcDhks9lUWlrKlHT4FWMNRmGswSiMNRiFsdY2Ho9HVVVVSkxMVFhYWKDDAQAEiZCaURYWFqakpKRAh9EhxcXF8cELhmCswSiMNRiFsQajMNZ8x0wyAMCp+OoEAAAAAAAAEIkyAAAAAAAAQBKJMpyBxWJRTk6OLBZLoENBJ8dYg1EYazAKYw1GYawBANB+QmozfwAAAAAAAKAlzCgDAAAAAAAARKIMAAAAAAAAkESiDAAAAAAAAJBEogwAAAAAAACQRKIMAAAAAAAAkCR1CXQARnK73SorK1NsbKxMJlOgwwEAAAAQIB6PR1VVVUpMTFRYGPMHAADHhVSirKysTDabLdBhAAAAAAgSpaWlSkpKCnQYAIAgEVKJstjYWEnH/xjGxcUFOBoAAAAAgeJwOGSz2bz3CAAASCGWKDux3DIuLo5EGQAAADocu90uu93e6vpWq1VWq9WPEXV8bMkCADhZSCXKAAAAgI6soKBAeXl5ra6fk5Oj3Nxc/wUEAEAnY/J4PJ5AB2EUh8Oh+Ph4VVZWMqMMAAAA7crlcqmhocGvfRw6dEjl5eXeY6fTqVtvvVWS9NJLL8lisTSqn5CQoJ49e/o1pmAXHh4us9ncpJx7AwBAc0iUAQAAAGepurpaBw4ckNEfrd1ut0pLSyVJNpuNpzc2w2QyKSkpSTExMY3KuTcAADSHpZcAAADAWXC5XDpw4ICio6OVkJBg6J5XLpdLtbW1kqTevXs3O3MqlHk8HpWXl+vAgQNKTk7m9wMAOCMSZQAAAMBZaGhokMfjUUJCgqKiogzt2+VyeV9HRkaSCGpGQkKCSkpK1NDQwO8HAHBGzM0GAAAA2gFPTwxO/HcBAPjCsESZ0+nUfffdp8TEREVFRSkjI0Nvvvlmq9oePHhQ48ePV7du3RQXF6cbb7xRn3/+uZ8jBgAAAAAAQCgxbOnlxIkTVVhYqOnTpys5OVnLly/X6NGjtX79emVmZrbYrrq6WiNGjFBlZaXmzZun8PBwLV68WMOGDVNxcbG6d+9u1I8AAAAAtNrv7n7bL9f92dNX++W6AADAoERZUVGRVq9erfz8fM2ePVuSlJ2drZSUFM2ZM0dbtmxpse2SJUu0Z88eFRUVafDgwZKkG264QSkpKXr88cf18MMPG/EjAAAAtMhut8tut7e6vtVqldVq9WNEQOfQo0cPbd++Xb1799bo0aO1ePFi9e/fX3v37tW4cePk8Xj0//7f/9PQoUMbHU+aNCnQoQMAOihDEmWFhYUym82aMmWKtywyMlKTJ0/WvHnzVFpaKpvN1mLbwYMHe5NkkjRgwABdc801euWVV0iUAQCAgCsoKFBeXl6r6+fk5Cg3N9d/AQGd0Nq1a72vT9wjFBQUSJIeeeSRRscAALSVIYmyHTt2qF+/foqLi2tUnp6eLkkqLi5uNlHmdru1c+dO3XnnnU3Opaena926daqqqlJsbGyz/TqdTjmdTu+xw+E4mx8DAACgWVOnTtXYsWO9x7W1td6tJTZv3tzkSYjMJoMR3nvvPd13331yOBxyuVyaN2+exo0bp4KCAj322GOKiYnRzTffrAcffFAej6fF67hcLt1///3629/+JkkaMWKEHn/8cUVERGjixIkKCwvT7t279fXXX+uKK67Q008/raioqNOea8nrr7+u++67T+Hh4Ro1alSjc71799Zrr72mnTt3avHixXK5XNq2bZtuvvlmLVmyxHv80ksv6eKLL26fXyIAIOQYkiiz2+3NfiA8UVZWVtZsu8OHD8vpdJ6xbf/+/Zttv3DhQp++3Q00f+1j0ZmxR0fbMNZ8x1hrG8aa7xhrbRNsY83ZUOt9ve35I7KEO0+pcUTSLiNDaoKx1jbNjbXI+DAN/H68vomoVniXer/HcOiL/3356/a4va/LS6sUZjr+rK7KyiO6c+JkvbS8UL16nqdvDn+jkd8bqnB3V83/5YP659pN6tXzPD30aF6Ta55q+apntWXTu/rbmvUym83KvutH+vWDC/Xzn85QXXWDind+oLV/ektRUdG6Y8qt+nXOQk3/2WzvuffeL1J0dLR+8IMfaPHixZo3b17zP9ehQ5o0aZI2bdqkiy++WEuXLtU333zTpF52drY+//xzHTlyRE888cTx34Pb3egYAIC2MuSpl7W1tbJYLE3KIyMjvedbaiepTW0lae7cuaqsrPT+Ky0t9Tl2AAAAoKN574MifVH6hX58R5auviFT4ybcKEn6eNe/dc3wkerV8zxJ0sTbJp/xWu/8a4NuybpVFotFXbp00W0/ukMbN6/3nh875ibFxMTKbDbr1vG3653NGxqdi409fm7y5Ml66623Wuzn3XffVWpqqnc22OTJkxUREdGWHx8AgDYzZEZZVFRUoyWQJ9TV1XnPt9ROUpvaSscTbM0l2QAAAIDOzOPxqH/yAP11zZuNyp9Z9nSjY5PJ5PvFz9DmdNf0pb82xQYAwFkyZEaZ1Wpt9klQJ8oSExObbXfuuefKYrG0qS0AAAAQqgZflq79pV80mvn174936srLM/X2xrd06NBXkqQVLz5/xmsNvWq4XlnzB9XX1+vYsWN68eWVGj7kf0t3//K3P6umploul0urX31RQ68a3uhcdfXxc8uWLdO1117bYj9XXHGFdu7cqd27d0uSnn/+edXX+38pKwAAJzNkRllaWprWr18vh8PRaEP/bdu2ec83JywsTAMHDtT27dubnNu2bZv69OnT4kb+AAAAQCCNmzsoYH13iz9HLy57RbkP/VK5C36pY8ca9K3EJC1f+pLunX6/xo4fpa7RXTVm1NgzXuv2WyepZP8+Xfu9oZKkqy7P1JQ7p3nPp6Veqluyb9Y3h7/WoEvSNWVy43PXX3+9ysvLdcUVV2j69Okt9pOQkKDnn39eN910kyIiIjRq1Ch179697b8EAADawJBEWVZWlh577DEtXbpUs2fPlnR8OeWyZcuUkZHhfeLl/v37dfToUQ0YMKBR2/vvv1/bt2/XoEHHP2x8+umnevvtt73XAtCxVNZ8I8fRppvztiQuurviu/JBGQAAX6SmpGnNH95oUp494U5lTzj+VPmammo9suih017HbDYr94GHlPtA8/UuHvAd/Tb/dy2e+8Mrq1od84033qgbb7zRe/zII494X5eUlHhf5+bmNmp36jEAAG1lSKIsIyND48aN09y5c3Xo0CH17dtXK1asUElJiZ577jlvvezsbG3cuLHR46mnTZumZ555RmPGjNHs2bMVHh6uRYsWqVevXpo1a5YR4YcMkhcwyuZdb+hv769sdf0bLsvWmEF3+DEiAAAAAAAMSpRJ0sqVKzV//nytWrVKFRUVSk1N1RtvvKGhQ4eetl1sbKw2bNigGTNmaMGCBXK73Ro+fLgWL16shIQEg6IPDSQvYJTMi76n1Auu8B7XH3Nq8evTJUkzxj6hiC6NH8IRF01CFgAAf+jaNUZflVSq/Oty3XL7TU3ODxsyXDnzFrTY/snHf+/zubvvvlvvvvtuk/KtW7ee9kFdAAAYwbBEWWRkpPLz85Wfn99inQ0bNjRbnpSUpFdffdVPkeEEkhcwSnzXxrMRnQ213tdJPfrKEs6HZLQPZsoCQOsk9EjQ23/bbEhfTz/99JkrAQAQIIYlyhD8SF4A6GyYKQugvf3s6aublNXV1Wnfvn06N7Gr4TOiXC6XDnx9/HWCLVZms9nQ/juCk7d1AQDgTEiUAQA6LWbKAjBCeHi4TCaTysvLlZCQIJPJZFjfLpfL+7quro5E2Sk8Ho/Ky8tlMpkUHh4e6HAAAB0AiTIAQKfFTFkARjCbzUpKStKBAwcaPZnRCG63W19/fXxKWUlJicLCwgztvyMwmUxKSkoiiQgAaBUSZQAAAMBZiomJUXJyshoaGgzt9+jRoxozZowk6YMPPlB0dLSh/XcE4eHhJMkAAK1GogwAAABoB2az2fCEjMvl0hdffCFJslgsioyMNLR/AAA6G+ZmAwAAAAAAACJRBgAAAAAAAEgiUQYAAAAAAABIIlEGAAAAAAAASCJRBgAAAAAAAEgiUQYAAAAAAABIIlEGAAAAAAAASDIwUXbkyBFNmTJFCQkJ6tq1q0aMGKEPPvigVW2Lioo0bdo0XXbZZQoPD5fJZPJztAAAAAAAAAg1XYzoxO12a8yYMfrwww917733qkePHlqyZImGDx+u999/X8nJyadtv3btWj377LNKTU1Vnz599NlnnxkRNgAA6CB+9vTVgQ6hkZqaGs16/vjrqU8OV9euXQMbEAAAAFrFkBllhYWF2rJli5YvX66cnBz97Gc/04YNG2Q2m5WTk3PG9j/96U9VWVmp7du3a+TIkQZEDAAAAAAAgFBjyIyywsJC9erVSzfffLO3LCEhQePHj9cLL7wgp9Mpi8XSYvtevXoZESYQMph5AQAAAABAU4bMKNuxY4cuvfRShYU17i49PV1Hjx7121JKp9Mph8PR6B8AAAAAAADQHEMSZXa7XVartUn5ibKysjK/9Ltw4ULFx8d7/9lsNr/0AwAAAAAAgI7P56WXbrdb9fX1raprsVhkMplUW1vb7NLKyMhISVJtba2vYbTK3LlzNXPmTO+xw+EI6mQZy+EAAAAAAAACx+dE2TvvvKMRI0a0qu6uXbs0YMAARUVFyel0NjlfV1cnSYqKivI1jFaxWCyn3fsMAAAAAAAAOMHnRNmAAQO0bNmyVtU9sbTSarXKbrc3OX+iLDEx0dcwAAAdADNlAaB92e32Rp+rT16ZUVxc3OQLaKvV2uwWKAAAoHk+J8rOO+88TZw40ac2aWlp2rRpk9xud6MN/bdt26bo6Gj169fP1zAAAACAkFNQUKC8vLxmz2VmZjYpy8nJUW5urp+jAgCg8/A5UdYWWVlZKiws1Jo1a5SVlSVJ+vrrr/Xqq6/q+9//fqPlkXv37pUkffvb3zYiNAAAAKDDmDp1qsaOHdvq+swmAwDAN4Ylyi6//HJNmjRJn3zyiXr06KElS5bI5XI1+UbsmmuukSSVlJR4y7744gutWrVKkrR9+3ZJ0oIFCyRJF1xwgW6//XYDfgoAAAAgsFhKCQCAfxmSKDObzVq7dq3uvfdePfnkk6qtrdXgwYO1fPly9e/f/4zt9+3bp/nz5zcqO3E8bNgwEmUAAAAAAAA4ayaPx+MJdBBGcTgcio+PV2VlpeLi4gIdTtCrqalRTEyMJKm6uppNr+E3jDUYhbEGozDWgODHvQEAoDlhZ64CAAAAAAAAdH4kygAAAAAAAACRKAMAAAAAAAAkkSgDAAAAAAAAJJEoAwAAAAAAACSRKAMAAAAAAAAkkSgDAAAAAAAAJEldAh0AgNBjt9tlt9u9x7W1td7XxcXFioqKalTfarXKarUaFh8AAAAAIDSRKANguIKCAuXl5TV7LjMzs0lZTk6OcnNz/RwVAAAAACDUkSgDYLipU6dq7Nixra7PbDIAwY6ZsgAAAJ0DiTIAhuMGEUBnw0xZAACAzoFEGQAAwFlipiwAAEDnQKIMXiwbAdDZ8L4GozB2AAAAOgcSZfBi2QiAzob3NQAAAAC+MHk8Hk+ggzCKw+FQfHy8KisrFRcXF+hwgs6pMy/OhG/PAQQ73tcAAC3h3gAA0JyQSpRVVlaqW7duKi0t5Y8hAAAAEMIcDodsNpuOHDmi+Pj4QIcDAAgSIbX0sqqqSpJks9kCHAkAAACAYFBVVUWiDADgFVIzytxut8rKyhQbGyuTyRTocDqEE9+0MQsP/sZYg1EYazAKYw1GYay1jcfjUVVVlRITExUWFhbocAAAQSKkZpSFhYUpKSkp0GF0SHFxcXzwgiEYazAKYw1GYazBKIw13zGTDABwKr46AQAAAAAAAESiDAAAAAAAAJBEogxnYLFYlJOTI4vFEuhQ0Mkx1mAUxhqMwliDURhrAAC0n5DazB8AAAAAAABoCTPKAAAAAAAAAJEoAwAAAAAAACSRKAMAAAAAAAAkkSgDAAAAAAAAJJEoAwAAAAAAACRJXQIdgJHcbrfKysoUGxsrk8kU6HAAAAAABIjH41FVVZUSExMVFsb8AQDAcSGVKCsrK5PNZgt0GAAAAACCRGlpqZKSkgIdBgAgSIRUoiw2NlbS8T+GcXFxAY4GAAAAQKA4HA7ZbDbvPQIAAFKIJcpOLLeMi4sjUQYAANqN3W6X3W5vdX2r1Sqr1erHiAC0FluyAABOFlKJMpweH/JhFMYajMJYg1EKCgqUl5fX6vo5OTnKzc31X0AAAABoExJl8OJDPozCWINRGGswytSpUzV27FjvcW1trTIzMyVJmzdvVlRUVKP6JGQBAACCk8nj8XgCHYRRHA6H4uPjVVlZydLLZpw686I1H/L5oI+2YKzBKIw1BEpNTY1iYmIkSdXV1eratWuAIwJwKu4NAADNIVGGFvEhH0ZhrMEojDUYhbEGBD/uDQAAzQkLdAAAAAAAAABAMCBRBgAAAAAAAIhEGQAAAAAAACCJRBkAAAAAAAAgSepiVEdOp1MPPvigVq1apYqKCqWmpmrBggUaOXLkadutWbNGL7/8st577z19+eWXstls+t73vqf58+erW7duxgQPAGiTx2/5XqBDaMR57Jj39W+zfyhLF8P+DLbarJffCHQIHRJjzXeMNQAAgKYM+9Q2ceJEFRYWavr06UpOTtby5cs1evRorV+/XpmZmS22mzJlihITE3Xbbbfp/PPP10cffaSnnnpKa9eu1QcffKCoqCijfgS/40O+7/iQ3zaMNd8x1gAAAACg8zPkbrSoqEirV69Wfn6+Zs+eLUnKzs5WSkqK5syZoy1btrTYtrCwUMOHD29Udtlll+mOO+7Qiy++qLvuusufoQMAAAAAACBEGLJHWWFhocxms6ZMmeIti4yM1OTJk7V161aVlpa22PbUJJkk3XTTTZKkXbt2tXusAAAAAAAACE2GJMp27Nihfv36KS4urlF5enq6JKm4uNin63355ZeSpB49erRLfAAAAAAAAIAhSy/tdrusVmuT8hNlZWVlPl3vkUcekdlsVlZW1mnrOZ1OOZ1O77HD4fCpHwAAAAAAAIQOQxJltbW1slgsTcojIyO951vrpZde0nPPPac5c+YoOTn5tHUXLlyovLw834IFAAAAgpTdbpfdbm91favV2uwX1gAAoHmGJMqioqIazew6oa6uznu+NTZt2qTJkyfr+uuv10MPPXTG+nPnztXMmTO9xw6HQzabrZVRAwA6OkdtnRx1//v7U3/M5X19sMKhiC7mRvXjIi2Ki4o0LD4A8FVBQYFPXwTn5OQoNzfXfwEBANDJGJIos1qtOnjwYJPyE9+GJSYmnvEaH374ocaOHauUlBQVFhaqS5czh26xWJqdyYbmcUMJoLPZune/3vxkT7Pnlqzf2qRs5MXJuj6ln7/DQifE31AYZerUqRo7dqz3uLa2VpmZmZKkzZs3N/kCmtlkAAD4xpBEWVpamtavXy+Hw9FoQ/9t27Z5z5/O3r17NWrUKPXs2VNr165VTEyMP8MNWdxQwijcUMIoV3z7fH3nW71aXT8uki9X0Db8DYVRTl1KWVNT432dlpamrl27BiIsAAA6DUMSZVlZWXrssce0dOlSzZ49W9LxjfaXLVumjIwM73LI/fv36+jRoxowYIC37ZdffqnrrrtOYWFh+sc//qGEhAQjQg5J3FDCKNxQwihxUZEkWWEI/oYCAAB0DoYkyjIyMjRu3DjNnTtXhw4dUt++fbVixQqVlJToueee89bLzs7Wxo0b5fF4vGWjRo3S559/rjlz5mjz5s3avHmz91yvXr00cuRII36EkMANJYzCDSWAzoa/oQAAAJ2DIYkySVq5cqXmz5+vVatWqaKiQqmpqXrjjTc0dOjQ07b78MMPJUmPPvpok3PDhg0jUQZ0QNxQAgAAAACCkWGJssjISOXn5ys/P7/FOhs2bGhSdvLsMgAAACCQHr/le4EOoRHnsWPe17/N/qEsrXjgldFmvfxGoEMAAKDVwgIdAAAAAAAAABAMSJQBAAAAAAAAIlEGAAAAAAAASCJRBgAAAAAAAEgycDN/AAAAAGfHUVsnR53Te1x/zOV9fbDCoYgu5kb14yItPGkaAAAfkCgDAAAAOoite/frzU/2NHtuyfqtTcpGXpys61P6+TssAAA6DRJlAAAAQAdxxbfP13e+1avV9eMiLX6MBgCAzodEGQAAANBBxEVFspQSAAA/YjN/AAAAAAAAQCTKAAAAAAAAAEkkygAAAAAAAABJJMoAAAAAAAAASSTKAAAAAAAAAEkkygAAAAAAAABJUpdABxBMXC6XGhoaAtZ/9Lk9Ata3P3g8HtVXV8nVUB/oUAAAAAAAAM6IRNl/VVdX68CBA/J4PAGL4dIfTwpY3/7gkUcNR49q999fl8N+INDhAAAAAAAAnBaJMh2fSXbgwAFFR0crISFBJpMpIHGUmwPTrz9V1zk1YNRYvf/Cs8wsAwAAAAAAQY1EmaSGhgZ5PB4lJCQoKioqYHGEm80B69tfYiItqoyOVkRMrGorvgl0OAAAAAAAAC1iM/+TBGomWWdnkonfLQAAAAAACHokygAAAAAAAACx9LJFj9/yPb9cd9bLb/jlugAAAAAAADg7zCgLUo/99knVOZ2SpF/MuU9Lly33+RqPPvFb/fHPr3uvN3/BQ6etP2vuPP1r67s+9/P8ylX6xZz7fG4HAAAAAAAQTJhRFqQe/7+n9JNJExVpsbT5GnOm/8K3Phc+3Oa+AAAAAAAAOjoSZUFozvwHJUk/+NGtMpvD1KtnT+3Zu1fjbs9Wmf1L9e+XrKefWKyIiAg1NDTo0cVPaPO776qhoUF9el+oRxf8St3i4/WLOffpOxddpCmTJraq35tvvU0/mXSHbhg5Ur+Yc58iIiJU8sUXTfqsrq7WrHkP6ONdu3Xuueeof3KyH38bAAAAAAAAxmDpZRB69Ne/kiS9tvolvfWX19Wje3d9vGuXViwt0Dv/+Ju+/vob/fUf6yRJS555VlHR0frbmj/qrb+8rgH9++mRRYvbJY6W+lz01O8UERGhTev+rheefUbvvvdeu/QHAAAAAAAQSMwo6yBuGDlS0VFRkqS01FSV7N8vSfr7W2+pqqpaa//xD0lSfX2DbEnf8mufm7ZsVd4D82QymRQXG6ubvv99ffHfcwAAAAAAAB0VibIOwnLSXmVmc5hcx45JkjwejxY8OF/Dh2Qa1uepTCZTu/cNAAAAAABgNBJlLZj18hsB7T+ma1c5qqoUHxd32nqjRo7U0mXLlD7oMkVHReloba1KSw+ofz//7Rs29Kor9fIf/6gr0gerurpGr/3lDaWlDvRbfwAAAAAAAEYgURak7p58p350xyRFRUWqV8+eLda7Z8pPtKi+XmN+OM47s+tnU37i10TZjJ9N06x5D2jIdaN07rnnKH3QZaqvr/dbfwAAAAAAAEYweTweT6CDMIrD4VB8fLwqKysVd9JMrbq6Ou3bt08XXnihIiMjAxbfl3v3BKxvf2lwuVT25Vf64A/LdPTw1+1+/UDP/OuoHr/le4EOocNhrLUNY813jLW2Yaz5jrHWNow13wXrWGvp3gAAENp46iUAAAAAAAAgll6GnBdffkXLXnihSfmCB+fr8sGDAxARAAAAAABAcCBRdpJQWIU64ZbxmnDLeEP79MgTEr9bAAAAAADQsbH0UpLZbJYkNqT3A5fbI4/LrWN1tYEOBQAAAAAA4LSYUSapS5cuio6OVnl5ucLDwxUWFpj8YYPLFZB+/cXjkSqrq/VNyV411JIoAwAAAAAAwc2wRJnT6dSDDz6oVatWqaKiQqmpqVqwYIFGjhx5xrYHDx7UjBkztG7dOrndbo0YMUKLFy9Wnz592iU2k8kkq9Wqffv26YsvvmiXa7aFo/xQwPr2B488clZVad/mtyWx9BIAAAAAAAQ3wxJlEydOVGFhoaZPn67k5GQtX75co0eP1vr165WZmdliu+rqao0YMUKVlZWaN2+ewsPDtXjxYg0bNkzFxcXq3r17u8QXERGh5OTkgC6/XPbkIwHr2x88brfqHJXyuDvXTDkAAAAAANA5GZIoKyoq0urVq5Wfn6/Zs2dLkrKzs5WSkqI5c+Zoy5YtLbZdsmSJ9uzZo6KiIg3+71MZb7jhBqWkpOjxxx/Xww8/3G5xhoWFKTIyst2u56ujh78OWN8AAAAAAAChzpDNuAoLC2U2mzVlyhRvWWRkpCZPnqytW7eqtLT0tG0HDx7sTZJJ0oABA3TNNdfolVde8WvcAAAAAAAACB2GzCjbsWOH+vXrp7i4uEbl6enpkqTi4mLZbLYm7dxut3bu3Kk777yzybn09HStW7dOVVVVio2NbbZfp9Mpp9PpPa6srJQkORyONv8s/lTX0BDoEDqcYP1vGewYa75jrLUNY813jLW2Yaz5jrHWNow13wXrWDsRl8fDXroAgP8xJFFmt9tltVqblJ8oKysra7bd4cOH5XQ6z9i2f//+zbZfuHCh8vLympQ3l5RDx/TLP8UHOgSECMYajMJYg1EYazBKsI+1qqoqxccHd4wAAOMYkiirra2VxWJpUn5iP7Da2toW20lqU1tJmjt3rmbOnOk9drvdOnz4sLp37y6TydT6HyCEORwO2Ww2lZaWNpkRCLQnxhqMwliDURhrMApjrW08Ho+qqqqUmJgY6FAAAEHEkERZVFRUoyWQJ9TV1XnPt9ROUpvaSscTbKcm2bp169aqmNFYXFwcH7xgCMYajMJYg1EYazAKY813zCQDAJzKkM38rVar7HZ7k/ITZS19i3PuuefKYrG0qS0AAAAAAADgC0MSZWlpafrss8+abOS5bds27/nmhIWFaeDAgdq+fXuTc9u2bVOfPn1a3MgfAAAAAAAA8IUhibKsrCy5XC4tXbrUW+Z0OrVs2TJlZGR4N9ffv3+/du/e3aTte++91yhZ9umnn+rtt9/WuHHjjAg/pFksFuXk5DS7TxzQnhhrMApjDUZhrMEojDUAANqPyWPQ85DHjx+vP/3pT5oxY4b69u2rFStWqKioSP/85z81dOhQSdLw4cO1cePGRo9orqqq0iWXXKKqqirNnj1b4eHhWrRokVwul4qLi5WQkGBE+AAAAAAAAOjkDNnMX5JWrlyp+fPna9WqVaqoqFBqaqreeOMNb5KsJbGxsdqwYYNmzJihBQsWyO12a/jw4Vq8eDFJMgAAAAAAALQbw2aUAQAAAAAAAMHMkD3KAAAAAAAAgGBHogwAAAAAAAAQiTIAAAAAAABAkoGb+QcDt9utsrIyxcbGymQyBTocAAAAAAHi8XhUVVWlxMREhYUxfwAAcFxIJcrKyspks9kCHQYAAACAIFFaWqqkpKRAhwEACBIhlSiLjY2VdPyPYVxcXICjAQAAABAoDodDNpvNe48AAIAUYomyE8st4+LiSJQBAACgw7Hb7bLb7a2ub7VaZbVa/RhRx8eWLACAk4VUogwAAADoyAoKCpSXl9fq+jk5OcrNzfVfQAAAdDIkygAAAIAOYurUqRo7dqz3uLa2VpmZmZKkzZs3KyoqqlF9ZpMBAOAbEmUAAABAB3HqUsqamhrv67S0NHXt2jUQYQEA0GnwHGQAAAAAAABAJMoAAAAAAAAASSy9BAAAOGs8iRAAAKBzIFEGwHDcUALobHgSIQAAQOdAogyA4bihBNDZ8CTC0HHg/k2BDqGRo/W13tcH5/9L0RFRp6kdGEm/GRLoEAAAaDUSZfBilg+Mwg0lgM6GJxECAAB0DiTK4MUsHxiFG0oYhS8AAAAAAPiCRBm8mOUDoLPhCwAAAAAAviBRBi9m+QDobPgCAAAAAIAvSJQBADotvgAAAAAA4AsSZQAAoMPjSYS+40mEHdNX1V/rUPU33uO6Bqf39cdf7VFkuKVR/Z4x3dUrpodh8QEA0NEZlihzOp168MEHtWrVKlVUVCg1NVULFizQyJEjT9suNze32f1lLBaL6urq/BUuAAAAEHReLH5di/+1vNlzN790T5OyGVdN1MzMO/0cFQAAnYdhibKJEyeqsLBQ06dPV3JyspYvX67Ro0dr/fr13v1iTuf3v/+9YmJivMdms9mf4QKdGjMvfMfMCwBAMJiQNlYj+17V6vo9Y7r7MRoAADofQxJlRUVFWr16tfLz8zV79mxJUnZ2tlJSUjRnzhxt2bLljNfIyspSjx5MGwcAAEDo6hXTg6WUAAD4kSGJssLCQpnNZk2ZMsVbFhkZqcmTJ2vevHkqLS2VzWY77TU8Ho8cDodiY2NlMpn8HXJAMMvHd8zyAYIb72u+430NAAAACJwwIzrZsWOH+vXrp7i4uEbl6enpkqTi4uIzXqNPnz6Kj49XbGysbrvtNn311Vf+CBUAAAAAAAAhypAZZXa7XVartUn5ibKysrIW255zzjm65557dMUVV8hisWjTpk363e9+p6KiIm3fvr1J8u1kTqdTTuf/ngTkcDjO4qcAAAAAAABAZ2ZIoqy2tlYWi6VJeWRkpPd8S37xi180Ov7hD3+o9PR0TZgwQUuWLNH999/fYtuFCxc2+8RMAACA9vRV9dc6VP2N97iu4X9f1H381R5Fhjf+HNQzpjv7TAEAAAQhQxJlUVFRjWZ2nVBXV+c974tbb71Vs2bN0ltvvXXaRNncuXM1c+ZM77HD4TjjXmgA/I8bSgCdzYvFr2vxv5Y3e+7ml+5pUjbjqomamXmnn6MCAACArwxJlFmtVh08eLBJud1ulyQlJib6fE2bzabDhw+fto7FYml2JhuAwOKGEkBnMyFtrEb2varV9XvGdPdjNAAAAGgrQxJlaWlpWr9+vRwOR6M9xbZt2+Y97wuPx6OSkhJdcskl7RkmAINwQwmjMHsRRukV04OxAwAA0AkYkijLysrSY489pqVLl2r27NmSjm+0v2zZMmVkZHiXQ+7fv19Hjx7VgAEDvG3Ly8uVkJDQ6Hq///3vVV5erlGjRhkRfsjghhJG4YYSRmH2IgAAAABfGJIoy8jI0Lhx4zR37lwdOnRIffv21YoVK1RSUqLnnnvOWy87O1sbN26Ux+Pxll1wwQW65ZZbNHDgQEVGRmrz5s1avXq10tLSNHXqVCPCDxncUALobJi9CAAAAMAXhiTKJGnlypWaP3++Vq1apYqKCqWmpuqNN97Q0KFDT9tuwoQJ2rJli/74xz+qrq5OF1xwgebMmaMHHnhA0dHRBkUfGrihBNDZMHsRAAAAgC8MS5RFRkYqPz9f+fn5LdbZsGFDk7JnnnnGj1HhZNxQAgAAAACAUBYW6AAAAAAAAACAYECiDAAAAAAAABCJMgAAAAAAAEASiTIAAAAAAABAEokyAAAAAAAAQBKJMgAAAAAAAEASiTIAAAAAAABAEokyAAAAAAAAQJLUJdABBBOXy6WGhoaA9X8s1hSwvgPGI4XVehTmCnQgAAAAAAAg1JEo+6/q6modOHBAHo8nYDEcG9E1YH0HVJ1bXbfXKeKwO9CRAAAAAACAEEaiTMdnkh04cEDR0dFKSEiQyRSYmV31UTUB6TegPB59c/SIqgdJXf55lJllAAAAAAAgYEiUSWpoaJDH41FCQoKioqICFkdYl8At+wyk7tHdVB1ZJXeUSWHVgZvRBwAAAAAAQhub+Z8kUDPJQt6J3zu/fgAAAAAAEEAkygAAAAAAAACx9LJFB+7f5JfrJv1miF+uCwAAAAAAgLPDjLIQVvalXVfffH2b2+8t+VwZNwxR+qhMrXj5hXaMDAAAAAAAwHjMKAtRx44dU+J5Vr295h9tvsaf1v5Zl333Ui35zW997rtLF4YeAAAAAAAILswoC1IWW5yOVB7xHiem9lZJ6ReSpH5XpCjvsQUaeuM16nflQC387aPeeiPHjdb0+bN15Zhhuijzu5rzq3nyeDzeczMevFdDb7xGYyb8QCWlX6jnd2ySpN88ma9f/HKW9zrVNdU6L+V8lX/zdbPxvVD4kp589nf6899e1+Drr9Kuz3b71DcAAAAAAECwYVpPB3XEUal3/vxPfX34G12U+V1lj79N37ImSpJ27flUG197Sw3HGnTND2/Qy6+9qh/dNF6StOfz/+ifhX9XeHi4N/EmSROyfqwrRg/Vo/MflsVi0R/feE3DrhyqhO49mu3/tqxbtW9/iY44KvV47iPe8tb2DQAAAAAAEGyYUdZB/egH4yRJPc7trgvP790o6XXbD3+k8PBwRUdF68c3j9fbmzd4z9168y3NJqpsiUn67ndS9cabayVJq159UdnjJ/gcV1v6BgAAAAAACAYkyoKU2WyWy+3yHtc5nY3OR1oi/1c3zKxjrmMtXstkMnlfd42OabHexFtu14pXXtDnX+zT3pLPdf3wkW0JvU19AwAAAAAABBqJsiD17d59VLRjuyTptb+9rpqjNa1u+9KfXlFDQ4Nqa2v18muv6urM4a1qN/b67+n9Dz9Q/u8W6cc339KmDffb2jcAAAAAAECgsUdZC5J+MySg/efnLNTMB+coN3+Bbrj6OnU/59xWtx3Qt5+G3zRSh49U6PvXjdH4G7Na1c5iseiH37tJBSuf1Yfrt7cp7rb2DQAAAAAAEGgkyoLUqBHXadSm67zHuffO977+bOu/G9XdunZjo+PhVw7T4l/lN7nmm6+ubXTc23aBDn1c2qjsyYcW6cmHFrUqxvkz5zUpa23fAAAAAAAAwYallwAAAAAAAICYUdbptPfMref/sEK/X760SfniX+UrM+NKv/YNAAAAAABgJBJlOK07f3yH7vzxHYEOAwAAAAAAwO9YenkSj8cT6BBC04nfO79+AAAAAAAQQMwokxQeHi6TyaTy8nIlJCTIZDIFJI76Y/UB6TegPB59c/SIVOdWWC2ZMgAAAAAAEDiGJcqcTqcefPBBrVq1ShUVFUpNTdWCBQs0cuTIM7Y9ePCgZsyYoXXr1sntdmvEiBFavHix+vTp0y6xmc1mJSUl6cCBAyopKWmXa7bFsYq6gPUdUHVudd1epzBXoAMBAAAAAAChzLBE2cSJE1VYWKjp06crOTlZy5cv1+jRo7V+/XplZma22K66ulojRoxQZWWl5s2bp/DwcC1evFjDhg1TcXGxunfv3i7xxcTEKDk5WQ0NDe1yvbb4cs32gPUdMB4prNZDkgwAAAAAAAScIYmyoqIirV69Wvn5+Zo9e7YkKTs7WykpKZozZ462bNnSYtslS5Zoz549Kioq0uDBgyVJN9xwg1JSUvT444/r4Ycfbrc4zWazzGZzu13PV12qWHoIAAAAAAAQKIZs5l9YWCiz2awpU6Z4yyIjIzV58mRt3bpVpaWlp207ePBgb5JMkgYMGKBrrrlGr7zyil/jBgAAAAAAQOgwJFG2Y8cO9evXT3FxcY3K09PTJUnFxcXNtnO73dq5c6cGDRrU5Fx6err27t2rqqqqdo8XAAAAAAAAoceQpZd2u11Wq7VJ+YmysrKyZtsdPnxYTqfzjG379+/fbHun0ymn0+k9rqyslCQ5HA7ffgCDVDlrAh1ChxOs/y2DHWPNd4y1tmGs+Y6x1jaMNd8x1tqGsea7YB1rJ+LyeNj+BADwP4Ykympra2WxWJqUR0ZGes+31E5Sm9pK0sKFC5WXl9ek3GaznTlodAxPBDoAhIwnAh0AQsYTgQ4AIeOJQAeAkPFEoAM4vaqqKsXHxwc6DABAkDAkURYVFdVoZtcJdXV13vMttZPUpraSNHfuXM2cOdN77Ha7dfjwYXXv3l0mk6n1P0AIczgcstlsKi0tbbJ0FmhPjDUYhbEGozDWYBTGWtt4PB5VVVUpMTEx0KEAAIKIIYkyq9WqgwcPNim32+2S1OIfp3PPPVcWi8Vbz5e20vGZaKfORuvWrVtrw8ZJ4uLi+OAFQzDWYBTGGozCWINRGGu+YyYZAOBUhmzmn5aWps8++6zJ/gTbtm3znm9OWFiYBg4cqO3btzc5t23bNvXp00exsbHtHi8AAAAAAABCjyGJsqysLLlcLi1dutRb5nQ6tWzZMmVkZHj3DNu/f792797dpO17773XKFn26aef6u2339a4ceOMCB8AAAAAAAAhwJCllxkZGRo3bpzmzp2rQ4cOqW/fvlqxYoVKSkr03HPPeetlZ2dr48aNjZ48M23aND3zzDMaM2aMZs+erfDwcC1atEi9evXSrFmzjAg/pFksFuXk5DT7QAWgPTHWYBTGGozCWINRGGsAALQfk8eg5yHX1dVp/vz5euGFF1RRUaHU1FT9+te/1vXXX++tM3z48CaJMkk6cOCAZsyYoXXr1sntdmv48OFavHix+vbta0ToAAAAAAAACAGGJcoAAAAAAACAYGbIHmUAAAAAAABAsCNRBgAAAAAAAIhEGQAAAAAAACCJRBkAAAAAAAAgSeoS6ACM5Ha7VVZWptjYWJlMpkCHAwAAACBAPB6PqqqqlJiYqLAw5g8AAI4LqURZWVmZbDZboMMAAAAAECRKS0uVlJQU6DAAAEEipBJlsbGxko7/MYyLiwtwNAAAAAACxeFwyGazee8RAACQQixRdmK5ZVxcHImyZtjtdtnt9lbXt1qtslqtfowIAM4O72sAgDNhSxYAwMlCKlGG0ysoKFBeXl6r6+fk5Cg3N9d/AQHAWeJ9DQAAAIAvTB6PxxPoIIzicDgUHx+vysrKZmeUuVwuNTQ0BCCy4HDo0CGVl5d7j51Op2699VZJ0ksvvSSLxdKofkJCgnr27HnW/ZrNZnXp0oVv80IIs3xglFPHWm1trTIzMyVJmzdvVlRUVKP6jDW0Fe9rQMdzpnsDAEBoIlH2X9XV1Tpw4IBC6NdxRm63W6WlpZIkm83m16cBRUdHy2q1KiIiwm99IHjk5uYyywcBUVNTo5iYGEnH3/e7du0a4IjQWfC+BnQ8JMoAAM0hUabjM8n27Nmj6OhoJSQkMLPpv1wul3bt2iVJuuiii2Q2m9u9D4/Ho/r6epWXl8vlcik5OZnHc4cAZvkgUEiUwV94XwM6HhJlAIDmsEeZpIaGBnk8HiUkJDT5IBvKXC6X93VkZKRfEmWSFBUVpfDwcH3xxReqr69XZGSkX/pB8Dj1BrGmpsb7Oi0tjeQFgA6H9zUAAIDOgak7J2EmWeAwiwwAAAAAAAQa2QkAAAAAAABALL1skb822GXjXgAAAAAAgODEjLIQVlZWpiFDhrS5/d69e3XppZfqkksu0bJly9oxMgAAAAAAAOMxoyxEHTt2TImJidq0aVObr1FYWKjBgweroKDA5767dGHoAQAAAACA4MKMsiBlMpl05MgR73GPHj1UUlIiSerdu7cefPBBXXHFFbrwwgu1YMECb73hw4fr5z//uQYPHqy+fftq1qxZ8ng83nP/7//9P11xxRW67rrrVFJSom7dukmSHnroId1zzz3e61RXVyshIUEVFRXNxrdy5UotXrxYa9asUVpamj755BMNHz5cs2fP1pAhQ/Ttb39bd999t7f+xIkTdeedd2ro0KFKSUlpp98SAAAAAABA+2FaTwd15MgRbd26VV9//bW+/e1va9KkSfrWt74lSfrkk0+0ZcsWNTQ0aOjQofrDH/6gW2+9VZL02Wef6Z133lF4eLg38SZJ2dnZuuyyy/T444/LYrHo1Vdf1fDhw3XOOec02392drY+//xzHTlyRE888YS3fO/evVq/fr0aGhp08cUXa+vWrbriiiskSe+//742b96s2NhY//xSAAAAAAAAzgKJsg7qROKrR48e6tOnj/bt2+dNlGVnZys8PFzh4eG67bbb9NZbb3nr33bbbQoPD29yPZvNpksuuUSvv/66xo0bp+XLl2vmzJk+x3XLLbeoS5cu6tKli9LS0rR3715vomzcuHEkyYAQE2wPMKmvr/e+fuihhxQRERHAaJoXbL8zAAAAIJSQKAsiZWVl3tdms1kHDhzQ0aNHJUm1tbX66quvFBERIZfLJYfD4a3vdrv15ZdfqqysTPX19aqoqPCeq6ysVG1trfdcfX2999xXX30lj8fjPf7BD36gp59+WklJSfrss8/03e9+V19//bUkyW63Kyys8UrdqqoqVVdXe9vX19fr6NGjjY7Ly8tVVlamo0ePyuVyNfoZT3bs2DEdOXJETz31lKqrq1v9O+OGEgAAAAAAtBf2KAtSvXv31o4dOyRJa9eu9SbMWmPNmjVqaGhQbW2tXnvttVY/2XLUqFEqLi7WU089pZtvvpkN9wEAAAAAQEghE9KCQM9Uys3N1fz58/Xoo4/qmmuuaXGvsOYkJyfrBz/4gY4cOaLrrrtON954Y6vaWSwWff/739eKFSu0cePGtoaODiDQ4/tULIcDAAAAAAQDEmVB6uqrr9bVV1/tPZ4zZ4739bZt2xrV/dvf/tbo+KqrrtKvf/3rJtcsLCxsdGyz2bRr165GZQ8//LAefvhhSceXdJ7OrFmzTnv9Z555xvv65A3/AQBob8GWzOYLAAAAgI7prJdeOp1O3XfffUpMTFRUVJQyMjL05ptvnrHdmjVrdMstt6hPnz6Kjo5W//79NWvWLB05cqRJ3d69e8tkMjX5d/fdd59t+AAAAAAAAICkdphRNnHiRBUWFmr69OlKTk7W8uXLNXr0aK1fv16ZmZkttpsyZYoSExN122236fzzz9dHH32kp556SmvXrtUHH3ygqKioRvXT0tKazGDq16/f2Ybf6Zw6q+tsvfbaa3rllVeaPClzwYIFysjIaNe+AAAAAAAAAumsEmVFRUVavXq18vPzNXv2bElSdna2UlJSNGfOnP/f3p1HR1Gl/x//dDokHcjCFiDRKEY2JcQ4AfJVtgCyiIL4NeB3RMOmoOiICIOiAkERRlBQcUSY0YCIMhhHdNxQ2SSCIJqAqDBBdggDJkBCyN71+4MfNTRJIGt1lvfrHM5J37q36unmOdXdT9+6pU2bNpU4NiEhQdHR0S5tkZGRGj58uJYvX67777/fZdsVV1yhe++9tyLhohwGDx6swYMHq0WLFkXuegkAAABrpaamKjU1tdT9g4KCFBQUVIURAQBQu1SoUJaQkCC73a4xY8aYbQ6HQ6NHj9ZTTz2lQ4cOKSQkpNixFxfJJOnOO+/U8OHDi6ybdV5eXp7y8/PVoEGDioRdIsMwqmS/uLzzr/3l1kUDAACoyxYtWqQZM2aUuv/06dNZjw4AgDKoUKEsKSlJbdq0kb+/v0t7586dJUnJycklFsqKc+zYMUlS06ZNi2xbu3at6tevr8LCQl199dWaMGGCxo8fX4Ho/6tevXqy2Ww6ceKEAgMDZbPZKmW/ZVVQUOCW45bkwqJVQUFBlcwoMwxDTqdTp0+fVnZ2trKzsyv9GAAAALXF2LFjNWjQIPNxdna2udxJYmJikeVLmE0GAEDZVKhQlpqaWuyb7/m2o0ePlml/L7zwgux2u2JiYlzaw8PD1bVrV7Vt21ZpaWlasmSJHnvsMR09elQvvPBCifvLzc1Vbm6u+TgjI6PYfna7XVdeeaUOHz6s/fv3lynmylTcjQzcyTAM8zXLy8ursgKi0+nUiRMntGvXLmb1AQAAXMLFl1JmZWWZf0dERFTZlRcAANQVFSqUZWdny9vbu0i7w+Ewt5fWu+++qzfffFOTJ09W69atXbZ9/PHHLo9HjhypW2+9VfPmzdOf/vQnXXnllcXuc/bs2aWemu7r66vWrVsrPz+/1DFXttdee81txy5Ofn6+Fi1aJOncr5cXL+hfGQzDUH5+vvLy8ip93wCQmZmpM2fOmI8vPMcfO3asyHnN19dXfn5+lsUHAAAAoHqpUKHMx8fHZcbWeTk5Oeb20ti4caNGjx6tfv366fnnn79sf5vNpgkTJmj16tVav359iYv8T5kyRY8//rj5OCMj45KXgtrtdtnt9lLFXBUu/DJXHeTl5enAgQOSzn3Z9PLycnNEAFA2P/zwgzZs2FDstvj4+CJtPXr0KHYNTQAAAAB1Q4UKZUFBQTpy5EiR9vN34gkODr7sPrZv365BgwYpLCxMCQkJ8vQsXUjnC17p6ekl9vH29i52xhuKx8wLALVNZGSk2rZtW+r+vr6+VRgNAAAAgOquQoWyiIgIrVu3ThkZGS4L+m/ZssXcfim//fab+vfvr2bNmumzzz4r0xeUvXv3SpICAwPLHjiKxcwLALWNn58fBX0AAAAApVahQllMTIxefPFFLV68WJMmTZJ0bgH9+Ph4RUVFmbO+Dh48qLNnz6pdu3bm2GPHjqlv377y8PDQ6tWrSyx4paenKyAgwOWSyPz8fP3lL3+Rl5eXevbsWZGngAsw8wJWYfYiAAAAAKA6qlChLCoqSkOGDNGUKVN0/PhxtWrVSkuXLtX+/fv15ptvmv1iY2O1YcMGlzsa9u/fX3v37tXkyZOVmJioxMREc1vz5s3Vp08fSecW8p85c6ZiYmJ0zTXXKD09Xe+++6527typWbNmqUWLFhV5CrgAMy9gFWYvAqht+AEAAACgdqhQoUyS3n77bU2dOlXLli3TyZMnFR4erk8++UTdu3e/5Ljt27dLkubMmVNkW48ePcxCWYcOHXT99dfrnXfe0YkTJ+Tl5aWIiAitXLlSQ4YMqWj4ANyA2YsAaht+AAAAAKgdKlwoczgcmjt3rubOnVtin/Xr1xdpu3B22aVERkbq448/Lm94AKohZi8CqG34AQAAAKB2qHChDAAAoK7jBwAAAIDagUIZAAAAUEpxcXHuDsFFXl6e+ffzzz8vLy8vN0ZTvOr2mgEAcCke7g4AAAAAAAAAqA4olAEAAAAAAACiUAYAAAAAAABIolAGAAAAAAAASKJQBgAAAAAAAEiiUAYAAAAAAABIolAGAAAAAAAASKJQBgAAAAAAAEiiUAYAAAAAAABIolAGAAAAAAAASJI83R0AAAAAgNLJzMzUmTNnzMf5+fnm38eOHVO9evVc+vv6+srPz8+y+AAAqOkolAEAAAA1xA8//KANGzYUuy0+Pr5IW48ePRQdHV3FUQEAUHtQKAMAAABqiMjISLVt27bU/X19faswGgAAah8KZQAAAEAN4efnx6WUAABUIRbzBwAAAAAAAEShDAAAAAAAAJBEoQwAAAAAAACQRKEMAAAAAAAAkEShDAAAAAAAAJBEoQwAAAAAAACQRKEMAAAAAAAAkEShDAAAAAAAAJBEoQwAAAAAAACQVAmFstzcXD3xxBMKDg6Wj4+PoqKi9NVXX5Vq7JEjRzR06FA1bNhQ/v7+uuOOO7R3795i+7755pu67rrr5HA41Lp1ay1YsKCioQMAAAAAAACmChfKRowYoXnz5mnYsGF65ZVXZLfbNWDAACUmJl5y3JkzZ9SzZ09t2LBBTz31lGbMmKGkpCT16NFDaWlpLn0XLVqk+++/X+3bt9eCBQt000036dFHH9ULL7xQ0fABAAAAAAAASZJnRQZv3bpVK1as0Ny5czVp0iRJUmxsrMLCwjR58mRt2rSpxLGvv/66UlJStHXrVnXq1EmSdOuttyosLEwvvfSSZs2aJUnKzs7W008/rdtuu00JCQmSpAceeEBOp1PPPfecxowZo0aNGlXkaQAAAAAAAAAVm1GWkJAgu92uMWPGmG0Oh0OjR4/W5s2bdejQoUuO7dSpk1kkk6R27dqpd+/eWrlypdm2bt06paWlady4cS7jH374YWVlZenTTz+tyFMAAAAAAAAAJFWwUJaUlKQ2bdrI39/fpb1z586SpOTk5GLHOZ1O7dixQx07diyyrXPnzvrtt9+UmZlpHkNSkb6RkZHy8PAwtwMAAAAAAAAVUaFLL1NTUxUUFFSk/Xzb0aNHix2Xnp6u3Nzcy45t27atUlNTZbfb1axZM5d+Xl5eatKkSYnHkM7daCA3N9d8fPr0aUlSRkbGZZ6Ze1wYK0qnuv5fVnfkWtmRa+VDrpUduVY+5FrZkWvlQ66VXXXNtfNxGYbh5kgAANVJhQpl2dnZ8vb2LtLucDjM7SWNk1SqsdnZ2fLy8ip2Pw6Ho8RjSNLs2bM1Y8aMIu0hISEljkHN8pe//MXdIaCOINdgFXINViHXYJXqnmuZmZkKCAhwdxgAgGqiQoUyHx+fYn9Vy8nJMbeXNE4q/he5i8f6+PgoLy+v2P3k5OSUeAxJmjJlih5//HHzsdPpVHp6upo0aSKbzVbiOPxXRkaGQkJCdOjQoSKX2AKViVyDVcg1WIVcg1XItfIxDEOZmZkKDg52dygAgGqkQoWyoKAgHTlypEh7amqqJJX4ptO4cWN5e3ub/S41NigoSIWFhTp+/LjL5Zd5eXlKS0u75Bubt7d3kVlrDRs2vPSTQrH8/f354AVLkGuwCrkGq5BrsAq5VnbMJAMAXKxCi/lHRETo3//+d5F1B7Zs2WJuL/agHh7q0KGDtm3bVmTbli1bFBoaKj8/P5d9XNx327ZtcjqdJR4DAAAAAAAAKIsKFcpiYmJUWFioxYsXm225ubmKj49XVFSUuRbYwYMHtWvXriJjv//+e5cC2O7du7V27VoNGTLEbOvVq5caN26shQsXuoxfuHCh6tevr9tuu60iTwEAAAAAAACQVMFLL6OiojRkyBBNmTJFx48fV6tWrbR06VLt379fb775ptkvNjZWGzZscLmjzLhx4/S3v/1Nt912myZNmqR69epp3rx5at68uSZOnGj28/Hx0XPPPaeHH35YQ4YMUb9+/bRx40a98847ev7559W4ceOKPAVchre3t6ZPn17sjReAykSuwSrkGqxCrsEq5BoAAJXHZlTwfsg5OTmaOnWq3nnnHZ08eVLh4eF67rnn1K9fP7NPdHR0kUKZJB0+fFgTJkzQl19+KafTqejoaM2fP1+tWrUqcpy//e1veumll7Rv3z6FhITokUce0fjx41mUHwAAAAAAAJWiwoUyAAAAAAAAoDao0BplAAAAAAAAQG1BoQwAAAAAAAAQhTIAAAAAAABAEoUyAAAAAAAAQJLk6e4ArOR0OnX06FH5+flxt0wAAACgDjMMQ5mZmQoODpaHB/MHAADn1KlC2dGjRxUSEuLuMAAAAABUE4cOHdKVV17p7jAAANVEnSqU+fn5STr3Zujv7+/maAAAAAC4S0ZGhkJCQszvCAAASHWsUHb+ckt/f38KZQAAAKhxUlNTlZqaWur+QUFBCgoKqsKIaj6WZAEAXKhOFcoAAACAmmzRokWaMWNGqftPnz5dcXFxVRcQAAC1DIUyAAAAoIYYO3asBg0aZD7Ozs5W165dJUmJiYny8fFx6c9sMgAAyoZCGQAAAFBDXHwpZVZWlvl3RESEGjRo4I6wAACoNSiUAbAc66sAAAAAAKojCmUALMf6KgBqG34AAAAAqB0olMHEh3xYhfVVYBXOa7AKPwAAAADUDhTKYOJDPqzC+iqwCuc1WIUfAAAAAGoHm2EYhruDsEpGRoYCAgJ0+vRp+fv7uzucaufimRel+ZDPB31UhqysLPn6+kqSzpw5Q6EMlYbzGtyF81rttWbtte4OwUV2tlMDb98vSfrXJy3l4+Ph3oCK0bvXb+4OoVh8NwAAFIcZZTAxywdAbcN5DQAAAEBZVL+fnAAAAAAAAAA3sGxGWW5urqZNm6Zly5bp5MmTCg8P18yZM9WnT59LjouLiyt2fRlvb2/l5ORUVbhArVYdLxs5b936MC4bAVBmnNfKjvMaAABAUZYVykaMGKGEhAQ99thjat26tZYsWaIBAwZo3bp15noxl7Jw4UJzrQ9JstvtVRkuAAAAAAAA6hhLCmVbt27VihUrNHfuXE2aNEmSFBsbq7CwME2ePFmbNm267D5iYmLUtGnTqg7Vrfg1vOz4NRyo3jivlR3nNQCXkpZWoPS0QvNxTu5/z2t79uTK4e16XmvcxK4mTViWGACA0rLkXTMhIUF2u11jxowx2xwOh0aPHq2nnnpKhw4dUkhIyCX3YRiGMjIy5OfnJ5vNVtUhAwAAANXOJ59kaNnbp4rdNuGx1CJt98U21PDhjas4KgAAag9LCmVJSUlq06ZNkdsud+7cWZKUnJx82UJZaGioeXv1wYMH66WXXlLz5s2rLGYAAACgurn9dn/dfFPp79jbuAnLlQAAUBaWFMpSU1MVFBRUpP1829GjR0sc26hRIz3yyCO66aab5O3trY0bN+qvf/2rtm7dqm3bthUpvl0oNzdXubm55uOMjIwKPAsAAIDicTkcrNKkiSe5AwBAFbLkXTY7O1ve3t5F2h0Oh7m9JOPHj3d5fNddd6lz584aNmyYXn/9dT355JMljp09e3axd8wE4F58oQRQ23A5HAAAQO1gyTdPHx8fl5ld5+Xk5Jjby+Kee+7RxIkT9fXXX1+yUDZlyhQ9/vjj5uOMjIzLXuIJoOrxhRJWoSgLq3A5HAAAQO1gybeBoKAgHTlypEh7auq5L8TBwcFl3mdISIjS09Mv2cfb27vYmWwoHl8oYRW+UMIqFGVhFS6HAwAAqB0s+UQXERGhdevWKSMjw2VNsS1btpjby8IwDO3fv1833nhjZYZZ5/GFElbhCyWsQlEWAAAAQFlY8k01JiZGL774ohYvXqxJkyZJOrfQfnx8vKKioszLIQ8ePKizZ8+qXbt25tgTJ04oMDDQZX8LFy7UiRMn1L9/fyvCrzP4QgmgtqEoCwAAAKAsLPn2EBUVpSFDhmjKlCk6fvy4WrVqpaVLl2r//v168803zX6xsbHasGGDDMMw266++mrdfffd6tChgxwOhxITE7VixQpFRERo7NixVoRfZ/CFEgAAAAAA1GWWVUXefvttTZ06VcuWLdPJkycVHh6uTz75RN27d7/kuGHDhmnTpk364IMPlJOTo6uvvlqTJ0/W008/rfr161sUPQAAAAAAAGo7ywplDodDc+fO1dy5c0vss379+iJtf/vb36owKgAAAAAAAOAcj8t3AQAAAAAAAGo/CmUAAAAAAACAKJQBAAAAAAAAkiiUAQAAAAAAAJIolAEAAAAAAACSKJQBAAAAAAAAkiiUAQAAAAAAAJIolAEAAAAAAACSKJQBAAAAAAAAkiiUAQAAAAAAAJIolAEAAAAAAACSKJQBAAAAAAAAkiRPdwdQnRQWFio/P99tx/fwCHbbsSvOkNOZLinX3YEAAAAAAACUC4Wy/+/MmTM6fPiwDMNwWwwNA6a77dgVZchQYeEZZWUtUmFhirvDAQAAAAAAKDMKZTo3k+zw4cOqX7++AgMDZbPZ3BLHmTPum81WUYZh6PTpxpLGKiPjaTGzDAAAAAAA1DQUyiTl5+fLMAwFBgbKx8fHbXHk5bmnQFc5bAoI8FRGpq88PBrL6Ux1d0AAAAAAAABlwmL+F3DXTLLawmazySabJF5HAAAAAABQ8zCjrARr1l5bJfvt3eu3KtkvAAAAAAAAKoYZZQAAAAAAAIAolNUKn322TlOmzCn3+E8/XadOne5Q165D9PPP/67EyAAAAAAAAGoOLr2s4QoKCjRgQE8NGNCz3Pt4662VeuKJsYqJGVDmY3t6kkIAAAAAAKB2YEZZNRUQEK7nnlugrl2H6g9/GKiVKz912TZr1l8VHf1HxcW9ouXLP9I994yXJN1xxxitWvWl2Xfjxu/VtevQEo8zefJftHnzj5ox41X16XNfmY8NAAAAAABQWzAdqBqz2WxKTFypffsOKzr6/xQVFaGrr75CkmS327V+/XuSpOXLPzLH3HvvHXr33Y81eHDf/79tle67b3CJx5gz50n9/PO/9dBD9+r223uV+dgAAAAAAAC1BTPKqrHY2P+VJF1zzZXq0iVSmzb9YG67997BxY65/fbe+v77HTp27ITOnDmrL774RkOGlO2SyvIeGwAAAAAAoCZjRlkNYrPZzL8bNKhfbB8fH4cGD+6jFSv+paZNG6t7985q3LihJccGAAAAAACoySiUlaB3r9/cHYKWL1+lKVPG6cCBI9q06UfNnj25VOPuvXewHnzwGQUGNtaECaMsPTYAAAAAAEBNRaGsGissdKpr16E6ezZbc+Y8aa4RdjmRkR1kt3to795D6tXrZkuPDQAAAAAAUFNRKKvGHnkkVs8880iR9tOnd7g8HjbsDg0bdodL23fffVjq43z66VvlPjYAAAAAAEBtwWL+AAAAAAAAgJhRVm1V9sytxx57Ttu2Fd3nV18tk4+Po0qPDQAAAAAAUBNQKLuAYRjuDqHKvPzy1Co/hmEYMmRIqr2vIwAAAAAAqL249FKS3W6XJOXl5bk5kpqtoEAyjEIZxhl3hwIAAAAAAFBmzCiT5Onpqfr16+vEiROqV6+ePDzcUz/My6u5M7EMw1B6+lnl5f5EoQwAAAAAANRIlhXKcnNzNW3aNC1btkwnT55UeHi4Zs6cqT59+lx27JEjRzRhwgR9+eWXcjqd6tmzp+bPn6/Q0NBKic1msykoKEj79u3TgQMHKmWf5ZGTc9xtx64oQ4YKC04qO+cf4tJLAAAAAABQE1lWKBsxYoQSEhL02GOPqXXr1lqyZIkGDBigdevWqWvXriWOO3PmjHr27KnTp0/rqaeeUr169TR//nz16NFDycnJatKkSaXE5+XlpdatW7v18svN341x27ErrlBO5++SCt0dCAAAAAAAQLlYUijbunWrVqxYoblz52rSpEmSpNjYWIWFhWny5MnatGlTiWNff/11paSkaOvWrerUqZMk6dZbb1VYWJheeuklzZo1q9Li9PDwkMPhuHzHKuJ0HnXbsQEAAAAAAOo6SxbjSkhIkN1u15gx/50x5XA4NHr0aG3evFmHDh265NhOnTqZRTJJateunXr37q2VK1dWadwAAAAAAACoOyyZUZaUlKQ2bdrI39/fpb1z586SpOTkZIWEhBQZ53Q6tWPHDo0aNarIts6dO+vLL79UZmam/Pz8ij1ubm6ucnNzzcenT5+WJGVkZJT7uVSlrCynu0Oocarr/2V1R66VHblWPuRa2ZFr5UOulR25Vj7kWtlV11w7H5dhsL4uAOC/LCmUpaamKigoqEj7+bajR4u/5DA9PV25ubmXHdu2bdtix8+ePVszZswo0l5cUQ41VYC7A0CdQa7BKuQarEKuwSrVO9cyMzMVEFC9YwQAWMeSQll2dra8vb2LtJ9fDyw7O7vEcZLKNVaSpkyZoscff9x87HQ6lZ6eriZNmshms5X+CdRhGRkZCgkJ0aFDh4rMCAQqE7kGq5BrsAq5BquQa+VjGIYyMzMVHBzs7lAAANWIJYUyHx8fl0sgz8vJyTG3lzROUrnGSucKbBcX2Ro2bFiqmOHK39+fD16wBLkGq5BrsAq5BquQa2XHTDIAwMUsWcw/KChIqampRdrPt5X0K07jxo3l7e1drrEAAAAAAABAWVhSKIuIiNC///3vIgt5btmyxdxeHA8PD3Xo0EHbtm0rsm3Lli0KDQ0tcSF/AAAAAAAAoCwsKZTFxMSosLBQixcvNttyc3MVHx+vqKgoc3H9gwcPateuXUXGfv/99y7Fst27d2vt2rUaMmSIFeHXad7e3po+fXqx68QBlYlcg1XINViFXINVyDUAACqPzbDofshDhw7Vhx9+qAkTJqhVq1ZaunSptm7dqjVr1qh79+6SpOjoaG3YsMHlFs2ZmZm68cYblZmZqUmTJqlevXqaN2+eCgsLlZycrMDAQCvCBwAAAAAAQC1nyWL+kvT2229r6tSpWrZsmU6ePKnw8HB98sknZpGsJH5+flq/fr0mTJigmTNnyul0Kjo6WvPnz6dIBgAAAAAAgEpj2YwyAAAAAAAAoDqzZI0yAAAAAAAAoLqjUAYAAAAAAACIQhkAAAAAAAAgycLF/KsDp9Opo0ePys/PTzabzd3hAAAAAHATwzCUmZmp4OBgeXgwfwAAcE6dKpQdPXpUISEh7g4DAAAAQDVx6NAhXXnlle4OAwBQTdSpQpmfn5+kc2+G/v7+bo4GAAAAgLtkZGQoJCTE/I4AAIBUxwpl5y+39Pf3p1AGAAAqTWpqqlJTU0vdPygoSEFBQVUYEYDSYkkWAMCF6lShDAAAoCosWrRIM2bMKHX/6dOnKy4uruoCAgAAQLlQKAMA1FrM8oFVxo4dq0GDBpmPs7Oz1bVrV0lSYmKifHx8XPqTZwAAANUThTKY+EIJq5BrsAqzfGCVi89TWVlZ5t8RERFq0KCBO8ICAAC1RGFhofLz890dRo1Wr1492e32y/ajUAYTXyhhFXINVmGWDwAAAGq6M2fO6PDhwzIMw92h1Gg2m01XXnmlfH19L93PqEOvdEZGhgICAnT69GkW8y/GxbN8SvOFki+VKA9yDe6SlZVlvjGeOXOGWT6oMuQaUP3x3QBATVBYWKiUlBTVr19fgYGB3ICknAzD0IkTJ3T27Fm1bt36kjPLmFEGE5eNwCrkGgAAAABcXn5+vgzDUGBgYJEJBSibwMBA7d+/X/n5+ZcslHlYGBMAAAAAAADKiJlkFVfa15AZZQAAAAAAADVIi3XJVbLfYz0jqmS/NYllM8pyc3P1xBNPKDg4WD4+PoqKitJXX3112XH//Oc/dffddys0NFT169dX27ZtNXHiRJ06darqgwYAAAAAAECdYVmhbMSIEZo3b56GDRumV155RXa7XQMGDFBiYuIlx40ZM0a//vqr7r33Xr366qvq37+/XnvtNd10003Kzs62KHoAAAAAAACU1ccff6wJEyaUe/xHH32k6667ThEREfrpp58qMbLiWXLp5datW7VixQrNnTtXkyZNkiTFxsYqLCxMkydP1qZNm0ocm5CQoOjoaJe2yMhIDR8+XMuXL9f9999flaEDAIAaoKouPygv44If80I37JCtGi6+y6UVAACgqhUUFGjQoEEaNGhQuffxxhtvaNq0afrjH/9Y5mN7epa97GVJoSwhIUF2u11jxowx2xwOh0aPHq2nnnpKhw4dUkhISLFjLy6SSdKdd96p4cOH69dff62qkN2CD/llx4d8oHrjvFZ2nNcAAABQ3dlsNj399NP69NNPlZWVpenTp2vYsGHmtmnTpumzzz5TdHS02rdvr1WrVmnVqlXq06ePxo4dq5iYGEnS+vXrNWHCBCUlJRV7nEcffVQbN27Url27tGDBAm3atEk2m03PP/+8Vq1apRMnTmjatGkaOXKkJKlly5a6++67tW7dOrVu3VrLly8v83OzpFCWlJSkNm3ayN/f36W9c+fOkqTk5OQSC2XFOXbsmCSpadOml+yXm5ur3Nxc83FGRkapjwHUZhQvyo7iBQAAAAD8l81mU1JSkvbu3auOHTuqS5cuatmypSTJbrfr+++/lyQtWbLEHDNy5EgtWbLELJTFx8dr1KhRJR7j1Vdf1Y4dO/TYY49p8ODBZru3t7e2bt2qXbt2qVOnTrrvvvvM2WNpaWnasmVLue8UaskaZampqQoKCirSfr7t6NGjZdrfCy+8ILvdbr6wJZk9e7YCAgLMf2UpxgEAAAAAAKB455fCCg0NVffu3fXNN9+Y20oqft1555367rvvlJqaqjNnzuiTTz7RPffcU+Zjn5+91q5dO3l6epoTqqRza+SXt0gmWVQoy87Olre3d5F2h8Nhbi+td999V2+++aYmTpyo1q1bX7LvlClTdPr0afPfoUOHyhY4AAAAAAAALuvC4pSvr2+xfXx8fDRkyBAtW7ZM77//vnr16qUmTZqU+Vjn60nSudlrBQUFlz12aVly6aWPj4/LJZDn5eTkmNtLY+PGjRo9erT69eun559//rL9vb29iy3QAQAAADVRamqqUlNTS90/KCio2Cs7AAA1W3VYGiY+Pl5xcXHav3+/Nm7cqJdffrlU40aOHKnhw4erWbNmevLJJ6s2yHKwpFAWFBSkI0eOFGk//yYfHBx82X1s375dgwYNUlhYmBISEsp15wIAAACgJlu0aJFmzJhR6v7Tp09XXFxc1QUEAKizCgsLdeONNyorK0uvvvqquT7Z5XTu3Fl2u1179uxR3759qzbIcrCk2hQREaF169YpIyPDZUH/LVu2mNsv5bffflP//v3VrFkzffbZZxWeRgcAAADURGPHjtWgQYPMx9nZ2erataskKTExsciVGswmAwBUlYkTJ+q5554r0m4YhsvjESNGaMSIES5tO3fuLPVx1q9ff8n9//777+bf+/fvL/V+S2JJoSwmJkYvvviiFi9erEmTJkk6d0fK+Ph4RUVFmYvsHzx4UGfPnlW7du3MsceOHVPfvn3l4eGh1atXKzAw0IqQAQAAgGrn4ksps7KyzL8jIiLUoEEDd4QFAECtYUmhLCoqSkOGDNGUKVN0/PhxtWrVSkuXLtX+/fv15ptvmv1iY2O1YcMGl+pg//79tXfvXk2ePFmJiYlKTEw0tzVv3lx9+vSx4inUCYVpJ+RM+28l1rhgXbn8Pbtlu2i9N48mTWVvQuESZUeuwSrkGqxCrgEAgLrk4lldFfXggw/qu+++K9K+efPmUq9rX1ksW+jr7bff1tSpU7Vs2TKdPHlS4eHh+uSTT9S9e/dLjtu+fbskac6cOUW29ejRg0JZJcr+1wfKentRsdtOjh9ZpK1B7Fj5jniwqsNCLUSuwSrkGqxCrgEAgKpU2YWp6uaNN96o8mOU9jW0rFDmcDg0d+5czZ07t8Q+F193KtX+ZKhOfAbeJe+be5S6v0eTplUYDWozcg1WIddgFXINAABUBbvdLknKy8uzfGZVbZOXlyfpv69pSbh1JEz2JoFcBgJLkGuwCrkGq5BrAACgKnh6eqp+/fo6ceKE6tWrJw8PD3eHVCM5nU6dOHFC9evXl6fnpUthFMoAAAAAAACqIZvNpqCgIO3bt08HDhxwdzg1moeHh6666irZbLZL9qNQBgAAAJRSi3XJ7g7BhZGdbf4dumGHbNXwspxjPSPcHQIA1GheXl5q3bq1eekgysfLy6tUM/IolAEAAAAAAFRjHh4ecjgc7g6jTuDiVgAAAAAAAEAUygAAAAAAAABJFMoAAAAAAAAASRTKAAAAAAAAAEkUygAAAAAAAABJ3PUSAAAAqDEK007Imfa7+djIzTX/zt+zWzZvb5f+Hk2ayt4k0LL4AACo6SiUAQAAADVE9r8+UNbbi4rddnL8yCJtDWLHynfEg1UdFgAAtQaFMgAAAKCG8Bl4l7xv7lHq/h5NmlZhNAAA1D4UygAAAIAawt4kkEspAQCoQizmDwAAAAAAAIhCGQAAAAAAACCJQhkAAAAAAAAgiUIZAAAAAAAAIIlCGQAAAAAAACCJQhkAAAAAAAAgiUIZAAAAAAAAIIlCGQAAAAAAACCJQhkAAAAAAAAgiUIZAAAAAAAAIIlCGQAAAAAAACCJQhkAAAAAAAAgiUIZAAAAAAAAIIlCGQAAAAAAACCJQhkAAAAAAAAgiUIZAAAAAAAAIIlCGQAAAAAAACCJQhkAAAAAAAAgiUIZAAAAAAAAIIlCGQAAAAAAACCJQhkAAAAAAAAgiUIZAAAAAAAAIMnCQllubq6eeOIJBQcHy8fHR1FRUfrqq69KNfbIkSMaOnSoGjZsKH9/f91xxx3au3dvFUcMAAAAAACAusSyQtmIESM0b948DRs2TK+88orsdrsGDBigxMTES447c+aMevbsqQ0bNuipp57SjBkzlJSUpB49eigtLc2i6AEAAAAAAFDbeVpxkK1bt2rFihWaO3euJk2aJEmKjY1VWFiYJk+erE2bNpU49vXXX1dKSoq2bt2qTp06SZJuvfVWhYWF6aWXXtKsWbOseAoAAAAAAACo5SyZUZaQkCC73a4xY8aYbQ6HQ6NHj9bmzZt16NChS47t1KmTWSSTpHbt2ql3795auXJllcYNAAAAAACAusOSGWVJSUlq06aN/P39Xdo7d+4sSUpOTlZISEiRcU6nUzt27NCoUaOKbOvcubO+/PJLZWZmys/Pr9jj5ubmKjc313x8+vRpSVJGRka5n0tVcmadcXcINU51/b+s7si1siPXyodcKztyrXzItbIj18qHXCu76ppr5+MyDMPNkQAAqhNLCmWpqakKCgoq0n6+7ejRo8WOS09PV25u7mXHtm3bttjxs2fP1owZM4q0F1eUQ80U4O4AUGeQa7AKuQarkGuwSnXPtczMTAUEVPcoAQBWsaRQlp2dLW9v7yLtDofD3F7SOEnlGitJU6ZM0eOPP24+djqdSk9PV5MmTWSz2Ur/BOqwjIwMhYSE6NChQ0VmBAKViVyDVcg1WIVcg1XItfIxDEOZmZkKDg52dygAgGrEkkKZj4+PyyWQ5+Xk5JjbSxonqVxjpXMFtouLbA0bNixVzHDl7+/PBy9YglyDVcg1WIVcg1XItbJjJhkA4GKWLOYfFBSk1NTUIu3n20r6Fadx48by9vYu11gAAAAAAACgLCwplEVEROjf//53kYU8t2zZYm4vjoeHhzp06KBt27YV2bZlyxaFhoaWuJA/AAAAAAAAUBaWFMpiYmJUWFioxYsXm225ubmKj49XVFSUubj+wYMHtWvXriJjv//+e5di2e7du7V27VoNGTLEivDrNG9vb02fPr3YdeKAykSuwSrkGqxCrsEq5BoAAJXHZlh0P+ShQ4fqww8/1IQJE9SqVSstXbpUW7du1Zo1a9S9e3dJUnR0tDZs2OByi+bMzEzdeOONyszM1KRJk1SvXj3NmzdPhYWFSk5OVmBgoBXhAwAAAAAAoJazZDF/SXr77bc1depULVu2TCdPnlR4eLg++eQTs0hWEj8/P61fv14TJkzQzJkz5XQ6FR0drfnz51MkAwAAAAAAQKWxbEYZAAAAAAAAUJ1ZskYZAAAAAAAAUN1RKAMAAAAAAABEoaxWiouLk81mc3cYJpvNpri4OHeHgSpS3fINdUdV597+/ftls9m0ZMkSy44J9+P/GO5E/gEA4H4UyuqAWbNmadWqVe4OA3UE+QZ3IfdQFcgruBP5BwCA9SiU1QHu/pCVnZ2tZ555xm3Hh7XcnW+ou6zIvWeeeUbZ2dlVegxUL5zT4E7kHwAA1qNQhirhdDqVk5MjSXI4HPL09HRzRABQcZ6ennI4HJfsc+H5D7hQQUGB8vLy3B0GAAAALoFCWQ2XmJioTp06yeFw6Nprr9WiRYtctttsNmVlZWnp0qWy2Wyy2WwaMWJEqfeflZWliRMnKiQkRN7e3mrbtq1efPFFGYZR5DiPPPKIli9frvbt28vb21tffPGFue3iNcrWr1+vjh07usTNuhzVX1Xn24oVKxQZGSk/Pz/5+/urQ4cOeuWVVyRJe/fulc1m0/z584uM27Rpk2w2m9577z1J/13jZc+ePRoxYoQaNmyogIAAjRw5UmfPni3/CwC3qercO3XqlEaMGKGAgAA1bNhQw4cP16lTp4r0K+48danzH6q3qsyr82vcvfjii3r55Zd17bXXytvbW7/88oskadeuXYqJiVHjxo3lcDjUsWNHffzxx+b4U6dOyW6369VXXzXbfv/9d3l4eKhJkyYu78MPPfSQWrRoUYFXAu5Q1ec1p9Opl19+We3bt5fD4VDz5s01duxYnTx5ski/uLg4BQcHq379+urZs6d++eUXtWzZskzHAwCgtmCaTw32008/qW/fvgoMDFRcXJwKCgo0ffp0NW/e3OyzbNky3X///ercubPGjBkjSbr22mtLtX/DMDRo0CCtW7dOo0ePVkREhFavXq0///nPOnLkSJGCxdq1a7Vy5Uo98sgjatq0qVq2bFnsfpOSktS/f38FBQVpxowZKiws1LPPPqvAwMDyvRCwRFXn21dffaU//vGP6t27t1544QVJ0q+//qpvv/1W48ePV2hoqLp06aLly5drwoQJLmOXL18uPz8/3XHHHS7tQ4cO1TXXXKPZs2frxx9/1N///nc1a9bM3D9qBivOdXfccYcSExP14IMP6rrrrtOHH36o4cOHlzrG0p7/UH1UdV6dFx8fr5ycHI0ZM0be3t5q3Lixfv75Z3Xp0kVXXHGFnnzySTVo0EArV67U4MGD9cEHH+jOO+9Uw4YNFRYWpm+++UaPPvqopHOFFZvNpvT0dP3yyy9q3769JGnjxo3q1q1bJb0ysIIV+Td27FgtWbJEI0eO1KOPPqp9+/bptddeU1JSkr799lvVq1dPkjRlyhTNmTNHAwcOVL9+/bR9+3b169ePmbEAgLrLQI01ePBgw+FwGAcOHDDbfvnlF8NutxsX/tc2aNDAGD58eJn3v2rVKkOSMXPmTJf2mJgYw2azGXv27DHbJBkeHh7Gzz//XGQ/kozp06ebjwcOHGjUr1/fOHLkiNmWkpJieHp6GqRk9VXV+TZ+/HjD39/fKCgoKLHPokWLDEnGr7/+arbl5eUZTZs2dTnm9OnTDUnGqFGjXMbfeeedRpMmTcocG9zLqnPdnDlzzLaCggKjW7duhiQjPj7ebD+fWxe61PkP1VdV59W+ffsMSYa/v79x/Phxl229e/c2OnToYOTk5JhtTqfTuPnmm43WrVubbQ8//LDRvHlz8/Hjjz9udO/e3WjWrJmxcOFCwzAMIy0tzbDZbMYrr7xS5hjhPlWdfxs3bjQkGcuXL3dp/+KLL1zajx07Znh6ehqDBw926RcXF2dIKtexAQCo6bj0soYqLCzU6tWrNXjwYF111VVm+3XXXad+/fpVyjE+++wz2e1285fs8yZOnCjDMPT555+7tPfo0UPXX3/9ZeP++uuvNXjwYAUHB5vtrVq10q233lopcaPyWZFvDRs2VFZWlr766qsS+wwdOlQOh0PLly8321avXq3ff/9d9957b5H+Dz74oMvjbt26KS0tTRkZGZUSM6qeVec6T09PPfTQQ2ab3W7Xn/70p1LvozTnP1QfVuTVeXfddZfLjOn09HStXbtWQ4cOVWZmpn7//Xf9/vvvSktLU79+/ZSSkqIjR45IOnfO+s9//qPdu3dLOjdzrHv37urWrZs2btwo6dwsM8MwmFFWg1iRf++//74CAgLUp08fM8d+//13RUZGytfXV+vWrZMkrVmzRgUFBRo3bpzL+LKc/wAAqG0olNVQJ06cUHZ2tlq3bl1kW9u2bSvlGAcOHFBwcLD8/Pxc2q+77jpz+4Wuueaay+7z+PHjys7OVqtWrYpsK64N1YMV+TZu3Di1adNGt956q6688kqNGjWqyDpPDRs21MCBA/Xuu++abcuXL9cVV1yhXr16FdnnhV9AJKlRo0aSVGR9FlRfVp3rgoKC5OvrW+79l+b8h+rDirw67+Lc2LNnjwzD0NSpUxUYGOjyb/r06ZLOvVdKMotfGzduVFZWlpKSktStWzd1797dLJRt3LhR/v7+uuGGGyo1blQdK/IvJSVFp0+fVrNmzYrk2ZkzZ8wcO/9Z7uLPYI0bNzbfMwEAqGtYowyVxsfHx90hoAZr1qyZkpOTtXr1an3++ef6/PPPFR8fr9jYWC1dutTsFxsbq/fff1+bNm1Shw4d9PHHH2vcuHHy8Cha97fb7cUey7joZhRARXH+Q0kuzg2n0ylJmjRpUomzh84XLYKDg3XNNdfom2++UcuWLWUYhm666SYFBgZq/PjxOnDggDZu3Kibb7652HMg6i6n06lmzZq5zMC+EOvCAgBQMgplNVRgYKB8fHyUkpJSZNv5SzTOK++dJK+++mp9/fXXyszMdJlVtmvXLnN7WTVr1kwOh0N79uwpsq24NlQPVuSbJHl5eWngwIEaOHCgnE6nxo0bp0WLFmnq1KnmF8f+/fsrMDBQy5cvV1RUlM6ePav77ruv3MdE9WbVuW7NmjU6c+aMy6yyi/eP2sOqc1pxQkNDJUn16tXTLbfcctn+3bp10zfffKNrrrlGERER8vPz0w033KCAgAB98cUX+vHHHzVjxoxKjRFVy4r8u/baa/X111+rS5culyzkn/8st2fPHpfZj2lpacy+BgDUWfz8WEPZ7Xb169dPq1at0sGDB832X3/9VatXr3bp26BBA506darMxxgwYIAKCwv12muvubTPnz9fNputXGuK2e123XLLLVq1apWOHj1qtu/Zs6fImmeoPqzIt7S0NJfHHh4eCg8PlyTl5uaa7Z6envrjH/+olStXasmSJerQoYPZD7WPVee6goICLVy40GwrLCzUggULyh03qjcr8qokzZo1U3R0tBYtWqTU1NQi20+cOOHyuFu3btq/f7/+8Y9/mJdienh46Oabb9a8efOUn5/P+mQ1jBX5N3ToUBUWFuq5554rsq2goMDcZ+/eveXp6ely/pNU5LMfAAB1CTPKarAZM2boiy++ULdu3TRu3DgVFBRowYIFat++vXbs2GH2i4yM1Ndff6158+aZl3FERUVddv8DBw5Uz5499fTTT2v//v264YYb9OWXX+qjjz7SY489VqZblF8oLi5OX375pbp06aKHHnrILMaFhYUpOTm5XPtE1avqfLv//vuVnp6uXr166corr9SBAwe0YMECRUREmOvinRcbG6tXX31V69at0wsvvFDpzxXVixXnui5duujJJ5/U/v37df311+uf//ynTp8+XZVPC25W1Xl1KX/961/VtWtXdejQQQ888IBCQ0P1n//8R5s3b9bhw4e1fft2s+/5Itju3bs1a9Yss7179+76/PPP5e3trU6dOlUoHlivqvOvR48eGjt2rGbPnq3k5GT17dtX9erVU0pKit5//3298soriomJUfPmzTV+/Hi99NJLGjRokPr376/t27fr888/V9OmTSt9RiUAADWCW++5iQrbsGGDERkZaXh5eRmhoaHGG2+8YUyfPt3l1uK7du0yunfvbvj4+JT5Vt+ZmZnGhAkTjODgYKNevXpG69atjblz5xpOp9OlnyTj4YcfLnYfkozp06e7tK1Zs8a48cYbDS8vL+Paa681/v73vxsTJ040HA5HqWOD9aoy3xISEoy+ffsazZo1M7y8vIyrrrrKGDt2rJGamlps//bt2xseHh7G4cOHi2w7H9OJEydc2uPj4w1Jxr59+0r9nFE9VPW5Li0tzbjvvvsMf39/IyAgwLjvvvuMpKQkQ5IRHx9v9rv4mIZx6fMfqreqzKt9+/YZkoy5c+cWu/23334zYmNjjRYtWhj16tUzrrjiCuP22283EhISivRt1qyZIcn4z3/+Y7YlJiYakoxu3bqV7Umj2qjq85phGMbixYuNyMhIw8fHx/Dz8zM6dOhgTJ482Th69KjZp6CgwJg6darRokULw8fHx+jVq5fx66+/Gk2aNDEefPDBynq6AADUGDbDYFVrVA+DBw/Wzz//XOyaHcDFbrzxRjVu3Fhr1qxxdygAANQqp06dUqNGjTRz5kw9/fTT7g4HAABLsUYZ3CI7O9vlcUpKij777DNFR0e7JyDUKNu2bVNycrJiY2PdHQoAADXaxZ/JJOnll1+WJD6XAQDqJGaU1UGFhYVFFgu+mK+vr8vd3ypbUFCQRowYodDQUB04cEALFy5Ubm6ukpKS1Lp16yo7LqxXmfm2c+dO/fDDD3rppZf0+++/a+/evXI4HJUVKmqZ6nCuQ+1DXsGdqiL/lixZoiVLlmjAgAHy9fVVYmKi3nvvPfXt27fIzQUAAKgLWMy/Djp06JDLLcCLM336dMXFxVVZDP3799d7772nY8eOydvbWzfddJNmzZpFkawWqsx8S0hI0LPPPqu2bdvqvffeo0iGS6oO5zrUPuQV3Kkq8i88PFyenp6aM2eOMjIyzAX+Z86cWcFoAQComZhRVgfl5OQoMTHxkn1CQ0MVGhpqUUSozcg3uAu5h6pAXsGdyD8AAKoehTIAAAAAAABALOYPAAAAAAAASKJQBgAAAAAAAEiiUAYAAAAAAABIolAGAAAAAAAASKJQBgB1UkFBgWbMmKF27dopLCxMERERGjNmjE6dOqX169crIiKi0o95//33a926dZKk9PR0denSRREREXr++ec1bdo0LV++vMLHWLJkiQICAhQREaEbbrhB4eHh+uijj8ztAwYM0O7duyt8HEmKi4uTzWbThx9+aLYZhqFrrrlGDRs2NNsiIiKUmZkpSXr55Zd17Ngxc9sbb7yhuXPnViiO5ORkrVixokL7AAAAAHCOp7sDAABYb/To0UpPT9fmzZvVqFEjGYahhIQEpaenV9kx//73v5t/f/XVV/L19dW3335b7v0VFBTI07Po21jPnj21atUqSdJ3332ngQMH6o477pAkffbZZ+U+XnEiIyP11ltv6c4775QkrVmzRk2bNtXJkyfNPsnJyebfL7/8sqKjo9WiRQtJ0oMPPljhGJKTk7Vq1Sr93//9X5nHlvQaAgAAAHUVM8oAoI7Zs2eP3n//fcXHx6tRo0aSJJvNpiFDhig0NNSlb0FBgfr166eOHTuqffv2uueee5SVlSVJSklJUZcuXXTDDTeoQ4cOeuaZZyRJ//rXvxQeHq6IiAiFhYWZM7qio6O1atUqff311/rzn/+s7777ThEREfr66681YsQIvfzyy5Kk/Px8Pfnkk+rcubMiIiI0dOhQs/A0YsQIjRo1St27d1dYWNhln+upU6fM5yhJLVu2NAtX8+bNU6dOnRQREaFOnTpp8+bNkiSn06lHHnlE1113nW644QZFRkYqJyen2P137dpVv/32mzlL7K233tKoUaNc+thsNp06dUrPPvusjh49qrvvvlsRERFKTk5WXFycHnvsMfN5jxs3Tm3atNH//M//aOLEiYqOjpYkHTt2TD179lRkZKTat2+vRx55RE6nU8ePH9e0adO0bt06RUREmIW31atX6w9/+IPCw8PVo0cP/fLLL5Kk9evXq3379ho9erQiIiJcZsMBAAAAoFAGAHXOjz/+qNatW6tp06aX7Wu32/Xuu+9q27Zt2rlzpwICArRgwQJJ0muvvabbb79d27dv108//aTHH39ckvTMM89o0aJFSk5O1o4dO9SjRw+Xfd5yyy169tln1bNnTyUnJ+uWW25x2T537lw1aNBAW7duVXJysksRTpJ++OEHffrpp9q1a1exMZ8vGrVp00Z33XWX5s2bV2y/++67T99//72Sk5O1YMECjRw5UpK0fft2rVmzRj///LO2b9+utWvXysvLq8TX6N5779XSpUt16tQpff/99+rXr1+x/aZNm6bg4GD94x//UHJycpHLWxcvXqyUlBT9/PPP2rhxo3bs2GFua9iwof71r3/phx9+0I4dO7R//36tXLlSzZo1c3kt33jjDR0/flz33HOPli5dqh07dmjMmDGKiYmRYRiSpF9//VWxsbFKTk7WkCFDSnxeAAAAQF3E9RYAgBIZhqH58+fr008/VUFBgU6fPq2bb75ZktS9e3f9+c9/1pkzZ9SjRw+z4NW7d2+NHz9eMTEx6tu3b5nXO1u1apVOnz6tDz74QJKUl5enli1bmtuHDBkiPz+/EsdfeOnlzp07dcstt+jHH39UcHCwS7+kpCQ9//zzSktLk6enp3bv3q3s7GyFhoaqoKBAo0aNUs+ePXXbbbfJw6Pk35WGDx+uPn36yNfXV0OHDr1k30tZs2aN7r33XtWrV8/c7/nLVZ1Op5544gklJibKMAwdP35cYWFhxV5uuWXLFnXo0EEdOnSQJA0bNkwPP/ywjhw5IkkKDQ0tUrwEAAAAcA4zygCgjvnDH/6glJQUpaWlXbbvu+++q7Vr12rDhg366aefNGnSJPMyxLvuukvffvut2rZta84uk85d0hgfH6/69etr+PDhmjNnTpniMwxDCxYsUHJyspKTk/XLL7+4rC3m6+tb6n2FhYXpqquuKrIWWl5env73f/9XL774onbu3KlvvvlGkpSbm6uAgADt3LlT99xzj3bt2qXw8HDt2bOnxGNcccUVuvrqqzVjxgxzVlplsNls5t/z5s3T8ePHtWXLFu3YsUP33HNPiZeDXk5ZXj8AAACgrqFQBgB1TKtWrXTXXXdp9OjROnXqlKRzxakPPvhAe/fudel78uRJNW3aVP7+/srMzNSSJUvMbSkpKWrevLliY2M1Z84cfffdd5KkXbt2metoPfTQQ2Z7aQ0ePFjz58/X2bNnJUlnz57Vzz//XK7nevjwYaWkpKhNmzYu7Tk5OcrLy9NVV10lSeblpJJ04sQJZWVlqW/fvpo1a5ZatmxprvFVkueee04zZ85Uq1atLtnP399fp0+fLnZbr1699O677yo/P1/5+fl6++23zW0nT55UixYt5HA4dOzYMb3//vsl7vN//ud/9NNPP2nnzp2SpBUrVuiKK67QFVdcccnYAAAAAHDpJQDUSW+99ZZmzpypqKgoeXp6yul0qnv37urdu7cOHjxo9ouNjdVHH32ktm3bKjAwUN26ddOBAwckSQkJCXrnnXfk5eUlp9OpN954Q5L01FNPaffu3fLy8lL9+vW1cOHCMsX2xBNPKDc3V1FRUeasqieeeELt27cv1fjza5RJ5xbInzVrlm644QaXPv7+/po5c6Y6d+6spk2bulzCeOjQIT3wwAPKz89XYWGhunTpoltvvfWSx+zYsaM6dux42dgeffRRPfDAA6pfv75L0VGSxo4dq59++knXX3+9GjVqpI4dO+ro0aOSZF7K2r59ewUHB7us69a7d2+9+OKLCg8P180336w33nhDy5cvV2xsrAoKCtSoUSO9//77LjPUAAAAABTPZpxf3RcAALhVZmam/Pz8lJ+fr2HDhikyMlJPPPGEu8MCAAAA6gwKZQAAVBNRUVHKzc1VTk6OunbtqgULFsjHx8fdYQEAAAB1BoUyAAAAAAAAQCzmDwAAAAAAAEiiUAYAAAAAAABIolAGAAAAAAAASKJQBgAAAAAAAEiiUAYAAAAAAABIolAGAAAAAAAASKJQBgAAAAAAAEiiUAYAAAAAAABIkv4fF/ZFlh0dIM0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x1000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_type = BASELINE\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_metrics_mean,\n",
    "        transf_metrics_mean,\n",
    "        dir_metrics_mean,\n",
    "        reweigh_metrics_mean,\n",
    "        eg_metrics_mean]\n",
    "#         pr_orig_metrics_mean,\n",
    "#         cpp_metrics_mean,\n",
    "#         ro_metrics_mean]\n",
    "\n",
    "\n",
    "errors = [orig_error_metrics,\n",
    "        transf_error_metrics,\n",
    "        dir_error_metrics,\n",
    "        reweigh_error_metrics,\n",
    "        eg_error_metrics]\n",
    "#         pr_orig_error_metrics,\n",
    "#         cpp_error_metrics,\n",
    "#         ro_error_metrics]\n",
    "\n",
    "index = pd.Series([model_type+'_orig']+ [model_type+'_syn'] + [model_type+'_dir'] + [model_type+'_rew'] + [model_type+'_eg'], name='Classifier Bias Mitigator')\n",
    "#                   + [model_type+'_rew']+  + [model_type+'_cpp'], name='Classifier Bias Mitigator')\n",
    "\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis=0).set_index(index)\n",
    "df_error = pd.concat([pd.DataFrame(metrics) for metrics in errors], axis=0).set_index(index)\n",
    "ax = df.plot.bar(yerr=df_error, capsize=4, rot=0, subplots=True, title=['','','','','', '', '', '', '', ''], fontsize = 12, figsize=(10,10))\n",
    "plot1 = ax[0]\n",
    "plot1.set_ylim=([0, 0.8])\n",
    "plot2 = ax[1]\n",
    "plot2.set_ylim=([-0.5, 0])\n",
    "plot3 = ax[2]\n",
    "plot3.set_ylim=([0, 1])\n",
    "plot4 = ax[3]\n",
    "plot4.set_ylim=([-0.5, 0])\n",
    "plot5 = ax[4]\n",
    "plot5.set_ylim=([-0.5, 0])\n",
    "plot5 = ax[5]\n",
    "plot5.set_ylim=([0, 0.2])\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.5, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7aff8d",
   "metadata": {},
   "source": [
    "## Visualization of MIA results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588cc377",
   "metadata": {},
   "source": [
    "### Visualization of MIA Attacks against various Fairness Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a42bd",
   "metadata": {},
   "source": [
    "#### Privacy risk subpopulations vs Fairness with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8dddfde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "%matplotlib inline\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "eg_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in eg_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "# cpp_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in cpp_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "eg_mia_metrics_mean = {k:sum(v)/N for (k,v) in eg_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "# cpp_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d6882740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entire_dataset_mia_privacy_risk</th>\n",
       "      <th>entire_dataset_label_0.0_mia_privacy_risk</th>\n",
       "      <th>entire_dataset_label_1.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_0.0_label_0.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_0.0_label_1.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_1.0_label_0.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_1.0_label_1.0_mia_privacy_risk</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier MIA Attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>orig</th>\n",
       "      <td>0.64480</td>\n",
       "      <td>0.737741</td>\n",
       "      <td>0.605814</td>\n",
       "      <td>0.737380</td>\n",
       "      <td>0.650751</td>\n",
       "      <td>0.743319</td>\n",
       "      <td>0.599477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syn</th>\n",
       "      <td>0.64725</td>\n",
       "      <td>0.746163</td>\n",
       "      <td>0.606302</td>\n",
       "      <td>0.748607</td>\n",
       "      <td>0.648359</td>\n",
       "      <td>0.749670</td>\n",
       "      <td>0.600864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dir</th>\n",
       "      <td>0.64610</td>\n",
       "      <td>0.742797</td>\n",
       "      <td>0.607110</td>\n",
       "      <td>0.743699</td>\n",
       "      <td>0.658351</td>\n",
       "      <td>0.747103</td>\n",
       "      <td>0.599885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rew</th>\n",
       "      <td>0.65030</td>\n",
       "      <td>0.748967</td>\n",
       "      <td>0.609345</td>\n",
       "      <td>0.737628</td>\n",
       "      <td>0.656423</td>\n",
       "      <td>0.758188</td>\n",
       "      <td>0.603685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eg</th>\n",
       "      <td>0.57230</td>\n",
       "      <td>0.627087</td>\n",
       "      <td>0.555299</td>\n",
       "      <td>0.665955</td>\n",
       "      <td>0.610166</td>\n",
       "      <td>0.623747</td>\n",
       "      <td>0.550487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        entire_dataset_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                    \n",
       "orig                                            0.64480   \n",
       "syn                                             0.64725   \n",
       "dir                                             0.64610   \n",
       "rew                                             0.65030   \n",
       "eg                                              0.57230   \n",
       "\n",
       "                        entire_dataset_label_0.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                              \n",
       "orig                                                     0.737741   \n",
       "syn                                                      0.746163   \n",
       "dir                                                      0.742797   \n",
       "rew                                                      0.748967   \n",
       "eg                                                       0.627087   \n",
       "\n",
       "                        entire_dataset_label_1.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                              \n",
       "orig                                                     0.605814   \n",
       "syn                                                      0.606302   \n",
       "dir                                                      0.607110   \n",
       "rew                                                      0.609345   \n",
       "eg                                                       0.555299   \n",
       "\n",
       "                        subpopulation_0.0_label_0.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                                 \n",
       "orig                                                        0.737380   \n",
       "syn                                                         0.748607   \n",
       "dir                                                         0.743699   \n",
       "rew                                                         0.737628   \n",
       "eg                                                          0.665955   \n",
       "\n",
       "                        subpopulation_0.0_label_1.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                                 \n",
       "orig                                                        0.650751   \n",
       "syn                                                         0.648359   \n",
       "dir                                                         0.658351   \n",
       "rew                                                         0.656423   \n",
       "eg                                                          0.610166   \n",
       "\n",
       "                        subpopulation_1.0_label_0.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                                 \n",
       "orig                                                        0.743319   \n",
       "syn                                                         0.749670   \n",
       "dir                                                         0.747103   \n",
       "rew                                                         0.758188   \n",
       "eg                                                          0.623747   \n",
       "\n",
       "                        subpopulation_1.0_label_1.0_mia_privacy_risk  \n",
       "Classifier MIA Attacks                                                \n",
       "orig                                                        0.599477  \n",
       "syn                                                         0.600864  \n",
       "dir                                                         0.599885  \n",
       "rew                                                         0.603685  \n",
       "eg                                                          0.550487  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "           transf_mia_metrics_mean,\n",
    "           dir_mia_metrics_mean,\n",
    "           reweigh_mia_metrics_mean,\n",
    "           eg_mia_metrics_mean\n",
    "          ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "          transf_mia_error_metrics,\n",
    "          dir_mia_error_metrics,\n",
    "          reweigh_mia_error_metrics,\n",
    "          eg_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn'] + ['dir'] + ['rew'] + ['eg'], name='Classifier MIA Attacks')\n",
    "#                   + ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "07df1431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['entire_dataset_mia_privacy_risk',\n",
       "       'entire_dataset_label_0.0_mia_privacy_risk',\n",
       "       'entire_dataset_label_1.0_mia_privacy_risk',\n",
       "       'subpopulation_0.0_label_0.0_mia_privacy_risk',\n",
       "       'subpopulation_0.0_label_1.0_mia_privacy_risk',\n",
       "       'subpopulation_1.0_label_0.0_mia_privacy_risk',\n",
       "       'subpopulation_1.0_label_1.0_mia_privacy_risk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7e2f4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = df[['subpopulation_0.0_label_0.0_mia_privacy_risk',\n",
    "       'subpopulation_0.0_label_1.0_mia_privacy_risk',\n",
    "       'subpopulation_1.0_label_0.0_mia_privacy_risk',\n",
    "       'subpopulation_1.0_label_1.0_mia_privacy_risk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "24d711e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subpopulation_0.0_label_0.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_0.0_label_1.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_1.0_label_0.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_1.0_label_1.0_mia_privacy_risk</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier MIA Attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>orig</th>\n",
       "      <td>0.737380</td>\n",
       "      <td>0.650751</td>\n",
       "      <td>0.743319</td>\n",
       "      <td>0.599477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syn</th>\n",
       "      <td>0.748607</td>\n",
       "      <td>0.648359</td>\n",
       "      <td>0.749670</td>\n",
       "      <td>0.600864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dir</th>\n",
       "      <td>0.743699</td>\n",
       "      <td>0.658351</td>\n",
       "      <td>0.747103</td>\n",
       "      <td>0.599885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rew</th>\n",
       "      <td>0.737628</td>\n",
       "      <td>0.656423</td>\n",
       "      <td>0.758188</td>\n",
       "      <td>0.603685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eg</th>\n",
       "      <td>0.665955</td>\n",
       "      <td>0.610166</td>\n",
       "      <td>0.623747</td>\n",
       "      <td>0.550487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        subpopulation_0.0_label_0.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                                 \n",
       "orig                                                        0.737380   \n",
       "syn                                                         0.748607   \n",
       "dir                                                         0.743699   \n",
       "rew                                                         0.737628   \n",
       "eg                                                          0.665955   \n",
       "\n",
       "                        subpopulation_0.0_label_1.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                                 \n",
       "orig                                                        0.650751   \n",
       "syn                                                         0.648359   \n",
       "dir                                                         0.658351   \n",
       "rew                                                         0.656423   \n",
       "eg                                                          0.610166   \n",
       "\n",
       "                        subpopulation_1.0_label_0.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                                 \n",
       "orig                                                        0.743319   \n",
       "syn                                                         0.749670   \n",
       "dir                                                         0.747103   \n",
       "rew                                                         0.758188   \n",
       "eg                                                          0.623747   \n",
       "\n",
       "                        subpopulation_1.0_label_1.0_mia_privacy_risk  \n",
       "Classifier MIA Attacks                                                \n",
       "orig                                                        0.599477  \n",
       "syn                                                         0.600864  \n",
       "dir                                                         0.599885  \n",
       "rew                                                         0.603685  \n",
       "eg                                                          0.550487  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "75f230c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Classifier MIA Attacks'>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_groups.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9225fcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  orig       syn       dir       rew        eg\n",
      "--------------------------------------------  --------  --------  --------  --------  --------\n",
      "subpopulation_0.0_label_0.0_mia_privacy_risk  0.73738   0.748607  0.743699  0.737628  0.665955\n",
      "subpopulation_0.0_label_1.0_mia_privacy_risk  0.650751  0.648359  0.658351  0.656423  0.610166\n",
      "subpopulation_1.0_label_0.0_mia_privacy_risk  0.743319  0.74967   0.747103  0.758188  0.623747\n",
      "subpopulation_1.0_label_1.0_mia_privacy_risk  0.599477  0.600864  0.599885  0.603685  0.550487\n"
     ]
    }
   ],
   "source": [
    "# Tabular Format\n",
    "# importing the modules\n",
    "from tabulate import tabulate\n",
    "\n",
    " \n",
    "# displaying the DataFrame\n",
    "print(tabulate(df_groups.T, headers = 'keys', tablefmt = 'simple'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a2e6d",
   "metadata": {},
   "source": [
    "### Visualizing using novel technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6faed82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_error_metrics = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "eg_mia_error_metrics = {k: v for (k,v) in eg_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "#orig_mia_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7f5e92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_error_metrics.keys():\n",
    "    for val in orig_mia_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in eg_mia_error_metrics.keys():\n",
    "    for val in eg_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"eg\", key.replace(\"_mia_attacker_advantage\", \"\"), val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5b110698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fairness</th>\n",
       "      <th>MIA</th>\n",
       "      <th>Privacy Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.517117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.517982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.517550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.521300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.524954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.504434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.505321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.502599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.503012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.501923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Fairness                                           MIA  Privacy Risk\n",
       "0       orig               entire_dataset_mia_privacy_risk      0.517117\n",
       "1       orig               entire_dataset_mia_privacy_risk      0.517982\n",
       "2       orig               entire_dataset_mia_privacy_risk      0.517550\n",
       "3       orig               entire_dataset_mia_privacy_risk      0.521300\n",
       "4       orig               entire_dataset_mia_privacy_risk      0.524954\n",
       "..       ...                                           ...           ...\n",
       "695       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.504434\n",
       "696       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.505321\n",
       "697       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.502599\n",
       "698       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.503012\n",
       "699       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.501923\n",
       "\n",
       "[700 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"Privacy Risk\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6e8a5e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fairness</th>\n",
       "      <th>MIA</th>\n",
       "      <th>Privacy Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.517117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.517982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.517550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.521300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.524954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.504434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.505321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.502599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.503012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.501923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Fairness                                           MIA  Privacy Risk\n",
       "0       orig               entire_dataset_mia_privacy_risk      0.517117\n",
       "1       orig               entire_dataset_mia_privacy_risk      0.517982\n",
       "2       orig               entire_dataset_mia_privacy_risk      0.517550\n",
       "3       orig               entire_dataset_mia_privacy_risk      0.521300\n",
       "4       orig               entire_dataset_mia_privacy_risk      0.524954\n",
       "..       ...                                           ...           ...\n",
       "695       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.504434\n",
       "696       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.505321\n",
       "697       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.502599\n",
       "698       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.503012\n",
       "699       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.501923\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only subgroups\n",
    "df_subgroups = df[~((df[\"MIA\"] == \"entire_dataset_label_0.0_mia_privacy_risk\") | (df[\"MIA\"] == \"entire_dataset_label_1.0_mia_privacy_risk\")) ]\n",
    "df_subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0df3d1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1f504a7cb90>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2kAAAOyCAYAAADpcZ1KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd2BUVd7/8ff09N6AQBJSgIA0BUERERFde3fVte3adl1X3V7dZ/d59rfdXlfdddeydrE3VOyiSCdAElJISEjvmT7398dAYEQJKGQmk8/rL3LmzswZCHfu555zvsdkGIaBiIiIiIiIRARzuDsgIiIiIiIiuyikiYiIiIiIRBCFNBERERERkQiikCYiIiIiIhJBFNJEREREREQiiEKaiIiIiIhIBFFIExERERERiSAKaSIiIiIiIhFEIU1ERERERCSCRFRIu/fee7nooov2ekxHRwc/+tGPmDVrFrNnz+Z3v/sdTqdziHooIiIiIiJycFnD3YGdHnnkEW655RYOO+ywvR73gx/8AKfTyYMPPkh3dze/+tWv6O/v589//vMQ9VREREREROTgCXtIa2pq4re//S3Lly8nPz9/r8euWrWKTz75hJdffpnCwkIAfv/733P55Zfzwx/+kOzs7CHosYiIiIiIyMET9umOGzZswGaz8fzzzzNt2rS9HrtixQoyMzMHAhrA7NmzMZlMfPbZZwe7qyIiIiIiIgdd2EfSFi5cyMKFC/fp2KamJkaNGhXSZrfbSUlJobGx8WB0T0REREREZEiFfSRtfzidTux2+x7tDocDt9v9lV/XMIyv0y0REREREZEDJuwjafsjJiYGj8ezR7vb7SYuLu4rv24gYNDd3f91uiYiIiIiMqRSU+PD3QU5SIZVSMvJyWHp0qUhbR6Ph87OTrKysr7Wa/t8ga/1fBERERERkQNhWE13nDVrFtu3b6e2tnag7ZNPPgHg0EMPDVe3REREREREDpiIDml+v5+WlhZcLhcA06ZNY+bMmdxwww2sXbuWjz/+mBtvvJHTTz9d5fdFRERERCQqRHRIa2xsZN68ebz88ssAmEwm7rjjDnJzc7nkkku4/vrrmT9/Pv/zP/8T3o6KiIiIiIgcICZDpQ3x+wO0t/eFuxsiIiIiIvssMzMx3F2QgySiR9JERERERERGGoU0ERERERGRCKKQJiIiIiIiEkEU0kRERERERCKIQpqIiIiIiEgEUUgTERERERGJIAppIiIiIiIiEUQhTUREREREJIIopImIiIiIiEQQhTQREREREZEIopAmIiIiIiISQRTSREREREREIohCmoiIiIiISARRSBMREREREYkgCmkiIiIiIiIRRCFNREREREQkgiikiYiIiIiIRBCFNBERERERkQiikCYiIiIiIhJBFNJEREREREQiiEKaiIiIiIhIBFFIExERERERiSAKaSIiIiIiIhFEIU1ERERERCSCKKSJiIiIiIhEEIU0ERERERGRCKKQJiIiIiIiEkEU0kRERERERCKIQpqIiIiIiEgEUUgTERERERGJIAppIiIiIiIiEUQhTUREREREJIIopImIiIiIiEQQhTQREREREZEIopAmIiIiIiISQRTSREREREREIohCmoiIiIiISARRSBMREREREYkgCmkiIiIiIiIRRCFNREREREQkgiikiYiIiIiIRBCFNBERERERkQiikCYiIiIiIhJBFNJEREREREQiiEKaiIiIiIhIBFFIExERERERiSAKaSIiIiIiIhFEIU1ERERERCSCKKSJiIiIiIhEEIU0ERERERGRCKKQJiIiIiIiEkEU0kRERERERCKIQpqIiIiIiEgEUUgTERERERGJIAppIiIiIiIiEUQhTUREREREJIIopImIiIiIiEQQhTQREREREZEIopAmIiIiIiISQRTSREREREREIohCmoiIiIiISARRSBMREREREYkgCmkiIiIiIiIRRCFNREREREQkgiikiYiIiIiIRBCFNBERERERkQiikCYiIiIiIhJBFNJEREREREQiiEKaiIiIiIhIBFFIExERERERiSAKaSIiIiIiIhFEIU1ERERERCSCKKSJiIiIiIhEEIU0ERERERGRCKKQJiIiIiIiEkEU0kRERERERCKIQpqIiIiIiEgEUUgTERERERGJIAppIiIiIiIiEUQhTUREREREJIIopImIiIiIiEQQhTQREREREZEIopAmIiIiIiISQRTSREREREREIohCmoiIiIiISARRSBMREREREYkgCmkiIiIiIiIRRCFNREREREQkgiikiYiIiIiIRBCFNBERERERkQiikCYiIiIiIhJBFNJEREREREQiiEKaiIiIiIhIBFFIExERERERiSAKaSIiIiIiIhFEIU1ERERERCSCKKSJiIiIiIhEEIU0ERERERGRCKKQJiIiIiIiEkEU0kRERERERCKIQpqIiIiIiEgEUUgTERERERGJIAppIiIiIiIiEUQhTUREREREJIIopImIiIiIiEQQhTQREREREZEIopAmIiIiIiISQRTSREREREREIohCmoiIiIiISARRSBMREREREYkgCmkiIiIiIiIRRCFNREREREQkgiikiYiIiIiIRBCFNBERERERkQiikCYiIiIiIhJBFNJEREREREQiiEKaiIiIiIhIBFFIExERERERiSAKaSIiIiIiIhFEIU1ERERERCSCKKSJiIiIiIhEEIU0ERERERGRCKKQJiIiIiIiEkEU0kRERERERCKIQpqIiIiIiEgEUUgTERERERGJIAppIiIiIiIiEUQhTUREREREJIIopImIiIiIiEQQhTQREREREZEIopAmIiIiIiISQcIe0gKBALfddhtHHXUU06dP54orrqCuru5Lj29ra+NHP/oRc+bM4fDDD+eGG26gqalpCHssIiIiIiJy8IQ9pN111108+uij/O///i+PPfYYgUCAyy+/HI/H84XHX3/99TQ0NPCvf/2Lf/3rXzQ0NHDNNdcMca9FREREREQOjrCGNI/Hwz//+U9+8IMfsGDBAiZOnMjNN9/M9u3bef311/c4vru7m08++YQrrriCSZMmUVpaypVXXsm6devo7Owc+g8gIiIiIiJygIU1pG3atIm+vj7mzp070JaUlERpaSmffvrpHsfHxMQQHx/PkiVL6O3tpbe3l+eee46CggKSkpKGsusiIiIiIiIHhTWcb759+3YARo0aFdKelZU18Nju7HY7f/rTn7jxxhs57LDDMJlMZGVl8fDDD2M2f728abWGfeaniIiIiIhIeEOa0+kEguFrdw6Hg66urj2ONwyDjRs3MmPGDC6//HL8fj8333wz3/ve9/jvf/9LQkLCV+qH2WwiNTX+Kz1XRERERETkQAprSIuJiQGCa9N2/hnA7XYTGxu7x/GvvPIKDz/8MG+//fZAILvnnns45phjeOqpp7j00ku/Uj8CAYPu7v6v9FwRERERkXDQIEP0CmtI2znNsbm5mXHjxg20Nzc3M2HChD2OX7FiBQUFBSEjZsnJyRQUFFBbW/u1+uLzBb7W80VERERERA6EsC7EmjhxIgkJCSxfvnygrbu7m7KyMmbNmrXH8Tk5OdTW1uJ2uwfa+vv7qa+vJz8/fyi6LCIiIiIiclCFNaTZ7Xa+9a1v8be//Y0333yTTZs2ccMNN5CTk8PixYvx+/20tLTgcrkAOP3004HgXmmbNm1i06ZN/PCHP8ThcHDmmWeG8ZOIiIiIiIgcGGEvafiDH/yAs88+m1//+tecf/75WCwWHnjgAWw2G42NjcybN4+XX34ZCFZ9fPTRRzEMg0suuYTLLrsMm83Go48+SmJiYpg/iYiIiIiIyNdnMgzDCHcnws3vD9De3hfuboiIiIiI7LPMTA1SRKuwj6SJiIiIiIjILgppIiIiIiIiEUQhTUREREREJIIopImIiIiIiEQQhTQREREREZEIopAmIiIiIiISQRTSREREREREIohCmoiIiIiISARRSBMREREREYkgCmkiIiIiIiIRRCFNREREREQkgiikiYiIiIiIRBCFNBERERERkQiikCYiIiIiIhJBFNJEREREREQiiEKaiIiIiIhIBFFIExERERERiSAKaSIiIiIiIhFEIU1ERERERCSCKKSJiIiIiIhEEIU0ERERERGRCKKQJiIiIiIiEkEU0kRERERERCKIQpqIiIiIiEgEUUgTERERERGJIAppIiIiIiIiEUQhTUREREREJIIopImIiIiIiEQQhTQREREREZEIopAmIiIiIiISQRTSREREREREIohCmoiIiIiISARRSBMREREREYkgCmkiIiIiIiIRRCFNREREREQkgiikiYiIiIiIRBCFNBERERERkQiikCYiIiIiIhJBFNJEREREREQiiEKaiIiIiIhIBFFIExERERERiSAKaSIiIiIiIhFEIU1ERERERCSCKKSJiIiIiIhEEIU0ERERERGRCKKQJiIiIiIiEkEU0kRERERERCKIQpqIiIiIiEgEUUgTERERERGJIAppIiIiIiIiEUQhTUREREREJIIopImIiIiIiEQQhTQREREREZEIopAmIiIiIiISQRTSREREREREIohCmoiIiIiISARRSBMREREREYkgCmkiIiIiIiIRRCFNREREREQkgiikiYiIiIiIRBBruDsgIiIiI1NTXzNPVjwPwDnFp5IdnxXmHomIRAaNpImIiEhYPFXxAhvby9nYXs5TlS+EuzsiIhFDIU1ERETCYnt/864/9zXv5UgRkZFFIU1ERERERCSCKKSJiIiIiIhEEIU0ERERCQu/P/CFfxYRGekU0kRERGRIlXdsAaDP5Rto2/3POx8XERmpVIJfRPbbtk1VVP/rQQAKLruUMRPHh7dDIjJsvFT1Oi/XLOXEguNI7HJz9OpOAJZNC16SvFT9Bi9Xv8GJ+Ys4afziMPZURCR8NJImIvut+l//JqttK1ltW6l+8D/h7o6IDBPlHVt4uWYpAC9Xv8H81W3kbfeQt93D/DXtAwEN4OWapRpRE5ERSyFNRPZbbE/brj93t4axJyIynJSkFnJiwXEDP6f1eAf+nN7tHQhoACcWHEdJauGQ9k9EJFKYDMMwwt2JcPP7A7S394W7GyIRqfW5Z+l65+2QNm93D2aCp44AJmxJiXs8L2XBQtJPPX0ouigiw8Du5xK334Pb7yHWFRi4WxwAnDHBnxwWOw6LHdC5RGRvMjP3/P6V6KA1aSKyV8nzF9DxyksYvl2L+ncfgjdj4O/uDnmOyWol6aijh6iHIjIc7H4usbLnBYgZiHftrPDowo9L5xIRGbE03VFE9sqWmkry/P27SEqevwBbaupB6pGIDEc6l4iI7DuFNBEZVOo3TsZk3beBd5PVSuo3TjrIPRKR4ci+6BgCZtO+HaxziYiMYAppIjKo/bkDrjvfIvJF2pwd3Fr1KGuLYvbp+KT583UuEZERSyFNRPZJ6jdOBotl7wfpzreIfIHGviZuWnkXzf2trCiNwz/I1YfPDMuL44emcyIiEUghTUT2icnuwDdILdimgum68y0iIaq7tnLzZ3fT6e4CwGMz0Rez98uP9UWxvN6zXPukiciIpZAmIoNyeXzc8vwm1mTnfukxhgnejrPS0eMewp6JSCTb2F7Obav/QZ+vf6DN7IfAXpal+UwmVpTG4d1WSE/zrvLi2jFIREYShTQR2avOXjd/fmQVDf73eH9BP86EL766ah9rpWlyFf994a6Qcv0iMjKtbF7L3Wv+hcfvGWgz/Ba6a2fxeN7ReExfPH16ddIEeqoO46TPGnj8iQ9YVdGC1+/lzjUP8FnTmqHqvohIWGkza7SZtciX2dbSyy1PrqHDaMAx6VMAEnp9fPv5dnaPagEz/PPUdOJcAc5e2ol79Fhm/PSXmGP2rUCAiESX97Z9zOObn8Vg1yWG4bPh3nwoRl8KAAV99Zzb+FbIucRvMnPvuNNY3PIJRf3bcJrtPDXqGGIXdbHNW4UJE9+ccAbzxswZ2g8kEqG0mXX00kiaiOwh4HZTtqGW//fwZ7R1uxnbH2BRWy8AvQlWvNbQ0bS1RbGYA3Dasi7sPoPErVvZ+Pv/xdfVFY7ui0iYGIbBqzVv8djmZ0IDmseBe+NsjL4UTEBBbA9nj1mL93M7eyRmBbi672WK+rcBEBvw8M3GN+juqAi+Dgb/3fwMr9W8pemPIhLVFNJEJISvq5ONv/s9rXfdhs/pAuAQex2LOvoHgprbtiukGcCK0jgmVzmJdwUG2v2tzbz5/mZdSImMEAEjwDOVL/JC1asDbVPL+5lQHsBddjiGM5GslFj+9M1xXJ/8GrnmVryfO5ckjIL0NDem3a5OVqSW0GUNHS14vupVnq18SecXEYlaCmkiMsC1rZ5NN/4WW/M2ctxtnLr9PUxGgDhTcE3JtF43cT4/xm5nDq/VRF+chYTRBgmjg22GycTTo47h8XW9PPTaZvyBwBe8m4hEC3/Az8Mbn+StuveCDYbBEat7OWZFL8etaCOvs5O8nER+8a2ZxK16BDzBQiIhUx2tYLFDTAqkTQSTzcyWjAm8kzILd9nhBPpCg9qbde/y8KYn8Qf8Q/MhRUSGkEKaiADg9QV4/dn3sfftmqJY3F/PNKOZQw/JY3OcnTtzU+m3WmhP2jVHqSndCoaBHUjIhaR8qMvNpS42B4Blqxu485n1uL26kBKJRh6/l/vWP8Ty7Z8NtM1Z18essmAQs2BwdtM7XH9UBgl9dQRaqgeOi3fsGgmzxu16TXsCZJQGOOrq05kwLhV8DtybZuPvDt3i4+PGFTyw/mG8fu9B+nQiIuGhkCYi9Lm83PzEapb0ZvFh6hQAApj4dPxRXDzHycoEFw+OSsZlCZ4y3jk0gdocO43pVt6alQgmEy9nJPJGWjzxWdBccGjI66+ubOVv/11FT79nj/cWkeHL6XNy55r7WddaFtK+JiOXbmvswM/xY3OJz0zHV7sq5LiMsWBPAls8ZOaFvrbVAbbm9fzwvGnMLMkEvw3P5sPwd2Ri8waw7ti4cU3rBu5a809cPtfB+ZAiImGg6o6ouqOMbC2dTm55cg2NbTv2MTIMTmj5GAqLWDSmgmdoYlVS7N5fZIe5nf2c1toLiVm84DiVpeWhoWyyrZtzxvoYe85ZmEx72ShJRCJet6eHO1c/QH1vQ0i7r2U03uopZLq7uGT76yRNnMjoq7+H2eHA9d6DeDcu2+f3sE1aQMxRlxIIGDz0+mbeWd2AGS/ntb+AzezihaNTcDmCN4/GJebyvWnfJtGecCA/pkhEU3XH6GUd/BARiVZVDd3c9tQauvt3mypkMmE/Zj6z+5bwD3uAupi9BzSTYWDsCFwfpcQR7w+wqKOZUzz/JXPqmfx3bfCxVE83x1a9gmujmy2tLRReeQUmq05BIsNRm7Od21ffR4uzLaTd25iPr24CYOKYE2ZROHYO9uwcTJbgnmgmR/x+vc/O481mExcfP4GkWBs8+zB5vcEiRue80cGSBSn0JFjY2lPPzSvv4drpl5Mak/K1P6OISDhpuqPICOTv72P97fdw60MfhQY04KqZXkq6/sttaVAXY/vC58f4dxUCSfYFmNntHPh5aXoCW2Jt4O5jTsOjXDujl3ifk3Mb3yQu4AYgsHI5m26/6yB8MhE52Bp6t/P3z+4aCGgxO6q6eutK8NVNwGI2c8UppZxw+Dgco8cMBDQAa96M/Xovy5jJA382mUwcl9rD5N5da9rSuv0U1bkHfm7qb+bvn91FU1/zV/psIiKRQiFNZITxtrWx8be/w77mY06qfxuzESzoYbWY+NXMFlxtz3JvTjw9VkvI88Yl5gJwYv4iYo3dpiqaTFx6xPWcmL8IgGM7XBQ6g8HPCPgxN73AD6c10WlP2tUHk4VHu3J4b23oNCkRiWxVXbXcvPJuujzdABTWubns+TZyV2bjaxyPw2blunOmMndyTsjzAt0t+NvqMGcVYs4s2Of3c334CIGeloGfE6ZOJ/O88wd+XpVUzPKYmSHP6XB3ctPKu9naU/9VPqKISETQmjS0Jk1GDm9vH5t/8TPszt6BtnWJ4/kgbx4/LVrPO+7NvJsaOh3JjInzJpzBvDFzKO/YQklqIb9+4yd0WHZMY/Qb/N9xfwWgvGMLhT4zztduxejv5P3kWF7MTOSIzn4Oz7+E9Y++zsTOSp4ZtYDK+LEAnH5UAaccka81aiIRzjAMbll1D5WdwZGsqeX9LFjRi4ngjZfnCk/k/EuOo2BUUsjzfA2bcL1xB1jtxJ3xWwxXL/3P/2GgDP9gTDGJxCy+FmtOyUBb9ycf0/D+x9xmTMPlNbCkN2ArWIfJvOuSJsbi4Kqpl1KSWvj1P7xIhNKatOilkTSREcLt8XP3q1v4KLY49IGkRH6cu4zHjS17BLQEayzXzbyaeWPmAAxc7GSZHAPHZLPrzyWphVgyC4g7/TeUZ4/mpYzgAv4PU+J4zbyWQ358Nc9POHUgoAEsea+af7+qvdREIp3JZOLbpd8ixkjC5g0wc6NzYJ8zm+Hn3J4V5GeHFu3wbFyG86W/Yrh7Mfracb5xO+bkLOJO/dWXjqiZ4lJCfjZcPThf/DPeze8NtCXNnsOEG67jZxceRlKcDX/baDwVMzACuy5rXH43d655gLUtGw7I5xcRGUoKaSIjQFevmz89upLVla18lDqF1UlF+DCzccLhzJi4lXsTeimPd4Q8Jzc+h5/Oup6ilD0vpM6Zcj4lfjslfjtnH3L+Ho+b4tP4cGzeQEERCF4wjctK5oqrTyQ3M/RC7t01Ddzx9DqcXT0H6BOLyIHm8fr5z0vVdK6ZgduTzBO5R9NvDp43LBlZjLvuBkzm4GWFEfDj+uBh3O89CMauPRIDrbUEWmqwpI0h7vQbMcUm73oDWyxxp/+G+AtvJmbhVWDZrbBQwI/rnQdwr35xoMlkMgU3yL7oUDJTYgh0ZeHZNAuz28IhFf1gGPgCvuAebo279nATERkONN0RTXeU6LatpZdbnlxLW/euPYTMRoBvZmwlJX4Fj2bG4baE3q+ZkTmFi0q/icNi/8rv6/F7eXjjE3zWvIb0mDR+ctj3B0pj97t83PnsOjbWdgwcn+Hu5KLG18k86yxyjjvuK7+viBx4fS4vtz21lor6nZvdG4CJI1NcLOpaw5jvXYM1MTjN0XD14nzzbvzbQkewTHEpxC7+AZas8QNt/a/8HX/dOgAsY6cS940fDjzmb96C87XbMJw73tNqJ+7UX2HJ+NyGagRvRN30xBrqm7o5veVNJnQ3sinfwRuHJxHYMTX7rOJTWDj2qAP0NyISGTTdMXoppKGQJtEp4PGweUsTd7xajdPtC3nspLl5nJjTwF+qn6XZHloG/+SC4zkhf+EBWSNmGAav1b7N1IxSRieEFhJw15fxwfsrebhmNAm+fi6uf5kkX3CNiuPYbzDum+dqnZpImASMAMu3r+TwnJl09ni4+Yk1bGsN/Z48vDSb75w0CYvZNPB/1d/ZgPPVWzG6m0KONWeOJ3bxtZjjU0Pfp7MR14ePABBzxIWYU0aFPt7bjvP1Wwm01hJz3PexFRz2pX3uc3p570+3M37b2oG2rTk2nj86Bf+OoHZC/rGcXLBY5xaJGgpp0UubFIlEIV9PN5v/8jeaO5x4Rx8H5uB/dbPJxEXHl3D09DFAId/uqOaWnrW4LGYcZiuXTL6AaZlTDlg/TCYTJ+Qv3KM90Lkdz5t3Ms3TR8b4WWz9YPtAQAPoeXsp1VNnMX7y+D2eKyIHlz/g56GNT/Jp00rWN1Wy/a0EYjvaYLe1pItnjeXchUWYdws7vq1rcb55N3idIa9nLZpLzPzLMFn3HJk3p4wi7sQff2lfzAlpxJ3yS3z16/Ya0ADibCampJvp37arrTUuFv9uEwXeqf+AI0fPJi0mdc8XEBGJIBpJQyNpEl3c2xsp//NfcfS0A7ApfhxLco7G4bByzelTmDI+feBYwwiw+oN/8JypnSunfXuP0a6DwXD10vfc/+LrauLB0cnYAwaLOzNoXN5JtrsdPyaeHH0sDcm5fPe0KUwryjjofRKRIK/fy/3rH2J92yYARrV4OOXtXmz+AI+NPo762GzOPaaIEw4fN/AcwzDwrnsN9/LHIeSSwoR99lnYp510UEeu/M1VA1MoDb+fpof/Q/d777AxIY/nxszBMWEl5oQuCFi4bOIlHJY78aD1RWSoaSQtemkkTSSK+PwB3njiLUp2BDSAiX1bmWXUc9KFZzIuO/RkbjKZmTHvag4J+LCah+Z0YBgBTI54XsxIoCIuWHSg09rBeXNs1KzIYU18ITVxo8Eb4Pan13HxCROYP230kPRNZKSzmC04LMH/l3kNbk5+rwvrjrofZze+jevCa5i9e0Dze3G992985e+HvpAthtiFV+335tX7y7v5PVzvPIDtkONxHH4eJouF7IsvJbawiI2+bPi4HvemWdiL1uBrGscjG1vJOrdnj3OhiEikUXVHkSjR5/Jy0+OreaZ/FJ8mTwKCS/vr8kqYVPQZHzQ+zZcNnA9VQAMwxyaxZe7pfJQSN9C2LcbGfdl+smf348lJG2gPGAYPvrKJ596v/tK+i8iBYzaZKfDNx9+ZQUeSFfduFRYdFpicEbrJva921R4BzZSYSdxpvz7oAc3XuBnXew8C4F33Gs7Xbsbw9GMymUiedxSnLSjhosUlmAJWPOUzCXRl0tXn4c+PfMbmrR17f3ERkTDTdEc03VGGv9ZOJzc/uYbGtuC6LpMR4OSmDxg1zkx1XhPvpwYD0Vl5i1hYuDicXQWCRQmeq3yZpXXvhrTbAgbntPSxqfNIPugKLSDwjTwzJx42mvjiEkTkwDMMgxc+rGHJe9Vg9mHJaCBjaxwXNryBPdbBuOt/SEzB+D2e437/33g3LgPAMmoiMcddgznm4I9U9b9yE/66tSFt5pTRxJ5wPeakrIG2FZua+ccLG/D5DUxGgDO2v8OWxHEcdfHpzCzJ5LOm1RSljCfZkfT5txCJeJruGL0U0lBIk+GturGbW59cQ3e/d6DNjpcbxqyg2l7PC7udwE0GfH/GFUxMK/6ilxpyHzV8yn83PYWf0NPQ4rZeLF2H8ExrCWAi2dvLRfWvEGt4yLniu6TO2nsBARHZN4ZhYDKZCAQMHn6jnGWrtoU8npEcw3WHxpKZPwZ7VtYXv0bAh/Olv2JOGY3jyAsxDdXUaZ8b17IH8FV9EvqAI57Y476PdfSkgaaNNe3c/vRajtn2PtO6KwF4N306jjMOYXn/66THpHLtjCvIiE1HZDhRSIteCmkopMnwFHC52PjgI9zTNY4+Y9cUpFRzLz/J+YB4VxM+4P4xKdTEBquq5cZlcdX070RUZbOKji38Y+2D9PvdIe0zul1M7hjDow2TOb/+DTK8wb2SAphI+eZF5Czas2qkiOy7LZ01vFD1KpeVfouHXqpiZUVryOPjshO44ZxpJCc4vuQVdjF8ni+s3niwGYaBZ+VzeD5bEvqAyYJj3kXYJy0YaNry1BL8r4Ye9/y8ZKrHBT9fsj2Ra2dcyaj47IPbaZEDSCEtemlNmsgw5OvsYMP//A7bivc4cdsyTEYAgGJ7C7/OfI14V3CPIivwre1dpBgWZmZM4UezfhBRAQ2gOLWQn866nuyYtJD2VUkxvJfVyJWp7xEX2LURdwATj63qoKmj//MvJSL7aH3rRm5ffR8VnVX89eXbmPLWv8nvbxh4fFJeKj+7YOZAQDO8bpzL7sffvu0LXy8cAQ2C23w4Dj2dmEXfA8tufTD8uN97ENeHj2AEgpVP8hYdjXnUmIFD1mfkUJW76zkOawwJtvgh67uIyN5oJA2NpMnw4u3tY9Mvf4Gjv3ugbVVSCc6CLM6M+QiT4Q853j79ZJxTF5HsSI7oDVz7vU4eWPdvNnVWhbSnev3M65xC6tufkerrZUn2fDYl5pMQa+P6c6YxfrTWkYjsj0+3r+I/Gx8nYARI7fJx+rJOkvoCuE02Hsk9nvzpE/nOSaXYrMH7uIHeNpyv3UagrRZTYibxZ/wWU0xCmD/FnvwtNThfuwWjvzOk3ZI7hdhjv4vJEY+/v5+tt99KbUs/D6cfDWnN2AvXYHgdTPScyPdOmj3wuUWGA42kRS+FNBTSZPhwe/z844UNJHz8Bkd2rBto7xidSc3UPhZ0OokL7PgvbbESc/R3sBXNDVNv958/4OfJ8iW817A8pD3G4mC2MZ+6N2opS9xVuMBuM3P1aVOYrr3URPbJsvoPeKr8eQwMMAwueKWDzE7fwOOemAQm/uUvWOOCxYb8TZU4X78Nw7nrppBl9CRiT/zRkK092x+Bvg6cr99GoKU6pN2cnBMsKJKcQ8Drxdnv5s6Xytm0tRNzYhuG14HhSmBSXirfP/MQYh2R99lEvohCWvTS7SKRYaKrz8Nf/ruSVRWtvJc2nfWJ4/Fjorcojbfm+Hg3LYFHc5LxA6bYZOJO+cWwCmgQ3KPpmxPP4pzi09h9zM/ld/NeYClZZ47BZt31iMcb4Pan1/LO6m0q0S+yF4Zh8FLV6zxZ/lwwoAGYTLxyWAYusy14jMlM7nnnDAQ0b/n79L/wp5CABmDOyCNSLx/M8anEnfILrIWHh7QHurbjfO02DCOA2WYjPjmBG86dxmETMgn0pGO4giODm2taueuBt+nu8wDovCIiYaORNDSSJpGvobWPW55cQ2vXrrVZNsPL5cmv8HSRhR7rrsIh81wWzpv/E8wJaV/0UsPGhrbN/HP9w7g+V1DkkOQZrH9vFP2uwEBbqqebi/s+YeJ138cxWhtfi+wuYAR4quJ53qn/MLTdGY9n82HkdXdzbuu7jL3qu8QfMhUjEMD9yRN4174a+kJmKzHzL8VWMm8Ie//VGIaBZ9XzeFY8G2ywWIk7+edYsotCjgsEDB55o5y3V20Dw+Dkpvcp6q/nreITOP/yb/Bm08ukxaRxfN4xET1dXEYujaRFL4U0FNIkchk+H5u2NHPny5X0u30hj00/3Eml8R5+AiHtC0bP4ewJZ0TFBUVjXxN3r/kXba72kPYCRw4zN/TzePtsbD4vF9W/QqqvF68thrwbfkhCifZSEwHwBXw8tPEJVjStDmkP9CbhLj8MuymGa844hMmj4zDHxGJ4+nG+ec8e+4+ZYpOIPe5aLDmRsX3HvvJWfYpr2X3EHHUptuIjvvAYwzB44YMaOpc8xZzODQD4MPP61CIqpnQCsHDsUZxZdHJUnFcluiikRS+FNBTSJDL5+/rY+Ne/s72tn8dHH4vfFBwtM5sMpsxrosK9OuR4Cya+OfEsjhg9Owy9PXh6PL3ct+4/bOmqCWnP8Pg4sdGC+zM/ObuFOI8thvF//htxSZFX2EBkKHn8Hu5b/xBlbZsx+w0yOn00p9vwd6XhqZhJgiM2pPhOoKsJ52u3EuhsCHkdc3oescf/AHPC8NxDLNDfiTkuZa/HeNva2PLrX2D2egba1hXF8NbsXYWJ5uQcxgUTz8JitnzRS4iEhUJa9FJIQyFNIo+nuZnNf/4Ljq7gvkXrE8fzYtaROOICjJtVQb2rJuT4BEsMV077NoUp+UPf2SHgDfj476anWb79s5D2WH+A8zb0E7fBjc3wE8DEM6MW4C0s5fpzppEcH56y4CLh1u/t5+61/6Kqqxa7N8BJ73UxqsXLk7MK2do2l4ykOH503nSy04Lrz3zbynAuvRPcod+F1vGziDn6cky2wfdKG448G5ZizZ2COTkHV20NNX//G+b+XioSxvDi/HjMKZ0hx0/LmMxlky/AZrGFp8Min6OQFr0U0lBIk8ji8wd4445HKFz3Zkj7xyWHUH6Elw5P6NS/sYljuOqQS0iNSRnCXg49wzB4o/ZtnqsKXSdjNgzOquwlfaWPt9MOZXVycKpjRnIMPzxvOjk7LkJFRooudzd3rL6fhr7txPf7OW1Z10AFx36zgzenncXllxw9sAeaZ8ObuD98BIzQqdP2Q8/APvPUqJ3i5638GNdb94AjnthF12AdU4qnpZnqRx/nLl8pPb4A9qLVWFJbQp5XklLIlVMvIdYaE6aei+yikBa9IrM8k8gI1e/ycvMTa3iyfzQrk3atq+ocH8vqGY17BLRDs6bxw5nfjfqABsFNaxfnL+SKQy7Gzq7pRgGTiVcL4siY4SM+a9c9p9YuF//voc/Ysq0rHN0VCYuW/jb+/tldNPRtB8DmM0hw7to7MS7g5sKcnoGABoDPHRrQrHZiFl2D49DTojag+ZurcL3zQPAHdx/Ol/+GZ8Ob2DOzmHDdtfzoW7NJiovFUzkDX2toMaLyzi3ctupeejy9Yei5iIwUGklDI2kSGVq7nNzy5FoaWoO/iyYjwEXNr+Eb38OS0kSM3S6WTJg4dfwJHJe3IGovovamrmcbd6+6jy5fP9aAwVXbOhi7o7DKO65JPNt/KMaOe1B2q5nvHpXNlKn5WGJjw9ltkYOqvqeBO9bcv0d4yFg/inPXrcdm+Ek55XQyTw0NX4Zh4Fp2H76KDzHFpxF7/HVYMvKGuvtDyle7Guebd4HPE9JuK12I44gLMJmtNHc6uemx1TR39mMbtwlbVg2Hr+tjzYQ4nDFmsuMyuXb6FSPiJplELo2kRS+FNBTSJPyqG7u59am1A3vzgMG8mDK8+eWsTQoNFg6TlcsO+RaHZJQOfUcjSKe7i3tX3c+8hkamtraGPFbmzeXBnqNwYyPB18/F9S8Tm5LMhJ//DGtKSng6LHIQVXZWc8/af+H07dqmwzDAWz0Ff2suZ43q58jxiaQcdfQXPt/weXB//Dj2madijkseqm6Hlb+1Fudrt2L0hc5QsIwpJXbRNZgc8XT1ebj5idVs3d7N8c6lzGjYTmeChSXHJNOVaCXVkcK10y8nOz4rTJ9CRjqFtOilkIZCmoRPwO1m48NPcHf7KPr9wZEfC35OSv6IsrwOtsWELk7PsCZw9aFXMSo+OxzdjTgBIwDOHpyv30qguSrkscZAGv/smMfJde+S5ekEwBOfTPHPfopj9Jgw9Fbk4FjfupH71z+EN7Brmw4jYMZTOY1AZzZnLyjkG4ePw2QyYbj7MDniw9jbyBLo78L5xu0EmipD2k3J2cQdfz3mlFE43T5eu+mflG7Ztc9cf4yJxxan0ZNgIcEWzzXTvsO4pNyh7r6IQloU05o0kTDxdXWx4Xf/i+2jNzm+/l1MRoB4k4uzs9/go8KuPQLahISx/HTujxXQdmM2mTHHJRN38s+xjg/demBDuotTHK8PBDQAS183L766Gp8/gEg0+GT7Su5d92+8fi9z1/QyutmD4bfg2XwodOXwnZMmceKc4NRF96oX6XvsZwS6msLc68hhjksm7qSfYv3cHmpGVxN9S/4XX/16Yh1WjppdyO53tOsz7fTGBS+her193LrqXso7tgxhz0Uk2mkkDY2kydDz9vax6Ve/wtHXOdBWllqAZUY7b2Tb8X9undmCUbM5c8IZ2p9nLwwjgGfFs3hWvcDKxBieyA7ubzR/rZVp6xsxY/Bi1pGsTypkSkEa3ztjCjF2a5h7LfLVvV33Pk9VPI/Zb7BoeTeTaty4bCYeKVhAlyWP751+CFML0zF8Hlzv/hNf5ccAmFNGE3f6rzHZVfl0J8Mw8Kx5Gc8nT8HuccxkxjH3AmyTj6XnsxU0/OMe6u0ZPDlpGpYJazGZd93wsZqtfHvyhUzLnDz0H0BGLI2kRS+FNBTSZGi5vX7+8fwGUj56lcM7ywbaGwrsPDknGXYLaBZMfHPCmRwx5vBwdHVYKl/3Anc0vxsSdA/ZkguVJj5J3XXxlJedyPXnTA2tcicyTPR7nfzf8r/T5enm+A+7mFjjHnisxxZPynU/p3DiWAJ9HThfv41AS3XI822TjiHmqEuGutsRz1uzEtdb9wYrXu7GNukYHEdeiLOqhre2ennmk0bMCR3YSz7DZN01zdRsMnPhxLOZM+qwoe66jFAKadFL0x1FhlBXn4e/PLqKVRWtvJ1+KJvix2EA66bG8uTclJCAlmiyc93M7yqg7af0oiPJikkb+HlMwiguuuQK7PMXhRxX29TDHx76jMY23aCR4SfGEkN+/7EYPhsrJ8bhse46d6QWFVBQkIW/uYr+Z3+3R0CzjJmMY9ZZQ93lYcGWP5O4036NKSE9pN1X9SlGfxdxRUWcvHASF58wAaMvFffG2RgeOwCmgEEg4OehjU/wVt174ei+iEQRjaShkTQZGo1tfdz8xBpau3ZVXxtraqU0YxnvFiSEHDvWkcZVh16t0s5fkdPn4l8bHmVrTz0/Pexa0mJSMQyDJe9V88KHNQSnMwUvakdZXFySsp3iyy7GZNX0R4l8Xp+f+14oY8XmFswJHVhzKxi9Jptz698jbs6RjL30UnzVnwT3AfP7Qp5rm7wIx9zzMWnq9F4FnN24Xr8df1MFmCzEnvQTrKMnhhzz2eZm7n2+DL+1B/uETzluTTN2r8Hrc5PwW0yckH8sJxcsHpHbpMjQ0Uha9FJIQyFNDi7D56O8ppXbXyin3x16wXTC4eNYkFrGTc3v0GMNXjQdmjqBb029GLvF9kUvJ/soYARod3WQERt6R/yTDz4hYc1jPNg7n16vnYvqXyXd240/r5iSH/9Qe6lJROt3ebn96XVsruvcrdVg4rhUrpydStL4cXhXPItn9YuhTzRZcMy7CPukBUPY2+HN8HtxvfcgluziL/1727y1g9ueXsuhTcuZ1xqcvl6fZeOF+cl47GaOGjOXc0tOw2zSxCU5OBTSopdCGgppcvD4nU42/vUmtrX28eSohQR2fFGbTPCt40o4ZmYuhmFQ8e5d3OWr5cS8YzmuUHdeD5ZAbzv9S36P29nJiph4Ej+xkeHsHHjck5XL5P/7PSazLqgkcvR5+1nTsp5JidO485GPqer0hzw+a2IWl59cijXgxvX2P/DVrgp53BSTSMxx38c6asJQdjsqGIbxpefjnZdPNR98ivfBu0IeWz45jo+nBWdIHJo1jYtLz8Nq1ki9HHgKadFLIQ2FNDk4PG1tbPrTn4npaAZgdVIRr2bOxWG38t3TJzO1MGPgWMPvo9vTQ3Jsari6G/WMQID+Jb/D11rLf7OTWB/v4JwPOxm11TtwzJLs+RQuPpoz549XUJaI0Onu4o7V99PY18SMFSnMrqzm0THH0+wIrrs89tBczl9UDD2tOF+7lUBHfcjzzWm5xC6+DnNSZji6H9Xcq17E6GnBPvdC6h56BPeH7wBQkxHPC4viCJiD5xATJq6feTVFKQXh7K5EKYW06KXbOiIHgc8f4O2HXqRgR0ADmN5dSUehh8Vn/oiCUckhx5ssVgW0g8xkNmOfcSqvrvw36xJjAHjiyBQWx/cwaaOLNzMOY1NiPps+qqWjx82l35iI1aIRNQmfNmc7t666lzZnO0eu6eOw8uD55NyGN3ko9xssWjQ1uAeap5++Jb/HcPWEPN+aN4OYY67EZNcU3gPNW7MSz6dPARDo2s7Y87/P9rQ0apd9wDPJx2B0bMSavh2AUf1zyUsYF87uisgwpCsQkQOs3+XjlifX8Lgzl3WJhQPtn02OY+1EJ6vbXwtj70Y2c9506nN3/ZtgMvH6jCRePjaJMeObsRFcM/jh+u3c+uQanJ9bQygylOJt8ZgDMST2BzikwjnQnuB38m1TGSfNzcdkMmFyxGObfGzIc+3TTyZm8bUKaAeBv7MhWKZ/58+Nm+lf8nuyjz6MaX/4PYX5OXi3TMPXnIundiJb1idx8xNr6HfpfCIi+04hTeQAau1y8seHP6OspgNMJj7InoYrxcYbcxJ5f1oCmEwsbVrBp3Ufh7urI5LFbOH7s77PkZnTQtorsmNYVtDPqaNeJ9EUvBjeUNPBnx9dSXtLZxh6KgKflrVR/3EpXeYknp+fgm/HFNzAqLFMuu57IcfaZ56KteAwsNiIWXg1jtlnY1KxioPCnJiFrXB2SJvR00L/kv/F3raZ68+ZxuxJ2XhrJuNvygdgU20H/77rebp63V/wiiIie9KaNLQmTQ6Mmu3d3PrkWrr6PACMs7TyncS3STQ5eXRUEhsSglPsLAZcWHIGh4+dG87ujmiGYfB2zds8U/Uqxm5Lz8yGwTHNHlbUH812fwpxPieXNrxKxtw55F14vgqKyJAwDIOXPqrlmXergg02F+a4HqY2uzghvoWia6/F7NhzE3bD6ybQtR1LRt4Q93jkMQwD77rXcC9/HHa/jDKZcBx+HpYpi3lsaSVvrgyuEVzQ+hlzOjewatRMFtzwHbpMjcTb4hmTMCpMn0CihdakRS+FNBTS5OsJeD2UPfoMdzdn4PQHL+Jn2Ku5IP5D7KZgFTa3ycTduan0O2K4cuYVFGgBeURY11LGv9b9BzeBkPZZnS5at0xnVs0GRrnbgo2HHErxNd/VXmpy0BiGgWHAf5dWDFzc75SeFMMPz5tGprkTk9eFJavwS15FhpJv6xqcb94NXldIu23CUdiPvJiXPtlG3fMvsaj104HHNmTm8e4iLxabje9Nu4zxyflD3GuJJgpp0UshDYU0+er8vb2U/fmvOBprKUvI54XseXwjbg3Hx64LPdBsoW/O2cQUH0GKI/mLX0zCYltvI3evuJuOQOhF1smfdFFYuWtqUgATrm9ezfRFhw91F2UEeGvru1R0VJOwIpOyuh4aY3ZVY8zNTOCGc6eR2LEZ55t3Y7LaiDvjt5gT0vfyijJU/O3bcL52C0ZPS0i7JacEx8LvsvH//Q1787aB9i2jY3hpfiKG2YTdbOPKqZcwKa1kqLstUUIhLXoppKGQJl+Nt6+Pjb/+DTE97QNt23MTKBjXT4pv18iM9iiKfD2eXu5ZcRc1rtaBNqvP4KR3e8jfHgxvr2bOYU1yCRccV8Kxh+aGq6sSZQzD4MWq13i19i0K61yc8EEPHuw8lPsNOuxJTByXwjVnHIKtYinu5U8MTK0zp48l7tRfY7LtOe1Rhl7A1YPrjTvwN24OaTclZuA4+rtU/PNxrDXlbItP4dkTYvA7gt8RdlMMP5n1PUYn5ISj2xIFFNKilxZYiHwFbq+ff7y6hQ3m0L2Htsf5+U92Ep4d65zMqbnEnX6jAlqES7QncP3hN3BY6q5/J5/VxPMLElk3Po4Ps4tZnVyCATzyRjlPLduC7m/J1xUwAjy2+RlerX2LyZVOTnqvG2vAIC7g5ryGpRxREM/1Z03GvPzfuD8OXfsU6G4h0F4Xxt7L7swxicSe+BNsE+eHtBs9rbhe+yvF3zoJ48hFvJh7In2Vh2N4bRh+Cz0bprGpXFUfRWRPGklDI2myf7r7PNz29FqqGroxGQG+1fQqo3tbeXdmAqsnxILJxNQeF99yFBC38GqVwB5GDMPglYqXean+nd0bwTDhqZmCv3XXCNrcydlcduIk7aUmX4k34OPfZY+xqnktADktXs56qwOrf8fjjjgKfnANxqZnCTRVhjzXlJhJ7PHXYUnTiG6kMQwD7/o3cH/8312h2h5L3Om/wZIymrrmXm56YjXdvnZMdjeB7uCU1VOPzOe0eQWYTKa9vLrInjSSFr3CHtICgQB33HEHTz75JD09PcyaNYsbb7yRsWPHfuHxXq+X2267jSVLltDT08OUKVP41a9+xaRJk75yHxTSZF81tvVx8xNraO0KToEz2Z2kjf+QjL5eto7aNe0o0+Tgh3N/QlJMUri6Kl/Dyua1/KfscbwBb0i7t6EAU/14vNgAmJlj5YLSWNJmzwpHN2WYcvnc3LfuP2zqqAhpz99s55TPtuFLSqXwqm/hX/EwRl97yDGWUROJOe4azDG6MItkvrq1OJfeDT4Xsd/4EdbcKQOPtXQ6uenx1TR17Nj7zjA4um0VyYdM4dSLjsdsNmEYhgKb7BOFtOgV9pB2xx138PDDD/OnP/2JnJwc/vrXv1JfX88LL7yA3W7f4/hf/epXLFu2jD/96U+MHj2aW2+9lZUrV/LKK6+QmPjVflEV0mQwRiBAeXULd7ywmb4dG5KaE9qxF6/GZPOEHDvRkcV3Zl9DnE0jaMNZbXcd9659kC5PT0h7Sa8X/5YpVPSP4cJtr5Lp6SThjPMYc9I3wtRTGU56vX3cteaf1HaHTlX0teXgr57GlUV+phbH4P30YfCFnltsk47BceSFmMyqMDoc+DsaCLRUYys5co/Huvs93PLEGmq293B4x3qOaVuJHzNl008g+ZQcGvu3c8GEs7CYLWHouQwnCmnRK6whzePxMGfOHH784x9zwQUXANDd3c1RRx3FH/7wB04++eSQ4+vq6jjuuOO45557WLBgwcDxp59+On/4wx+YO/er7TulkCZ7E3C7Kfv7LWxt6uHpnAUYJjOWzDpseWWYzKH/fRamT+WMqRdg1iayUaHD1cm9ax+krrchpH1Mv4dFS72k9O46b9gWLKbgWxcMdRdlGOlwdXLH6vvZ3tcEu42S+JrGYto2he+eNpmJXR/gWflc6BNNZhxHXIh98rFD3GM5WAzDwNnRwvP/fpOZG14Leez5+clU5zqYljGZyyZfgM1iC1MvZThQSIteYb2S3LRpE319fSHhKikpidLSUj799NM9jv/ggw9ITExk/vz5Ice/9dZbXzmgieyNt6OD9Tf+D/aqjRT11bO4dTm2cRuwF2wICWhWs5WLJ53HWdO+pYAWRVJjUrjh0O8xLWNySHsnFkwmZ0jbyxVOyus6h7B3Mpw09bfw98/uwt3YwAWvdJDWGRyR924rxNY0lZ+cM5mSmif2DGiOeGJP/LECWpTxrn8D/3M3ctLcNNwxCQPt9Zk2to4KziJa07qBu9b8E6fP9WUvIyJRLKxzJrZv3w7AqFGjQtqzsrIGHttddXU1Y8eO5fXXX+cf//gHTU1NlJaW8vOf/5zCwq+3safVqgtrCeXzB1j27yXktTUOtM3oqmCrP5kadq0/S3Yk8d3pl1KQPC4c3ZSDzGqN4eoZl/Ds+qd4vfETAPriLDx2XBqnvdNJTpuPD9MP4bPYAtY+tpqrz5jCrIlZYe61RJLa7npu++w+krZ1cMq7XcR4DE5f1snDpbOICxzCTy6dQUb3JvqqV4Q8z5wyioSTfoglOTtMPZeDwbt17a7CImsfo+j8E6l4+mO6XX6WTMnFb2keOLa8cwu3rf4HP5h5OYn2hL28qohEm7CGNKczeCf682vPHA4HXV1dexzf29tLbW0td911Fz/96U9JSkri7rvv5oILLuDll18mPf2rbexpNptITY3/Ss+V6NTn9HLTfz5ltXMcpybkU9pbA8CnpXHUjN71+1qUls+P511FWmxKeDoqQ+by+ZcxfnM+9616Ar8JXDFmXlqQzBWr2zkyuYay3kJa/Unc8fRarjz9EE6eNz7cXZYIsKG5nJtW3IPP5eT894IBDSCxP8B5m6qYe8c1ZKTGA1m0ddbQ9XFwJC22cCbZp1+POUbfTdHE8Hupe/fB3bZTMPBteInSU4/gI+sR9L7fhM20CWtO7cBztnbXc9Nnd/PrBT8gIy4tLP0WkaEX1pAWExMDBNem7fwzgNvtJjZ2z6ILVquV3t5ebr755oGRs5tvvpmjjz6aZ599lssvv/wr9SMQMOju7v9Kz5Xo09rl4qbHVlHf0ofZZNB2CGzbYmNjfgwbinb9Xh4+aiYXlZ6DyWWjw6U1jSPBjKzZXH9oKvesvB+n4eObrd1kpxtADzckvcIDvQuo8mVz77PrqN/ezdnHFGIxa5R+pFrdvJ771jyMz/CB1cRrRyRx6rIuLAb4LDYmXnYhFqCjI3j+ME0/A1tjDebU0TjmnEeXE3Dq3BJt4k76Mb0v30ygq2mgzVn+IYdmN2M/7lz+sRQMnw1b7o6tFwyD1rZGfvXGX7n+0CvJiddIveyiQYboFdaQtnOaY3NzM+PG7Zoq1tzczIQJe27+m5OTg9VqDZnaGBMTw9ixY6mvr/9affH5Al/r+RIdarf3cMtTa+jq9RBrcjM9fxkrMw1W5qcMLPQ3GQanjTqSRRNPw2SY9LszwoxPKeQnc37ElnUvUOTctZ9agtnNNYlv8N++I1jhGc+b729m3Iv3M/HbF5P4NbYIkeHpo4ZPeWTTUxjsWrtamxnPq2PzWdRUQcEPf0RCYeEe5w/HcT/AZLbgDwABnVuiUmIOcaf9BufSO/E3bBxo9jdVMrnvXn64+GJue9OCx2fHllfGnPX9TKpysuSYAH/95E6umfYdxiVpjzyRaBfWW7wTJ04kISGB5cuXD7R1d3dTVlbGrFl77js0a9YsfD4f69atG2hzuVzU1dWRl5c3JH2W6GT4fGx45Cn+8vCndPV6yLB2UDRxKaszd1xg7QhoMQZ8d+I3Oa70dO1hM4JlxmUw5/DLiFl0DVh2TX+1mgJ8K+F9FiZ8ytmNb5Pc0Uj9TX+j9cOPw9hbGWpLt77Dw5ueDAlohseOe+NsRs1eSMGJJcQmfXFpdZNKro8IppgEYk/8EbZJx4S0G71tjFt1F79cYMbeNZ5JH6UzZ10fyX0Bzn2jg/jGTm5ddS/lHVvC1HMRGSph3yft5ptv5rHHHuP//b//x5gxYwb2SXvxxRcxm820t7eTmJg4MB3ysssuo6mpid///vekpKRw2223sWLFCl588UXS0r7aXG2V4B/Z/P19bPjz34nZVsXaxEI25Y8mUFJGkyP0YinTsHH1rGvISRodpp5KJPI3V+F87VYMZ3Ad7Xspsfg3B5hQ6x44JoCJjF/+nozxY8PVTRkChmHw3JZXeGfLW8T3B+hIDk5WCbhi8WyexQXTR3F4y1MYnY2Y4lOJO+O3mONSwttpCTvPhqW4P3wUjNCR0/68RbQ/9RaW3dq35Np5cX4KVrOVb0++kGmZkz//cjLCqAR/9Ap7SPP7/dx0000888wzuFwuZs2axY033khubi719fUce+yx/PGPf+TMM88EgsVD/va3v/Hqq6/icrmYOXMmv/zlLykqKvoafVBIG6m8fX2U3fg/xHa1DLStmBzHB9NCq2hNtKbynbnXEWeLG+ouyjAQ6G3D+eotbHA18Z9RyWR0+DhtWRfxruDF1dKMw6gaN4Mbzp3OmAytH4hGASPAfzc9w5otH3Hasi7iXAEeX5xKlzkZb/ksrjksnqLqx8G967vGnDWeuFN+gUn7YI14vvr1OJfeBZ7Q9fH9tmLaPqrCGvDTlGrj6UXJeG3BSVBmzFw46WzmjDosHF2WCKGQFr3CHtIigULayOTx+rnvhQ1kvf8807orB9rXF8bw5uzEgSmOC5MncsbMS7X/meyVx9XD/3zwB7pMwWCW2Ovn9Dd7qLQV8lZGcPp2nMPKD86eSsnYlDD2VA40r9/Lg2X/pbZyNae/3UlSf/B3oD3exmO5p/KDWX4yK57fY6TEftgZ2GecqqnTAkCgczv9r92C0RW6BZE7YSIVn7bz6JiZ+Kesx2T3hDx+VtHJLBw3HxmZFNKil0IaCmkjUXe/h9ufWsuWhm7Mhp8r258kpcPDB9PiWVEaByYTVsPg/HHHMad4cbi7K8NEY8927ll5D63+fjJi0jjaciqPvr2d3S/NrRYzV55SymHaSy1qbO2u568r7mRUk5PT3+7Euts/eOxhRaSYK0OfYLUTs+AKbOP3XHstI5vh7sO59C782zYEG6wO4k77NZ6EHO5asoGyhjrsE1dgdjhDnndC3kJOHn+8Av8IpJAWvRTSUEgbaba393PzE6tp6XQNtB1q24Q9tYzV+cHpjEkBE1dOvZSCLFXlk/3T6+3j4Y1PcnrhN8iJz2Z9VRt3Prset9dPkqmfbiMOE3DB3FHMPyQb21dcSyuRIWAYPLa0grcqV2IvWUXJVicnftBNABPJUzNJiGkOOd6UkE7s4h9gyVCxK/liRsCH+8P/4i17i5jF12LLnwmAzx/ggZc2sryiFseEFZjjegGYUO2icqyDuXlzOa/kdM36GGEU0qKXQhoKaSOFEQhQUdvO7c+V0efyhTy2eNZYjoxfzi09q8m2xHHlnOtIiftqm6OLfF7N9m4efupdrrA+z3LPeF7uncb525aSbvFQ+NOfEpurgiLDkdcX4P4Xy/h0UzCIWdIbMMd3ckKVn3lJlcTE9IQcb8kuJmbxtZhjk8LRXRlm/K21e4T5gGHw2JsVLF1VhWPCZ8zY1siCz3ppyLTx/PxkpoydwcWl52E1h3WHJRlCCmnRSyENhbSRIODxUHbzbVRv7+HZrPm79jwzwfnHFrPosLEYRoCazW8xpmg+dqt9kFcU2XcBVw89z/weo7eF/2QncfgHblLbg9UfvVYHY39wPUmlGrUdTpxuH3c8s46NtR0h7cePauNE/1LwuUParSVHEXPUxSoSIl+bYRiseOUF3v2okZMbP2LnBMe2JAvPLkwhL7eUyw+5CIdF32MjgUJa9NKtFol63u4uyv74V2Jb6pkAnJT0Oi/FLcJutXHVqZOZUZwJgMlkpmDiovB2VqKS57PnMPW28FxmIt0uM0kduy7gbT43r770CSePLyIuRhfwka62u466tu10PvAO2+1FYN81KnZxbjWH9r8Pu+2PhsmE4/BvYjtksdYLyQHh3fQOE+ufIdOWyO4lRDw2E267mbL2zdyx+j6+O/UyVSQWGcY0cVmims8f4J37nyK2pX6g7ZBtTcxIfo+fnj9jIKCJHEyOw8/ls/GTWJ4cS2OmnecXpOC2Bi/Y16YX8qp/LH98ZCXt3a5BXknCaXN7JXd+fDeu+++jZPt6zm1YSpwvWMDhmBljmDujgJCAZo8l9oQbsE9VQQc5MHwNG3G//xAA6Tk9xBcE95Btj3Pw/NEp+HacV6q6alnVvC5s/RSRr08hTaKW0+3j1qfW8l93HlsTsgfaV06IZXORk6r+j8LYOxlJTFY7M+ddzThzcI+0raPsPHVcCp9NimPD0e1Miq9gW0sff3joM7a19Ia5t/JF1rdu5M7V93PiW82MawqOX6T6ejmn8S3OnDOGby0uwTF5IbbShQCYkrOJP/1GrGOnhrPbEefT92vo7XEPfqB8IX/DRjD8Az8nZbpIKbawcdx0etp37Rfrayygv2FUOLooIgeI1qShNWnRqL3bxS1PrqG+pY8ptq1cFPseW6sMPiuMY82E4PSPKbZ0rp73U93hliHj8Xv5zyd3scq5LaQ93hcgvyabFe0ziXPYuPasQ5gwLjVMvZQv8mF5NQ9X/YvxzV2c/F4X5h3fnP1TZjPt2qswWSxAsDKfZ8US7NO+gcmhjcs/78HbP8Tj8lE6fTTT54zF6/HzwdLgFgVHLioiNV3T8wbj2bgsOJq2W1gDeMs3k5fi4jDF9OOtmQyYOPmIPM44ary+56KY1qRFL4U0FNKizdamHm55cg2dvW4WxaznpNhVmE3gNeCfuSlUx9o5Ni6f02ZfhcVsCXd3ZYQxDIMX1z3Gq62rQtothsG0+lg+bjyKGAJcGVdF6eUXY4nThX64fbCukQdf2UTA3oNj0nIO2dLPsSs78Bx1ApMvPk8XwPvhwds/xNnnBcBiMREbb6e3OziyNm58Giede0g4uzds+Bo24nzjDnCHXruUUcg/22fjJbi+9fCO9RSn25j/oyuxWvR9F40U0qKXQhoKadHC8Pspe/ol7qxLxOf1cX78hxzmqA45pjcmjm2zTuKwSSeFqZciQZ9WL+Phqpfxfe76flqzQeEHMNbZgic1iwm/+Bm2NG0HEQ6GYfDq8q08uWzLQJs5vpPjHJUc66og9Vu/xZKWG8YeDj+7h7TPi0+0c/E1c4e4R8NXoKsJ52u3EuhsCGnfbsrirvb55HY1ckrzBwBsG1NK0XUX0mv0MSm9JBzdlYNEIS16KaShkBYNAi4n6/9yEzFbK1iXkk/WhB6mG20hx5iSc4g7/jrMKZqn/3V1tPVritIBUN2yiXvW/IvenXPnDIMTPuxmQu2uNTueuEQm/unPWOP0dzxUAkYAw4CnX1nPq+taB9odePl2yodMNNcCYErMJO6MGzHH6CJpX+0tpAEccugYps8ZS0KiYwh7NXwZnn6cb96Dv25tSHtXbwy9ZW7MuxWyWTExmY8PjeOS0vM4NHv6EPdUDhaFtOilwiEy7Hn7+lj3m/8hZmsFAId01lDvdNJn3jVEYRkzmfjTf6OA9hV9frH/B29WUlfdQV11Bx++uWUvz5S9KcicyE/n/oTR7LogbUkN3Rnlo5gi7n+jCq8vMNTdG5G8fi//WPNvXvjb/zD+hXtI9AVv4KWZe/hJ2msDAQ3A6GnB8+nT4epqVFr32TYevWc5779RqQIj+8BkjyP2+OuxHXJ8SHtirIuY5F0/tybaWDHFht/w868N/+WDbcuHuKcisr8U0mRY83j93Pd6FVXe0FGG2J4Aj2Yn4QdskxcR+40fahH/17BhVUPIhVNna//AYx2tGoX+OtLjM/jRUb9isi0dTCY+K43n1blJ+M2wZnw8H48Zyycbm7np8dX0u758BEK+PqfPxR0r/sHoFz6mtHwrSb5+zml4kwmmOn6a8gqZtIccb82bgWPON8PU2+jl9xsKa/vBZDYTM/d8HPMvgx3rrM0WSCsxsGda6bHGsOSoDNz24CWfYUDAo5FKkUin6Y5ouuNw1dPv4fan11G5rZPEUes5bfN6cpu9LJ8Sx8eHxGMCvpd2OKUzzg53V4e9zy/2N1vMeD3BymKJSQ6+9b054exeVAgYAZ5d/TBvdawHILPdS2uKlYBhwVM1lUBHDmMy4rnh3GmkJcWEubfRp8fTy20r7yewtZaz3+jAsts3Y1w2JOeFHm+fcQr2w87AZNK9zn3h9fqprWzjzRc3EfDv32WH3WHh5POmkj06afCDRzhf42Zcr9+O4e4Fi42Yk3/G2xtcPL66FvuETzHH9uPZMpXY/jxuOHcaBaP0dzrcabpj9FJIQyFtOGpq7+fmJ9fQ3NWDffxaLGnNODwBxjV6qMiLIdZvcGn+8UwpXhTurkYFLfYfOh82fMp/Nz9NwAid3ujYNpa+bSUkJCZw/Skl5OamYzIrIBwIbc4Obl35D9rcwXWsE6ucHP9xDwCOFEgtBNPOwngWGzFHfwdbkW5MDMbvD1Bf00FFWTM1FW0DN3b2l81upnBiFiWTsxg9LkXVNAcR6G7G+dqt2GecMvB7+v7aRh58Yw2mxDb87cFp/w6bhe8fM5rJM4vD2V35mhTSopdCGgppw4lhGFTUtnPHc2X0BbqwF6/EHBe6+W+WD66e/h2ysyaEqZfRR4v9h1ZFxxbuW/cQfb7+kPaSToOa8iM4bdtH5BSMpuTa72G22cPUy+jQ2NfELZ/9g15fT0j7qcv7Ke3uJTkfdmYCU1wKscdfhyWzYOg7OkwYhkFjXRcVG5up2tSCy+k7oK8fn2inaFIWxaVZZGQnKLB9CSPgw2QOXd+6urKVe5asx7NjfevUrgqOb/kY5wlnM/PskzAMQ3+fw5BCWvRSSEMhbbgIeL2U3XonFQ3dvDR+IvaSNZisocFhSvokLik+nbg4bQR8IA0W0iA4DXLnBrUKa19fc38r96z9F039LQNtpoDBWe90MqYx+G/hHVPAxJ/+GEu81lt+FTXdW7lt5f24A65djQYc2+xhUXcnsCugmTPHE7v4WszxOrd8nmEYtDb1UlHWTOXGFvq+xhqygpIMrFYzW6vacbv2HvBS0+MonhwMbEkpsV/5PUeSyvou1i15EE+bi2l1mwaqP9YdNouNh9v5ziEXEWvVdOrhRCEteimkoZA2HPh6e9jwp78Ruz1YWW35lDg+npoQcszxeQs5efxizFojckAFAgYP3vbhoBdMOymsHTj93n7uW3475Z7gNLzJW5wsWh464tNy9BkcedFp4ejesLapvYJXX7yb7SkmehJ2zGUMmDirqZdZfaHfB9aiucTMvwyTVaOWu+ts7w8Gs7JmOtudez3WZrdQUJxOTWU7HvcXn0t2nzrt9wXYWtUenCpZ2YZ/kOqm2WOSKCnNonBSJrFx+nf6Mt6KD3G+9Q9a1oF/t3sTzSlWnlicyujUXK6Z9h0S7Qlf/iISURTSopdCGgppkc4fCLDsln8ytuz9kPZnFySzdbQDm9nGtyadw2Ha9+WA8bh91FV3UFPRSu2Wwe9ofxGr1cwJZ01mbEHaQejhyOEP+Hl8+Z184KzHFDCYv7KX6eXBC+K69BweSV3McYeN5bxjizBrqtI+Wdm0hs+euZ/5n/XQkWThyeNScVptmGsP5RclFpI2PbfjSBP22Wdjn3aipoHt0NvtpnJjM5Ubm2nZ3rvXY80WE3nj0ygqzSKvKB2bzbJHEaLYeDu93cGRt3Hj0zjp3EP2eB2P20dVeSsVG5rZVtvB3q5aTCYYOz6N4tIsCoozsNktX37wCONvqqT/xT+B34ffA+2bweeErngLTyxOoT82+HeVFZvJtTMuJy1Go8bDgUJa9FJIQyEtkjndPu5+bj2VtbWc2/ESo5s9AKwtimXZYQkkxyRx1bTLGJeYG+aeDn+9PW5qKtqoqWxlW23nfldg+yImE4wel0JBSQYFxekkqCrhV2IYBm+ve5JnWj7FAGaV9TOnoZ/R+QbvuCexpP9QDp2YwxUnT8Jm1UXp3ry37WNqn/gPszfsWu/XkG7nxcITueHM4xidHofrnQfwVa8gduFVWPNmhLG3kcHl9LJlUwuVZc001HXt9ViTCcbkpVA0KYvxEzJxxISui3rw9g/xuHwDo+1ej58PllYCcOSiIlLT975pe1+vm8qNwb40N/bs9VirzUxBcQbFk7PIzU/FYhnZsywCPS04X72VQEd98GcfdFbD8kkpvJMfOvqYYk/m2hlXkBOfFY6uyn5QSIte+x3SvF4vNpvtSx9fsWIFhx122Nfu2FBSSItM7d0ubn1qLT19ldhKVuHG4OylnWzOc7ByUhx5PjNXzr6GlNRx4e7qsGQYBu0tfVRXtFFT0UbL9r1f8BwImTmJFJSkU1CSQWp6nEYn9tO6mvd5sPI5zm7qZnKve2C91HpPLv/uPYr8sZlce9YhxMd8+Tl6pDIMg1dr3uLF6tco2urixPe72fnb1xWbSP5PfknmuGDVO8PvxehpxZwyKnwdDjOvx091RSuVZc3UVXcQCOz9UiFrdCLFpVkUTcwiLuHLpxt++n4Nk6aNOiBToTvb+6nY0ExFWTNdHXufbhkTa6NwUiYlpVlkj0kasecew+PE+da9+LeuDml/OzGR17JiYbe/lnhrHNdM/w55SWOHtpOyXxTSotd+h7SrrrqKO+64Y4+g1tvby1/+8heeeuopysrKDmgnDzaFtMiztamHW55cQ2zMWnrzq/GZg98cZr9BwGJidiCO84/6MXaH5s3vD78/QGNd144RszZ6ulyDPsdqM2MEDPx7GVkrnTGKrJxEGuuDr70v0yOT02IpKM6goCSD7NGJI/aiaX/1dDdifvM+Ai1VIe31vlT+0bOQ5JRUrizyMmrhAv2d7hAwAjy5+UXebdg1ZXr6pn6OXtlLa1ImU375C5IyNC3X7wuwtbqdyh0l832DrANLzYijuDT8hTsMw6Blew/lG4LTMAcrcpSYHDNQcCQtY+QV3TECATyfPoVnzcsh7Z/Fx/BkTtJAUJtU5aQ9I45vHn0FJalFYeip7AuFtOi13yFt1qxZTJ8+nTvvvBO7PXi37M033+T3v/89bW1tXHzxxfz0pz89KJ09WBTSIocRCFD23GvcWeUge9THNOd0hjxuNgxOi8ln4dyrMZs1rWtfeNw+tla1U1PRRu2WL1+0v7u4BDv5RenkF6czJi+Vh+/+eJ/3SQsEgiW4q8tbqa5oHVhvMuj7FadTUJzBmLyUET8taTCGz4Nr2X34qj4NaX8jIZGUT+3k9rRhOWIB4y+9eMTvpeYP+Hlw/ROsbF0V0p7j8nHB2h5GXfxL4kaP3JL6gYBBw9ZOKsqaqdrcOuj5ITHJQdGOYJaeFXk3yQIBg221HZRvaKa6vHXQvdkyshIonpxFUWnWiCt05C1/H9e7DwbnPe6wKc7Of3JSGF8fHG122028dHQaJy68jGmZU8LXWflSCmnRa79DWllZGZdffjmTJk3if/7nf/jrX//K66+/zvTp0/nd737HhAnDb28qhbTIEHC7Wfe3W4it3sjG8Qm8Pid0bUKcP8Clo45i8hRVshtMb7drYLRsW23noFOVANIy43cEpXQyc0JHtj6/2N9sMQ9c/CQmOfjW9754Y9+dpbmDga2N9pbB/5/ZHRbGFaYzviSDsQWp2B3WQZ8zEhlGAM+KZ/GsegGAFQkOumpMlFbtGh01Jk2j5IbrRmxQ8/i93L3q35R3l4e0Fzg9XNLYRUzAwJScQ/zpv8HkGDkjKoZh0NzYQ2VZM5WbWujv9ez1+Ng4G4UTMymenEX26OEzVdDn9VNT2UbFhma2VrUPeh4cPS6Z4snZFH7BWrpo5d9egfON2zGc3QNttS4LlvV+LDsGUn0WeP7oFI4+5lvMHTW8lrOMBApp0esrFQ7ZsmULl156KW1tbSQmJnLDDTdw3nnnDZsT9+cppIWft6+PDb//A3FtDQNtbx+awNoJwaCW7Q1wZemF5IzVIv4vYhgGbc19VFe0UlPRRmvT3quuQXCB/6ixKQPBbG/TlT6/2H/ZK5upq+oAvrwi2xfp6nAGA1t5K9u3dQ96vMViIjc/lfySDPKL0omLV2ntz/OWf0DZJ//h35mJnLKsizEtu0Y8P0ybysRLL2BOaU4YexgeTp+Th168hUkfbuH5o1Pojw0G1Ul9bi7Y3oVt5zefI564b/wIS9b48HV2iLS39lFZFlzD1d2596nOdoeFgpIMikuzGJOXitk8PL/fd9pZ/KSirJnGQYqfmC0m8grTKd5RldJqje6bHIGeVpyv3UqgvQ4Adxe0VYBpR0jrSLTwxHGpuGLMnFl0MseOmx/G3srnKaRFr69c3bGuro7LLruM7Oxs7r//fmJjh+9Gkgpp4eX1+bn/hTIK3n+I8V3NA+2b8xy8ekQSpT4rl829jrikkXehuTc715dVl7dSU9m2T9MKbXYL48ankV+czrjxacTE7luBic8v9u9o69+vimxfpL/XQ01lK9XlbdTXdgxaTdJkgpwxyQOFR7R57S6ryl/n31vfIGDA8R92U1znZm3SeF7OPBJMJs49pojjZ48dtjfS9le3p4cnnvgLR7xbhzUATWlWnj42hUOcbs5q7mHnRGlzyihij78ec3J2WPt7MPV0uajc2EzFhmbaBhnJtljN5BUGy9ePK4zecLLz76R8Q/Ogo/t2h4XxJcFRxNHjUoZ9WP0yhteF66178dUGpwV7eqG1AvotZp5YnEp3wq7lBSfkLeTk8cePmPNJpFNIi177FNIWLlz4hf8Ze3t76e7uJiUlhbi44EWayWRi6dKlB76nB5FCWvj09Hu4/Zl1VNZ3McFSy/zm90nv8LNiUhwfTI9nESmcOv+HWGy6IAdwu3auL2tla1U7Hvfe11tAcM1YflFGcH3ZuBQsEXjhtXPdXHV5cF+2wdaRAKRnxgdL+5dkkJ4VP+IvGGob13HvliX4/QGK3s1kubWEwG4buy86NJdvHlsctReZO7U527nrrds5e0k1lt2+3TpyLEwc52fn34hl7FRij70ak33/bzBEuv4+D1WbWqjY2Mz2+r2PWJtMkFuQSvGkLApKMkbc9OK25l4qdowuDnajKy7BTtGkTEomZ5ORnRB15xzDCOD59Gk8q18Cs4W2CRfy4MctNE3ajDkudHbGvDFzOK/kdMymyPs+GWkU0qLXPoW0n//85/t1MvrjH//4tTo11BTSwqOpo59bnlhD026lk+c5VhGIr2b9+FjOT5jI7MO/HXVfhPurp8s1sH9Zw9aufVpflr5zfVlJxrC7mPD7AtTXdlBd3kZNRSvO/r1XaoNgtbaCHZ83Jzc56oPIl+l0d9Hj6SMukMZNT6ymsS24F9gYSxsuw05+8XiuOHkSdlv0Xog/8MFSVrpfZ0qFk2M/DW4r4bNDdjHYdyw7s009Acfsc6Nqrd7ODZ8ry5qpr9n7hs8AOblJFJdmUTgxk9g4TSM2DIPG+i4qNjSzZVPLoBVqU9JiKZ6cTXFpFsmp0XUT0VvxIRgBbCXz2Nbax9+f/ATnmA8xJ4ROE52ZcQiXTDkfqzl6zyfDgUJa9NJm1iikDTXDMKis6+T2Z9fT6wy9AD925hhmx72HNX0cBZMWh6mH4TVQbKOijdqKNlqbB19fZjabGDU2mfzidPKLMkhKiY5NowMBg6aG7oF1bIOto4Hgfkg719nlFqRF7ZStwfQ6vdzx9FqaGxr4YdLL+E0BHvQcxsKtdUw4dTFZR80LdxcPqIBh8MRblbz+aR3WnCps48qZu6aXGdVORhcbWB2A2UrM/EuxlUTHZ/f5AtRWtlG5sZnayra9bpMBkJ4VH9zLbFIWicnRcY44GPz+AHVV7VTs41YE2aMTKS7NpnBSZlSum23vdvG3J1bQnv4BluQ2ACZUu5hW3s/G0w7lssO/g8MSfZ97uFBIi15fKaT19vbS19dHdnY2Xq+Xhx56iIaGBo4//nhmzZp1MPp5UCmkDR3D52P9HfdQ3tDCSxlzIRA8sZuA844tZvGskblppt8foGFr58DG0n09g68vszt2ri/LYNz4VBxRvoGxYRi0t/YPBLZ9KY5itZkZNz6NgpIM8grTR0zFtp08zl4aH/0dKf4WHslOZNwaDyVbg79bsSefQe5ppw6rUdYv4/MH+OdLG/m4rIkYk4dL4t+jPqeTHJeXKT0ezBYwxSYRu/gHWLKH935PO0vMV2xoprqiddApz0kpMQN7maWOwD3Bvi6P20d1RRsVG5oGHaHcOXW0pDSbgpIMbPbo2Sam1+nllidX4k14iThnF6cu68JiBIuKrDi5lEvnf5d4W/RNHR4OFNKi136HtDVr1nD55ZfzzW9+kx/96Ef89re/5fHHHycpKYne3l5uv/12jj322IPV34NCIW1o+Pr6WP+Xm4jbtgWATyak8pb/ZOxWC1ecMplDJ2SGuYdDy+3yUrsluH/Z1qp9W4eVkOQY2L9s9LiRvZ9YT5eL6opgYGus6xp0epfZbGL0uJTgOrbidOJHwJ5IvsbNOF/+O68l2+jbBnPXhZ7nbJd+j4J5s8PUuwOjp6mF/7yyic+2B0flJ9m2cXXimyHHmNPziD3+B5gT0sPRxa/NMAyatnVTURacijfYFOC4BDtFO0rmf347Dfnq+vs8A0VYmht79nqs1Womvzid4snZjC1IjYpztbN8Oc7X76ZpHVh2+7ramm3jo5Mn8oOZV5DsSApfB0cohbTotd8h7bLLLsPpdPLXv/6VjIwM5s6dy5lnnsmNN97IjTfeyMaNG3nyyScPVn8PCoW0g88fCPDOzQ+Qu/GDkPZXDi3k5NN+QOHo5DD1bGh1d7qoqQhWY2ys27f1ZRnZCQPBbLitLxsqzn4vtZVtVJe3UlfTgX+Q6UkAWaMTKSgOFh75KtUph4vuhjL+sOFfmFwBTlvWSXpX8Opqy7g4Xk44je+eOYvS/LQw9/KrWfbJCyT/+xX6DDuPjDkB944pV5eMqWSm80MArONnEXP05ZhswyuUG4ZBe0sfFWXNVJY10zNIUQu7w0rhxGDJ/FFjo7cKYaTo6nBSsaGJ8rJmutqdez02JtbK+ImZlJRmk5M7fPaZ212gv5O+x34KPg+9TdBdG5wB0xMbrP7YG28h1Z7KdTOvJDNueN4MGa4U0qLXfoe0mTNncvPNN3P00UezdOlSrr32Wh577DGmTZvGxx9/zNVXX83q1asPUncPDoW0g8vp9nHPkvWk17/LlKbVJLQHL6DLxsfw0aEJ/Gr+r0mKTQlvJw8SwzBo2d4bDGYVbYOWwIZdIz7B9WXpWjuyn7weP3XV7cHCI5VteNx7LwAAkJIeR0FJcAPtaBx5aGmr4p7P7qUj4Ofkd7tw2U28PC+ZDDd0lh/BeYvnMnfy8NniwjAMXln6H3KfWUaMN/gVVhubzROjFzFvxlguPK4Y77L7MKeOwj5jeE3p7O50DlQb7Gjt3+uxVpuZ/KJ0ikqzGFeQFpGVW6PdznN8RVkTlWUt9PftfWPwxCQHRZOzKCnNJi1zeE0/9VZ+hOudB8Dvw9kOrVvhv4vSaE/ZNY18dsbhXDL1rDD2cuRRSIte+71Aw2w243AE70i+9957JCUlMXXqVCC4Vi0mRheUsktHj5vbn1jJ4X1vckRiJb5YqPaaWZcfS22JgxvGnxZ1Ac3vC7BtayfVFa3UVrTR17v3L23Ysb6sMFjsYmxB2ohbO3Ug2ewWxk/IZPyEzJC95KorWunr+eJ/i862flZ91M+qj+qIT7QPjLCNGpscFdOUMtPH86N5P+eBD25iyTEmMMAwm2iJhcTSD1jydi8dPfP5xuHjhkWgeWTdC3TUrqDIu+seY66zmXOKLBx3/ARMJhOWhVdiGiblwft63WzZGNxoebBpdGazibEFqRSVZlFQHF3rnoYjk8lE1qhEskYlMveYQhq2dlK+oYmqza1fOIW9p9vNqo/qWPVRHemZ8RRPDq4XTEiK/GsnW9FczElZOF+7jdi0LnKT4Rh3P88YiRgmE0ZHBivWZTAvo2vEzI4ROZj2eyTt0ksvJT09nYsuuoirrrqKBQsW8Oc//5m2tja+973vkZiYyP3333+w+ntQaCTt4Khr7uUfTy7nTF6nyNY00O4y4K3RmZw852riMwvD2MMDx+X0snVLO9UVrdRVd+zz+rKC4uD+ZdESBiJZ8I53D1XlrdSUt9HRtvdRCghOIcsvChYeGVuQNuwviP1+L0+9fzPv+ltD2m0Bg+TqfCaMWcCZU5OJyc0NUw8Ht6G6nTteexdz4cfM2tTDEWv68FhMtJ5wHgvOOCHc3dtnbpeXqs2tVJQ107C1c9A1laPHJVNcmsX4CZn7vAm9hI/P66d2SzsVG5qorWonMEjlzdFjkymePDz+fQO97Thfu5VAWy0A6+PtLE+OY3Ed/KvnGHosyXx/dhKTj5weVdtcRCqNpEWv/Q5pGzZs4PLLL6ejo4O0tDQeffRR8vPzmTt3LoFAgAceeIApU6YcrP4eFAppB5YRCFD20ps8XtPGt63vk24JrcJnzikh9rjvY44d3guMuzudO6bU7VvhCoDMnJ3ry7QBc7h1tPVTU9FKVXkrzQ17H70AsFjNjM1PDVaKLEonNi6yL6T2ZtmnD/J09wYCu/3+mf0BznzTRXanhzHXXEvyIYeEsYdf7KMN2/nnSxvJMrWzKOsdnh1j57iVvYyefjaHLl4U7u4Nyuv1U1vZRkVZM1v34cI9MyeR4tJMCidlkTACCt1EK7fLy5ZNrVRsaKKhrmuvx5rNJsYVplEyOZu8wjSstsi8MWR43biW3YevekXwZ4Jr1HoDDl7ZXsoR9avxlkxl8g3fx2wbvufK4UAhLXp95RL8W7Zsobi4mLi44IL71157jZkzZ5KZOfwq9CmkHTgBr4e1f7+NuMr1rJoUy9xUN6m7FXGwTZiPY97FmCzDbzqfYRg0N/bs2Fi6jfZ9XF82Ji9lYP+yhCRdaEWivh431RXBwiMNWzsHLehiMsGosckD0yKH47rBsk2v80DdG7gsJjAMFqzoZVpFsABCwGQm7aLLyJp/VJh7uctrn2zl8bcqmWLbykUJ7xNj8lEVY2Os24sjNZe402/EZI28vZr8/gD1NR1UlDVTXd6Kz7v3ojYpabHBvcxKs0hJi96CNiNVb7eLio0tVGxooq15798hNruF8SUZFE/OYkxeasQVgzGMAJ7PluBZ+fxAm6cX2jYBO37N+0bl4f/ONzgsf054OjkCKKRFL21mjULageLt62Pt//2BxJaGgbZPZ8Zxgq0fm2EiZu752KYcN6xGj3y+ANtqOwaCWf8+rS+zkleURkFxBmMLUrE7hl8gHcncLh+1W4KBbWtV+6AX1RCswLmztH9a5vAZIW1sWMs96x/C7Q5w4cvtOHZb47Vu1GSO/tH3yUiJDWMPwdnbxarb/8XDgRLmxVdwUuwqQq5VTSYch38T2yGLI+bv3TAMGuu6qChrpmpzCy7n3ovXxCc6KC7NpGhSliq4jiDtLX2UlzVRuWHw6p1x8XaKJkXmtgreLctxLbsf/F46q8HZsuuxrlgrT5yQzMLSEzkhf2FE9TtaKKRFr30Kacceeyx33nknEydOZOHCvf8nM5lMLF269IB28mBTSPv6vD4/d770LpNX/Je8xl1BpmKsA89kO6ccfgXWsVPD2MN95+z3snVLG9UVbdRV79tFemJyDPnFwcIfOblaXxYtfF4/9bWdVJcHq3O6nHvfnwqCmwcXlARH2LJHJ0Xc3e/P6+lu5L6Pb6Oz181pb3eS6AywOc/ByzOzcdTP5Yenz2NcdnguAhrrt1Bz859J7/LgjnOQV+ompBaIPZbYY78bEecWwzBobeoNlszf2DLohvQ7y7IXl2YxKjdZF68jmGEYbN/WTcWGZrZsah401CfvGG0tjqDRVn9zFc7XbyPQ10l3LfQ3g9Nm5onjU+hMCt6oXJA7j3NKTg1zT6OPQlr02qeQ9otf/ILvfe97jB07lp///OeDfpn88Y9/PGAdHAoKaV9Pr9PLn19+gbbkT7D7fZy1tJPsDh+rSmJxTUrgm0f8AEf62HB3c6+6OpzBC/HKNrbX79v6sqxRiQP7lw2n0RP5agIBg+31OytFttHT5Rr0ObHxNvKLMigoSSc3LzViS6T7PE4er3yBtVuWM3tDH+8cmojfYsLwWaF2JtcsWsjkgqHdS23L9io6/t8fSOrfVYTHkQqpRcHppqbkbOKOvx5zyqgh7dfndbb3D5TMH2y/LJvdQkFxsGR+bn50bHAsB5bfH6C+uoPysmZqylvxDbLnY9aoxOD02ElZxCWEd7pvoK8D52u34m+t5ePmEj4a20fz2F03bTP6ZvLLE87BEaHr7IYrhbTopemOKKR9Hdvbe/nzW4/hSSsfaItz+imsd1M4LoNFx/wYU0xCGHv4xQzDoKmhZ2Bj6cH2IwIwW0zk5qWSX5xOXlG6FvKPYIZh0NbcFwxs5a37tP+dzW4hrzCN/OIM8grTIm4arGEYvF33Hk9Xvvi5ByBrWw7HzTyfI6YMTSBat72Se9f/i2nlXRy9clfhIftYSMsBa+5kYhd9D5MjPPtM9Xa7qdwYDGatTb17PdZsMZE3Po2i0izyitKx6QJV9pHX46e6PFgBtK66fa83D00myM1Ppbg0i4KSjLCdXwyfG39jOf6cUu54bhUV1jewJHXgbRiPr76EwjFJXHf2NBIivILlcKKQFr32K6Q5nU5MJtOX7oW2bt06/u///o/HH3/8gHVwKCik7T/DMCjbup27Vj0CSc0hj1kNB1dmzqR0yimYzJFzIbpz6trOYObsG3zqmiPGSl5hcLRM68vkywQrfbZSXd5GY/3eq7fBjoIy+SmML8kgvygj7HfAd7eutYwH1j2K1whdf5nTHM/i+nRmXHIe9oNYIOqDmjU8WvkYmIMjaPNW9jB9s5P+CVZKknzYphyHY843MZmHNuy4nF62bAruZdY4SIU+kwnG5KVQNClYUl37HsrX1d/nCf7+bWiiaZBqtBZrcJPz4slZjBufFrYRW58/wL9eXc8n21fibwnOpim0NpEZMHHytAxGH39cWPoVbRTSotc+hbS+vj5+85vf8Oqrr2IymVi8eDH/7//9P2JjgwvK29vb+dvf/saSJUswm82sX7/+oHf8QFJI2z+G38/KO++kqq+cZYeHzodPMqfzw9mXkxmXHqbehXL2e6itbKemopW6mo59Wl+WlLJzfVkGObnJEb+mSCJLf5+H2spg4ZG6mo5By6wD5IxJGljHlpwa3kIdANt6G7lj5QN0+7qDDYbBcct7KK1y4YmJo/AnPyM2L++Av+8rmz/ixfolYNr1d2b3+7m0oovxdgPHvIuxTzz6gL/vl/F6/FRXtFJZ1kxddcegVT+zRydSVJpF0cTwTz2T6NXV4aSyrJnysmY6B9nv0RFjpXDn2sexQ7/20TAMnnpnC698vJUFMWWc6FtB62YTZsPAvuhExp17Nmbtpfa1KKRFr30Kaf/7v//LI488woknnkhCQgJLlizhwgsv5Gc/+xkvv/wyv/vd7+jq6mLWrFn8+te/ZsKECUPR9wNGIW3f+Z1OPvvzH0iprwfgnZkJrJ4YDGp5McX8YPbFxFjDOw2ws72f6oo2aipaadrWvW/ry0YH15cVFGeQmhGn9WVyQHjcPuqqO6gqb2XrljY87sE3OU/LjKegOJ2CkoywVvrrbK/lnk/upM4Oc9b2cvj6XReDPouVvBt/T/yY0QfkvYxAgCdXvMKynnfY/ePG+QNc1tDJOFMsMcd9H+uog//d4vcF2FrVTuXGZmoq2gZdE5SaETdQxCEpzJUwZWQZKFazoZmKjc2DVh9OSHIM/K6mZw3tMoRPli6lcP3DtG8EY7fT4IYZo1jwnZ+RGpMypP2JJgpp0Wufqzsee+yx/PKXvwTgqaee4pZbbuG6667jN7/5DVlZWfz85z/nxBNPPOgdPhgU0vaNz+/ntZv/j+JN1QNtBvDMwhTGTj6WC6aehNk09HfEAgGD5obuYDCrbBv0ziKAxWIiN3/X+rL4BK0vk4PL7w+wrbaT6opWasrb6O8bfDuHhCTHjr3Y0hk1NmXIR3U9/Z08+N5f6W/oYfFH3Vh35BV3pp13JpzLpecd/bXXlvg9Hj78+++go4mnj03BawueQxxeM9c0tJCTOIrY46/DnHjwplgGAgYNWzt3lMxvxePee3W9xOQYikozKZ409Be7Il8k9He4ZdAbQmmZ8QOB7WDv82gYBs6X/4anegPt5eDb8RXd7zDx+PFpBJJTuOGwq8iJzzqo/YhWCmnRa59C2rRp07jjjjs46qjgxqbt7e0cccQR2O12TjrpJH71q1+RkDB8v6gU0vZU1dDN+NFJAz/3uJz8/c17aLc3cOabnYxuDa7nKh/nIGXOROYtvmFI++f1+qmvCe5fVlvZhrN/8PVlMbE715cF9y+z2bWAX8JjZ+GanYVHujr2XhUQgtOW8ouCI2y5BalDVoAi4PPywrt/Z0PTdk55twtrAowpNOjDwbPmEzjn3BPI/IojSN6+Xj7542/I3N4BQM0oOy8cnUzAk8BlJRdzSO9G7JMXYrId+IvInZvTV5Q1s2VTy6CjELFxNoomZVFUmkn26CSNtkvE8vkC1Fa2UVHWTO2WtkGnXI/KTaZ4chaFEzOJOUgFPQyfB9c7D+ApX057BfT3w5OLUmlJC76fwxTL9Ydewbik3IPy/tFMIS167VNImzhxIk888QRTpwb3ovH5fEyZMoVzzz2X3//+9we9kwfbSA1prc89S9c7bwPgD/ix7FiIHzCCZfUTYm2YTeAPGPR7+zB2XJNsLIihsN5N3Rg7h8yaQclR3xmSRfw71/rUVLRRX9Mx6DQkgOTUWPKLg4U/csZofZlEHsMw6GjrHyg80rJ970UBAKw2M2ML0ijYMRJ8sC6sdu/j8k8exLvuI6Z6Pez87+4zzCzxHcXCs84mL2f/LhS8fh8P//svHPlheUj7sqmZLDj7x5SMzj5Q3Q/R3tpH5Y6S+d2de99Gwe6wUFCSQXFpFmPyUnX+kGHH7fJRtbmF8g3NNGzt3OuxZrOJsePTKJl8cCqRGoaBZ9ULuD95hg0mG48WpRDY7WaHFRvXzPg2JamFB/R9o51CWvT6SiHN7/czefJkHnvsMaZPn36w+3jQjdSQ5u3ooOYXP8Hw7X1qz+58Znjw1HRG+fx8q+gbZE45/iD2EDra+oPVGCva2L6te5+ekz0macf6snRS0rW+TIaX3m4X1RXBwiMNWzsHXVNpMsHocSnBwiPFGSQkHbypu96qT+l/817MRug543XPNAoXncPU8VmY7aEFMz4/Kg/Q73Hxv8vuodvawJw1vRy+ITj/aV1BKnOuupExGakHtN89Xa5gyfwNzYNul2CxmskrTKO4NItxhelYI3RvO5H91dvjHrhBMdjWEcE9/TIonhzc0+9A3qDwVn2K8+37KHfAwznJeHd7bZNh4fKSc5g+duYBe79op5AWvb5WSHv66aeZPHnyQe/kwTZSQxpA+b/uhA8+3efjV5fE0l8Sw/mzrsQxZtIB708gYNC0rTu4bqeybdDNYSF4UbVzfVl+YbqqqknUcDm9uypFVu/b6HFmTiIFJcFpkakH4SaFv7mK7pduwurddZH3TnIstjKD0b40Sn/xSyw7pr939Lj59f3L+b/LDyd1x76C7f09/L9378Jpbws+2TBYtLyHfkcy37jqRtISDszeZ/19Hqp2lMwf7AaPyQS5BakUTwrvHlMiQ6WjtY/ysuCNi56uvY8ox8bbKJqYRfHkLLJGJR6Qc4q/tZa+V2+hNtDLg6OSce3YJmDsdg8nfNCF9/xTmTXvjK/9PiOBQlr02ueQdueddzJpUvCi3O/3c9xxx3HvvfdSXFy8x/GjRx+Yil9DZSSHNG9HB1t+/iPM/sEv/nxmqDs6neNO+TnmpAO3iN/rCa4vq65opbayHZdzH9aXxdnI37F/WW6+1pdJ9PN6/dRXd1BdHryB4XYNPgKenBa7o/BIBtmjD8zFFUCgt43O5/+GrbeRDfF23GsDjGoL9scwmbDEx2Mym3F5/Li9fhw2CzF2y46p0/0YO0rsryuOZfkh8RzW2c/ZqTNJPObbX6tfHrePqvJgyfz6mo5BRyFzcpMoLg2uxYmN080dGXmC62O7qdjQTOXGlkG/f5NTYykqzaJkchYpaXF7PXYwgf5O+l69lcburTwwOoXY7gBnL+3E7jPwmaH9tAXMO+nSkOd80cj8SKeQFr32OaR9/svdMIwv/cLfuHHjgendEBnJIc0wDBr+7zr6agefSugdY2XSL2/D7Ph6J2aA/l4PNVvaqClvpb62E/++rC9Li6WgOFj4I3t0ktaHyIgVCBg01nVSXd5GdUUrvd3uQZ8Tl2Anvzid8SUZjB6X8rU3uDU8Tra+eiuP9zZy+luDb+D9eTunTh/mdnFSyhTijv4OJuv+B6WdRRIqNzZTW9mGf5AiCRlZCRSVZlI06eBXtRMZTvz+APU1HVSUNVNd3jrovqKZOYkUlwaL6XzVCsmGz0P/sn/SXPsJresguXfXewYAX6yd2B2Fgz6/Xh5C19OnLFhI+qmnf6V+DGcKadFrn0Las88+u18vesYZw2uIeiSHNH9TJT1P/h/NawjW0/8yJsiaBonn/gZL1v4v6t1ZHKFm5/5lDYMXR4Dgne78omAwS03/+uFQJNrs3CupakelyI7WwbegsDss5BUGp0SOG5/2lUeijYCft9+5naqNlRy1spf9uW2yuiSWuHw4rvgk7NNP2q9RvkDAoL6mg8qyZqorWgctN56cGkvRpOCGvqkZB2Y6pUg027mRe0VZM3VV7XsdlTaZYExeCsWl2YyfsP/ThQ3DwL3qRZrff4aOcoh1GRiwX+cTk9VK/h//ii31wK5nHQ4U0qLXPoW0aDeSQ5r7kyfxrH6Jrhrob/7y4+KyITkP7NNPwjH7nH167UDAYHt9VzCYVbbtU5lxq9VMbkEq+UXBqnVx8ZqCJLI/dm7mXl0e3Mx9MDv3DCwoyfjK/+fWNW7igyX3csxnHft0YeUzw8ajEzht3new5s3Yp/cwjOB61Z0l8wfbdiMuwT4QzDJzDtxUT5GRxtnvYcumFio2DL6+02IxkVeUTsnkbMaNT8OyH4V3vNWfsf2Ve6mrNOhMMlFUP/hekgOOnEXJZdfs+/FRRCEteimkMbJD2kePLGF8z+s4fP1sXwPmL/htCJghZypY7GCbtICYoy790tfzevzUVbdTXdHG1i1tuJyDr5uJjbORt6Ma45j8odv/SSTa9fW6qakIToncVtNJILD3073JBDljkgcKjyTtx/5nLq+HT/94HdlbB78Zs22cjaOu+S3W9L3viWQYBu0tfVSUNVNZ1kzPINM6HTFWxk8IlswPx+bfItGuu9NJxY6CIx1tex+1tzusFE4M3igZPS55n26UGK5eXlnTxFtV/+Xbb1diHXwlBAGLmcI//X1EjqKBQlo0U0hjZIe0B296C7fHICa5Cnv3Rg6taN/jmNUlsdgKTCzq6P/CkbS+XnewAl1FG9tqOgZdEwKQmh43sH9Z1iitLxM52NwuH1ur2qkub2VrVTtez96nCAKkZ8UPFB5Jz4rf60XWJ6+uJLf8frrX9X/hzZ6ddt702dvU6a4OZ7BU+MbmQadvWm1m8ovSKS7NYuz4tK+91k5EBmcYBm3NfZRvaKJyYzN9PXsf9YpPdFBcmklxafag5xKAD9bV0/vc/1FQs/fKkwDx+UmM/tWtI3a0XCEteqnO8EhnsREgQH9XCb2mQjZlbia/fR0x/uCFkc8MK0rj6IsLjm6dmj8zeHe7ddf+Zc2Ng68v23mHfmcw+7pVoURk/zhirBSXZlFcmoXPF2BbbbBSZHVFG64vmTrY1txHW3MfKz6oJTE5JjjCVpxBTu6eG8OXlXWyynMWebnljG7YdQ75vITM4Ki8r2ZlSEjr63VTubGFyrLmQc8pZrOJsQWpFJVmUVCcoequIkPMZDKRkZ1ARnYCcxaMp7Gui4qyJrZsasXj3nMGTV+Pm9XL61m9vJ7UjLgd56JsklK+uHiPbVszk5PM9JrBvLfRNBPEp3QTaKn6SuvlRSKZRtIY2SNp99/yHl5X6BnQHPAxurucvI519I3x8PC8NDBMxPekMoeFOLcbdHcOfnfLajMztiBtx/qyNJW4FolAu+9NWF3euk//t2NibeQXB6dE5uanYrWaefDvb+L0Bu/77X4OCQlrOwoQ7Zw6bZp1IVWbg8UJ9mXj7tHjkikuzWL8hExiYm1f52OLyEHg9wWo3dJORVnTPlVbDW6Dkb1jG4xd/6d3zvLJc+/9ps9XWS8fbTSSFr32O6S9+OKLLF68GLs9ei64R3JIu+dv72F8Sfl7U8BPjq2Bdgf0ubOx+gf/N4+Lt+9aX5aXglXry0SGjZ1rwHaOsLU29Q76HKvNzLjxadRVNuP1h041/HxYaxtnZWK2Qb1nHFtj51LfHjPoOrlgme9MCidlkZD41cp8i8jQc7t8VJe3Ur6hiW21nXs9dufoePHkbPKL0nnk9mWD3vTZn/Xy0UwhLXrtd0grLS0lPj6ek046iTPPPJOpU6cerL4NmZEa0jp63Dx050fY9qvQ7Z5SM4LrywqKM8gapSpqItGiu9NFdUUrNeWtNNZ3DTrS9WXMAT8pzm3U5VhJ6M3EMPY+CpaSFrtj/6Wvv2GuiIRfX4+byo3NVJQ107J97zd/rDYzht+PPxB6LfH5sDbYevmRQiEteu13SNu+fTvPPvsszz33HLW1tRQUFHDWWWdx6qmnkpmZebD6eVCN1JC25L0q6j6sw/oVLrxGj925viyD5NR9rwAnIsOTs99DbWU7VeWt1Fe371OBoP2xs7BA0aQsMrITdLNHJEp1tPVTsaGJirLmfZpe/XnmgI9RPeV8NLue7mQvi9p6OfXoH43YNWkKadHra61JW7lyJUuWLOH111+nt7eXefPmceaZZ7Jw4UKs1uFTk2SkhjSAB2//EGff3vcb+jy73cLJ35xK9uikg9QrEYlkXo8/WCmyopXayrZBN5P+MjaHhZLSbIpKMxmVu28lukUkOhiGQVNDz0Al1y8rYPRlAiY/HVlbaRm1hYunXMChuZMOUk8jm0Ja9DoghUPWrVvHX/7yFz799FMAMjIyuOSSS/j2t7+NxRL5a5IU0vbtxGixmCidPprpc8ZqbYiIAMHz51Mvb6J1Qwv7W/zeZDFxxoXTdcNHZIQLBAzqazqo2NBEVXkrPu8+bJC287kEiMlM4Lxzp47IaxOFtOj1lUPatm3beO6553juuefYunUr48aN46yzzmLBggUsW7aMu+66i+OPP54///nPB7rPB5xC2t5DmsKZiAxGN3xE5EBoae/nsX98gnU/18vb7BZOGYGzfBTSotd+z0l88sknee6551i5ciUOh4MTTjiBP/zhDxx22GEDx5SUlNDR0cFjjz02LEKafDFdSInIgaRziogM5oMN24Obq+7jEEIA6LKamDgte8QFNPn/7N13eBRV38bxe9MhgUAk9N5CF0R6LwIivQmIiEiTzkNRUGlSVEBAkCpIB+kdaWKQSO9NQJAqLYSSkJC28/7BuyuRkgWT7Cb5fq7L6yGzs7NneH7M5p5z5pyk7aVD2hdffKHXX39dQ4cOVd26deXl5fXM/fz8/PTuu+/+5wYi4fGLFIC4xDUFgK0aVcqtOUduMMoHyd5Lh7T169crb968io6Otj5v9ujRI0VGRipVqn+6XBs1ahRnjUTC4IIHIC5xTQEQ17iuILl46ZCWM2dODRkyRCdOnNCKFSskPZ7lsVOnTnr//ffVv39/OTm97OPjsCcueADiEtcUAHGN6wqSm5cOad99953Wrl2rnj17WrcVKlRI/fr106RJk5Q2bVp16tQpThuJ+FO4RGYVfD0TFzwA/xm/RAGIa1xXkFy9dEhbt26dPvnkE7Vs2dK6LU2aNGrXrp1cXFw0b948QloiUqpiTns3AUASwA0fAHGJcIbk7qVD2t27d5UtW7ZnvpY7d27duHHjPzcKAJC4cMMHQFzhpg+gl157VLlz59bmzZuf+dovv/yiHDly/OdGAQAAIHkqVTEnAQ3J3kv3pLVt21affvqp7t27p5o1a+q1115TUFCQduzYoU2bNmn06NHx0U4AAAAASBZMhmHYuFzgPxYuXKgpU6bozp071m1p06ZVjx491Lp16zhtYEKIjjYrKOihvZsBAAAA2MzXN1XsOyFReqWQJkmGYeivv/7SvXv3lDp1auXOnTvRTr1PSAMAAEBiQ0hLul56uKOFyWRS7ty5Y2wLDQ3VgQMHVLly5f/cMAAAAABIjl46pF27dk1Dhw7Vvn37FBER8cx9Tp8+/Z8bBgAAAADJ0UuHtNGjR+vQoUNq3ry5Dh06pBQpUqh48eIKCAjQ2bNnNWnSpPhoJwAAAAAkCy/9ENn+/fvVp08fff7552rSpInc3d3Vv39/rVixQqVKldL27dvjo50AAAAAkCy8dEh7+PCh/Pz8JD1eM+3UqVOSJGdnZ7Vu3Vp79uyJ2xYCAAAAQDLy0iEtffr0CgwMlCTlyJFD9+/f1+3btyVJadKkiTEtPwAAAADg5bx0SKtSpYomTJigw4cPK0uWLMqYMaNmz56tkJAQrVixQhkyZIiPdgIAAABAsvDSIa1nz55KnTq1Jk6cKEnq06eP5s6dq1KlSmndunX68MMP47yRAAAAAJBcvPJi1rdu3VL69OklSQcOHNCRI0dUrFgxlS5dOk4bmBBYzBoAAACJDYtZJ10vHdLmzp2r+vXry8fHJ77alOAIaQAAAEhsCGlJ10uHtCJFikiSypcvr0aNGqlGjRpyd3ePl8YlFEIaAAAAEhtCWtL10iHt7t272rRpkzZu3KiDBw8qZcqUqlWrlho2bKiyZcvGVzvjFSENAAAAiQ0hLel65WfSJOn69evauHGjNm7cqFOnTilDhgyqX7+++vbtG5dtjHeENAAAACQ2hLSk6z+FNIvLly9r3rx5Wrx4scxms06fPh0XbUswhDQAAAAkNoS0pMvlVd9448YNbdy4UevXr9fp06f12muvqU2bNmrYsGFctg8AAAAAkpWXDmkLFy7Uxo0bdfjwYbm5ualGjRrq3bu3KlasKCenl152DQAAAADwhJce7lioUCGVLl1aDRs2VK1ateTp6RlfbUswDHcEAABAYsNwx6TrpUPazZs3lSFDhvhqj10Q0gAAAJDYENKSLpuGO65evVpVqlRR2rRptXv37lj3b9So0X9tFwAAAAAkSzb1pBUoUEBLly5VsWLFVKBAgRcf0GRidkcAAAAgntGTlnTZFNKuXbsmX19fubm56dq1a7EeNEuWLHHSuIRCSAMAAEBiQ0hLul76mbSPPvpIHTp0ULly5eKrTQmOkAYAAIDEhpCWdL30nPmHDh2SyWSKj7YAAAAAQLL30iGtUqVKWrt2rSIjI+OjPQAAAACQrL30Ytbu7u5au3atNm3apDx58ihlypQxXjeZTJo7d26cNRAAAAAAkpOXDmk3btxQiRIlrD//+5G2l3zEDQAAAADwhJeeOCQpYuIQAAAAJDZMHJJ0vVRP2rFjx3Tt2jXlyJFDhQoViq82AQAAAECyZVNIe/DggTp37qwjR47IMAyZTCaVKFFC48aNU6ZMmeK7jQAAAACQbNg0u+OECRN06tQp9ejRQzNmzNAnn3yiCxcuaPDgwfHdPgAAAABIVmzqSduxY4f+97//6YMPPpAkVa5cWRkyZFC/fv0UGhr61AyPAAAAAJKOTz/9VKtWrXru6xMnTlSdOnViPc6kSZM0efJknTlzJi6bl+TYFNJu376twoULx9hWpkwZRUdH6/r168qTJ0+8NA4AAACAY/D19dXkyZOf+VrOnDltOkbz5s1VqVKlOGxV0mRTSIuKipKbm1uMbd7e3pKk8PDwuG8VAAAAAIfi5uam4sWL/6djZMyYURkzZoybBiVhNj2T9iLM4A8AAAAgOjpaM2bMUL169VSsWDEVL15cLVu21J49e6z7TJo0SX5+ftaf33//ffXr1089e/ZU8eLF9eGHH+rq1avy8/PTpk2b1LNnT5UoUUKlS5fW559/rtDQ0BifuWzZMr3zzjsqUqSIqlatqkmTJik6Otr6elBQkPr27asKFSqoaNGiatiwoVavXm193Ww2a/z48apevbqKFCmi6tWra9y4cYqMjIy/vygbvPRi1v9mMpnioh0AAAAAHFxUVNRT25ydnWUymTR27FgtXrxYffv2lZ+fn27evKnvv/9evXr10q+//qoUKVI885ibNm1SgwYNNHXqVJnNZuv2IUOGqGnTppoyZYqOHTum8ePHK23atOrbt68kafr06Ro/frzatGmjgQMH6vTp05o0aZKuX7+uUaNGSZL69++vO3fuaNiwYfLy8tKaNWv0ySefKGPGjCpbtqxmzpypxYsX65NPPlG2bNl09OhRjR8/Xq6ururZs2c8/A3axuaQNnToUHl5eVl/tvSgffHFF/L09LRuN5lMmjt3bhw2EQAAAIC9Xbt27al5KiSpb9++6tSpk27duqU+ffro/ffft77m7u6uHj166MyZM88dKunq6qphw4ZZH6+6evWqJKlKlSr65JNPJEnlypVTQECAfv31V/Xt21fBwcGaMmWK3n33XX3++eeSpIoVKypNmjT6/PPP9eGHHypfvnzat2+funXrppo1a0qSSpcurTRp0lg/a9++fSpSpIiaNm1qfT1FihRKlcq+C4XbFNJKlSol6emhjc/azvBHAAAAIOnx9fXV1KlTn9puecZs3Lhxkh4PMbxw4YIuXbqkHTt2SJIiIiKee9zcuXM/Nf+FpKdCXcaMGXXt2jVJ0uHDh/Xo0SNVr149Ru9e9erVJUkBAQHKly+fypQpo0mTJunUqVOqVKlSjOAnPZ4Mcdy4cWrdurWqV6+uqlWrqk2bNrb8dcQrm0La/Pnz47sdAAAAAByYm5ubihYt+tzXjx8/rmHDhun48eNKkSKF8ubNq8yZM0t6cUfOk6PynvTv4ZFOTk7W49y7d0+S1KlTp2e+99atW5Kk8ePHa9q0adq0aZM2b94sJycnlS9fXsOHD1eWLFnUoUMHeXp6asWKFRo7dqzGjBmjfPny6fPPP1fZsmWf2+b49p+fSQMAAACQvIWEhKhDhw7y8/PThg0blDt3bjk5Ocnf31+bN2+O889LnTq1JGns2LHPnP4/Xbp0kqRUqVKpf//+6t+/vy5cuKDt27drypQpGjZsmGbMmCEnJye99957eu+993Tnzh35+/tr2rRp6tGjhwICAp7Zw5cQ/vPsjgAAAACStwsXLujevXtq27at8ubNKyenxzFj586dkhRjQpC48Prrr8vV1VU3b95U0aJFrf+5uLjo22+/1dWrV3Xt2jVVqVJFP//8s6THwyo7duyo8uXL6++//5YktWzZUiNGjJAkvfbaa2rSpInee+89PXjwQCEhIXHa5pdBTxoAAACA/yRXrlzy8vLStGnT5OLiIhcXF23evFnLly+XJIWFhcXp56VNm1YdOnTQxIkTFRISojJlyujmzZuaOHGiTCaTChQooFSpUiljxowaMWKEQkJClD17dp04cUL+/v7q3LmzpMdzbMyePVvp0qVTiRIldPPmTf34448qXbq0fHx84rTNL4OQBgAAAOA/SZUqlaZMmaJvvvlGvXr1kqenpwoWLKgFCxaoY8eOOnDggHVSj7jSu3dv+fr6atGiRfrhhx/k7e2tcuXK6X//+591dsbJkyfr22+/1cSJE3X37l1lypRJ3bt3tz7L1qtXL7m5uWnFihX6/vvvlSpVKlWvXt06zb+9mAymY1R0tFlBQQ/t3QwAAADAZr6+9p0mHvGHZ9IAAAAAwIEQ0gAAAADAgRDSAAAAAMCBENIAAAAAwIEQ0gAAAADAgRDSAAAAAMCBENIAAAAAPNPZy3ft3YRkiZAGAAAA4Cl37odp8PTfded+mL2bkuwQ0gAAAAA8Zfn2c3r4KErLfzln76YkO4Q0AAAAADHcuR+mn/dckiRt3nPJoXvTVq5cKT8/P3s3I04R0gAAAADEsHz7OUVFmyVJkVFmh+5Nq1u3rnbt2mXvZsQpQhoAAAAAqyd70SwcuTfNw8NDvr6+9m5GnDIZhmHYuxH2Fh1tVlDQQ3s3AwAAALCZr2+q57529VawZq45oas3g1/6uMGhEQoLj35qewp3Z6VK6WbzcbJmSKWODYsoa/rnt/NZ7t27p4kTJ+qXX37R3bt3VahQIfXp00dlypTRpEmTtHfvXvn6+srf31+NGzdW4cKFNXDgQJ05c0aSFBQUpC+//FK//fabnJ2d1bx5cx07dkylSpVSjx49Xqot9uJi7wYAAAAAiFszVh3X4bO34/SYYeHRCgu3vTft1t0wzTAf1/DO5W1+T3R0tNq3b6/IyEiNGTNGPj4+mjdvnj766CMtWrRIkrR//361bdtWa9asUXR0tA4dOmR9v9lsVufOnRUdHa0ffvhBrq6uGj16tA4cOKBSpUrZfrJ2RkgDAAAA4BB27dqlkydPat26dcqfP78kadiwYTp+/LhmzZqlvHnzSpJ69uypVKke99A9GdL27dunY8eOadOmTcqdO7ckacKECapevXoCn8l/Y/eQZjabNXnyZC1btkzBwcEqVaqUBg8erGzZssX63rVr16p///7avn27smbNmgCtBQAAABxfp8ZF9cOaE7ryEsMdo82G7tx/FOt+r3l7yNnJFOt+2TKkUoeGRWz+fEk6e/asUqVKZQ1okmQymfTmm29q165dyps3r1577TVrQPu3U6dOydvb2xrQJCldunTKlSvXS7XD3uwe0qZMmaJFixbpq6++UsaMGTVmzBh16NBB69atk5vb88e8Xrt2TcOHD0/AlgIAAACJQ9b0qTS0Y7mXes/0lce0PuCvWPcrVzSTOjcu9qpNe6HnTZdhGIZcXB5HFw8Pj+e+39nZWWazOV7alpDsOrtjRESEZs+erZ49e6pq1aoqUKCAxo8frxs3bmjLli3PfZ/ZbFb//v1VuHDhBGwtAAAAkDQ9a0bH54nPmR79/PwUHByss2fPWrcZhqGDBw9ahzq+SIECBRQcHKzz589bt929e1eXLtl2bo7Crj1pf/zxhx4+fKhy5f5J+alTp1ahQoW0f/9+1atX75nvmzZtmiIjI9W9e3ft2bMnTtri4sJqBAAAAEienlwXLTaWddPiozetYsWKKliwoPr27asvvvhCr732mhYsWKCzZ89qyJAh+u233174/jJlyuj111/XgAED9MUXX8jDw0NjxoxRWFiYTKbYh2g6CruGtBs3bkiSMmXKFGN7+vTpra/927FjxzR79mwtX75cN2/ejJN2ODmZlDatZ5wcCwAAAEhMXqYXzWLznktqVj2fXvNOEadtcXZ21uzZs/X111+re/fuioiIUJEiRTRnzhwVL1481pAmSZMmTdLw4cPVrl07ubu7q3Xr1rpw4YJcXV3jtK3xya4hLSzscTfpv589c3d31/3795/aPzQ0VP369VO/fv2UM2fOOAtpZrOhBw9C4+RYAAAAQEKIq06GzXsuySvlyweYLXsuqVXtAnHShif5+Pjo66+/fuZrPXr0eGqtsyZNmqhJkyaSHq+RdurUKU2YMMEayiIiIjRnzhxlyJAhztsaX+wa0iwP/UVERMR4ADA8PFwpUjydykeMGKFcuXKpZcuWcd6WqKjE/4AhAAAA8LJa1y6g1vEQtuzBxcVFffr0UcuWLdWqVStFRkZq1qxZcnNzU+XKle3dPJvZNaRZhjneunVL2bNnt26/deuW/Pz8ntp/xYoVcnNzU4kSJSQ9XuxOkurVq6cuXbqoS5cuCdBqAAAAAI4oderUmjZtmiZMmKCffvpJTk5OeuONNzRv3jz5+PjYu3k2s2tIK1CggLy8vLR3715rSHvw4IFOnTqlNm3aPLX/v2d8PHr0qPr3768ZM2bEWEsBAAAAQPJUtmxZLVmyxN7N+E/sGtLc3NzUpk0bjR07Vj4+PsqSJYvGjBmjjBkzqlatWoqOjlZQUJBSpUolDw8P5ciRI8b7LZOLZM6cWWnSpLHDGQAAAABA3LL7vPM9e/ZUs2bN9Pnnn6tVq1ZydnbWrFmz5OrqquvXr6tixYrauHGjvZsJAAAAAAnCZDxvWe9kJDrarKCgh/ZuBgAAAGAzX99U9m4C4onde9IAAAAAAP8gpAEAAACAAyGkAQAAAIADsevsjgAAAAAci2EYCv/7nELP7lN02EM5p/BUyvyl5Z45n0wmk72blywwcYiYOAQAAACJT3xMHBJx+7Jur5us8Ovnn3rNPVMe+dbvLjff7HH+uYiJ4Y4AAAAAFHH7sv6e9/kzA5okhV8/r7/nfa6I25cTuGXJDyENAAAASOYMw9DtdZNlfvTi0WXmRw91e933YjBe/GK4oxjuCAAAgMTHluGOlyd3selYRlSkoh/es/mznT3TyOTi+sJ9snefZvPxnuTv76+JEyfq/PnzSpkypapUqaKBAwfqgw8+UMGCBTV69Gjrvr/99pu6du2q3377TV999ZUkKW3atFq9erVCQ0NVtmxZDR8+XBkyZHilttgLPWkAAABAEhV1/7ZN/71MQJOk6If3Yj3mqwgKClL37t3VtGlTbdy4UZMnT9b+/fv1zTffqEmTJtq8ebMePXpk3X/16tWqXr260qRJI0lav3697t27pwULFmjmzJk6efKkJkyY8EptsSdCGgAAAACHcPPmTUVERChz5szKkiWLSpYsqWnTpun9999X/fr1FRERoW3btkmSQkJCtG3bNjVp0sT6/lSpUmn48OHKkyePSpcurbp16+rQoUP2Op1XxhT8AAAAQBLl4u1r037Rj0JkhIfZfFyTewo5e3i9arOeq2DBgqpXr566dOkiX19fVahQQVWrVtVbb70lFxcX1ahRQ6tXr1a9evW0adMmpUqVShUrVrS+P3v27HJ1/WcYZqpUqRQZGRnn7YxvhDQAAAAgibL1ubBH187q7zkDbT5uplaD5ZEl/6s264XGjRunbt26aefOnfr999/Vv39/lSxZUnPnzlXTpk3VpUsX3blzR2vXrlXDhg3l7Oxsfa+bm1u8tCmhMdwRAAAASObcM+eTe6Y8tu2bKa/cM+eLl3YcPXpUo0aNUu7cudWuXTvNmDFDo0aN0p49e3Tnzh1VrFhRvr6+Wrp0qQ4cOBBjqGNSQk8aAAAAkMyZTCb51u+uv+d9/sJp+J08POVbv5tMJlO8tMPLy0uLFi2Sq6urWrRoofDwcG3cuFE5c+ZU2rRp5eTkpEaNGmnatGkqWrSo8uSxLVgmNvSkAQAAAJCbb3ZlbjviuT1q7pnyKnPbEXLzzR5vbciTJ48mTZqkPXv2qFGjRmrVqpWcnZ01c+ZMOTk9ji5NmjTRo0ePkmwvmsQ6aZJYJw0AAACJjy3rpL0KwzAU/vc5hZ7dp+iwh3JO4amU+UvLPXO+eOtBexl79+5V586d9dtvvylVqvj5O7A3hjsCAAAAsDKZTPLIkj/eJgZ5VefPn9fZs2c1bdo0NW7cOMkGNInhjgAAAAASgUuXLmngwIFKkyaN+vTpY+/mxCuGO4rhjgAAAEh84mu4I+yPnjQAAAAAcCCENAAAAABwIIQ0AAAAAHAghDQAAAAAcCCENAAAAABwIIQ0AAAAAHAghDQAAAAAkqSTt87+p9cRNwhpAAAAALT0xHoN2zFey06sf+bry/7/9aXPeT2pqF69uiZNmmTz/n5+flq5cmWctsElTo8GAAAAINE5eeuslp/cIEla9v//27xIPevry06st25ffnKDCqfPr8Lp8yd8QxPA8uXL5e7ubtc20JMGAAAAJHOF0+dX88LvWH9ednKDtUftyYAmSc0Lv5NkA5ok+fj4yNPT065tMBmGYdi1BQ4gOtqsoKCH9m4GAAAAYDNf31Sx7tNt3WcvdcyHkWEKjQx77uspXVPI0zWF9efv64987uc+77UX8fPzU7du3bRq1SpFRkZqwYIFypw5syZOnKi1a9cqJCRE+fLlU8+ePVWxYkWdOXNGDRo00MqVK1W4cOHHn92tm/bs2aN9+/bJ2dlZZrNZ5cuX18CBA9WwYUMdOnRI48aN0/Hjx+Xj46Nq1aqpb9++8vLykvR4uGPjxo3Vo0cPSdK6des0ZcoUXb16VQUKFFD9+vU1cuRInTlzxtrmTp066fjx4zp48KDSpEmjNm3aqHPnzi99/hb0pAEAAABJ1O3QoJf670UBTZJCI8Ni7P+iz31VixYt0nfffafJkycrZ86cGjhwoAICAjR27FitWrVKb7/9trp06aJff/1Vfn5+ypIliwICAiRJ0dHR2rt3rx4+fKiTJ09Kko4dO6bg4GBVrVpVf/zxhz788ENVqlRJa9eu1dixY3Xy5Em1b99ez+q72rFjhz755BM1a9ZMa9euVZMmTTR27Nin9luwYIEaNWqkjRs3qlWrVvr222+1e/fuV/47IKQBAAAAcBgNGzZU0aJFVbx4cV26dEnr16/X6NGjVaZMGeXMmVMffvih3nnnHc2aNUvS454vS0g7duyYXF1dVbx4ce3du1eS9Ouvv6pkyZLy9vbWrFmzVKFCBXXp0kU5c+bUm2++qXHjxuno0aPat2/fU22ZNWuW6tSpo48++ki5cuVSq1at1KpVq6f2a926tRo1aqRs2bKpa9euSpUqlU6cOPHKfwdMHAIAAAAkUb4pfV76Pc8b8vjvoY5x/bkWOXLksP751KlTkh6HoCdFRkYqderUkqRq1arpp59+0qNHjxQQEKCyZcsqS5Ys2rNnjzp27Ch/f381atTIerxLly6pRIkST33u+fPnVaZMmRjbTp48qVq1asXYVqpUKc2ZMyfGtpw5c8b4OXXq1AoPD7f5nP+NkAYAAAAkUS/7XNi/JwkxmUzWYYChkWF6J3/1GLM+xtXnPsnDw8P6Z8tnL1y48KnJPJycHg8KLF26tNzc3LRv3z7t3r1bDRs2VJYsWbRw4UJdu3ZNp0+ftk6pbzabVb9+fXXp0uWpz/XxeTpYuri4yGw2x9pmZ2fnp7b9l6k/GO4IAAAA4JmzOP7UYspzZ31MCPny5ZMk3b59Wzly5LD+t3LlSuvaZK6urqpYsaK2b9+uo0ePqly5cipZsqSioqI0adIk5c+fX1mzZrUe788//4xxrKioKI0ePVrXr19/6vMLFCigo0ePxth2+PDheD5rQhoAAACQ7J28dfapgGbpMWtepN5TQe3krbMJ0q58+fKpWrVqGjJkiH755RdduXJFM2fO1PTp05U9e3brftWrV9fKlSuVPn16ZcuWTR4eHipRooTWrFmjGjVqWPdr3769Tp06pWHDhun8+fM6fPiw+vbtq4sXLz41ZFGSOnbsqJ9//lk//vijLl68qBUrVmjBggXxft6ENAAAACCZK5w+v5r9fxB7MqBZPBnUmiXwOmnjx49XrVq1NHjwYNWtW1erV6/WyJEj1bhxY+s+VapUUXR0tMqWLWvdVr58eZnN5hghrXjx4vrhhx90+vRpNW7cWB9//LFy5cqlOXPmyM3N7anPrly5soYPH66FCxeqXr16WrZsmVq1aiVXV9d4PWfWSRPrpAEAACDxsWWdtJd18tbZFwaw2F5Pavbt26d06dIpd+7c1m3Tpk3T8uXLtW3btnj7XHrSAAAAAEhSrAEsOQU0Sdq1a5c++ugj7dmzR3///be2b9+uuXPnqmHDhvH6ufSkiZ40AAAAJD7x0ZOGmCIiIvTNN99oy5YtCgoKUqZMmdSsWTN16NDhmTM6xhVCmghpAAAASHwIaUkXwx0BAAAAwIEQ0gAAAADAgRDSAAAAAMCBENIAAAAAwIEQ0gAAAADAgbjYuwEAAAAA7Ofy4p904+ctL/2+jG/XVvaWLeKhRSCkAQAAAMlYhlo1dXX5ShlRUTa/x+Tqqgxv1YjHVsXk5+en0aNH69q1a1q1apV++eWXBPtse2C4IwAAAJCMub/2mjLWfuul3pOx1ltyf+21eGrR87Vv317Lly9P8M9NaIQ0AAAAIJnL0rSxTC62DbIzuboqS9NG8dug5/D09JSPj49dPjshEdIAAACAJOpAxy7W/86M+faZ+0SFhur4p5/J5GpbSHNycdHxTz/TXz/OfebroZev6EDHLq/c5hs3bujjjz9WiRIlVLlyZa1bt8762qRJk1S9enVJ0tWrV+Xn56fp06erQoUKqlGjhkJCQl75cx0Jz6QBAAAASVT4rdvWP7unT//sncxGjP1iEx0WpuiwMEU9ePDsw0VFvdTxnhQVFaUOHTrIy8tLCxYsUEREhIYNG/bC96xatUpz585VWFiYvLy8XulzHQ0hDQAAAIBD2L17t86dO6etW7cqe/bskqTRo0erUaNGz31P69atlTdv3gRqYcIgpAEAAABJlHt6X+uf3dKkefZOTibrfkZ0tCKC7kqG8dRuJhcXuXqnlsnZWZLkkjr1sw/n4hLjc1/G2bNn5e3tbQ1oklSwYEF5eHg89z05cuR4pc9yZIQ0AAAAIIl6c+a0WPdxSZkyxn4XZvyg6xs2PbVfxtq1lLvTR7EeL2X2bDZ97rOYTCaZzean2/iCSU1eFOASKyYOAQAAAGD1rJkeE2pGx4IFCyo4OFjnzp2zbrt48WKSmRDEVoQ0AAAAAFbPWjctodZFK1OmjF5//XUNGDBAR44c0fHjxzVgwAA5OSWv2JK8zhYAAABArJ7sTUvIddGcnJw0ffp05c6dW+3bt1fnzp31zjvvJIu10Z5kMoxnPBWYzERHmxUU9NDezQAAAABs5uubKl6Pb3k2LdM7dW16Fg1xh540AAAAAE/J0rSxnD1TJlgvGv5BT5roSQMAAEDiE989aZIUfPacUuXPF++fg5joSQMAAADwTAQ0+yCkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAADJnP/ms3pwP8zezcD/c7F3AwAAAADY14Hdl7Trlz9Vsmx2la+eR6m9U9i7SckaIQ0AAACAoqPM2rfrog7uuUxYszNCGgAAAAArwpr9EdIAAAAAPIWwZj8mwzAMezfC3qKjzQoKemjvZgAAAAA28/VN9dzXAm+FaPOakwq8GWLTsR7cC5MtqcDN3VnuHq5ycjLFum+6DF6q3bCw0qX3sqkNFsHBwfrmm2+0detWRUZGqnDhwurfv7+KFi0qSVq3bp2mTJmiq1evqkCBAqpfv75GjhypM2fOvNTnODJ60gAAAIAk5udVJ3Xh7O04P25EeLQiwqNt2vf+3TD9bD6pNp3L2Hx8wzDUsWNHeXh4aPr06fLy8tKaNWvUqlUrLV26VDdv3tQnn3yivn37qnr16tqzZ49Gjx79qqfjsAhpAAAAABzCnj17dOTIEe3Zs0dp0qSRJP3vf//ToUOHNG/ePF29elV16tTRRx99JEnKlSuXLl68qDlz5tiv0fGAkAYAAAAkMXUaF9aWNSd1O46HO1rYMuzRN4OXajUsbPtBJZ08eVKGYahatWoxtkdERCg8PFx//vmnatWqFeO1UqVKEdIAAAAAOLZ06b3UuqPtwwzHDd2qh8HhL9zH2cUp3icQMZvN8vLy0sqVK596zc3NTQ0aNJDZbI6Xz3YkhDQAAAAAz5UQ4cwif/78CgkJUWRkpPLmzWvd/vnnn6tAgQIqUKCAjh49GuM9hw8fjtc22QMhDQAAAMBTEjKcWVSqVEkFCxZUnz599NlnnylTpkxatGiRVq5cqVmzZqljx47q3LmzihUrpmrVqungwYNasGBBgrQtITEFv5iCHwAAAInPi6bgf1lPDne0Rzh7UlBQkMaMGaMdO3YoLCxMefLkUffu3VW9enVJ0rJlyzR9+nTduHFDRYoUUfHixbVgwQKdOHEiwdsaX+hJAwAAAGD3cGbh4+Pz3Gn19+3bp5IlS2rbtm3WbdOmTVPGjBkTqnkJgpAGAAAAJHNvlsuhEmWz2TWc2WLXrl1at26dRo8erezZs+v06dOaO3euWrdube+mxSmGO4rhjgAAAEh84nK4Y2IRERGhb775Rlu2bFFQUJAyZcqkZs2aqUOHDnJ2drZ38+IMIU2ENAAAACQ+yTGkJRdO9m4AAAAAAOAfhDQAAAAAcCCENAAAAABwIIQ0AAAAAHAghDQAAAAAcCCENAAAAABwIIQ0AAAAAHAghDQAAAAAcCCENAAAAABwIIQ0AAAAAHAghDQAAAAAcCCENAAAAABwIIQ0AAAAAHAghDQAAAAAcCCENAAAAABwIIQ0AAAAAHAghDQAAAAAcCCENAAAAABwIIQ0AAAAAHAghDQAAAAAcCCENAAAAABwIIQ0AAAAAHAghDQAAAAAcCCENAAAAABwIIQ0AAAAAHAghDQAAAAAcCCENAAAAABwIIQ0AAAAAHAghDQAAAAAcCCENAAAAABwIIQ0AAAAAHAghDQAAAAAcCCENAAAAABwIIQ0AAAAAHAghDQAAAAAcCCENAAAAABwIIQ0AAAAAHAghDQAAAAAcCCENAAAAABwIIQ0AAAAAHAghDQAAAAAcCCENAAAAABwIIQ0AAAAAHAghDQAAAAAcCCENAAAAABwIIQ0AAAAAHAghDQAAAAAcCB2D2lms1nfffedKlWqpOLFi6tjx466cuXKc/c/d+6cOnXqpDJlyqhcuXLq2bOn/v777wRsMQAAAADEH7uHtClTpmjRokX68ssvtWTJEpnNZnXo0EERERFP7Xv37l19+OGH8vDw0Pz58zVz5kwFBQWpQ4cOCg8Pt0PrAQAAACBu2TWkRUREaPbs2erZs6eqVq2qAgUKaPz48bpx44a2bNny1P7btm1TaGiovvnmG+XPn19FihTRmDFjdP78eR06dMgOZwAAAAAAccuuIe2PP/7Qw4cPVa5cOeu21KlTq1ChQtq/f/9T+5crV05TpkyRh4eHdZuT0+NTePDgQfw3GAAAAADimYs9P/zGjRuSpEyZMsXYnj59eutrT8qaNauyZs0aY9uMGTPk4eGhUqVK/ae2uLjYfeQnAAAAANg3pIWFhUmS3NzcYmx3d3fX/fv3Y33//PnztWDBAn3++efy8fF55XY4OZmUNq3nK78fAAAAAOKKXUOaZdhiREREjCGM4eHhSpEixXPfZxiGJk6cqKlTp+rjjz/W+++//5/aYTYbevAg9D8dAwAAAEhIdDIkXXYNaZZhjrdu3VL27Nmt22/duiU/P79nvicyMlIDBw7U+vXrNXDgQLVr1y5O2hIVZY6T4wAAAADAf2HXB7EKFCggLy8v7d2717rtwYMHOnXq1HOfMRswYIB+/vlnjRs3Ls4CGgAAAAA4Crv2pLm5ualNmzYaO3asfHx8lCVLFo0ZM0YZM2ZUrVq1FB0draCgIKVKlUoeHh5auXKlNm7cqAEDBqh06dK6ffu29ViWfQAAAAAgMTMZhmHYswHR0dH69ttvtXLlSj169EilSpXS4MGDlTVrVl29elU1atTQ6NGj1aRJE7Vv314BAQHPPI5ln1drg1lBQQ//y2kAAAAACcrXN5W9m4B4YveQ5ggIaQAAAEhsCGlJF4uDAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAOxe0gzm8367rvvVKlSJRUvXlwdO3bUlStXnrv/3bt31bdvX5UqVUqlS5fWsGHDFBYWloAtBgAAAID4Y/eQNmXKFC1atEhffvmllixZIrPZrA4dOigiIuKZ+/fs2VOXLl3SnDlzNHHiRPn7+2vo0KEJ22gAAAAAiCcmwzAMe314RESEypYtq379+ql169aSpAcPHqhSpUoaOXKk6tWrF2P/w4cPq2XLltq4caPy5MkjSdq1a5c6dOggf39/ZciQ4ZXaER1tVlDQw/92MgAAAEAC8vVNZe8mIJ7YtSftjz/+0MOHD1WuXDnrttSpU6tQoULav3//U/sfOHBAvr6+1oAmSaVLl5bJZNLBgwcTpM0AAAAAEJ9c7PnhN27ckCRlypQpxvb06dNbX3vSzZs3n9rXzc1NadKk0fXr11+5HU5OJvn4eL7y+wEAAAAgrtg1pFkm/HBzc4ux3d3dXffv33/m/v/e17J/eHj4K7fDZDLJ2dn0yu8HAAAAgLhi1+GOHh4ekvTUJCHh4eFKkSLFM/d/1oQi4eHhSpkyZfw0EgAAAAASkF1DmmXo4q1bt2Jsv3Xr1jMnAcmYMeNT+0ZEROjevXtKnz59/DUUAAAAABKIXUNagQIF5OXlpb1791q3PXjwQKdOnVKpUqWe2r9UqVK6ceOGLl26ZN22b98+SVLJkiXjv8EAAAAAEM/s+kyam5ub2rRpo7Fjx8rHx0dZsmTRmDFjlDFjRtWqVUvR0dEKCgpSqlSp5OHhoddff11vvPGG+vTpo6FDhyo0NFSDBw9Wo0aNXnn6fQAAAABwJHZdJ02SoqOj9e2332rlypV69OiRSpUqpcGDBytr1qy6evWqatSoodGjR6tJkyaSpDt37mjYsGH67bff5O7urjp16mjgwIFyd3e352kAAAAAQJywe0gDAAAAAPzDrs+kAQAAAABiIqQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAEAAACAAyGkAQAAAIADIaQBAAAAgAMhpAF2Yjab7d0EAAAAOCBCGpBArl69KsMwJEnR0dFycuKfH5IGs9nMTQfEijpBbKgR2CK51Am/JQIJYNWqVerQoYO2bt0qSTKZTAoODlbv3r21Z88eO7cOeHlHjx7VF198ocjISDk5OVlvOuzbt0/379+3c+vgKKgTxIYagS2SY50Q0oAEULRoUXl5eWnHjh26f/++nJyctH37dh09elSlS5e2d/OAl7Znzx799ttvWrFihXXbihUr1KNHD4WEhNixZXAk1AliQ43AFsmxTghpQDwzDEN58+ZV7dq1deLECW3cuFGStHfvXhUtWlROTk6Kjo62cysB21iGmDRp0kQlSpTQmjVrdPXqVUnSr7/+qkqVKilLliz2bCIcAHWC2FAjsEVyrhNCGhAPDMOwBi+TySRJatmypdKlS6dt27bpr7/+UmBgoPLnzy9JcnZ2tltbAVuZzWY5OTnJMAz5+vqqZs2aCgsL0/LlyyVJt2/f1jvvvCNJ1ucvkfxQJ4gNNQJbJPc6cbF3A4CkxDAMmc1mOTs7y9nZWSEhIbp9+7a8vb3l4+OjJk2a6Mcff9T06dMVEBCgCxcuyNvbW5UrV1aOHDkkPZ5UhNAGR/JkXUtSVFSUXF1dVbNmTe3bt087d+5UxowZdeHCBe3fv19vvPGGvL297dxqJDTqBLGhRmAL6uQxk5EUoyeQgGbPnq3cuXOratWqMbaPHz9eS5cuVZo0aWQYhlasWCFPT0/17dtX/v7+yps3rypUqKBly5bJbDarQ4cOatq0qVKmTElIg13dunVLbm5u1tq19AZfvHhRM2bMkIuLi4oWLarmzZtr3759mjx5sv7880/rrKWpU6fWu+++q3feeUcZMmSw89kgvlAniA01AltQJ8/GcEfgP3j48KECAgKUOXNmSY/v/jx69Eiffvqpdu7cqZEjR+qrr75Sly5drMMfP/jgA6VOnVqenp7q3r27Vq5cqcqVK2vq1KmqUqUKsz3Crnbv3q327dvrxIkTkv4Zrjt9+nQ1bNhQISEhCgoK0u7duxUSEqLSpUurVKlSevjwoTp06KBVq1apdu3amjZtmpo2baqxY8fqxo0b9jwlxAPqBLGhRmAL6uT56EkDXlFkZKRcXV2tPwcHBytVqlS6f/++unbtqvbt26tGjRq6e/eu/v77b4WFhSlt2rTKkyePJkyYoJ07d6pr166qWbOmJOnmzZu6ePGiypQpY69TAhQREaHr169bh99Kj+9mfvrpp+rVq5fKlSsnSQoKCpKXl5fc3Nx09epVDRw4UK6urpoyZYo8PDz0xx9/aNGiRYqMjNQXX3yhlClT2uuUEA+oE8SGGoEtqJPnI6QBr+DJ7nhJmjdvnrZt26YhQ4bIZDKpa9euyp8/v9zc3HTu3DmFh4fr4sWLypEjhz799FO9/vrr6tSpk1KnTq2xY8fKx8fHjmcDPK5py7h/Sfrjjz904MABtWnTRvv379f//vc/DRs2TOnSpdOmTZt0+/ZtnT17VtWqVdPHH3+szZs3a9asWapTp466du1q57NBfKFOEBtqBLagTmLHxCHAS3oyoH3//fdycXFR/vz5debMGfn7+6t9+/bq0qWLVq1aJbPZrPr16ytLlix6/fXX1apVKx05ckTVqlVT7dq1FRUVpdSpU9v5jJDcWSarcXV1VWBgoG7fvq1p06bpzJkzKlKkiLJkyaLChQurT58+ioqKUqlSpZQ2bVrly5dP69atU65cuVSzZk2tXbtWR44cUWhoqFKmTGn9t2KZoQuJG3WC2FAjsAV1YiMDwEs7cuSIsXz5cqNevXrG4sWLDcMwjP79+xuNGjUyDh069Mz3mM1mo0WLFsbSpUsTsqmAzdauXWsUKFDAWLhwoXHixAmjSZMmxueff26Eh4cbkZGRxu7du40rV64Yt2/fNgzDMMLDw40KFSoYGzZsMAzDMM6ePWvP5iOBUCeIDTUCW1AnL5YEYiaQ8N577z199tlnatOmjVq2bClJ6tGjh4KCgrRp0yYFBwfr5MmTGjFihL7//nv98ssvatiwoSSpfPnykv5Z08OyUCNgL5cuXVK7du20evVqjRkzRk2aNFHhwoVVuXJlHT16VBs3bpSLi4uyZ8+uGzduyGw2KzIyUlOnTlXGjBnl5+cnScqXL58ksTh7EkWdIDbUCGxBndiG4Y7AS4iKipKLi4smTJig7t27KygoyPpatmzZ1KRJE61fv14VKlRQ6dKlFRwcrIMHD2rDhg2qXr26+vXrZ93fMmQySXTJI1HLkSOHHj58qOPHj6tFixby8PCQJOuzAdu2bVPlypV16dIljRo1SoZhKDIyUmazWSNHjlSePHliHI8lJJIm6gSxoUZgC+rENkwcAryiFi1ayMnJSWPGjFG2bNkkPZ6lqHnz5sqdO7cGDRokX19fBQUFyc3NTV5eXpJYrBqOxXLjYf/+/eratatat26tHj16yMXl8T28ZcuWac6cOWrdurXee+89HT9+XKdOnVKqVKlUt25dO7ceCYU6QWyoEdiCOrEdt/CB/2cYhmy5Z2HpVh8yZIiOHDminTt3KjIyUpLk5uam999/X1u2bNHRo0clSWnTppWXl5eio6NlGAYBDQ7F8sVYqlQpVapUSbt27bLWriQ1a9ZMuXLl0k8//aRjx46paNGievfdd61fllFRUXZpNxIWdYLYUCOwBXViO0Ia8P9MJpN1VqAXcXZ2ltlsVuHChfXOO+9o3rx5+uuvv6yvN2vWTD/88IN1/TPLsEZnZ+cY0/YD8c3W5x0tNx569uypwMBAbdu2TSEhIZIe12/Tpk1VsmRJa4+x9M8zlZYvXCRe1AliQ43AFtRJ3GK4I/CEJUuW6Pjx4xo5cuQLhyVapncNDg5W+fLl1bRpU/Xv31+enp4x9jP+tZ4akNAuXbqke/fu6fXXX3/hfpaaHj9+vLZt26ZevXqpVq1aCdRK2Bt1gthQI7AFdRJ36ElDsvTvoY2WPz969EiHDx+W2Wx+4bBEJycnRUVFKVWqVGrfvr1CQ0OtCzI+iYCGhPSsu5gDBgzQ3LlzJdk2A9bHH3+swMBA7dixQw8fPoz1+Eh8qBPEhhqBLaiT+JV8+gyBJ1jCU2BgoNKlS2f92c3NTd7e3rp9+7YyZMjwwmNYQlyfPn3it7GAjZ6cKTQiIkJubm6qVKmSDhw4YP35Re+NioqSh4eHpk6dKj8/v6d6hpmJNGmgThAbagS2oE7iV/I+eyQr/37YdPny5WratKkWLFhg3fbGG2/o+PHj1p9fNBr433eIkuo6HXBc/+4RPn78uL788ktJsn45urq6yjAM68Q1L2J5JvONN96Qp6dnsr+LmVRQJ4gNNQJbUCcJi5CGJO/fD5uePHlSYWFhKlasmBo1aqRRo0Zp2rRpunfvnvLkyaP8+fPL399f0rOHK1rCmOV4kydPVkBAALM2IkFFRUVZJ7ux3IA4fPiwVq5cqe7du+vYsWOSpDJlyujAgQN68OCBTCbTc780o6Ki5OzsLCcnJwUGBur27dvJ/i5mUkCdIDbUCGxBnSQ8/jaQ5FmC1rZt21S9enUNHDhQlStX1qFDh9SnTx/17NlTGzZs0GeffaY7d+4oZcqU1vc+eXExm80xnlXbsmWLateureXLl1sXYgQSiouLi8xms7755ht98sknmjhxosqXL6+ffvpJly9f1ueff66TJ08qU6ZMKl68uPbv3y/p6RsPT950MAxDI0aMUNWqVXX27NkEPyfEPeoEsaFGYAvqJOER0pAs7N27V+PGjVObNm00bdo09ezZU+7u7oqIiNBHH32k4cOH68CBA5o/f75u3rypEydOxHh/VFSUnJyc5OTkpD///FNt2rTR0KFD1bJlS23ZskUlS5a005khuTp16pRq166tQ4cOKVeuXNq6dasCAgKUP39+jR49Wjlz5lTPnj21bds2hYeHW28kWIaT/HvdviVLlqhChQr6448/NGvWLFWoUMFu54a4Q50gNtQIbEGdJDym4EeSYlnJ/t9Gjx6tgwcPaunSpU91p1umyd+3b5+WLVumDRs2qFixYvrhhx/k5eVl3S88PFwjRozQ+vXrVb9+fXXv3l3p06eP93NC8ma5RP/7buSYMWN0+fJljR07Vu7u7goMDJSTk5N8fHys+/Tt21ePHj3S9u3b9cEHH2jgwIHWY1qOd+DAAX355ZcKDg5Wt27d1LhxY4acJELUCWJDjcAW1InjYHZHJAlms1kmk8ka0M6fP6+0adPKx8dHYWFhunLlinLnzm29SERGRsrV1VUBAQE6evSounTpotKlSytfvnxyd3fX/v375e7ubr2w+Pv7a9CgQcqTJ4/mzp2rYsWK2fN0kUw8edPBsqaMJIWGhmrv3r3y8/OTu7u7JCldunSSpAcPHujixYsqVqyYBg4cqP3792vv3r26fv26QkNDlTJlSplMJt29e1cDBw7UwYMH1apVK3Xs2FGpUqWyz4niP6FOEBtqBLagThwLIQ1JguVC4u/vr2+++UZhYWFKkSKFhg8frpIlSypz5sz69ddfdfXqVWXLls26ptnixYutQxmjo6OVNm1a9e7dW2+99ZY12ElS2rRpNWrUKFWpUsVu54jkx/JlOX36dN24cUN+fn5q2bKl9TVnZ2eFhITIy8tLhmEoMjJSI0aMkJeXl4oWLarXXntNb7/9ti5cuKBt27YpZcqU1hsPixcvlre3t5YuXapcuXLZ8zTxH1EniA01AltQJ46F/kUkWk9OeR8VFaVvvvlGAwYMUN26ddWvXz9lyJBBgwcPltlsVseOHRUYGKilS5cqJCTE+j4XFxflzZtX0uN1zwzD0NGjR5UtW7YYU80WK1aMgIYEt23bNlWsWFErVqzQ+fPnNXToUM2ZM0cpU6ZU+fLltWPHDuuSESaTSW5ubjp58qTSpEkTY1atUqVK6ebNmwoMDLT2Jrdr105ff/01X5ZJAHWC2FAjsAV14lgIaUi0LA+fRkdH68aNGwoICNCECRPUrVs3vf3228qQIYPOnz+v+fPnK0OGDPrf//6nZcuWqWfPnlq9erV69eqlQ4cO6a233pL0OOhduXJFU6ZMUWRkpNKnT//MKfiB+PDvx4P//vtvzZw5Ux988IG2bNmiefPmqWHDhlq8eLGuXLminj17ytPTU7Nnz9b27dsVGhqqn3/+WW5ubipXrpykx1+it27d0rx581SgQAF5e3tbj//kLKZIPKgTxIYagS2oE8dHSEOidfbsWTVq1EiXL1/W1atX9eDBA/n5+en06dPq16+f7ty5o+bNm+u7777TrVu31LZtWw0ZMkReXl5asWKFDMPQsmXL9Prrr0t63KuWNm1a1atXT3PnzmWsNBKUyWRSWFiYli5dqqCgIG3btk23bt1Shw4dFBYWpilTpmjXrl26du2apk+fLkn68ssvlSJFCv3vf/9TmzZtNGjQIDVu3FilSpWyHjMoKEj79+/XO++8Yx3mi8SLOkFsqBHYgjpxfMzuCIe1b98+pU+fXjlz5lR0dLScnZ1jPMgaGBioihUr6qefflKRIkV0/Phx+fr6atKkSUqbNq1atmypyMhINWjQQO3atVPv3r3l5uYm6fGDrqlTp5b0uCfOycmJXjMkCMukNZaaftLixYv19ddfa//+/Tpz5ox27NihVq1aafbs2bp586Y+/PBDXbx4UYMGDdKcOXP0xhtvyGw26+jRo7pz544qVqxonfb4ydm0LJ+JxIM6QWyoEdiCOkm86EmDQwoODtaYMWN06NAhSY+HNj548CDGc2iPHj3SG2+8ocOHD8vZ2VnFixfXDz/8oAsXLqhly5bKkSOHdXHE2bNna9myZYqKipIka0CzLE5NQEN8u337tipUqKB9+/ZJUowvS0tdli1bVs7Ozjp16pSKFCmirl27asuWLTpz5ozq16+vIkWKKDIyUhEREZo4caJ2794tJycnlShRQjVr1pSHh4f1WE/WNF+WiQd1gthQI7AFdZL4EdLgkDw9PbVgwQI1adJEknTx4kW1aNFC7du3182bNyVJWbNm1aNHj3T//n1J0sOHD/X333+rUKFCypEjh27fvq2ff/5ZI0aM0JQpU9SqVaun1lBjbQ4kFF9fXw0dOtS6YOfdu3fVs2dPHT9+3PrlGRkZqdy5c+v8+fPWn6dMmaKKFSuqatWqkh4P861fv75MJlOM9WksnrVOIBIP6gSxoUZgC+ok8eNvFg7FMqOik5OT3N3ddfLkSY0fP17jx4/XqFGj9L///U/Dhg3T+++/r3Llyqls2bLauXOnevXqJU9PT/n4+Gjz5s06f/68zp49q+LFi6tq1arWC8uT3fFAQrGsPfPWW28pIiJCx48fl5eXlwIDA9WrVy+1b99ebdq0Uf78+fXgwQPdu3dP0uM7odmyZdPGjRuVK1cu/fTTTzp37pymT5+uPHny2PekEOeoE8SGGoEtqJOkgW4EOAzLgtROTk46efKkJkyYoIcPH2rXrl1atmyZ3njjDY0ZM0YuLi7q06ePjhw5ogwZMsjHx0eXLl2SJPXu3VtffvmlChQooLFjx2r69Okx7vwQ0JCQLMNzLXcar1y5okWLFum9995TypQptWjRIlWtWlUzZ87U1KlTJUnVq1fXr7/+KknKli2b3n33XaVIkUIjRoyQm5ubli1bZv2yfHL4LxIv6gSxoUZgC+okaWHiEDiUsLAwBQQE6Ntvv1XNmjXVunVrLV68WIsWLdKmTZuULl06RUREqHfv3oqKilJUVJTu3r2ruXPnKnXq1M/sKXvWw7JAQvr777/1/vvvK1++fPryyy/VokULValSRUOHDtWjR4+0bt06jR07Vo0bN5bJZNK9e/fUp08fpU+fXpIUERGhu3fvKkOGDJKo6aSKOkFsqBHYgjpJGghpsJsnZ2qUHo+XHjlypLZu3aqWLVtq4MCBkqSrV6+qbdu2qlixooYPHy7p8eyMq1at0oIFC3TlyhXNnDlTlSpVeuHxgYQWHh6uQYMGKUWKFHrttdfUqVMneXp6aunSpRo+fLjmzJmjkiVLymQyadmyZQoICNDPP/+sXLlyae3atXJ1dY1x4+HJ4cBIOqgTxIYagS2ok6SFv3UkOMMwYgQoS/e5l5eXKlasKCcnJ6VIkcK6f+bMmdW5c2ctX75cJ06ckPR4dsYPPvhAffr0Ue3atVWgQIGnPoeLChKSZYarJz169EgPHz7U8uXL5evrK09PT0lSs2bN5OfnpxkzZlgnvmnSpIkGDRokPz8/Xb16VZcvX5YUc4iuZTgwEi/qBLGhRmAL6iTp428eCerJ587Onz+vTz/9VKNHj9aqVasUGhqqOnXqqHz58lq7dq31PU5OTqpVq5ZKlCih8ePHxzhe3bp1NXHiRPn6+ib0qQCS/rnTaHkG4MCBAzp+/LgePnwob29vdevWTV5eXtYvRstdyf79+2vnzp36/fffZRiGnJ2dlT59ek2dOlU7d+7kIe0khjpBbKgR2II6ST4Y7ogEZxiGNm/erC+//FJvvvmmwsPDdfToURUuXFgzZszQ4cOH1b59e/Xs2VMfffSRtdftt99+U8eOHTVx4kTVrl3beiyTycR4adjFk8NCLly4oJ49eyokJEQRERHKnj27OnbsqBo1amj06NFavXq1NmzYoHTp0lnf369fPx06dEgLFy5UpkyZYhybmk46qBPEhhqBLaiT5IWeNCSoY8eOqUOHDlq9erXatm2riRMnatq0afriiy/0xx9/6Ntvv1XJkiXVvHlzfffddwoLC7N2tb/55psaMWKEdc0P6Z9ueS4ssAeTyaSQkBBt2bJF06ZNU8mSJbVy5UqNGDFCmTNnVv/+/XXjxg19+OGHcnd3t86mZdGtWzeZzWY9ePDgqWNT00kHdYLYUCOwBXWSzBhAAnr06JFRq1Ytw8/Pz9i+fbt1e3BwsDFx4kSjTJkyxp07d4zz588bNWrUMPr06WMYhmGYzeYYx/n3z4C9LFq0yChXrpxRtmxZ4/Dhw9btFy9eNOrWrWv079/fMAzDmDdvnlGsWDHj1KlThmH8U8PUcvJAnSA21AhsQZ0kH/SkIcFER0fL3d1dffr0kaenp27dumV9zcvLSyVLlpS3t7cuX76s7Nmzq1mzZtq/f79CQkKemlaf9c5gb8b/jxR/9913Va5cOT169Ehubm7W17NkyaKWLVvK399fQUFBaty4sbJkyaKhQ4dK+qeGLcN1kTRRJ4gNNQJbUCfJj4u9G4Dkw9KVXqdOHS1evFh79+5VuXLllCNHDuvrV65ckYeHh1xcXNS6dWt16dLFnk0GnstkMlmfl2zWrJnOnj2rXbt2yc/PT87OznJxcVHKlCmVMmVKPXz4UD4+Pho+fLgiIyOfOhbDTJIu6gSxoUZgC+ok+aEnDf+Z8RJzz1ju3vTo0UP79+/X/PnzdfbsWd2/f18bN25UzZo1raEtderUkp49zSzgCCzPS5YrV07FixdXQECA9u7da3391q1bypUrl3VB0DfffFPlypWzS1thP9QJYkONwBbUSfLC7I54Zcb/r3f2sndkjP+fnWjYsGFavHixChYsKFdXV92/f19jxoxRsWLF4qnFQOxedoYry53NP//8U/369dPt27dVr149hYeHa+XKlRo6dKiaNGkSY1YuJH7UCWJDjcAW1Ameh540vJLo6GiZTCY5Ozvr/v372rp1q65cuWJ9/UXZ3/Ja9+7dlTlzZhUsWFBdu3bV5s2bCWiwG8MwYnxZWtaYiY2Tk5MMw1DevHnVqFEjRURE6OLFi/Ly8tKSJUvUpEkTSTxHmVRQJ4gNNQJbUCeIDSENNlm9enWMny0XlXHjxqlatWoaOXKkWrdurY0bN0p68cXByclJ0dHReu2119S8eXPt3bvXOqSRh1mRUEJDQ61/ttxxdHZ21l9//aUePXro448/1tSpU603H8xm83OPZbnx0KRJE2vP8AcffKBChQopIiLipYYEw7FQJ4gNNQJbUCd4WYQ0xOqXX37R9OnTde/ePeu2hw8fqmfPngoICNC4ceO0YsUK5cyZU4sXL9aJEyckvbg3zXLx+fjjj5UmTRotXrxYFy5c4GFWJIgff/xRH3zwgUJCQiQ9vqlgGIYmTZqkRo0ayWQyKXfu3FqwYIEWLlxoHV7yvJp2cnKS2WxW6tSp1bRpU126dEnLly+XJLm5uXFHM5GiThAbagS2oE7wSuJnZn8kJREREU9tO3LkiPH2228bR48eNQzDMO7du2c0bdrUKF68uPHdd98ZYWFhhmE8e32zqKioGMf+8ccfjbZt2xp///13PJ4F8I+LFy9a146xOHbsmFGvXj1j79691m1t2rQx3n77beOXX34xDOP568tERUXFqOsPP/zQaN68uXHx4sV4aD0SCnWC2FAjsAV1glfBFPx4LsudHFdXVxmGodGjRytz5sxq166drl27psyZMyt37tzasmWLVqxYoQoVKqhAgQJas2aNdUahJ+/mREVFycXFRc7Oznr48KEGDx4sf39/LViwQO3atbPfiSLZscwgeuzYMaVLl06ZM2fWtm3b5O3trSJFiuj8+fP64YcfdOvWLbm5uWnDhg1644035O3tHeNhbONfk+f4+/tr3759atCggV5//XXr5yBxok4QG2oEtqBO8CoY7oinWJ4Ls0z1KkmRkZEKDg7W999/r3v37qlu3boaPHiwLl++rDVr1qhkyZLq3r27Pv74Y129elXr16/XX3/9ZX2vJLm4PL4nMHPmTFWrVk0PHjzQ7NmzVaBAgQQ+QyRH/17KISQkRK1bt9b3338vSapUqZLatGmj69eva+7cuUqRIoVWrVqlBg0a6LffftOOHTsk/fO8ZVRUlPWZghs3bujjjz9Wnz595Orqqrp16ypXrlwJe4KIE9QJYkONwBbUCf4rQhqeYrlDs3v3bs2ZM0cXLlyQm5ubevbsqZQpU2ry5MmSpMyZM+vbb7+Vh4eHWrRoIVdXV/3yyy/y8fHR4cOHtXXrVkmSq6urJGnHjh2qVauWVq1apS+//FIzZ85kNkckGMtNglu3bslsNsvLy0sDBgzQxo0bdfToUb355puqU6eOFixYoGvXrqlRo0ZKmTKlPD09df/+fY0dOzbGejSW43399deqW7euUqRIoTVr1qh3795yc3Ozyzniv6NOEBtqBLagTvCf2W2gJRxKZGSk9c/h4eFG3759jTfeeMOoUKGCUatWLWP9+vWGYRjGvHnzjEKFChmnT582DMMw6tatawwfPtwwDMPYs2eP0bp1a2PBggXG+fPnrce7evWq8d577xnlypUzpk+fboSGhibgmSG5io6OjvHz8uXLjWrVqhnvvPOOMWLECCM8PNwwDMOoV6+e0aVLFyMsLMy4ceOGUaZMGWPnzp2GYRjGo0ePjN69exvDhw835syZY9y5c8d6vKVLlxqVKlUymjdvbuzevTvhTgxxijpBbKgR2II6QVzjmbRkzvj/sc4uLi6Kjo7W+fPn9fDhQ7m6umrr1q26deuWJkyYoEWLFqlMmTJ69913tXr1ao0bN05Tp05V06ZNrXd7rl69qg8//FDvvfee9fgRERFasGCBcufOrTFjxihTpkx2PFskF0+uPRMVFaVr165p6dKl6tixo06dOqWtW7cqZcqU6tOnj/r166fOnTtrx44dqlKlinx8fDRq1ChVq1ZN27ZtU5YsWdSvXz9lyZJF0uMhK9988402b96svn37qmnTpsxKmkhRJ4gNNQJbUCeIDybDYDGF5Mp44mHUFStWaMSIEUqXLp3CwsJUpkwZff3113JxcdGGDRs0ffp0Va9eXb1799aOHTvUo0cPTZw4UTVq1NCBAwd09epVVa5cWT4+PtZjG4YhJycnPXz4UJ6envY8VSQTT35R3r17V+PGjZOLi4tu3LihAgUKqHfv3rp//75++OEHrVmzRnPnzlWuXLn08ccf6/r165ozZ45u3rypOXPm6OrVq6pZs6Y++OCDGJ9hNpt16NAh5cuXT97e3vY4TfxH1AliQ43AFtQJ4hMhLZk7c+aMrl27poULF6pp06YKCQnR9OnTVbhwYX333XeSpEePHmnUqFE6evSoRo8erUKFCqlz5846cuSIfv/99xh3dKKjo+Xk5MQaHbCrw4cPa8SIEXJ1dVWKFCm0e/duDRo0SG3btpUkHThwQF999ZWyZs2qCRMm6K+//lLDhg3VoUMH9ezZU1FRUXJycrJOnvPkFzGSDuoEsaFGYAvqBPGBiUOSuU8++US9e/dWunTpVLduXTVq1Eh9+/bV1q1bdeDAAUmSh4eH6tatK09PT/3444+SpP79+2vYsGExLiKGYcjZ2ZmABrsJDAxU3759NXXqVJUvX15LlizRt99+q/Lly2vLli0KCgqSJBUvXlxvv/22Dh06pJ07dypXrlxq3LixLl26ZF0qwrJYqCS+LJMY6gSxoUZgC+oE8YmQlkxZptkfOnSoXF1drRcGNzc3lS9fXuXLl9eYMWOs28uWLavChQvr5MmTunDhgvLmzas6derEOCbhDPaWLl06ubi4aOfOnXJ3d5ckpU2bVr169dLBgwe1fft2RUdHy8XFRVWrVlXu3Lk1cuRISdKQIUOsQ1UsnlyGAkkHdYLYUCOwBXWC+EQ1JEGWYPUilrs0xYsXV61atfTHH39o9+7dkqQ0adKoS5cu+uOPP7R69Wrrezp06KCFCxcqd+7c8dJu4L+w3Hjo1KmT8uXLp7NnzyokJESS9Prrr6tp06aaMWOGrl+/LknKkyePmjRpok6dOj3zOEiaqBPEhhqBLagTxDdCWhJz/PhxHT9+3KZ9LWGuR48eCgkJ0fbt23Xv3j1JUtGiRa0LVlsuOhkyZFDatGltCoFAQrPceMiTJ49q166tixcvatu2bdbXe/TooQcPHmju3LmKiIiQJDVo0EBNmzaV9M8dTIaZJG3UCWJDjcAW1AniGyEtifn999/Vp08fSY+nv39RoLKMf86cObOaNm0qf39/7du3T9Lj59A6deqkUaNGycvL66n3AfHN399fvXr10tixY7Vr1y7rl9yLatryWuvWreXt7a0tW7bo2rVrkh7fZHj//fd15coVMV9S0kGdIDbUCGxBncDRMLtjEvP333+rQYMGyps3r1KnTq0hQ4ZY19p4Fss0/NHR0WrSpInSpUunoUOHKlu2bAnYauAfZrNZkyZN0oIFC1S3bl1duHBBFy9e1FtvvaUvvvhCJpMpxvIRz3q/k5OTVqxYoXnz5qlOnTr6+OOPY7yGxI86QWyoEdiCOoGjonISOUvGtvxvYGCgQkJCdPToUTVo0OCFAU2SNaA5Ozurbdu2SpcundKmTRvv7QaeJzAwUP7+/ho1apSGDRum+fPnq0OHDgoICNCkSZMkvfjOpuWLtGnTpvL29taePXt069YtSYoxvTESN+oEsaFGYAvqBI7KJfZd4Kgs07ZK/1wk3NzcNGjQIC1cuFC7d+9WvXr1Yj2OZTx006ZNrWOlAXsJDg7WtWvXYtwsaNiwoe7du6cZM2aoSZMmypo163PXkXnyxsPgwYOVPn16pU6dOsY+PAOQ+FEniA01AltQJ3BU9KQlYi4uLgoLC9OUKVO0ePFibdq0Sblz51bbtm3VuXNnrVy5UgcPHoz1OP++w8MIWNhTcHCwUqVKpdu3b1u3pUmTRvXq1VP+/Pmt0xe/6EvP8qVpGfZrGAZ1ncRQJ4gNNQJbUCdwVIS0RMjyD3/NmjWqXLmyfvvtNwUEBGjo0KEaNGiQrly5osaNG6t06dIaM2bMc48THR1tXYBakmbMmKGFCxcqMjIyQc4DeJbixYvLzc1N/v7+CgsLs27PmTOnWrRooWPHjunYsWOSnn1DISoqSk5OTnJ2dlZQUJD++OMPmUwm1vFLYqgTxIYagS2oEzgqQloi8O+LgslkUkhIiJYsWaIePXpo8eLFmjx5sho3bqz169drx44dMplM6tatm06cOKFVq1ZJkh48eCDpcTizdM2bTCb5+/urbt26WrBggbJlyyY3N7cEP0ckH9u2bdOhQ4esSzs8ydKr261bN61fv14nT560vubs7KyiRYsqS5Ys1llIn/wStLzXMgR47Nixqly5sk6cOMGyEYmI5Xr3888/6+7du8/chzqBxLUEL8a1BIkdIc3BRUVFPfNuzK+//qr79++rbdu2On/+vDp16qQVK1Zo+PDhqlmzpu7fv6/SpUurSZMmGj58uOrVq6eVK1cqIiJCzs7OcnZ21pUrV/TRRx9pwIABql+/vjZv3qzKlSvb4SyRHPz666+qWLGiJkyYoM6dO6tnz57avn27pH++TC29uu+8844KFSqk77//3voAtiQVLlxY9+/fj/Fvwmw2y2w2W9+7evVqVa5cWfv27dPUqVPVrFkzZtdKREwmk27duqXevXvrt99+e+YvO9RJ8sa1BLbgWoLEjipycC4uLjKbzZozZ46WLVumX3/9VdLjdcyuXr2qESNGqEWLFvL29taaNWvUoEEDjRkzRvv375ckDRo0SO3bt1fdunXVrl07ubm5yWw2a8SIEWrQoIHSpUunVatW6eOPP1aKFCnseKZIysLDwzVv3jw1bdpUK1eu1KRJk5Q1a1b1799fFy9efOaNiGHDhmn//v1asmSJ9U55YGCg3N3dlSFDBkmPfyFzcnKSk5OTjh8/rmbNmunbb7/Vxx9/rEWLFqlSpUoJep6IG4cOHZIkLVmyRH///fcL96VOkheuJXgZXEuQmLFOmoNbs2aNRo0apUyZMskwDKVNm1ZTpkzR5cuXNWDAAN2+fVsLFy5U7ty5JT1eJ61WrVoaMWKEGjVq9NTxjh07pv79+8vb21uffPKJSpYsmcBnhOTo0KFDateundauXaucOXNKkm7fvq1u3bopRYoUmjRpUozZsCxry8ycOVObNm2S2WxW48aNtW3bNgUHB2v69OnWL83Q0FB9+umnCggIULNmzdSlSxeWkUjEoqOj1a1bN4WGhuro0aP66KOP1K1bt2c+tE+dJD9cS2ArriVI7JiC30FYsvKTdwFv3rypxYsXq2fPnnrvvff04MEDRUZGKmXKlMqePbsqVaqkhQsXKjg4WCEhIfLy8tLatWtVqFAhlS1b9qnjm0wmpU2bVkOGDFHZsmXpjkeCSZ06tTw9PXXnzh3lzJlTZrNZvr6++uyzz9SqVStt27ZNTZo0se5v+ffQsWNHlSpVSosWLdKuXbuUM2dOffbZZ/Lw8LDuu2PHDnl6emrhwoUqUKBAgp8b4tbRo0d1+fJlTZ48Wbt379b48eNVq1atZ/5/S50kP1xLYCuuJUjs6ElzAE+ud/bkqvbr1q3T999/rwkTJihLlizasGGDbt68qQsXLqh+/frKnj27pk+frp9//lmFChWSJF2+fFlDhgxR3bp17XY+wL+dOXNGX3zxhcqXL6/evXtL+qfWBw0apMOHD2vTpk0vPMajR4+sX5TR0dEymUxycnJSREQEk90kIefOndOaNWvUo0cPRUVFqVGjRipRooSGDRtm05Bs6iRp41oCW3EtQWJHV4odWfKxJaDNmjVLkyZN0s8//yxJKlGihG7fvq1evXqpdOnSWrp0qXbt2qWbN2+qX79+evTokcaNG6exY8fqnXfe0TvvvKPdu3cT0OBw/Pz8lD17dh08eFDHjx+P8dr777+va9eu6ZdffrFuO3r0qPr06RNjPw8PDxmGYX1g29ITzJdl0pIvXz7169dP7u7u8vT0VL9+/bR+/XodOHDgqX2pk+SHawlsxbUEiR0hLQE9fPhQ169ff2po48aNG1WuXDktWbJEO3bsUO/evbV161ZlzZpVs2bNUocOHTRjxgx9+eWX+uGHH7RkyRIZhqELFy5Ikt5++221a9dO7dq1k5OTk6Kioux2jkie/r0g+rNea9eunS5fvqxt27YpNDTUWv9ZsmRRiRIldO7cOet79u7dq3z58kmKuQSF5U4mEqcX1cm/WWZiq127tkqXLq0pU6Y8NY02dZL0cC2BLbiWIDmg8hLQ5s2bNX/+/BjPnZ0+fVo//PCDunTpoq1bt+qnn35S+fLlNXXqVD169EjFixdXnTp1VKRIEfn5+cnb21sLFy5UwYIFVapUqac+wzAMa88cEJ9+/fVX9ejRQ5Ke+SC2hbOzswzDUJEiRVSnTh399ttv2rhxo/V1wzB09uxZpUuXzrqtY8eO6tq1qyQ9c7Y2JB621sm/PfmLUb9+/XTy5Elt3bo1xi9Q1EnSwLUEtuBaguSGkJaAXFxcNHv2bG3fvl2LFy/WvXv39PPPPysyMlIffPCBwsLCNH36dJ08eVKnTp3SvHnzJEkBAQFq0KCBevTooffff1/jxo1Ts2bNlCVLlqc+g4sLEsr58+e1e/dubdiwQdKL72xavgy7du2qnDlzasaMGVq+fLn++usvrV27VunTp1exYsWs+1vqmEdmE7+XqZPnKVKkiOrWravRo0crMDDQup06SRq4lsAWXEuQ3DBxSDx7ciIQSapYsaICAwNVv359jRgxQrt379aFCxdUp04d/fjjjwoKCtJ7772nvXv36scff9T69euVPn16LViwQDdu3JCrq6s6d+4cY6YhICFZavratWv69ttvde7cOa1cuVIuLi5P1fuTLFMcX7lyRUuXLtWKFSvk6empsLAwDRo0iGcpk5hXrZPnCQoK0tGjR1WtWrV4ajESGtcS2IJrCZIrQlo8sYyBfrKbfdu2bfrss8/04MED62QfDx8+lIeHh2bNmqUTJ06oRYsWqlixoqZOnaqJEyeqZs2a+vTTT5U1a9YYx39yRkggoVh+ObLYvHmzxo4dq4YNG6p79+5Pvf4it2/f1rVr11S8ePF4ai3sJS7rBEkT1xLYgmsJkjMqOx5ER0dbV6S/evWqtm3bpsDAQFWvXl179+5VkyZNNHHiRF27dk2enp66d++eZsyYoUqVKqlixYoyDEPXr19Xo0aNdPny5ae69HnuDAnNbDbLMIynvgxLly6tKlWqaPny5bp27ZqcnJxsGoJiGIZ8fX2tv1Qx2U3SENd1gqSHawlswbUEIKT9ZxEREdbpXC1fDs7OzoqIiNCnn36q+vXra+jQofrggw+0e/duSVK3bt0UGBio5cuXS5ICAwOVIUMG7dmzR/v371f37t118OBB9ezZU2vXrlWOHDlifCbPnSEhWb4oTSaTDh8+rPHjx2vZsmU6efKk0qZNqwYNGih16tSaOHGipBc/0G0YhnW9GYvo6GhuOiQB8VEn/96GxI1rCWzBtQR4jJD2H0RGRmrixIlq06aNIiIi5OLioujoaN28eVPt2rXTzZs3NXPmTP3000+KiorS0qVLdfnyZWXOnFkdOnTQggULdPbsWfn5+alu3bq6du2aevfuLVdXVy1atEiZM2eWxJ1B2JfJZFJYWJg+/fRTdejQQRcvXtT8+fM1YMAATZ48WcWKFVO9evUUEBCgvXv3Snr2A91RUVEymUxydnZWUFCQdVa2l5mlC44rvuuEm1OJH9cS2IJrCfAYIe0/cHV1Va1atZQ5c2aNHj1a0uMviYMHDyo0NFRjxozRm2++KbPZrLCwMB04cEC//fabJKlDhw5KnTq1vvrqKy1fvlx58uTR3LlztWzZMk2YMEHe3t7Wiw53BpEQLHcXn3WXMSAgQGfOnNHy5cs1ceJErV27VpGRkZo/f75u3LihGjVqyM/PT5MnT5b0z1TZkp6q4/Hjx6t69eo6ceKEwsPDE+LUEIeoE8SGGoEtqBPgxQhprygiIkKS9Prrr+v999/X4sWLrYtLnz9/XoUKFZKXl5d++uknDRkyRO3bt1eBAgW0evVqnT59Wm5ubhoxYoSuXbumSZMmKVWqVHJ3d1fmzJljrHAPxLfDhw9b/2y582gRHR0ts9msVatWqXLlysqVK5dWrFihmjVrytvbWzNmzJDZbFaePHnUoEEDXb16VQsXLrQe68k6Xrt2rapUqaJdu3bpu+++04ABA+Tu7p6wJ4tXRp0gNtQIbEGdALYhpL0iNzc3mc1mTZ8+XcHBwXJ2dtaYMWMkSe3atVOvXr20d+9e+fv766233lK7du303nvv6fjx41q/fr2CgoJUrlw5zZ49W/7+/qpQoYL12Kxwj4Syfft2vf/++1q9erVMJpNcXFx09uxZ/fTTTzp16pRCQ0Pl5OSkiIgIHTx4UB999JHGjx+vDz74QMuWLVNoaKi++uor3bt3T+XKlZOfn5927dql6Ohoubq6ysnJSadPn9a7776rMWPGqGPHjlqyZIkqV65s71PHS6BOEBtqBLagTgDbMY7uFZ09e1ZdunRR+vTpVa5cOWXOnFk7duzQjh07VK1aNUVFRWns2LGqXr26GjZsKEnas2eP0qVLJ39/fxUqVEjvvPOOdUFqptSHPeTNm1c1a9bUvHnzVLduXU2cOFFz5sxR7ty5defOHRUsWFATJkxQ1apVNWbMGFWpUkX+/v7WO5XHjx/X3r17FRkZqQwZMujzzz+3LhcRERGhfv36KSAgQI0bN9bUqVPl4+Njz9PFK6JOEBtqBLagTgDbkQpe0datW5UrVy5NnjxZKVKkULNmzTRmzBgNGzZM1apVk5ubm/7++2+lT59e7u7u2rhxo44fP65PPvlEb7zxhjWcWRDQkJAsC4DmyJFDtWvX1sSJE/Xpp58qKipKq1atUvr06fXHH3+oe/fumjhxoqpUqaKiRYvqxo0bCg8Pl4uLi0JDQ/X777+radOm8vX1lSTrl2V0dLQCAwOVOXNmzZ8/X4UKFbLn6eIVUSeIDTUCW1AnwMtjMetX1LFjRzk7O2vatGnWbX/88Yfatm2rjh07qmPHjho6dKhWrlypTJky6d69e+rbt69atGgh6Z8HZZllCAnpWYusBwUFaerUqVqyZIkqVaqkKVOmWL9Q169fr88//1xz587Vw4cPNWDAAJnNZhUsWFB//PGHcufOrW+++UaZMmWy1ykhHlAniA01AltQJ8CrI6S9gsjISA0aNEj379/XiBEjlD59ekmPu9r79++v3bt369dff1XKlCm1c+dO3bt3T3Xr1rX2llkuRkBCio6Otg4ZuXHjhi5fvqwCBQooderU2r9/vz7//HPly5dPkydPti4k6uzsrJo1a+rtt99W37599ddff+nYsWO6dOmSihQpourVq0uippMS6gSxoUZgC+oE+G8YY/eSDMOQq6urihcvrjlz5sjf31/NmzeX9HhK/gcPHujBgwfq16+fpkyZEuNhVctzZ1xYEN8iIyN15swZFSlSxFp3lkXWhwwZoi1btihlypTKnDmzxo0bp5IlS6px48ZatWqVDh8+rBIlSig6Olrh4eHKlCmTwsLCJEk5c+ZUrly5YnzWk1/ESFyoE8SGGoEtqBMg7jGF4Ct67733lD17ds2fP1+LFy/WjRs3tHnzZplMJo0dO1Zt27aVFHMdEJ47Q0IIDQ3V8OHD1bFjR+si62azWVeuXFHLli11/fp1TZ48WVOnTtWff/6pmTNnKiIiQjVr1lSOHDlirDsTFBSkW7duqWzZspJiDs+11DZflokTdYLYUCOwBXUCxI9kH9KioqKeuf15o0BNJpN1ocQBAwaobNmyGj16tDp27KhBgwapevXqqlev3lMXGHrPkFBSpkyp8uXLK23atNZnJp2cnBQQECB3d3dNnjxZ5cqVk7e3t1xdXbV9+3bt3btXefPmVe3atXXw4EHVrl1bQ4cOVePGjZU1a1aVKFHiqc+hphM36gSxoUZgC+oEiB/JPqRZere2bdumgIAA/fHHH5JefDGw3MXx8/PToEGDtGHDBg0ZMkQBAQFq06aNpOeHPCA+WequYsWKqlSpklasWKFLly5Jks6dO6e8efPKy8tLixYt0meffaauXbsqbdq0+vHHH3X37l1Vq1ZNNWrU0N27d5UzZ04NGzZMs2bN0muvvWbP00Ico04QG2oEtqBOgPiT7CYO+ffDpgEBAfriiy/k5eUls9msW7duqWPHjmrZsqVSpUr10sdnvTM4igMHDmj06NHKnj27xo8fr5s3b8psNuv48eNas2aNKleurHfffVfLli3TsGHDNHDgQLVo0UIBAQG6f/++dX0/iWcAkjLqBLGhRmAL6gSIW8mqJy06OjpGQLt7966mTp2q+vXra+3atVq/fr1atmypcePG6ffff4/1eP8eKhkdHU1Ag8MoXry46tSpo/379+v3339XhgwZ5OzsrK+//lqvv/666tevL+nxF6uLi4sWLlyogwcPqmrVqtYvS54BSPqoE8SGGoEtqBMgbiXZRBEVFaW7d+/K19fXekfG2dlZkZGRWrhwoapVq6bTp0/rypUrWrBggcLDw/XVV19p3bp16tixo0qWLKnIyEi5uro+dWzL8VxcXBQZGamlS5eqZcuWXFTgMCwT1VSrVk379u3T5MmTVb58eRmGobt37ypHjhxKmTKlNmzYoBs3bmjcuHHKlSuXcufOHeMYPAOQtFEniA01AltQJ0DcS5I9aZcvX9Zbb72lffv2SfrnjsyBAwfUsWNHBQQEKCoqSuHh4cqePbtmzpypatWq6dy5c5o5c6a6d++ucePG6a+//pL0z52d6Oho6zoekjR//nxVrFhR/v7+unfvXsKfKJKNu3fvauvWrTp9+rQePXok6cXPPVq+6PLmzau3335b165d07Jly+Tj46OyZcvq008/Vf369TVs2DDVrVtXNWrUUO7cuWUYBgutJ2LUCWJDjcAW1Algf0nqmbTg4GDrc2QHDhzQm2++Kelxr9rs2bO1ePFiFShQQOPGjVPKlCm1fv16DR48WJ6enhowYIC1K/7s2bNq0aKFhg8frgYNGsgwDJnNZms4+/333zVy5EhFRkaqe/fuql+/PhcXxJtZs2Zp0qRJypMnjy5cuKAqVaqod+/eypkz5wvvPFpeu3nzpsaPH68TJ05o6dKlcnNz0+bNmxUcHKymTZtae4u5i5m4USeIDTUCW1AngIMwkpCVK1cav/zyi/XnW7duGWvWrDEiIyONHTt2GNWrVzdatWoV4z3vvvuu0aZNG+PPP/+0bps/f77RqFEj4/79+zH2vX79utGpUyejVKlSxsSJE42QkJD4PSEkexcvXjTq1atnrF+/3ggNDTU2bdpktG3b1qhfv74RFhZm83F+/fVXo3z58sYXX3zx1GuRkZFx2WTYAXWC2FAjsAV1AjiOJDPc8fbt21q0aJG2bdumBw8eKDg4WKtWrdKQIUO0d+9eVa5cWW+//baOHTtmnWZfkrp166awsDC1aNFCgwcP1scff6xvv/1WzZo1U+rUqWU2myVJo0aNUu3ateXl5aUVK1aoZ8+e8vT0tNfpIpnYsWOHgoOD9fbbbytFihSqU6eOBg4cqJs3b+q777577jp/Fsb/d5SXLFlSHTt2VIMGDWJsN1hkPUmgThAbagS2oE4Ax5FkQpqvr6/q1q2rgIAAlS5dWj/++KPatGmjLFmyaO3atQoJCVHDhg1VsGBBTZo0yfq+SpUqacKECWrTpo2cnJzk4+OjDRs26L333pP0eEFGy/EnT56scePGKVu2bHY5RyQfli+0tGnTyjAMPXz40Lq9QIEC6tmzpxYsWBDjhsOzmEwmGYYhLy8vtWvXzjoEmEXWkwbqBLGhRmAL6gRwPIk2pBmGoejoaElSZGSkDMPQ3r17defOHRUoUECNGzdWypQp1apVK/3+++/65ZdflC9fPtWvX19HjhzRL7/8Iunx82pZs2ZVnz59NHjwYI0cOVKZMmWyThJi0bFjR1WqVMku54qk78lak/75IvPw8FCaNGm0ffv2GNubN2+unDlzau7cuZJk7fH9N8u/EYvIyMg4bTcSFnWCl0WNwBbUCeB4EmVIM5vNMplMcnZ2VmhoqEJCQmQymdSvXz8NHjxY0dHRWrNmjSTpvffeU7Zs2bR27VpdvXpVderUUfHixfXdd99JUoxud0uvmWWSEO74IL4FBgZK+ueL8MkhIZJUsWJFeXh46Pfff9fNmzclPa5PNzc3tW/fXj///LMCAwPl5OQU4xd4s9lsXSrCZDJp+/btev/997Vr166EPD3EEeoEsbH8//5v1AieRJ0AiUeiCmmWC4IlTI0dO1Z16tRRp06d9M033yhv3rxq3ry5cufOrd27d1un4O/atavOnDmjzZs3K3369HrrrbcUGBio/fv3P/NzLMcH4svly5fVrl07dezYUV26dNHChQslxRwSYjab5enpqcaNG+vAgQPy9/eX9E99FixYUNmzZ9epU6divDcqKkpOTk5ydnbWxYsX9eGHH2rQoEGqVKmSKlasmNCniv+AOoEtVq5cqUGDBun06dOSYva4UiOwoE6AxCVRpRHLBeGvv/7Sjz/+qN27d6tfv37KlSuX5s+fb/0FpmXLlgoODtaWLVsUERGhihUrqnz58lq4cKGOHDmiunXrat26dSpVqpQ9TwfJ1OXLl9WtWzdlyZJFnTp10muvvaaRI0dq9uzZCgkJkRRzauKWLVsqV65c2rRpk/bu3Ws9TkhIiK5du6b06dNL+meYiYuLi6KiojRs2DA1btxYGTNm1Jo1a9SpU6dnLs4Ox0SdIDaWoWSXLl3SgQMH9NtvvykiIsL6XJAFNZK8USdA4uTwIc1yETD+f8HDFStWqHv37lq7dq0+++wzNWjQQIMGDVKzZs00fvx4mc1mlStXTmXKlNGBAwe0adMmBQUFacCAAcqSJYtSp04tNzc3pU2b9rljqoH4dPz4cUVFRal37956++23NXLkSPXr109TpkyxPitpMplkMpms9d+rVy9Jj2cZDQgI0KVLl7R+/XqVKlVKmTJlkqQYi6xXqVJF586d06xZszR69GhlzJjRDmeK/4I6QWwsvwAfOnRI0uOZ+Y4cOSIp5gQN1EjyRp0AiVTczugfd6Kioqx/fvTokREYGGgYhmEcOHDAaNOmjVGhQoUY+x89etSoUKGCMWTIEMMwDOOvv/4y2rdvb7zxxhuGn5+fcevWrQRrO/AiY8eONRo1amQYRsw6f//99422bdsap0+fNgzDMMxmc4z3nT592ujatatRrVo1o2LFika9evWMkydPWl+Piooyvv32W6NUqVLGmjVrnno/EhfqBLExm83G6tWrjdq1axs7d+40qlatanz55ZfG3bt3ra8/CzWSvFAnQOLksCHNYvr06Ub16tWNd99913j77beNDRs2GNOnTzfeeOMNY8uWLdb9Hj16ZEyfPt0oXLiwcfHiRcMwHi/KuG3bNiM4ONi635O/7AAJyfIFtnXrVqNYsWLGhQsXDMMwjPDwcMMwDOPw4cNG2bJljblz51oX+/z3l15kZKRx48YN4+jRo08d1zAeL7jOIuuJG3WClzF79mxjzJgxhmEYxnfffWfUrFnT+Pnnn5/ajxpJ3qgTIPExGca/5nR2AIZhyGw2a9SoUdq1a5d69OihAgUKaMGCBdq5c6fKlCmjyMhIXbx4UcuXL7e+7+LFi+rcubM8PT21cuXKGMeMiopiAUU4hJMnT2rYsGEqUqSIBg8eLOnxzFhOTk7q3bu3rl69qvnz5ytFihSSpKCgIAUGBip//vxPHcsymxaSHuoEL2L8//OI169fV4YMGeTk5KSoqCg1adJEuXPnVr9+/ZQ1a9YYzy1SI8kPdQIkXg75TJrJZNLdu3d16NAhDR48WPXq1ZOPj4/++usvmUwm1alTRxUqVNCDBw80e/Zs6/uyZcum/v37q2vXrk8dk4AGR+Hn56eSJUvqwIEDOnDggKR/Huzu2rWrTpw4YZ36+N69e+rVq5fmz5//zGPxZZl0USd4Ecsv1JkyZZKTk5MiIiLk4uKijh076uDBg9q5c2eM/R48eECNJEPUCZB4OWRIk6Rz587p5s2bKl26tEaMGKEaNWooXbp0mjNnjjw8PGQYhipXrqyFCxfqzp07kh5fPGrWrKmaNWvaufXAs5nNZrm4uKhWrVpKkyaNfvjhB0mSu7u7JCkiIkK+vr66ceOGJMnb21vffvutvvzyS7u1GQmPOsHLcnNzkyTVr19f+fPn1+bNm61TrUtSqlSpqBFQJ0Ai4rAhLUeOHIqOjlbx4sV1/vx5zZgxQ+PGjVO2bNk0ZMgQhYaGqmLFijKbzSyWiETDst5MiRIlVL9+fZ05c0YTJ05UVFSUJOn06dPy9fVVsWLFJD2+u+nr6ytJzEaajFAneBVPzsx39uxZrVmzRuHh4ZKoEfyDOgESB4cdA/jaa6+pRo0a2rFjh6ZMmWJ97uL8+fOKiIhQpkyZVKVKFS1ZskQZMmSwc2uRnL3sGH3L2P933nlHzs7OGjp0qLZt26ZMmTJp79696t27t1KmTBnjGQGJRdYTO+oEsfmvz/s4OzvLMAwVK1ZM1atXV/r06a09J0+iRhI36gRIHhxy4hCL48ePq1evXsqSJYvq1q2rLFmyaPLkyXJzc9OECROULl06SbIuxvjkLypAQnjyF+Q///xTXl5eL70+zIEDB/Tnn3/q0qVLatasmfLkyRMfTYUdUSeITVzUiPTPL/CWSWaQtFAnQPLh0CFNkk6cOKEvv/xSjx49UmhoqKpUqaLPP//c3s1CMvfkncw///xTn332mS5evChPT0999NFHeu+992I9xr97QJ48tpOTEzcdkgDqBLGJixp5kefVDxIX6gRIfhw+pEmPp89/+PChDMNQmjRpJDENLOwvPDxc169f16xZs+Tm5qbq1atrw4YNWr9+vWbNmqVSpUrFegxLHXNXM+miThCbuKgRyzIz/LKddFEnQPKSKEKa9M9dHrPZLJPJxMUFCerfvxRHRkbqiy++0OrVq1W+fHl999138vLykiS9++678vLy0oQJE5QqVapnHu/fvSARERFyc3PjizORo04QG2oEtqBOACSaW7GWiwjDe5CQDMOwfrlJss6u5+rqqlatWilTpkzy8PCwfllKUr9+/RQQEKAdO3Y893jOzs4ymUzy9/dX1apVNXfuXEk8V5lYUSeIDTUCW1AnACwcdnZHwB5CQ0OVMmVK688mk0nOzs66cuWKpk2bJjc3N+XIkUNVq1bV66+/rjp16mj58uW6ceOG9eHtUqVKqV69epo5c6ZKly5t3W4ZZmI53tChQ3Xy5Em1bdtWbdq0scv54tVQJ4gNNQJbUCcAnifR9KQB8W3BggVq06aNQkJCJP0za+iiRYvUoEEDBQcH6969e5o1a5Y++ugj3blzR+3atZOXl5emTp0a41h9+vTRuXPntGrVKuudUBcXF5nNZo0YMUINGjRQunTptHLlSnXt2tW6xAQcH3WC2FAjsAV1AuCFDCCZCw4ONgzDMC5fvmwcP348xmuBgYFGq1atjBUrVli3HTlyxKhdu7bRo0cPwzAMY+HChUbBggWNEydOGIZhGGaz2TAMw9i6dasRFBRkfd/8+fONChUqGK1atTL2798fr+eEuEedIDbUCGxBnQCwBSENydrNmzeN9evXG3fv3rVuO378uHH16lXDMAzj559/NkqXLh3jizQiIsJYs2aN4efnZ5w9e9aIjIw0Wrdubbz77rvP/ZxVq1YZxYsXN1atWmVER0fH2/kgflAniA01AltQJwBsxXBHJGu///67PvnkE925c0chISF68OCBPvroI02YMEHS44lqQkNDrQ9pG4YhV1dXFS1aVFmyZNG+ffvk4uKiDz/8UFevXtXff/8d4/hms1mS1KhRI+3atUuNGjVi6vREiDpBbKgR2II6AWAr/uUiWWvUqJF8fHzUrVs3NW3aVDdv3lS/fv20bds2HTx4UOXKlZO3t7eWLVsm6Z+ZsB49eqTAwEBlzpxZklS5cmXt2rXL+rPFk1+Onp6eCXRWiGvUCWJDjcAW1AkAWxHSkKyYzWbrw9mWhUFv3bqly5cvq2HDhsqXL5+aN2+uXLlyafr06YqKilKHDh00a9YsrV69WteuXVNoaKjWrl2rN998U8WKFZMkubm5SfpnumQkbtQJYkONwBbUCYBXlWgWswb+K8taMZIUHBxsXfTz999/1+TJk2UYhr766ivlyJFDu3fv1ocffqixY8eqXr16GjhwoHbs2CEfHx9FRkZKkr766iuVLFnSbueD+EGdIDbUCGxBnQD4LwhpSJKe/HI0DMM6ZOT+/fv6+uuvdeHCBRUtWlQNGzZUkSJFdObMGTVs2FCffvqpWrZsKQ8PD/Xu3Vtnz57VkiVLlCJFCp07d05//vmnXF1d9fbbb9vz9BBHqBPEhhqBLagTAHGN4Y5Icvz9/dWkSROFh4fH2L58+XJVr15dV69eVYkSJbRhwwbNmzdPgYGB8vPzU+PGjTV37lxduHBBktS3b19dv35dM2bMkCQVKlRIDRo0sH5ZMswkcaNOEBtqBLagTgDEB0Iakhxvb2+dO3dOixYtkvT4wevAwEAtXrxYgwYN0rx58/TJJ5+oatWq2rt3r7Zs2SJJGjx4sO7du6eVK1fq1q1b8vb2VseOHXX58mU9q8PZxcUlQc8LcYs6QWyoEdiCOgEQH/gXjyTDMsSkcOHC6ty5s6ZMmaK6desqQ4YM+vXXX/Xo0SOVKVNGd+7c0axZs3TgwAF5e3vrl19+0Ztvvqn8+fOre/fu+v7777V27VpVr15dw4YNk7u7u71PDXGIOkFsqBHYgjoBEJ8IaUgyLM8AuLq6qmXLllqzZo0mTpyoUaNG6Y033pDZbJaLi4t++OEH3bt3Tz/++KPOnj2rPn36aMeOHcqfP78++ugjZcyYUWFhYWrWrJn12E8+b4DEjTpBbKgR2II6ARCvEmbNbCBhbN682di+fbthGIbx008/GQUKFDAOHz5sff3HH380GjdubOzatcswDMPYu3evUbBgQaNs2bLG/PnznzpeVFRUgrQbCYs6QWyoEdiCOgEQX5jdEYmSYRgyDCPGwp23b99WmzZtlCtXLo0aNUpeXl5q166dnJ2dNX/+fEVERKhhw4Zq0aKFPvzwQ0nSiBEjdP/+fRUuXFiVKlVSnjx57HVKiAfUCWJDjcAW1AmAhMbEIUiUTCaTnJycFBwcbH3A2tfXV23bttW1a9e0ceNGubm5qXv37jp48KDWrFkjNzc35ciRQ1OmTNHYsWPVpEkT7d27V+3atVO7du34skyCqBPEhhqBLagTAAmNkIZE49+dvv7+/vrggw+0adMm67bmzZsrU6ZM2r59u86fP6/y5curXr16+u677/To0SONHDlSb7/9tk6ePKkKFSpo3bp1Kly48DOPj8SJOkFsqBHYgjoBYE+ENDg8s9kss9lsfUjbIkuWLDIMQ/7+/rp3754kyc3NTS1atNCtW7e0bt06SVLnzp0VEhKiiRMn6rXXXtPgwYM1ffp09e3bV9LjB7QlPXV8JC7UCWJDjcAW1AkAR0BIg8N68hkAJycnHTlyRFOmTNGWLVt0+/Zt5c2bVw0bNtSJEyf0888/W99Xs2ZNZc2aVZs3b9ahQ4eUJ08eNWnSRMePH1dERIRcXFzk5uYms9kswzCYQSuRo04QG2oEtqBOADgSQhoclslkkslkktls1jfffKO2bdvq999/16BBg9SmTRvt379frVu3VsaMGbVt2zZdvHjR+t6sWbPq5s2bmjNnjh49eqQ+ffpowYIFcnNzs+7j5OTEncwkgDpBbKgR2II6AeBICGlwaIsWLdJnn32m+/fva/HixZo7d662bNkiLy8vTZo0SXfu3LE+uP3TTz8pOjpat27dUkhIiJo2baq33npLHh4e1i/KqKgoO58R4gN1gthQI7AFdQLAURDS4BAszwA8KTo6WmazWatWrdKxY8eUPXt2OTk5ycfHR//73/9048YNbd68WVWqVFHFihW1fPlyvfvuu6pdu7bc3NzUq1cv1a9fP8YxXVxYvz0xo04QG2oEtqBOADg61kmD3ZnNZuvaM1euXNH9+/eVNWtWeXt76+HDh+rdu7fu3bun5cuXKyoqyvql9+GHHypVqlT6v/buPK6nfH/g+Ku6KmSrpIhrr0gJk4pQY012QxNFTDI1ttzCD4mRGUuTpbLW2KKMTMYwhIvJOnO7lsEYNI2xjKVtYkpavr8/PDrX1zeKGWN7Px+PHo++3/M553zOOe863/f3s5ylS5eSmZnJhQsXOHHiBPb29nTs2BH43+xZ0sXk9SdxIsojMSIqQuJECPE6kK94xEunra1NXl4eISEhpKSkYGhoSFFREe7u7kyYMIGRI0fi6+vLsWPHcHR0pLi4GB0dHWrXrs3169cBMDIyokOHDnTo0EHZ7qM3YvH6kzgR5ZEYERUhcSKEeB1IkiZeuvv37/Pxxx+TlZXFmjVrISIvkgAAHdNJREFUKCoqIjk5mZUrV2JqasrQoUNxc3MjNDSU1atXY2pqSlZWFpcuXWLEiBEa2yu9UcrN8s0icSLKIzEiKkLiRAjxOpAkTfxtSvv/l97IVCoVWlpaXLlyhZSUFMLCwmjVqhUAzZo1o7i4mMWLFzNgwAD8/f0ZMWIEbm5uuLu7c/DgQVq0aIGzs7PGfuRG+XqTOBHlkRgRFSFxIoR4ncl/FvG3ePTZM9nZ2Tx48EBZdu7cOVQqFY0bN1beq1q1Ku7u7hQWFrJjxw6aNGmCj48PRUVFODk5ERERQWxsLEZGRi/jcMQLInEiyiMxIipC4kQI8bqTJE28UI8Ooi4qKmL69OkMGjSIYcOGERQUxL1792jfvj2ZmZn8+OOPynpaWloYGhqir6+vTGHcq1cvGjVqxOHDh3F0dESlUlFcXPxSjkv8tSRORHkkRkRFSJwIId4UkqSJF6p0hquzZ8+SlJREWloaM2bMoEePHqSkpBAUFEROTg79+/dnyZIl3Lp1S1n3t99+w8DAQOmOUrduXfz9/dm5cydHjx5FS0sLHR2dl3Jc4q8lcSLKIzEiKkLiRAjxppAxaeIv9egYgNL+/8nJyYwfPx5zc3Nmz55Nhw4dcHV1pWnTpixYsIDk5GR8fX3x9PRk/PjxODo6YmhoyOrVq3FxcaFx48bKtjp16oSlpSV79uzBycnpJR+teF4SJ6I8EiOiIiROhBBvKnlOmvhTcnNz2bhxIx06dMDW1lZ5/8GDB+jq6gKQmZnJrFmzOHHiBDt37sTExEQpN2nSJG7dusXGjRs5efIkW7du5erVq+Tl5eHh4cGQIUM09pmVlYWhoeGLPzjxl5E4EeWRGBEVIXEihHhbSEua+FPOnj3Lpk2byM3NVW6Y8+fPJz09nfr169OjRw/atWvHkCFD2L9/Pz/99BMmJibKDbV///6MGzeOvLw82rZtS9u2bbl79y7VqlVT9lH6jJpScrN8/UiciPJIjIiKkDgRQrwtZEya+FOcnJzo2bMn33//Pdu2bWPcuHEcP34ca2trjh49ysSJE0lOTqZTp0706NGD+fPnAyjfeJ49e5YWLVqgpaWlDMg2MDAAUF7LGIDXn8SJKI/EiKgIiRMhxNtCujuK5/LoN41paWlMnToVfX19KlWqxMKFCzEyMuLWrVssXbqUgwcPcujQIdLT0xk6dCj29va4urpStWpVFi1ahIeHB35+fi/5iMSLIHEiyiMxIipC4kQI8baRljTxXHR0dPj999+5cuUKTZo0oUePHvz3v/9FR0dHeY5MnTp18PHxobi4mNjYWJo1a8aYMWM4ePAghw8fZsOGDXh7e8vN8g0mcSLKIzEiKkLiRAjxtpExaaJCHu+j/+DBAwIDA7l27Rp79uzBw8ODI0eOkJ+fz40bN6hbty4ADRo0wNHRkbS0NFQqFe7u7uzcuZNKlSoRHx+vbK+kpARtbfnO4HUncSLKIzEiKkLiRAjxtpP/UKJCHu+jr6ury+jRo7l58yZJSUkYGBjQv39/8vPzOXjwoFq59PR0DA0N0dLSwszMjNGjR7Nnzx5OnjwJPHz4qNws3wwSJ6I8EiOiIiROhBBvO/kvJZ6odBA1PJz22NfXl7NnzyrvtWnTht69e7N48WIKCgro168f9evXZ8uWLWzbto2rV6/yzTffkJ+fj4ODA/Dwxuvq6oqNjQ3Tpk0D/vfwUfF6kjgR5ZEYERUhcSKEEP8jSZrQ8OgMV4WFhcp7t27dIjw8XCmnr6+Pj48P+fn5REdHA+Dt7c0ff/xBaGgoM2bMICwsjEGDBtG5c2dlverVqxMYGIiXl9ffeFTiryZxIsojMSIqQuJECCE0yeyO4olWrVrFnj17qFmzJu3bt8fa2hpfX18iIiLo3r07AIWFhaxYsYLY2Fi++uor6tevT0hICGlpafj6+uLg4IC+vj7wsIuJfIP55pE4EeWRGBEVIXEihBD/Iy1pQkNGRgaenp4kJiYydOhQzMzMMDc3x8bGhu7duxMeHs79+/cBqFSpErVr1yY/P1/5xjMgIID58+fTpUsX9PX1KS4ulpvlG0jiRJRHYkRUhMSJEEJokiRNaDh16hQGBgYkJiYyZMgQJk+ejL29PYWFhfj4+HDv3j3Wr19PUVERADk5OQwZMoSzZ8+SlZWFiYkJ5ubmqFQqVCoVOjo6crN8A0mciPJIjIiKkDgRQghNMgW/0HDz5k2+/fZbzp07x5EjR7h8+TLXrl3j5s2bdOvWjUmTJjFjxgwuXLjA3bt3uXz5MuvWrWPOnDlq25Gb5JtN4kSUR2JEVITEiRBCaJIxaUJDZmYmEydO5Pz58xgbG+Po6IiJiQlVq1blk08+ITk5mX//+9+cPHkSPT09pkyZojxMtKioiH/8Q3L/t4HEiSiPxIioCIkTIYTQJEmaKNODBw/Izc3F2NiYwsJCKlWqxOHDh5k3bx7Lly+nQYMGFBYWoqurC2g+eFS8HSRORHkkRkRFSJwIIYQ6+fpJlElHR4dLly6xe/duXFxcyMjIICIiAisrK8zMzNDS0lJuliUlJXKzfEtJnIjySIyIipA4EUIIddKSJsqkUqlISUlh/PjxNGzYkBs3btCnTx9mzpz5sqsmXiESJ6I8EiOiIiROhBBCnSRp4ql++eUXMjIyaNCgASYmJoB0MxGaJE5EeSRGREVInAghxEOSpIkKKy4uRltbW2bQEk8lcSLKIzEiKkLiRAjxNpMkTQghhBBCCCFeIfIwayGEEEIIIYR4hUiSJoQQQgghhBCvEEnShBBCCCGEEOIVIkmaEEIIIYQQQrxCJEkTQgghhBBCiFeIJGlCCCGEEEII8QqRJE0IIYQQADz+VB55So8QQrwckqQJIZ7ohx9+ICgoiC5dumBjY0PXrl2ZOXMmV69eVStnYWHBsmXL/ta6LVu2DAsLC+X1vXv3GDt2LLa2trzzzjv88ssvWFhYsG3btheyfy8vLywsLPDw8HhimUmTJmFhYcHUqVNfSB3KqpOXl9ffsq+ybNu2DQsLC65du/bEMteuXftLrsvzbqesOHkbHDlyBAsLC/r06VPm8tzcXIKDg/nPf/6jvJeamsqYMWP+8rpMnToVV1fXv3y7QgjxJvnHy66AEOLVFBcXx7x582jfvj2TJ0/GxMSEK1euEBMTQ3JyMuvWrcPS0vKl1e+9997D2dlZeZ2UlMSBAwcICQmhWbNm1K1bl4SEBBo0aPDC6qCtrc2pU6e4efMmpqamasvy8vI4cODAC9v368rExOSFX5eneTxOzM3NX0o9/m6JiYk0b96cixcvkpqaStu2bdWW//jjj2zfvp1BgwYp733xxRekpaX93VUVQgiBtKQJIcqQmppKWFgYnp6exMbG0qdPH9q3b8+QIUPYvHkzenp6/N///d9LraOpqSmtW7dWXufk5ADg6emJvb09urq6tG7dGkNDwxdWhxYtWqCnp8fu3bs1lh04cIDKlStTp06dF7b/19HfcV2e5vE4+cc/3vzvKnNzc9m3bx+jRo2iUaNGxMfHv+wqCSGEKIckaUIIDTExMVSrVo3AwECNZYaGhkydOpV3332XvLy8Mte/cOECH330EQ4ODrRs2RJnZ2fmzp3L/fv3lTJHjhxhyJAh2NnZ8c477/Dhhx+qfWv/66+/MnbsWNq3b4+trS1Dhw7l0KFDyvJHuzt6eXkp3S0tLS2ZOnVqmd3hbty4QWBgIPb29tja2jJixAjOnz+vLC9d5/PPP6dnz57Y2tqSmJj4xPNUpUoVOnfuXGaStmvXLnr06KGRBJSUlLBq1Sq6deuGtbU1PXr0YMOGDWplvLy8CAkJITo6GmdnZ2xtbfH19SUjI4PExES6deuGnZ0dI0eOLLNrYVRUFE5OTtjZ2eHv76/RPfXixYv4+fnRpk0b2rRpQ0BAgFqZEydOYGFhQXx8PC4uLrRp04YjR46QlZXF5MmT6dChA61ataJfv34kJSVp7P/06dN4eHjQqlUrunTpwpo1azTOcel1Ke0iefr0aQYMGICNjQ19+vQp85yWx8LCgri4OKZPn469vT12dnZMmDCBjIwM5bw+HicABQUFLFiwgM6dO2NtbU2fPn3YtWuX2rZdXV2ZN28eI0aMwMbGhunTpwMPk76QkBCcnJxo1aoVQ4YM4dixY89Ur1JJSUkMGDAAW1tbunTpQnh4OA8ePFCWl3fdnmTHjh0UFRXh7OxM37592bNnj5KswsPr7e3tDYC3tzdeXl5MnTqVL7/8kuvXr6tdr2vXrhEcHEzHjh1p2bIljo6OBAcHk52drWxPpVKxdu1aevXqhY2NDd26dSMmJuaJ49vOnz9Pu3bt8PX1VY533bp19OzZk1atWuHs7ExoaCj37t0r91iFEOJNIUmaEEKNSqXi8OHDODo6Urly5TLLuLm5ERAQQJUqVTSW3b59m2HDhpGfn8+nn37K6tWr6d27Nxs2bGD9+vUAXL16FX9/f6ytrVm+fDlhYWGkp6czZswYSkpKKCkpwc/Pj/z8fBYsWEB0dDQ1a9bkww8/5MqVKxr7nDVrFoMHDwYgISEBf39/jTJZWVl4eHhw7tw5Zs6cSXh4OCUlJQwbNkyjS9eyZcvw9fVlwYIFdOjQ4anny83NTenyWOrevXt8++23uLu7a5QPDQ1l6dKl9O3blxUrVtCzZ0/mzZtHVFSUWrmvv/6aY8eOERYWxvTp0zl27BjDhw9n/fr1TJkyhTlz5nD69GnmzJmjtl5qaio7d+4kJCSEuXPncuHCBby9vZUPuOnp6Xh4eJCZmcn8+fMJCwvj6tWrvP/++2RmZqptKzIykilTphASEoKdnR1BQUGkpaUxe/ZsVq9eTYsWLZgyZQrHjx/XOMbevXuzatUq7OzsWLhwYbldP/38/Hj33XeJjIykUaNGTJw4US0pr6iIiAhKSkr47LPPCA4O5sCBA8ybNw8oO05UKhUBAQHEx8fj4+PD8uXLsbOzY9KkSRoJaFxcHK1atSI6OprBgwdTUFDAiBEj2L9/P5MmTSIyMhJTU1M++OADjUTtafUq3faUKVNo2bIlkZGRjBkzhg0bNjB37lzg2a7b4xITE3F2dsbY2Jj+/ftTWFjIl19+qSxv2bIlISEhAISEhDBr1iz8/f3p3LkztWvXJiEhgS5dupCfn4+3tzdpaWnMmjWLmJgYvL292blzJxEREcr2FixYwIIFC3B1dWXFihUMHjyYRYsWsWrVKo26paWlMXr0aGxtbYmKikJXV5evv/6ahQsXMmzYMGJiYggICGD79u18/PHH5V1+IYR4Y7z5/TyEEM8kOzubgoKC5x6rc/HiRaysrFiyZAkGBgYAODk5ceTIEU6cOMGYMWM4c+YM9+/fx8/PT+kOaGpqyv79+8nLyyM/P5+ff/5Z+aAIYGNjQ2RkpFrLQqmmTZsqY8JKu0A+3sK0bt06cnJy2Lx5M/Xq1QOgU6dOuLm5sWTJEpYuXaqU7dWrl9rYnKfp0qULlStXZvfu3YwcORKAvXv3YmRkpDHuJz09nS1bthAYGKhMyNCxY0e0tLRYuXIlnp6e1KpVC4CioiIiIyOpUaMGAMnJyaSkpLBv3z7q168PwKlTp9i+fbvaPnR0dIiNjVXOR+PGjenfvz9JSUkMHz6cyMhIKleuzNq1a5Xr4+joSNeuXVmzZg1TpkxRtuXp6UnPnj2V19999x0BAQF07doVAHt7e2rWrImurq5aHQIDA3n//feBh9dj7969HD9+HBcXlyeeRy8vLwICAgBwdnZmwIABREVFKde/opo3b84nn3yivD5z5ozSKldWnBw5coSUlBQiIiJwc3NT9p+fn8+iRYtwd3dXWkPr1q3Lv/71L2XbW7Zs4cKFC2zZsgVbW1vgYUx5eXmxaNEitVbYp9WrpKSEqKgounbtqiRlAPn5+ezcuZPCwsJnum6P+umnnzh37pwS33Xr1sXBwYGEhAR8fHwAMDAwoGnTpso5Kv3d0NBQ6Z4KD8etmZqaMn/+fCUGHRwcOH36NN999x3wsGvl+vXrGT58OEFBQcDDv/87d+7w/fff4+fnp9Tt6tWrjBw5EktLS6Kjo5U4+u677zA3N2fYsGFoa2tjb29PlSpV+P3338s8RiGEeBNJS5oQQo2Ojg4AxcXFz7V+x44d2bhxI3p6ely+fJn9+/ezfPlysrKylATL1tYWPT09Bg8eTFhYGCkpKVhaWjJp0iQMDAwwNjamadOmzJw5kylTprBjxw5KSkqYNm0azZo1e656HTt2DCsrK+rUqUNRURFFRUVoa2vTqVMnjh49qlbWysqqwtvV19fH1dVVrXvezp076dWrF1paWmpljx8/jkqlwtXVValDUVERrq6uFBQUkJqaqpRt0qSJkqABGBsbU6tWLeXDMUDNmjW5e/eu2j7atGmjNomJlZUV9evX5/vvv1fqYG9vj76+vrJ/AwMD2rVrV+55aN++PcuWLWP8+PF88cUXZGRkMGXKFNq0aaNWrl27dsrvlStXxtjYmNzc3KeexwEDBii/a2lp0a1bNyWZfxaPjlOEh8l/fn7+E8sfO3YMLS0tOnfurHFN7ty5w6VLl5Syj5+PY8eOUbt2bVq2bKmsV1xcjIuLC2fPnlVLKp5Wr/T0dDIzM+nWrZtamdGjR7Nt2zYqVar0TNftUYmJiVSvXp127dqRm5tLbm4uPXr0ID09XaMFtDxWVlZs2rSJevXq8csvv3Do0CFiYmL4+eeflb/tU6dOUVRURPfu3dXWnTFjhlq31z/++IORI0dy584dZs+ejZ6enrLMwcGB9PR0Bg4cSGRkJD/88AN9+vR5qTOXCiHE301a0oQQamrUqEHVqlW5cePGE8vk5eVRWFiolkSUKu3SFRcXR15eHmZmZtjY2Kh9CDM3N2fjxo2sWrWKrVu3sn79eqpXr46npycTJ05ES0uL2NhYli9fzt69e0lKSqJSpUp07dqV2bNnl7nf8uTk5HDlyhVatmxZ5vJHP8iX1Y3zaXr16sVHH33EzZs30dPT49ixY0ycOLHMOgD07t27zO3cunVL+b20teRRFamXsbGxxntGRkZKkpSTk8OuXbs0xlwBGpN5PL6/iIgIVqxYwTfffMOePXvQ1tbGycmJOXPmKK2TgEY3WW1t7XKft2ViYqJRZ5VKRW5uLvr6+k9d91HPuu+cnBxUKpVGolnq9u3bSnL2+PnIycnhzp07T4ypO3fuKLH6tHqVxoWRkdFT61nR61aqsLCQr776itzcXJycnDSWx8fH4+Dg8MR9luXzzz9nxYoV5OTkYGxsjLW1NZUrV1a+LCg9lvImhsnJyaFx48bk5uaycOFCtUd4uLm5UVJSwqZNm4iOjmbZsmXUq1ePf/3rX0prpxBCvOkkSRNCaOjYsSMnTpygoKBALbkqtWXLFubPn8/WrVs1PqCuWrWKtWvXMnv2bLp37061atUAlLFApR7tvpiamkpCQgIrVqzA0tKSXr16UadOHUJDQ5k1axYXLlxg9+7drF69mlq1ajFr1qxnPqZq1aphb29PcHBwmcsf77L3LDp16kTVqlXZvXs3VapUwdzcHGtra41y1atXBx52vaxatarG8rp16z53HUqV1SXszp072NnZAQ/Pg5OTk9LV7VHlzXRYrVo1goKCCAoK4ueff2b//v1ER0cze/bsMscbPYvSD/2lMjIy0NHRoWbNmn9qu+WpVq0aVapUUcZLPu6f//znU9dt2LAhixYtKnN5RbsMl8ZFVlaW2vvZ2dmcP38eOzu757puBw4cIDs7m48//ljjODZv3sy+ffvIzMx8anL4qB07dvDpp58SFBTEwIEDlURswoQJ/PDDDxrH0rhxY2XdGzdu8OuvvypdgGvWrMmaNWv46quvCA0NZd++fUo3WgB3d3fc3d25e/cuhw8fZvXq1QQFBdG2bVuZMVUI8VaQ7o5CCA2jRo0iJyeHxYsXayy7c+cOsbGxNG3atMwWhNTUVJo2bcqgQYOUBO3WrVtcvHiRkpISANauXYuLiwsPHjxAV1cXR0dHZVKAGzducPLkSZycnDhz5gxaWlpYWVkxadIkmjdv/tQWvqext7cnPT2dRo0a0apVK+Vn+/btbN26Venm+Tx0dXXp2rUre/bs4ZtvvnliS1lpN8Ds7Gy1OmRlZbFkyRK1GfeeV2pqqloXyNOnT3P9+nWlxcTe3p7Lly9jZWWl7N/a2pq1a9eyd+/eJ273+vXrajNZNm7cGF9fX5ycnJ77mjxq3759yu8qlYrk5GTatm37p5LnirC3tycvLw+VSqV2TS5evEhUVBRFRUVPXfe3337DyMhIbd0jR46wZs2aCsdU48aNqVWrlsbkKtu3b2fMmDEUFhY+13VLTEzE1NSU9957j/bt26v9eHl5UVhYqIybK6uu2trqHxFSU1OpXr06H3zwgZKg/fHHH6Smpip/2zY2NlSqVEnjWGJjYwkMDFT2U7VqVapWrcrQoUNp3bo1s2fPVuJ24sSJyvjEatWq0atXL/z9/SkqKuL27dsVOqdCCPG6k5Y0IYSG1q1bM2HCBBYvXkxaWhr9+/enVq1aXLp0iZiYGAoKCspM4ODhh7To6GhWrVpF69atuXLlCitXruTBgwdKl0IHBwcWLVpEQEAAw4cPR0dHh/j4eHR1dXFxcaFevXro6+sTHBzMuHHjMDY25ujRo/z444/KVOHPauTIkWzfvp2RI0cyatQoatWqxa5du9iyZQvTpk173lOlcHNzw8/PD21tbWbMmFFmGQsLC/r27cvMmTO5fv061tbWpKenExERgbm5OQ0bNvzT9SgpKWHMmDGMHTuW7OxswsPDad68OX379gXA398fDw8P/Pz8eP/999HT0yMhIYF9+/apTZ7yuHr16mFqasrcuXO5d+8eDRo04OzZsxw6dEhtMojntWDBAgoKCmjUqJHyEOV169b96e2Wp3Pnzrzzzjv4+/vj7+9PkyZNOHPmDEuXLsXZ2fmp3fYGDhzIxo0b8fHxYezYsZiZmXH06FFWr17N8OHDqVSpUoXqoKOjw7hx45gzZw5GRka4urqSnp7O0qVLGTZsGDVq1Hjm63b79m1SUlIYMWKExthIgLZt29KgQQMSEhLw9fVVvlA5ePAgNWrUwNLSkurVq5ORkcGhQ4ewsrLCxsaGzZs38+mnn+Li4sLt27eJiYkhIyND6dZpaGiIt7c3a9euRVdXF3t7e06fPs3mzZsJDg7WSPy0tbWZPXs2gwYNYuHChcyZMwcHBwdmzZrF/Pnz6dSpE7m5uURGRtKwYUMsLS0rdE6FEOJ1J0maEKJMH374IS1atCAuLo558+bx+++/Y2ZmRpcuXZQPpGXx8/MjOzub9evXExUVhZmZGf369VNmMMzNzcXS0pIVK1YQFRVFYGAgxcXFWFtbExsbq3SRio2NJTw8nLCwMHJzc2nYsCFz5sxh4MCBz3U8derUIT4+nvDwcEJDQykoKKBhw4aEhYVpdMV8Hk5OTlSvXh0zMzOaNGnyxHKffPIJK1euJD4+nps3b2JkZISbmxsTJ078U615pbp27UrdunUJCgqiqKgIFxcXpk+frnRbtbS0JC4ujoiICIKDg1GpVDRv3pyoqCjefffdp247MjKSzz77jCVLlpCdnY2ZmRkfffSRMlPlnxEaGsrKlSu5evUqLVq0IDY2Vm0CkhdFW1ubVatWsWTJElauXElmZiZ16tTBx8dHac15kipVqhAXF0d4eDgLFy7k7t271KtXj8mTJzNq1KhnqsewYcOoUqUKMTExJCQkYGpqiq+vL76+vsCzX7ekpCSKi4ufOoarX79+LFu2jJSUFDp27Ii7uztxcXGkpKTw9ddfM3DgQA4dOkRAQADjx4/H19eXa9eukZiYyKZNm6hTpw6dO3fG09OTmTNnkpaWRpMmTQgKCsLIyIj4+HjWrFmDubk5M2fOxMPDo8x6WFpa4u3tzeeff06fPn3w8PCgsLCQ+Ph4Nm3ahL6+Po6OjgQFBVU48RVCiNedlqq80dxCCCHEC7Jt2zamTZvG/v37n/uxD0IIIcSbRsakCSGEEEIIIcQrRJI0IYQQQgghhHiFSHdHIYQQQgghhHiFSEuaEEIIIYQQQrxCJEkTQgghhBBCiFeIJGlCCCGEEEII8QqRJE0IIYQQQgghXiGSpAkhhBBCCCHEK0SSNCGEEEIIIYR4hUiSJoQQQgghhBCvEEnShBBCCCGEEOIV8v86Hs8piLleFAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 908.5x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.figure(figsize=(15,8))\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df_subgroups, x=\"MIA\", y=\"Privacy Risk\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Privacy Risk\" )\n",
    "g.set(ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359dc0bf",
   "metadata": {},
   "source": [
    "### ROC curves and AUC scores with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5b7b52ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7fb5d538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['entire_dataset_mia_auc', 'entire_dataset_mia_privacy_risk', 'entire_dataset_mia_ppv', 'entire_dataset_mia_attacker_advantage', 'entire_dataset_mia_result', 'entire_dataset_label_0.0_mia_auc', 'entire_dataset_label_0.0_mia_privacy_risk', 'entire_dataset_label_0.0_mia_ppv', 'entire_dataset_label_0.0_mia_attacker_advantage', 'entire_dataset_label_0.0_mia_result', 'entire_dataset_label_1.0_mia_auc', 'entire_dataset_label_1.0_mia_privacy_risk', 'entire_dataset_label_1.0_mia_ppv', 'entire_dataset_label_1.0_mia_attacker_advantage', 'entire_dataset_label_1.0_mia_result', 'subpopulation_0.0_label_0.0_mia_auc', 'subpopulation_0.0_label_0.0_mia_privacy_risk', 'subpopulation_0.0_label_0.0_mia_ppv', 'subpopulation_0.0_label_0.0_mia_attacker_advantage', 'subpopulation_0.0_label_0.0_mia_result', 'subpopulation_0.0_label_1.0_mia_auc', 'subpopulation_0.0_label_1.0_mia_privacy_risk', 'subpopulation_0.0_label_1.0_mia_ppv', 'subpopulation_0.0_label_1.0_mia_attacker_advantage', 'subpopulation_0.0_label_1.0_mia_result', 'subpopulation_1.0_label_0.0_mia_auc', 'subpopulation_1.0_label_0.0_mia_privacy_risk', 'subpopulation_1.0_label_0.0_mia_ppv', 'subpopulation_1.0_label_0.0_mia_attacker_advantage', 'subpopulation_1.0_label_0.0_mia_result', 'subpopulation_1.0_label_1.0_mia_auc', 'subpopulation_1.0_label_1.0_mia_privacy_risk', 'subpopulation_1.0_label_1.0_mia_ppv', 'subpopulation_1.0_label_1.0_mia_attacker_advantage', 'subpopulation_1.0_label_1.0_mia_result'])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_mia_metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for orig dataset with different subpopulations\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for key in [\"entire_dataset_mia_result\", \n",
    "            \"subpopulation_0.0_label_0.0_mia_result\",\n",
    "            \"subpopulation_0.0_label_1.0_mia_result\", \n",
    "            \"subpopulation_1.0_label_0.0_mia_result\",\n",
    "            \"subpopulation_1.0_label_1.0_mia_result\"]:\n",
    "     # fprs = [mia_res.fpr for mia_res in orig_mia_metrics[key]]\n",
    "    # tprs = [mia_res.tpr for mia_res in orig_mia_metrics[key]]\n",
    "    tprs = []\n",
    "    \n",
    "    # aucs = [mia_res.get_auc() for mia_res in orig_mia_metrics[key]]\n",
    "    aucs = []\n",
    "\n",
    "    # mean_fpr = np.mean(fprs, axis=0)\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "    for mia_res in orig_mia_metrics[key]:\n",
    "        interp_tpr = np.interp(mean_fpr, mia_res.fpr, mia_res.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(mia_res.get_auc())\n",
    "    \n",
    "    #print(mean_fpr)\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    \n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    \n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        #color=\"b\",\n",
    "        label=r\"Mean ROC for %s $\\pm$ 1 std. dev. (AUC = %0.2f $\\pm$ %0.2f)\" % ( key ,mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        #label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve with variability\",\n",
    ")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ff10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entire dataset with different subpopulations\n",
    "# fig, ax = plt.subplots(figsize=(12, 10))\n",
    "fig, ax = plt.subplots(figsize=(24, 18))\n",
    "\n",
    "for mia_metrics, name in zip([orig_mia_metrics, transf_mia_metrics], [\"orig\", \"syn\"]): \n",
    "#                               dir_mia_metrics, reweigh_mia_metrics], [\"orig\", \"syn\", \"dir\", \"reweigh\"] ):\n",
    "    for key in [\"entire_dataset_mia_result\", \n",
    "                \"subpopulation_0.0_label_0.0_mia_result\",\n",
    "                \"subpopulation_0.0_label_1.0_mia_result\", \n",
    "                \"subpopulation_1.0_label_0.0_mia_result\",\n",
    "                \"subpopulation_1.0_label_1.0_mia_result\"]:\n",
    "   \n",
    "        # fprs = [mia_res.fpr for mia_res in orig_mia_metrics[key]]\n",
    "        # tprs = [mia_res.tpr for mia_res in orig_mia_metrics[key]]\n",
    "        tprs = []\n",
    "        # aucs = [mia_res.get_auc() for mia_res in orig_mia_metrics[key]]\n",
    "        aucs = []\n",
    "\n",
    "        # mean_fpr = np.mean(fprs, axis=0)\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "        for mia_res in mia_metrics[key]:\n",
    "            print(mia_res)\n",
    "            interp_tpr = np.interp(mean_fpr, mia_res.fpr, mia_res.tpr)\n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "            aucs.append(mia_res.get_auc())\n",
    "\n",
    "        #print(mean_fpr)\n",
    "        print(tprs)\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std(aucs)\n",
    "\n",
    "        ax.plot(\n",
    "            mean_fpr,\n",
    "            mean_tpr,\n",
    "            #color=\"b\",\n",
    "            label=r\"%s Mean ROC for %s $\\pm$ 1 std. dev. (AUC = %0.2f $\\pm$ %0.2f)\" % (name, key ,mean_auc, std_auc),\n",
    "            lw=2,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        std_tpr = np.std(tprs, axis=0)\n",
    "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        ax.fill_between(\n",
    "            mean_fpr,\n",
    "            tprs_lower,\n",
    "            tprs_upper,\n",
    "            color=\"grey\",\n",
    "            alpha=0.2,\n",
    "            #label=r\"$\\pm$ 1 std. dev.\",\n",
    "        )\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve for MIA attacks against Fairness Approaches\",\n",
    ")\n",
    "ax.legend(loc=\"lower right\")\n",
    "# ax.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entire dataset\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "for mia_res in orig_mia_metrics[\"entire_dataset_mia_result\"]:\n",
    "    plt.plot(mia_res.fpr,mia_res.tpr,label=f\"{mia_res.get_name()} auc={mia_res.get_auc()}\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e701aad9",
   "metadata": {},
   "source": [
    "## MIA Attacks AUC vs Fairness Bar Chart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f18425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "egr_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in eg_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "eg_mia_metrics_mean = {k:sum(v)/N for (k,v) in eg_mia_metrics.items() if k.endswith(\"mia_auc\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a025ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b078a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuazlization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "        transf_mia_metrics_mean,\n",
    "        dir_mia_metrics_mean,\n",
    "        reweigh_mia_metrics_mean,\n",
    "        eg_mia_metrics_mean\n",
    "        ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "        transf_mia_error_metrics,\n",
    "        dir_mia_error_metrics,\n",
    "        reweigh_mia_error_metrics,\n",
    "          egr_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn']+ ['dir']+ ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2233661a",
   "metadata": {},
   "source": [
    "###  MIA Attackers Advantage Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f09191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data structures to plot point categorical plot from seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ef741",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "egr_mia_error_metrics = {k: v for (k,v) in eg_mia_metrics.items() if k.endswith(\"attacker_advantage\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87375802",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_metrics_att_ad.keys():\n",
    "    for val in orig_mia_metrics_att_ad[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in egr_mia_error_metrics.keys():\n",
    "    for val in egr_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"egr\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "advantage_metrics_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105df8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"attacker_advantage\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac8578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting without scaling y limis to 1\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"attacker_advantage\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's Advantage\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf746e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15,8))\n",
    "\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"attacker_advantage\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's Advantage\" )\n",
    "g.set(ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b0356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(orig_mia_metrics_att_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "egr_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in eg_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "eg_mia_metrics_mean = {k:sum(v)/N for (k,v) in eg_mia_metrics.items() if k.endswith(\"attacker_advantage\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e9be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuazlization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "        transf_mia_metrics_mean,\n",
    "        dir_mia_metrics_mean,\n",
    "        reweigh_mia_metrics_mean,\n",
    "           eg_mia_metrics_mean\n",
    "        ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "        transf_mia_error_metrics,\n",
    "        dir_mia_error_metrics,\n",
    "        reweigh_mia_error_metrics,\n",
    "          egr_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn']+ ['dir']+ ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1309a4",
   "metadata": {},
   "source": [
    "## PPV Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "egr_mia_error_metrics = {k: v for (k,v) in eg_mia_metrics.items() if k.endswith(\"mia_ppv\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14018577",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_metrics_att_ad.keys():\n",
    "    for val in orig_mia_metrics_att_ad[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in egr_mia_error_metrics.keys():\n",
    "    for val in egr_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"egr\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "advantage_metrics_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95980069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"PPV\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff9b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting without scaling y limis to 1\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"PPV\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's PPV\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38297706",
   "metadata": {},
   "source": [
    "# Dataset Exploration for comparison with Shokri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c85d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame([dataset_orig.features, dataset_orig.labels]).drop_duplicates()\n",
    "\n",
    "df = pd.DataFrame(dataset_orig.features, columns=dataset_orig.feature_names)\n",
    "\n",
    "df[\"labels\"] = dataset_orig.labels\n",
    "df\n",
    "#df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d14528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"age\", \"labels\"]].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f7423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352b318b",
   "metadata": {},
   "source": [
    "## DT Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd7c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_orig_model_metrics(dataset_orig_train, dataset_orig_test, unprivileged_groups, f_label, uf_label, BASELINE, SCALER, ATTACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feceb031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_egr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ad93b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
