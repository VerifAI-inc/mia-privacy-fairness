{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending the Model class to support OpenVINO models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial we will see:\n",
    "- How to add support for querying OpenVINO models\n",
    "- How to load and query an OpenVINO model from a checkpoint file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "<td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/privacytrustlab/ml_privacy_meter/blob/master/advanced/openvino_models.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/privacytrustlab/ml_privacy_meter/blob/master/advanced/openvino_models.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow one of the [OpenVINO installation tutorials](https://docs.openvino.ai/latest/openvino_docs_install_guides_install_runtime.html) specific to your platform to install the OpenVINO library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from openvino.runtime import Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we install the Privacy Meter library from the local source. A version will be pushed to pip soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -e ../.\n",
    "from privacy_meter.model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add support for querying OpenVINO models, we shall extend the `Model` class of Privacy Meter. \n",
    "\n",
    "Additional arguments to set the device for inference and input shape accepted by the model are specified in the `OpenVinoModel` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class OpenVinoModel(Model):\n",
    "    def __init__(self, model_obj, loss_fn,\n",
    "                 input_shape=None,\n",
    "                 device_name=None):\n",
    "            \"\"\"Constructor\n",
    "            Args:\n",
    "                model_obj: model object\n",
    "                loss_fn: loss function\n",
    "            \"\"\"\n",
    "            # Initializes the parent model\n",
    "            super().__init__(model_obj, loss_fn)\n",
    "            \n",
    "            # Set initial input shape if provided\n",
    "            if input_shape is not None:\n",
    "                input_layer = next(iter(self.model_obj.inputs))\n",
    "                self.model_obj.reshape({input_layer.any_name: input_shape})\n",
    "                \n",
    "            # Set device\n",
    "            if device_name is None:\n",
    "                self.device_name = 'CPU'\n",
    "            else:\n",
    "                self.device_name = device_name\n",
    "                \n",
    "            # Create a second loss function, per point\n",
    "            self.loss_fn_no_reduction = deepcopy(loss_fn)\n",
    "            self.loss_fn_no_reduction.reduction = 'none'\n",
    "\n",
    "\n",
    "    def get_outputs(self, batch_samples):\n",
    "        \"\"\"Function to get the model output from a given input.\n",
    "        Args:\n",
    "            batch_samples: Model input\n",
    "        Returns:\n",
    "            Model output\n",
    "        \"\"\"\n",
    "        model_obj = self.model_obj\n",
    "        input_layer = next(iter(model_obj.inputs))\n",
    "        \n",
    "        # get current input shape\n",
    "        current_input_shape = input_layer.get_partial_shape()\n",
    "\n",
    "        # create new input shape with batch_size = len(batch_samples)\n",
    "        new_input_shape = current_input_shape\n",
    "        new_input_shape[0] = len(batch_samples)\n",
    "\n",
    "        # reshape network with new input shape\n",
    "        model_obj.reshape({input_layer.any_name: new_input_shape})\n",
    "        \n",
    "        # compile model before inference\n",
    "        compiled_model_obj = ie.compile_model(model=model_obj, device_name=self.device_name)\n",
    "\n",
    "        # get predictions\n",
    "        output_layer = next(iter(compiled_model_obj.outputs))\n",
    "        outputs = compiled_model_obj(inputs=[batch_samples])[output_layer]\n",
    "    \n",
    "        return outputs\n",
    "\n",
    "    def get_loss(self, batch_samples, batch_labels, per_point=True):\n",
    "        \"\"\"Function to get the model loss on a given input and an expected output.\n",
    "        Args:\n",
    "            batch_samples: Model input\n",
    "            batch_labels: Model expected output\n",
    "            per_point: Boolean indicating if loss should be returned per point or reduced\n",
    "        Returns:\n",
    "            The loss value, as defined by the loss_fn attribute.\n",
    "        \"\"\"\n",
    "        outputs = self.get_outputs(batch_samples)\n",
    "\n",
    "        if per_point:\n",
    "            return self.loss_fn_no_reduction(batch_labels, outputs).numpy()\n",
    "        else:\n",
    "            return self.loss_fn(batch_labels, outputs).numpy()\n",
    "\n",
    "\n",
    "    def get_grad(self, batch_samples, batch_labels):\n",
    "        \"\"\"Function to get the gradient of the model loss with respect to the model parameters, on a given input and an\n",
    "        expected output.\n",
    "        Args:\n",
    "            batch_samples: Model input\n",
    "            batch_labels: Model expected output\n",
    "        Returns:\n",
    "            A list of gradients of the model loss (one item per layer) with respect to the model parameters.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def get_intermediate_outputs(self, layers, batch_samples, forward_pass=True):\n",
    "        \"\"\"Function to get the intermediate output of layers (a.k.a. features), on a given input.\n",
    "        Args:\n",
    "            layers: List of integers and/or strings, indicating which layers values should be returned\n",
    "            batch_samples: Model input\n",
    "            forward_pass: Boolean indicating if a new forward pass should be executed. If True, then a forward pass is\n",
    "                executed on batch_samples. Else, the result is the one of the last forward pass.\n",
    "        Returns:\n",
    "            A list of intermediate outputs of layers.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading an OpenVINO model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and store the `.xml` and `.bin` checkpoint files of your OpenVINO model. \n",
    "\n",
    "For this tutorial, the `classification.xml` and `classification.bin` files from the [OpenVINO API Tutorial](https://github.com/openvinotoolkit/openvino_notebooks/tree/main/notebooks/002-openvino-api) have been downloaded and stored in `privacy_meter/docs/models/`.\n",
    "\n",
    "We load the OpenVINO model from the checkpoint files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Core()\n",
    "model_xml_filepath = \"./models/classification.xml\"\n",
    "model = ie.read_model(model=model_xml_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the required arguments for wrapping the model into the `OpenVinoModel` object compatible with Privacy Meter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "device_name = \"CPU\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create the `OpenVinoModel` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "openvino_model = OpenVinoModel(\n",
    "    model_obj=model,\n",
    "    loss_fn=loss_fn,\n",
    "    device_name=device_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying an OpenVINO model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code tests if the OpenVINO model can be queried successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ImageNet A from Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def resize_img(image, label):\n",
    "    resized_image = tf.image.resize(image, [224, 224])\n",
    "    channels_first_image = tf.transpose(resized_image, [2, 0, 1])\n",
    "    return channels_first_image, label\n",
    "    \n",
    "ds = tfds.load('imagenet_a', split='test', as_supervised=True)\n",
    "ds = ds.map(resize_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 500\n",
    "\n",
    "x, y, ctr = [], [], 0\n",
    "for (image, label) in tfds.as_numpy(ds):\n",
    "    x.append(image)\n",
    "    y.append(label)\n",
    "    ctr = ctr + 1\n",
    "    \n",
    "    if ctr == num_samples:\n",
    "        break\n",
    "    \n",
    "x = np.array(x)\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=1001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Outputs and Loss Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = openvino_model.get_outputs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1001)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = openvino_model.get_loss(x, y, per_point=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_values.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privacy_meter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:39:03) \n[GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff5ee332438c92f929e001ac582f4dc65f589c5b69932de359bcb69410618153"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
