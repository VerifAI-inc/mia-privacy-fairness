{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8c9f6b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "151964f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f57d13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 16:07:54.619774: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743077274.636702   92164 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743077274.640910   92164 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743077274.655267   92164 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743077274.655294   92164 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743077274.655296   92164 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743077274.655298   92164 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-27 16:07:54.660972: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/temporaryuser2/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  vect_normalized_discounted_cumulative_gain = vmap(\n",
      "/home/temporaryuser2/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n",
      "/home/temporaryuser2/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from data_utils import DatasetBuilder\n",
    "from metrics_utils import compute_metrics, describe_metrics, get_test_metrics, test\n",
    "from plot_utils import plot\n",
    "from mitigators import NullMitigator, SyntheticMitigator, DIRMitigator, ReweighMitigator, EGMitigator, PRMitigator, CPPMitigator, ROMitigator \n",
    "from test_algorithms import TestAlgorithms\n",
    "from plot_utils import plot_algo_lr, plot_algo\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from oversample import label_bias, selection_bias \n",
    "from sklearn import preprocessing\n",
    "from privacy_meter.dataset import Dataset\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180b2a8",
   "metadata": {},
   "source": [
    "## Arguments & Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "564c7837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-a', '--attack'], dest='attack', nargs=None, const=None, default='mia1', type=None, choices=['mia1', 'mia2'], required=False, help='attacks: our implementation, their implementation', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct argument parser\n",
    "import argparse\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--data\", choices=['adult', 'compas', 'german', 'bank', 'meps19', 'grade', 'law_sex', 'law_race', 'law_aif_gender', 'law_aif_race'], default='compas', help=\"dataset: adult, compas, german, bank, meps19, grade\")\n",
    "ap.add_argument(\"-c\", \"--classifier\", choices=['lr', 'rf', 'svm', 'nn', 'nb'], default='lr', help=\"baseline model: lr, rf, svm, nn, nb, dt\")\n",
    "ap.add_argument(\"-m\", \"--mitigator\", choices=['dir', 'rew', 'egr', 'pr', 'cpp', 'ro'], required=False, help=\"mitigators: dir, rew, egr, pr, cpp, ro\")\n",
    "ap.add_argument(\"-b\", \"--bias\", default=0., help=\"amount of bias: o-1\")\n",
    "ap.add_argument(\"-t\", \"--biastype\", choices=['label', 'selection', 'none'], default='none', help=\"amount of bias: o-1\")\n",
    "ap.add_argument(\"-o\", \"--os\", default=2, help=\"oversample mode: 1: privi unfav 2: unpriv fav\")\n",
    "ap.add_argument(\"-a\", \"--attack\", choices=['mia1', 'mia2'], default='mia1', help=\"attacks: our implementation, their implementation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4f8856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['']\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19b063bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 'compas',\n",
       " 'classifier': 'lr',\n",
       " 'mitigator': None,\n",
       " 'bias': 0.0,\n",
       " 'biastype': 'none',\n",
       " 'os': 2,\n",
       " 'attack': 'mia1'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0dd1c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"bank\"\n",
    "BASELINE = \"dprf\" \n",
    "MITIGATOR = args[\"mitigator\"]\n",
    "BIAS = float(args[\"bias\"])\n",
    "BIAS_TYPE = args[\"biastype\"]\n",
    "OS_MODE = 2\n",
    "ATTACK = \"mia2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b16266c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# global constants\n",
    "if BASELINE == 'svm' or BASELINE == 'nn':\n",
    "    SCALER = False \n",
    "else:\n",
    "    SCALER = False \n",
    "DISPLAY = False \n",
    "THRESH_ARR = 0.5\n",
    "\n",
    "# loop ten times \n",
    "N = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49502a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of favor and unfavor\n",
    "priv_metric_orig = defaultdict(float)\n",
    "favor_metric_orig = defaultdict(float)\n",
    "favor_metric_transf = defaultdict(float)\n",
    "\n",
    "# for each pre-processing approach, we create a mia_metric_results\n",
    "orig_metrics = defaultdict(list)\n",
    "orig_mia_metrics = defaultdict(list)\n",
    "\n",
    "transf_metrics = defaultdict(list) \n",
    "transf_mia_metrics = defaultdict(list) \n",
    "\n",
    "reweigh_metrics = defaultdict(list) \n",
    "reweigh_mia_metrics = defaultdict(list) \n",
    "\n",
    "dir_metrics = defaultdict(list) \n",
    "dir_mia_metrics = defaultdict(list) \n",
    "\n",
    "eg_metrics = defaultdict(list) \n",
    "eg_mia_metrics = defaultdict(list) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a48a7",
   "metadata": {},
   "source": [
    "## Loading & Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52a31333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bank'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da867c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside load_data(), self.DATASET = bank\n",
      "INSIDE BANK\n",
      "GETTINT OUTSIDE BANK\n"
     ]
    }
   ],
   "source": [
    "# load dataset and set the groups\n",
    "dataset_builder =  DatasetBuilder(DATASET)\n",
    "dataset_orig = dataset_builder.load_data()\n",
    "sens_attr = dataset_orig.protected_attribute_names[0]\n",
    "unprivileged_groups = dataset_builder.unprivileged_groups\n",
    "privileged_groups = dataset_builder.privileged_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aabd2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30448, 57)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb84777c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'age': 1}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "privileged_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a78a2150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'age'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fedd14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# favorable and unfavorable labels and feature_names\n",
    "f_label = dataset_orig.favorable_label\n",
    "uf_label = dataset_orig.unfavorable_label\n",
    "feature_names = dataset_orig.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fb1ad08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if ATTACK == \"mia1\":\n",
    "    # training data split ratio\n",
    "    p = 0.5\n",
    "    # split dataset into train, validation, and test\n",
    "    dataset_orig_train, dataset_orig_test = dataset_orig.split([p], shuffle=True)\n",
    "    dataset_orig_val = dataset_orig_test\n",
    "    print(dataset_orig_train.features)\n",
    "\n",
    "    # introduce label or selection biases, assuming the original data is fair\n",
    "    if BIAS_TYPE == 'label':\n",
    "        dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    elif BIAS_TYPE == 'selection':\n",
    "        dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    else:\n",
    "        print('no bias type specified')\n",
    "        \n",
    "    dataset_orig_train\n",
    "    dataset_orig_train?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cfd5f8",
   "metadata": {},
   "source": [
    "## Run Mitigating Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3ae7f8",
   "metadata": {},
   "source": [
    "### Setup for MIA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad51a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14350dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ATTACK == \"mia2\":\n",
    "    # prepare data format\n",
    "    X = dataset_orig.features\n",
    "    y_true = dataset_orig.labels.ravel()\n",
    "    sens_attr = dataset_orig.protected_attribute_names[0]\n",
    "    sens_attr_index = dataset_orig.feature_names.index(sens_attr)\n",
    "    sensitive_features = dataset_orig.features[:, sens_attr_index]\n",
    "\n",
    "    X_other_features = np.delete(X, sens_attr_index, axis=1)\n",
    "    X_other_features_normalized = preprocessing.normalize(X_other_features, norm='l2')\n",
    "\n",
    "    # Reconstruct X by combining the sensitive attribute and the normalized features\n",
    "    # Insert the sensitive attribute back into its original position\n",
    "    X_normalized = np.insert(X_other_features_normalized, sens_attr_index, sensitive_features, axis=1)\n",
    "    X = X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89c1ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_indices_reference():\n",
    "    # Determine split sizes proportionally (to sum up to the full dataset size)\n",
    "    num_train_points = int(X.shape[0] * 0.12)\n",
    "    num_test_points = int(X.shape[0] * 0.12)\n",
    "    num_population_points = int(X.shape[0] * 0.3)  # Reduced from 30000\n",
    "\n",
    "    # Start with all indices\n",
    "    all_indices = np.arange(X.shape[0])\n",
    "\n",
    "    # Select train indices without replacement\n",
    "    train_index = np.random.choice(all_indices, num_train_points, replace=False)\n",
    "    # Remove train indices from available indices\n",
    "    remaining_indices = np.setdiff1d(all_indices, train_index)\n",
    "\n",
    "    # Select test indices from the remaining indices without replacement\n",
    "    test_index = np.random.choice(remaining_indices, num_test_points, replace=False)\n",
    "    # Remove test indices from available indices\n",
    "    remaining_indices = np.setdiff1d(remaining_indices, test_index)\n",
    "\n",
    "    # Select population indices from the remaining indices (can also choose all remaining points)\n",
    "    population_index = np.random.choice(remaining_indices, min(num_population_points, len(remaining_indices)), replace=False)\n",
    "    \n",
    "    # Summary of counts\n",
    "    print(\"==============================================================\")\n",
    "    print(\"GET UNIQUE INDICES REFERENCE\")\n",
    "    print(f\"Number of train points: {len(train_index)}\")\n",
    "    print(f\"Number of test points: {len(test_index)}\")\n",
    "    print(f\"Number of population points: {len(population_index)}\")\n",
    "    print(\"==============================================================\")\n",
    "    \n",
    "    return train_index, test_index, population_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "414d335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(train_index, test_index, population_index, g_train, g_test, g_pop_train):\n",
    "    # create the target model's dataset\n",
    "    train_ds = {'x': X[train_index], 'y': y_true[train_index],'g':g_train}\n",
    "    test_ds = {'x': X[test_index], 'y': y_true[test_index], 'g':g_test}\n",
    "    target_dataset = Dataset(\n",
    "        data_dict={'train': train_ds, 'test': test_ds},\n",
    "        default_input='x', default_output='y', default_group='g'\n",
    "    )\n",
    "\n",
    "    # create the reference dataset\n",
    "    population_ds = {'x': X[population_index], 'y': y_true[population_index], 'g': g_pop_train}\n",
    "    reference_dataset = Dataset(\n",
    "        data_dict={'train': population_ds},\n",
    "        default_input='x', default_output='y', default_group='g'\n",
    "    )\n",
    "    \n",
    "    return target_dataset, reference_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e23be8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features, labels, and protected attributes into a DataFrame\n",
    "def create_binary_label_dataset(dataset_orig, X, y, sensitive_features, sens_attr_name, privileged_value, unprivileged_value):\n",
    "    print(\"=====================================================\")\n",
    "    print(\"CREATE BINARY LABEL DATASET\")\n",
    "    # Extract the feature names from the original dataset\n",
    "    feature_names = dataset_orig.feature_names\n",
    "\n",
    "    # Create a DataFrame with features, labels, and sensitive attribute\n",
    "    df = pd.DataFrame(X, columns=feature_names)\n",
    "    df[dataset_orig.label_names[0]] = y\n",
    "#     print(df.head())\n",
    "    # print(dataset_orig.feature_names)\n",
    "    # print(dataset_orig.features.shape)\n",
    "    \n",
    "    # df_orig, _ = dataset_orig.convert_to_dataframe()\n",
    "\n",
    "    # # Display the first few rows\n",
    "    # print(\"Original df's head:\", df_orig.head())\n",
    "    \n",
    "    # Get the unique labels and their counts\n",
    "    # unique_labels, counts = np.unique(dataset_orig.labels, return_counts=True)\n",
    "\n",
    "    # # Print the value counts\n",
    "    # for label, count in zip(unique_labels, counts):\n",
    "    #     print(f\"Label {label}: {count} instances\")\n",
    "\n",
    "    # Create the BinaryLabelDataset\n",
    "    dataset = BinaryLabelDataset(\n",
    "        favorable_label=1.0,  # Adjust as per your dataset\n",
    "        unfavorable_label=0.0,  # Adjust as per your dataset\n",
    "        df=df,  # DataFrame containing features, labels, and protected attribute\n",
    "        label_names=dataset_orig.label_names,  # Column name of labels in DataFrame\n",
    "        protected_attribute_names=[sens_attr_name],  # Protected attribute column\n",
    "        privileged_protected_attributes=[privileged_value],  # Privileged group values\n",
    "        unprivileged_protected_attributes=[unprivileged_value]  # Unprivileged group values\n",
    "    )\n",
    "    \n",
    "    # print(dataset.feature_names)\n",
    "    # print(dataset.features.shape)\n",
    "    # # Get the unique labels and their counts\n",
    "    # unique_labels, counts = np.unique(dataset.labels, return_counts=True)\n",
    "\n",
    "    # Print the value counts\n",
    "    # for label, count in zip(unique_labels, counts):\n",
    "    #     print(f\"Label {label}: {count} instances\")\n",
    "    \n",
    "    print(\"=====================================================\")\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22a3f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_logs():\n",
    "    # Search for directories ending with _group or _pop\n",
    "    for pattern in [\"*_group\", \"*_pop\"]:\n",
    "        # Find matching directories\n",
    "        for log_dir in glob.glob(pattern):\n",
    "            if os.path.exists(log_dir) and os.path.isdir(log_dir):  # Ensure it's a directory\n",
    "                shutil.rmtree(log_dir)\n",
    "                print(f\"{log_dir} deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31097df4",
   "metadata": {},
   "source": [
    "### Calling Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69a3e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = dataset_orig.convert_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b3d0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_dataset = None\n",
    "# reference_dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cc3b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e67badb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets():\n",
    "    target_dataset = None\n",
    "    reference_dataset = None\n",
    "    \n",
    "    if ATTACK == \"mia1\":\n",
    "        # split dataset into train, validation, and test\n",
    "        dataset_orig_train, dataset_orig_test = dataset_orig.split([p], shuffle=True)\n",
    "        dataset_orig_val = dataset_orig_test\n",
    "\n",
    "    elif ATTACK == \"mia2\":\n",
    "        train_index, test_index, population_index = get_unique_indices_reference()\n",
    "\n",
    "        g_train = y_true[train_index] + (sensitive_features[train_index] + 1) * 2 # 2, 4, 3, 5\n",
    "        g_test = y_true[test_index] + (sensitive_features[test_index] + 1) * 2\n",
    "        g_pop_train = y_true[population_index] + (sensitive_features[population_index] + 1) * 2\n",
    "\n",
    "        # for Audit\n",
    "        target_dataset, reference_dataset = create_datasets(train_index, test_index, population_index, g_train, g_test, g_pop_train)\n",
    "\n",
    "        # for mitigators\n",
    "        privileged_value = [1]\n",
    "        unprivileged_value = [0]\n",
    "        # Convert train dataset\n",
    "        dataset_orig_train = create_binary_label_dataset(\n",
    "            dataset_orig=dataset_orig,\n",
    "            X=X[train_index],\n",
    "            y=y_true[train_index],\n",
    "            sensitive_features=sensitive_features[train_index],\n",
    "            sens_attr_name=sens_attr,\n",
    "            privileged_value=privileged_value,\n",
    "            unprivileged_value=unprivileged_value\n",
    "        )\n",
    "        \n",
    "#         dataset_orig_val = create_binary_label_dataset(\n",
    "#             dataset_orig=dataset_orig,\n",
    "#             X=X[valid_index],\n",
    "#             y=y_true[valid_index],\n",
    "#             sensitive_features=sensitive_features[valid_index],\n",
    "#             sens_attr_name=sens_attr,\n",
    "#             privileged_value=privileged_value,\n",
    "#             unprivileged_value=unprivileged_value\n",
    "#         )\n",
    "\n",
    "        # Convert test dataset\n",
    "        dataset_orig_test = create_binary_label_dataset(\n",
    "            dataset_orig=dataset_orig,\n",
    "            X=X[test_index],\n",
    "            y=y_true[test_index],\n",
    "            sensitive_features=sensitive_features[test_index],\n",
    "            sens_attr_name=sens_attr,\n",
    "            privileged_value=privileged_value,\n",
    "            unprivileged_value=unprivileged_value\n",
    "        )\n",
    "        \n",
    "        dataset_orig_val = dataset_orig_test\n",
    "        \n",
    "    return dataset_orig_train, dataset_orig_val, dataset_orig_test, target_dataset, reference_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eea401f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION  0\n",
      "==============================================================\n",
      "GET UNIQUE INDICES REFERENCE\n",
      "Number of train points: 3653\n",
      "Number of test points: 3653\n",
      "Number of population points: 9134\n",
      "==============================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "privileged vs. unprivileged:  3446.0 207.0\n",
      "base_pos unpriv:  0.34299516908212563\n",
      "base_pos priv:  0.12100986651189785\n",
      "DIFFERENCE IS GOOD\n",
      "base_pos unpriv:  0.34299516908212563\n",
      "base_pos priv:  0.12100986651189785\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(3653, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[[1]] [[0]]\n",
      "#### Dataset feature names\n",
      "['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'job=admin.', 'job=blue-collar', 'job=entrepreneur', 'job=housemaid', 'job=management', 'job=retired', 'job=self-employed', 'job=services', 'job=student', 'job=technician', 'job=unemployed', 'marital=divorced', 'marital=married', 'marital=single', 'education=basic.4y', 'education=basic.6y', 'education=basic.9y', 'education=high.school', 'education=illiterate', 'education=professional.course', 'education=university.degree', 'default=no', 'default=yes', 'housing=no', 'housing=yes', 'loan=no', 'loan=yes', 'contact=cellular', 'contact=telephone', 'month=apr', 'month=aug', 'month=dec', 'month=jul', 'month=jun', 'month=mar', 'month=may', 'month=nov', 'month=oct', 'month=sep', 'day_of_week=fri', 'day_of_week=mon', 'day_of_week=thu', 'day_of_week=tue', 'day_of_week=wed', 'poutcome=failure', 'poutcome=nonexistent', 'poutcome=success']\n",
      "number of favorable labels:  488\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.221985\n",
      "#### Train shape, validation shape, test shape\n",
      "(3653, 57) (3653, 57) (3653, 57)\n",
      "#######################################################################\n",
      "                    dprf\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training differentially private random forest\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 73\u001b[0m\n\u001b[1;32m     70\u001b[0m test_cases \u001b[38;5;241m=\u001b[39m TestAlgorithms(BASELINE)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# null mitigator\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m orig_metrics, orig_mia_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtest_cases\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_original\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_orig_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_orig_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_orig_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBASELINE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_mia_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munprivileged_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivileged_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mATTACK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTHRESH_ARR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDISPLAY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCALER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_dataset\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# synthetic data mitigator\u001b[39;00m\n\u001b[1;32m     76\u001b[0m metric_transf_train, transf_metrics, transf_mia_metrics \u001b[38;5;241m=\u001b[39m test_cases\u001b[38;5;241m.\u001b[39mrun_oversample(dataset_orig_train, dataset_orig_val, dataset_orig_test, privileged_groups, unprivileged_groups, base_rate_privileged, base_rate_unprivileged, BASELINE, transf_metrics, transf_mia_metrics, f_label, uf_label, ATTACK, THRESH_ARR, DISPLAY, OS_MODE, SCALER, target_dataset, reference_dataset)\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/test_algorithms.py:18\u001b[0m, in \u001b[0;36mTestAlgorithms.run_original\u001b[0;34m(self, dataset_orig_train, dataset_orig_val, dataset_orig_test, model_type, orig_metrics, orig_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m------------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m null_mitigator \u001b[38;5;241m=\u001b[39m NullMitigator()\n\u001b[0;32m---> 18\u001b[0m orig_metrics, orig_mia_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mnull_mitigator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_mitigator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_orig_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_orig_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_orig_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_mia_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munprivileged_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivileged_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mATTACK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTHRESH_ARR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDISPLAY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCALER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# null_mitigator.run_explainer(dataset_orig_train, dataset_orig_test, model_type, SCALER)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m orig_metrics, orig_mia_metrics\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/mitigators.py:65\u001b[0m, in \u001b[0;36mNullMitigator.run_mitigator\u001b[0;34m(self, dataset_orig_train, dataset_orig_val, dataset_orig_test, model_type, orig_metrics, orig_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_mitigator\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_orig_train, dataset_orig_val, dataset_orig_test, \n\u001b[1;32m     61\u001b[0m                   model_type, orig_metrics, orig_mia_metrics, f_label, uf_label, \n\u001b[1;32m     62\u001b[0m                   unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, \n\u001b[1;32m     63\u001b[0m                   DISPLAY, SCALER, target_dataset, reference_dataset):\n\u001b[1;32m     64\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset_orig_train\n\u001b[0;32m---> 65\u001b[0m     metrics, mia_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mget_test_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_orig_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_orig_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_mia_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mATTACK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mun_log\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muf_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munprivileged_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivileged_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTHRESH_ARR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDISPLAY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCALER\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# if ATTACK == \"mia1\":\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m#             elif ATTACK == \"mia2\":\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m#     metrics, mia_metrics = get_test_metrics_for_mia2(dataset_orig, target_dataset, reference_dataset, \"un_log\", f_label, uf_label, unprivileged_groups, privileged_groups, THRESH_ARR)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# For exp\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# explainer = Explainer()\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# explainer.tree_explain(dataset, dataset_orig_test, unprivileged_groups, 'orig')\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metrics, mia_metrics\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/metrics_utils.py:667\u001b[0m, in \u001b[0;36mget_test_metrics\u001b[0;34m(target_dataset, reference_dataset, dataset_orig_train, dataset_orig_val, dataset_orig_test, model_type, test_metrics, mia_metrics, ATTACK, log_type, f_label, uf_label, unprivileged_groups, privileged_groups, THRESH_ARR, DISPLAY, SCALER)\u001b[0m\n\u001b[1;32m    665\u001b[0m     mod_orig \u001b[38;5;241m=\u001b[39m test_model\u001b[38;5;241m.\u001b[39mset_model(dataset, \u001b[38;5;28;01mNone\u001b[39;00m, ATTACK)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     mod_orig \u001b[38;5;241m=\u001b[39m \u001b[43mtest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCALER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mATTACK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ATTACK \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmia1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    670\u001b[0m     thresh_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.01\u001b[39m, THRESH_ARR, \u001b[38;5;241m50\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/models.py:396\u001b[0m, in \u001b[0;36mTModel.set_model\u001b[0;34m(self, dataset, SCALER, ATTACK)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    395\u001b[0m     model \u001b[38;5;241m=\u001b[39m MLP()\n\u001b[0;32m--> 396\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCALER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mATTACK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trained_model\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/models.py:159\u001b[0m, in \u001b[0;36mDPRF.train\u001b[0;34m(self, dataset_train, SCALER, ATTACK)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ATTACK \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmia2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    158\u001b[0m     model \u001b[38;5;241m=\u001b[39m dp\u001b[38;5;241m.\u001b[39mRandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, bounds\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m), max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m29\u001b[39m)\n\u001b[0;32m--> 159\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/diffprivlib/models/forest.py:263\u001b[0m, in \u001b[0;36mRandomForestClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Todo: Remove when scikit-learn v1.1 is a min requirement\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 263\u001b[0m     trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtree_idxs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtree_idxs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtree_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trees\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     trees \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\n\u001b[1;32m    278\u001b[0m         delayed(_parallel_build_trees)(\n\u001b[1;32m    279\u001b[0m             tree\u001b[38;5;241m=\u001b[39mt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    289\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:197\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    190\u001b[0m         X,\n\u001b[1;32m    191\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    195\u001b[0m     )\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/diffprivlib/models/forest.py:455\u001b[0m, in \u001b[0;36mDecisionTreeClassifier._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/diffprivlib/models/forest.py:441\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# Build and fit the _FittingTree\u001b[39;00m\n\u001b[1;32m    439\u001b[0m fitting_tree \u001b[38;5;241m=\u001b[39m _FittingTree(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbounds,\n\u001b[1;32m    440\u001b[0m                             random_state)\n\u001b[0;32m--> 441\u001b[0m \u001b[43mfitting_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m fitting_tree\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# Load params from _FittingTree into sklearn.Tree\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/diffprivlib/models/forest.py:526\u001b[0m, in \u001b[0;36m_FittingTree.build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m parent, is_left, depth, bounds \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m    525\u001b[0m node_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_count\n\u001b[0;32m--> 526\u001b[0m bounds_lower, bounds_upper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_bounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;66;03m# Update parent node with its child\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parent \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_TREE_UNDEFINED:\n",
      "File \u001b[0;32m~/Desktop/sdp2/mia-privacy-fairness/venv/lib/python3.9/site-packages/diffprivlib/validation.py:114\u001b[0m, in \u001b[0;36mcheck_bounds\u001b[0;34m(bounds, shape, min_separation, dtype)\u001b[0m\n\u001b[1;32m    111\u001b[0m _lower \u001b[38;5;241m=\u001b[39m lower[i]\n\u001b[1;32m    112\u001b[0m _upper \u001b[38;5;241m=\u001b[39m upper[i]\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_lower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mReal\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_upper, Real):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEach bound must be numeric, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_lower\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(_lower)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_upper\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(_upper)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _lower \u001b[38;5;241m>\u001b[39m _upper:\n",
      "File \u001b[0;32m/usr/lib/python3.9/abc.py:117\u001b[0m, in \u001b[0;36mABCMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Register a virtual subclass of an ABC.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    Returns the subclass, to allow usage as a class decorator.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _abc_register(\u001b[38;5;28mcls\u001b[39m, subclass)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__instancecheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, instance):\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _abc_instancecheck(\u001b[38;5;28mcls\u001b[39m, instance)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.011384  0.012342  0.259191       0.0      0.259191   \n",
      "1     1.0  0.001711  0.000000  0.290241       0.0      0.102794   \n",
      "2     0.0  0.006218  0.018829  0.263604       0.0      0.247129   \n",
      "3     1.0  0.001498  0.021053  0.294748       0.0      0.098249   \n",
      "4     1.0  0.009078  0.006180  0.259572       0.0      0.259572   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.008577  0.012554  0.263626       0.0      0.247149   \n",
      "3649  1.0  0.008212  0.007019  0.294796       0.0      0.098265   \n",
      "3650  1.0  0.008803  0.000000  0.262370       0.0      0.262370   \n",
      "3651  1.0  0.002290  0.000000  0.261922       0.0      0.261922   \n",
      "3652  1.0  0.041376  0.000000  0.294058       0.0      0.098019   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.228686       0.097603   0.254079     0.259191  ...        0.0   \n",
      "1           0.209706       0.133584   0.005198     0.030725  ...        0.0   \n",
      "2           0.184194       0.158824   0.252310     0.226630  ...        0.0   \n",
      "3           0.079488       0.056730   0.043901     0.150995  ...        0.0   \n",
      "4           0.229023       0.097747   0.248921     0.259572  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.184209       0.158837   0.252330     0.226648  ...        0.0   \n",
      "3649        0.079501       0.056739   0.043909     0.151020  ...        0.0   \n",
      "3650        0.175561       0.088920   0.257492     0.262370  ...        0.0   \n",
      "3651        0.126878       0.161098   0.257112     0.261922  ...        0.0   \n",
      "3652        0.100159       0.045524   0.052065     0.150642  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0                 0.0         0.259191          0.00000         0.000000   \n",
      "1                 0.0         0.000000          0.00000         0.290241   \n",
      "2                 0.0         0.000000          0.00000         0.263604   \n",
      "3                 0.0         0.000000          0.00000         0.294748   \n",
      "4                 0.0         0.000000          0.00000         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "3648              0.0         0.000000          0.00000         0.263626   \n",
      "3649              0.0         0.000000          0.00000         0.294796   \n",
      "3650              0.0         0.000000          0.26237         0.000000   \n",
      "3651              0.0         0.000000          0.00000         0.000000   \n",
      "3652              0.0         0.000000          0.00000         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000               0.0              0.259191   \n",
      "1            0.000000               0.0              0.290241   \n",
      "2            0.000000               0.0              0.263604   \n",
      "3            0.000000               0.0              0.294748   \n",
      "4            0.259572               0.0              0.259572   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.000000               0.0              0.263626   \n",
      "3649         0.000000               0.0              0.294796   \n",
      "3650         0.000000               0.0              0.262370   \n",
      "3651         0.261922               0.0              0.261922   \n",
      "3652         0.294058               0.0              0.294058   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  0.0  \n",
      "2                  0.0  0.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  0.0  \n",
      "...                ...  ...  \n",
      "3648               0.0  0.0  \n",
      "3649               0.0  0.0  \n",
      "3650               0.0  0.0  \n",
      "3651               0.0  0.0  \n",
      "3652               0.0  0.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n",
      "=====================================================================================\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.003689  0.055540  0.259186  0.000000      0.259186   \n",
      "1     1.0  0.020915  0.013875  0.291382  0.000000      0.097127   \n",
      "2     1.0  0.004793  0.006236  0.261914  0.000000      0.261914   \n",
      "3     1.0  0.047698  0.018806  0.263278  0.000000      0.246823   \n",
      "4     1.0  0.093993  0.000000  0.292754  0.041822      0.097585   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "9129  1.0  0.077691  0.018680  0.261521  0.000000      0.261521   \n",
      "9130  1.0  0.004975  0.000000  0.294778  0.000000      0.098259   \n",
      "9131  1.0  0.016270  0.006246  0.262340  0.000000      0.262340   \n",
      "9132  1.0  0.021249  0.028035  0.294370  0.042053      0.098123   \n",
      "9133  1.0  0.010666  0.012553  0.263605  0.000000      0.247129   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.228681       0.097601   0.248550     0.259186  ...        0.0   \n",
      "1           0.190205       0.131671   0.003567     0.049684  ...        0.0   \n",
      "2           0.126874       0.161094   0.257105     0.261914  ...        0.0   \n",
      "3           0.183966       0.158628   0.252474     0.226349  ...        0.0   \n",
      "4           0.099714       0.045322   0.051502     0.149974  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "9129        0.174993       0.088633   0.256956     0.261521  ...        0.0   \n",
      "9130        0.079496       0.056735   0.046312     0.151011  ...        0.0   \n",
      "9131        0.175541       0.088910   0.257463     0.262340  ...        0.0   \n",
      "9132        0.079386       0.056657   0.043845     0.150802  ...        0.0   \n",
      "9133        0.184194       0.158824   0.252549     0.226630  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.000000              0.0         0.000000         0.259186   \n",
      "1            0.000000              0.0         0.000000         0.291382   \n",
      "2            0.000000              0.0         0.261914         0.000000   \n",
      "3            0.263278              0.0         0.000000         0.000000   \n",
      "4            0.000000              0.0         0.292754         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "9129         0.000000              0.0         0.261521         0.000000   \n",
      "9130         0.000000              0.0         0.294778         0.000000   \n",
      "9131         0.000000              0.0         0.000000         0.000000   \n",
      "9132         0.000000              0.0         0.000000         0.294370   \n",
      "9133         0.000000              0.0         0.263605         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0             0.00000          0.000000              0.259186   \n",
      "1             0.00000          0.000000              0.291382   \n",
      "2             0.00000          0.000000              0.261914   \n",
      "3             0.00000          0.000000              0.263278   \n",
      "4             0.00000          0.292754              0.000000   \n",
      "...               ...               ...                   ...   \n",
      "9129          0.00000          0.000000              0.261521   \n",
      "9130          0.00000          0.000000              0.294778   \n",
      "9131          0.26234          0.000000              0.262340   \n",
      "9132          0.00000          0.294370              0.000000   \n",
      "9133          0.00000          0.000000              0.263605   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  1.0  \n",
      "2                  0.0  0.0  \n",
      "3                  0.0  1.0  \n",
      "4                  0.0  1.0  \n",
      "...                ...  ...  \n",
      "9129               0.0  1.0  \n",
      "9130               0.0  0.0  \n",
      "9131               0.0  0.0  \n",
      "9132               0.0  0.0  \n",
      "9133               0.0  0.0  \n",
      "\n",
      "[9134 rows x 58 columns]\n",
      "=====================================================================================\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['dir_log_group']\n",
      "Results are stored in: ['dir_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  [0.08830384]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: [0.06468954]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 136, Test = 159\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.29\n",
      "  Test Accuracy (TNR): 0.81\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.06515038]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 71, Test = 78\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [1.15799184]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3029, Test = 3005\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: [0.0542806]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 417, Test = 411\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.90259281]\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['rew_log_group']\n",
      "Results are stored in: ['rew_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.07443034]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: [0.28721523]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 136, Test = 159\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.07\n",
      "  Test Accuracy (TNR): 0.97\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: [0.26557345]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 71, Test = 78\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.06\n",
      "  Test Accuracy (TNR): 0.99\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.80\n",
      "  Optimal thershold: [1.12578563]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3029, Test = 3005\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.50\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: [0.04322842]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 417, Test = 411\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [1.29265713]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['eg_log_group']\n",
      "Results are stored in: ['eg_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: [0.14394083]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 136, Test = 159\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.31\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: [0.09911678]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 71, Test = 78\n",
      "  AUC: 0.87\n",
      "  Privacy Risk: 0.84\n",
      "  Accuracy: 0.84\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.69\n",
      "  Positive predictive value: 0.88\n",
      "  Optimal thershold: [0.21431285]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3029, Test = 3005\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: [0.02045748]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 417, Test = 411\n",
      "  AUC: 0.89\n",
      "  Privacy Risk: 0.83\n",
      "  Accuracy: 0.83\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.67\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.21541658]\n",
      ")\n",
      "dir_log_group deleted.\n",
      "eg_log_group deleted.\n",
      "rew_log_group deleted.\n",
      "syn_log_group deleted.\n",
      "un_log_group deleted.\n",
      "dir_log_pop deleted.\n",
      "eg_log_pop deleted.\n",
      "rew_log_pop deleted.\n",
      "syn_log_pop deleted.\n",
      "un_log_pop deleted.\n",
      "ITERATION  1\n",
      "==============================================================\n",
      "GET UNIQUE INDICES REFERENCE\n",
      "Number of train points: 3653\n",
      "Number of test points: 3653\n",
      "Number of population points: 9134\n",
      "==============================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "privileged vs. unprivileged:  3438.0 215.0\n",
      "base_pos unpriv:  0.3302325581395349\n",
      "base_pos priv:  0.10616637579988365\n",
      "DIFFERENCE IS GOOD\n",
      "base_pos unpriv:  0.3302325581395349\n",
      "base_pos priv:  0.10616637579988365\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(3653, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[[1]] [[0]]\n",
      "#### Dataset feature names\n",
      "['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'job=admin.', 'job=blue-collar', 'job=entrepreneur', 'job=housemaid', 'job=management', 'job=retired', 'job=self-employed', 'job=services', 'job=student', 'job=technician', 'job=unemployed', 'marital=divorced', 'marital=married', 'marital=single', 'education=basic.4y', 'education=basic.6y', 'education=basic.9y', 'education=high.school', 'education=illiterate', 'education=professional.course', 'education=university.degree', 'default=no', 'default=yes', 'housing=no', 'housing=yes', 'loan=no', 'loan=yes', 'contact=cellular', 'contact=telephone', 'month=apr', 'month=aug', 'month=dec', 'month=jul', 'month=jun', 'month=mar', 'month=may', 'month=nov', 'month=oct', 'month=sep', 'day_of_week=fri', 'day_of_week=mon', 'day_of_week=thu', 'day_of_week=tue', 'day_of_week=wed', 'poutcome=failure', 'poutcome=nonexistent', 'poutcome=success']\n",
      "number of favorable labels:  436\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.224066\n",
      "#### Train shape, validation shape, test shape\n",
      "(3653, 57) (3653, 57) (3653, 57)\n",
      "#######################################################################\n",
      "                    rf\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['un_log_group']\n",
      "Results are stored in: ['un_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.05971256]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: [0.68086777]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 144, Test = 133\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.4784051]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 71, Test = 66\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.24\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.98228238]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3073, Test = 3064\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.50\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: [0.25830269]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 365, Test = 390\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.46\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.90585568]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  3653 6876\n",
      "after transf priv:  0.10616637579988365\n",
      "after transf unpriv:  0.10616637579988365\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['syn_log_group']\n",
      "Results are stored in: ['syn_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.11992883]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: [0.73408963]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 144, Test = 133\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.18372353]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 71, Test = 66\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.24\n",
      "  Test Accuracy (TNR): 0.94\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.64825531]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3073, Test = 3064\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.50\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: [0.16795166]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 365, Test = 390\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.11\n",
      "  Test Accuracy (TNR): 0.97\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.87\n",
      "  Optimal thershold: [0.58659435]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.004554  0.000000  0.290860  0.000000      0.000000   \n",
      "1     1.0  0.010934  0.018828  0.263590  0.000000      0.247115   \n",
      "2     1.0  0.007763  0.056038  0.261511  0.000000      0.261511   \n",
      "3     1.0  0.006935  0.012493  0.262353  0.000000      0.262353   \n",
      "4     0.0  0.006408  0.000000  0.294514  0.042073      0.098171   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.006444  0.006236  0.261908  0.000000      0.261908   \n",
      "3649  1.0  0.009549  0.006247  0.262367  0.000000      0.262367   \n",
      "3650  1.0  0.010638  0.049826  0.261586  0.000000      0.261586   \n",
      "3651  1.0  0.013496  0.000000  0.262336  0.000000      0.262336   \n",
      "3652  1.0  0.010668  0.018738  0.262331  0.000000      0.262331   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.020177       0.255567   0.012199     0.059272  ...    0.29086   \n",
      "1           0.184184       0.158816   0.252355     0.226617  ...    0.00000   \n",
      "2           0.126679       0.160846   0.256590     0.261511  ...    0.00000   \n",
      "3           0.175550       0.088915   0.257476     0.262353  ...    0.00000   \n",
      "4           0.079425       0.056685   0.046270     0.150876  ...    0.00000   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.126871       0.161090   0.257158     0.261908  ...    0.00000   \n",
      "3649        0.175559       0.088919   0.257430     0.262367  ...    0.00000   \n",
      "3650        0.126715       0.160892   0.256723     0.261586  ...    0.00000   \n",
      "3651        0.175538       0.088909   0.257756     0.262336  ...    0.00000   \n",
      "3652        0.175535       0.088907   0.257276     0.262331  ...    0.00000   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0                 0.0         0.000000         0.000000          0.29086   \n",
      "1                 0.0         0.000000         0.000000          0.26359   \n",
      "2                 0.0         0.000000         0.261511          0.00000   \n",
      "3                 0.0         0.000000         0.000000          0.00000   \n",
      "4                 0.0         0.000000         0.294514          0.00000   \n",
      "...               ...              ...              ...              ...   \n",
      "3648              0.0         0.261908         0.000000          0.00000   \n",
      "3649              0.0         0.262367         0.000000          0.00000   \n",
      "3650              0.0         0.000000         0.261586          0.00000   \n",
      "3651              0.0         0.000000         0.262336          0.00000   \n",
      "3652              0.0         0.262331         0.000000          0.00000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000          0.000000              0.290860   \n",
      "1            0.000000          0.000000              0.263590   \n",
      "2            0.000000          0.000000              0.261511   \n",
      "3            0.262353          0.000000              0.262353   \n",
      "4            0.000000          0.294514              0.000000   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.000000          0.000000              0.261908   \n",
      "3649         0.000000          0.000000              0.262367   \n",
      "3650         0.000000          0.000000              0.261586   \n",
      "3651         0.000000          0.000000              0.262336   \n",
      "3652         0.000000          0.000000              0.262331   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  0.0  \n",
      "2                  0.0  0.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  0.0  \n",
      "...                ...  ...  \n",
      "3648               0.0  0.0  \n",
      "3649               0.0  0.0  \n",
      "3650               0.0  0.0  \n",
      "3651               0.0  0.0  \n",
      "3652               0.0  0.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.004431  0.000000  0.275861  0.039409      0.189654   \n",
      "1     1.0  0.011039  0.019685  0.275591  0.039370      0.189469   \n",
      "2     1.0  0.004682  0.007028  0.295183  0.000000      0.030748   \n",
      "3     1.0  0.005382  0.000000  0.275707  0.000000      0.189548   \n",
      "4     1.0  0.008329  0.000000  0.259261  0.000000      0.259261   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.004487  0.007006  0.294246  0.000000      0.098082   \n",
      "3649  1.0  0.012007  0.012553  0.263620  0.000000      0.247144   \n",
      "3650  1.0  0.039715  0.006559  0.275487  0.000000      0.189398   \n",
      "3651  1.0  0.020678  0.000000  0.294772  0.000000      0.098257   \n",
      "3652  1.0  0.005553  0.006568  0.275865  0.000000      0.189657   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.107399       0.101572   0.211821     0.242173  ...        0.0   \n",
      "1           0.107294       0.101473   0.215050     0.241937  ...        0.0   \n",
      "2           0.087658       0.123508   0.042293     0.125662  ...        0.0   \n",
      "3           0.107339       0.101515   0.217890     0.242038  ...        0.0   \n",
      "4           0.228748       0.097630   0.253501     0.259261  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.100223       0.045553   0.055501     0.150739  ...        0.0   \n",
      "3649        0.184206       0.158834   0.252265     0.226644  ...        0.0   \n",
      "3650        0.107253       0.101435   0.217717     0.241846  ...        0.0   \n",
      "3651        0.079494       0.056734   0.042234     0.151008  ...        0.0   \n",
      "3652        0.107400       0.101574   0.215263     0.242177  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.275861         0.000000         0.000000              0.0   \n",
      "1            0.000000         0.000000         0.275591              0.0   \n",
      "2            0.000000         0.295183         0.000000              0.0   \n",
      "3            0.000000         0.000000         0.000000              0.0   \n",
      "4            0.000000         0.259261         0.000000              0.0   \n",
      "...               ...              ...              ...              ...   \n",
      "3648         0.000000         0.294246         0.000000              0.0   \n",
      "3649         0.263620         0.000000         0.000000              0.0   \n",
      "3650         0.000000         0.000000         0.000000              0.0   \n",
      "3651         0.000000         0.000000         0.294772              0.0   \n",
      "3652         0.000000         0.000000         0.275865              0.0   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000          0.275861              0.000000   \n",
      "1            0.000000          0.275591              0.000000   \n",
      "2            0.000000          0.000000              0.295183   \n",
      "3            0.275707          0.000000              0.275707   \n",
      "4            0.000000          0.000000              0.259261   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.000000          0.000000              0.294246   \n",
      "3649         0.000000          0.000000              0.263620   \n",
      "3650         0.275487          0.000000              0.275487   \n",
      "3651         0.000000          0.000000              0.294772   \n",
      "3652         0.000000          0.000000              0.275865   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  0.0  \n",
      "2                  0.0  0.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  0.0  \n",
      "...                ...  ...  \n",
      "3648               0.0  0.0  \n",
      "3649               0.0  0.0  \n",
      "3650               0.0  1.0  \n",
      "3651               0.0  1.0  \n",
      "3652               0.0  0.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n",
      "=====================================================================================\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.022348  0.006275  0.263569  0.000000      0.247096   \n",
      "1     1.0  0.011044  0.006247  0.262379  0.000000      0.262379   \n",
      "2     1.0  0.002198  0.012553  0.263603  0.000000      0.247128   \n",
      "3     1.0  0.012840  0.006993  0.293704  0.083915      0.097901   \n",
      "4     1.0  0.001180  0.000000  0.290240  0.000000      0.102794   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "9129  0.0  0.014383  0.021053  0.294739  0.000000      0.098246   \n",
      "9130  1.0  0.131912  0.000000  0.292359  0.041766      0.030454   \n",
      "9131  1.0  0.012609  0.026247  0.275594  0.000000      0.189471   \n",
      "9132  1.0  0.015577  0.000000  0.262356  0.000000      0.262356   \n",
      "9133  1.0  0.010241  0.018737  0.262320  0.000000      0.262320   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.184170       0.158803   0.252515     0.226600  ...        0.0   \n",
      "1           0.175567       0.088923   0.257204     0.262379  ...        0.0   \n",
      "2           0.184193       0.158824   0.252786     0.226629  ...        0.0   \n",
      "3           0.079206       0.056529   0.046609     0.150461  ...        0.0   \n",
      "4           0.209706       0.133583   0.005659     0.030725  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "9129        0.079485       0.056728   0.042230     0.150991  ...        0.0   \n",
      "9130        0.086819       0.122326   0.041491     0.124460  ...        0.0   \n",
      "9131        0.107295       0.101474   0.217801     0.241939  ...        0.0   \n",
      "9132        0.175552       0.088916   0.257360     0.262356  ...        0.0   \n",
      "9133        0.175527       0.088903   0.257444     0.262320  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.000000          0.00000         0.263569         0.000000   \n",
      "1            0.000000          0.00000         0.262379         0.000000   \n",
      "2            0.263603          0.00000         0.000000         0.000000   \n",
      "3            0.000000          0.00000         0.000000         0.000000   \n",
      "4            0.000000          0.29024         0.000000         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "9129         0.000000          0.00000         0.000000         0.294739   \n",
      "9130         0.000000          0.00000         0.000000         0.000000   \n",
      "9131         0.000000          0.00000         0.000000         0.000000   \n",
      "9132         0.000000          0.00000         0.000000         0.262356   \n",
      "9133         0.000000          0.00000         0.000000         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000          0.000000              0.263569   \n",
      "1            0.000000          0.000000              0.262379   \n",
      "2            0.000000          0.000000              0.263603   \n",
      "3            0.293704          0.293704              0.000000   \n",
      "4            0.000000          0.000000              0.290240   \n",
      "...               ...               ...                   ...   \n",
      "9129         0.000000          0.000000              0.294739   \n",
      "9130         0.292359          0.292359              0.000000   \n",
      "9131         0.275594          0.000000              0.275594   \n",
      "9132         0.000000          0.000000              0.262356   \n",
      "9133         0.262320          0.000000              0.262320   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  0.0  \n",
      "2                  0.0  0.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  0.0  \n",
      "...                ...  ...  \n",
      "9129               0.0  0.0  \n",
      "9130               0.0  0.0  \n",
      "9131               0.0  0.0  \n",
      "9132               0.0  0.0  \n",
      "9133               0.0  0.0  \n",
      "\n",
      "[9134 rows x 58 columns]\n",
      "=====================================================================================\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['dir_log_group']\n",
      "Results are stored in: ['dir_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  [0.06630057]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: [0.06630057]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 144, Test = 133\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.3098387]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 71, Test = 66\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.55\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [1.00795551]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3073, Test = 3064\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: [0.05956447]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 365, Test = 390\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.45\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.96395582]\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['rew_log_group']\n",
      "Results are stored in: ['rew_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.167114]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: [0.31086137]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 144, Test = 133\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.3364008]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 71, Test = 66\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [1.10774832]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3073, Test = 3064\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: [0.27171271]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 365, Test = 390\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.46\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.9677374]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['eg_log_group']\n",
      "Results are stored in: ['eg_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: [0.15743031]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 144, Test = 133\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: [0.12452384]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 71, Test = 66\n",
      "  AUC: 0.92\n",
      "  Privacy Risk: 0.86\n",
      "  Accuracy: 0.87\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.74\n",
      "  Attacker advantage: 0.73\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.21670973]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3073, Test = 3064\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: [0.13717879]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 365, Test = 390\n",
      "  AUC: 0.93\n",
      "  Privacy Risk: 0.87\n",
      "  Accuracy: 0.87\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.83\n",
      "  Attacker advantage: 0.75\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.21560154]\n",
      ")\n",
      "dir_log_group deleted.\n",
      "eg_log_group deleted.\n",
      "rew_log_group deleted.\n",
      "syn_log_group deleted.\n",
      "un_log_group deleted.\n",
      "dir_log_pop deleted.\n",
      "eg_log_pop deleted.\n",
      "rew_log_pop deleted.\n",
      "syn_log_pop deleted.\n",
      "un_log_pop deleted.\n",
      "ITERATION  2\n",
      "==============================================================\n",
      "GET UNIQUE INDICES REFERENCE\n",
      "Number of train points: 3653\n",
      "Number of test points: 3653\n",
      "Number of population points: 9134\n",
      "==============================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "privileged vs. unprivileged:  3453.0 200.0\n",
      "base_pos unpriv:  0.315\n",
      "base_pos priv:  0.11815812337098175\n",
      "DIFFERENCE IS GOOD\n",
      "base_pos unpriv:  0.315\n",
      "base_pos priv:  0.11815812337098175\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(3653, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[[1]] [[0]]\n",
      "#### Dataset feature names\n",
      "['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'job=admin.', 'job=blue-collar', 'job=entrepreneur', 'job=housemaid', 'job=management', 'job=retired', 'job=self-employed', 'job=services', 'job=student', 'job=technician', 'job=unemployed', 'marital=divorced', 'marital=married', 'marital=single', 'education=basic.4y', 'education=basic.6y', 'education=basic.9y', 'education=high.school', 'education=illiterate', 'education=professional.course', 'education=university.degree', 'default=no', 'default=yes', 'housing=no', 'housing=yes', 'loan=no', 'loan=yes', 'contact=cellular', 'contact=telephone', 'month=apr', 'month=aug', 'month=dec', 'month=jul', 'month=jun', 'month=mar', 'month=may', 'month=nov', 'month=oct', 'month=sep', 'day_of_week=fri', 'day_of_week=mon', 'day_of_week=thu', 'day_of_week=tue', 'day_of_week=wed', 'poutcome=failure', 'poutcome=nonexistent', 'poutcome=success']\n",
      "number of favorable labels:  471\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.196842\n",
      "#### Train shape, validation shape, test shape\n",
      "(3653, 57) (3653, 57) (3653, 57)\n",
      "#######################################################################\n",
      "                    rf\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['un_log_group']\n",
      "Results are stored in: ['un_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.18152488]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: [0.04678741]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 137, Test = 144\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.50\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: [0.30680328]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 63, Test = 58\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: [1.20682853]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3045, Test = 3058\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: [0.05448869]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 408, Test = 393\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.61\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 0.79\n",
      "  Optimal thershold: [1.1429191]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  3653 6906\n",
      "after transf priv:  0.11815812337098175\n",
      "after transf unpriv:  0.11815812337098175\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['syn_log_group']\n",
      "Results are stored in: ['syn_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.07613177]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.45\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: [0.03801176]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 137, Test = 144\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: [0.12774084]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 63, Test = 58\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [1.14235585]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3045, Test = 3058\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: [0.04833584]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 408, Test = 393\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: [1.29428931]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.010829  0.000000  0.263637  0.000000      0.247159   \n",
      "1     1.0  0.009090  0.007240  0.004262  0.086886      0.031677   \n",
      "2     1.0  0.010507  0.000000  0.263638  0.000000      0.247160   \n",
      "3     1.0  0.004984  0.006558  0.275433  0.000000      0.189360   \n",
      "4     1.0  0.031341  0.006565  0.275734  0.000000      0.189567   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.007200  0.024981  0.262299  0.000000      0.262299   \n",
      "3649  1.0  0.018950  0.007000  0.294001  0.042000      0.098000   \n",
      "3650  1.0  0.010239  0.000000  0.263630  0.000000      0.247154   \n",
      "3651  1.0  0.015592  0.006568  0.275836  0.000000      0.189637   \n",
      "3652  1.0  0.016694  0.000000  0.294261  0.000000      0.098087   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.184217       0.158844   0.252400     0.226658  ...        0.0   \n",
      "1           0.031761       0.218851   0.029300     0.129458  ...        0.0   \n",
      "2           0.184218       0.158844   0.252401     0.226659  ...        0.0   \n",
      "3           0.107232       0.101414   0.222107     0.241797  ...        0.0   \n",
      "4           0.107349       0.101525   0.215161     0.242062  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.175514       0.088896   0.257304     0.262299  ...        0.0   \n",
      "3649        0.100139       0.045515   0.051388     0.150613  ...        0.0   \n",
      "3650        0.184213       0.158840   0.252514     0.226652  ...        0.0   \n",
      "3651        0.107389       0.101563   0.215241     0.242151  ...        0.0   \n",
      "3652        0.100228       0.045555   0.052635     0.150746  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.000000         0.000000         0.000000         0.000000   \n",
      "1            0.304101         0.000000         0.000000         0.000000   \n",
      "2            0.000000         0.000000         0.000000         0.263638   \n",
      "3            0.000000         0.275433         0.000000         0.000000   \n",
      "4            0.000000         0.000000         0.275734         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "3648         0.000000         0.000000         0.000000         0.262299   \n",
      "3649         0.294001         0.000000         0.000000         0.000000   \n",
      "3650         0.000000         0.000000         0.000000         0.000000   \n",
      "3651         0.000000         0.000000         0.275836         0.000000   \n",
      "3652         0.000000         0.000000         0.000000         0.294261   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.263637          0.000000              0.263637   \n",
      "1            0.000000          0.304101              0.000000   \n",
      "2            0.000000          0.000000              0.263638   \n",
      "3            0.000000          0.000000              0.275433   \n",
      "4            0.000000          0.000000              0.275734   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.000000          0.000000              0.262299   \n",
      "3649         0.000000          0.294001              0.000000   \n",
      "3650         0.263630          0.000000              0.263630   \n",
      "3651         0.000000          0.000000              0.275836   \n",
      "3652         0.000000          0.000000              0.294261   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  0.0  \n",
      "2                  0.0  0.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  0.0  \n",
      "...                ...  ...  \n",
      "3648               0.0  0.0  \n",
      "3649               0.0  0.0  \n",
      "3650               0.0  0.0  \n",
      "3651               0.0  0.0  \n",
      "3652               0.0  1.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.052335  0.000000  0.261567  0.000000      0.261567   \n",
      "1     1.0  0.007442  0.000000  0.295150  0.000000      0.098383   \n",
      "2     1.0  0.007775  0.000000  0.261910  0.000000      0.261910   \n",
      "3     1.0  0.008556  0.007006  0.294261  0.000000      0.098087   \n",
      "4     1.0  0.004600  0.000000  0.275872  0.000000      0.189662   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.042678  0.021418  0.000900  0.171341      0.099949   \n",
      "3649  1.0  0.019961  0.000000  0.294794  0.000000      0.098265   \n",
      "3650  1.0  0.020451  0.034406  0.289012  0.082575      0.102358   \n",
      "3651  1.0  0.018796  0.000000  0.261868  0.000000      0.261868   \n",
      "3652  1.0  0.012246  0.012469  0.261858  0.000000      0.261858   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.126706       0.160880   0.256705     0.261567  ...        0.0   \n",
      "1           0.073845       0.009880   0.060020     0.151202  ...        0.0   \n",
      "2           0.126872       0.161091   0.257160     0.261910  ...        0.0   \n",
      "3           0.100228       0.045555   0.054102     0.150746  ...        0.0   \n",
      "4           0.107403       0.101576   0.215269     0.242183  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.195730       0.135495   0.003399     0.051127  ...        0.0   \n",
      "3649        0.079500       0.056739   0.040767     0.151019  ...        0.0   \n",
      "3650        0.208818       0.133018   0.007862     0.030595  ...        0.0   \n",
      "3651        0.126852       0.161065   0.257178     0.261868  ...        0.0   \n",
      "3652        0.126847       0.161059   0.257406     0.261858  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.000000         0.261567         0.000000              0.0   \n",
      "1            0.295150         0.000000         0.000000              0.0   \n",
      "2            0.000000         0.261910         0.000000              0.0   \n",
      "3            0.000000         0.000000         0.000000              0.0   \n",
      "4            0.000000         0.000000         0.275872              0.0   \n",
      "...               ...              ...              ...              ...   \n",
      "3648         0.299846         0.000000         0.000000              0.0   \n",
      "3649         0.000000         0.294794         0.000000              0.0   \n",
      "3650         0.000000         0.289012         0.000000              0.0   \n",
      "3651         0.261868         0.000000         0.000000              0.0   \n",
      "3652         0.000000         0.261858         0.000000              0.0   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000          0.000000              0.261567   \n",
      "1            0.000000          0.000000              0.295150   \n",
      "2            0.000000          0.000000              0.261910   \n",
      "3            0.294261          0.000000              0.294261   \n",
      "4            0.000000          0.000000              0.275872   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.000000          0.000000              0.000000   \n",
      "3649         0.000000          0.000000              0.294794   \n",
      "3650         0.000000          0.289012              0.000000   \n",
      "3651         0.000000          0.000000              0.261868   \n",
      "3652         0.000000          0.000000              0.261858   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0             0.000000  0.0  \n",
      "1             0.000000  0.0  \n",
      "2             0.000000  0.0  \n",
      "3             0.000000  1.0  \n",
      "4             0.000000  0.0  \n",
      "...                ...  ...  \n",
      "3648          0.299846  1.0  \n",
      "3649          0.000000  0.0  \n",
      "3650          0.000000  0.0  \n",
      "3651          0.000000  0.0  \n",
      "3652          0.000000  0.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n",
      "=====================================================================================\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.014419  0.006276  0.263612       0.0      0.247136   \n",
      "1     1.0  0.005647  0.012360  0.259564       0.0      0.259564   \n",
      "2     0.0  0.031995  0.000000  0.262254       0.0      0.262254   \n",
      "3     1.0  0.006231  0.006236  0.261904       0.0      0.261904   \n",
      "4     1.0  0.005112  0.000000  0.261895       0.0      0.261895   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "9129  1.0  0.030738  0.000000  0.287938       0.0      0.000000   \n",
      "9130  1.0  0.012001  0.021078  0.295094       0.0      0.030739   \n",
      "9131  1.0  0.008748  0.018738  0.262328       0.0      0.262328   \n",
      "9132  1.0  0.015819  0.014033  0.294690       0.0      0.098230   \n",
      "9133  1.0  0.007600  0.006180  0.259572       0.0      0.259572   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.184199       0.158829   0.252496     0.226636  ...        0.0   \n",
      "1           0.229015       0.097744   0.248913     0.259564  ...        0.0   \n",
      "2           0.175483       0.088881   0.257259     0.262254  ...        0.0   \n",
      "3           0.126869       0.161087   0.257213     0.261904  ...        0.0   \n",
      "4           0.126865       0.161082   0.257442     0.261895  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "9129        0.025809       0.287938   0.006919     0.058676  ...        0.0   \n",
      "9130        0.087631       0.123470   0.043284     0.125624  ...        0.0   \n",
      "9131        0.175533       0.088906   0.257392     0.262328  ...        0.0   \n",
      "9132        0.079472       0.056719   0.048102     0.150966  ...        0.0   \n",
      "9133        0.229022       0.097747   0.248979     0.259572  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.263612         0.000000              0.0         0.000000   \n",
      "1            0.000000         0.000000              0.0         0.259564   \n",
      "2            0.000000         0.000000              0.0         0.262254   \n",
      "3            0.000000         0.000000              0.0         0.261904   \n",
      "4            0.000000         0.261895              0.0         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "9129         0.000000         0.000000              0.0         0.000000   \n",
      "9130         0.000000         0.295094              0.0         0.000000   \n",
      "9131         0.262328         0.000000              0.0         0.000000   \n",
      "9132         0.000000         0.294690              0.0         0.000000   \n",
      "9133         0.000000         0.259572              0.0         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000               0.0              0.263612   \n",
      "1            0.000000               0.0              0.259564   \n",
      "2            0.000000               0.0              0.262254   \n",
      "3            0.000000               0.0              0.261904   \n",
      "4            0.000000               0.0              0.261895   \n",
      "...               ...               ...                   ...   \n",
      "9129         0.287938               0.0              0.287938   \n",
      "9130         0.000000               0.0              0.295094   \n",
      "9131         0.000000               0.0              0.262328   \n",
      "9132         0.000000               0.0              0.294690   \n",
      "9133         0.000000               0.0              0.259572   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  0.0  \n",
      "2                  0.0  1.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  0.0  \n",
      "...                ...  ...  \n",
      "9129               0.0  0.0  \n",
      "9130               0.0  1.0  \n",
      "9131               0.0  0.0  \n",
      "9132               0.0  0.0  \n",
      "9133               0.0  0.0  \n",
      "\n",
      "[9134 rows x 58 columns]\n",
      "=====================================================================================\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['dir_log_group']\n",
      "Results are stored in: ['dir_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  [0.11312205]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: [0.0977594]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 137, Test = 144\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: [0.26785626]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 63, Test = 58\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [1.10147878]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3045, Test = 3058\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: [0.08949346]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 408, Test = 393\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.93\n",
      "  Optimal thershold: [1.1130629]\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['rew_log_group']\n",
      "Results are stored in: ['rew_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.18003045]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: [0.27442222]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 137, Test = 144\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.14\n",
      "  Test Accuracy (TNR): 0.90\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.2276334]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 63, Test = 58\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.40\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: [0.86036956]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3045, Test = 3058\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: [0.05683396]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 408, Test = 393\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [1.10677184]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['eg_log_group']\n",
      "Results are stored in: ['eg_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: [0.30110509]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 137, Test = 144\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: [0.31471074]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 63, Test = 58\n",
      "  AUC: 0.90\n",
      "  Privacy Risk: 0.86\n",
      "  Accuracy: 0.86\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.81\n",
      "  Attacker advantage: 0.72\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.35667494]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3045, Test = 3058\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: [0.09431068]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 408, Test = 393\n",
      "  AUC: 0.90\n",
      "  Privacy Risk: 0.86\n",
      "  Accuracy: 0.86\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.76\n",
      "  Attacker advantage: 0.72\n",
      "  Positive predictive value: 0.95\n",
      "  Optimal thershold: [0.4462871]\n",
      ")\n",
      "dir_log_group deleted.\n",
      "eg_log_group deleted.\n",
      "rew_log_group deleted.\n",
      "syn_log_group deleted.\n",
      "un_log_group deleted.\n",
      "dir_log_pop deleted.\n",
      "eg_log_pop deleted.\n",
      "rew_log_pop deleted.\n",
      "syn_log_pop deleted.\n",
      "un_log_pop deleted.\n",
      "ITERATION  3\n",
      "==============================================================\n",
      "GET UNIQUE INDICES REFERENCE\n",
      "Number of train points: 3653\n",
      "Number of test points: 3653\n",
      "Number of population points: 9134\n",
      "==============================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "privileged vs. unprivileged:  3437.0 216.0\n",
      "base_pos unpriv:  0.35648148148148145\n",
      "base_pos priv:  0.11230724469013675\n",
      "DIFFERENCE IS GOOD\n",
      "base_pos unpriv:  0.35648148148148145\n",
      "base_pos priv:  0.11230724469013675\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(3653, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[[1]] [[0]]\n",
      "#### Dataset feature names\n",
      "['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'job=admin.', 'job=blue-collar', 'job=entrepreneur', 'job=housemaid', 'job=management', 'job=retired', 'job=self-employed', 'job=services', 'job=student', 'job=technician', 'job=unemployed', 'marital=divorced', 'marital=married', 'marital=single', 'education=basic.4y', 'education=basic.6y', 'education=basic.9y', 'education=high.school', 'education=illiterate', 'education=professional.course', 'education=university.degree', 'default=no', 'default=yes', 'housing=no', 'housing=yes', 'loan=no', 'loan=yes', 'contact=cellular', 'contact=telephone', 'month=apr', 'month=aug', 'month=dec', 'month=jul', 'month=jun', 'month=mar', 'month=may', 'month=nov', 'month=oct', 'month=sep', 'day_of_week=fri', 'day_of_week=mon', 'day_of_week=thu', 'day_of_week=tue', 'day_of_week=wed', 'poutcome=failure', 'poutcome=nonexistent', 'poutcome=success']\n",
      "number of favorable labels:  463\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.244174\n",
      "#### Train shape, validation shape, test shape\n",
      "(3653, 57) (3653, 57) (3653, 57)\n",
      "#######################################################################\n",
      "                    rf\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['un_log_group']\n",
      "Results are stored in: ['un_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.13285844]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: [0.27220608]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 139, Test = 129\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: [0.53621616]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 77, Test = 78\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.23\n",
      "  Test Accuracy (TNR): 0.97\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.26325682]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3051, Test = 3049\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.45\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: [0.03387242]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 386, Test = 397\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.32\n",
      "  Test Accuracy (TNR): 0.81\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.88\n",
      "  Optimal thershold: [0.77400767]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  3653 6874\n",
      "after transf priv:  0.11230724469013675\n",
      "after transf unpriv:  0.11230724469013675\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['syn_log_group']\n",
      "Results are stored in: ['syn_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.11929447]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: [0.74684305]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 139, Test = 129\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.33472588]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 77, Test = 78\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.35\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.49078827]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3051, Test = 3049\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.29\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: [0.03621263]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 386, Test = 397\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.25\n",
      "  Test Accuracy (TNR): 0.83\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.81\n",
      "  Optimal thershold: [1.31350045]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.027519  0.000000  0.262280  0.000000      0.262280   \n",
      "1     1.0  0.012316  0.000000  0.289813  0.082804      0.000000   \n",
      "2     1.0  0.006935  0.006247  0.262368  0.000000      0.262368   \n",
      "3     1.0  0.009266  0.000000  0.261911  0.000000      0.261911   \n",
      "4     1.0  0.007066  0.007012  0.294490  0.042070      0.098163   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.009603  0.000000  0.262368  0.000000      0.262368   \n",
      "3649  1.0  0.010723  0.000000  0.262369  0.000000      0.262369   \n",
      "3650  1.0  0.011980  0.018704  0.261858  0.000000      0.261858   \n",
      "3651  1.0  0.006724  0.006561  0.275574  0.000000      0.189457   \n",
      "3652  1.0  0.009220  0.000000  0.263641  0.000000      0.247163   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.175501       0.088890   0.257405     0.262280  ...        0.0   \n",
      "1           0.050599       0.251010   0.005322     0.059058  ...        0.0   \n",
      "2           0.175560       0.088920   0.257491     0.262368  ...        0.0   \n",
      "3           0.126873       0.161092   0.257101     0.261911  ...        0.0   \n",
      "4           0.079418       0.056680   0.047401     0.150864  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.175559       0.088920   0.257490     0.262368  ...        0.0   \n",
      "3649        0.175560       0.088920   0.257432     0.262369  ...        0.0   \n",
      "3650        0.126847       0.161059   0.257049     0.261858  ...        0.0   \n",
      "3651        0.107287       0.101467   0.219847     0.241922  ...        0.0   \n",
      "3652        0.184220       0.158846   0.252404     0.226662  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.000000         0.000000              0.0         0.000000   \n",
      "1            0.000000         0.000000              0.0         0.289813   \n",
      "2            0.262368         0.000000              0.0         0.000000   \n",
      "3            0.000000         0.000000              0.0         0.000000   \n",
      "4            0.000000         0.000000              0.0         0.294490   \n",
      "...               ...              ...              ...              ...   \n",
      "3648         0.000000         0.000000              0.0         0.000000   \n",
      "3649         0.000000         0.000000              0.0         0.262369   \n",
      "3650         0.000000         0.000000              0.0         0.000000   \n",
      "3651         0.000000         0.000000              0.0         0.275574   \n",
      "3652         0.000000         0.263641              0.0         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.262280          0.000000              0.262280   \n",
      "1            0.000000          0.289813              0.000000   \n",
      "2            0.000000          0.000000              0.262368   \n",
      "3            0.261911          0.000000              0.261911   \n",
      "4            0.000000          0.294490              0.000000   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.262368          0.000000              0.262368   \n",
      "3649         0.000000          0.000000              0.262369   \n",
      "3650         0.261858          0.000000              0.261858   \n",
      "3651         0.000000          0.000000              0.275574   \n",
      "3652         0.000000          0.000000              0.263641   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  1.0  \n",
      "2                  0.0  0.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  0.0  \n",
      "...                ...  ...  \n",
      "3648               0.0  0.0  \n",
      "3649               0.0  0.0  \n",
      "3650               0.0  0.0  \n",
      "3651               0.0  0.0  \n",
      "3652               0.0  0.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.008307  0.012471  0.261897  0.000000      0.261897   \n",
      "1     1.0  0.018628  0.006179  0.259530  0.000000      0.259530   \n",
      "2     1.0  0.001320  0.000000  0.259588  0.000000      0.259588   \n",
      "3     1.0  0.032634  0.000000  0.295026  0.000000      0.098342   \n",
      "4     1.0  0.002667  0.006247  0.262374  0.000000      0.262374   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.018590  0.031367  0.263481  0.000000      0.247013   \n",
      "3649  1.0  0.019419  0.007219  0.001214  0.043312      0.031582   \n",
      "3650  1.0  0.010456  0.006247  0.262360  0.000000      0.262360   \n",
      "3651  1.0  0.056247  0.014013  0.294279  0.000000      0.098093   \n",
      "3652  1.0  0.028000  0.006245  0.262296  0.000000      0.262296   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.126866       0.161083   0.257028     0.261897  ...        0.0   \n",
      "1           0.228986       0.097731   0.248999     0.259530  ...        0.0   \n",
      "2           0.229036       0.097753   0.248936     0.259588  ...        0.0   \n",
      "3           0.073814       0.009875   0.058590     0.151138  ...        0.0   \n",
      "4           0.175563       0.088922   0.257496     0.262374  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.184108       0.158750   0.252191     0.226524  ...        0.0   \n",
      "3649        0.000000       0.246099   0.016427     0.129068  ...        0.0   \n",
      "3650        0.175554       0.088917   0.257483     0.262360  ...        0.0   \n",
      "3651        0.079361       0.056640   0.046700     0.150756  ...        0.0   \n",
      "3652        0.175511       0.088895   0.257063     0.262296  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0             0.00000              0.0         0.261897         0.000000   \n",
      "1             0.00000              0.0         0.259530         0.000000   \n",
      "2             0.00000              0.0         0.000000         0.259588   \n",
      "3             0.00000              0.0         0.000000         0.295026   \n",
      "4             0.00000              0.0         0.000000         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "3648          0.00000              0.0         0.000000         0.263481   \n",
      "3649          0.00000              0.0         0.303184         0.000000   \n",
      "3650          0.26236              0.0         0.000000         0.000000   \n",
      "3651          0.00000              0.0         0.000000         0.000000   \n",
      "3652          0.00000              0.0         0.000000         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000               0.0              0.261897   \n",
      "1            0.000000               0.0              0.259530   \n",
      "2            0.000000               0.0              0.259588   \n",
      "3            0.000000               0.0              0.295026   \n",
      "4            0.262374               0.0              0.262374   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.000000               0.0              0.263481   \n",
      "3649         0.000000               0.0              0.000000   \n",
      "3650         0.000000               0.0              0.262360   \n",
      "3651         0.294279               0.0              0.294279   \n",
      "3652         0.262296               0.0              0.262296   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0             0.000000  0.0  \n",
      "1             0.000000  0.0  \n",
      "2             0.000000  0.0  \n",
      "3             0.000000  0.0  \n",
      "4             0.000000  0.0  \n",
      "...                ...  ...  \n",
      "3648          0.000000  0.0  \n",
      "3649          0.303184  1.0  \n",
      "3650          0.000000  0.0  \n",
      "3651          0.000000  0.0  \n",
      "3652          0.000000  0.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n",
      "=====================================================================================\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.003354  0.007013  0.294564  0.042081      0.098188   \n",
      "1     1.0  0.007030  0.000000  0.261912  0.000000      0.261912   \n",
      "2     1.0  0.041838  0.027994  0.293942  0.000000      0.097981   \n",
      "3     0.0  0.004374  0.012493  0.262357  0.000000      0.262357   \n",
      "4     1.0  0.056811  0.000000  0.275266  0.000000      0.189245   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "9129  1.0  0.009752  0.012345  0.259238  0.000000      0.259238   \n",
      "9130  1.0  0.005851  0.000000  0.259219  0.000000      0.259219   \n",
      "9131  1.0  0.008899  0.000000  0.263646  0.000000      0.247168   \n",
      "9132  1.0  0.023046  0.000000  0.263582  0.000000      0.247108   \n",
      "9133  1.0  0.015644  0.000000  0.294786  0.000000      0.098262   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.079438       0.056694   0.042205     0.150902  ...        0.0   \n",
      "1           0.126873       0.161092   0.257162     0.261912  ...        0.0   \n",
      "2           0.100119       0.045506   0.051711     0.150583  ...        0.0   \n",
      "3           0.175552       0.088916   0.257480     0.262357  ...        0.0   \n",
      "4           0.107167       0.101353   0.217542     0.241651  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "9129        0.228727       0.097621   0.253478     0.259238  ...        0.0   \n",
      "9130        0.228711       0.097614   0.254165     0.259219  ...        0.0   \n",
      "9131        0.184223       0.158849   0.252349     0.226666  ...        0.0   \n",
      "9132        0.184179       0.158811   0.252348     0.226611  ...        0.0   \n",
      "9133        0.079498       0.056737   0.043239     0.151015  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.000000              0.0         0.294564         0.000000   \n",
      "1            0.000000              0.0         0.000000         0.000000   \n",
      "2            0.000000              0.0         0.293942         0.000000   \n",
      "3            0.000000              0.0         0.000000         0.000000   \n",
      "4            0.000000              0.0         0.000000         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "9129         0.259238              0.0         0.000000         0.000000   \n",
      "9130         0.259219              0.0         0.000000         0.000000   \n",
      "9131         0.000000              0.0         0.000000         0.263646   \n",
      "9132         0.000000              0.0         0.000000         0.000000   \n",
      "9133         0.000000              0.0         0.000000         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000          0.294564              0.000000   \n",
      "1            0.261912          0.000000              0.261912   \n",
      "2            0.000000          0.000000              0.293942   \n",
      "3            0.262357          0.000000              0.262357   \n",
      "4            0.275266          0.000000              0.275266   \n",
      "...               ...               ...                   ...   \n",
      "9129         0.000000          0.000000              0.259238   \n",
      "9130         0.000000          0.000000              0.259219   \n",
      "9131         0.000000          0.000000              0.263646   \n",
      "9132         0.263582          0.000000              0.263582   \n",
      "9133         0.294786          0.000000              0.294786   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  0.0  \n",
      "2                  0.0  1.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  1.0  \n",
      "...                ...  ...  \n",
      "9129               0.0  0.0  \n",
      "9130               0.0  0.0  \n",
      "9131               0.0  0.0  \n",
      "9132               0.0  0.0  \n",
      "9133               0.0  0.0  \n",
      "\n",
      "[9134 rows x 58 columns]\n",
      "=====================================================================================\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['dir_log_group']\n",
      "Results are stored in: ['dir_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  [0.10021593]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.45\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: [0.04185206]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 139, Test = 129\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: [0.36644935]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 77, Test = 78\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.35\n",
      "  Test Accuracy (TNR): 0.86\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 0.88\n",
      "  Optimal thershold: [1.30932316]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3051, Test = 3049\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.50\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: [0.0396121]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 386, Test = 397\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [1.04910153]\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['rew_log_group']\n",
      "Results are stored in: ['rew_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.13989504]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: [0.71251589]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 139, Test = 129\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: [0.44042404]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 77, Test = 78\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.91\n",
      "  Optimal thershold: [1.03545181]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3051, Test = 3049\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: [0.25809306]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 386, Test = 397\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.40\n",
      "  Test Accuracy (TNR): 0.75\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.90074715]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['eg_log_group']\n",
      "Results are stored in: ['eg_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: [0.27443685]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 139, Test = 129\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.68\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: [0.28768207]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 77, Test = 78\n",
      "  AUC: 0.93\n",
      "  Privacy Risk: 0.85\n",
      "  Accuracy: 0.85\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.83\n",
      "  Attacker advantage: 0.69\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.29188155]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3051, Test = 3049\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: [0.09431068]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 386, Test = 397\n",
      "  AUC: 0.92\n",
      "  Privacy Risk: 0.86\n",
      "  Accuracy: 0.86\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.79\n",
      "  Attacker advantage: 0.73\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.45065221]\n",
      ")\n",
      "dir_log_group deleted.\n",
      "eg_log_group deleted.\n",
      "rew_log_group deleted.\n",
      "syn_log_group deleted.\n",
      "un_log_group deleted.\n",
      "dir_log_pop deleted.\n",
      "eg_log_pop deleted.\n",
      "rew_log_pop deleted.\n",
      "syn_log_pop deleted.\n",
      "un_log_pop deleted.\n",
      "ITERATION  4\n",
      "==============================================================\n",
      "GET UNIQUE INDICES REFERENCE\n",
      "Number of train points: 3653\n",
      "Number of test points: 3653\n",
      "Number of population points: 9134\n",
      "==============================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "privileged vs. unprivileged:  3440.0 213.0\n",
      "base_pos unpriv:  0.3051643192488263\n",
      "base_pos priv:  0.11395348837209303\n",
      "DIFFERENCE IS GOOD\n",
      "base_pos unpriv:  0.3051643192488263\n",
      "base_pos priv:  0.11395348837209303\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(3653, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[[1]] [[0]]\n",
      "#### Dataset feature names\n",
      "['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'job=admin.', 'job=blue-collar', 'job=entrepreneur', 'job=housemaid', 'job=management', 'job=retired', 'job=self-employed', 'job=services', 'job=student', 'job=technician', 'job=unemployed', 'marital=divorced', 'marital=married', 'marital=single', 'education=basic.4y', 'education=basic.6y', 'education=basic.9y', 'education=high.school', 'education=illiterate', 'education=professional.course', 'education=university.degree', 'default=no', 'default=yes', 'housing=no', 'housing=yes', 'loan=no', 'loan=yes', 'contact=cellular', 'contact=telephone', 'month=apr', 'month=aug', 'month=dec', 'month=jul', 'month=jun', 'month=mar', 'month=may', 'month=nov', 'month=oct', 'month=sep', 'day_of_week=fri', 'day_of_week=mon', 'day_of_week=thu', 'day_of_week=tue', 'day_of_week=wed', 'poutcome=failure', 'poutcome=nonexistent', 'poutcome=success']\n",
      "number of favorable labels:  457\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.191211\n",
      "#### Train shape, validation shape, test shape\n",
      "(3653, 57) (3653, 57) (3653, 57)\n",
      "#######################################################################\n",
      "                    rf\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['un_log_group']\n",
      "Results are stored in: ['un_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.16796808]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: [0.28506741]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 137\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.28917659]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 65, Test = 75\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.26\n",
      "  Test Accuracy (TNR): 0.89\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.37979795]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3048, Test = 3059\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.35\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: [0.04140839]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 392, Test = 382\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.61\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.83\n",
      "  Optimal thershold: [1.21385888]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  3653 6880\n",
      "after transf priv:  0.11395348837209303\n",
      "after transf unpriv:  0.11395348837209303\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['syn_log_group']\n",
      "Results are stored in: ['syn_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.11553233]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.32\n",
      "  Test Accuracy (TNR): 0.70\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: [0.04257391]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 137\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.80\n",
      "  Optimal thershold: [0.22720917]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 65, Test = 75\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.15\n",
      "  Test Accuracy (TNR): 0.99\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.91\n",
      "  Optimal thershold: [1.21285305]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3048, Test = 3059\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.37\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: [0.04257391]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 392, Test = 382\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: [1.3778363]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.003117  0.000000  0.294793       0.0      0.098264   \n",
      "1     1.0  0.030918  0.000000  0.294681       0.0      0.098227   \n",
      "2     1.0  0.008202  0.000000  0.263643       0.0      0.247166   \n",
      "3     1.0  0.023581  0.000000  0.292860       0.0      0.024405   \n",
      "4     1.0  0.014251  0.031368  0.263488       0.0      0.247020   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.002929  0.012471  0.261897       0.0      0.261897   \n",
      "3649  1.0  0.020313  0.000000  0.263590       0.0      0.247116   \n",
      "3650  1.0  0.008470  0.000000  0.275865       0.0      0.189657   \n",
      "3651  1.0  0.019541  0.006235  0.261863       0.0      0.261863   \n",
      "3652  1.0  0.003355  0.006236  0.261908       0.0      0.261908   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.079500       0.056738   0.045378     0.151018  ...        0.0   \n",
      "1           0.079470       0.056717   0.043223     0.150961  ...        0.0   \n",
      "2           0.184222       0.158848   0.252407     0.226664  ...        0.0   \n",
      "3           0.058435       0.218113   0.004913     0.066323  ...        0.0   \n",
      "4           0.184113       0.158754   0.252377     0.226530  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.126866       0.161083   0.257147     0.261897  ...        0.0   \n",
      "3649        0.184184       0.158816   0.252475     0.226618  ...        0.0   \n",
      "3650        0.107400       0.101574   0.215264     0.242177  ...        0.0   \n",
      "3651        0.126850       0.161062   0.257114     0.261863  ...        0.0   \n",
      "3652        0.126871       0.161090   0.257217     0.261908  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.294793         0.000000         0.000000          0.00000   \n",
      "1            0.000000         0.000000         0.000000          0.00000   \n",
      "2            0.000000         0.263643         0.000000          0.00000   \n",
      "3            0.000000         0.000000         0.000000          0.29286   \n",
      "4            0.263488         0.000000         0.000000          0.00000   \n",
      "...               ...              ...              ...              ...   \n",
      "3648         0.000000         0.261897         0.000000          0.00000   \n",
      "3649         0.263590         0.000000         0.000000          0.00000   \n",
      "3650         0.000000         0.000000         0.275865          0.00000   \n",
      "3651         0.000000         0.261863         0.000000          0.00000   \n",
      "3652         0.261908         0.000000         0.000000          0.00000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000               0.0              0.294793   \n",
      "1            0.294681               0.0              0.294681   \n",
      "2            0.000000               0.0              0.263643   \n",
      "3            0.000000               0.0              0.292860   \n",
      "4            0.000000               0.0              0.263488   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.000000               0.0              0.261897   \n",
      "3649         0.000000               0.0              0.263590   \n",
      "3650         0.000000               0.0              0.275865   \n",
      "3651         0.000000               0.0              0.261863   \n",
      "3652         0.000000               0.0              0.261908   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  1.0  \n",
      "2                  0.0  0.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  0.0  \n",
      "...                ...  ...  \n",
      "3648               0.0  0.0  \n",
      "3649               0.0  0.0  \n",
      "3650               0.0  0.0  \n",
      "3651               0.0  0.0  \n",
      "3652               0.0  0.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.014205  0.000000  0.263618  0.000000      0.247142   \n",
      "1     1.0  0.005092  0.012554  0.263628  0.000000      0.247151   \n",
      "2     1.0  0.043127  0.000000  0.275454  0.000000      0.189375   \n",
      "3     1.0  0.010752  0.006171  0.259196  0.000000      0.259196   \n",
      "4     1.0  0.004986  0.000000  0.263657  0.000000      0.247178   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.043701  0.012542  0.263384  0.000000      0.246922   \n",
      "3649  1.0  0.010291  0.012553  0.263606  0.000000      0.247130   \n",
      "3650  1.0  0.004432  0.000000  0.294570  0.042081      0.098190   \n",
      "3651  1.0  0.015602  0.006235  0.261873  0.000000      0.261873   \n",
      "3652  1.0  0.001558  0.000000  0.294775  0.000000      0.098258   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.184204       0.158832   0.252502     0.226641  ...        0.0   \n",
      "1           0.184211       0.158839   0.252392     0.226650  ...        0.0   \n",
      "2           0.107240       0.101422   0.217691     0.241817  ...        0.0   \n",
      "3           0.228690       0.097605   0.254260     0.259196  ...        0.0   \n",
      "4           0.184231       0.158856   0.252300     0.226675  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.184040       0.158691   0.252098     0.226440  ...        0.0   \n",
      "3649        0.184195       0.158825   0.252550     0.226631  ...        0.0   \n",
      "3650        0.079440       0.056696   0.042206     0.150905  ...        0.0   \n",
      "3651        0.126854       0.161068   0.257243     0.261873  ...        0.0   \n",
      "3652        0.079495       0.056735   0.046779     0.151009  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.263618              0.0         0.000000         0.000000   \n",
      "1            0.000000              0.0         0.000000         0.263628   \n",
      "2            0.000000              0.0         0.000000         0.000000   \n",
      "3            0.000000              0.0         0.000000         0.259196   \n",
      "4            0.000000              0.0         0.263657         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "3648         0.000000              0.0         0.000000         0.263384   \n",
      "3649         0.000000              0.0         0.263606         0.000000   \n",
      "3650         0.000000              0.0         0.294570         0.000000   \n",
      "3651         0.000000              0.0         0.000000         0.000000   \n",
      "3652         0.000000              0.0         0.000000         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000           0.00000              0.263618   \n",
      "1            0.000000           0.00000              0.263628   \n",
      "2            0.275454           0.00000              0.275454   \n",
      "3            0.000000           0.00000              0.259196   \n",
      "4            0.000000           0.00000              0.263657   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.000000           0.00000              0.263384   \n",
      "3649         0.000000           0.00000              0.263606   \n",
      "3650         0.000000           0.29457              0.000000   \n",
      "3651         0.261873           0.00000              0.261873   \n",
      "3652         0.294775           0.00000              0.294775   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  0.0  \n",
      "2                  0.0  0.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  0.0  \n",
      "...                ...  ...  \n",
      "3648               0.0  0.0  \n",
      "3649               0.0  0.0  \n",
      "3650               0.0  0.0  \n",
      "3651               0.0  0.0  \n",
      "3652               0.0  0.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n",
      "=====================================================================================\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.051032  0.013119  0.275492  0.000000      0.189401   \n",
      "1     0.0  0.009641  0.000000  0.289101  0.000000      0.096367   \n",
      "2     1.0  0.009698  0.000000  0.289057  0.041294      0.102374   \n",
      "3     1.0  0.001447  0.006277  0.263643  0.000000      0.247165   \n",
      "4     1.0  0.010577  0.021857  0.001838  0.043714      0.025500   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "9129  1.0  0.004428  0.006247  0.262384  0.000000      0.262384   \n",
      "9130  1.0  0.018604  0.000000  0.295146  0.000000      0.030744   \n",
      "9131  1.0  0.004686  0.000000  0.261903  0.000000      0.261903   \n",
      "9132  1.0  0.010671  0.007020  0.294824  0.000000      0.098275   \n",
      "9133  1.0  0.021439  0.000000  0.294519  0.042074      0.098173   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.107255       0.101436   0.214972     0.241850  ...        0.0   \n",
      "1           0.174407       0.195960   0.000721     0.049295  ...        0.0   \n",
      "2           0.226875       0.126991   0.009699     0.030600  ...        0.0   \n",
      "3           0.184221       0.158848   0.252466     0.226663  ...        0.0   \n",
      "4           0.061057       0.227898   0.005272     0.069298  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "9129        0.175570       0.088925   0.257328     0.262384  ...        0.0   \n",
      "9130        0.087647       0.123492   0.042020     0.125646  ...        0.0   \n",
      "9131        0.126869       0.161087   0.257331     0.261903  ...        0.0   \n",
      "9132        0.079508       0.056744   0.041172     0.151034  ...        0.0   \n",
      "9133        0.079426       0.056686   0.041130     0.150878  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.000000         0.000000         0.275492         0.000000   \n",
      "1            0.289101         0.000000         0.000000         0.000000   \n",
      "2            0.000000         0.000000         0.289057         0.000000   \n",
      "3            0.000000         0.000000         0.000000         0.000000   \n",
      "4            0.305998         0.000000         0.000000         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "9129         0.000000         0.262384         0.000000         0.000000   \n",
      "9130         0.000000         0.000000         0.000000         0.295146   \n",
      "9131         0.000000         0.000000         0.000000         0.261903   \n",
      "9132         0.294824         0.000000         0.000000         0.000000   \n",
      "9133         0.294519         0.000000         0.000000         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000          0.000000              0.275492   \n",
      "1            0.000000          0.000000              0.289101   \n",
      "2            0.000000          0.289057              0.000000   \n",
      "3            0.263643          0.000000              0.263643   \n",
      "4            0.000000          0.000000              0.000000   \n",
      "...               ...               ...                   ...   \n",
      "9129         0.000000          0.000000              0.262384   \n",
      "9130         0.000000          0.000000              0.295146   \n",
      "9131         0.000000          0.000000              0.261903   \n",
      "9132         0.000000          0.000000              0.294824   \n",
      "9133         0.000000          0.294519              0.000000   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0             0.000000  0.0  \n",
      "1             0.000000  0.0  \n",
      "2             0.000000  0.0  \n",
      "3             0.000000  0.0  \n",
      "4             0.305998  1.0  \n",
      "...                ...  ...  \n",
      "9129          0.000000  0.0  \n",
      "9130          0.000000  0.0  \n",
      "9131          0.000000  0.0  \n",
      "9132          0.000000  0.0  \n",
      "9133          0.000000  0.0  \n",
      "\n",
      "[9134 rows x 58 columns]\n",
      "=====================================================================================\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['dir_log_group']\n",
      "Results are stored in: ['dir_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  [0.10201871]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: [0.06578876]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 137\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: [0.13186467]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 65, Test = 75\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.17\n",
      "  Test Accuracy (TNR): 0.97\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [1.38642596]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3048, Test = 3059\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: [0.08122537]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 392, Test = 382\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.36\n",
      "  Test Accuracy (TNR): 0.72\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.89250403]\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['rew_log_group']\n",
      "Results are stored in: ['rew_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.1576533]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: [0.28992665]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 137\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.80\n",
      "  Optimal thershold: [0.34884462]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 65, Test = 75\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.28\n",
      "  Test Accuracy (TNR): 0.85\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: [0.47891531]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3048, Test = 3059\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: [0.0772245]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 392, Test = 382\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.92\n",
      "  Optimal thershold: [1.07688755]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['eg_log_group']\n",
      "Results are stored in: ['eg_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: [0.31471074]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 137\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.68\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.35\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: [0.27195577]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 65, Test = 75\n",
      "  AUC: 0.89\n",
      "  Privacy Risk: 0.83\n",
      "  Accuracy: 0.81\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.65\n",
      "  Positive predictive value: 0.89\n",
      "  Optimal thershold: [0.46203546]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3048, Test = 3059\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: [0.09431068]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 392, Test = 382\n",
      "  AUC: 0.90\n",
      "  Privacy Risk: 0.86\n",
      "  Accuracy: 0.86\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.72\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.49429632]\n",
      ")\n",
      "dir_log_group deleted.\n",
      "eg_log_group deleted.\n",
      "rew_log_group deleted.\n",
      "syn_log_group deleted.\n",
      "un_log_group deleted.\n",
      "dir_log_pop deleted.\n",
      "eg_log_pop deleted.\n",
      "rew_log_pop deleted.\n",
      "syn_log_pop deleted.\n",
      "un_log_pop deleted.\n"
     ]
    }
   ],
   "source": [
    "# favorable and unfavorable labels and feature_names\n",
    "f_label = dataset_orig.favorable_label\n",
    "uf_label = dataset_orig.unfavorable_label\n",
    "feature_names = dataset_orig.feature_names\n",
    "\n",
    "try:\n",
    "    # run mitigating algorithms\n",
    "    for i in range(N):\n",
    "        print('ITERATION ', i)\n",
    "        dataset_orig_train, dataset_orig_val, dataset_orig_test, target_dataset, reference_dataset = prepare_datasets()\n",
    "\n",
    "        # check fairness on the original data\n",
    "        metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                                     unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "        print(\"privileged vs. unprivileged: \", metric_orig_train.num_positives(privileged=True) + metric_orig_train.num_negatives(privileged=True), metric_orig_train.num_positives(privileged=False) + metric_orig_train.num_negatives(privileged=False)) \n",
    "        base_rate_unprivileged = metric_orig_train.base_rate(privileged=False)\n",
    "        base_rate_privileged = metric_orig_train.base_rate(privileged=True)\n",
    "\n",
    "        print('base_pos unpriv: ', base_rate_unprivileged)\n",
    "        print('base_pos priv: ', base_rate_privileged)\n",
    "\n",
    "        print(\"DIFFERENCE IS GOOD\")\n",
    "        print('base_pos unpriv: ', base_rate_unprivileged)\n",
    "        print('base_pos priv: ', base_rate_privileged)\n",
    "\n",
    "        # favorable and unfavorable labels and feature_names\n",
    "        f_label = dataset_orig.favorable_label\n",
    "        uf_label = dataset_orig.unfavorable_label\n",
    "        feature_names = dataset_orig.feature_names\n",
    "\n",
    "        # introduce label or selection biases, assuming the original data is fair\n",
    "        if BIAS_TYPE == 'label':\n",
    "            dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "        elif BIAS_TYPE == 'selection':\n",
    "            dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "        else:\n",
    "            print('no bias type specified')\n",
    "\n",
    "        # show data info\n",
    "        print(\"#### Training Dataset shape\")\n",
    "        print(dataset_orig_train.features.shape)\n",
    "        print(\"#### Favorable and unfavorable labels\")\n",
    "        print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "        print(\"#### Protected attribute names\")\n",
    "        print(dataset_orig_train.protected_attribute_names)\n",
    "        print(\"#### Privileged and unprivileged protected groups\")\n",
    "        print(privileged_groups, unprivileged_groups)\n",
    "        print(\"#### Privileged and unprivileged protected attribute values\")\n",
    "        print(dataset_orig_train.privileged_protected_attributes, dataset_orig_train.unprivileged_protected_attributes)\n",
    "        print(\"#### Dataset feature names\")\n",
    "        print(dataset_orig_train.feature_names)\n",
    "        print('number of favorable labels: ', np.count_nonzero(dataset_orig_train.labels==f_label))\n",
    "        print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "        # statistics of favored/positive class BEFORE transf \n",
    "        priv_metric_orig['total_priv'] += metric_orig_train.num_instances(privileged = True) \n",
    "        priv_metric_orig['total_unpriv'] += metric_orig_train.num_instances(privileged = False) \n",
    "        favor_metric_orig['total_favor'] += metric_orig_train.base_rate()\n",
    "        favor_metric_orig['total_unfavor'] += 1 - metric_orig_train.base_rate()\n",
    "        favor_metric_orig['priv_favor'] += metric_orig_train.base_rate(privileged = True)\n",
    "        favor_metric_orig['priv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = True)\n",
    "        favor_metric_orig['unpriv_favor'] += metric_orig_train.base_rate(privileged = False)\n",
    "        favor_metric_orig['unpriv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = False)\n",
    "\n",
    "        print(\"#### Train shape, validation shape, test shape\")\n",
    "        print(dataset_orig_train.features.shape, dataset_orig_val.features.shape, dataset_orig_test.features.shape)\n",
    "\n",
    "        # testing mitigation methods \n",
    "        test_cases = TestAlgorithms(BASELINE)\n",
    "\n",
    "        # null mitigator\n",
    "        orig_metrics, orig_mia_metrics = test_cases.run_original(dataset_orig_train, dataset_orig_val, dataset_orig_test, BASELINE, orig_metrics, orig_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset) \n",
    "\n",
    "        # synthetic data mitigator\n",
    "        metric_transf_train, transf_metrics, transf_mia_metrics = test_cases.run_oversample(dataset_orig_train, dataset_orig_val, dataset_orig_test, privileged_groups, unprivileged_groups, base_rate_privileged, base_rate_unprivileged, BASELINE, transf_metrics, transf_mia_metrics, f_label, uf_label, ATTACK, THRESH_ARR, DISPLAY, OS_MODE, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        # statistics of favored/positive class AFTER transf\n",
    "        favor_metric_transf['total_favor'] += metric_transf_train.base_rate()\n",
    "        favor_metric_transf['total_unfavor'] += 1 - metric_transf_train.base_rate()\n",
    "        favor_metric_transf['priv_favor'] += metric_transf_train.base_rate(privileged = True)\n",
    "        favor_metric_transf['priv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = True)\n",
    "        favor_metric_transf['unpriv_favor'] += metric_transf_train.base_rate(privileged = False)\n",
    "        favor_metric_transf['unpriv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = False)\n",
    "\n",
    "        # dir mitigator\n",
    "        dir_metrics, dir_mia_metrics = test_cases.run_dir(dataset_orig_train, dataset_orig_val, dataset_orig_test,  sens_attr, BASELINE, dir_metrics, dir_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset) \n",
    "\n",
    "        # reweigh mitigator\n",
    "        reweigh_metrics, reweigh_mia_metrics = test_cases.run_rew(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, reweigh_metrics, reweigh_mia_metrics, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        # eg mitigator, in-processing\n",
    "        eg_metrics, eg_mia_metrics = test_cases.run_eg(dataset_orig_train, dataset_orig_val, dataset_orig_test, eg_metrics, eg_mia_metrics, BASELINE, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        # cpp mitigator\n",
    "    #     cpp_metrics, cpp_mia_metrics = test_cases.run_cpp(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, cpp_metrics, cpp_mia_metrics, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        delete_logs()\n",
    "except ValueError as e:\n",
    "    print(\"Error detected: No samples generated. Adjusting datasets...\")\n",
    "    delete_logs()\n",
    "    # percentage of favor and unfavor\n",
    "    priv_metric_orig = defaultdict(float)\n",
    "    favor_metric_orig = defaultdict(float)\n",
    "    favor_metric_transf = defaultdict(float)\n",
    "\n",
    "    # for each pre-processing approach, we create a mia_metric_results\n",
    "    orig_metrics = defaultdict(list)\n",
    "    orig_mia_metrics = defaultdict(list)\n",
    "\n",
    "    transf_metrics = defaultdict(list) \n",
    "    transf_mia_metrics = defaultdict(list) \n",
    "\n",
    "    reweigh_metrics = defaultdict(list) \n",
    "    reweigh_mia_metrics = defaultdict(list) \n",
    "\n",
    "    dir_metrics = defaultdict(list) \n",
    "    dir_mia_metrics = defaultdict(list) \n",
    "\n",
    "    eg_metrics = defaultdict(list) \n",
    "    eg_mia_metrics = defaultdict(list) \n",
    "    # run mitigating algorithms\n",
    "    for i in range(N):\n",
    "        print('ITERATION ', i)\n",
    "        dataset_orig_train, dataset_orig_val, dataset_orig_test, target_dataset, reference_dataset = prepare_datasets()\n",
    "\n",
    "        # check fairness on the original data\n",
    "        metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                                     unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "        print(\"privileged vs. unprivileged: \", metric_orig_train.num_positives(privileged=True) + metric_orig_train.num_negatives(privileged=True), metric_orig_train.num_positives(privileged=False) + metric_orig_train.num_negatives(privileged=False)) \n",
    "        base_rate_unprivileged = metric_orig_train.base_rate(privileged=False)\n",
    "        base_rate_privileged = metric_orig_train.base_rate(privileged=True)\n",
    "\n",
    "        print('base_pos unpriv: ', base_rate_unprivileged)\n",
    "        print('base_pos priv: ', base_rate_privileged)\n",
    "\n",
    "        while(base_rate_privileged >= base_rate_unprivileged and (base_rate_privileged - base_rate_unprivileged) <= 0.05):\n",
    "            print(\"DIFFERENCE IS TOO LOW, GETTING DATASETS AGAIN\")\n",
    "            dataset_orig_train, dataset_orig_val, dataset_orig_test, target_dataset, reference_dataset = prepare_datasets()\n",
    "             # check fairness on the original data\n",
    "            metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                                         unprivileged_groups=unprivileged_groups,\n",
    "                                                         privileged_groups=privileged_groups)\n",
    "            print(\"privileged vs. unprivileged: \", metric_orig_train.num_positives(privileged=True) + metric_orig_train.num_negatives(privileged=True), metric_orig_train.num_positives(privileged=False) + metric_orig_train.num_negatives(privileged=False)) \n",
    "            base_rate_unprivileged = metric_orig_train.base_rate(privileged=False)\n",
    "            base_rate_privileged = metric_orig_train.base_rate(privileged=True)\n",
    "\n",
    "        print(\"DIFFERENCE IS GOOD\")\n",
    "        print('base_pos unpriv: ', base_rate_unprivileged)\n",
    "        print('base_pos priv: ', base_rate_privileged)\n",
    "\n",
    "        # favorable and unfavorable labels and feature_names\n",
    "        f_label = dataset_orig.favorable_label\n",
    "        uf_label = dataset_orig.unfavorable_label\n",
    "        feature_names = dataset_orig.feature_names\n",
    "\n",
    "        # introduce label or selection biases, assuming the original data is fair\n",
    "        if BIAS_TYPE == 'label':\n",
    "            dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "        elif BIAS_TYPE == 'selection':\n",
    "            dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "        else:\n",
    "            print('no bias type specified')\n",
    "\n",
    "        # show data info\n",
    "        print(\"#### Training Dataset shape\")\n",
    "        print(dataset_orig_train.features.shape)\n",
    "        print(\"#### Favorable and unfavorable labels\")\n",
    "        print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "        print(\"#### Protected attribute names\")\n",
    "        print(dataset_orig_train.protected_attribute_names)\n",
    "        print(\"#### Privileged and unprivileged protected groups\")\n",
    "        print(privileged_groups, unprivileged_groups)\n",
    "        print(\"#### Privileged and unprivileged protected attribute values\")\n",
    "        print(dataset_orig_train.privileged_protected_attributes, dataset_orig_train.unprivileged_protected_attributes)\n",
    "        print(\"#### Dataset feature names\")\n",
    "        print(dataset_orig_train.feature_names)\n",
    "        print('number of favorable labels: ', np.count_nonzero(dataset_orig_train.labels==f_label))\n",
    "        print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "        # statistics of favored/positive class BEFORE transf \n",
    "        priv_metric_orig['total_priv'] += metric_orig_train.num_instances(privileged = True) \n",
    "        priv_metric_orig['total_unpriv'] += metric_orig_train.num_instances(privileged = False) \n",
    "        favor_metric_orig['total_favor'] += metric_orig_train.base_rate()\n",
    "        favor_metric_orig['total_unfavor'] += 1 - metric_orig_train.base_rate()\n",
    "        favor_metric_orig['priv_favor'] += metric_orig_train.base_rate(privileged = True)\n",
    "        favor_metric_orig['priv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = True)\n",
    "        favor_metric_orig['unpriv_favor'] += metric_orig_train.base_rate(privileged = False)\n",
    "        favor_metric_orig['unpriv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = False)\n",
    "\n",
    "        print(\"#### Train shape, validation shape, test shape\")\n",
    "        print(dataset_orig_train.features.shape, dataset_orig_val.features.shape, dataset_orig_test.features.shape)\n",
    "\n",
    "        # testing mitigation methods \n",
    "        test_cases = TestAlgorithms(BASELINE)\n",
    "\n",
    "        # null mitigator\n",
    "        orig_metrics, orig_mia_metrics = test_cases.run_original(dataset_orig_train, dataset_orig_val, dataset_orig_test, BASELINE, orig_metrics, orig_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset) \n",
    "        print(\"ORIG MIA METRICS \", orig_mia_metrics)\n",
    "        \n",
    "        # synthetic data mitigator\n",
    "        metric_transf_train, transf_metrics, transf_mia_metrics = test_cases.run_oversample(dataset_orig_train, dataset_orig_val, dataset_orig_test, privileged_groups, unprivileged_groups, base_rate_privileged, base_rate_unprivileged, BASELINE, transf_metrics, transf_mia_metrics, f_label, uf_label, ATTACK, THRESH_ARR, DISPLAY, OS_MODE, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        # statistics of favored/positive class AFTER transf\n",
    "        favor_metric_transf['total_favor'] += metric_transf_train.base_rate()\n",
    "        favor_metric_transf['total_unfavor'] += 1 - metric_transf_train.base_rate()\n",
    "        favor_metric_transf['priv_favor'] += metric_transf_train.base_rate(privileged = True)\n",
    "        favor_metric_transf['priv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = True)\n",
    "        favor_metric_transf['unpriv_favor'] += metric_transf_train.base_rate(privileged = False)\n",
    "        favor_metric_transf['unpriv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = False)\n",
    "\n",
    "        # dir mitigator\n",
    "        dir_metrics, dir_mia_metrics = test_cases.run_dir(dataset_orig_train, dataset_orig_val, dataset_orig_test,  sens_attr, BASELINE, dir_metrics, dir_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset) \n",
    "\n",
    "        # reweigh mitigator\n",
    "        reweigh_metrics, reweigh_mia_metrics = test_cases.run_rew(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, reweigh_metrics, reweigh_mia_metrics, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        # eg mitigator, in-processing\n",
    "        eg_metrics, eg_mia_metrics = test_cases.run_eg(dataset_orig_train, dataset_orig_val, dataset_orig_test, eg_metrics, eg_mia_metrics, BASELINE, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        # cpp mitigator\n",
    "    #     cpp_metrics, cpp_mia_metrics = test_cases.run_cpp(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, cpp_metrics, cpp_mia_metrics, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        delete_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a163caa5",
   "metadata": {},
   "source": [
    "## Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47b50fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dictionary to store SHAP values\n",
    "# shap_results = {\n",
    "#     \"orig\": orig_metrics['shap_values'],\n",
    "#     \"transf\": transf_metrics['shap_values'],\n",
    "#     \"dir\": dir_metrics['shap_values'],\n",
    "#     \"reweigh\": reweigh_metrics['shap_values'],\n",
    "#     \"eg\": eg_metrics['shap_values']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2293e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_results = pd.DataFrame.from_dict(shap_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # File path\n",
    "# today = datetime.now().strftime('%Y-%m-%d')\n",
    "# file_path = f\"./mia2_results/rf_{ATTACK}_{DATASET}_shap_values_{today}.csv\"\n",
    "\n",
    "# # Save to CSV\n",
    "# shap_results.to_csv(file_path, index=True)\n",
    "\n",
    "# file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90de2a9",
   "metadata": {},
   "source": [
    "## Display Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72632350",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig_copy = priv_metric_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8530a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b736dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c736a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73a4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig = priv_metric_orig_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf623751",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "print('1)\\n')\n",
    "print(DATASET)\n",
    "print(dataset_orig_train.features.shape[0])\n",
    "\n",
    "print('2)\\n')\n",
    "priv_metric_orig = {k: [v/N] for (k,v) in priv_metric_orig.items()}\n",
    "results = [priv_metric_orig]\n",
    "tr = pd.Series(['orig'], name='num_instance')\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis = 0).set_index([tr])\n",
    "print(df)\n",
    "\n",
    "print('3)\\n')\n",
    "favor_metric_orig = {k: [v/N] for (k,v) in favor_metric_orig.items()}\n",
    "favor_metric_transf = {k: [v/N] for (k,v) in favor_metric_transf.items()}\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "results = [favor_metric_orig, favor_metric_transf]\n",
    "tr = pd.Series(['orig'] + ['transf'], name='dataset')\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis = 0).set_index([tr])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5039b1e0",
   "metadata": {},
   "source": [
    "# Train/Test Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef1ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_metrics(metrics):\n",
    "    accuracy_metrics = defaultdict(list)\n",
    "\n",
    "    # List of accuracy-related keys\n",
    "    accuracy_keys = [\n",
    "        'accuracy_train_0_-', 'accuracy_train_0_+',\n",
    "        'accuracy_train_1_-', 'accuracy_train_1_+',\n",
    "        'accuracy_test_0_-', 'accuracy_test_0_+',\n",
    "        'accuracy_test_1_-', 'accuracy_test_1_+',\n",
    "        'accuracy_train', 'accuracy_test'\n",
    "    ]\n",
    "\n",
    "    # Separate accuracy metrics into a new dictionary\n",
    "    for key in accuracy_keys:\n",
    "        if key in metrics:\n",
    "            accuracy_metrics[key] = metrics.pop(key)\n",
    "\n",
    "    return metrics, accuracy_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e982d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_metrics, orig_acc = separate_metrics(orig_metrics)\n",
    "transf_metrics, transf_acc = separate_metrics(transf_metrics)\n",
    "reweigh_metrics, reweigh_acc = separate_metrics(reweigh_metrics)\n",
    "dir_metrics, dir_acc = separate_metrics(dir_metrics)\n",
    "eg_metrics, eg_acc = separate_metrics(eg_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8cc8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std_accuracy(acc_metrics):\n",
    "    mean_std_accuracies = {\n",
    "        key: {\n",
    "            \"mean\": sum(values) / len(values),\n",
    "            \"std\": statistics.stdev(values) if len(values) > 1 else 0  # Avoid error if only one value\n",
    "        }\n",
    "        for key, values in acc_metrics.items()\n",
    "    }\n",
    "    return mean_std_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_acc_stats = calculate_mean_std_accuracy(orig_acc)\n",
    "transf_acc_stats = calculate_mean_std_accuracy(transf_acc)\n",
    "reweigh_acc_stats = calculate_mean_std_accuracy(reweigh_acc)\n",
    "dir_acc_stats = calculate_mean_std_accuracy(dir_acc)\n",
    "eg_acc_stats = calculate_mean_std_accuracy(eg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae83fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary to DataFrame with mean and std\n",
    "train_test_data = {\n",
    "    \"orig_acc_mean\": {key: value[\"mean\"] for key, value in orig_acc_stats.items()},\n",
    "    \"orig_acc_std\": {key: value[\"std\"] for key, value in orig_acc_stats.items()},\n",
    "    \"transf_acc_mean\": {key: value[\"mean\"] for key, value in transf_acc_stats.items()},\n",
    "    \"transf_acc_std\": {key: value[\"std\"] for key, value in transf_acc_stats.items()},\n",
    "    \"reweigh_acc_mean\": {key: value[\"mean\"] for key, value in reweigh_acc_stats.items()},\n",
    "    \"reweigh_acc_std\": {key: value[\"std\"] for key, value in reweigh_acc_stats.items()},\n",
    "    \"dir_acc_mean\": {key: value[\"mean\"] for key, value in dir_acc_stats.items()},\n",
    "    \"dir_acc_std\": {key: value[\"std\"] for key, value in dir_acc_stats.items()},\n",
    "    \"eg_acc_mean\": {key: value[\"mean\"] for key, value in eg_acc_stats.items()},\n",
    "    \"eg_acc_std\": {key: value[\"std\"] for key, value in eg_acc_stats.items()},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063eb6e5",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccdbe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary to DataFrame\n",
    "train_test_df = pd.DataFrame(train_test_data)\n",
    "\n",
    "# File path\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "file_path = f\"./dprf_new_mia2_results/{BASELINE}_{ATTACK}_{DATASET}_train_test_accuracies_{today}_depth29_eps1.csv\"\n",
    "\n",
    "# Save to CSV\n",
    "train_test_df.to_csv(file_path, index=True)\n",
    "\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd3105",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8158ae75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb16e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance_df = pd.DataFrame(orig_metrics[\"feature_importances\"])  # Extract feature importance across runs\n",
    "# feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a78a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "print('4)\\n')\n",
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_error_metrics = {k: [statistics.stdev(v)] for (k,v) in orig_metrics.items()}\n",
    "transf_error_metrics = {k: [statistics.stdev(v)] for (k,v) in transf_metrics.items()}\n",
    "reweigh_error_metrics = {k: [statistics.stdev(v)] for (k,v) in reweigh_metrics.items()}\n",
    "dir_error_metrics = {k: [statistics.stdev(v)] for (k,v) in dir_metrics.items()}\n",
    "eg_error_metrics = {k: [statistics.stdev(v)] for (k,v) in eg_metrics.items()}\n",
    "# pr_orig_error_metrics = {k: [statistics.stdev(v)] for (k,v) in pr_orig_metrics.items()}\n",
    "# cpp_error_metrics = {k: [statistics.stdev(v)] for (k,v) in cpp_metrics.items()}\n",
    "# ro_error_metrics = {k: [statistics.stdev(v)] for (k,v) in ro_metrics.items()}\n",
    "\n",
    "# mean value metrics\n",
    "orig_metrics_mean = {k: [sum(v)/N] for (k,v) in orig_metrics.items()}\n",
    "transf_metrics_mean = {k: [sum(v)/N] for (k,v) in transf_metrics.items()}\n",
    "reweigh_metrics_mean = {k:[sum(v)/N] for (k,v) in reweigh_metrics.items()}\n",
    "dir_metrics_mean = {k:[sum(v)/N] for (k,v) in dir_metrics.items()}\n",
    "eg_metrics_mean = {k:[sum(v)/N] for (k,v) in eg_metrics.items()}\n",
    "# pr_orig_metrics_mean = {k: [sum(v)/N] for (k,v) in pr_orig_metrics.items()}\n",
    "# cpp_metrics_mean = {k: [sum(v)/N] for (k,v) in cpp_metrics.items()}\n",
    "# ro_metrics_mean = {k: [sum(v)/N] for (k,v) in ro_metrics.items()}\n",
    "\n",
    "# Python paired sample t-test\n",
    "# from scipy.stats import ttest_rel\n",
    "# def paired_t (a, b):\n",
    "#     np_a = np.array(a)\n",
    "#     np_b = np.array(b)\n",
    "#     s, p = ttest_rel(np.absolute(np_a), np.absolute(np_b))\n",
    "#     return p\n",
    "\n",
    "# def acc_diff (a, b):\n",
    "#     np_a = np.array(a)\n",
    "#     np_b = np.array(b)\n",
    "#     delta = np_a - np_b\n",
    "#     m = statistics.mean(delta)\n",
    "#     s = statistics.stdev(delta)\n",
    "#     return [m, s]\n",
    "\n",
    "# if BASELINE == 'lr':\n",
    "#     plot_algo_lr(orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, eg_metrics_mean, pr_orig_metrics_mean, orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, eg_error_metrics, BASELINE)\n",
    "#     stat =  {k: [paired_t(transf_metrics[k], v)] for (k,v) in orig_metrics.items()}\n",
    "#     print(\"5)\")\n",
    "#     print(stat)\n",
    "# else:\n",
    "#     plot_algo(orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, eg_metrics_mean, orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, eg_error_metrics, BASELINE)\n",
    "#     stat =  {k: [paired_t(transf_metrics[k], v)] for (k,v) in orig_metrics.items()}\n",
    "#     print(stat)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1627a85",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f14ab",
   "metadata": {},
   "source": [
    "### Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c6d438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type=BASELINE\n",
    "# Set up plotting options\n",
    "plt.rcParams.update({'font.size': 8})  # Set global font size\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "\n",
    "# Metrics and errors as lists of dictionaries\n",
    "results = [orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, eg_metrics_mean]\n",
    "errors = [orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, eg_error_metrics]\n",
    "\n",
    "# Classifier bias mitigators (for labels)\n",
    "index = pd.Series(\n",
    "    [model_type+'_orig', model_type+'_syn', model_type+'_dir', model_type+'_rew', model_type+'_eg'])\n",
    "\n",
    "# Create DataFrame for metrics and error bars\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis=0).set_index(index)\n",
    "df_error = pd.concat([pd.DataFrame(metrics) for metrics in errors], axis=0).set_index(index)\n",
    "\n",
    "# Dynamically generate titles for all metrics in df\n",
    "titles = list(df.columns)\n",
    "\n",
    "# Plot fairness metrics with error bars\n",
    "ax = df.plot.bar(\n",
    "    yerr=df_error, \n",
    "    capsize=2, \n",
    "    rot=0, \n",
    "    subplots=True, \n",
    "    title=titles, \n",
    "    fontsize=8, \n",
    "    figsize=(7, 10),  # Reduced overall figure size\n",
    "    legend=True,\n",
    "    width=0.7  # Adjusted bar width to make bars closer\n",
    ")\n",
    "\n",
    "# Adjust Y-axis limits dynamically based on metric names\n",
    "for i, subplot in enumerate(ax):\n",
    "    metric = titles[i]\n",
    "    if \"fpr\" in metric or \"fnr\" in metric:  # Subgroup-specific metrics\n",
    "        subplot.set_ylim([0, 1])  # False positive/negative rates range from 0 to 1\n",
    "    elif metric in [\"bal_acc\", \"disp_imp\", \"theil_ind\"]:  # General metrics\n",
    "        subplot.set_ylim([0, 1])\n",
    "    elif metric in [\"avg_odds_diff\", \"stat_par_diff\", \"eq_opp_diff\"]:  # Difference metrics\n",
    "        subplot.set_ylim([-0.5, 0.5])  # Allow for negative values\n",
    "\n",
    "    # Move legend inside the plot\n",
    "    subplot.legend(loc='upper left', fontsize=8, frameon=True)\n",
    "\n",
    "# Tight layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a118582a",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c52e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of method names corresponding to results/errors\n",
    "method_names = [\"orig\", \"transf\", \"dir\", \"rew\", \"eg\"]\n",
    "\n",
    "# Initialize a list to hold data for the DataFrame\n",
    "fairness_data = []\n",
    "\n",
    "# Populate the data list with metrics and errors\n",
    "for method, metric, error in zip(method_names, results, errors):\n",
    "    for key in metric.keys():\n",
    "        fairness_data.append({\n",
    "            \"Method\": method,\n",
    "            \"Metric\": key,\n",
    "            \"Mean\": metric[key][0],  # Assuming the metric values are single-item lists\n",
    "            \"Error\": error[key][0]   # Assuming the error values are single-item lists\n",
    "        })\n",
    "\n",
    "# Create DataFrame from the data list\n",
    "fairness_df = pd.DataFrame(fairness_data)\n",
    "\n",
    "# File path with today's date\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "file_path = f\"./dprf_new_mia2_results/{BASELINE}_{ATTACK}_{DATASET}_fairness_metrics_{today}_depth29_eps1.csv\"\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "fairness_df.to_csv(file_path, index=True)\n",
    "\n",
    "print(f\"File saved at: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7aff8d",
   "metadata": {},
   "source": [
    "## Visualization of MIA results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588cc377",
   "metadata": {},
   "source": [
    "\n",
    "### Visualization of MIA Attacks against various Fairness Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a42bd",
   "metadata": {},
   "source": [
    "#### Privacy risk subpopulations vs Fairness with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dddfde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "%matplotlib inline\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "eg_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in eg_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "# cpp_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in cpp_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "eg_mia_metrics_mean = {k:sum(v)/N for (k,v) in eg_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "# cpp_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6882740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "           orig_mia_error_metrics,\n",
    "           transf_mia_metrics_mean,\n",
    "           transf_mia_error_metrics,\n",
    "           dir_mia_metrics_mean,\n",
    "           dir_mia_error_metrics,\n",
    "           reweigh_mia_metrics_mean,\n",
    "           reweigh_mia_error_metrics,\n",
    "           eg_mia_metrics_mean,\n",
    "           eg_mia_error_metrics\n",
    "          ]\n",
    "\n",
    "index = pd.Series(['orig'] + ['orig_std'] + ['syn'] + ['syn_std'] + ['dir'] + ['dir_std'] + ['rew'] + \n",
    "                  ['rew_std'] + ['eg'] + ['eg_std'], name='Classifier MIA Attacks')\n",
    "#                   + ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0aab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [orig_mia_metrics_mean,\n",
    "           transf_mia_metrics_mean,\n",
    "           dir_mia_metrics_mean,\n",
    "           reweigh_mia_metrics_mean,\n",
    "           eg_mia_metrics_mean,\n",
    "          ]\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "          transf_mia_error_metrics,\n",
    "          dir_mia_error_metrics,\n",
    "          reweigh_mia_error_metrics,\n",
    "          eg_mia_error_metrics\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df1431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = df[['subpopulation_0.0_label_0.0_mia_privacy_risk',\n",
    "       'subpopulation_1.0_label_0.0_mia_privacy_risk',\n",
    "                       'subpopulation_0.0_label_1.0_mia_privacy_risk',\n",
    "       'subpopulation_1.0_label_1.0_mia_privacy_risk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e94927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = df_groups.rename(columns={'subpopulation_0.0_label_0.0_mia_privacy_risk': 'G0-',\n",
    "                           'subpopulation_1.0_label_0.0_mia_privacy_risk': 'G1-',\n",
    "                           'subpopulation_0.0_label_1.0_mia_privacy_risk': 'G0+',\n",
    "                           'subpopulation_1.0_label_1.0_mia_privacy_risk': 'G1+'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d711e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f230c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225fcad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tabular Format\n",
    "# importing the modules\n",
    "from tabulate import tabulate\n",
    "\n",
    " \n",
    "# displaying the DataFrame\n",
    "print(tabulate(df_groups.T, headers = 'keys', tablefmt = 'simple'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7040e9bb",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696b6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7b42a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of method names corresponding to results/errors\n",
    "method_names = [\"orig\", \"transf\", \"dir\", \"rew\", \"eg\"]\n",
    "\n",
    "# Initialize a list to hold data for the DataFrame\n",
    "pr_data = []\n",
    "\n",
    "# Populate the data list with metrics and errors\n",
    "for method, metric, error in zip(method_names, results, errors):\n",
    "    for key in metric.keys():\n",
    "        pr_data.append({\n",
    "            \"Method\": method,\n",
    "            \"Metric\": key,\n",
    "            \"Mean Privacy Risk\": metric[key],  # Privacy risk mean\n",
    "            \"Error\": error[key]               # Privacy risk error\n",
    "        })\n",
    "\n",
    "# Create DataFrame from the data list\n",
    "pr_df = pd.DataFrame(pr_data)\n",
    "\n",
    "# File path with today's date\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "file_path = f\"./dprf_new_mia2_results/{BASELINE}_{ATTACK}_{DATASET}_mia_privacy_risks_metrics_{today}_depth29_eps1.csv\"\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "pr_df.to_csv(file_path, index=True)\n",
    "\n",
    "print(f\"File saved at: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f69948e",
   "metadata": {},
   "source": [
    "# Main Bar Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99444ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subpopulations and fairness methods\n",
    "subpopulations = {\n",
    "    'subpopulation_0.0_label_0.0_mia_privacy_risk': \"Unprivileged Unfavorable\", \n",
    "    'subpopulation_0.0_label_1.0_mia_privacy_risk': \"Unprivileged Favorable\", \n",
    "    'subpopulation_1.0_label_0.0_mia_privacy_risk': \"Privileged Unfavorable\",\n",
    "    'subpopulation_1.0_label_1.0_mia_privacy_risk': \"Privileged Favorable\"\n",
    "}\n",
    "\n",
    "fairness_methods = [\"syn\", \"dir\", \"rew\", \"eg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84957cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine results into a list\n",
    "all_results = [\n",
    "    transf_mia_metrics_mean,\n",
    "    dir_mia_metrics_mean,\n",
    "    reweigh_mia_metrics_mean,\n",
    "    eg_mia_metrics_mean\n",
    "]\n",
    "\n",
    "# Organize data for plotting\n",
    "data = {subpopulations[key]: [results[key] for results in all_results] for key in subpopulations.keys()}\n",
    "orig_values = orig_mia_metrics_mean\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "idx = 0\n",
    "\n",
    "for key, value in subpopulations.items():\n",
    "    accuracies = data[value]\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot bar chart (excluding 'orig')\n",
    "    ax.bar(fairness_methods, accuracies, color='skyblue', edgecolor='black')\n",
    "    \n",
    "    # Add dashed line for 'orig' MIA accuracy\n",
    "    ax.axhline(orig_values[key], color='red', linestyle='--', label='Orig MIA')\n",
    "    \n",
    "    # Title and labels\n",
    "    ax.set_title(f\"MIA Accuracies - {value}\", fontsize=10)\n",
    "    ax.set_ylabel(\"MIA Accuracy\")\n",
    "    ax.set_xticks(np.arange(len(fairness_methods)))\n",
    "    ax.set_xticklabels(fairness_methods, rotation=45)\n",
    "    ax.legend()\n",
    "    \n",
    "    idx = idx + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a2e6d",
   "metadata": {},
   "source": [
    "### Visualizing using novel technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faed82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_error_metrics = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "eg_mia_error_metrics = {k: v for (k,v) in eg_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "#orig_mia_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_error_metrics.keys():\n",
    "    for val in orig_mia_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in eg_mia_error_metrics.keys():\n",
    "    for val in eg_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"eg\", key.replace(\"_mia_attacker_advantage\", \"\"), val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b110698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"Privacy Risk\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8a5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only subgroups\n",
    "df_subgroups = df[~((df[\"MIA\"] == \"entire_dataset_label_0.0_mia_privacy_risk\") | (df[\"MIA\"] == \"entire_dataset_label_1.0_mia_privacy_risk\")) ]\n",
    "df_subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df3d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15,8))\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df_subgroups, x=\"MIA\", y=\"Privacy Risk\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Privacy Risk\" )\n",
    "g.set(ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359dc0bf",
   "metadata": {},
   "source": [
    "### ROC curves and AUC scores with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7b52ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for orig dataset with different subpopulations\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for key in [\"entire_dataset_mia_result\", \n",
    "            \"subpopulation_0.0_label_0.0_mia_result\",\n",
    "            \"subpopulation_0.0_label_1.0_mia_result\", \n",
    "            \"subpopulation_1.0_label_0.0_mia_result\",\n",
    "            \"subpopulation_1.0_label_1.0_mia_result\"]:\n",
    "     # fprs = [mia_res.fpr for mia_res in orig_mia_metrics[key]]\n",
    "    # tprs = [mia_res.tpr for mia_res in orig_mia_metrics[key]]\n",
    "    tprs = []\n",
    "    \n",
    "    # aucs = [mia_res.get_auc() for mia_res in orig_mia_metrics[key]]\n",
    "    aucs = []\n",
    "\n",
    "    # mean_fpr = np.mean(fprs, axis=0)\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "    for mia_res in orig_mia_metrics[key]:\n",
    "        interp_tpr = np.interp(mean_fpr, mia_res.fpr, mia_res.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(mia_res.get_auc())\n",
    "    \n",
    "    #print(mean_fpr)\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    \n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    \n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        #color=\"b\",\n",
    "        label=r\"Mean ROC for %s $\\pm$ 1 std. dev. (AUC = %0.2f $\\pm$ %0.2f)\" % ( key ,mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        #label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve with variability\",\n",
    ")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ff10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entire dataset with different subpopulations\n",
    "# fig, ax = plt.subplots(figsize=(12, 10))\n",
    "fig, ax = plt.subplots(figsize=(24, 18))\n",
    "\n",
    "for mia_metrics, name in zip([orig_mia_metrics, transf_mia_metrics], [\"orig\", \"syn\"]): \n",
    "#                               dir_mia_metrics, reweigh_mia_metrics], [\"orig\", \"syn\", \"dir\", \"reweigh\"] ):\n",
    "    for key in [\"entire_dataset_mia_result\", \n",
    "                \"subpopulation_0.0_label_0.0_mia_result\",\n",
    "                \"subpopulation_0.0_label_1.0_mia_result\", \n",
    "                \"subpopulation_1.0_label_0.0_mia_result\",\n",
    "                \"subpopulation_1.0_label_1.0_mia_result\"]:\n",
    "   \n",
    "        # fprs = [mia_res.fpr for mia_res in orig_mia_metrics[key]]\n",
    "        # tprs = [mia_res.tpr for mia_res in orig_mia_metrics[key]]\n",
    "        tprs = []\n",
    "        # aucs = [mia_res.get_auc() for mia_res in orig_mia_metrics[key]]\n",
    "        aucs = []\n",
    "\n",
    "        # mean_fpr = np.mean(fprs, axis=0)\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "        for mia_res in mia_metrics[key]:\n",
    "            print(mia_res)\n",
    "            interp_tpr = np.interp(mean_fpr, mia_res.fpr, mia_res.tpr)\n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "            aucs.append(mia_res.get_auc())\n",
    "\n",
    "        #print(mean_fpr)\n",
    "        print(tprs)\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std(aucs)\n",
    "\n",
    "        ax.plot(\n",
    "            mean_fpr,\n",
    "            mean_tpr,\n",
    "            #color=\"b\",\n",
    "            label=r\"%s Mean ROC for %s $\\pm$ 1 std. dev. (AUC = %0.2f $\\pm$ %0.2f)\" % (name, key ,mean_auc, std_auc),\n",
    "            lw=2,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        std_tpr = np.std(tprs, axis=0)\n",
    "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        ax.fill_between(\n",
    "            mean_fpr,\n",
    "            tprs_lower,\n",
    "            tprs_upper,\n",
    "            color=\"grey\",\n",
    "            alpha=0.2,\n",
    "            #label=r\"$\\pm$ 1 std. dev.\",\n",
    "        )\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve for MIA attacks against Fairness Approaches\",\n",
    ")\n",
    "ax.legend(loc=\"lower right\")\n",
    "# ax.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entire dataset\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "for mia_res in orig_mia_metrics[\"entire_dataset_mia_result\"]:\n",
    "    plt.plot(mia_res.fpr,mia_res.tpr,label=f\"{mia_res.get_name()} auc={mia_res.get_auc()}\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e701aad9",
   "metadata": {},
   "source": [
    "## MIA Attacks AUC vs Fairness Bar Chart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f18425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "egr_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in eg_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "eg_mia_metrics_mean = {k:sum(v)/N for (k,v) in eg_mia_metrics.items() if k.endswith(\"mia_auc\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b078a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuazlization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "        transf_mia_metrics_mean,\n",
    "        dir_mia_metrics_mean,\n",
    "        reweigh_mia_metrics_mean,\n",
    "        eg_mia_metrics_mean\n",
    "        ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "        transf_mia_error_metrics,\n",
    "        dir_mia_error_metrics,\n",
    "        reweigh_mia_error_metrics,\n",
    "          egr_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn']+ ['dir']+ ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2233661a",
   "metadata": {},
   "source": [
    "###  MIA Attackers Advantage Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f09191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data structures to plot point categorical plot from seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ef741",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "egr_mia_error_metrics = {k: v for (k,v) in eg_mia_metrics.items() if k.endswith(\"attacker_advantage\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_metrics_att_ad.keys():\n",
    "    for val in orig_mia_metrics_att_ad[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in egr_mia_error_metrics.keys():\n",
    "    for val in egr_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"egr\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "advantage_metrics_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105df8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"attacker_advantage\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac8578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting without scaling y limis to 1\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"attacker_advantage\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's Advantage\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf746e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15,8))\n",
    "\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"attacker_advantage\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's Advantage\" )\n",
    "g.set(ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b0356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(orig_mia_metrics_att_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "egr_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in eg_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "eg_mia_metrics_mean = {k:sum(v)/N for (k,v) in eg_mia_metrics.items() if k.endswith(\"attacker_advantage\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuazlization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "        transf_mia_metrics_mean,\n",
    "        dir_mia_metrics_mean,\n",
    "        reweigh_mia_metrics_mean,\n",
    "           eg_mia_metrics_mean\n",
    "        ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "        transf_mia_error_metrics,\n",
    "        dir_mia_error_metrics,\n",
    "        reweigh_mia_error_metrics,\n",
    "          egr_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn']+ ['dir']+ ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1309a4",
   "metadata": {},
   "source": [
    "## PPV Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "egr_mia_error_metrics = {k: v for (k,v) in eg_mia_metrics.items() if k.endswith(\"mia_ppv\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14018577",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_metrics_att_ad.keys():\n",
    "    for val in orig_mia_metrics_att_ad[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in egr_mia_error_metrics.keys():\n",
    "    for val in egr_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"egr\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "advantage_metrics_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95980069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"PPV\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff9b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting without scaling y limis to 1\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"PPV\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's PPV\" )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
