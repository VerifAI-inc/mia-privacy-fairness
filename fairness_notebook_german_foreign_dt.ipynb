{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8c9f6b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "151964f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4aa3557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset, BankDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f6016af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import StandardDataset\n",
    "StandardDataset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f57d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from data_utils import DatasetBuilder\n",
    "from metrics_utils import compute_metrics, describe_metrics, get_test_metrics, test\n",
    "from plot_utils import plot\n",
    "from mitigators import NullMitigator, SyntheticMitigator, DIRMitigator, ReweighMitigator, EGRMitigator, PRMitigator, CPPMitigator, ROMitigator \n",
    "from test_algorithms import TestAlgorithms\n",
    "from plot_utils import plot_algo_lr, plot_algo\n",
    "\n",
    "# Metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "\n",
    "# Bias insertion\n",
    "from oversample import label_bias, selection_bias "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180b2a8",
   "metadata": {},
   "source": [
    "## Arguments & Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "564c7837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-o', '--os'], dest='os', nargs=None, const=None, default=2, type=None, choices=None, required=False, help='oversample mode: 1: privi unfav 2: unpriv fav', metavar=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct argument parser\n",
    "import argparse\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--data\", choices=['adult', 'compas', 'bank', 'meps19', 'grade', 'law_sex', 'german_age', 'german_foreign'], default='compas', help=\"dataset: adult, compas, german, bank, meps19, grade \")\n",
    "ap.add_argument(\"-c\", \"--classifier\", choices=['lr', 'rf', 'svm', 'nn', 'nb'], default='lr', help=\"baseline model: lr, rf, svm, nn, nb, dt\")\n",
    "ap.add_argument(\"-m\", \"--mitigator\", choices=['dir', 'rew', 'egr', 'pr', 'cpp', 'ro'], required=False, help=\"mitigators: dir, rew, egr, pr, cpp, ro\")\n",
    "ap.add_argument(\"-b\", \"--bias\", default=0., help=\"amount of bias: o-1\")\n",
    "ap.add_argument(\"-t\", \"--biastype\", choices=['label', 'selection', 'none'], default='none', help=\"amount of bias: o-1\")\n",
    "ap.add_argument(\"-o\", \"--os\", default=2, help=\"oversample mode: 1: privi unfav 2: unpriv fav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4f8856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['']\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19b063bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 'compas',\n",
       " 'classifier': 'lr',\n",
       " 'mitigator': None,\n",
       " 'bias': 0.0,\n",
       " 'biastype': 'none',\n",
       " 'os': 2}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0dd1c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"german_foreign\"#args[\"data\"]\n",
    "BASELINE = \"dt\" #args[\"classifier\"]\n",
    "MITIGATOR = args[\"mitigator\"]\n",
    "BIAS = float(args[\"bias\"])\n",
    "BIAS_TYPE = args[\"biastype\"]\n",
    "OS_MODE = int(args[\"os\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b16266c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# global constants\n",
    "if BASELINE == 'svm' or BASELINE == 'nn':\n",
    "    SCALER = False \n",
    "else:\n",
    "    SCALER = False \n",
    "DISPLAY = False \n",
    "THRESH_ARR = 0.5\n",
    "\n",
    "# loop ten times \n",
    "N = 3 \n",
    "\n",
    "# percentage of favor and unfavor\n",
    "priv_metric_orig = defaultdict(float)\n",
    "favor_metric_orig = defaultdict(float)\n",
    "favor_metric_transf = defaultdict(float)\n",
    "\n",
    "# for each pre-processing approach, we create a mia_metric_results\n",
    "orig_metrics = defaultdict(list)\n",
    "orig_mia_metrics = defaultdict(list)\n",
    "\n",
    "transf_metrics = defaultdict(list) \n",
    "transf_mia_metrics = defaultdict(list) \n",
    "\n",
    "reweigh_metrics = defaultdict(list) \n",
    "reweigh_mia_metrics = defaultdict(list) \n",
    "\n",
    "dir_metrics = defaultdict(list) \n",
    "dir_mia_metrics = defaultdict(list) \n",
    "\n",
    "egr_metrics = defaultdict(list) \n",
    "egr_mia_metrics = defaultdict(list) \n",
    "\n",
    "\n",
    "pr_orig_metrics = defaultdict(list) \n",
    "cpp_metrics = defaultdict(list) \n",
    "ro_metrics = defaultdict(list) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a48a7",
   "metadata": {},
   "source": [
    "## Loading & Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da867c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and set the groups\n",
    "dataset_builder =  DatasetBuilder(DATASET)\n",
    "dataset_orig = dataset_builder.load_data()\n",
    "sens_attr = dataset_orig.protected_attribute_names[0]\n",
    "unprivileged_groups = dataset_builder.unprivileged_groups\n",
    "privileged_groups = dataset_builder.privileged_groups\n",
    "\n",
    "# training data split ratio\n",
    "p = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9aabd2f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 56)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb84777c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'foreign': 1}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "privileged_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fb1ad08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.000e+00 6.540e+02 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]\n",
      " [4.800e+01 3.578e+03 4.000e+00 ... 0.000e+00 0.000e+00 1.000e+00]\n",
      " [4.800e+01 5.381e+03 3.000e+00 ... 0.000e+00 0.000e+00 1.000e+00]\n",
      " ...\n",
      " [3.600e+01 3.249e+03 2.000e+00 ... 1.000e+00 0.000e+00 1.000e+00]\n",
      " [6.000e+00 1.872e+03 4.000e+00 ... 1.000e+00 0.000e+00 1.000e+00]\n",
      " [2.400e+01 1.469e+03 4.000e+00 ... 0.000e+00 1.000e+00 0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# split dataset into train, validation, and test\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([p], shuffle=True)\n",
    "dataset_orig_val = dataset_orig_test\n",
    "print(dataset_orig_train.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a15c69f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no bias type specified\n"
     ]
    }
   ],
   "source": [
    "# NOT SUITABLE\n",
    "# favorable and unfavorable labels and feature_names\n",
    "f_label = dataset_orig_train.favorable_label\n",
    "uf_label = dataset_orig_train.unfavorable_label\n",
    "feature_names = dataset_orig_train.feature_names\n",
    "\n",
    "# introduce label or selection biases, assuming the original data is fair\n",
    "if BIAS_TYPE == 'label':\n",
    "    dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "elif BIAS_TYPE == 'selection':\n",
    "    dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "else:\n",
    "    print('no bias type specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "494296e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               instance weights features                \\\n",
       "                                                         \n",
       "                                   month credit_amount   \n",
       "instance names                                           \n",
       "472                         1.0      9.0         654.0   \n",
       "115                         1.0     48.0        3578.0   \n",
       "310                         1.0     48.0        5381.0   \n",
       "653                         1.0     36.0        8086.0   \n",
       "612                         1.0     21.0        3357.0   \n",
       "...                         ...      ...           ...   \n",
       "34                          1.0     12.0        1474.0   \n",
       "347                         1.0     24.0        3758.0   \n",
       "392                         1.0     36.0        3249.0   \n",
       "432                         1.0      6.0        1872.0   \n",
       "100                         1.0     24.0        1469.0   \n",
       "\n",
       "                                                                      \\\n",
       "                                                                       \n",
       "               investment_as_income_percentage residence_since   age   \n",
       "instance names                                                         \n",
       "472                                        4.0             3.0  28.0   \n",
       "115                                        4.0             1.0  47.0   \n",
       "310                                        3.0             4.0  40.0   \n",
       "653                                        2.0             4.0  42.0   \n",
       "612                                        4.0             2.0  29.0   \n",
       "...                                        ...             ...   ...   \n",
       "34                                         4.0             1.0  33.0   \n",
       "347                                        1.0             4.0  23.0   \n",
       "392                                        2.0             4.0  39.0   \n",
       "432                                        4.0             4.0  36.0   \n",
       "100                                        4.0             4.0  41.0   \n",
       "\n",
       "                                                                        \\\n",
       "                                                   protected attribute   \n",
       "               number_of_credits people_liable_for             foreign   \n",
       "instance names                                                           \n",
       "472                          1.0               1.0                 0.0   \n",
       "115                          1.0               1.0                 0.0   \n",
       "310                          1.0               1.0                 0.0   \n",
       "653                          4.0               1.0                 0.0   \n",
       "612                          1.0               1.0                 0.0   \n",
       "...                          ...               ...                 ...   \n",
       "34                           1.0               1.0                 0.0   \n",
       "347                          1.0               1.0                 0.0   \n",
       "392                          1.0               2.0                 0.0   \n",
       "432                          3.0               1.0                 0.0   \n",
       "100                          1.0               1.0                 0.0   \n",
       "\n",
       "                           ...                                         \\\n",
       "                           ...                                          \n",
       "               status=A11  ... housing=A151 housing=A152 housing=A153   \n",
       "instance names             ...                                          \n",
       "472                   1.0  ...          0.0          1.0          0.0   \n",
       "115                   0.0  ...          0.0          1.0          0.0   \n",
       "310                   0.0  ...          0.0          0.0          1.0   \n",
       "653                   0.0  ...          0.0          1.0          0.0   \n",
       "612                   1.0  ...          0.0          1.0          0.0   \n",
       "...                   ...  ...          ...          ...          ...   \n",
       "34                    0.0  ...          0.0          1.0          0.0   \n",
       "347                   0.0  ...          1.0          0.0          0.0   \n",
       "392                   1.0  ...          0.0          0.0          1.0   \n",
       "432                   1.0  ...          0.0          0.0          1.0   \n",
       "100                   0.0  ...          1.0          0.0          0.0   \n",
       "\n",
       "                                                                   \\\n",
       "                                                                    \n",
       "               skill_level=A171 skill_level=A172 skill_level=A173   \n",
       "instance names                                                      \n",
       "472                         0.0              1.0              0.0   \n",
       "115                         0.0              0.0              1.0   \n",
       "310                         1.0              0.0              0.0   \n",
       "653                         0.0              0.0              0.0   \n",
       "612                         0.0              0.0              1.0   \n",
       "...                         ...              ...              ...   \n",
       "34                          0.0              0.0              0.0   \n",
       "347                         1.0              0.0              0.0   \n",
       "392                         0.0              0.0              0.0   \n",
       "432                         0.0              0.0              0.0   \n",
       "100                         0.0              1.0              0.0   \n",
       "\n",
       "                                                              labels  \n",
       "                                                                      \n",
       "               skill_level=A174 telephone=A191 telephone=A192         \n",
       "instance names                                                        \n",
       "472                         0.0            1.0            0.0    0.0  \n",
       "115                         0.0            0.0            1.0    1.0  \n",
       "310                         0.0            0.0            1.0    1.0  \n",
       "653                         1.0            0.0            1.0    0.0  \n",
       "612                         0.0            1.0            0.0    1.0  \n",
       "...                         ...            ...            ...    ...  \n",
       "34                          1.0            0.0            1.0    1.0  \n",
       "347                         0.0            1.0            0.0    1.0  \n",
       "392                         1.0            0.0            1.0    1.0  \n",
       "432                         1.0            0.0            1.0    1.0  \n",
       "100                         0.0            1.0            0.0    1.0  \n",
       "\n",
       "[500 rows x 58 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4446244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig_train?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cfd5f8",
   "metadata": {},
   "source": [
    "## Run Mitigating Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eea401f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Train dataset's features are as below:\n",
      "[[1.8000e+01 1.2950e+03 4.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [2.7000e+01 5.1900e+03 4.0000e+00 ... 0.0000e+00 0.0000e+00 1.0000e+00]\n",
      " [5.4000e+01 1.5945e+04 3.0000e+00 ... 0.0000e+00 0.0000e+00 1.0000e+00]\n",
      " ...\n",
      " [2.7000e+01 2.5280e+03 4.0000e+00 ... 0.0000e+00 0.0000e+00 1.0000e+00]\n",
      " [1.2000e+01 3.0590e+03 2.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [3.6000e+01 8.1330e+03 1.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 56)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['foreign']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'foreign': 1}] [{'foreign': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'foreign', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192']\n",
      "privileged vs. unprivileged:  23.0 477.0\n",
      "base_pos unpriv:  0.6645702306079665\n",
      "base_pos priv:  0.9130434782608695\n",
      "number of favorable labels:  338\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.248473\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 56) (500, 56) (500, 56)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.95      0.93       162\n",
      "         1.0       0.98      0.95      0.96       338\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.94      0.95      0.95       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "Train accuracy:  0.952\n",
      "Validating Original ...\n",
      "Accuracy for threshold: 0.01  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.02  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.03  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.04  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.05  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.060000000000000005  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.06999999999999999  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.08  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.09  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.09999999999999999  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.11  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.12  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.13  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.14  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.15000000000000002  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.16  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.17  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.18000000000000002  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.19  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.2  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.21000000000000002  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.22  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.23  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.24000000000000002  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.25  is: 0.69\n",
      "Balanced accuracy is:  0.5908599567619506\n",
      "Accuracy for threshold: 0.26  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.27  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.28  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.29000000000000004  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.3  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.31  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.32  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.33  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.34  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.35000000000000003  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.36000000000000004  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.37  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.38  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.39  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.4  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.41000000000000003  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.43  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.44  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.45  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.46  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.47000000000000003  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.48000000000000004  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.49  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.5  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Best thresh:  0.42000000000000004\n",
      "Best balanced accuracy: 0.6285\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.8694\n",
      "Corresponding average odds difference value: -0.0395\n",
      "Corresponding statistical parity difference value: -0.1026\n",
      "Corresponding equal opportunity difference value: -0.0790\n",
      "Corresponding Theil index value: 0.2376\n",
      "Corresponding false positive_rate for privileged: 0.5000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5000\n",
      "Corresponding false negative_rate for unprivileged: 0.2457\n",
      "Testing Original ...\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "True positive rate is:  0.7569060773480663\n",
      "True negative rate is:  0.5\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Test Accuracy is:  0.686\n",
      "Best balanced accuracy: 0.6285\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.8694\n",
      "Corresponding average odds difference value: -0.0395\n",
      "Corresponding statistical parity difference value: -0.1026\n",
      "Corresponding equal opportunity difference value: -0.0790\n",
      "Corresponding Theil index value: 0.2376\n",
      "Corresponding false positive_rate for privileged: 0.5000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5000\n",
      "Corresponding false negative_rate for unprivileged: 0.2457\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 160\n",
      "Number of test samples (ntest): 136\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 350\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 2\n",
      "Number of test samples (ntest): 2\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 21\n",
      "Number of test samples (ntest): 12\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.30010459245033816\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 162, Test = 138\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.47\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -0.30010459245033816\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 338, Test = 362\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 160, Test = 136\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.47\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -0.30010459245033816\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 350\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 2, Test = 2\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 21, Test = 12\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.06899287148695143\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 1862\n",
      "after transf priv:  0.9130434782608695\n",
      "after transf unpriv:  0.9129961935834693\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000047\n",
      "[INFO]: training decision tree\n",
      "Train metrics:\n",
      "Classification report for train: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.97       162\n",
      "         1.0       1.00      1.00      1.00      1700\n",
      "\n",
      "    accuracy                           1.00      1862\n",
      "   macro avg       0.99      0.98      0.99      1862\n",
      "weighted avg       1.00      1.00      1.00      1862\n",
      "\n",
      "Train accuracy:  0.9957035445757251\n",
      "Validating Original ...\n",
      "Accuracy for threshold: 0.01  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.02  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.03  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.04  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.05  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.060000000000000005  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.06999999999999999  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.08  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.09  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.09999999999999999  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.11  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.12  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.13  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.14  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.15000000000000002  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.16  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.17  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.18000000000000002  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.19  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.2  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.21000000000000002  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.22  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.23  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.24000000000000002  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.25  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.26  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.27  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.28  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.29000000000000004  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.3  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.31  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.32  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.33  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.34  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.35000000000000003  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.36000000000000004  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.37  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.38  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.39  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.4  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.41000000000000003  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.43  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.44  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.45  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.46  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.47000000000000003  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.48000000000000004  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.49  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.5  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Best thresh:  0.01\n",
      "Best balanced accuracy: 0.5917\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.8851\n",
      "Corresponding average odds difference value: -0.0107\n",
      "Corresponding statistical parity difference value: -0.0902\n",
      "Corresponding equal opportunity difference value: -0.0876\n",
      "Corresponding Theil index value: 0.2484\n",
      "Corresponding false positive_rate for privileged: 0.5000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5662\n",
      "Corresponding false negative_rate for unprivileged: 0.2543\n",
      "Testing Original ...\n",
      "Accuracy for threshold: 0.5  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "True positive rate is:  0.7486187845303868\n",
      "True negative rate is:  0.43478260869565216\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Test Accuracy is:  0.662\n",
      "Best balanced accuracy: 0.5917\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.8851\n",
      "Corresponding average odds difference value: -0.0107\n",
      "Corresponding statistical parity difference value: -0.0902\n",
      "Corresponding equal opportunity difference value: -0.0876\n",
      "Corresponding Theil index value: 0.2484\n",
      "Corresponding false positive_rate for privileged: 0.5000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5662\n",
      "Corresponding false negative_rate for unprivileged: 0.2543\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 160\n",
      "Number of test samples (ntest): 136\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 350\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 2\n",
      "Number of test samples (ntest): 2\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 21\n",
      "Number of test samples (ntest): 12\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 162, Test = 138\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.78\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.52\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 338, Test = 362\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 160, Test = 136\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.52\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 350\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 2, Test = 2\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 21, Test = 12\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.05448818528406968\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: training decision tree\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.97      0.96       162\n",
      "         1.0       0.99      0.98      0.98       338\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.97      0.97      0.97       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "Train accuracy:  0.976\n",
      "Validating Original ...\n",
      "Accuracy for threshold: 0.01  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.02  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.03  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.04  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.05  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.060000000000000005  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.06999999999999999  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.08  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.09  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.09999999999999999  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.11  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.12  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.13  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.14  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.15000000000000002  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.16  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.17  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.18000000000000002  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.19  is: 0.696\n",
      "Balanced accuracy is:  0.6106974137240772\n",
      "Accuracy for threshold: 0.2  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.21000000000000002  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.22  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.23  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.24000000000000002  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.25  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.26  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.27  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.28  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.29000000000000004  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.3  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.31  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.32  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.33  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.34  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.35000000000000003  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.36000000000000004  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.37  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.38  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.39  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.4  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.41000000000000003  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.43  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.44  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.45  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.46  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.47000000000000003  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.48000000000000004  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.49  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.5  is: 0.706\n",
      "Balanced accuracy is:  0.6355392745616142\n",
      "Best thresh:  0.5\n",
      "Best balanced accuracy: 0.6355\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.9113\n",
      "Corresponding average odds difference value: -0.0099\n",
      "Corresponding statistical parity difference value: -0.0697\n",
      "Corresponding equal opportunity difference value: -0.0419\n",
      "Corresponding Theil index value: 0.2068\n",
      "Corresponding false positive_rate for privileged: 0.5000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5221\n",
      "Corresponding false negative_rate for unprivileged: 0.2086\n",
      "Testing Original ...\n",
      "Accuracy for threshold: 0.5  is: 0.706\n",
      "Balanced accuracy is:  0.6355392745616142\n",
      "True positive rate is:  0.7928176795580111\n",
      "True negative rate is:  0.4782608695652174\n",
      "Balanced accuracy is:  0.6355392745616142\n",
      "Test Accuracy is:  0.706\n",
      "Best balanced accuracy: 0.6355\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.9113\n",
      "Corresponding average odds difference value: -0.0099\n",
      "Corresponding statistical parity difference value: -0.0697\n",
      "Corresponding equal opportunity difference value: -0.0419\n",
      "Corresponding Theil index value: 0.2068\n",
      "Corresponding false positive_rate for privileged: 0.5000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5221\n",
      "Corresponding false negative_rate for unprivileged: 0.2086\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 160\n",
      "Number of test samples (ntest): 136\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 350\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 2\n",
      "Number of test samples (ntest): 2\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 21\n",
      "Number of test samples (ntest): 12\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.25131442828090605\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 162, Test = 138\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -0.2231435513142097\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 338, Test = 362\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.25131442828090605\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 160, Test = 136\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -0.2231435513142097\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 350\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.25131442828090605\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 2, Test = 2\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 21, Test = 12\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.94      0.97       162\n",
      "         1.0       0.97      1.00      0.98       338\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.98      0.97      0.97       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "Train accuracy:  0.978\n",
      "Validating Original ...\n",
      "Accuracy for threshold: 0.01  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.02  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.03  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.04  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.05  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.060000000000000005  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.06999999999999999  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.08  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.09  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.09999999999999999  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.11  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.12  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.13  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.14  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.15000000000000002  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.16  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.17  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.18000000000000002  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.19  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.2  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.21000000000000002  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.22  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.23  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.24000000000000002  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.25  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.26  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.27  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.28  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.29000000000000004  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.3  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.31  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.32  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.33  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.34  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.35000000000000003  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.36000000000000004  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.37  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.38  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.39  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.4  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.41000000000000003  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.43  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.44  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.45  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.46  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.47000000000000003  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.48000000000000004  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.49  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.5  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Best thresh:  0.01\n",
      "Best balanced accuracy: 0.5967\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.8090\n",
      "Corresponding average odds difference value: -0.2666\n",
      "Corresponding statistical parity difference value: -0.1637\n",
      "Corresponding equal opportunity difference value: -0.0848\n",
      "Corresponding Theil index value: 0.2455\n",
      "Corresponding false positive_rate for privileged: 1.0000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5515\n",
      "Corresponding false negative_rate for unprivileged: 0.2514\n",
      "Testing Original ...\n",
      "Accuracy for threshold: 0.01  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "True positive rate is:  0.7734806629834254\n",
      "True negative rate is:  0.4420289855072464\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Test Accuracy is:  0.682\n",
      "Best balanced accuracy: 0.6078\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.8282\n",
      "Corresponding average odds difference value: -0.2552\n",
      "Corresponding statistical parity difference value: -0.1473\n",
      "Corresponding equal opportunity difference value: -0.0619\n",
      "Corresponding Theil index value: 0.2257\n",
      "Corresponding false positive_rate for privileged: 1.0000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5515\n",
      "Corresponding false negative_rate for unprivileged: 0.2286\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 160\n",
      "Number of test samples (ntest): 136\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 2\n",
      "Number of test samples (ntest): 2\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 21\n",
      "Number of test samples (ntest): 12\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.16170528965505807\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 162, Test = 138\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.7193423346069456\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 338, Test = 362\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.38852008037297825\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 160, Test = 136\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.7193423346069456\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 350\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.38852008037297825\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 2, Test = 2\n",
      "  AUC: 1.00\n",
      "  Privacy Risk: 1.00\n",
      "  Accuracy: 1.00\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 1.00\n",
      "  Attacker advantage: 1.00\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 21, Test = 12\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Fitting ExponentiatedGradient ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done fitting\n",
      "Accuracy for threshold: 0.01  is: 0.362\n",
      "Balanced accuracy is:  0.3934862679157659\n",
      "Accuracy for threshold: 0.02  is: 0.362\n",
      "Balanced accuracy is:  0.3934862679157659\n",
      "Accuracy for threshold: 0.03  is: 0.362\n",
      "Balanced accuracy is:  0.3934862679157659\n",
      "Accuracy for threshold: 0.04  is: 0.362\n",
      "Balanced accuracy is:  0.3934862679157659\n",
      "Accuracy for threshold: 0.05  is: 0.362\n",
      "Balanced accuracy is:  0.3934862679157659\n",
      "Accuracy for threshold: 0.060000000000000005  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.06999999999999999  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.08  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.09  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.09999999999999999  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.11  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.12  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.13  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.14  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.15000000000000002  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.16  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.17  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.18000000000000002  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.19  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.2  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.21000000000000002  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.22  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.23  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.24000000000000002  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.25  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.26  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.27  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.28  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.29000000000000004  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.3  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.31  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.32  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.33  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.34  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.35000000000000003  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.36000000000000004  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.37  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.38  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.39  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.4  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.41000000000000003  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.43  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.44  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.45  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.46  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.47000000000000003  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.48000000000000004  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.49  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.5  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.5  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "True positive rate is:  0.2513812154696133\n",
      "True negative rate is:  0.5942028985507246\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Test Accuracy is:  0.346\n",
      "Best balanced accuracy: 0.4228\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.4788\n",
      "Corresponding average odds difference value: 0.2497\n",
      "Corresponding statistical parity difference value: 0.1555\n",
      "Corresponding equal opportunity difference value: 0.0876\n",
      "Corresponding Theil index value: 0.8345\n",
      "Corresponding false positive_rate for privileged: 0.0000\n",
      "Corresponding false negative_rate for privileged: 0.8333\n",
      "Corresponding false positive_rate for unpribileged: 0.4118\n",
      "Corresponding false negative_rate for unprivileged: 0.7457\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.94      0.97       160\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       160\n",
      "   macro avg       0.50      0.47      0.49       160\n",
      "weighted avg       1.00      0.94      0.97       160\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      1.00      1.00       317\n",
      "\n",
      "    accuracy                           1.00       317\n",
      "   macro avg       0.50      0.50      0.50       317\n",
      "weighted avg       1.00      1.00      1.00       317\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.43      0.60       136\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.43       136\n",
      "   macro avg       0.50      0.21      0.30       136\n",
      "weighted avg       1.00      0.43      0.60       136\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.74      0.85       350\n",
      "\n",
      "    accuracy                           0.74       350\n",
      "   macro avg       0.50      0.37      0.43       350\n",
      "weighted avg       1.00      0.74      0.85       350\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       2.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.50      0.42      0.45        12\n",
      "weighted avg       1.00      0.83      0.91        12\n",
      "\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 160\n",
      "Number of test samples (ntest): 136\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 350\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 2\n",
      "Number of test samples (ntest): 2\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 21\n",
      "Number of test samples (ntest): 12\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.70\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.38\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 162, Test = 138\n",
      "  AUC: 0.82\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.59\n",
      "  Positive predictive value: 0.78\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 338, Test = 362\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.31\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 160, Test = 136\n",
      "  AUC: 0.82\n",
      "  Privacy Risk: 0.80\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.59\n",
      "  Positive predictive value: 0.78\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 350\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 2, Test = 2\n",
      "  AUC: 1.00\n",
      "  Privacy Risk: 1.00\n",
      "  Accuracy: 1.00\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 1.00\n",
      "  Attacker advantage: 1.00\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -0.05379642460566901\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 21, Test = 12\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] post-processing Calibrated Equal Odds ......\n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best balanced accuracy: 0.6276\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.6831\n",
      "Corresponding average odds difference value: -0.3729\n",
      "Corresponding statistical parity difference value: -0.3169\n",
      "Corresponding equal opportunity difference value: -0.2457\n",
      "Corresponding Theil index value: 0.2330\n",
      "Corresponding false positive_rate for privileged: 1.0000\n",
      "Corresponding false negative_rate for privileged: 0.0000\n",
      "Corresponding false positive_rate for unpribileged: 0.5000\n",
      "Corresponding false negative_rate for unprivileged: 0.2457\n",
      "#### Train dataset's features are as below:\n",
      "[[1.8000e+01 1.2950e+03 4.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [2.7000e+01 5.1900e+03 4.0000e+00 ... 0.0000e+00 0.0000e+00 1.0000e+00]\n",
      " [5.4000e+01 1.5945e+04 3.0000e+00 ... 0.0000e+00 0.0000e+00 1.0000e+00]\n",
      " ...\n",
      " [2.7000e+01 2.5280e+03 4.0000e+00 ... 0.0000e+00 0.0000e+00 1.0000e+00]\n",
      " [1.2000e+01 3.0590e+03 2.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [3.6000e+01 8.1330e+03 1.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 56)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['foreign']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'foreign': 1}] [{'foreign': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'foreign', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192']\n",
      "privileged vs. unprivileged:  23.0 477.0\n",
      "base_pos unpriv:  0.6645702306079665\n",
      "base_pos priv:  0.9130434782608695\n",
      "number of favorable labels:  338\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.248473\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 56) (500, 56) (500, 56)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.95      0.93       162\n",
      "         1.0       0.98      0.95      0.96       338\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.94      0.95      0.95       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "Train accuracy:  0.952\n",
      "Validating Original ...\n",
      "Accuracy for threshold: 0.01  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.02  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.03  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.04  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.05  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.060000000000000005  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.06999999999999999  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.08  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.09  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.09999999999999999  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.11  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.12  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.13  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.14  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.15000000000000002  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.16  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.17  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.18000000000000002  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.19  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.2  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.21000000000000002  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.22  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.23  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.24000000000000002  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.25  is: 0.69\n",
      "Balanced accuracy is:  0.5908599567619506\n",
      "Accuracy for threshold: 0.26  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.27  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.28  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.29000000000000004  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.3  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.31  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.32  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.33  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.34  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.35000000000000003  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.36000000000000004  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.37  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.38  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.39  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.4  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.41000000000000003  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.43  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.44  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.45  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.46  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.47000000000000003  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.48000000000000004  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.49  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.5  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Best thresh:  0.42000000000000004\n",
      "Best balanced accuracy: 0.6285\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.8694\n",
      "Corresponding average odds difference value: -0.0395\n",
      "Corresponding statistical parity difference value: -0.1026\n",
      "Corresponding equal opportunity difference value: -0.0790\n",
      "Corresponding Theil index value: 0.2376\n",
      "Corresponding false positive_rate for privileged: 0.5000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5000\n",
      "Corresponding false negative_rate for unprivileged: 0.2457\n",
      "Testing Original ...\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "True positive rate is:  0.7569060773480663\n",
      "True negative rate is:  0.5\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Test Accuracy is:  0.686\n",
      "Best balanced accuracy: 0.6285\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.8694\n",
      "Corresponding average odds difference value: -0.0395\n",
      "Corresponding statistical parity difference value: -0.1026\n",
      "Corresponding equal opportunity difference value: -0.0790\n",
      "Corresponding Theil index value: 0.2376\n",
      "Corresponding false positive_rate for privileged: 0.5000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5000\n",
      "Corresponding false negative_rate for unprivileged: 0.2457\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 160\n",
      "Number of test samples (ntest): 136\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 350\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 2\n",
      "Number of test samples (ntest): 2\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 21\n",
      "Number of test samples (ntest): 12\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.30010459245033816\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 162, Test = 138\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.47\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -0.30010459245033816\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 338, Test = 362\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 160, Test = 136\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.47\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -0.30010459245033816\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 350\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 2, Test = 2\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 21, Test = 12\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.06899287148695143\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  500 1862\n",
      "after transf priv:  0.9130434782608695\n",
      "after transf unpriv:  0.9129961935834693\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000047\n",
      "[INFO]: training decision tree\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.97       162\n",
      "         1.0       1.00      1.00      1.00      1700\n",
      "\n",
      "    accuracy                           1.00      1862\n",
      "   macro avg       0.99      0.98      0.99      1862\n",
      "weighted avg       1.00      1.00      1.00      1862\n",
      "\n",
      "Train accuracy:  0.9957035445757251\n",
      "Validating Original ...\n",
      "Accuracy for threshold: 0.01  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.02  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.03  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.04  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.05  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.060000000000000005  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.06999999999999999  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.08  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.09  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.09999999999999999  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.11  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.12  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.13  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.14  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.15000000000000002  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.16  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.17  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.18000000000000002  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.19  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.2  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.21000000000000002  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.22  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.23  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.24000000000000002  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.25  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.26  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.27  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.28  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.29000000000000004  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.3  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.31  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.32  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.33  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.34  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.35000000000000003  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.36000000000000004  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.37  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.38  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.39  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.4  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.41000000000000003  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.43  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.44  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.45  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.46  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.47000000000000003  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.48000000000000004  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.49  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.5  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Best thresh:  0.01\n",
      "Best balanced accuracy: 0.5917\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.8851\n",
      "Corresponding average odds difference value: -0.0107\n",
      "Corresponding statistical parity difference value: -0.0902\n",
      "Corresponding equal opportunity difference value: -0.0876\n",
      "Corresponding Theil index value: 0.2484\n",
      "Corresponding false positive_rate for privileged: 0.5000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5662\n",
      "Corresponding false negative_rate for unprivileged: 0.2543\n",
      "Testing Original ...\n",
      "Accuracy for threshold: 0.5  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "True positive rate is:  0.7486187845303868\n",
      "True negative rate is:  0.43478260869565216\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Test Accuracy is:  0.662\n",
      "Best balanced accuracy: 0.5917\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.8851\n",
      "Corresponding average odds difference value: -0.0107\n",
      "Corresponding statistical parity difference value: -0.0902\n",
      "Corresponding equal opportunity difference value: -0.0876\n",
      "Corresponding Theil index value: 0.2484\n",
      "Corresponding false positive_rate for privileged: 0.5000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5662\n",
      "Corresponding false negative_rate for unprivileged: 0.2543\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 160\n",
      "Number of test samples (ntest): 136\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 350\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 2\n",
      "Number of test samples (ntest): 2\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 21\n",
      "Number of test samples (ntest): 12\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 162, Test = 138\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.78\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.52\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 338, Test = 362\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 160, Test = 136\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.52\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 350\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 2, Test = 2\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 21, Test = 12\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.05448818528406968\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: training decision tree\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.97      0.96       162\n",
      "         1.0       0.99      0.98      0.98       338\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.97      0.97      0.97       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "Train accuracy:  0.976\n",
      "Validating Original ...\n",
      "Accuracy for threshold: 0.01  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.02  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.03  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.04  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.05  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.060000000000000005  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.06999999999999999  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.08  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.09  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.09999999999999999  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.11  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.12  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.13  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.14  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.15000000000000002  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.16  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.17  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.18000000000000002  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.19  is: 0.696\n",
      "Balanced accuracy is:  0.6106974137240772\n",
      "Accuracy for threshold: 0.2  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.21000000000000002  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.22  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.23  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.24000000000000002  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.25  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.26  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.27  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.28  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.29000000000000004  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.3  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.31  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.32  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.33  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.34  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.35000000000000003  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.36000000000000004  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.37  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.38  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.39  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.4  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.41000000000000003  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.43  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.44  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.45  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.46  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.47000000000000003  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.48000000000000004  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.49  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.5  is: 0.706\n",
      "Balanced accuracy is:  0.6355392745616142\n",
      "Best thresh:  0.5\n",
      "Best balanced accuracy: 0.6355\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.9113\n",
      "Corresponding average odds difference value: -0.0099\n",
      "Corresponding statistical parity difference value: -0.0697\n",
      "Corresponding equal opportunity difference value: -0.0419\n",
      "Corresponding Theil index value: 0.2068\n",
      "Corresponding false positive_rate for privileged: 0.5000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5221\n",
      "Corresponding false negative_rate for unprivileged: 0.2086\n",
      "Testing Original ...\n",
      "Accuracy for threshold: 0.5  is: 0.706\n",
      "Balanced accuracy is:  0.6355392745616142\n",
      "True positive rate is:  0.7928176795580111\n",
      "True negative rate is:  0.4782608695652174\n",
      "Balanced accuracy is:  0.6355392745616142\n",
      "Test Accuracy is:  0.706\n",
      "Best balanced accuracy: 0.6355\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.9113\n",
      "Corresponding average odds difference value: -0.0099\n",
      "Corresponding statistical parity difference value: -0.0697\n",
      "Corresponding equal opportunity difference value: -0.0419\n",
      "Corresponding Theil index value: 0.2068\n",
      "Corresponding false positive_rate for privileged: 0.5000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5221\n",
      "Corresponding false negative_rate for unprivileged: 0.2086\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 160\n",
      "Number of test samples (ntest): 136\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 350\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 2\n",
      "Number of test samples (ntest): 2\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 21\n",
      "Number of test samples (ntest): 12\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.25131442828090605\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 162, Test = 138\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -0.2231435513142097\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 338, Test = 362\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.25131442828090605\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 160, Test = 136\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -0.2231435513142097\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 350\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.25131442828090605\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 2, Test = 2\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 21, Test = 12\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.94      0.97       162\n",
      "         1.0       0.97      1.00      0.98       338\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.98      0.97      0.97       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "Train accuracy:  0.978\n",
      "Validating Original ...\n",
      "Accuracy for threshold: 0.01  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.02  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.03  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.04  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.05  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.060000000000000005  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.06999999999999999  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.08  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.09  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.09999999999999999  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.11  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.12  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.13  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.14  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.15000000000000002  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.16  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.17  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.18000000000000002  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.19  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.2  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for threshold: 0.21000000000000002  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.22  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.23  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.24000000000000002  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.25  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.26  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.27  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.28  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.29000000000000004  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.3  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.31  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.32  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.33  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.34  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.35000000000000003  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.36000000000000004  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.37  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.38  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.39  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.4  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.41000000000000003  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.43  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.44  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.45  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.46  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.47000000000000003  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.48000000000000004  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.49  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.5  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Best thresh:  0.01\n",
      "Best balanced accuracy: 0.5967\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.8090\n",
      "Corresponding average odds difference value: -0.2666\n",
      "Corresponding statistical parity difference value: -0.1637\n",
      "Corresponding equal opportunity difference value: -0.0848\n",
      "Corresponding Theil index value: 0.2455\n",
      "Corresponding false positive_rate for privileged: 1.0000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5515\n",
      "Corresponding false negative_rate for unprivileged: 0.2514\n",
      "Testing Original ...\n",
      "Accuracy for threshold: 0.01  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "True positive rate is:  0.7734806629834254\n",
      "True negative rate is:  0.4420289855072464\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Test Accuracy is:  0.682\n",
      "Best balanced accuracy: 0.6078\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.8282\n",
      "Corresponding average odds difference value: -0.2552\n",
      "Corresponding statistical parity difference value: -0.1473\n",
      "Corresponding equal opportunity difference value: -0.0619\n",
      "Corresponding Theil index value: 0.2257\n",
      "Corresponding false positive_rate for privileged: 1.0000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5515\n",
      "Corresponding false negative_rate for unprivileged: 0.2286\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 160\n",
      "Number of test samples (ntest): 136\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 350\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 2\n",
      "Number of test samples (ntest): 2\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 21\n",
      "Number of test samples (ntest): 12\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.16170528965505807\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 162, Test = 138\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.7193423346069456\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 338, Test = 362\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.38852008037297825\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 160, Test = 136\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.7193423346069456\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 350\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.38852008037297825\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 2, Test = 2\n",
      "  AUC: 1.00\n",
      "  Privacy Risk: 1.00\n",
      "  Accuracy: 1.00\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 1.00\n",
      "  Attacker advantage: 1.00\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 21, Test = 12\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Fitting ExponentiatedGradient ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done fitting\n",
      "Accuracy for threshold: 0.01  is: 0.362\n",
      "Balanced accuracy is:  0.3934862679157659\n",
      "Accuracy for threshold: 0.02  is: 0.362\n",
      "Balanced accuracy is:  0.3934862679157659\n",
      "Accuracy for threshold: 0.03  is: 0.362\n",
      "Balanced accuracy is:  0.3934862679157659\n",
      "Accuracy for threshold: 0.04  is: 0.362\n",
      "Balanced accuracy is:  0.3934862679157659\n",
      "Accuracy for threshold: 0.05  is: 0.362\n",
      "Balanced accuracy is:  0.3934862679157659\n",
      "Accuracy for threshold: 0.060000000000000005  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.06999999999999999  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.08  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.09  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.09999999999999999  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.11  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.12  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.13  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.14  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.15000000000000002  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.16  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.17  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.18000000000000002  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.19  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.2  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.21000000000000002  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.22  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.23  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.24000000000000002  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.25  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.26  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.27  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.28  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.29000000000000004  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.3  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.31  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.32  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.33  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.34  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.35000000000000003  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.36000000000000004  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.37  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.38  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.39  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.4  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.41000000000000003  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.43  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.44  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.45  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.46  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.47000000000000003  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.48000000000000004  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.49  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.5  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.5  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "True positive rate is:  0.2513812154696133\n",
      "True negative rate is:  0.5942028985507246\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Test Accuracy is:  0.346\n",
      "Best balanced accuracy: 0.4228\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.4788\n",
      "Corresponding average odds difference value: 0.2497\n",
      "Corresponding statistical parity difference value: 0.1555\n",
      "Corresponding equal opportunity difference value: 0.0876\n",
      "Corresponding Theil index value: 0.8345\n",
      "Corresponding false positive_rate for privileged: 0.0000\n",
      "Corresponding false negative_rate for privileged: 0.8333\n",
      "Corresponding false positive_rate for unpribileged: 0.4118\n",
      "Corresponding false negative_rate for unprivileged: 0.7457\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.94      0.97       160\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       160\n",
      "   macro avg       0.50      0.47      0.49       160\n",
      "weighted avg       1.00      0.94      0.97       160\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      1.00      1.00       317\n",
      "\n",
      "    accuracy                           1.00       317\n",
      "   macro avg       0.50      0.50      0.50       317\n",
      "weighted avg       1.00      1.00      1.00       317\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.43      0.60       136\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.43       136\n",
      "   macro avg       0.50      0.21      0.30       136\n",
      "weighted avg       1.00      0.43      0.60       136\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.74      0.85       350\n",
      "\n",
      "    accuracy                           0.74       350\n",
      "   macro avg       0.50      0.37      0.43       350\n",
      "weighted avg       1.00      0.74      0.85       350\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       2.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.50      0.42      0.45        12\n",
      "weighted avg       1.00      0.83      0.91        12\n",
      "\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 160\n",
      "Number of test samples (ntest): 136\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 350\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 2\n",
      "Number of test samples (ntest): 2\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 21\n",
      "Number of test samples (ntest): 12\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.70\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.38\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 162, Test = 138\n",
      "  AUC: 0.82\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.59\n",
      "  Positive predictive value: 0.78\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 338, Test = 362\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.31\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 160, Test = 136\n",
      "  AUC: 0.82\n",
      "  Privacy Risk: 0.80\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.59\n",
      "  Positive predictive value: 0.78\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 350\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 2, Test = 2\n",
      "  AUC: 1.00\n",
      "  Privacy Risk: 1.00\n",
      "  Accuracy: 1.00\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 1.00\n",
      "  Attacker advantage: 1.00\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -0.05379642460566901\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 21, Test = 12\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] post-processing Calibrated Equal Odds ......\n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best balanced accuracy: 0.6276\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.6831\n",
      "Corresponding average odds difference value: -0.3729\n",
      "Corresponding statistical parity difference value: -0.3169\n",
      "Corresponding equal opportunity difference value: -0.2457\n",
      "Corresponding Theil index value: 0.2330\n",
      "Corresponding false positive_rate for privileged: 1.0000\n",
      "Corresponding false negative_rate for privileged: 0.0000\n",
      "Corresponding false positive_rate for unpribileged: 0.5000\n",
      "Corresponding false negative_rate for unprivileged: 0.2457\n",
      "#### Train dataset's features are as below:\n",
      "[[1.8000e+01 1.2950e+03 4.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [2.7000e+01 5.1900e+03 4.0000e+00 ... 0.0000e+00 0.0000e+00 1.0000e+00]\n",
      " [5.4000e+01 1.5945e+04 3.0000e+00 ... 0.0000e+00 0.0000e+00 1.0000e+00]\n",
      " ...\n",
      " [2.7000e+01 2.5280e+03 4.0000e+00 ... 0.0000e+00 0.0000e+00 1.0000e+00]\n",
      " [1.2000e+01 3.0590e+03 2.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [3.6000e+01 8.1330e+03 1.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(500, 56)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['foreign']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'foreign': 1}] [{'foreign': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'foreign', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192']\n",
      "privileged vs. unprivileged:  23.0 477.0\n",
      "base_pos unpriv:  0.6645702306079665\n",
      "base_pos priv:  0.9130434782608695\n",
      "number of favorable labels:  338\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.248473\n",
      "#### Train shape, validation shape, test shape\n",
      "(500, 56) (500, 56) (500, 56)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.95      0.93       162\n",
      "         1.0       0.98      0.95      0.96       338\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.94      0.95      0.95       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "Train accuracy:  0.952\n",
      "Validating Original ...\n",
      "Accuracy for threshold: 0.01  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.02  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.03  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.04  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.05  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.060000000000000005  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.06999999999999999  is: 0.686\n",
      "Balanced accuracy is:  0.5410160941628633\n",
      "Accuracy for threshold: 0.08  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.09  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.09999999999999999  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.11  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.12  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.13  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.14  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.15000000000000002  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.16  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.17  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.18000000000000002  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.19  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.2  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.21000000000000002  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.22  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.23  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.24000000000000002  is: 0.696\n",
      "Balanced accuracy is:  0.5927616302346065\n",
      "Accuracy for threshold: 0.25  is: 0.69\n",
      "Balanced accuracy is:  0.5908599567619506\n",
      "Accuracy for threshold: 0.26  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.27  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.28  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.29000000000000004  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.3  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.31  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.32  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.33  is: 0.68\n",
      "Balanced accuracy is:  0.601889662903355\n",
      "Accuracy for threshold: 0.34  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.35000000000000003  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.36000000000000004  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.37  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.38  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.39  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.4  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.41000000000000003  is: 0.68\n",
      "Balanced accuracy is:  0.6086155817119066\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.43  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.44  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.45  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.46  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.47000000000000003  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.48000000000000004  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.49  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Accuracy for threshold: 0.5  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Best thresh:  0.42000000000000004\n",
      "Best balanced accuracy: 0.6285\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.8694\n",
      "Corresponding average odds difference value: -0.0395\n",
      "Corresponding statistical parity difference value: -0.1026\n",
      "Corresponding equal opportunity difference value: -0.0790\n",
      "Corresponding Theil index value: 0.2376\n",
      "Corresponding false positive_rate for privileged: 0.5000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5000\n",
      "Corresponding false negative_rate for unprivileged: 0.2457\n",
      "Testing Original ...\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.686\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "True positive rate is:  0.7569060773480663\n",
      "True negative rate is:  0.5\n",
      "Balanced accuracy is:  0.6284530386740331\n",
      "Test Accuracy is:  0.686\n",
      "Best balanced accuracy: 0.6285\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.8694\n",
      "Corresponding average odds difference value: -0.0395\n",
      "Corresponding statistical parity difference value: -0.1026\n",
      "Corresponding equal opportunity difference value: -0.0790\n",
      "Corresponding Theil index value: 0.2376\n",
      "Corresponding false positive_rate for privileged: 0.5000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5000\n",
      "Corresponding false negative_rate for unprivileged: 0.2457\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 160\n",
      "Number of test samples (ntest): 136\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 350\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 2\n",
      "Number of test samples (ntest): 2\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 21\n",
      "Number of test samples (ntest): 12\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.29\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.30010459245033816\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 162, Test = 138\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.47\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -0.30010459245033816\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 338, Test = 362\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 160, Test = 136\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.47\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -0.30010459245033816\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 350\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.40546510810816444\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 2, Test = 2\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 21, Test = 12\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.06899287148695143\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin, transf:  500 1862\n",
      "after transf priv:  0.9130434782608695\n",
      "after transf unpriv:  0.9129961935834693\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000047\n",
      "[INFO]: training decision tree\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.97       162\n",
      "         1.0       1.00      1.00      1.00      1700\n",
      "\n",
      "    accuracy                           1.00      1862\n",
      "   macro avg       0.99      0.98      0.99      1862\n",
      "weighted avg       1.00      1.00      1.00      1862\n",
      "\n",
      "Train accuracy:  0.9957035445757251\n",
      "Validating Original ...\n",
      "Accuracy for threshold: 0.01  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.02  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.03  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.04  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.05  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.060000000000000005  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.06999999999999999  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.08  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.09  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.09999999999999999  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.11  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.12  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.13  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.14  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.15000000000000002  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.16  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.17  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.18000000000000002  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.19  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.2  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.21000000000000002  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.22  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.23  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.24000000000000002  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.25  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.26  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.27  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.28  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.29000000000000004  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.3  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.31  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.32  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.33  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.34  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.35000000000000003  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.36000000000000004  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.37  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.38  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.39  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.4  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.41000000000000003  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.43  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.44  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.45  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.46  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.47000000000000003  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.48000000000000004  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.49  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Accuracy for threshold: 0.5  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Best thresh:  0.01\n",
      "Best balanced accuracy: 0.5917\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.8851\n",
      "Corresponding average odds difference value: -0.0107\n",
      "Corresponding statistical parity difference value: -0.0902\n",
      "Corresponding equal opportunity difference value: -0.0876\n",
      "Corresponding Theil index value: 0.2484\n",
      "Corresponding false positive_rate for privileged: 0.5000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5662\n",
      "Corresponding false negative_rate for unprivileged: 0.2543\n",
      "Testing Original ...\n",
      "Accuracy for threshold: 0.5  is: 0.662\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "True positive rate is:  0.7486187845303868\n",
      "True negative rate is:  0.43478260869565216\n",
      "Balanced accuracy is:  0.5917006966130195\n",
      "Test Accuracy is:  0.662\n",
      "Best balanced accuracy: 0.5917\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.8851\n",
      "Corresponding average odds difference value: -0.0107\n",
      "Corresponding statistical parity difference value: -0.0902\n",
      "Corresponding equal opportunity difference value: -0.0876\n",
      "Corresponding Theil index value: 0.2484\n",
      "Corresponding false positive_rate for privileged: 0.5000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5662\n",
      "Corresponding false negative_rate for unprivileged: 0.2543\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 160\n",
      "Number of test samples (ntest): 136\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 350\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 2\n",
      "Number of test samples (ntest): 2\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 21\n",
      "Number of test samples (ntest): 12\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 162, Test = 138\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.78\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.52\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 338, Test = 362\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 160, Test = 136\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.52\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 350\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 2, Test = 2\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 21, Test = 12\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.05448818528406968\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: training decision tree\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.97      0.96       162\n",
      "         1.0       0.99      0.98      0.98       338\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.97      0.97      0.97       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "Train accuracy:  0.976\n",
      "Validating Original ...\n",
      "Accuracy for threshold: 0.01  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.02  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.03  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.04  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.05  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.060000000000000005  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.06999999999999999  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.08  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.09  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.09999999999999999  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.11  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.12  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.13  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.14  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.15000000000000002  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.16  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.17  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.18000000000000002  is: 0.706\n",
      "Balanced accuracy is:  0.5951837617103051\n",
      "Accuracy for threshold: 0.19  is: 0.696\n",
      "Balanced accuracy is:  0.6106974137240772\n",
      "Accuracy for threshold: 0.2  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.21000000000000002  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.22  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.23  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.24000000000000002  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.25  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.26  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.27  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.28  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.29000000000000004  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.3  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.31  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.32  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.33  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.34  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.35000000000000003  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.36000000000000004  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.37  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.38  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.39  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.4  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.41000000000000003  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.43  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.44  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.45  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.46  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.47000000000000003  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.48000000000000004  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.49  is: 0.702\n",
      "Balanced accuracy is:  0.6215669789414685\n",
      "Accuracy for threshold: 0.5  is: 0.706\n",
      "Balanced accuracy is:  0.6355392745616142\n",
      "Best thresh:  0.5\n",
      "Best balanced accuracy: 0.6355\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.9113\n",
      "Corresponding average odds difference value: -0.0099\n",
      "Corresponding statistical parity difference value: -0.0697\n",
      "Corresponding equal opportunity difference value: -0.0419\n",
      "Corresponding Theil index value: 0.2068\n",
      "Corresponding false positive_rate for privileged: 0.5000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5221\n",
      "Corresponding false negative_rate for unprivileged: 0.2086\n",
      "Testing Original ...\n",
      "Accuracy for threshold: 0.5  is: 0.706\n",
      "Balanced accuracy is:  0.6355392745616142\n",
      "True positive rate is:  0.7928176795580111\n",
      "True negative rate is:  0.4782608695652174\n",
      "Balanced accuracy is:  0.6355392745616142\n",
      "Test Accuracy is:  0.706\n",
      "Best balanced accuracy: 0.6355\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.9113\n",
      "Corresponding average odds difference value: -0.0099\n",
      "Corresponding statistical parity difference value: -0.0697\n",
      "Corresponding equal opportunity difference value: -0.0419\n",
      "Corresponding Theil index value: 0.2068\n",
      "Corresponding false positive_rate for privileged: 0.5000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5221\n",
      "Corresponding false negative_rate for unprivileged: 0.2086\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 160\n",
      "Number of test samples (ntest): 136\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 350\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 2\n",
      "Number of test samples (ntest): 2\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 21\n",
      "Number of test samples (ntest): 12\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.25131442828090605\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 162, Test = 138\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -0.2231435513142097\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 338, Test = 362\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.25131442828090605\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 160, Test = 136\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -0.2231435513142097\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 350\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.20\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.25131442828090605\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 2, Test = 2\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 21, Test = 12\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.94      0.97       162\n",
      "         1.0       0.97      1.00      0.98       338\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.98      0.97      0.97       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "Train accuracy:  0.978\n",
      "Validating Original ...\n",
      "Accuracy for threshold: 0.01  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.02  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.03  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.04  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.05  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for threshold: 0.060000000000000005  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.06999999999999999  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.08  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.09  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.09999999999999999  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.11  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.12  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.13  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.14  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Accuracy for threshold: 0.15000000000000002  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.16  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.17  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.18000000000000002  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.19  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.2  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.21000000000000002  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.22  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.23  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.24000000000000002  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.25  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.26  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.27  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.28  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.29000000000000004  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.3  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.31  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.32  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.33  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.34  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.35000000000000003  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.36000000000000004  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.37  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.38  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.39  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.4  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.41000000000000003  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.43  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.44  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.45  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.46  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.47000000000000003  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.48000000000000004  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.49  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Accuracy for threshold: 0.5  is: 0.666\n",
      "Balanced accuracy is:  0.5967051004884298\n",
      "Best thresh:  0.01\n",
      "Best balanced accuracy: 0.5967\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.8090\n",
      "Corresponding average odds difference value: -0.2666\n",
      "Corresponding statistical parity difference value: -0.1637\n",
      "Corresponding equal opportunity difference value: -0.0848\n",
      "Corresponding Theil index value: 0.2455\n",
      "Corresponding false positive_rate for privileged: 1.0000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5515\n",
      "Corresponding false negative_rate for unprivileged: 0.2514\n",
      "Testing Original ...\n",
      "Accuracy for threshold: 0.01  is: 0.682\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "True positive rate is:  0.7734806629834254\n",
      "True negative rate is:  0.4420289855072464\n",
      "Balanced accuracy is:  0.6077548242453359\n",
      "Test Accuracy is:  0.682\n",
      "Best balanced accuracy: 0.6078\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.8282\n",
      "Corresponding average odds difference value: -0.2552\n",
      "Corresponding statistical parity difference value: -0.1473\n",
      "Corresponding equal opportunity difference value: -0.0619\n",
      "Corresponding Theil index value: 0.2257\n",
      "Corresponding false positive_rate for privileged: 1.0000\n",
      "Corresponding false negative_rate for privileged: 0.1667\n",
      "Corresponding false positive_rate for unpribileged: 0.5515\n",
      "Corresponding false negative_rate for unprivileged: 0.2286\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 160\n",
      "Number of test samples (ntest): 136\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 350\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 2\n",
      "Number of test samples (ntest): 2\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 21\n",
      "Number of test samples (ntest): 12\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.16170528965505807\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 162, Test = 138\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.7193423346069456\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 338, Test = 362\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.38852008037297825\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 160, Test = 136\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.7193423346069456\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 350\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.38852008037297825\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 2, Test = 2\n",
      "  AUC: 1.00\n",
      "  Privacy Risk: 1.00\n",
      "  Accuracy: 1.00\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 1.00\n",
      "  Attacker advantage: 1.00\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 21, Test = 12\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Fitting ExponentiatedGradient ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done fitting\n",
      "Accuracy for threshold: 0.01  is: 0.362\n",
      "Balanced accuracy is:  0.3934862679157659\n",
      "Accuracy for threshold: 0.02  is: 0.362\n",
      "Balanced accuracy is:  0.3934862679157659\n",
      "Accuracy for threshold: 0.03  is: 0.362\n",
      "Balanced accuracy is:  0.3934862679157659\n",
      "Accuracy for threshold: 0.04  is: 0.362\n",
      "Balanced accuracy is:  0.3934862679157659\n",
      "Accuracy for threshold: 0.05  is: 0.362\n",
      "Balanced accuracy is:  0.3934862679157659\n",
      "Accuracy for threshold: 0.060000000000000005  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.06999999999999999  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.08  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.09  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.09999999999999999  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.11  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.12  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.13  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.14  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.15000000000000002  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.16  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.17  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.18000000000000002  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.19  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.2  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.21000000000000002  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.22  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.23  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.24000000000000002  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.25  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.26  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.27  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.28  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.29000000000000004  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.3  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.31  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.32  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.33  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.34  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.35000000000000003  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.36000000000000004  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.37  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.38  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.39  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.4  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.41000000000000003  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.42000000000000004  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.43  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.44  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.45  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.46  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.47000000000000003  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.48000000000000004  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.49  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.5  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Accuracy for threshold: 0.5  is: 0.346\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "True positive rate is:  0.2513812154696133\n",
      "True negative rate is:  0.5942028985507246\n",
      "Balanced accuracy is:  0.422792057010169\n",
      "Test Accuracy is:  0.346\n",
      "Best balanced accuracy: 0.4228\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.4788\n",
      "Corresponding average odds difference value: 0.2497\n",
      "Corresponding statistical parity difference value: 0.1555\n",
      "Corresponding equal opportunity difference value: 0.0876\n",
      "Corresponding Theil index value: 0.8345\n",
      "Corresponding false positive_rate for privileged: 0.0000\n",
      "Corresponding false negative_rate for privileged: 0.8333\n",
      "Corresponding false positive_rate for unpribileged: 0.4118\n",
      "Corresponding false negative_rate for unprivileged: 0.7457\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.94      0.97       160\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94       160\n",
      "   macro avg       0.50      0.47      0.49       160\n",
      "weighted avg       1.00      0.94      0.97       160\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      1.00      1.00       317\n",
      "\n",
      "    accuracy                           1.00       317\n",
      "   macro avg       0.50      0.50      0.50       317\n",
      "weighted avg       1.00      1.00      1.00       317\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.43      0.60       136\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.43       136\n",
      "   macro avg       0.50      0.21      0.30       136\n",
      "weighted avg       1.00      0.43      0.60       136\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.74      0.85       350\n",
      "\n",
      "    accuracy                           0.74       350\n",
      "   macro avg       0.50      0.37      0.43       350\n",
      "weighted avg       1.00      0.74      0.85       350\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       2.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.50      0.42      0.45        12\n",
      "weighted avg       1.00      0.83      0.91        12\n",
      "\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 160\n",
      "Number of test samples (ntest): 136\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 317\n",
      "Number of test samples (ntest): 350\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 2\n",
      "Number of test samples (ntest): 2\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 21\n",
      "Number of test samples (ntest): 12\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 500, Test = 500\n",
      "  AUC: 0.70\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.38\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 162, Test = 138\n",
      "  AUC: 0.82\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.59\n",
      "  Positive predictive value: 0.78\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 338, Test = 362\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.31\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 160, Test = 136\n",
      "  AUC: 0.82\n",
      "  Privacy Risk: 0.80\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.59\n",
      "  Positive predictive value: 0.78\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 317, Test = 350\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 2, Test = 2\n",
      "  AUC: 1.00\n",
      "  Privacy Risk: 1.00\n",
      "  Accuracy: 1.00\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 1.00\n",
      "  Attacker advantage: 1.00\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -0.05379642460566901\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 21, Test = 12\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] post-processing Calibrated Equal Odds ......\n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Best balanced accuracy: 0.6276\n",
      "Corresponding 1-min(DI, 1/DI) value: 0.6831\n",
      "Corresponding average odds difference value: -0.3729\n",
      "Corresponding statistical parity difference value: -0.3169\n",
      "Corresponding equal opportunity difference value: -0.2457\n",
      "Corresponding Theil index value: 0.2330\n",
      "Corresponding false positive_rate for privileged: 1.0000\n",
      "Corresponding false negative_rate for privileged: 0.0000\n",
      "Corresponding false positive_rate for unpribileged: 0.5000\n",
      "Corresponding false negative_rate for unprivileged: 0.2457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# run mitigating algorithms\n",
    "for i in range(N):\n",
    "    # split dataset into train, validation, and test\n",
    "    dataset_orig_train, dataset_orig_test = dataset_orig.split([p], shuffle=True)\n",
    "    dataset_orig_val = dataset_orig_test\n",
    "    print(\"#### Train dataset's features are as below:\")\n",
    "    print(dataset_orig_train.features)\n",
    "\n",
    "    # favorable and unfavorable labels and feature_names\n",
    "    f_label = dataset_orig_train.favorable_label\n",
    "    uf_label = dataset_orig_train.unfavorable_label\n",
    "    feature_names = dataset_orig_train.feature_names\n",
    "\n",
    "    # introduce label or selection biases, assuming the original data is fair\n",
    "    if BIAS_TYPE == 'label':\n",
    "        dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    elif BIAS_TYPE == 'selection':\n",
    "        dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    else:\n",
    "        print('no bias type specified')\n",
    "\n",
    "    # show data info\n",
    "    print(\"#### Training Dataset shape\")\n",
    "    print(dataset_orig_train.features.shape)\n",
    "    print(\"#### Favorable and unfavorable labels\")\n",
    "    print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "    print(\"#### Protected attribute names\")\n",
    "    print(dataset_orig_train.protected_attribute_names)\n",
    "    print(\"#### Privileged and unprivileged protected groups\")\n",
    "    print(privileged_groups, unprivileged_groups)\n",
    "    print(\"#### Privileged and unprivileged protected attribute values\")\n",
    "    print(dataset_orig_train.privileged_protected_attributes, dataset_orig_train.unprivileged_protected_attributes)\n",
    "    print(\"#### Dataset feature names\")\n",
    "    print(dataset_orig_train.feature_names)\n",
    "\n",
    "    # check fairness on the original data\n",
    "    metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    print(\"privileged vs. unprivileged: \", metric_orig_train.num_positives(privileged=True) + metric_orig_train.num_negatives(privileged=True), metric_orig_train.num_positives(privileged=False) + metric_orig_train.num_negatives(privileged=False)) \n",
    "    base_rate_unprivileged = metric_orig_train.base_rate(privileged=False)\n",
    "    base_rate_privileged = metric_orig_train.base_rate(privileged=True)\n",
    "    print('base_pos unpriv: ', base_rate_unprivileged)\n",
    "    print('base_pos priv: ', base_rate_privileged)\n",
    "    print('number of favorable labels: ', np.count_nonzero(dataset_orig_train.labels==f_label))\n",
    "    print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "    # statistics of favored/positive class BEFORE transf \n",
    "    priv_metric_orig['total_priv'] += metric_orig_train.num_instances(privileged = True) \n",
    "    priv_metric_orig['total_unpriv'] += metric_orig_train.num_instances(privileged = False) \n",
    "    favor_metric_orig['total_favor'] += metric_orig_train.base_rate()\n",
    "    favor_metric_orig['total_unfavor'] += 1 - metric_orig_train.base_rate()\n",
    "    favor_metric_orig['priv_favor'] += metric_orig_train.base_rate(privileged = True)\n",
    "    favor_metric_orig['priv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = True)\n",
    "    favor_metric_orig['unpriv_favor'] += metric_orig_train.base_rate(privileged = False)\n",
    "    favor_metric_orig['unpriv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = False)\n",
    "\n",
    "    print(\"#### Train shape, validation shape, test shape\")\n",
    "    print(dataset_orig_train.features.shape, dataset_orig_val.features.shape, dataset_orig_test.features.shape)\n",
    "\n",
    "    # testing mitigation methods \n",
    "    test_cases = TestAlgorithms(BASELINE)\n",
    "\n",
    "    # null mitigator\n",
    "    orig_metrics, orig_mia_metrics = test_cases.run_original(dataset_orig_train, dataset_orig_val, dataset_orig_test, BASELINE, orig_metrics, orig_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, THRESH_ARR, DISPLAY, SCALER) \n",
    "\n",
    "    # synthetic data mitigator\n",
    "    metric_transf_train, transf_metrics, transf_mia_metrics = test_cases.run_oversample(dataset_orig_train, dataset_orig_val, dataset_orig_test, privileged_groups, unprivileged_groups, base_rate_privileged, base_rate_unprivileged, BASELINE, transf_metrics, transf_mia_metrics, f_label, uf_label, THRESH_ARR, DISPLAY, OS_MODE, SCALER)\n",
    "    \n",
    "    # statistics of favored/positive class AFTER transf\n",
    "    favor_metric_transf['total_favor'] += metric_transf_train.base_rate()\n",
    "    favor_metric_transf['total_unfavor'] += 1 - metric_transf_train.base_rate()\n",
    "    favor_metric_transf['priv_favor'] += metric_transf_train.base_rate(privileged = True)\n",
    "    favor_metric_transf['priv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = True)\n",
    "    favor_metric_transf['unpriv_favor'] += metric_transf_train.base_rate(privileged = False)\n",
    "    favor_metric_transf['unpriv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = False)\n",
    "\n",
    "    # dir mitigator\n",
    "    dir_metrics, dir_mia_metrics = test_cases.run_dir(dataset_orig_train, dataset_orig_val, dataset_orig_test,  sens_attr, BASELINE, dir_metrics, dir_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, THRESH_ARR, DISPLAY, SCALER) \n",
    "    \n",
    "    # reweigh mitigator\n",
    "    reweigh_metrics, reweigh_mia_metrics = test_cases.run_rew(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, reweigh_metrics, reweigh_mia_metrics, THRESH_ARR, DISPLAY, SCALER)\n",
    "\n",
    "    # egr mitigator, in-processing\n",
    "    train_test_egr, egr_metrics, egr_mia_metrics = test_cases.run_egr(dataset_orig_train, dataset_orig_val, dataset_orig_test, egr_metrics, egr_mia_metrics, BASELINE, f_label, uf_label, unprivileged_groups, privileged_groups,THRESH_ARR, DISPLAY, SCALER)\n",
    "    # egr gave error so I replaced it with reweigh\n",
    "#     egr_metrics, egr_mia_metrics = test_cases.run_rew(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, egr_metrics, egr_mia_metrics, THRESH_ARR, DISPLAY, SCALER)\n",
    "\n",
    "    # cpp mitigator\n",
    "    cpp_metrics = test_cases.run_cpp(dataset_orig_train, dataset_orig_val, dataset_orig_test, cpp_metrics, BASELINE, unprivileged_groups, privileged_groups, THRESH_ARR, SCALER)\n",
    "\n",
    "    # ro mitigator\n",
    "    # ro_metrics = test_cases.run_ro(dataset_orig_train, dataset_orig_val, dataset_orig_test, ro_metrics, BASELINE, unprivileged_groups, privileged_groups, THRESH_ARR, SCALER)\n",
    "\n",
    "    if (BASELINE == 'lr'):\n",
    "        pr_orig_metrics = test_cases.run_pr(dataset_orig_train, dataset_orig_val, dataset_orig_test, pr_orig_metrics, sens_attr, f_label, uf_label, unprivileged_groups, privileged_groups, THRESH_ARR, DISPLAY, SCALER) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90de2a9",
   "metadata": {},
   "source": [
    "## Display Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72632350",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig_copy = priv_metric_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8530a47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float, {'total_priv': 160.0, 'total_unpriv': 3340.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priv_metric_orig_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b736dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float, {'total_priv': 160.0, 'total_unpriv': 3340.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priv_metric_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c73a4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig = priv_metric_orig_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf623751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)\n",
      "\n",
      "german_foreign\n",
      "500\n",
      "2)\n",
      "\n",
      "              total_priv  total_unpriv\n",
      "num_instance                          \n",
      "orig           53.333333   1113.333333\n",
      "3)\n",
      "\n",
      "         total_favor  total_unfavor  priv_favor  priv_unfavor  unpriv_favor  \\\n",
      "dataset                                                                       \n",
      "orig        1.591333       0.742000    2.085231      0.248102      1.567698   \n",
      "transf      1.807334       0.192666    1.807453      0.192547      1.807332   \n",
      "\n",
      "         unpriv_unfavor  \n",
      "dataset                  \n",
      "orig           0.765635  \n",
      "transf         0.192668  \n",
      "4)\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'numerator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# dataframe to display fairness metrics\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# error metrics\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m orig_error_metrics \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mstatistics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43morig_metrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     26\u001b[0m transf_error_metrics \u001b[38;5;241m=\u001b[39m {k: [statistics\u001b[38;5;241m.\u001b[39mstdev(v)] \u001b[38;5;28;01mfor\u001b[39;00m (k,v) \u001b[38;5;129;01min\u001b[39;00m transf_metrics\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     27\u001b[0m reweigh_error_metrics \u001b[38;5;241m=\u001b[39m {k: [statistics\u001b[38;5;241m.\u001b[39mstdev(v)] \u001b[38;5;28;01mfor\u001b[39;00m (k,v) \u001b[38;5;129;01min\u001b[39;00m reweigh_metrics\u001b[38;5;241m.\u001b[39mitems()}\n",
      "Cell \u001b[1;32mIn[41], line 25\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# dataframe to display fairness metrics\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# error metrics\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m orig_error_metrics \u001b[38;5;241m=\u001b[39m {k: [\u001b[43mstatistics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;28;01mfor\u001b[39;00m (k,v) \u001b[38;5;129;01min\u001b[39;00m orig_metrics\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     26\u001b[0m transf_error_metrics \u001b[38;5;241m=\u001b[39m {k: [statistics\u001b[38;5;241m.\u001b[39mstdev(v)] \u001b[38;5;28;01mfor\u001b[39;00m (k,v) \u001b[38;5;129;01min\u001b[39;00m transf_metrics\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     27\u001b[0m reweigh_error_metrics \u001b[38;5;241m=\u001b[39m {k: [statistics\u001b[38;5;241m.\u001b[39mstdev(v)] \u001b[38;5;28;01mfor\u001b[39;00m (k,v) \u001b[38;5;129;01min\u001b[39;00m reweigh_metrics\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\statistics.py:922\u001b[0m, in \u001b[0;36mstdev\u001b[1;34m(data, xbar)\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(T, Decimal):\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _decimal_sqrt_of_frac(mss\u001b[38;5;241m.\u001b[39mnumerator, mss\u001b[38;5;241m.\u001b[39mdenominator)\n\u001b[1;32m--> 922\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _float_sqrt_of_frac(\u001b[43mmss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumerator\u001b[49m, mss\u001b[38;5;241m.\u001b[39mdenominator)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'numerator'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "print('1)\\n')\n",
    "print(DATASET)\n",
    "print(dataset_orig_train.features.shape[0])\n",
    "\n",
    "print('2)\\n')\n",
    "priv_metric_orig = {k: [v/N] for (k,v) in priv_metric_orig.items()}\n",
    "results = [priv_metric_orig]\n",
    "tr = pd.Series(['orig'], name='num_instance')\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis = 0).set_index([tr])\n",
    "print(df)\n",
    "\n",
    "print('3)\\n')\n",
    "favor_metric_orig = {k: [v/N] for (k,v) in favor_metric_orig.items()}\n",
    "favor_metric_transf = {k: [v/N] for (k,v) in favor_metric_transf.items()}\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "results = [favor_metric_orig, favor_metric_transf]\n",
    "tr = pd.Series(['orig'] + ['transf'], name='dataset')\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis = 0).set_index([tr])\n",
    "print(df)\n",
    "\n",
    "print('4)\\n')\n",
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_error_metrics = {k: [statistics.stdev(v)] for (k,v) in orig_metrics.items()}\n",
    "transf_error_metrics = {k: [statistics.stdev(v)] for (k,v) in transf_metrics.items()}\n",
    "reweigh_error_metrics = {k: [statistics.stdev(v)] for (k,v) in reweigh_metrics.items()}\n",
    "dir_error_metrics = {k: [statistics.stdev(v)] for (k,v) in dir_metrics.items()}\n",
    "egr_error_metrics = {k: [statistics.stdev(v)] for (k,v) in egr_metrics.items()}\n",
    "pr_orig_error_metrics = {k: [statistics.stdev(v)] for (k,v) in pr_orig_metrics.items()}\n",
    "cpp_error_metrics = {k: [statistics.stdev(v)] for (k,v) in cpp_metrics.items()}\n",
    "ro_error_metrics = {k: [statistics.stdev(v)] for (k,v) in ro_metrics.items()}\n",
    "\n",
    "# mean value metrics\n",
    "orig_metrics_mean = {k: [sum(v)/N] for (k,v) in orig_metrics.items()}\n",
    "transf_metrics_mean = {k: [sum(v)/N] for (k,v) in transf_metrics.items()}\n",
    "reweigh_metrics_mean = {k:[sum(v)/N] for (k,v) in reweigh_metrics.items()}\n",
    "dir_metrics_mean = {k:[sum(v)/N] for (k,v) in dir_metrics.items()}\n",
    "egr_metrics_mean = {k:[sum(v)/N] for (k,v) in egr_metrics.items()}\n",
    "pr_orig_metrics_mean = {k: [sum(v)/N] for (k,v) in pr_orig_metrics.items()}\n",
    "cpp_metrics_mean = {k: [sum(v)/N] for (k,v) in cpp_metrics.items()}\n",
    "ro_metrics_mean = {k: [sum(v)/N] for (k,v) in ro_metrics.items()}\n",
    "\n",
    "# Python paired sample t-test\n",
    "from scipy.stats import ttest_rel\n",
    "def paired_t (a, b):\n",
    "    np_a = np.array(a)\n",
    "    np_b = np.array(b)\n",
    "    s, p = ttest_rel(np.absolute(np_a), np.absolute(np_b))\n",
    "    return p\n",
    "\n",
    "def acc_diff (a, b):\n",
    "    np_a = np.array(a)\n",
    "    np_b = np.array(b)\n",
    "    delta = np_a - np_b\n",
    "    m = statistics.mean(delta)\n",
    "    s = statistics.stdev(delta)\n",
    "    return [m, s]\n",
    "\n",
    "if BASELINE == 'lr':\n",
    "    plot_algo_lr(orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, egr_metrics_mean, pr_orig_metrics_mean, cpp_metrics_mean, ro_metrics_mean, orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, egr_error_metrics, pr_orig_error_metrics, cpp_error_metrics, ro_error_metrics, BASELINE)\n",
    "    stat =  {k: [paired_t(transf_metrics[k], v)] for (k,v) in orig_metrics.items()}\n",
    "    print(\"5)\")\n",
    "    print(stat)\n",
    "else:\n",
    "    plot_algo(orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, egr_metrics_mean, cpp_metrics_mean, ro_metrics_mean, orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, egr_error_metrics, cpp_error_metrics, ro_error_metrics, BASELINE)\n",
    "    stat =  {k: [paired_t(transf_metrics[k], v)] for (k,v) in orig_metrics.items()}\n",
    "    print(stat)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1627a85",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f14ab",
   "metadata": {},
   "source": [
    "### Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c6d438",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = BASELINE\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_metrics_mean,\n",
    "        transf_metrics_mean,\n",
    "        dir_metrics_mean,\n",
    "        reweigh_metrics_mean,\n",
    "        egr_metrics_mean,\n",
    "        pr_orig_metrics_mean,\n",
    "        cpp_metrics_mean,\n",
    "        ro_metrics_mean]\n",
    "\n",
    "\n",
    "errors = [orig_error_metrics,\n",
    "        transf_error_metrics,\n",
    "        dir_error_metrics,\n",
    "        reweigh_error_metrics,\n",
    "        egr_error_metrics,\n",
    "        pr_orig_error_metrics,\n",
    "        cpp_error_metrics,\n",
    "        ro_error_metrics]\n",
    "\n",
    "index = pd.Series([model_type+'_orig']+ [model_type+'_syn']+ [model_type+'_dir']+ [model_type+'_rew']+ [model_type+'_egr'] + [model_type+'_cpp'], name='Classifier Bias Mitigator')\n",
    "\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis=0).set_index(index)\n",
    "df_error = pd.concat([pd.DataFrame(metrics) for metrics in errors], axis=0).set_index(index)\n",
    "ax = df.plot.bar(yerr=df_error, capsize=4, rot=0, subplots=True, title=['','','','','', '', '', '', '', ''], fontsize = 12, figsize=(10,10))\n",
    "plot1 = ax[0]\n",
    "plot1.set_ylim=([0, 0.8])\n",
    "plot2 = ax[1]\n",
    "plot2.set_ylim=([-0.5, 0])\n",
    "plot3 = ax[2]\n",
    "plot3.set_ylim=([0, 1])\n",
    "plot4 = ax[3]\n",
    "plot4.set_ylim=([-0.5, 0])\n",
    "plot5 = ax[4]\n",
    "plot5.set_ylim=([-0.5, 0])\n",
    "plot5 = ax[5]\n",
    "plot5.set_ylim=([0, 0.2])\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.5, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6be0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7aff8d",
   "metadata": {},
   "source": [
    "## Visualization of MIA results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588cc377",
   "metadata": {},
   "source": [
    "### Visualization of MIA Attacks against various Fairness Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a42bd",
   "metadata": {},
   "source": [
    "#### Privacy risk subpopulations vs Fairness with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dddfde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "%matplotlib inline\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "egr_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in egr_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "# cpp_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in cpp_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "egr_mia_metrics_mean = {k:sum(v)/N for (k,v) in egr_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "# cpp_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6882740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "           transf_mia_metrics_mean,\n",
    "           dir_mia_metrics_mean,\n",
    "           reweigh_mia_metrics_mean,\n",
    "           egr_mia_metrics_mean\n",
    "          ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "          transf_mia_error_metrics,\n",
    "          dir_mia_error_metrics,\n",
    "          reweigh_mia_error_metrics,\n",
    "          egr_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn']+ ['dir']+ ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df1431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = df[['subpopulation_0.0_label_0.0_mia_privacy_risk',\n",
    "       'subpopulation_0.0_label_1.0_mia_privacy_risk',\n",
    "       'subpopulation_1.0_label_0.0_mia_privacy_risk',\n",
    "       'subpopulation_1.0_label_1.0_mia_privacy_risk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d711e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f230c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabular Format\n",
    "# importing the modules\n",
    "from tabulate import tabulate\n",
    "\n",
    " \n",
    "# displaying the DataFrame\n",
    "print(tabulate(df_groups.T, headers = 'keys', tablefmt = 'simple'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a2e6d",
   "metadata": {},
   "source": [
    "### Visualizing using novel technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faed82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_error_metrics = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "egr_mia_error_metrics = {k: v for (k,v) in egr_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "#orig_mia_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_error_metrics.keys():\n",
    "    for val in orig_mia_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in egr_mia_error_metrics.keys():\n",
    "    for val in egr_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"egr\", key.replace(\"_mia_attacker_advantage\", \"\"), val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b110698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"Privacy Risk\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8a5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only subgroups\n",
    "df_subgroups = df[~((df[\"MIA\"] == \"entire_dataset_label_0.0_mia_privacy_risk\") | (df[\"MIA\"] == \"entire_dataset_label_1.0_mia_privacy_risk\")) ]\n",
    "df_subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df3d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15,8))\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df_subgroups, x=\"MIA\", y=\"Privacy Risk\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Privacy Risk\" )\n",
    "g.set(ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359dc0bf",
   "metadata": {},
   "source": [
    "### ROC curves and AUC scores with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7b52ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb5d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for orig dataset with different subpopulations\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for key in [\"entire_dataset_mia_result\", \"subpopulation_0.0_label_0.0_mia_result\",\n",
    "            \"subpopulation_0.0_label_1.0_mia_result\", \"subpopulation_1.0_label_0.0_mia_result\", \"subpopulation_1.0_label_1.0_mia_result\"]:\n",
    "     # fprs = [mia_res.fpr for mia_res in orig_mia_metrics[key]]\n",
    "    # tprs = [mia_res.tpr for mia_res in orig_mia_metrics[key]]\n",
    "    tprs = []\n",
    "    \n",
    "    # aucs = [mia_res.get_auc() for mia_res in orig_mia_metrics[key]]\n",
    "    aucs = []\n",
    "\n",
    "    # mean_fpr = np.mean(fprs, axis=0)\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "    for mia_res in orig_mia_metrics[key]:\n",
    "        interp_tpr = np.interp(mean_fpr, mia_res.fpr, mia_res.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(mia_res.get_auc())\n",
    "    \n",
    "    #print(mean_fpr)\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    \n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    \n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        #color=\"b\",\n",
    "        label=r\"Mean ROC for %s $\\pm$ 1 std. dev. (AUC = %0.2f $\\pm$ %0.2f)\" % ( key ,mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        #label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve with variability\",\n",
    ")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ff10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entire dataset with different subpopulations\n",
    "# fig, ax = plt.subplots(figsize=(12, 10))\n",
    "fig, ax = plt.subplots(figsize=(24, 18))\n",
    "\n",
    "for mia_metrics, name in zip([orig_mia_metrics, transf_mia_metrics, dir_mia_metrics, reweigh_mia_metrics], [\"orig\", \"syn\", \"dir\", \"reweigh\"] ):\n",
    "    for key in [\"entire_dataset_mia_result\", \"subpopulation_0.0_label_0.0_mia_result\",\n",
    "            \"subpopulation_0.0_label_1.0_mia_result\", \"subpopulation_1.0_label_0.0_mia_result\",\n",
    "                \"subpopulation_1.0_label_1.0_mia_result\"]:\n",
    "   \n",
    "        # fprs = [mia_res.fpr for mia_res in orig_mia_metrics[key]]\n",
    "        # tprs = [mia_res.tpr for mia_res in orig_mia_metrics[key]]\n",
    "        tprs = []\n",
    "        # aucs = [mia_res.get_auc() for mia_res in orig_mia_metrics[key]]\n",
    "        aucs = []\n",
    "\n",
    "        # mean_fpr = np.mean(fprs, axis=0)\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "        for mia_res in mia_metrics[key]:\n",
    "            interp_tpr = np.interp(mean_fpr, mia_res.fpr, mia_res.tpr)\n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "            aucs.append(mia_res.get_auc())\n",
    "\n",
    "        #print(mean_fpr)\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std(aucs)\n",
    "\n",
    "        ax.plot(\n",
    "            mean_fpr,\n",
    "            mean_tpr,\n",
    "            #color=\"b\",\n",
    "            label=r\"%s Mean ROC for %s $\\pm$ 1 std. dev. (AUC = %0.2f $\\pm$ %0.2f)\" % (name, key ,mean_auc, std_auc),\n",
    "            lw=2,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        std_tpr = np.std(tprs, axis=0)\n",
    "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        ax.fill_between(\n",
    "            mean_fpr,\n",
    "            tprs_lower,\n",
    "            tprs_upper,\n",
    "            color=\"grey\",\n",
    "            alpha=0.2,\n",
    "            #label=r\"$\\pm$ 1 std. dev.\",\n",
    "        )\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve for MIA attacks against Fairness Approaches\",\n",
    ")\n",
    "ax.legend(loc=\"lower right\")\n",
    "# ax.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entire dataset\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "for mia_res in orig_mia_metrics[\"entire_dataset_mia_result\"]:\n",
    "    plt.plot(mia_res.fpr,mia_res.tpr,label=f\"{mia_res.get_name()} auc={mia_res.get_auc()}\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e701aad9",
   "metadata": {},
   "source": [
    "## MIA Attacks AUC vs Fairness Bar Chart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f18425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"mia_auc\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a025ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b078a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuazlization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "        transf_mia_metrics_mean,\n",
    "        dir_mia_metrics_mean,\n",
    "        reweigh_mia_metrics_mean,\n",
    "        ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "        transf_mia_error_metrics,\n",
    "        dir_mia_error_metrics,\n",
    "        reweigh_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn']+ ['dir']+ ['rew'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2233661a",
   "metadata": {},
   "source": [
    "###  MIA Attackers Advantage Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f09191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data structures to plot point categorical plot from seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ef741",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "egr_mia_error_metrics = {k: v for (k,v) in egr_mia_metrics.items() if k.endswith(\"attacker_advantage\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87375802",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efae376f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'orig_mia_metrics_att_ad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m advantage_metrics_arrays \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[43morig_mia_metrics_att_ad\u001b[49m\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m orig_mia_metrics_att_ad[key]:\n\u001b[0;32m      4\u001b[0m         advantage_metrics_arrays\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morig\u001b[39m\u001b[38;5;124m\"\u001b[39m, key\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_mia_attacker_advantage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m), val])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'orig_mia_metrics_att_ad' is not defined"
     ]
    }
   ],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_metrics_att_ad.keys():\n",
    "    for val in orig_mia_metrics_att_ad[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in egr_mia_error_metrics.keys():\n",
    "    for val in egr_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"egr\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "advantage_metrics_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "105df8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fairness</th>\n",
       "      <th>MIA</th>\n",
       "      <th>attacker_advantage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Fairness, MIA, attacker_advantage]\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"attacker_advantage\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45ac8578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m sns\u001b[38;5;241m.\u001b[39mset_theme()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#sns.set_style('ticks')\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcatplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMIA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattacker_advantage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFairness\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#palette={\"male\": \"g\", \"female\": \"m\"},\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmarkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m^\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinestyles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks(rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m     14\u001b[0m g\u001b[38;5;241m.\u001b[39mset_axis_labels(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassifier Membership Inference Attacks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttacker\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Advantage\u001b[39m\u001b[38;5;124m\"\u001b[39m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:3040\u001b[0m, in \u001b[0;36mcatplot\u001b[1;34m(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, seed, units, weights, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs)\u001b[0m\n\u001b[0;32m   3028\u001b[0m     p\u001b[38;5;241m.\u001b[39m_point_kwargs_backcompat(\n\u001b[0;32m   3029\u001b[0m         kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m\"\u001b[39m, deprecated),\n\u001b[0;32m   3030\u001b[0m         kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoin\u001b[39m\u001b[38;5;124m\"\u001b[39m, deprecated),\n\u001b[0;32m   3031\u001b[0m         kwargs\n\u001b[0;32m   3032\u001b[0m     )\n\u001b[0;32m   3033\u001b[0m     err_kws, capsize \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39m_err_kws_backcompat(\n\u001b[0;32m   3034\u001b[0m         normalize_kwargs(kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merr_kws\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}), mpl\u001b[38;5;241m.\u001b[39mlines\u001b[38;5;241m.\u001b[39mLine2D),\n\u001b[0;32m   3035\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3036\u001b[0m         errwidth\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m, deprecated),\n\u001b[0;32m   3037\u001b[0m         capsize\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapsize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m   3038\u001b[0m     )\n\u001b[1;32m-> 3040\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_points\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3041\u001b[0m \u001b[43m        \u001b[49m\u001b[43maggregator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3042\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmarkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmarkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3043\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinestyles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinestyles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3044\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdodge\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdodge\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3047\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr_kws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3049\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3051\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   3053\u001b[0m     aggregator \u001b[38;5;241m=\u001b[39m agg_cls(estimator, errorbar, n_boot\u001b[38;5;241m=\u001b[39mn_boot, seed\u001b[38;5;241m=\u001b[39mseed)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:1184\u001b[0m, in \u001b[0;36m_CategoricalPlotter.plot_points\u001b[1;34m(self, aggregator, markers, linestyles, dodge, color, capsize, err_kws, plot_kws)\u001b[0m\n\u001b[0;32m   1181\u001b[0m plot_kws\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkeredgewidth\u001b[39m\u001b[38;5;124m\"\u001b[39m, plot_kws[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinewidth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.75\u001b[39m)\n\u001b[0;32m   1182\u001b[0m plot_kws\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkersize\u001b[39m\u001b[38;5;124m\"\u001b[39m, plot_kws[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinewidth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi))\n\u001b[1;32m-> 1184\u001b[0m markers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_prop_with_hue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmarker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_kws\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m linestyles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_prop_with_hue(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinestyle\u001b[39m\u001b[38;5;124m\"\u001b[39m, linestyles, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, plot_kws)\n\u001b[0;32m   1187\u001b[0m base_positions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_levels[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:346\u001b[0m, in \u001b[0;36m_CategoricalPlotter._map_prop_with_hue\u001b[1;34m(self, name, value, fallback, plot_kws)\u001b[0m\n\u001b[0;32m    344\u001b[0m levels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hue_map\u001b[38;5;241m.\u001b[39mlevels\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m--> 346\u001b[0m     mapping \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m}\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     mapping \u001b[38;5;241m=\u001b[39m {k: value \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m levels}\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting without scaling y limis to 1\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"attacker_advantage\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's Advantage\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf746e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15,8))\n",
    "\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"attacker_advantage\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's Advantage\" )\n",
    "g.set(ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b0356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(orig_mia_metrics_att_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "egr_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in egr_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "egr_mia_metrics_mean = {k:sum(v)/N for (k,v) in egr_mia_metrics.items() if k.endswith(\"attacker_advantage\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e9be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuazlization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "        transf_mia_metrics_mean,\n",
    "        dir_mia_metrics_mean,\n",
    "        reweigh_mia_metrics_mean,\n",
    "           egr_mia_metrics_mean\n",
    "        ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "        transf_mia_error_metrics,\n",
    "        dir_mia_error_metrics,\n",
    "        reweigh_mia_error_metrics,\n",
    "          egr_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn']+ ['dir']+ ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1309a4",
   "metadata": {},
   "source": [
    "## PPV Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "egr_mia_error_metrics = {k: v for (k,v) in egr_mia_metrics.items() if k.endswith(\"mia_ppv\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14018577",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'orig_mia_metrics_att_ad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m advantage_metrics_arrays \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[43morig_mia_metrics_att_ad\u001b[49m\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m orig_mia_metrics_att_ad[key]:\n\u001b[0;32m      4\u001b[0m         advantage_metrics_arrays\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morig\u001b[39m\u001b[38;5;124m\"\u001b[39m, key\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_mia_ppv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m), val])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'orig_mia_metrics_att_ad' is not defined"
     ]
    }
   ],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_metrics_att_ad.keys():\n",
    "    for val in orig_mia_metrics_att_ad[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in egr_mia_error_metrics.keys():\n",
    "    for val in egr_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"egr\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "advantage_metrics_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "95980069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fairness</th>\n",
       "      <th>MIA</th>\n",
       "      <th>PPV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Fairness, MIA, PPV]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"PPV\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fff9b694",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m sns\u001b[38;5;241m.\u001b[39mset_theme()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#sns.set_style('ticks')\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcatplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMIA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPPV\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFairness\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#palette={\"male\": \"g\", \"female\": \"m\"},\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmarkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m^\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinestyles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks(rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m     15\u001b[0m g\u001b[38;5;241m.\u001b[39mset_axis_labels(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassifier Membership Inference Attacks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttacker\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms PPV\u001b[39m\u001b[38;5;124m\"\u001b[39m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:3040\u001b[0m, in \u001b[0;36mcatplot\u001b[1;34m(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, seed, units, weights, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs)\u001b[0m\n\u001b[0;32m   3028\u001b[0m     p\u001b[38;5;241m.\u001b[39m_point_kwargs_backcompat(\n\u001b[0;32m   3029\u001b[0m         kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m\"\u001b[39m, deprecated),\n\u001b[0;32m   3030\u001b[0m         kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoin\u001b[39m\u001b[38;5;124m\"\u001b[39m, deprecated),\n\u001b[0;32m   3031\u001b[0m         kwargs\n\u001b[0;32m   3032\u001b[0m     )\n\u001b[0;32m   3033\u001b[0m     err_kws, capsize \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39m_err_kws_backcompat(\n\u001b[0;32m   3034\u001b[0m         normalize_kwargs(kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merr_kws\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}), mpl\u001b[38;5;241m.\u001b[39mlines\u001b[38;5;241m.\u001b[39mLine2D),\n\u001b[0;32m   3035\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3036\u001b[0m         errwidth\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m, deprecated),\n\u001b[0;32m   3037\u001b[0m         capsize\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapsize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m   3038\u001b[0m     )\n\u001b[1;32m-> 3040\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_points\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3041\u001b[0m \u001b[43m        \u001b[49m\u001b[43maggregator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3042\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmarkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmarkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3043\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinestyles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinestyles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3044\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdodge\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdodge\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3047\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr_kws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3049\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3051\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   3053\u001b[0m     aggregator \u001b[38;5;241m=\u001b[39m agg_cls(estimator, errorbar, n_boot\u001b[38;5;241m=\u001b[39mn_boot, seed\u001b[38;5;241m=\u001b[39mseed)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:1184\u001b[0m, in \u001b[0;36m_CategoricalPlotter.plot_points\u001b[1;34m(self, aggregator, markers, linestyles, dodge, color, capsize, err_kws, plot_kws)\u001b[0m\n\u001b[0;32m   1181\u001b[0m plot_kws\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkeredgewidth\u001b[39m\u001b[38;5;124m\"\u001b[39m, plot_kws[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinewidth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.75\u001b[39m)\n\u001b[0;32m   1182\u001b[0m plot_kws\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkersize\u001b[39m\u001b[38;5;124m\"\u001b[39m, plot_kws[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinewidth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi))\n\u001b[1;32m-> 1184\u001b[0m markers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_prop_with_hue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmarker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_kws\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m linestyles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_prop_with_hue(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinestyle\u001b[39m\u001b[38;5;124m\"\u001b[39m, linestyles, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, plot_kws)\n\u001b[0;32m   1187\u001b[0m base_positions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_levels[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:346\u001b[0m, in \u001b[0;36m_CategoricalPlotter._map_prop_with_hue\u001b[1;34m(self, name, value, fallback, plot_kws)\u001b[0m\n\u001b[0;32m    344\u001b[0m levels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hue_map\u001b[38;5;241m.\u001b[39mlevels\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m--> 346\u001b[0m     mapping \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m}\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     mapping \u001b[38;5;241m=\u001b[39m {k: value \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m levels}\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting without scaling y limis to 1\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"PPV\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's PPV\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38297706",
   "metadata": {},
   "source": [
    "# Dataset Exploration for comparison with Shokri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c85d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame([dataset_orig.features, dataset_orig.labels]).drop_duplicates()\n",
    "\n",
    "df = pd.DataFrame(dataset_orig.features, columns=dataset_orig.feature_names)\n",
    "\n",
    "df[\"labels\"] = dataset_orig.labels\n",
    "df\n",
    "#df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d14528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"age\", \"labels\"]].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f7423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
