{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8c9f6b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b31f29-34e6-457c-8551-d9b3f8cfc0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "151964f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmatplotlib\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minline\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2481\u001b[39m, in \u001b[36mInteractiveShell.run_line_magic\u001b[39m\u001b[34m(self, magic_name, line, _stack_depth)\u001b[39m\n\u001b[32m   2479\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mlocal_ns\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.get_local_scope(stack_depth)\n\u001b[32m   2480\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m-> \u001b[39m\u001b[32m2481\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2483\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2484\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2485\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2486\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/IPython/core/magics/pylab.py:103\u001b[39m, in \u001b[36mPylabMagics.matplotlib\u001b[39m\u001b[34m(self, line)\u001b[39m\n\u001b[32m     98\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     99\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAvailable matplotlib backends: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m         % _list_matplotlib_backends_and_gui_loops()\n\u001b[32m    101\u001b[39m     )\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     gui, backend = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshell\u001b[49m\u001b[43m.\u001b[49m\u001b[43menable_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28mself\u001b[39m._show_matplotlib_backend(args.gui, backend)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3637\u001b[39m, in \u001b[36mInteractiveShell.enable_matplotlib\u001b[39m\u001b[34m(self, gui)\u001b[39m\n\u001b[32m   3634\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mmatplotlib_inline\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_inline\u001b[39;00m\n\u001b[32m   3636\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pylabtools \u001b[38;5;28;01mas\u001b[39;00m pt\n\u001b[32m-> \u001b[39m\u001b[32m3637\u001b[39m gui, backend = \u001b[43mpt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_gui_and_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgui\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpylab_gui_select\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3639\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gui != \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3640\u001b[39m     \u001b[38;5;66;03m# If we have our first gui selection, store it\u001b[39;00m\n\u001b[32m   3641\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pylab_gui_select \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/IPython/core/pylabtools.py:338\u001b[39m, in \u001b[36mfind_gui_and_backend\u001b[39m\u001b[34m(gui, gui_select)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mfind_gui_and_backend\u001b[39m(gui=\u001b[38;5;28;01mNone\u001b[39;00m, gui_select=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    322\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Given a gui string return the gui and mpl backend.\u001b[39;00m\n\u001b[32m    323\u001b[39m \n\u001b[32m    324\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    335\u001b[39m \u001b[33;03m    'WXAgg','Qt4Agg','module://matplotlib_inline.backend_inline','agg').\u001b[39;00m\n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mmatplotlib\u001b[39;00m\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _matplotlib_manages_backends():\n\u001b[32m    341\u001b[39m         backend_registry = matplotlib.backends.registry.backend_registry\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f57d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from data_utils import DatasetBuilder\n",
    "from metrics_utils import compute_metrics, describe_metrics, get_test_metrics, test\n",
    "from plot_utils import plot\n",
    "from mitigators import NullMitigator, SyntheticMitigator, DIRMitigator, ReweighMitigator, EGMitigator, PRMitigator, CPPMitigator, ROMitigator \n",
    "from test_algorithms import TestAlgorithms\n",
    "from plot_utils import plot_algo_lr, plot_algo\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from oversample import label_bias, selection_bias \n",
    "from sklearn import preprocessing\n",
    "from privacy_meter.dataset import Dataset\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180b2a8",
   "metadata": {},
   "source": [
    "## Arguments & Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c7837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct argument parser\n",
    "import argparse\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--data\", choices=['adult', 'compas', 'german', 'bank', 'meps19', 'grade', 'law_sex', 'law_race', 'law_aif_gender', 'law_aif_race'], default='compas', help=\"dataset: adult, compas, german, bank, meps19, grade\")\n",
    "ap.add_argument(\"-c\", \"--classifier\", choices=['lr', 'rf', 'svm', 'nn', 'nb'], default='lr', help=\"baseline model: lr, rf, svm, nn, nb, dt\")\n",
    "ap.add_argument(\"-m\", \"--mitigator\", choices=['dir', 'rew', 'egr', 'pr', 'cpp', 'ro'], required=False, help=\"mitigators: dir, rew, egr, pr, cpp, ro\")\n",
    "ap.add_argument(\"-b\", \"--bias\", default=0., help=\"amount of bias: o-1\")\n",
    "ap.add_argument(\"-t\", \"--biastype\", choices=['label', 'selection', 'none'], default='none', help=\"amount of bias: o-1\")\n",
    "ap.add_argument(\"-o\", \"--os\", default=2, help=\"oversample mode: 1: privi unfav 2: unpriv fav\")\n",
    "ap.add_argument(\"-a\", \"--attack\", choices=['mia1', 'mia2'], default='mia1', help=\"attacks: our implementation, their implementation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f8856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['']\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b063bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd1c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"law_race\"\n",
    "BASELINE = \"dprf\" \n",
    "MITIGATOR = args[\"mitigator\"]\n",
    "BIAS = float(args[\"bias\"])\n",
    "BIAS_TYPE = args[\"biastype\"]\n",
    "OS_MODE = 1\n",
    "ATTACK = \"mia1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16266c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# global constants\n",
    "if BASELINE == 'svm' or BASELINE == 'nn':\n",
    "    SCALER = False \n",
    "else:\n",
    "    SCALER = False \n",
    "DISPLAY = False \n",
    "THRESH_ARR = 0.5\n",
    "\n",
    "# loop ten times \n",
    "N = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49502a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of favor and unfavor\n",
    "priv_metric_orig = defaultdict(float)\n",
    "favor_metric_orig = defaultdict(float)\n",
    "favor_metric_transf = defaultdict(float)\n",
    "\n",
    "# for each pre-processing approach, we create a mia_metric_results\n",
    "orig_metrics = defaultdict(list)\n",
    "orig_mia_metrics = defaultdict(list)\n",
    "\n",
    "transf_metrics = defaultdict(list) \n",
    "transf_mia_metrics = defaultdict(list) \n",
    "\n",
    "reweigh_metrics = defaultdict(list) \n",
    "reweigh_mia_metrics = defaultdict(list) \n",
    "\n",
    "dir_metrics = defaultdict(list) \n",
    "dir_mia_metrics = defaultdict(list) \n",
    "\n",
    "eg_metrics = defaultdict(list) \n",
    "eg_mia_metrics = defaultdict(list) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a48a7",
   "metadata": {},
   "source": [
    "## Loading & Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a31333",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da867c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and set the groups\n",
    "dataset_builder =  DatasetBuilder(DATASET)\n",
    "dataset_orig = dataset_builder.load_data()\n",
    "sens_attr = dataset_orig.protected_attribute_names[0]\n",
    "unprivileged_groups = dataset_builder.unprivileged_groups\n",
    "privileged_groups = dataset_builder.privileged_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aabd2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb84777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78a2150",
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fedd14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# favorable and unfavorable labels and feature_names\n",
    "f_label = dataset_orig.favorable_label\n",
    "uf_label = dataset_orig.unfavorable_label\n",
    "feature_names = dataset_orig.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb1ad08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if ATTACK == \"mia1\":\n",
    "    # training data split ratio\n",
    "    p = 0.5\n",
    "    # split dataset into train, validation, and test\n",
    "    dataset_orig_train, dataset_orig_test = dataset_orig.split([p], shuffle=True)\n",
    "    dataset_orig_val = dataset_orig_test\n",
    "    print(dataset_orig_train.features)\n",
    "\n",
    "    # introduce label or selection biases, assuming the original data is fair\n",
    "    if BIAS_TYPE == 'label':\n",
    "        dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    elif BIAS_TYPE == 'selection':\n",
    "        dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    else:\n",
    "        print('no bias type specified')\n",
    "        \n",
    "    dataset_orig_train\n",
    "    dataset_orig_train?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cfd5f8",
   "metadata": {},
   "source": [
    "## Run Mitigating Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3ae7f8",
   "metadata": {},
   "source": [
    "### Setup for MIA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad51a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14350dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ATTACK == \"mia2\":\n",
    "    # prepare data format\n",
    "    X = dataset_orig.features\n",
    "    y_true = dataset_orig.labels.ravel()\n",
    "    sens_attr = dataset_orig.protected_attribute_names[0]\n",
    "    sens_attr_index = dataset_orig.feature_names.index(sens_attr)\n",
    "    sensitive_features = dataset_orig.features[:, sens_attr_index]\n",
    "\n",
    "    X_other_features = np.delete(X, sens_attr_index, axis=1)\n",
    "    X_other_features_normalized = preprocessing.normalize(X_other_features, norm='l2')\n",
    "\n",
    "    # Reconstruct X by combining the sensitive attribute and the normalized features\n",
    "    # Insert the sensitive attribute back into its original position\n",
    "    X_normalized = np.insert(X_other_features_normalized, sens_attr_index, sensitive_features, axis=1)\n",
    "    X = X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c1ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_indices_reference():\n",
    "    # Determine split sizes proportionally (to sum up to the full dataset size)\n",
    "    num_train_points = int(X.shape[0] * 0.12)\n",
    "    num_test_points = int(X.shape[0] * 0.12)\n",
    "    num_population_points = int(X.shape[0] * 0.3)  # Reduced from 30000\n",
    "\n",
    "    # Start with all indices\n",
    "    all_indices = np.arange(X.shape[0])\n",
    "\n",
    "    # Select train indices without replacement\n",
    "    train_index = np.random.choice(all_indices, num_train_points, replace=False)\n",
    "    # Remove train indices from available indices\n",
    "    remaining_indices = np.setdiff1d(all_indices, train_index)\n",
    "\n",
    "    # Select test indices from the remaining indices without replacement\n",
    "    test_index = np.random.choice(remaining_indices, num_test_points, replace=False)\n",
    "    # Remove test indices from available indices\n",
    "    remaining_indices = np.setdiff1d(remaining_indices, test_index)\n",
    "\n",
    "    # Select population indices from the remaining indices (can also choose all remaining points)\n",
    "    population_index = np.random.choice(remaining_indices, min(num_population_points, len(remaining_indices)), replace=False)\n",
    "    \n",
    "    # Summary of counts\n",
    "    print(\"==============================================================\")\n",
    "    print(\"GET UNIQUE INDICES REFERENCE\")\n",
    "    print(f\"Number of train points: {len(train_index)}\")\n",
    "    print(f\"Number of test points: {len(test_index)}\")\n",
    "    print(f\"Number of population points: {len(population_index)}\")\n",
    "    print(\"==============================================================\")\n",
    "    \n",
    "    return train_index, test_index, population_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414d335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(train_index, test_index, population_index, g_train, g_test, g_pop_train):\n",
    "    # create the target model's dataset\n",
    "    train_ds = {'x': X[train_index], 'y': y_true[train_index],'g':g_train}\n",
    "    test_ds = {'x': X[test_index], 'y': y_true[test_index], 'g':g_test}\n",
    "    target_dataset = Dataset(\n",
    "        data_dict={'train': train_ds, 'test': test_ds},\n",
    "        default_input='x', default_output='y', default_group='g'\n",
    "    )\n",
    "\n",
    "    # create the reference dataset\n",
    "    population_ds = {'x': X[population_index], 'y': y_true[population_index], 'g': g_pop_train}\n",
    "    reference_dataset = Dataset(\n",
    "        data_dict={'train': population_ds},\n",
    "        default_input='x', default_output='y', default_group='g'\n",
    "    )\n",
    "    \n",
    "    return target_dataset, reference_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23be8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features, labels, and protected attributes into a DataFrame\n",
    "def create_binary_label_dataset(dataset_orig, X, y, sensitive_features, sens_attr_name, privileged_value, unprivileged_value):\n",
    "    print(\"=====================================================\")\n",
    "    print(\"CREATE BINARY LABEL DATASET\")\n",
    "    # Extract the feature names from the original dataset\n",
    "    feature_names = dataset_orig.feature_names\n",
    "\n",
    "    # Create a DataFrame with features, labels, and sensitive attribute\n",
    "    df = pd.DataFrame(X, columns=feature_names)\n",
    "    df[dataset_orig.label_names[0]] = y\n",
    "#     print(df.head())\n",
    "    # print(dataset_orig.feature_names)\n",
    "    # print(dataset_orig.features.shape)\n",
    "    \n",
    "    # df_orig, _ = dataset_orig.convert_to_dataframe()\n",
    "\n",
    "    # # Display the first few rows\n",
    "    # print(\"Original df's head:\", df_orig.head())\n",
    "    \n",
    "    # Get the unique labels and their counts\n",
    "    # unique_labels, counts = np.unique(dataset_orig.labels, return_counts=True)\n",
    "\n",
    "    # # Print the value counts\n",
    "    # for label, count in zip(unique_labels, counts):\n",
    "    #     print(f\"Label {label}: {count} instances\")\n",
    "\n",
    "    # Create the BinaryLabelDataset\n",
    "    dataset = BinaryLabelDataset(\n",
    "        favorable_label=1.0,  # Adjust as per your dataset\n",
    "        unfavorable_label=0.0,  # Adjust as per your dataset\n",
    "        df=df,  # DataFrame containing features, labels, and protected attribute\n",
    "        label_names=dataset_orig.label_names,  # Column name of labels in DataFrame\n",
    "        protected_attribute_names=[sens_attr_name],  # Protected attribute column\n",
    "        privileged_protected_attributes=[privileged_value],  # Privileged group values\n",
    "        unprivileged_protected_attributes=[unprivileged_value]  # Unprivileged group values\n",
    "    )\n",
    "    \n",
    "    # print(dataset.feature_names)\n",
    "    # print(dataset.features.shape)\n",
    "    # # Get the unique labels and their counts\n",
    "    # unique_labels, counts = np.unique(dataset.labels, return_counts=True)\n",
    "\n",
    "    # Print the value counts\n",
    "    # for label, count in zip(unique_labels, counts):\n",
    "    #     print(f\"Label {label}: {count} instances\")\n",
    "    \n",
    "    print(\"=====================================================\")\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a3f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_logs():\n",
    "    # Search for directories ending with _group or _pop\n",
    "    for pattern in [\"*_group\", \"*_pop\"]:\n",
    "        # Find matching directories\n",
    "        for log_dir in glob.glob(pattern):\n",
    "            if os.path.exists(log_dir) and os.path.isdir(log_dir):  # Ensure it's a directory\n",
    "                shutil.rmtree(log_dir)\n",
    "                print(f\"{log_dir} deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31097df4",
   "metadata": {},
   "source": [
    "### Calling Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a3e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = dataset_orig.convert_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_dataset = None\n",
    "# reference_dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc3b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67badb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets():\n",
    "    target_dataset = None\n",
    "    reference_dataset = None\n",
    "    \n",
    "    if ATTACK == \"mia1\":\n",
    "        # split dataset into train, validation, and test\n",
    "        dataset_orig_train, dataset_orig_test = dataset_orig.split([p], shuffle=True)\n",
    "        dataset_orig_val = dataset_orig_test\n",
    "\n",
    "    elif ATTACK == \"mia2\":\n",
    "        train_index, test_index, population_index = get_unique_indices_reference()\n",
    "\n",
    "        g_train = y_true[train_index] + (sensitive_features[train_index] + 1) * 2 # 2, 4, 3, 5\n",
    "        g_test = y_true[test_index] + (sensitive_features[test_index] + 1) * 2\n",
    "        g_pop_train = y_true[population_index] + (sensitive_features[population_index] + 1) * 2\n",
    "\n",
    "        # for Audit\n",
    "        target_dataset, reference_dataset = create_datasets(train_index, test_index, population_index, g_train, g_test, g_pop_train)\n",
    "\n",
    "        # for mitigators\n",
    "        privileged_value = [1]\n",
    "        unprivileged_value = [0]\n",
    "        # Convert train dataset\n",
    "        dataset_orig_train = create_binary_label_dataset(\n",
    "            dataset_orig=dataset_orig,\n",
    "            X=X[train_index],\n",
    "            y=y_true[train_index],\n",
    "            sensitive_features=sensitive_features[train_index],\n",
    "            sens_attr_name=sens_attr,\n",
    "            privileged_value=privileged_value,\n",
    "            unprivileged_value=unprivileged_value\n",
    "        )\n",
    "        \n",
    "#         dataset_orig_val = create_binary_label_dataset(\n",
    "#             dataset_orig=dataset_orig,\n",
    "#             X=X[valid_index],\n",
    "#             y=y_true[valid_index],\n",
    "#             sensitive_features=sensitive_features[valid_index],\n",
    "#             sens_attr_name=sens_attr,\n",
    "#             privileged_value=privileged_value,\n",
    "#             unprivileged_value=unprivileged_value\n",
    "#         )\n",
    "\n",
    "        # Convert test dataset\n",
    "        dataset_orig_test = create_binary_label_dataset(\n",
    "            dataset_orig=dataset_orig,\n",
    "            X=X[test_index],\n",
    "            y=y_true[test_index],\n",
    "            sensitive_features=sensitive_features[test_index],\n",
    "            sens_attr_name=sens_attr,\n",
    "            privileged_value=privileged_value,\n",
    "            unprivileged_value=unprivileged_value\n",
    "        )\n",
    "        \n",
    "        dataset_orig_val = dataset_orig_test\n",
    "        \n",
    "    return dataset_orig_train, dataset_orig_val, dataset_orig_test, target_dataset, reference_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea401f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.052335  0.000000  0.261567  0.000000      0.261567   \n",
      "1     1.0  0.007442  0.000000  0.295150  0.000000      0.098383   \n",
      "2     1.0  0.007775  0.000000  0.261910  0.000000      0.261910   \n",
      "3     1.0  0.008556  0.007006  0.294261  0.000000      0.098087   \n",
      "4     1.0  0.004600  0.000000  0.275872  0.000000      0.189662   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.042678  0.021418  0.000900  0.171341      0.099949   \n",
      "3649  1.0  0.019961  0.000000  0.294794  0.000000      0.098265   \n",
      "3650  1.0  0.020451  0.034406  0.289012  0.082575      0.102358   \n",
      "3651  1.0  0.018796  0.000000  0.261868  0.000000      0.261868   \n",
      "3652  1.0  0.012246  0.012469  0.261858  0.000000      0.261858   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.126706       0.160880   0.256705     0.261567  ...        0.0   \n",
      "1           0.073845       0.009880   0.060020     0.151202  ...        0.0   \n",
      "2           0.126872       0.161091   0.257160     0.261910  ...        0.0   \n",
      "3           0.100228       0.045555   0.054102     0.150746  ...        0.0   \n",
      "4           0.107403       0.101576   0.215269     0.242183  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.195730       0.135495   0.003399     0.051127  ...        0.0   \n",
      "3649        0.079500       0.056739   0.040767     0.151019  ...        0.0   \n",
      "3650        0.208818       0.133018   0.007862     0.030595  ...        0.0   \n",
      "3651        0.126852       0.161065   0.257178     0.261868  ...        0.0   \n",
      "3652        0.126847       0.161059   0.257406     0.261858  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.000000         0.261567         0.000000              0.0   \n",
      "1            0.295150         0.000000         0.000000              0.0   \n",
      "2            0.000000         0.261910         0.000000              0.0   \n",
      "3            0.000000         0.000000         0.000000              0.0   \n",
      "4            0.000000         0.000000         0.275872              0.0   \n",
      "...               ...              ...              ...              ...   \n",
      "3648         0.299846         0.000000         0.000000              0.0   \n",
      "3649         0.000000         0.294794         0.000000              0.0   \n",
      "3650         0.000000         0.289012         0.000000              0.0   \n",
      "3651         0.261868         0.000000         0.000000              0.0   \n",
      "3652         0.000000         0.261858         0.000000              0.0   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000          0.000000              0.261567   \n",
      "1            0.000000          0.000000              0.295150   \n",
      "2            0.000000          0.000000              0.261910   \n",
      "3            0.294261          0.000000              0.294261   \n",
      "4            0.000000          0.000000              0.275872   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.000000          0.000000              0.000000   \n",
      "3649         0.000000          0.000000              0.294794   \n",
      "3650         0.000000          0.289012              0.000000   \n",
      "3651         0.000000          0.000000              0.261868   \n",
      "3652         0.000000          0.000000              0.261858   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0             0.000000  0.0  \n",
      "1             0.000000  0.0  \n",
      "2             0.000000  0.0  \n",
      "3             0.000000  1.0  \n",
      "4             0.000000  0.0  \n",
      "...                ...  ...  \n",
      "3648          0.299846  1.0  \n",
      "3649          0.000000  0.0  \n",
      "3650          0.000000  0.0  \n",
      "3651          0.000000  0.0  \n",
      "3652          0.000000  0.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n",
      "=====================================================================================\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.014419  0.006276  0.263612       0.0      0.247136   \n",
      "1     1.0  0.005647  0.012360  0.259564       0.0      0.259564   \n",
      "2     0.0  0.031995  0.000000  0.262254       0.0      0.262254   \n",
      "3     1.0  0.006231  0.006236  0.261904       0.0      0.261904   \n",
      "4     1.0  0.005112  0.000000  0.261895       0.0      0.261895   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "9129  1.0  0.030738  0.000000  0.287938       0.0      0.000000   \n",
      "9130  1.0  0.012001  0.021078  0.295094       0.0      0.030739   \n",
      "9131  1.0  0.008748  0.018738  0.262328       0.0      0.262328   \n",
      "9132  1.0  0.015819  0.014033  0.294690       0.0      0.098230   \n",
      "9133  1.0  0.007600  0.006180  0.259572       0.0      0.259572   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.184199       0.158829   0.252496     0.226636  ...        0.0   \n",
      "1           0.229015       0.097744   0.248913     0.259564  ...        0.0   \n",
      "2           0.175483       0.088881   0.257259     0.262254  ...        0.0   \n",
      "3           0.126869       0.161087   0.257213     0.261904  ...        0.0   \n",
      "4           0.126865       0.161082   0.257442     0.261895  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "9129        0.025809       0.287938   0.006919     0.058676  ...        0.0   \n",
      "9130        0.087631       0.123470   0.043284     0.125624  ...        0.0   \n",
      "9131        0.175533       0.088906   0.257392     0.262328  ...        0.0   \n",
      "9132        0.079472       0.056719   0.048102     0.150966  ...        0.0   \n",
      "9133        0.229022       0.097747   0.248979     0.259572  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.263612         0.000000              0.0         0.000000   \n",
      "1            0.000000         0.000000              0.0         0.259564   \n",
      "2            0.000000         0.000000              0.0         0.262254   \n",
      "3            0.000000         0.000000              0.0         0.261904   \n",
      "4            0.000000         0.261895              0.0         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "9129         0.000000         0.000000              0.0         0.000000   \n",
      "9130         0.000000         0.295094              0.0         0.000000   \n",
      "9131         0.262328         0.000000              0.0         0.000000   \n",
      "9132         0.000000         0.294690              0.0         0.000000   \n",
      "9133         0.000000         0.259572              0.0         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000               0.0              0.263612   \n",
      "1            0.000000               0.0              0.259564   \n",
      "2            0.000000               0.0              0.262254   \n",
      "3            0.000000               0.0              0.261904   \n",
      "4            0.000000               0.0              0.261895   \n",
      "...               ...               ...                   ...   \n",
      "9129         0.287938               0.0              0.287938   \n",
      "9130         0.000000               0.0              0.295094   \n",
      "9131         0.000000               0.0              0.262328   \n",
      "9132         0.000000               0.0              0.294690   \n",
      "9133         0.000000               0.0              0.259572   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  0.0  \n",
      "2                  0.0  1.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  0.0  \n",
      "...                ...  ...  \n",
      "9129               0.0  0.0  \n",
      "9130               0.0  1.0  \n",
      "9131               0.0  0.0  \n",
      "9132               0.0  0.0  \n",
      "9133               0.0  0.0  \n",
      "\n",
      "[9134 rows x 58 columns]\n",
      "=====================================================================================\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['dir_log_group']\n",
      "Results are stored in: ['dir_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  [0.11312205]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: [0.0977594]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 137, Test = 144\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: [0.26785626]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 63, Test = 58\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [1.10147878]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3045, Test = 3058\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: [0.08949346]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 408, Test = 393\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.93\n",
      "  Optimal thershold: [1.1130629]\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['rew_log_group']\n",
      "Results are stored in: ['rew_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.18003045]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: [0.27442222]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 137, Test = 144\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.14\n",
      "  Test Accuracy (TNR): 0.90\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.2276334]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 63, Test = 58\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.40\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: [0.86036956]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3045, Test = 3058\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: [0.05683396]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 408, Test = 393\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [1.10677184]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['eg_log_group']\n",
      "Results are stored in: ['eg_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: [0.30110509]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 137, Test = 144\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.32\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: [0.31471074]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 63, Test = 58\n",
      "  AUC: 0.90\n",
      "  Privacy Risk: 0.86\n",
      "  Accuracy: 0.86\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.81\n",
      "  Attacker advantage: 0.72\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.35667494]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3045, Test = 3058\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: [0.09431068]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 408, Test = 393\n",
      "  AUC: 0.90\n",
      "  Privacy Risk: 0.86\n",
      "  Accuracy: 0.86\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.76\n",
      "  Attacker advantage: 0.72\n",
      "  Positive predictive value: 0.95\n",
      "  Optimal thershold: [0.4462871]\n",
      ")\n",
      "dir_log_group deleted.\n",
      "eg_log_group deleted.\n",
      "rew_log_group deleted.\n",
      "syn_log_group deleted.\n",
      "un_log_group deleted.\n",
      "dir_log_pop deleted.\n",
      "eg_log_pop deleted.\n",
      "rew_log_pop deleted.\n",
      "syn_log_pop deleted.\n",
      "un_log_pop deleted.\n",
      "ITERATION  3\n",
      "==============================================================\n",
      "GET UNIQUE INDICES REFERENCE\n",
      "Number of train points: 3653\n",
      "Number of test points: 3653\n",
      "Number of population points: 9134\n",
      "==============================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "privileged vs. unprivileged:  3437.0 216.0\n",
      "base_pos unpriv:  0.35648148148148145\n",
      "base_pos priv:  0.11230724469013675\n",
      "DIFFERENCE IS GOOD\n",
      "base_pos unpriv:  0.35648148148148145\n",
      "base_pos priv:  0.11230724469013675\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(3653, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[[1]] [[0]]\n",
      "#### Dataset feature names\n",
      "['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'job=admin.', 'job=blue-collar', 'job=entrepreneur', 'job=housemaid', 'job=management', 'job=retired', 'job=self-employed', 'job=services', 'job=student', 'job=technician', 'job=unemployed', 'marital=divorced', 'marital=married', 'marital=single', 'education=basic.4y', 'education=basic.6y', 'education=basic.9y', 'education=high.school', 'education=illiterate', 'education=professional.course', 'education=university.degree', 'default=no', 'default=yes', 'housing=no', 'housing=yes', 'loan=no', 'loan=yes', 'contact=cellular', 'contact=telephone', 'month=apr', 'month=aug', 'month=dec', 'month=jul', 'month=jun', 'month=mar', 'month=may', 'month=nov', 'month=oct', 'month=sep', 'day_of_week=fri', 'day_of_week=mon', 'day_of_week=thu', 'day_of_week=tue', 'day_of_week=wed', 'poutcome=failure', 'poutcome=nonexistent', 'poutcome=success']\n",
      "number of favorable labels:  463\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.244174\n",
      "#### Train shape, validation shape, test shape\n",
      "(3653, 57) (3653, 57) (3653, 57)\n",
      "#######################################################################\n",
      "                    rf\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['un_log_group']\n",
      "Results are stored in: ['un_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.13285844]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: [0.27220608]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 139, Test = 129\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: [0.53621616]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 77, Test = 78\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.23\n",
      "  Test Accuracy (TNR): 0.97\n",
      "  Attacker advantage: 0.21\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.26325682]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3051, Test = 3049\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.45\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: [0.03387242]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 386, Test = 397\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.32\n",
      "  Test Accuracy (TNR): 0.81\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.88\n",
      "  Optimal thershold: [0.77400767]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  3653 6874\n",
      "after transf priv:  0.11230724469013675\n",
      "after transf unpriv:  0.11230724469013675\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['syn_log_group']\n",
      "Results are stored in: ['syn_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.11929447]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: [0.74684305]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 139, Test = 129\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.33472588]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 77, Test = 78\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.35\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.49078827]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3051, Test = 3049\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.29\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: [0.03621263]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 386, Test = 397\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.25\n",
      "  Test Accuracy (TNR): 0.83\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.81\n",
      "  Optimal thershold: [1.31350045]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.027519  0.000000  0.262280  0.000000      0.262280   \n",
      "1     1.0  0.012316  0.000000  0.289813  0.082804      0.000000   \n",
      "2     1.0  0.006935  0.006247  0.262368  0.000000      0.262368   \n",
      "3     1.0  0.009266  0.000000  0.261911  0.000000      0.261911   \n",
      "4     1.0  0.007066  0.007012  0.294490  0.042070      0.098163   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.009603  0.000000  0.262368  0.000000      0.262368   \n",
      "3649  1.0  0.010723  0.000000  0.262369  0.000000      0.262369   \n",
      "3650  1.0  0.011980  0.018704  0.261858  0.000000      0.261858   \n",
      "3651  1.0  0.006724  0.006561  0.275574  0.000000      0.189457   \n",
      "3652  1.0  0.009220  0.000000  0.263641  0.000000      0.247163   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.175501       0.088890   0.257405     0.262280  ...        0.0   \n",
      "1           0.050599       0.251010   0.005322     0.059058  ...        0.0   \n",
      "2           0.175560       0.088920   0.257491     0.262368  ...        0.0   \n",
      "3           0.126873       0.161092   0.257101     0.261911  ...        0.0   \n",
      "4           0.079418       0.056680   0.047401     0.150864  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.175559       0.088920   0.257490     0.262368  ...        0.0   \n",
      "3649        0.175560       0.088920   0.257432     0.262369  ...        0.0   \n",
      "3650        0.126847       0.161059   0.257049     0.261858  ...        0.0   \n",
      "3651        0.107287       0.101467   0.219847     0.241922  ...        0.0   \n",
      "3652        0.184220       0.158846   0.252404     0.226662  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.000000         0.000000              0.0         0.000000   \n",
      "1            0.000000         0.000000              0.0         0.289813   \n",
      "2            0.262368         0.000000              0.0         0.000000   \n",
      "3            0.000000         0.000000              0.0         0.000000   \n",
      "4            0.000000         0.000000              0.0         0.294490   \n",
      "...               ...              ...              ...              ...   \n",
      "3648         0.000000         0.000000              0.0         0.000000   \n",
      "3649         0.000000         0.000000              0.0         0.262369   \n",
      "3650         0.000000         0.000000              0.0         0.000000   \n",
      "3651         0.000000         0.000000              0.0         0.275574   \n",
      "3652         0.000000         0.263641              0.0         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.262280          0.000000              0.262280   \n",
      "1            0.000000          0.289813              0.000000   \n",
      "2            0.000000          0.000000              0.262368   \n",
      "3            0.261911          0.000000              0.261911   \n",
      "4            0.000000          0.294490              0.000000   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.262368          0.000000              0.262368   \n",
      "3649         0.000000          0.000000              0.262369   \n",
      "3650         0.261858          0.000000              0.261858   \n",
      "3651         0.000000          0.000000              0.275574   \n",
      "3652         0.000000          0.000000              0.263641   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  1.0  \n",
      "2                  0.0  0.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  0.0  \n",
      "...                ...  ...  \n",
      "3648               0.0  0.0  \n",
      "3649               0.0  0.0  \n",
      "3650               0.0  0.0  \n",
      "3651               0.0  0.0  \n",
      "3652               0.0  0.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.008307  0.012471  0.261897  0.000000      0.261897   \n",
      "1     1.0  0.018628  0.006179  0.259530  0.000000      0.259530   \n",
      "2     1.0  0.001320  0.000000  0.259588  0.000000      0.259588   \n",
      "3     1.0  0.032634  0.000000  0.295026  0.000000      0.098342   \n",
      "4     1.0  0.002667  0.006247  0.262374  0.000000      0.262374   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.018590  0.031367  0.263481  0.000000      0.247013   \n",
      "3649  1.0  0.019419  0.007219  0.001214  0.043312      0.031582   \n",
      "3650  1.0  0.010456  0.006247  0.262360  0.000000      0.262360   \n",
      "3651  1.0  0.056247  0.014013  0.294279  0.000000      0.098093   \n",
      "3652  1.0  0.028000  0.006245  0.262296  0.000000      0.262296   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.126866       0.161083   0.257028     0.261897  ...        0.0   \n",
      "1           0.228986       0.097731   0.248999     0.259530  ...        0.0   \n",
      "2           0.229036       0.097753   0.248936     0.259588  ...        0.0   \n",
      "3           0.073814       0.009875   0.058590     0.151138  ...        0.0   \n",
      "4           0.175563       0.088922   0.257496     0.262374  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.184108       0.158750   0.252191     0.226524  ...        0.0   \n",
      "3649        0.000000       0.246099   0.016427     0.129068  ...        0.0   \n",
      "3650        0.175554       0.088917   0.257483     0.262360  ...        0.0   \n",
      "3651        0.079361       0.056640   0.046700     0.150756  ...        0.0   \n",
      "3652        0.175511       0.088895   0.257063     0.262296  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0             0.00000              0.0         0.261897         0.000000   \n",
      "1             0.00000              0.0         0.259530         0.000000   \n",
      "2             0.00000              0.0         0.000000         0.259588   \n",
      "3             0.00000              0.0         0.000000         0.295026   \n",
      "4             0.00000              0.0         0.000000         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "3648          0.00000              0.0         0.000000         0.263481   \n",
      "3649          0.00000              0.0         0.303184         0.000000   \n",
      "3650          0.26236              0.0         0.000000         0.000000   \n",
      "3651          0.00000              0.0         0.000000         0.000000   \n",
      "3652          0.00000              0.0         0.000000         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000               0.0              0.261897   \n",
      "1            0.000000               0.0              0.259530   \n",
      "2            0.000000               0.0              0.259588   \n",
      "3            0.000000               0.0              0.295026   \n",
      "4            0.262374               0.0              0.262374   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.000000               0.0              0.263481   \n",
      "3649         0.000000               0.0              0.000000   \n",
      "3650         0.000000               0.0              0.262360   \n",
      "3651         0.294279               0.0              0.294279   \n",
      "3652         0.262296               0.0              0.262296   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0             0.000000  0.0  \n",
      "1             0.000000  0.0  \n",
      "2             0.000000  0.0  \n",
      "3             0.000000  0.0  \n",
      "4             0.000000  0.0  \n",
      "...                ...  ...  \n",
      "3648          0.000000  0.0  \n",
      "3649          0.303184  1.0  \n",
      "3650          0.000000  0.0  \n",
      "3651          0.000000  0.0  \n",
      "3652          0.000000  0.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n",
      "=====================================================================================\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.003354  0.007013  0.294564  0.042081      0.098188   \n",
      "1     1.0  0.007030  0.000000  0.261912  0.000000      0.261912   \n",
      "2     1.0  0.041838  0.027994  0.293942  0.000000      0.097981   \n",
      "3     0.0  0.004374  0.012493  0.262357  0.000000      0.262357   \n",
      "4     1.0  0.056811  0.000000  0.275266  0.000000      0.189245   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "9129  1.0  0.009752  0.012345  0.259238  0.000000      0.259238   \n",
      "9130  1.0  0.005851  0.000000  0.259219  0.000000      0.259219   \n",
      "9131  1.0  0.008899  0.000000  0.263646  0.000000      0.247168   \n",
      "9132  1.0  0.023046  0.000000  0.263582  0.000000      0.247108   \n",
      "9133  1.0  0.015644  0.000000  0.294786  0.000000      0.098262   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.079438       0.056694   0.042205     0.150902  ...        0.0   \n",
      "1           0.126873       0.161092   0.257162     0.261912  ...        0.0   \n",
      "2           0.100119       0.045506   0.051711     0.150583  ...        0.0   \n",
      "3           0.175552       0.088916   0.257480     0.262357  ...        0.0   \n",
      "4           0.107167       0.101353   0.217542     0.241651  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "9129        0.228727       0.097621   0.253478     0.259238  ...        0.0   \n",
      "9130        0.228711       0.097614   0.254165     0.259219  ...        0.0   \n",
      "9131        0.184223       0.158849   0.252349     0.226666  ...        0.0   \n",
      "9132        0.184179       0.158811   0.252348     0.226611  ...        0.0   \n",
      "9133        0.079498       0.056737   0.043239     0.151015  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.000000              0.0         0.294564         0.000000   \n",
      "1            0.000000              0.0         0.000000         0.000000   \n",
      "2            0.000000              0.0         0.293942         0.000000   \n",
      "3            0.000000              0.0         0.000000         0.000000   \n",
      "4            0.000000              0.0         0.000000         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "9129         0.259238              0.0         0.000000         0.000000   \n",
      "9130         0.259219              0.0         0.000000         0.000000   \n",
      "9131         0.000000              0.0         0.000000         0.263646   \n",
      "9132         0.000000              0.0         0.000000         0.000000   \n",
      "9133         0.000000              0.0         0.000000         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000          0.294564              0.000000   \n",
      "1            0.261912          0.000000              0.261912   \n",
      "2            0.000000          0.000000              0.293942   \n",
      "3            0.262357          0.000000              0.262357   \n",
      "4            0.275266          0.000000              0.275266   \n",
      "...               ...               ...                   ...   \n",
      "9129         0.000000          0.000000              0.259238   \n",
      "9130         0.000000          0.000000              0.259219   \n",
      "9131         0.000000          0.000000              0.263646   \n",
      "9132         0.263582          0.000000              0.263582   \n",
      "9133         0.294786          0.000000              0.294786   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  0.0  \n",
      "2                  0.0  1.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  1.0  \n",
      "...                ...  ...  \n",
      "9129               0.0  0.0  \n",
      "9130               0.0  0.0  \n",
      "9131               0.0  0.0  \n",
      "9132               0.0  0.0  \n",
      "9133               0.0  0.0  \n",
      "\n",
      "[9134 rows x 58 columns]\n",
      "=====================================================================================\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['dir_log_group']\n",
      "Results are stored in: ['dir_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  [0.10021593]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.45\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: [0.04185206]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 139, Test = 129\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: [0.36644935]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 77, Test = 78\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.35\n",
      "  Test Accuracy (TNR): 0.86\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 0.88\n",
      "  Optimal thershold: [1.30932316]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3051, Test = 3049\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.50\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: [0.0396121]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 386, Test = 397\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [1.04910153]\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['rew_log_group']\n",
      "Results are stored in: ['rew_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.13989504]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: [0.71251589]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 139, Test = 129\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: [0.44042404]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 77, Test = 78\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.91\n",
      "  Optimal thershold: [1.03545181]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3051, Test = 3049\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: [0.25809306]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 386, Test = 397\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.40\n",
      "  Test Accuracy (TNR): 0.75\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.90074715]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['eg_log_group']\n",
      "Results are stored in: ['eg_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: [0.27443685]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 139, Test = 129\n",
      "  AUC: 0.63\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.68\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: [0.28768207]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 77, Test = 78\n",
      "  AUC: 0.93\n",
      "  Privacy Risk: 0.85\n",
      "  Accuracy: 0.85\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.83\n",
      "  Attacker advantage: 0.69\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.29188155]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3051, Test = 3049\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: [0.09431068]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 386, Test = 397\n",
      "  AUC: 0.92\n",
      "  Privacy Risk: 0.86\n",
      "  Accuracy: 0.86\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.79\n",
      "  Attacker advantage: 0.73\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.45065221]\n",
      ")\n",
      "dir_log_group deleted.\n",
      "eg_log_group deleted.\n",
      "rew_log_group deleted.\n",
      "syn_log_group deleted.\n",
      "un_log_group deleted.\n",
      "dir_log_pop deleted.\n",
      "eg_log_pop deleted.\n",
      "rew_log_pop deleted.\n",
      "syn_log_pop deleted.\n",
      "un_log_pop deleted.\n",
      "ITERATION  4\n",
      "==============================================================\n",
      "GET UNIQUE INDICES REFERENCE\n",
      "Number of train points: 3653\n",
      "Number of test points: 3653\n",
      "Number of population points: 9134\n",
      "==============================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "=====================================================\n",
      "CREATE BINARY LABEL DATASET\n",
      "=====================================================\n",
      "privileged vs. unprivileged:  3440.0 213.0\n",
      "base_pos unpriv:  0.3051643192488263\n",
      "base_pos priv:  0.11395348837209303\n",
      "DIFFERENCE IS GOOD\n",
      "base_pos unpriv:  0.3051643192488263\n",
      "base_pos priv:  0.11395348837209303\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(3653, 57)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['age']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'age': 1}] [{'age': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[[1]] [[0]]\n",
      "#### Dataset feature names\n",
      "['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'job=admin.', 'job=blue-collar', 'job=entrepreneur', 'job=housemaid', 'job=management', 'job=retired', 'job=self-employed', 'job=services', 'job=student', 'job=technician', 'job=unemployed', 'marital=divorced', 'marital=married', 'marital=single', 'education=basic.4y', 'education=basic.6y', 'education=basic.9y', 'education=high.school', 'education=illiterate', 'education=professional.course', 'education=university.degree', 'default=no', 'default=yes', 'housing=no', 'housing=yes', 'loan=no', 'loan=yes', 'contact=cellular', 'contact=telephone', 'month=apr', 'month=aug', 'month=dec', 'month=jul', 'month=jun', 'month=mar', 'month=may', 'month=nov', 'month=oct', 'month=sep', 'day_of_week=fri', 'day_of_week=mon', 'day_of_week=thu', 'day_of_week=tue', 'day_of_week=wed', 'poutcome=failure', 'poutcome=nonexistent', 'poutcome=success']\n",
      "number of favorable labels:  457\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.191211\n",
      "#### Train shape, validation shape, test shape\n",
      "(3653, 57) (3653, 57) (3653, 57)\n",
      "#######################################################################\n",
      "                    rf\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['un_log_group']\n",
      "Results are stored in: ['un_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.16796808]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: [0.28506741]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 137\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.28917659]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 65, Test = 75\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.26\n",
      "  Test Accuracy (TNR): 0.89\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.37979795]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3048, Test = 3059\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.35\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: [0.04140839]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 392, Test = 382\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.61\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.83\n",
      "  Optimal thershold: [1.21385888]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  3653 6880\n",
      "after transf priv:  0.11395348837209303\n",
      "after transf unpriv:  0.11395348837209303\n",
      "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['syn_log_group']\n",
      "Results are stored in: ['syn_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.11553233]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.32\n",
      "  Test Accuracy (TNR): 0.70\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: [0.04257391]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 137\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.80\n",
      "  Optimal thershold: [0.22720917]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 65, Test = 75\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.15\n",
      "  Test Accuracy (TNR): 0.99\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.91\n",
      "  Optimal thershold: [1.21285305]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3048, Test = 3059\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.37\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: [0.04257391]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 392, Test = 382\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: [1.3778363]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.003117  0.000000  0.294793       0.0      0.098264   \n",
      "1     1.0  0.030918  0.000000  0.294681       0.0      0.098227   \n",
      "2     1.0  0.008202  0.000000  0.263643       0.0      0.247166   \n",
      "3     1.0  0.023581  0.000000  0.292860       0.0      0.024405   \n",
      "4     1.0  0.014251  0.031368  0.263488       0.0      0.247020   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.002929  0.012471  0.261897       0.0      0.261897   \n",
      "3649  1.0  0.020313  0.000000  0.263590       0.0      0.247116   \n",
      "3650  1.0  0.008470  0.000000  0.275865       0.0      0.189657   \n",
      "3651  1.0  0.019541  0.006235  0.261863       0.0      0.261863   \n",
      "3652  1.0  0.003355  0.006236  0.261908       0.0      0.261908   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.079500       0.056738   0.045378     0.151018  ...        0.0   \n",
      "1           0.079470       0.056717   0.043223     0.150961  ...        0.0   \n",
      "2           0.184222       0.158848   0.252407     0.226664  ...        0.0   \n",
      "3           0.058435       0.218113   0.004913     0.066323  ...        0.0   \n",
      "4           0.184113       0.158754   0.252377     0.226530  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.126866       0.161083   0.257147     0.261897  ...        0.0   \n",
      "3649        0.184184       0.158816   0.252475     0.226618  ...        0.0   \n",
      "3650        0.107400       0.101574   0.215264     0.242177  ...        0.0   \n",
      "3651        0.126850       0.161062   0.257114     0.261863  ...        0.0   \n",
      "3652        0.126871       0.161090   0.257217     0.261908  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.294793         0.000000         0.000000          0.00000   \n",
      "1            0.000000         0.000000         0.000000          0.00000   \n",
      "2            0.000000         0.263643         0.000000          0.00000   \n",
      "3            0.000000         0.000000         0.000000          0.29286   \n",
      "4            0.263488         0.000000         0.000000          0.00000   \n",
      "...               ...              ...              ...              ...   \n",
      "3648         0.000000         0.261897         0.000000          0.00000   \n",
      "3649         0.263590         0.000000         0.000000          0.00000   \n",
      "3650         0.000000         0.000000         0.275865          0.00000   \n",
      "3651         0.000000         0.261863         0.000000          0.00000   \n",
      "3652         0.261908         0.000000         0.000000          0.00000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000               0.0              0.294793   \n",
      "1            0.294681               0.0              0.294681   \n",
      "2            0.000000               0.0              0.263643   \n",
      "3            0.000000               0.0              0.292860   \n",
      "4            0.000000               0.0              0.263488   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.000000               0.0              0.261897   \n",
      "3649         0.000000               0.0              0.263590   \n",
      "3650         0.000000               0.0              0.275865   \n",
      "3651         0.000000               0.0              0.261863   \n",
      "3652         0.000000               0.0              0.261908   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  1.0  \n",
      "2                  0.0  0.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  0.0  \n",
      "...                ...  ...  \n",
      "3648               0.0  0.0  \n",
      "3649               0.0  0.0  \n",
      "3650               0.0  0.0  \n",
      "3651               0.0  0.0  \n",
      "3652               0.0  0.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.014205  0.000000  0.263618  0.000000      0.247142   \n",
      "1     1.0  0.005092  0.012554  0.263628  0.000000      0.247151   \n",
      "2     1.0  0.043127  0.000000  0.275454  0.000000      0.189375   \n",
      "3     1.0  0.010752  0.006171  0.259196  0.000000      0.259196   \n",
      "4     1.0  0.004986  0.000000  0.263657  0.000000      0.247178   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "3648  1.0  0.043701  0.012542  0.263384  0.000000      0.246922   \n",
      "3649  1.0  0.010291  0.012553  0.263606  0.000000      0.247130   \n",
      "3650  1.0  0.004432  0.000000  0.294570  0.042081      0.098190   \n",
      "3651  1.0  0.015602  0.006235  0.261873  0.000000      0.261873   \n",
      "3652  1.0  0.001558  0.000000  0.294775  0.000000      0.098258   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.184204       0.158832   0.252502     0.226641  ...        0.0   \n",
      "1           0.184211       0.158839   0.252392     0.226650  ...        0.0   \n",
      "2           0.107240       0.101422   0.217691     0.241817  ...        0.0   \n",
      "3           0.228690       0.097605   0.254260     0.259196  ...        0.0   \n",
      "4           0.184231       0.158856   0.252300     0.226675  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "3648        0.184040       0.158691   0.252098     0.226440  ...        0.0   \n",
      "3649        0.184195       0.158825   0.252550     0.226631  ...        0.0   \n",
      "3650        0.079440       0.056696   0.042206     0.150905  ...        0.0   \n",
      "3651        0.126854       0.161068   0.257243     0.261873  ...        0.0   \n",
      "3652        0.079495       0.056735   0.046779     0.151009  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.263618              0.0         0.000000         0.000000   \n",
      "1            0.000000              0.0         0.000000         0.263628   \n",
      "2            0.000000              0.0         0.000000         0.000000   \n",
      "3            0.000000              0.0         0.000000         0.259196   \n",
      "4            0.000000              0.0         0.263657         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "3648         0.000000              0.0         0.000000         0.263384   \n",
      "3649         0.000000              0.0         0.263606         0.000000   \n",
      "3650         0.000000              0.0         0.294570         0.000000   \n",
      "3651         0.000000              0.0         0.000000         0.000000   \n",
      "3652         0.000000              0.0         0.000000         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000           0.00000              0.263618   \n",
      "1            0.000000           0.00000              0.263628   \n",
      "2            0.275454           0.00000              0.275454   \n",
      "3            0.000000           0.00000              0.259196   \n",
      "4            0.000000           0.00000              0.263657   \n",
      "...               ...               ...                   ...   \n",
      "3648         0.000000           0.00000              0.263384   \n",
      "3649         0.000000           0.00000              0.263606   \n",
      "3650         0.000000           0.29457              0.000000   \n",
      "3651         0.261873           0.00000              0.261873   \n",
      "3652         0.294775           0.00000              0.294775   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0                  0.0  0.0  \n",
      "1                  0.0  0.0  \n",
      "2                  0.0  0.0  \n",
      "3                  0.0  0.0  \n",
      "4                  0.0  0.0  \n",
      "...                ...  ...  \n",
      "3648               0.0  0.0  \n",
      "3649               0.0  0.0  \n",
      "3650               0.0  0.0  \n",
      "3651               0.0  0.0  \n",
      "3652               0.0  0.0  \n",
      "\n",
      "[3653 rows x 58 columns]\n",
      "=====================================================================================\n",
      "=============================================================\n",
      "TRANSFROM PRIVACY METER DATASET\n",
      "DATAFRAME BEFORE DIR TRANSFORM       age  duration  campaign     pdays  previous  emp.var.rate  \\\n",
      "0     1.0  0.051032  0.013119  0.275492  0.000000      0.189401   \n",
      "1     0.0  0.009641  0.000000  0.289101  0.000000      0.096367   \n",
      "2     1.0  0.009698  0.000000  0.289057  0.041294      0.102374   \n",
      "3     1.0  0.001447  0.006277  0.263643  0.000000      0.247165   \n",
      "4     1.0  0.010577  0.021857  0.001838  0.043714      0.025500   \n",
      "...   ...       ...       ...       ...       ...           ...   \n",
      "9129  1.0  0.004428  0.006247  0.262384  0.000000      0.262384   \n",
      "9130  1.0  0.018604  0.000000  0.295146  0.000000      0.030744   \n",
      "9131  1.0  0.004686  0.000000  0.261903  0.000000      0.261903   \n",
      "9132  1.0  0.010671  0.007020  0.294824  0.000000      0.098275   \n",
      "9133  1.0  0.021439  0.000000  0.294519  0.042074      0.098173   \n",
      "\n",
      "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month=sep  \\\n",
      "0           0.107255       0.101436   0.214972     0.241850  ...        0.0   \n",
      "1           0.174407       0.195960   0.000721     0.049295  ...        0.0   \n",
      "2           0.226875       0.126991   0.009699     0.030600  ...        0.0   \n",
      "3           0.184221       0.158848   0.252466     0.226663  ...        0.0   \n",
      "4           0.061057       0.227898   0.005272     0.069298  ...        0.0   \n",
      "...              ...            ...        ...          ...  ...        ...   \n",
      "9129        0.175570       0.088925   0.257328     0.262384  ...        0.0   \n",
      "9130        0.087647       0.123492   0.042020     0.125646  ...        0.0   \n",
      "9131        0.126869       0.161087   0.257331     0.261903  ...        0.0   \n",
      "9132        0.079508       0.056744   0.041172     0.151034  ...        0.0   \n",
      "9133        0.079426       0.056686   0.041130     0.150878  ...        0.0   \n",
      "\n",
      "      day_of_week=fri  day_of_week=mon  day_of_week=thu  day_of_week=tue  \\\n",
      "0            0.000000         0.000000         0.275492         0.000000   \n",
      "1            0.289101         0.000000         0.000000         0.000000   \n",
      "2            0.000000         0.000000         0.289057         0.000000   \n",
      "3            0.000000         0.000000         0.000000         0.000000   \n",
      "4            0.305998         0.000000         0.000000         0.000000   \n",
      "...               ...              ...              ...              ...   \n",
      "9129         0.000000         0.262384         0.000000         0.000000   \n",
      "9130         0.000000         0.000000         0.000000         0.295146   \n",
      "9131         0.000000         0.000000         0.000000         0.261903   \n",
      "9132         0.294824         0.000000         0.000000         0.000000   \n",
      "9133         0.294519         0.000000         0.000000         0.000000   \n",
      "\n",
      "      day_of_week=wed  poutcome=failure  poutcome=nonexistent  \\\n",
      "0            0.000000          0.000000              0.275492   \n",
      "1            0.000000          0.000000              0.289101   \n",
      "2            0.000000          0.289057              0.000000   \n",
      "3            0.263643          0.000000              0.263643   \n",
      "4            0.000000          0.000000              0.000000   \n",
      "...               ...               ...                   ...   \n",
      "9129         0.000000          0.000000              0.262384   \n",
      "9130         0.000000          0.000000              0.295146   \n",
      "9131         0.000000          0.000000              0.261903   \n",
      "9132         0.000000          0.000000              0.294824   \n",
      "9133         0.000000          0.294519              0.000000   \n",
      "\n",
      "      poutcome=success    y  \n",
      "0             0.000000  0.0  \n",
      "1             0.000000  0.0  \n",
      "2             0.000000  0.0  \n",
      "3             0.000000  0.0  \n",
      "4             0.305998  1.0  \n",
      "...                ...  ...  \n",
      "9129          0.000000  0.0  \n",
      "9130          0.000000  0.0  \n",
      "9131          0.000000  0.0  \n",
      "9132          0.000000  0.0  \n",
      "9133          0.000000  0.0  \n",
      "\n",
      "[9134 rows x 58 columns]\n",
      "=====================================================================================\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['dir_log_group']\n",
      "Results are stored in: ['dir_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  [0.10201871]\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: [0.06578876]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 137\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: [0.13186467]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 65, Test = 75\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.17\n",
      "  Test Accuracy (TNR): 0.97\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [1.38642596]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3048, Test = 3059\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: [0.08122537]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 392, Test = 382\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.36\n",
      "  Test Accuracy (TNR): 0.72\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.89250403]\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training random forest\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['rew_log_group']\n",
      "Results are stored in: ['rew_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Best thresh:  [0.1576533]\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: [0.28992665]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 137\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.80\n",
      "  Optimal thershold: [0.34884462]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 65, Test = 75\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.28\n",
      "  Test Accuracy (TNR): 0.85\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: [0.47891531]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3048, Test = 3059\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: [0.0772245]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 392, Test = 382\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.92\n",
      "  Optimal thershold: [1.07688755]\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "========================================================================\n",
      "RUN MIA2 ATTACK\n",
      "Results are stored in: ['eg_log_group']\n",
      "Results are stored in: ['eg_log_pop']\n",
      "========================================================================\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 3653, Test = 3653\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: [0.31471074]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 148, Test = 137\n",
      "  AUC: 0.67\n",
      "  Privacy Risk: 0.68\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.35\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: [0.27195577]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 65, Test = 75\n",
      "  AUC: 0.89\n",
      "  Privacy Risk: 0.83\n",
      "  Accuracy: 0.81\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.65\n",
      "  Positive predictive value: 0.89\n",
      "  Optimal thershold: [0.46203546]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 3048, Test = 3059\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: [0.09431068]\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 392, Test = 382\n",
      "  AUC: 0.90\n",
      "  Privacy Risk: 0.86\n",
      "  Accuracy: 0.86\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.72\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: [0.49429632]\n",
      ")\n",
      "dir_log_group deleted.\n",
      "eg_log_group deleted.\n",
      "rew_log_group deleted.\n",
      "syn_log_group deleted.\n",
      "un_log_group deleted.\n",
      "dir_log_pop deleted.\n",
      "eg_log_pop deleted.\n",
      "rew_log_pop deleted.\n",
      "syn_log_pop deleted.\n",
      "un_log_pop deleted.\n"
     ]
    }
   ],
   "source": [
    "# favorable and unfavorable labels and feature_names\n",
    "f_label = dataset_orig.favorable_label\n",
    "uf_label = dataset_orig.unfavorable_label\n",
    "feature_names = dataset_orig.feature_names\n",
    "\n",
    "try:\n",
    "    # run mitigating algorithms\n",
    "    for i in range(N):\n",
    "        print('ITERATION ', i)\n",
    "        dataset_orig_train, dataset_orig_val, dataset_orig_test, target_dataset, reference_dataset = prepare_datasets()\n",
    "\n",
    "        # check fairness on the original data\n",
    "        metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                                     unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "        print(\"privileged vs. unprivileged: \", metric_orig_train.num_positives(privileged=True) + metric_orig_train.num_negatives(privileged=True), metric_orig_train.num_positives(privileged=False) + metric_orig_train.num_negatives(privileged=False)) \n",
    "        base_rate_unprivileged = metric_orig_train.base_rate(privileged=False)\n",
    "        base_rate_privileged = metric_orig_train.base_rate(privileged=True)\n",
    "\n",
    "        print('base_pos unpriv: ', base_rate_unprivileged)\n",
    "        print('base_pos priv: ', base_rate_privileged)\n",
    "\n",
    "        print(\"DIFFERENCE IS GOOD\")\n",
    "        print('base_pos unpriv: ', base_rate_unprivileged)\n",
    "        print('base_pos priv: ', base_rate_privileged)\n",
    "\n",
    "        # favorable and unfavorable labels and feature_names\n",
    "        f_label = dataset_orig.favorable_label\n",
    "        uf_label = dataset_orig.unfavorable_label\n",
    "        feature_names = dataset_orig.feature_names\n",
    "\n",
    "        # introduce label or selection biases, assuming the original data is fair\n",
    "        if BIAS_TYPE == 'label':\n",
    "            dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "        elif BIAS_TYPE == 'selection':\n",
    "            dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "        else:\n",
    "            print('no bias type specified')\n",
    "\n",
    "        # show data info\n",
    "        print(\"#### Training Dataset shape\")\n",
    "        print(dataset_orig_train.features.shape)\n",
    "        print(\"#### Favorable and unfavorable labels\")\n",
    "        print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "        print(\"#### Protected attribute names\")\n",
    "        print(dataset_orig_train.protected_attribute_names)\n",
    "        print(\"#### Privileged and unprivileged protected groups\")\n",
    "        print(privileged_groups, unprivileged_groups)\n",
    "        print(\"#### Privileged and unprivileged protected attribute values\")\n",
    "        print(dataset_orig_train.privileged_protected_attributes, dataset_orig_train.unprivileged_protected_attributes)\n",
    "        print(\"#### Dataset feature names\")\n",
    "        print(dataset_orig_train.feature_names)\n",
    "        print('number of favorable labels: ', np.count_nonzero(dataset_orig_train.labels==f_label))\n",
    "        print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "        # statistics of favored/positive class BEFORE transf \n",
    "        priv_metric_orig['total_priv'] += metric_orig_train.num_instances(privileged = True) \n",
    "        priv_metric_orig['total_unpriv'] += metric_orig_train.num_instances(privileged = False) \n",
    "        favor_metric_orig['total_favor'] += metric_orig_train.base_rate()\n",
    "        favor_metric_orig['total_unfavor'] += 1 - metric_orig_train.base_rate()\n",
    "        favor_metric_orig['priv_favor'] += metric_orig_train.base_rate(privileged = True)\n",
    "        favor_metric_orig['priv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = True)\n",
    "        favor_metric_orig['unpriv_favor'] += metric_orig_train.base_rate(privileged = False)\n",
    "        favor_metric_orig['unpriv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = False)\n",
    "\n",
    "        print(\"#### Train shape, validation shape, test shape\")\n",
    "        print(dataset_orig_train.features.shape, dataset_orig_val.features.shape, dataset_orig_test.features.shape)\n",
    "\n",
    "        # testing mitigation methods \n",
    "        test_cases = TestAlgorithms(BASELINE)\n",
    "\n",
    "        # null mitigator\n",
    "        orig_metrics, orig_mia_metrics = test_cases.run_original(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, BASELINE, orig_metrics, orig_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset) \n",
    "\n",
    "        # synthetic data mitigator\n",
    "        metric_transf_train, transf_metrics, transf_mia_metrics = test_cases.run_oversample(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, privileged_groups, unprivileged_groups, base_rate_privileged, base_rate_unprivileged, BASELINE, transf_metrics, transf_mia_metrics, f_label, uf_label, ATTACK, THRESH_ARR, DISPLAY, OS_MODE, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        # statistics of favored/positive class AFTER transf\n",
    "        favor_metric_transf['total_favor'] += metric_transf_train.base_rate()\n",
    "        favor_metric_transf['total_unfavor'] += 1 - metric_transf_train.base_rate()\n",
    "        favor_metric_transf['priv_favor'] += metric_transf_train.base_rate(privileged = True)\n",
    "        favor_metric_transf['priv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = True)\n",
    "        favor_metric_transf['unpriv_favor'] += metric_transf_train.base_rate(privileged = False)\n",
    "        favor_metric_transf['unpriv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = False)\n",
    "\n",
    "        # dir mitigator\n",
    "        dir_metrics, dir_mia_metrics = test_cases.run_dir(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test,  sens_attr, BASELINE, dir_metrics, dir_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset) \n",
    "\n",
    "        # reweigh mitigator\n",
    "        reweigh_metrics, reweigh_mia_metrics = test_cases.run_rew(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, reweigh_metrics, reweigh_mia_metrics, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        # eg mitigator, in-processing\n",
    "        eg_metrics, eg_mia_metrics = test_cases.run_eg(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, eg_metrics, eg_mia_metrics, BASELINE, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        # cpp mitigator\n",
    "    #     cpp_metrics, cpp_mia_metrics = test_cases.run_cpp(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, cpp_metrics, cpp_mia_metrics, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        delete_logs()\n",
    "except ValueError as e:\n",
    "    print(\"Error detected: No samples generated. Adjusting datasets...\")\n",
    "    delete_logs()\n",
    "    # percentage of favor and unfavor\n",
    "    priv_metric_orig = defaultdict(float)\n",
    "    favor_metric_orig = defaultdict(float)\n",
    "    favor_metric_transf = defaultdict(float)\n",
    "\n",
    "    # for each pre-processing approach, we create a mia_metric_results\n",
    "    orig_metrics = defaultdict(list)\n",
    "    orig_mia_metrics = defaultdict(list)\n",
    "\n",
    "    transf_metrics = defaultdict(list) \n",
    "    transf_mia_metrics = defaultdict(list) \n",
    "\n",
    "    reweigh_metrics = defaultdict(list) \n",
    "    reweigh_mia_metrics = defaultdict(list) \n",
    "\n",
    "    dir_metrics = defaultdict(list) \n",
    "    dir_mia_metrics = defaultdict(list) \n",
    "\n",
    "    eg_metrics = defaultdict(list) \n",
    "    eg_mia_metrics = defaultdict(list) \n",
    "    # run mitigating algorithms\n",
    "    for i in range(N):\n",
    "        print('ITERATION ', i)\n",
    "        dataset_orig_train, dataset_orig_val, dataset_orig_test, target_dataset, reference_dataset = prepare_datasets()\n",
    "\n",
    "        # check fairness on the original data\n",
    "        metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                                     unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "        print(\"privileged vs. unprivileged: \", metric_orig_train.num_positives(privileged=True) + metric_orig_train.num_negatives(privileged=True), metric_orig_train.num_positives(privileged=False) + metric_orig_train.num_negatives(privileged=False)) \n",
    "        base_rate_unprivileged = metric_orig_train.base_rate(privileged=False)\n",
    "        base_rate_privileged = metric_orig_train.base_rate(privileged=True)\n",
    "\n",
    "        print('base_pos unpriv: ', base_rate_unprivileged)\n",
    "        print('base_pos priv: ', base_rate_privileged)\n",
    "\n",
    "        while(base_rate_privileged >= base_rate_unprivileged and (base_rate_privileged - base_rate_unprivileged) <= 0.05):\n",
    "            print(\"DIFFERENCE IS TOO LOW, GETTING DATASETS AGAIN\")\n",
    "            dataset_orig_train, dataset_orig_val, dataset_orig_test, target_dataset, reference_dataset = prepare_datasets()\n",
    "             # check fairness on the original data\n",
    "            metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                                         unprivileged_groups=unprivileged_groups,\n",
    "                                                         privileged_groups=privileged_groups)\n",
    "            print(\"privileged vs. unprivileged: \", metric_orig_train.num_positives(privileged=True) + metric_orig_train.num_negatives(privileged=True), metric_orig_train.num_positives(privileged=False) + metric_orig_train.num_negatives(privileged=False)) \n",
    "            base_rate_unprivileged = metric_orig_train.base_rate(privileged=False)\n",
    "            base_rate_privileged = metric_orig_train.base_rate(privileged=True)\n",
    "\n",
    "        print(\"DIFFERENCE IS GOOD\")\n",
    "        print('base_pos unpriv: ', base_rate_unprivileged)\n",
    "        print('base_pos priv: ', base_rate_privileged)\n",
    "\n",
    "        # favorable and unfavorable labels and feature_names\n",
    "        f_label = dataset_orig.favorable_label\n",
    "        uf_label = dataset_orig.unfavorable_label\n",
    "        feature_names = dataset_orig.feature_names\n",
    "\n",
    "        # introduce label or selection biases, assuming the original data is fair\n",
    "        if BIAS_TYPE == 'label':\n",
    "            dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "        elif BIAS_TYPE == 'selection':\n",
    "            dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "        else:\n",
    "            print('no bias type specified')\n",
    "\n",
    "        # show data info\n",
    "        print(\"#### Training Dataset shape\")\n",
    "        print(dataset_orig_train.features.shape)\n",
    "        print(\"#### Favorable and unfavorable labels\")\n",
    "        print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "        print(\"#### Protected attribute names\")\n",
    "        print(dataset_orig_train.protected_attribute_names)\n",
    "        print(\"#### Privileged and unprivileged protected groups\")\n",
    "        print(privileged_groups, unprivileged_groups)\n",
    "        print(\"#### Privileged and unprivileged protected attribute values\")\n",
    "        print(dataset_orig_train.privileged_protected_attributes, dataset_orig_train.unprivileged_protected_attributes)\n",
    "        print(\"#### Dataset feature names\")\n",
    "        print(dataset_orig_train.feature_names)\n",
    "        print('number of favorable labels: ', np.count_nonzero(dataset_orig_train.labels==f_label))\n",
    "        print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "        # statistics of favored/positive class BEFORE transf \n",
    "        priv_metric_orig['total_priv'] += metric_orig_train.num_instances(privileged = True) \n",
    "        priv_metric_orig['total_unpriv'] += metric_orig_train.num_instances(privileged = False) \n",
    "        favor_metric_orig['total_favor'] += metric_orig_train.base_rate()\n",
    "        favor_metric_orig['total_unfavor'] += 1 - metric_orig_train.base_rate()\n",
    "        favor_metric_orig['priv_favor'] += metric_orig_train.base_rate(privileged = True)\n",
    "        favor_metric_orig['priv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = True)\n",
    "        favor_metric_orig['unpriv_favor'] += metric_orig_train.base_rate(privileged = False)\n",
    "        favor_metric_orig['unpriv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = False)\n",
    "\n",
    "        print(\"#### Train shape, validation shape, test shape\")\n",
    "        print(dataset_orig_train.features.shape, dataset_orig_val.features.shape, dataset_orig_test.features.shape)\n",
    "\n",
    "        # testing mitigation methods \n",
    "        test_cases = TestAlgorithms(BASELINE)\n",
    "\n",
    "        # null mitigator\n",
    "        orig_metrics, orig_mia_metrics = test_cases.run_original(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, BASELINE, orig_metrics, orig_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset) \n",
    "        print(\"ORIG MIA METRICS \", orig_mia_metrics)\n",
    "        \n",
    "        # synthetic data mitigator\n",
    "        metric_transf_train, transf_metrics, transf_mia_metrics = test_cases.run_oversample(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, privileged_groups, unprivileged_groups, base_rate_privileged, base_rate_unprivileged, BASELINE, transf_metrics, transf_mia_metrics, f_label, uf_label, ATTACK, THRESH_ARR, DISPLAY, OS_MODE, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        # statistics of favored/positive class AFTER transf\n",
    "        favor_metric_transf['total_favor'] += metric_transf_train.base_rate()\n",
    "        favor_metric_transf['total_unfavor'] += 1 - metric_transf_train.base_rate()\n",
    "        favor_metric_transf['priv_favor'] += metric_transf_train.base_rate(privileged = True)\n",
    "        favor_metric_transf['priv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = True)\n",
    "        favor_metric_transf['unpriv_favor'] += metric_transf_train.base_rate(privileged = False)\n",
    "        favor_metric_transf['unpriv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = False)\n",
    "\n",
    "        # dir mitigator\n",
    "        dir_metrics, dir_mia_metrics = test_cases.run_dir(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test,  sens_attr, BASELINE, dir_metrics, dir_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset) \n",
    "\n",
    "        # reweigh mitigator\n",
    "        reweigh_metrics, reweigh_mia_metrics = test_cases.run_rew(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, reweigh_metrics, reweigh_mia_metrics, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        # eg mitigator, in-processing\n",
    "        eg_metrics, eg_mia_metrics = test_cases.run_eg(DATASET, dataset_orig_train, dataset_orig_val, dataset_orig_test, eg_metrics, eg_mia_metrics, BASELINE, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        # cpp mitigator\n",
    "    #     cpp_metrics, cpp_mia_metrics = test_cases.run_cpp(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, cpp_metrics, cpp_mia_metrics, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "        delete_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a163caa5",
   "metadata": {},
   "source": [
    "## Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47b50fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dictionary to store SHAP values\n",
    "# shap_results = {\n",
    "#     \"orig\": orig_metrics['shap_values'],\n",
    "#     \"transf\": transf_metrics['shap_values'],\n",
    "#     \"dir\": dir_metrics['shap_values'],\n",
    "#     \"reweigh\": reweigh_metrics['shap_values'],\n",
    "#     \"eg\": eg_metrics['shap_values']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2293e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_results = pd.DataFrame.from_dict(shap_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # File path\n",
    "# today = datetime.now().strftime('%Y-%m-%d')\n",
    "# file_path = f\"./mia2_results/rf_{ATTACK}_{DATASET}_shap_values_{today}.csv\"\n",
    "\n",
    "# # Save to CSV\n",
    "# shap_results.to_csv(file_path, index=True)\n",
    "\n",
    "# file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90de2a9",
   "metadata": {},
   "source": [
    "## Display Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5297f75-7e94-4c41-ae69-97b4e11bdcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38506977-5981-4c45-a7d0-38613da7edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig_copy = priv_metric_orig\n",
    "\n",
    "priv_metric_orig_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b736dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c736a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73a4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig = priv_metric_orig_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf623751",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "print('1)\\n')\n",
    "print(DATASET)\n",
    "print(dataset_orig_train.features.shape[0])\n",
    "\n",
    "print('2)\\n')\n",
    "priv_metric_orig = {k: [v/N] for (k,v) in priv_metric_orig.items()}\n",
    "results = [priv_metric_orig]\n",
    "tr = pd.Series(['orig'], name='num_instance')\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis = 0).set_index([tr])\n",
    "print(df)\n",
    "\n",
    "print('3)\\n')\n",
    "favor_metric_orig = {k: [v/N] for (k,v) in favor_metric_orig.items()}\n",
    "favor_metric_transf = {k: [v/N] for (k,v) in favor_metric_transf.items()}\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "results = [favor_metric_orig, favor_metric_transf]\n",
    "tr = pd.Series(['orig'] + ['transf'], name='dataset')\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis = 0).set_index([tr])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5039b1e0",
   "metadata": {},
   "source": [
    "# Train/Test Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef1ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_metrics(metrics):\n",
    "    accuracy_metrics = defaultdict(list)\n",
    "\n",
    "    # List of accuracy-related keys\n",
    "    accuracy_keys = [\n",
    "        'accuracy_train_0_-', 'accuracy_train_0_+',\n",
    "        'accuracy_train_1_-', 'accuracy_train_1_+',\n",
    "        'accuracy_test_0_-', 'accuracy_test_0_+',\n",
    "        'accuracy_test_1_-', 'accuracy_test_1_+',\n",
    "        'accuracy_train', 'accuracy_test'\n",
    "    ]\n",
    "\n",
    "    # Separate accuracy metrics into a new dictionary\n",
    "    for key in accuracy_keys:\n",
    "        if key in metrics:\n",
    "            accuracy_metrics[key] = metrics.pop(key)\n",
    "\n",
    "    return metrics, accuracy_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e982d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_metrics, orig_acc = separate_metrics(orig_metrics)\n",
    "transf_metrics, transf_acc = separate_metrics(transf_metrics)\n",
    "reweigh_metrics, reweigh_acc = separate_metrics(reweigh_metrics)\n",
    "dir_metrics, dir_acc = separate_metrics(dir_metrics)\n",
    "eg_metrics, eg_acc = separate_metrics(eg_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8cc8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std_accuracy(acc_metrics):\n",
    "    mean_std_accuracies = {\n",
    "        key: {\n",
    "            \"mean\": sum(values) / len(values),\n",
    "            \"std\": statistics.stdev(values) if len(values) > 1 else 0  # Avoid error if only one value\n",
    "        }\n",
    "        for key, values in acc_metrics.items()\n",
    "    }\n",
    "    return mean_std_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_acc_stats = calculate_mean_std_accuracy(orig_acc)\n",
    "transf_acc_stats = calculate_mean_std_accuracy(transf_acc)\n",
    "reweigh_acc_stats = calculate_mean_std_accuracy(reweigh_acc)\n",
    "dir_acc_stats = calculate_mean_std_accuracy(dir_acc)\n",
    "eg_acc_stats = calculate_mean_std_accuracy(eg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae83fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary to DataFrame with mean and std\n",
    "train_test_data = {\n",
    "    \"orig_acc_mean\": {key: value[\"mean\"] for key, value in orig_acc_stats.items()},\n",
    "    \"orig_acc_std\": {key: value[\"std\"] for key, value in orig_acc_stats.items()},\n",
    "    \"transf_acc_mean\": {key: value[\"mean\"] for key, value in transf_acc_stats.items()},\n",
    "    \"transf_acc_std\": {key: value[\"std\"] for key, value in transf_acc_stats.items()},\n",
    "    \"reweigh_acc_mean\": {key: value[\"mean\"] for key, value in reweigh_acc_stats.items()},\n",
    "    \"reweigh_acc_std\": {key: value[\"std\"] for key, value in reweigh_acc_stats.items()},\n",
    "    \"dir_acc_mean\": {key: value[\"mean\"] for key, value in dir_acc_stats.items()},\n",
    "    \"dir_acc_std\": {key: value[\"std\"] for key, value in dir_acc_stats.items()},\n",
    "    \"eg_acc_mean\": {key: value[\"mean\"] for key, value in eg_acc_stats.items()},\n",
    "    \"eg_acc_std\": {key: value[\"std\"] for key, value in eg_acc_stats.items()},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063eb6e5",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccdbe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary to DataFrame\n",
    "train_test_df = pd.DataFrame(train_test_data)\n",
    "\n",
    "# File path\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "file_path = f\"./dprf_mia1_results/{BASELINE}_{ATTACK}_{DATASET}_train_test_accuracies_{today}_depth7_eps50.csv\"\n",
    "\n",
    "# Save to CSV\n",
    "train_test_df.to_csv(file_path, index=True)\n",
    "\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd3105",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8158ae75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb16e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance_df = pd.DataFrame(orig_metrics[\"feature_importances\"])  # Extract feature importance across runs\n",
    "# feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a78a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "print('4)\\n')\n",
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_error_metrics = {k: [statistics.stdev(v)] for (k,v) in orig_metrics.items()}\n",
    "transf_error_metrics = {k: [statistics.stdev(v)] for (k,v) in transf_metrics.items()}\n",
    "reweigh_error_metrics = {k: [statistics.stdev(v)] for (k,v) in reweigh_metrics.items()}\n",
    "dir_error_metrics = {k: [statistics.stdev(v)] for (k,v) in dir_metrics.items()}\n",
    "eg_error_metrics = {k: [statistics.stdev(v)] for (k,v) in eg_metrics.items()}\n",
    "# pr_orig_error_metrics = {k: [statistics.stdev(v)] for (k,v) in pr_orig_metrics.items()}\n",
    "# cpp_error_metrics = {k: [statistics.stdev(v)] for (k,v) in cpp_metrics.items()}\n",
    "# ro_error_metrics = {k: [statistics.stdev(v)] for (k,v) in ro_metrics.items()}\n",
    "\n",
    "# mean value metrics\n",
    "orig_metrics_mean = {k: [sum(v)/N] for (k,v) in orig_metrics.items()}\n",
    "transf_metrics_mean = {k: [sum(v)/N] for (k,v) in transf_metrics.items()}\n",
    "reweigh_metrics_mean = {k:[sum(v)/N] for (k,v) in reweigh_metrics.items()}\n",
    "dir_metrics_mean = {k:[sum(v)/N] for (k,v) in dir_metrics.items()}\n",
    "eg_metrics_mean = {k:[sum(v)/N] for (k,v) in eg_metrics.items()}\n",
    "# pr_orig_metrics_mean = {k: [sum(v)/N] for (k,v) in pr_orig_metrics.items()}\n",
    "# cpp_metrics_mean = {k: [sum(v)/N] for (k,v) in cpp_metrics.items()}\n",
    "# ro_metrics_mean = {k: [sum(v)/N] for (k,v) in ro_metrics.items()}\n",
    "\n",
    "# Python paired sample t-test\n",
    "# from scipy.stats import ttest_rel\n",
    "# def paired_t (a, b):\n",
    "#     np_a = np.array(a)\n",
    "#     np_b = np.array(b)\n",
    "#     s, p = ttest_rel(np.absolute(np_a), np.absolute(np_b))\n",
    "#     return p\n",
    "\n",
    "# def acc_diff (a, b):\n",
    "#     np_a = np.array(a)\n",
    "#     np_b = np.array(b)\n",
    "#     delta = np_a - np_b\n",
    "#     m = statistics.mean(delta)\n",
    "#     s = statistics.stdev(delta)\n",
    "#     return [m, s]\n",
    "\n",
    "# if BASELINE == 'lr':\n",
    "#     plot_algo_lr(orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, eg_metrics_mean, pr_orig_metrics_mean, orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, eg_error_metrics, BASELINE)\n",
    "#     stat =  {k: [paired_t(transf_metrics[k], v)] for (k,v) in orig_metrics.items()}\n",
    "#     print(\"5)\")\n",
    "#     print(stat)\n",
    "# else:\n",
    "#     plot_algo(orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, eg_metrics_mean, orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, eg_error_metrics, BASELINE)\n",
    "#     stat =  {k: [paired_t(transf_metrics[k], v)] for (k,v) in orig_metrics.items()}\n",
    "#     print(stat)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1627a85",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f14ab",
   "metadata": {},
   "source": [
    "### Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b83d225-b984-4107-997e-a7be4f183a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type=BASELINE\n",
    "# Set up plotting options\n",
    "plt.rcParams.update({'font.size': 8})  # Set global font size\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "\n",
    "# Metrics and errors as lists of dictionaries\n",
    "results = [orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, eg_metrics_mean]\n",
    "errors = [orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, eg_error_metrics]\n",
    "\n",
    "# Classifier bias mitigators (for labels)\n",
    "index = pd.Series(\n",
    "    [model_type+'_orig', model_type+'_syn', model_type+'_dir', model_type+'_rew', model_type+'_eg'])\n",
    "\n",
    "# Create DataFrame for metrics and error bars\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis=0).set_index(index)\n",
    "df_error = pd.concat([pd.DataFrame(metrics) for metrics in errors], axis=0).set_index(index)\n",
    "\n",
    "# Dynamically generate titles for all metrics in df\n",
    "titles = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149148b8-21fc-4cad-bfab-dc793d2d6293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fairness metrics with error bars\n",
    "ax = df.plot.bar(\n",
    "    yerr=df_error, \n",
    "    capsize=2, \n",
    "    rot=0, \n",
    "    subplots=True, \n",
    "    title=titles, \n",
    "    fontsize=8, \n",
    "    figsize=(7, 10),  \n",
    "    legend=True,\n",
    "    width=0.7  \n",
    ")\n",
    "\n",
    "# Adjust Y-axis limits dynamically\n",
    "for i, subplot in enumerate(ax):\n",
    "    metric = titles[i]\n",
    "    y_values = df[metric]\n",
    "    y_errors = df_error[metric]\n",
    "\n",
    "    # Compute min and max with error bars included\n",
    "    y_min = (y_values - y_errors).min()\n",
    "    y_max = (y_values + y_errors).max()\n",
    "\n",
    "    # Add padding\n",
    "    y_range = y_max - y_min\n",
    "    padding = 0.1 * y_range if y_range > 0 else 0.05  # ensure some space even for flat values\n",
    "\n",
    "    lower = max(0, y_min - padding)\n",
    "    upper = y_max + padding\n",
    "\n",
    "    # Print min and max to check them\n",
    "    print(f\"Metric: {metric:20} | Min: {y_min:.4f} | Max: {y_max:.4f} | Range: ({lower:.4f}, {upper:.4f})\")\n",
    "\n",
    "    # Set Y-axis limits\n",
    "    subplot.set_ylim([lower, upper])\n",
    "\n",
    "    # Optional: force specific bounds if needed\n",
    "    if \"fpr\" in metric or \"fnr\" in metric:\n",
    "        subplot.set_ylim([0, 1])  # Keep 01 if needed for these metrics\n",
    "\n",
    "    # Move legend inside the plot\n",
    "    subplot.legend(loc='upper left', fontsize=8, frameon=True)\n",
    "\n",
    "# Better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a118582a",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c52e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of method names corresponding to results/errors\n",
    "method_names = [\"orig\", \"transf\", \"dir\", \"rew\", \"eg\"]\n",
    "\n",
    "# Initialize a list to hold data for the DataFrame\n",
    "fairness_data = []\n",
    "\n",
    "# Populate the data list with metrics and errors\n",
    "for method, metric, error in zip(method_names, results, errors):\n",
    "    for key in metric.keys():\n",
    "        fairness_data.append({\n",
    "            \"Method\": method,\n",
    "            \"Metric\": key,\n",
    "            \"Mean\": metric[key][0],  # Assuming the metric values are single-item lists\n",
    "            \"Error\": error[key][0]   # Assuming the error values are single-item lists\n",
    "        })\n",
    "\n",
    "# Create DataFrame from the data list\n",
    "fairness_df = pd.DataFrame(fairness_data)\n",
    "\n",
    "# File path with today's date\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "file_path = f\"./dprf_mia1_results/{BASELINE}_{ATTACK}_{DATASET}_fairness_metrics_{today}_depth7_eps50.csv\"\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "fairness_df.to_csv(file_path, index=True)\n",
    "\n",
    "print(f\"File saved at: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7aff8d",
   "metadata": {},
   "source": [
    "## Visualization of MIA results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588cc377",
   "metadata": {},
   "source": [
    "\n",
    "### Visualization of MIA Attacks against various Fairness Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a42bd",
   "metadata": {},
   "source": [
    "#### Privacy risk subpopulations vs Fairness with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dddfde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "%matplotlib inline\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "eg_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in eg_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "# cpp_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in cpp_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "eg_mia_metrics_mean = {k:sum(v)/N for (k,v) in eg_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "# cpp_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6882740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "           orig_mia_error_metrics,\n",
    "           transf_mia_metrics_mean,\n",
    "           transf_mia_error_metrics,\n",
    "           dir_mia_metrics_mean,\n",
    "           dir_mia_error_metrics,\n",
    "           reweigh_mia_metrics_mean,\n",
    "           reweigh_mia_error_metrics,\n",
    "           eg_mia_metrics_mean,\n",
    "           eg_mia_error_metrics\n",
    "          ]\n",
    "\n",
    "index = pd.Series(['orig'] + ['orig_std'] + ['syn'] + ['syn_std'] + ['dir'] + ['dir_std'] + ['rew'] + \n",
    "                  ['rew_std'] + ['eg'] + ['eg_std'], name='Classifier MIA Attacks')\n",
    "#                   + ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0aab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [orig_mia_metrics_mean,\n",
    "           transf_mia_metrics_mean,\n",
    "           dir_mia_metrics_mean,\n",
    "           reweigh_mia_metrics_mean,\n",
    "           eg_mia_metrics_mean,\n",
    "          ]\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "          transf_mia_error_metrics,\n",
    "          dir_mia_error_metrics,\n",
    "          reweigh_mia_error_metrics,\n",
    "          eg_mia_error_metrics\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df1431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = df[['subpopulation_0.0_label_0.0_mia_privacy_risk',\n",
    "       'subpopulation_1.0_label_0.0_mia_privacy_risk',\n",
    "                       'subpopulation_0.0_label_1.0_mia_privacy_risk',\n",
    "       'subpopulation_1.0_label_1.0_mia_privacy_risk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e94927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = df_groups.rename(columns={'subpopulation_0.0_label_0.0_mia_privacy_risk': 'G0-',\n",
    "                           'subpopulation_1.0_label_0.0_mia_privacy_risk': 'G1-',\n",
    "                           'subpopulation_0.0_label_1.0_mia_privacy_risk': 'G0+',\n",
    "                           'subpopulation_1.0_label_1.0_mia_privacy_risk': 'G1+'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d711e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f230c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225fcad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tabular Format\n",
    "# importing the modules\n",
    "from tabulate import tabulate\n",
    "\n",
    " \n",
    "# displaying the DataFrame\n",
    "print(tabulate(df_groups.T, headers = 'keys', tablefmt = 'simple'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7040e9bb",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696b6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7b42a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of method names corresponding to results/errors\n",
    "method_names = [\"orig\", \"transf\", \"dir\", \"rew\", \"eg\"]\n",
    "\n",
    "# Initialize a list to hold data for the DataFrame\n",
    "pr_data = []\n",
    "\n",
    "# Populate the data list with metrics and errors\n",
    "for method, metric, error in zip(method_names, results, errors):\n",
    "    for key in metric.keys():\n",
    "        pr_data.append({\n",
    "            \"Method\": method,\n",
    "            \"Metric\": key,\n",
    "            \"Mean Privacy Risk\": metric[key],  # Privacy risk mean\n",
    "            \"Error\": error[key]               # Privacy risk error\n",
    "        })\n",
    "\n",
    "# Create DataFrame from the data list\n",
    "pr_df = pd.DataFrame(pr_data)\n",
    "\n",
    "# File path with today's date\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "file_path = f\"./dprf_mia1_results/{BASELINE}_{ATTACK}_{DATASET}_mia_privacy_risks_metrics_{today}_depth7_eps50.csv\"\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "pr_df.to_csv(file_path, index=True)\n",
    "\n",
    "print(f\"File saved at: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f69948e",
   "metadata": {},
   "source": [
    "# Main Bar Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99444ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subpopulations and fairness methods\n",
    "subpopulations = {\n",
    "    'subpopulation_0.0_label_0.0_mia_privacy_risk': \"Unprivileged Unfavorable\", \n",
    "    'subpopulation_0.0_label_1.0_mia_privacy_risk': \"Unprivileged Favorable\", \n",
    "    'subpopulation_1.0_label_0.0_mia_privacy_risk': \"Privileged Unfavorable\",\n",
    "    'subpopulation_1.0_label_1.0_mia_privacy_risk': \"Privileged Favorable\"\n",
    "}\n",
    "\n",
    "fairness_methods = [\"syn\", \"dir\", \"rew\", \"eg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84957cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine results into a list\n",
    "all_results = [\n",
    "    transf_mia_metrics_mean,\n",
    "    dir_mia_metrics_mean,\n",
    "    reweigh_mia_metrics_mean,\n",
    "    eg_mia_metrics_mean\n",
    "]\n",
    "\n",
    "# Organize data for plotting\n",
    "data = {subpopulations[key]: [results[key] for results in all_results] for key in subpopulations.keys()}\n",
    "orig_values = orig_mia_metrics_mean\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "idx = 0\n",
    "\n",
    "for key, value in subpopulations.items():\n",
    "    accuracies = data[value]\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot bar chart (excluding 'orig')\n",
    "    ax.bar(fairness_methods, accuracies, color='skyblue', edgecolor='black')\n",
    "    \n",
    "    # Add dashed line for 'orig' MIA accuracy\n",
    "    ax.axhline(orig_values[key], color='red', linestyle='--', label='Orig MIA')\n",
    "    \n",
    "    # Title and labels\n",
    "    ax.set_title(f\"MIA Accuracies - {value}\", fontsize=10)\n",
    "    ax.set_ylabel(\"MIA Accuracy\")\n",
    "    ax.set_xticks(np.arange(len(fairness_methods)))\n",
    "    ax.set_xticklabels(fairness_methods, rotation=45)\n",
    "    ax.legend()\n",
    "    \n",
    "    idx = idx + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a2e6d",
   "metadata": {},
   "source": [
    "### Visualizing using novel technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faed82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_error_metrics = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "eg_mia_error_metrics = {k: v for (k,v) in eg_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "#orig_mia_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_error_metrics.keys():\n",
    "    for val in orig_mia_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in eg_mia_error_metrics.keys():\n",
    "    for val in eg_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"eg\", key.replace(\"_mia_attacker_advantage\", \"\"), val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b110698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"Privacy Risk\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8a5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only subgroups\n",
    "df_subgroups = df[~((df[\"MIA\"] == \"entire_dataset_label_0.0_mia_privacy_risk\") | (df[\"MIA\"] == \"entire_dataset_label_1.0_mia_privacy_risk\")) ]\n",
    "df_subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df3d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15,8))\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df_subgroups, x=\"MIA\", y=\"Privacy Risk\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Privacy Risk\" )\n",
    "g.set(ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359dc0bf",
   "metadata": {},
   "source": [
    "### ROC curves and AUC scores with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7b52ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for orig dataset with different subpopulations\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for key in [\"entire_dataset_mia_result\", \n",
    "            \"subpopulation_0.0_label_0.0_mia_result\",\n",
    "            \"subpopulation_0.0_label_1.0_mia_result\", \n",
    "            \"subpopulation_1.0_label_0.0_mia_result\",\n",
    "            \"subpopulation_1.0_label_1.0_mia_result\"]:\n",
    "     # fprs = [mia_res.fpr for mia_res in orig_mia_metrics[key]]\n",
    "    # tprs = [mia_res.tpr for mia_res in orig_mia_metrics[key]]\n",
    "    tprs = []\n",
    "    \n",
    "    # aucs = [mia_res.get_auc() for mia_res in orig_mia_metrics[key]]\n",
    "    aucs = []\n",
    "\n",
    "    # mean_fpr = np.mean(fprs, axis=0)\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "    for mia_res in orig_mia_metrics[key]:\n",
    "        interp_tpr = np.interp(mean_fpr, mia_res.fpr, mia_res.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(mia_res.get_auc())\n",
    "    \n",
    "    #print(mean_fpr)\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    \n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    \n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        #color=\"b\",\n",
    "        label=r\"Mean ROC for %s $\\pm$ 1 std. dev. (AUC = %0.2f $\\pm$ %0.2f)\" % ( key ,mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        #label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve with variability\",\n",
    ")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ff10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entire dataset with different subpopulations\n",
    "# fig, ax = plt.subplots(figsize=(12, 10))\n",
    "fig, ax = plt.subplots(figsize=(24, 18))\n",
    "\n",
    "for mia_metrics, name in zip([orig_mia_metrics, transf_mia_metrics], [\"orig\", \"syn\"]): \n",
    "#                               dir_mia_metrics, reweigh_mia_metrics], [\"orig\", \"syn\", \"dir\", \"reweigh\"] ):\n",
    "    for key in [\"entire_dataset_mia_result\", \n",
    "                \"subpopulation_0.0_label_0.0_mia_result\",\n",
    "                \"subpopulation_0.0_label_1.0_mia_result\", \n",
    "                \"subpopulation_1.0_label_0.0_mia_result\",\n",
    "                \"subpopulation_1.0_label_1.0_mia_result\"]:\n",
    "   \n",
    "        # fprs = [mia_res.fpr for mia_res in orig_mia_metrics[key]]\n",
    "        # tprs = [mia_res.tpr for mia_res in orig_mia_metrics[key]]\n",
    "        tprs = []\n",
    "        # aucs = [mia_res.get_auc() for mia_res in orig_mia_metrics[key]]\n",
    "        aucs = []\n",
    "\n",
    "        # mean_fpr = np.mean(fprs, axis=0)\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "        for mia_res in mia_metrics[key]:\n",
    "            print(mia_res)\n",
    "            interp_tpr = np.interp(mean_fpr, mia_res.fpr, mia_res.tpr)\n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "            aucs.append(mia_res.get_auc())\n",
    "\n",
    "        #print(mean_fpr)\n",
    "        print(tprs)\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std(aucs)\n",
    "\n",
    "        ax.plot(\n",
    "            mean_fpr,\n",
    "            mean_tpr,\n",
    "            #color=\"b\",\n",
    "            label=r\"%s Mean ROC for %s $\\pm$ 1 std. dev. (AUC = %0.2f $\\pm$ %0.2f)\" % (name, key ,mean_auc, std_auc),\n",
    "            lw=2,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        std_tpr = np.std(tprs, axis=0)\n",
    "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        ax.fill_between(\n",
    "            mean_fpr,\n",
    "            tprs_lower,\n",
    "            tprs_upper,\n",
    "            color=\"grey\",\n",
    "            alpha=0.2,\n",
    "            #label=r\"$\\pm$ 1 std. dev.\",\n",
    "        )\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve for MIA attacks against Fairness Approaches\",\n",
    ")\n",
    "ax.legend(loc=\"lower right\")\n",
    "# ax.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entire dataset\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "for mia_res in orig_mia_metrics[\"entire_dataset_mia_result\"]:\n",
    "    plt.plot(mia_res.fpr,mia_res.tpr,label=f\"{mia_res.get_name()} auc={mia_res.get_auc()}\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e701aad9",
   "metadata": {},
   "source": [
    "## MIA Attacks AUC vs Fairness Bar Chart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f18425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "egr_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in eg_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "eg_mia_metrics_mean = {k:sum(v)/N for (k,v) in eg_mia_metrics.items() if k.endswith(\"mia_auc\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b078a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuazlization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "        transf_mia_metrics_mean,\n",
    "        dir_mia_metrics_mean,\n",
    "        reweigh_mia_metrics_mean,\n",
    "        eg_mia_metrics_mean\n",
    "        ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "        transf_mia_error_metrics,\n",
    "        dir_mia_error_metrics,\n",
    "        reweigh_mia_error_metrics,\n",
    "          egr_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn']+ ['dir']+ ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2233661a",
   "metadata": {},
   "source": [
    "###  MIA Attackers Advantage Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f09191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data structures to plot point categorical plot from seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ef741",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "egr_mia_error_metrics = {k: v for (k,v) in eg_mia_metrics.items() if k.endswith(\"attacker_advantage\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_metrics_att_ad.keys():\n",
    "    for val in orig_mia_metrics_att_ad[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in egr_mia_error_metrics.keys():\n",
    "    for val in egr_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"egr\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "advantage_metrics_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105df8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"attacker_advantage\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac8578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting without scaling y limis to 1\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"attacker_advantage\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's Advantage\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf746e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15,8))\n",
    "\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"attacker_advantage\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's Advantage\" )\n",
    "g.set(ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b0356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(orig_mia_metrics_att_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "egr_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in eg_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "eg_mia_metrics_mean = {k:sum(v)/N for (k,v) in eg_mia_metrics.items() if k.endswith(\"attacker_advantage\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuazlization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "        transf_mia_metrics_mean,\n",
    "        dir_mia_metrics_mean,\n",
    "        reweigh_mia_metrics_mean,\n",
    "           eg_mia_metrics_mean\n",
    "        ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "        transf_mia_error_metrics,\n",
    "        dir_mia_error_metrics,\n",
    "        reweigh_mia_error_metrics,\n",
    "          egr_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn']+ ['dir']+ ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1309a4",
   "metadata": {},
   "source": [
    "## PPV Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "egr_mia_error_metrics = {k: v for (k,v) in eg_mia_metrics.items() if k.endswith(\"mia_ppv\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14018577",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_metrics_att_ad.keys():\n",
    "    for val in orig_mia_metrics_att_ad[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in egr_mia_error_metrics.keys():\n",
    "    for val in egr_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"egr\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "advantage_metrics_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95980069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"PPV\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff9b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting without scaling y limis to 1\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"PPV\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's PPV\" )\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
