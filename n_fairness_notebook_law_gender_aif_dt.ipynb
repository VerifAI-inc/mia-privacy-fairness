{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8c9f6b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "151964f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f57d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from data_utils import DatasetBuilder\n",
    "from metrics_utils import compute_metrics, describe_metrics, get_test_metrics, test\n",
    "from plot_utils import plot\n",
    "from mitigators import NullMitigator, SyntheticMitigator, DIRMitigator, ReweighMitigator, EGMitigator, PRMitigator, CPPMitigator, ROMitigator \n",
    "from test_algorithms import TestAlgorithms\n",
    "from plot_utils import plot_algo_lr, plot_algo\n",
    "\n",
    "# Metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "\n",
    "# Bias insertion\n",
    "from oversample import label_bias, selection_bias \n",
    "from metrics_utils import get_orig_model_metrics\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Privacy Meter\n",
    "from privacy_meter.dataset import Dataset\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "696bb6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180b2a8",
   "metadata": {},
   "source": [
    "## Arguments & Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "564c7837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-a', '--attack'], dest='attack', nargs=None, const=None, default='mia1', type=None, choices=['mia1', 'mia2'], required=False, help='attacks: our implementation, their implementation', metavar=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct argument parser\n",
    "import argparse\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--data\", choices=['adult', 'compas', 'german', 'bank', 'meps19', 'grade', 'law_sex'], default='compas', help=\"dataset: adult, compas, german, bank, meps19, grade\")\n",
    "ap.add_argument(\"-c\", \"--classifier\", choices=['lr', 'rf', 'svm', 'nn', 'nb'], default='lr', help=\"baseline model: lr, rf, svm, nn, nb, dt\")\n",
    "ap.add_argument(\"-m\", \"--mitigator\", choices=['dir', 'rew', 'egr', 'pr', 'cpp', 'ro'], required=False, help=\"mitigators: dir, rew, egr, pr, cpp, ro\")\n",
    "ap.add_argument(\"-b\", \"--bias\", default=0., help=\"amount of bias: o-1\")\n",
    "ap.add_argument(\"-t\", \"--biastype\", choices=['label', 'selection', 'none'], default='none', help=\"amount of bias: o-1\")\n",
    "ap.add_argument(\"-o\", \"--os\", default=2, help=\"oversample mode: 1: privi unfav 2: unpriv fav\")\n",
    "ap.add_argument(\"-a\", \"--attack\", choices=['mia1', 'mia2'], default='mia1', help=\"attacks: our implementation, their implementation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4f8856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['']\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19b063bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 'compas',\n",
       " 'classifier': 'lr',\n",
       " 'mitigator': None,\n",
       " 'bias': 0.0,\n",
       " 'biastype': 'none',\n",
       " 'os': 2,\n",
       " 'attack': 'mia1'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0dd1c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"law_gender_aif\"#args[\"data\"]\n",
    "BASELINE = \"dt\" #args[\"classifier\"]\n",
    "MITIGATOR = args[\"mitigator\"]\n",
    "BIAS = float(args[\"bias\"])\n",
    "BIAS_TYPE = args[\"biastype\"]\n",
    "OS_MODE = int(args[\"os\"])\n",
    "ATTACK = \"mia1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b16266c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# global constants\n",
    "if BASELINE == 'svm' or BASELINE == 'nn':\n",
    "    SCALER = False \n",
    "else:\n",
    "    SCALER = False \n",
    "DISPLAY = False \n",
    "THRESH_ARR = 0.5\n",
    "\n",
    "# loop ten times \n",
    "N = 20\n",
    "\n",
    "# percentage of favor and unfavor\n",
    "priv_metric_orig = defaultdict(float)\n",
    "favor_metric_orig = defaultdict(float)\n",
    "favor_metric_transf = defaultdict(float)\n",
    "\n",
    "# for each pre-processing approach, we create a mia_metric_results\n",
    "orig_metrics = defaultdict(list)\n",
    "orig_mia_metrics = defaultdict(list)\n",
    "\n",
    "transf_metrics = defaultdict(list) \n",
    "transf_mia_metrics = defaultdict(list) \n",
    "\n",
    "reweigh_metrics = defaultdict(list) \n",
    "reweigh_mia_metrics = defaultdict(list) \n",
    "\n",
    "dir_metrics = defaultdict(list) \n",
    "dir_mia_metrics = defaultdict(list) \n",
    "\n",
    "eg_metrics = defaultdict(list) \n",
    "eg_mia_metrics = defaultdict(list) \n",
    "\n",
    "\n",
    "pr_orig_metrics = defaultdict(list) \n",
    "cpp_metrics = defaultdict(list) \n",
    "ro_metrics = defaultdict(list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42c45e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mia1'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATTACK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a48a7",
   "metadata": {},
   "source": [
    "## Loading & Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "da867c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and set the groups\n",
    "dataset_builder =  DatasetBuilder(DATASET)\n",
    "dataset_orig = dataset_builder.load_data()\n",
    "sens_attr = dataset_orig.protected_attribute_names[0]\n",
    "unprivileged_groups = dataset_builder.unprivileged_groups\n",
    "privileged_groups = dataset_builder.privileged_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9aabd2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22342, 4)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb84777c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'gender': 1}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "privileged_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a78a2150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gender'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5fedd14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# favorable and unfavorable labels and feature_names\n",
    "f_label = dataset_orig.favorable_label\n",
    "uf_label = dataset_orig.unfavorable_label\n",
    "feature_names = dataset_orig.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1fb1ad08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         1.         0.975     ]\n",
      " [1.         1.         0.75675676 0.95      ]\n",
      " [1.         0.         0.67567568 0.9       ]\n",
      " ...\n",
      " [1.         0.         0.67567568 0.875     ]\n",
      " [1.         1.         0.86486486 0.975     ]\n",
      " [1.         0.         0.83783784 0.875     ]]\n",
      "no bias type specified\n"
     ]
    }
   ],
   "source": [
    "if ATTACK == \"mia1\":\n",
    "    # training data split ratio\n",
    "    p = 0.5\n",
    "    # split dataset into train, validation, and test\n",
    "    dataset_orig_train, dataset_orig_test = dataset_orig.split([p], shuffle=True)\n",
    "    dataset_orig_val = dataset_orig_test\n",
    "    print(dataset_orig_train.features)\n",
    "\n",
    "    # introduce label or selection biases, assuming the original data is fair\n",
    "    if BIAS_TYPE == 'label':\n",
    "        dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    elif BIAS_TYPE == 'selection':\n",
    "        dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    else:\n",
    "        print('no bias type specified')\n",
    "        \n",
    "    dataset_orig_train\n",
    "    dataset_orig_train?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cfd5f8",
   "metadata": {},
   "source": [
    "## Run Mitigating Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3ae7f8",
   "metadata": {},
   "source": [
    "### Setup for MIA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad51a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14350dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ATTACK == \"mia2\":\n",
    "    # prepare data format\n",
    "    X = dataset_orig.features\n",
    "    y_true = dataset_orig.labels.ravel()\n",
    "    sens_attr = dataset_orig.protected_attribute_names[0]\n",
    "    sens_attr_index = dataset_orig.feature_names.index(sens_attr)\n",
    "    sensitive_features = dataset_orig.features[:, sens_attr_index]\n",
    "\n",
    "    X_other_features = np.delete(X, sens_attr_index, axis=1)\n",
    "    X_other_features_normalized = preprocessing.normalize(X_other_features, norm='l2')\n",
    "\n",
    "    # Reconstruct X by combining the sensitive attribute and the normalized features\n",
    "    # Insert the sensitive attribute back into its original position\n",
    "    X_normalized = np.insert(X_other_features_normalized, sens_attr_index, sensitive_features, axis=1)\n",
    "    X = X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89c1ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_indices_reference():\n",
    "    # Determine split sizes proportionally (to sum up to the full dataset size)\n",
    "    num_train_points = int(X.shape[0] * 0.12)\n",
    "    num_test_points = int(X.shape[0] * 0.12)\n",
    "    num_population_points = int(X.shape[0] * 0.3)  # Reduced from 30000\n",
    "\n",
    "    # Start with all indices\n",
    "    all_indices = np.arange(X.shape[0])\n",
    "\n",
    "    # Select train indices without replacement\n",
    "    train_index = np.random.choice(all_indices, num_train_points, replace=False)\n",
    "    # Remove train indices from available indices\n",
    "    remaining_indices = np.setdiff1d(all_indices, train_index)\n",
    "\n",
    "    # Select test indices from the remaining indices without replacement\n",
    "    test_index = np.random.choice(remaining_indices, num_test_points, replace=False)\n",
    "    # Remove test indices from available indices\n",
    "    remaining_indices = np.setdiff1d(remaining_indices, test_index)\n",
    "\n",
    "    # Select population indices from the remaining indices (can also choose all remaining points)\n",
    "    population_index = np.random.choice(remaining_indices, min(num_population_points, len(remaining_indices)), replace=False)\n",
    "\n",
    "    # Summary of counts\n",
    "    print(\"==============================================================\")\n",
    "    print(\"GET UNIQUE INDICES REFERENCE\")\n",
    "    print(f\"Number of train points: {len(train_index)}\")\n",
    "    print(f\"Number of test points: {len(test_index)}\")\n",
    "    print(f\"Number of population points: {len(population_index)}\")\n",
    "    print(\"==============================================================\")\n",
    "    \n",
    "    return train_index, test_index, population_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "414d335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(train_index, test_index, population_index, g_train, g_test, g_pop_train):\n",
    "    # create the target model's dataset\n",
    "    train_ds = {'x': X[train_index], 'y': y_true[train_index],'g':g_train}\n",
    "    test_ds = {'x': X[test_index], 'y': y_true[test_index], 'g':g_test}\n",
    "    target_dataset = Dataset(\n",
    "        data_dict={'train': train_ds, 'test': test_ds},\n",
    "        default_input='x', default_output='y', default_group='g'\n",
    "    )\n",
    "\n",
    "    # create the reference dataset\n",
    "    population_ds = {'x': X[population_index], 'y': y_true[population_index], 'g': g_pop_train}\n",
    "    reference_dataset = Dataset(\n",
    "        data_dict={'train': population_ds},\n",
    "        default_input='x', default_output='y', default_group='g'\n",
    "    )\n",
    "    \n",
    "    return target_dataset, reference_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e23be8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features, labels, and protected attributes into a DataFrame\n",
    "def create_binary_label_dataset(dataset_orig, X, y, sensitive_features, sens_attr_name, privileged_value, unprivileged_value):\n",
    "    print(\"=====================================================\")\n",
    "    print(\"CREATE BINARY LABEL DATASET\")\n",
    "    # Extract the feature names from the original dataset\n",
    "    feature_names = dataset_orig.feature_names\n",
    "\n",
    "    # Create a DataFrame with features, labels, and sensitive attribute\n",
    "    df = pd.DataFrame(X, columns=feature_names)\n",
    "    df[dataset_orig.label_names[0]] = y\n",
    "#     df[sens_attr_name] = sensitive_features\n",
    "\n",
    "    print(df.head())\n",
    "    # print(dataset_orig.feature_names)\n",
    "    # print(dataset_orig.features.shape)\n",
    "    \n",
    "    # df_orig, _ = dataset_orig.convert_to_dataframe()\n",
    "\n",
    "    # # Display the first few rows\n",
    "    # print(\"Original df's head:\", df_orig.head())\n",
    "    \n",
    "    # Get the unique labels and their counts\n",
    "    # unique_labels, counts = np.unique(dataset_orig.labels, return_counts=True)\n",
    "\n",
    "    # # Print the value counts\n",
    "    # for label, count in zip(unique_labels, counts):\n",
    "    #     print(f\"Label {label}: {count} instances\")\n",
    "\n",
    "    # Create the BinaryLabelDataset\n",
    "    dataset = BinaryLabelDataset(\n",
    "        favorable_label=1.0,  # Adjust as per your dataset\n",
    "        unfavorable_label=0.0,  # Adjust as per your dataset\n",
    "        df=df,  # DataFrame containing features, labels, and protected attribute\n",
    "        label_names=dataset_orig.label_names,  # Column name of labels in DataFrame\n",
    "        protected_attribute_names=[sens_attr_name],  # Protected attribute column\n",
    "        privileged_protected_attributes=[privileged_value],  # Privileged group values\n",
    "        unprivileged_protected_attributes=[unprivileged_value]  # Unprivileged group values\n",
    "    )\n",
    "    \n",
    "    # print(dataset.feature_names)\n",
    "    # print(dataset.features.shape)\n",
    "    # # Get the unique labels and their counts\n",
    "    # unique_labels, counts = np.unique(dataset.labels, return_counts=True)\n",
    "\n",
    "    # Print the value counts\n",
    "    # for label, count in zip(unique_labels, counts):\n",
    "    #     print(f\"Label {label}: {count} instances\")\n",
    "    \n",
    "    print(\"=====================================================\")\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "22a3f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_logs():\n",
    "    # Search for directories ending with _group or _pop\n",
    "    for pattern in [\"*_group\", \"*_pop\"]:\n",
    "        # Find matching directories\n",
    "        for log_dir in glob.glob(pattern):\n",
    "            if os.path.exists(log_dir) and os.path.isdir(log_dir):  # Ensure it's a directory\n",
    "                shutil.rmtree(log_dir)\n",
    "                print(f\"{log_dir} deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31097df4",
   "metadata": {},
   "source": [
    "### Calling Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b3d0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = None\n",
    "reference_dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eea401f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Train dataset's features are as below:\n",
      "[[1.         0.         0.86486486 0.825     ]\n",
      " [1.         0.         0.64864865 0.9       ]\n",
      " [1.         0.         0.81081081 0.75      ]\n",
      " ...\n",
      " [1.         0.         0.86486486 0.9       ]\n",
      " [1.         0.         0.78378378 0.75      ]\n",
      " [1.         1.         0.59459459 0.85      ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6309.0 4862.0\n",
      "base_pos unpriv:  0.2914438502673797\n",
      "base_pos priv:  0.3067047075606277\n",
      "number of favorable labels:  3352\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.015261\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3445\n",
      "Number of test samples (ntest): 3475\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1417\n",
      "Number of test samples (ntest): 1381\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4374\n",
      "Number of test samples (ntest): 4330\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1935\n",
      "Number of test samples (ntest): 1985\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.95      0.83      7819\n",
      "         1.0       0.62      0.18      0.27      3352\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.57      0.55     11171\n",
      "weighted avg       0.70      0.72      0.66     11171\n",
      "\n",
      "Train accuracy:  0.7204368454032763\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.55\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4274440148269396\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7819, Test = 7805\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4274440148269396\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3352, Test = 3366\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.176777061517446\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3445, Test = 3475\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.44183275227903934\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1417, Test = 1381\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.3862943611198906\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4374, Test = 4330\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4274440148269396\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1935, Test = 1985\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.176777061517446\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11278\n",
      "after transf priv:  0.3067047075606277\n",
      "after transf unpriv:  0.3067015496075669\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000003\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3445\n",
      "Number of test samples (ntest): 3475\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1417\n",
      "Number of test samples (ntest): 1381\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4374\n",
      "Number of test samples (ntest): 4330\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1935\n",
      "Number of test samples (ntest): 1985\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7819\n",
      "         1.0       0.63      0.18      0.28      3459\n",
      "\n",
      "    accuracy                           0.72     11278\n",
      "   macro avg       0.68      0.57      0.55     11278\n",
      "weighted avg       0.70      0.72      0.66     11278\n",
      "\n",
      "Train accuracy:  0.7158184075190637\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.61\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7819, Test = 7805\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4818380868927383\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3352, Test = 3366\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.2376111634747657\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3445, Test = 3475\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.49\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.2992428948528569\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1417, Test = 1381\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.42\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.9473813189441862\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4374, Test = 4330\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5340824859302579\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1935, Test = 1985\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.2376111634747657\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3445\n",
      "Number of test samples (ntest): 3475\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1417\n",
      "Number of test samples (ntest): 1381\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4374\n",
      "Number of test samples (ntest): 4330\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1935\n",
      "Number of test samples (ntest): 1985\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7819\n",
      "         1.0       0.64      0.14      0.23      3352\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7185569778891774\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.26\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.41897882727488733\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7819, Test = 7805\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.41897882727488733\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3352, Test = 3366\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -1.3993664426872434\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3445, Test = 3475\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.36000273403140703\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1417, Test = 1381\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.55\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -1.08462604669337\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4374, Test = 4330\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.41897882727488733\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1935, Test = 1985\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -1.213022639845854\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3445\n",
      "Number of test samples (ntest): 3475\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1417\n",
      "Number of test samples (ntest): 1381\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4374\n",
      "Number of test samples (ntest): 4330\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1935\n",
      "Number of test samples (ntest): 1985\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.95      0.83      7819\n",
      "         1.0       0.62      0.17      0.27      3352\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.56      0.55     11171\n",
      "weighted avg       0.70      0.72      0.66     11171\n",
      "\n",
      "Train accuracy:  0.7195416703965626\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4560649889634026\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7819, Test = 7805\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4464185744590191\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3352, Test = 3366\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.1859536261462875\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3445, Test = 3475\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.43887492150553054\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1417, Test = 1381\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.3199544348700085\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4374, Test = 4330\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.41662390121555953\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1935, Test = 1985\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.176287158962144\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3445\n",
      "Number of test samples (ntest): 3475\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1417\n",
      "Number of test samples (ntest): 1381\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4374\n",
      "Number of test samples (ntest): 4330\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1935\n",
      "Number of test samples (ntest): 1985\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7819\n",
      "         1.0       0.58      0.15      0.23      3352\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.55      0.53     11171\n",
      "weighted avg       0.68      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7118431653388237\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.02\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -1.505774340303506\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7819, Test = 7805\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.06\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.010738730963293974\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3352, Test = 3366\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.16\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.505774340303506\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3445, Test = 3475\n",
      "  AUC: 0.48\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.50\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.05\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.010738730963293974\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1417, Test = 1381\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.15\n",
      "  Test Accuracy (TNR): 0.88\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.010738730963293974\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4374, Test = 4330\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1935, Test = 1985\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.20\n",
      "  Test Accuracy (TNR): 0.83\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -4.5392629171971075\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.86486486 0.875     ]\n",
      " [1.         1.         1.         0.9       ]\n",
      " [1.         1.         0.89189189 0.925     ]\n",
      " ...\n",
      " [1.         1.         0.83783784 0.925     ]\n",
      " [1.         1.         0.72972973 0.85      ]\n",
      " [1.         1.         0.66216216 0.8       ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6341.0 4830.0\n",
      "base_pos unpriv:  0.28612836438923395\n",
      "base_pos priv:  0.30831099195710454\n",
      "number of favorable labels:  3337\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.022183\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3448\n",
      "Number of test samples (ntest): 3472\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1382\n",
      "Number of test samples (ntest): 1416\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4386\n",
      "Number of test samples (ntest): 4318\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1955\n",
      "Number of test samples (ntest): 1965\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7834\n",
      "         1.0       0.65      0.13      0.22      3337\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.69      0.55      0.52     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7190940828932056\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.31\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.8609406367909901\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7834, Test = 7790\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3794896217049037\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3337, Test = 3381\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -1.285198244248522\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3448, Test = 3472\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3282967916059711\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1382, Test = 1416\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.48\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.041453874828161\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4386, Test = 4318\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.3794896217049037\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1955, Test = 1965\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.81\n",
      "  Optimal thershold: -1.241713132308783\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11325\n",
      "after transf priv:  0.30831099195710454\n",
      "after transf unpriv:  0.30818619582664525\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000125\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3448\n",
      "Number of test samples (ntest): 3472\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1382\n",
      "Number of test samples (ntest): 1416\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4386\n",
      "Number of test samples (ntest): 4318\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1955\n",
      "Number of test samples (ntest): 1965\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7834\n",
      "         1.0       0.65      0.16      0.25      3491\n",
      "\n",
      "    accuracy                           0.71     11325\n",
      "   macro avg       0.69      0.56      0.54     11325\n",
      "weighted avg       0.70      0.71      0.65     11325\n",
      "\n",
      "Train accuracy:  0.7144370860927153\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.33\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.9555114450274365\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7834, Test = 7790\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.42\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3184537311185346\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3337, Test = 3381\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -1.2992829841302609\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3448, Test = 3472\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.34830669426821587\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1382, Test = 1416\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.39\n",
      "  Test Accuracy (TNR): 0.69\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.9382696385929302\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4386, Test = 4318\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.37\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.3184537311185346\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1955, Test = 1965\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.82\n",
      "  Optimal thershold: -1.2992829841302609\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3448\n",
      "Number of test samples (ntest): 3472\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1382\n",
      "Number of test samples (ntest): 1416\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4386\n",
      "Number of test samples (ntest): 4318\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1955\n",
      "Number of test samples (ntest): 1965\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7834\n",
      "         1.0       0.66      0.12      0.20      3337\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.69      0.55      0.52     11171\n",
      "weighted avg       0.70      0.72      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7190045653925342\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.33\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.587786664902119\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7834, Test = 7790\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.16\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5596157879354228\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3337, Test = 3381\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -1.5260563034950494\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3448, Test = 3472\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.373513508301562\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1382, Test = 1416\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -1.791759469228055\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4386, Test = 4318\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5978370007556204\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1955, Test = 1965\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.4816045409242156\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3448\n",
      "Number of test samples (ntest): 3472\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1382\n",
      "Number of test samples (ntest): 1416\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4386\n",
      "Number of test samples (ntest): 4318\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1955\n",
      "Number of test samples (ntest): 1965\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83      7834\n",
      "         1.0       0.62      0.16      0.25      3337\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.56      0.54     11171\n",
      "weighted avg       0.69      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7187360128905201\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.33\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.9909217418105789\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7834, Test = 7790\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3534049791806058\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3337, Test = 3381\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.46\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -0.9909217418105789\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3448, Test = 3472\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.30\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.17420720467003667\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1382, Test = 1416\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.008601846947981\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4386, Test = 4318\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.43\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.32974302411509576\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1955, Test = 1965\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.81\n",
      "  Optimal thershold: -1.245555137476787\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3448\n",
      "Number of test samples (ntest): 3472\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1382\n",
      "Number of test samples (ntest): 1416\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4386\n",
      "Number of test samples (ntest): 4318\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1955\n",
      "Number of test samples (ntest): 1965\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7834\n",
      "         1.0       0.57      0.14      0.23      3337\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.55      0.52     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7115746128368096\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7834, Test = 7790\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3337, Test = 3381\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.24\n",
      "  Test Accuracy (TNR): 0.80\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -2.1383784091420277\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3448, Test = 3472\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.16\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1382, Test = 1416\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.32\n",
      "  Test Accuracy (TNR): 0.74\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -2.1383784091420277\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4386, Test = 4318\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1955, Test = 1965\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.10\n",
      "  Test Accuracy (TNR): 0.92\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.78378378 0.85      ]\n",
      " [1.         1.         0.63513514 0.65      ]\n",
      " [1.         1.         0.72972973 0.85      ]\n",
      " ...\n",
      " [1.         1.         0.94594595 0.875     ]\n",
      " [1.         0.         0.67567568 0.725     ]\n",
      " [1.         1.         1.         0.875     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6357.0 4814.0\n",
      "base_pos unpriv:  0.2860407145824678\n",
      "base_pos priv:  0.31052383199622463\n",
      "number of favorable labels:  3351\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.024483\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3437\n",
      "Number of test samples (ntest): 3483\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1377\n",
      "Number of test samples (ntest): 1421\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4383\n",
      "Number of test samples (ntest): 4321\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1974\n",
      "Number of test samples (ntest): 1946\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7820\n",
      "         1.0       0.65      0.14      0.23      3351\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.69      0.55      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7195416703965626\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.23\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.2367626271489267\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7820, Test = 7804\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3351, Test = 3367\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.270462545594769\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3437, Test = 3483\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.35020242943311486\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1377, Test = 1421\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.1370785694959058\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4383, Test = 4321\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.6061358035703156\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1974, Test = 1946\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.3217558399823195\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11341\n",
      "after transf priv:  0.31052383199622463\n",
      "after transf unpriv:  0.3103932584269663\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000131\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3437\n",
      "Number of test samples (ntest): 3483\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1377\n",
      "Number of test samples (ntest): 1421\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4383\n",
      "Number of test samples (ntest): 4321\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1974\n",
      "Number of test samples (ntest): 1946\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.82      7820\n",
      "         1.0       0.66      0.15      0.25      3521\n",
      "\n",
      "    accuracy                           0.71     11341\n",
      "   macro avg       0.69      0.56      0.53     11341\n",
      "weighted avg       0.70      0.71      0.64     11341\n",
      "\n",
      "Train accuracy:  0.7128119213473239\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.32\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.6466271649250525\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7820, Test = 7804\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.44183275227903934\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3351, Test = 3367\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.2729656758128873\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3437, Test = 3483\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.38505623647695725\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1377, Test = 1421\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -1.0986122886681098\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4383, Test = 4321\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.49875304253172154\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1974, Test = 1946\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.2729656758128873\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3437\n",
      "Number of test samples (ntest): 3483\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1377\n",
      "Number of test samples (ntest): 1421\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4383\n",
      "Number of test samples (ntest): 4321\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1974\n",
      "Number of test samples (ntest): 1946\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.83      7820\n",
      "         1.0       0.63      0.14      0.23      3351\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7177513203831349\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.31\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -1.2367626271489267\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7820, Test = 7804\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.5389965007326871\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3351, Test = 3367\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -1.2367626271489267\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3437, Test = 3483\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.5753641449035618\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1377, Test = 1421\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.3862943611198906\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4383, Test = 4321\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5389965007326871\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1974, Test = 1946\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -1.221214610760442\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3437\n",
      "Number of test samples (ntest): 3483\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1377\n",
      "Number of test samples (ntest): 1421\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4383\n",
      "Number of test samples (ntest): 4321\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1974\n",
      "Number of test samples (ntest): 1946\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7820\n",
      "         1.0       0.64      0.14      0.23      3351\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7182884253871632\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.0435478187188225\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7820, Test = 7804\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.49\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.30751354613822796\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3351, Test = 3367\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.0634855070538578\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3437, Test = 3483\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4189314998927539\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1377, Test = 1421\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.0595884484548586\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4383, Test = 4321\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5385949048492785\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1974, Test = 1946\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.4238402068938674\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3437\n",
      "Number of test samples (ntest): 3483\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1377\n",
      "Number of test samples (ntest): 1421\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4383\n",
      "Number of test samples (ntest): 4321\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1974\n",
      "Number of test samples (ntest): 1946\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7820\n",
      "         1.0       0.57      0.16      0.25      3351\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.55      0.53     11171\n",
      "weighted avg       0.68      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7121117178408379\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.02\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.01178425015858181\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7820, Test = 7804\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.01178425015858181\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3351, Test = 3367\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.19\n",
      "  Test Accuracy (TNR): 0.85\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -1.2259660299134414\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3437, Test = 3483\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.01178425015858181\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1377, Test = 1421\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.18\n",
      "  Test Accuracy (TNR): 0.86\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -1.2259660299134414\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4383, Test = 4321\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1974, Test = 1946\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.21\n",
      "  Test Accuracy (TNR): 0.84\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -4.446877710279016\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.89189189 0.9       ]\n",
      " [1.         0.         0.64864865 0.975     ]\n",
      " [1.         1.         0.71621622 0.825     ]\n",
      " ...\n",
      " [1.         0.         0.27027027 0.675     ]\n",
      " [1.         1.         0.89189189 0.55      ]\n",
      " [1.         1.         0.58108108 0.9       ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6339.0 4832.0\n",
      "base_pos unpriv:  0.28373344370860926\n",
      "base_pos priv:  0.3118788452437293\n",
      "number of favorable labels:  3348\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.028145\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3461\n",
      "Number of test samples (ntest): 3459\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1371\n",
      "Number of test samples (ntest): 1427\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4362\n",
      "Number of test samples (ntest): 4342\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1977\n",
      "Number of test samples (ntest): 1943\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7823\n",
      "         1.0       0.64      0.14      0.22      3348\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.718467460388506\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.9985288301111273\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7823, Test = 7801\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3610133455373305\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3348, Test = 3370\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -1.041453874828161\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3461, Test = 3459\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.43671765161226894\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1371, Test = 1427\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.35\n",
      "  Test Accuracy (TNR): 0.75\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.79\n",
      "  Optimal thershold: -0.8754687373538999\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4362, Test = 4342\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3610133455373305\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1977, Test = 1943\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.1637819237426907\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11368\n",
      "after transf priv:  0.3118788452437293\n",
      "after transf unpriv:  0.31179160866971567\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000087\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3461\n",
      "Number of test samples (ntest): 3459\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1371\n",
      "Number of test samples (ntest): 1427\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4362\n",
      "Number of test samples (ntest): 4342\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1977\n",
      "Number of test samples (ntest): 1943\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.97      0.82      7823\n",
      "         1.0       0.68      0.13      0.23      3545\n",
      "\n",
      "    accuracy                           0.71     11368\n",
      "   macro avg       0.70      0.55      0.52     11368\n",
      "weighted avg       0.70      0.71      0.64     11368\n",
      "\n",
      "Train accuracy:  0.710503166783955\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.0541605260972757\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7823, Test = 7801\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4424086232998486\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3348, Test = 3370\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.55\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.0541605260972757\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3461, Test = 3459\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.4424086232998486\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1371, Test = 1427\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -1.0498221244986778\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4362, Test = 4342\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.43\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.31015492830383945\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1977, Test = 1943\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.1297028757381407\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3461\n",
      "Number of test samples (ntest): 3459\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1371\n",
      "Number of test samples (ntest): 1427\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4362\n",
      "Number of test samples (ntest): 4342\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1977\n",
      "Number of test samples (ntest): 1943\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7823\n",
      "         1.0       0.65      0.14      0.23      3348\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.69      0.55      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7193626353952197\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.8754687373538999\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7823, Test = 7801\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4462871026284195\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3348, Test = 3370\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -1.213022639845854\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3461, Test = 3459\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.05\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.78845736036427\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1371, Test = 1427\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.4350845252893227\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4362, Test = 4342\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.46\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.3011379329671728\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1977, Test = 1943\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -1.2110902720948\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3461\n",
      "Number of test samples (ntest): 3459\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1371\n",
      "Number of test samples (ntest): 1427\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4362\n",
      "Number of test samples (ntest): 4342\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1977\n",
      "Number of test samples (ntest): 1943\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7823\n",
      "         1.0       0.63      0.14      0.23      3348\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.718019872885149\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.7654746616688541\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7823, Test = 7801\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3434471788845665\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3348, Test = 3370\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.50\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -1.0170596382637906\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3461, Test = 3459\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.4919591142705287\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1371, Test = 1427\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.43\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -0.9452751613353841\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4362, Test = 4342\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.55\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.35526743708212033\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1977, Test = 1943\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -1.2014228471046893\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3461\n",
      "Number of test samples (ntest): 3459\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1371\n",
      "Number of test samples (ntest): 1427\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4362\n",
      "Number of test samples (ntest): 4342\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1977\n",
      "Number of test samples (ntest): 1943\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7823\n",
      "         1.0       0.60      0.13      0.21      3348\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.66      0.55      0.52     11171\n",
      "weighted avg       0.69      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7133649628502372\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -2.2005122411852853\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7823, Test = 7801\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3348, Test = 3370\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.17\n",
      "  Test Accuracy (TNR): 0.88\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -2.2005122411852853\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3461, Test = 3459\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1371, Test = 1427\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.19\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -2.2005122411852853\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4362, Test = 4342\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1977, Test = 1943\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.17\n",
      "  Test Accuracy (TNR): 0.88\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -4.365357283328168\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.62162162 0.775     ]\n",
      " [1.         1.         0.86486486 0.875     ]\n",
      " [1.         0.         0.67567568 0.875     ]\n",
      " ...\n",
      " [0.         1.         0.83783784 0.725     ]\n",
      " [1.         1.         0.83783784 0.775     ]\n",
      " [1.         1.         0.51351351 0.65      ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6303.0 4868.0\n",
      "base_pos unpriv:  0.2953985209531635\n",
      "base_pos priv:  0.3109630334761225\n",
      "number of favorable labels:  3398\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.015565\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3430\n",
      "Number of test samples (ntest): 3490\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1438\n",
      "Number of test samples (ntest): 1360\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4343\n",
      "Number of test samples (ntest): 4361\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1960\n",
      "Number of test samples (ntest): 1960\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7773\n",
      "         1.0       0.61      0.17      0.27      3398\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.67      0.56      0.54     11171\n",
      "weighted avg       0.69      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7146182078596366\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.31\n",
      "  Test Accuracy (TNR): 0.72\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3101549283038396\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7773, Test = 7851\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.43\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3050135288034208\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3398, Test = 3320\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.0761394328160512\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3430, Test = 3490\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.4781817756896279\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1438, Test = 1360\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.0704414117014134\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4343, Test = 4361\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.41\n",
      "  Test Accuracy (TNR): 0.64\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.3050135288034208\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1960, Test = 1960\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.42\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -0.8690378470236094\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11280\n",
      "after transf priv:  0.3109630334761225\n",
      "after transf unpriv:  0.3108298171589311\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000133\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3430\n",
      "Number of test samples (ntest): 3490\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1438\n",
      "Number of test samples (ntest): 1360\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4343\n",
      "Number of test samples (ntest): 4361\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1960\n",
      "Number of test samples (ntest): 1960\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.97      0.82      7773\n",
      "         1.0       0.65      0.13      0.22      3507\n",
      "\n",
      "    accuracy                           0.71     11280\n",
      "   macro avg       0.68      0.55      0.52     11280\n",
      "weighted avg       0.69      0.71      0.63     11280\n",
      "\n",
      "Train accuracy:  0.7081560283687943\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.31\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.8690378470236094\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7773, Test = 7851\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4241572411203169\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3398, Test = 3320\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.40\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.8690378470236094\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3430, Test = 3490\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.34500713907105024\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1438, Test = 1360\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.43\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.8544153281560676\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4343, Test = 4361\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.4300363688386698\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1960, Test = 1960\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.2039728043259361\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3430\n",
      "Number of test samples (ntest): 3490\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1438\n",
      "Number of test samples (ntest): 1360\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4343\n",
      "Number of test samples (ntest): 4361\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1960\n",
      "Number of test samples (ntest): 1960\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7773\n",
      "         1.0       0.62      0.17      0.27      3398\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.56      0.54     11171\n",
      "weighted avg       0.69      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7151553128636648\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -1.041453874828161\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7773, Test = 7851\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.5899629443247145\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3398, Test = 3320\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.041453874828161\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3430, Test = 3490\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.5852582185487601\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1438, Test = 1360\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.43\n",
      "  Test Accuracy (TNR): 0.70\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -0.9139892348858759\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4343, Test = 4361\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5899629443247145\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1960, Test = 1960\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.3217558399823195\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3430\n",
      "Number of test samples (ntest): 3490\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1438\n",
      "Number of test samples (ntest): 1360\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4343\n",
      "Number of test samples (ntest): 4361\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1960\n",
      "Number of test samples (ntest): 1960\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.94      0.82      7773\n",
      "         1.0       0.60      0.19      0.29      3398\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.57      0.56     11171\n",
      "weighted avg       0.69      0.72      0.66     11171\n",
      "\n",
      "Train accuracy:  0.7156924178676931\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.32\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.8510798316030078\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7773, Test = 7851\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.45817906706253464\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3398, Test = 3320\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.0709157826532794\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3430, Test = 3490\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3572250467009524\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1438, Test = 1360\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.61\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.0709157826532794\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4343, Test = 4361\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.45817906706253464\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1960, Test = 1960\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.38\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.8915601910742753\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3430\n",
      "Number of test samples (ntest): 3490\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1438\n",
      "Number of test samples (ntest): 1360\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4343\n",
      "Number of test samples (ntest): 4361\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1960\n",
      "Number of test samples (ntest): 1960\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.94      0.82      7773\n",
      "         1.0       0.58      0.18      0.28      3398\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.56      0.55     11171\n",
      "weighted avg       0.68      0.71      0.66     11171\n",
      "\n",
      "Train accuracy:  0.7119326828394951\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7773, Test = 7851\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3398, Test = 3320\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.18\n",
      "  Test Accuracy (TNR): 0.86\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3430, Test = 3490\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1438, Test = 1360\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.18\n",
      "  Test Accuracy (TNR): 0.84\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4343, Test = 4361\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1960, Test = 1960\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.18\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         0.         0.75675676 0.825     ]\n",
      " [1.         1.         0.81081081 0.75      ]\n",
      " [1.         0.         0.45945946 0.725     ]\n",
      " ...\n",
      " [1.         1.         0.91891892 0.8       ]\n",
      " [1.         1.         0.72972973 0.85      ]\n",
      " [1.         0.         0.75675676 0.825     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6294.0 4877.0\n",
      "base_pos unpriv:  0.28808693869181873\n",
      "base_pos priv:  0.31188433428662216\n",
      "number of favorable labels:  3368\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.023797\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3472\n",
      "Number of test samples (ntest): 3448\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1405\n",
      "Number of test samples (ntest): 1393\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4331\n",
      "Number of test samples (ntest): 4373\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1963\n",
      "Number of test samples (ntest): 1957\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7803\n",
      "         1.0       0.68      0.13      0.21      3368\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.70      0.55      0.52     11171\n",
      "weighted avg       0.71      0.72      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7185569778891774\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7803, Test = 7821\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3368, Test = 3350\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.180625440328945\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3472, Test = 3448\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.48550781578170077\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1405, Test = 1393\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.2237754316221157\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4331, Test = 4373\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.46505720531041\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1963, Test = 1957\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.44\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.9100211188605596\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11339\n",
      "after transf priv:  0.31188433428662216\n",
      "after transf unpriv:  0.3117938553022795\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000090\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3472\n",
      "Number of test samples (ntest): 3448\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1405\n",
      "Number of test samples (ntest): 1393\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4331\n",
      "Number of test samples (ntest): 4373\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1963\n",
      "Number of test samples (ntest): 1957\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7803\n",
      "         1.0       0.64      0.19      0.29      3536\n",
      "\n",
      "    accuracy                           0.71     11339\n",
      "   macro avg       0.68      0.57      0.56     11339\n",
      "weighted avg       0.70      0.71      0.66     11339\n",
      "\n",
      "Train accuracy:  0.7136431784107946\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.32\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.6449450787420676\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7803, Test = 7821\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.324558469495364\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3368, Test = 3350\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.46\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.0138157520080326\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3472, Test = 3448\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.42\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.2876820724517809\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1405, Test = 1393\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.0761394328160512\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4331, Test = 4373\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.39956538598097613\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1963, Test = 1957\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.42\n",
      "  Test Accuracy (TNR): 0.64\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.9932517730102834\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3472\n",
      "Number of test samples (ntest): 3448\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1405\n",
      "Number of test samples (ntest): 1393\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4331\n",
      "Number of test samples (ntest): 4373\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1963\n",
      "Number of test samples (ntest): 1957\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83      7803\n",
      "         1.0       0.64      0.17      0.27      3368\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.69      0.56      0.55     11171\n",
      "weighted avg       0.70      0.72      0.66     11171\n",
      "\n",
      "Train accuracy:  0.7209739504073046\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -1.004202604197035\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7803, Test = 7821\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5911822539032572\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3368, Test = 3350\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -1.415281897993143\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3472, Test = 3448\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.416893803931787\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1405, Test = 1393\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.24\n",
      "  Test Accuracy (TNR): 0.85\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4331, Test = 4373\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.6539264674066639\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1963, Test = 1957\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -1.415281897993143\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3472\n",
      "Number of test samples (ntest): 3448\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1405\n",
      "Number of test samples (ntest): 1393\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4331\n",
      "Number of test samples (ntest): 4373\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1963\n",
      "Number of test samples (ntest): 1957\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7803\n",
      "         1.0       0.64      0.14      0.23      3368\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7173932503804494\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.5324789207047458\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7803, Test = 7821\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.39\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.28976197563152095\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3368, Test = 3350\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.1015563641491697\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3472, Test = 3448\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.41\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.28140281130291367\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1405, Test = 1393\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.0426757828455004\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4331, Test = 4373\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.5083083851841786\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1963, Test = 1957\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.27\n",
      "  Test Accuracy (TNR): 0.80\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.8367263322313733\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3472\n",
      "Number of test samples (ntest): 3448\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1405\n",
      "Number of test samples (ntest): 1393\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4331\n",
      "Number of test samples (ntest): 4373\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1963\n",
      "Number of test samples (ntest): 1957\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.95      0.82      7803\n",
      "         1.0       0.60      0.16      0.26      3368\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.66      0.56      0.54     11171\n",
      "weighted avg       0.69      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7143496553576224\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.22613146080768315\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7803, Test = 7821\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3368, Test = 3350\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.21\n",
      "  Test Accuracy (TNR): 0.84\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.9711560936566841\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3472, Test = 3448\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.22613146080768315\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1405, Test = 1393\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.22\n",
      "  Test Accuracy (TNR): 0.85\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -0.8699602472611774\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4331, Test = 4373\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1963, Test = 1957\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.23\n",
      "  Test Accuracy (TNR): 0.82\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -1.5975747581970028\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         0.         0.83783784 0.85      ]\n",
      " [1.         1.         0.94594595 0.925     ]\n",
      " [1.         1.         0.75675676 0.675     ]\n",
      " ...\n",
      " [1.         1.         0.7027027  0.825     ]\n",
      " [1.         0.         0.67567568 0.95      ]\n",
      " [0.         0.         0.51351351 0.875     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6342.0 4829.0\n",
      "base_pos unpriv:  0.2851522054255539\n",
      "base_pos priv:  0.31362346263008517\n",
      "number of favorable labels:  3366\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.028471\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3452\n",
      "Number of test samples (ntest): 3468\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1377\n",
      "Number of test samples (ntest): 1421\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4353\n",
      "Number of test samples (ntest): 4351\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1989\n",
      "Number of test samples (ntest): 1931\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.83      7805\n",
      "         1.0       0.62      0.14      0.22      3366\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.55      0.53     11171\n",
      "weighted avg       0.69      0.72      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7151553128636648\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.32\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.16\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.0937696641923216\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7805, Test = 7819\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.55\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.35020242943311486\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3366, Test = 3352\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.0986122886681098\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3452, Test = 3468\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3184537311185346\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1377, Test = 1421\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.379514674134512\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4353, Test = 4351\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4033122547470633\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1989, Test = 1931\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.110882381259924\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11371\n",
      "after transf priv:  0.31362346263008517\n",
      "after transf unpriv:  0.31358122887253925\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000042\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3452\n",
      "Number of test samples (ntest): 3468\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1377\n",
      "Number of test samples (ntest): 1421\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4353\n",
      "Number of test samples (ntest): 4351\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1989\n",
      "Number of test samples (ntest): 1931\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.97      0.82      7805\n",
      "         1.0       0.67      0.13      0.22      3566\n",
      "\n",
      "    accuracy                           0.71     11371\n",
      "   macro avg       0.69      0.55      0.52     11371\n",
      "weighted avg       0.70      0.71      0.63     11371\n",
      "\n",
      "Train accuracy:  0.7077653680415091\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.16\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.0704414117014134\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7805, Test = 7819\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4646127806108591\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3366, Test = 3352\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -1.0986122886681098\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3452, Test = 3468\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4595323293784402\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1377, Test = 1421\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -1.1786549963416462\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4353, Test = 4351\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.48835276791393206\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1989, Test = 1931\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.0986122886681098\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3452\n",
      "Number of test samples (ntest): 3468\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1377\n",
      "Number of test samples (ntest): 1421\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4353\n",
      "Number of test samples (ntest): 4351\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1989\n",
      "Number of test samples (ntest): 1931\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7805\n",
      "         1.0       0.63      0.13      0.21      3366\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.67      0.55      0.52     11171\n",
      "weighted avg       0.69      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7140811028556082\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.32\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -1.3581234841531944\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7805, Test = 7819\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.587786664902119\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3366, Test = 3352\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.3581234841531944\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3452, Test = 3468\n",
      "  AUC: 0.49\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5436154465889816\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1377, Test = 1421\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -1.128465251817791\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4353, Test = 4351\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.6373558209315298\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1989, Test = 1931\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.3581234841531944\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3452\n",
      "Number of test samples (ntest): 3468\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1377\n",
      "Number of test samples (ntest): 1421\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4353\n",
      "Number of test samples (ntest): 4351\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1989\n",
      "Number of test samples (ntest): 1931\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.83      7805\n",
      "         1.0       0.63      0.14      0.23      3366\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.55      0.53     11171\n",
      "weighted avg       0.69      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.71614000537105\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.33\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.1375186178413517\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7805, Test = 7819\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3403389466711788\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3366, Test = 3352\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -1.2058960888534116\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3452, Test = 3468\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.364962857350459\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1377, Test = 1421\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -1.1976713898172702\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4353, Test = 4351\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.323551682919995\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1989, Test = 1931\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.2474583810743511\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3452\n",
      "Number of test samples (ntest): 3468\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1377\n",
      "Number of test samples (ntest): 1421\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4353\n",
      "Number of test samples (ntest): 4351\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1989\n",
      "Number of test samples (ntest): 1931\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.82      7805\n",
      "         1.0       0.60      0.12      0.21      3366\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.66      0.54      0.51     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7115746128368096\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -2.8681476051736525\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7805, Test = 7819\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3366, Test = 3352\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.15\n",
      "  Test Accuracy (TNR): 0.89\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -2.8681476051736525\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3452, Test = 3468\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.50\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.04\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.06438968197241014\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1377, Test = 1421\n",
      "  AUC: 0.49\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.13\n",
      "  Test Accuracy (TNR): 0.90\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -2.8681476051736525\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4353, Test = 4351\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1989, Test = 1931\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.21\n",
      "  Test Accuracy (TNR): 0.85\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -5.192804829634776\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         0.         0.81081081 0.8       ]\n",
      " [1.         1.         0.51351351 0.725     ]\n",
      " [1.         0.         0.72972973 0.85      ]\n",
      " ...\n",
      " [1.         1.         0.2972973  0.75      ]\n",
      " [0.         0.         0.72972973 0.55      ]\n",
      " [1.         1.         0.75675676 0.9       ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6338.0 4833.0\n",
      "base_pos unpriv:  0.297951582867784\n",
      "base_pos priv:  0.3198169769643421\n",
      "number of favorable labels:  3467\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.021865\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3393\n",
      "Number of test samples (ntest): 3527\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1440\n",
      "Number of test samples (ntest): 1358\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4311\n",
      "Number of test samples (ntest): 4393\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2027\n",
      "Number of test samples (ntest): 1893\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.97      0.82      7704\n",
      "         1.0       0.66      0.14      0.23      3467\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.69      0.55      0.53     11171\n",
      "weighted avg       0.70      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7106794378300958\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.31\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.2280703559049964\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7704, Test = 7920\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.44895022004790314\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3467, Test = 3251\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.215022640512521\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3393, Test = 3527\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4700036292457356\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1440, Test = 1358\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.6945957207744071\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4311, Test = 4393\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.44895022004790314\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2027, Test = 1893\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.2019299026961359\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11326\n",
      "after transf priv:  0.3198169769643421\n",
      "after transf unpriv:  0.31976744186046513\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000050\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3393\n",
      "Number of test samples (ntest): 3527\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1440\n",
      "Number of test samples (ntest): 1358\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4311\n",
      "Number of test samples (ntest): 4393\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2027\n",
      "Number of test samples (ntest): 1893\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.97      0.82      7704\n",
      "         1.0       0.68      0.15      0.24      3622\n",
      "\n",
      "    accuracy                           0.71     11326\n",
      "   macro avg       0.69      0.56      0.53     11326\n",
      "weighted avg       0.70      0.71      0.63     11326\n",
      "\n",
      "Train accuracy:  0.7050150097121667\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.36000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.075596312967188\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7704, Test = 7920\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4171748437810725\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3467, Test = 3251\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.31\n",
      "  Test Accuracy (TNR): 0.76\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.8472978603872037\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3393, Test = 3527\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.33928320122686323\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1440, Test = 1358\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.27\n",
      "  Test Accuracy (TNR): 0.78\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -0.7958013346200287\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4311, Test = 4393\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4171748437810725\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2027, Test = 1893\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -1.1169614273363062\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3393\n",
      "Number of test samples (ntest): 3527\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1440\n",
      "Number of test samples (ntest): 1358\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4311\n",
      "Number of test samples (ntest): 4393\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2027\n",
      "Number of test samples (ntest): 1893\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.96      0.82      7704\n",
      "         1.0       0.64      0.15      0.24      3467\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.68      0.55      0.53     11171\n",
      "weighted avg       0.69      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7098737803240533\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.456758402495715\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7704, Test = 7920\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.456758402495715\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3467, Test = 3251\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.39\n",
      "  Test Accuracy (TNR): 0.68\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.9007865453381898\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3393, Test = 3527\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.45198512374305727\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1440, Test = 1358\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.40\n",
      "  Test Accuracy (TNR): 0.70\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -0.9007865453381898\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4311, Test = 4393\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.46224162391024626\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2027, Test = 1893\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -1.1274327272036018\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3393\n",
      "Number of test samples (ntest): 3527\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1440\n",
      "Number of test samples (ntest): 1358\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4311\n",
      "Number of test samples (ntest): 4393\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2027\n",
      "Number of test samples (ntest): 1893\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7704\n",
      "         1.0       0.62      0.16      0.26      3467\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.67      0.56      0.54     11171\n",
      "weighted avg       0.69      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7096947453227106\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.34\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.39\n",
      "  Test Accuracy (TNR): 0.64\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.35357477083048516\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7704, Test = 7920\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.35357477083048516\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3467, Test = 3251\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.2274418600341945\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3393, Test = 3527\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.4923912714031744\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1440, Test = 1358\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.0818670511487967\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4311, Test = 4393\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.35446004937753683\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2027, Test = 1893\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.2091600497726847\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3393\n",
      "Number of test samples (ntest): 3527\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1440\n",
      "Number of test samples (ntest): 1358\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4311\n",
      "Number of test samples (ntest): 4393\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2027\n",
      "Number of test samples (ntest): 1893\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.95      0.82      7704\n",
      "         1.0       0.60      0.15      0.25      3467\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.66      0.55      0.53     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7058454927938412\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.50\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.04778476567262651\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7704, Test = 7920\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.50\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3467, Test = 3251\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.15\n",
      "  Test Accuracy (TNR): 0.89\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -0.04778476567262651\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3393, Test = 3527\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1440, Test = 1358\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.16\n",
      "  Test Accuracy (TNR): 0.88\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.04778476567262651\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4311, Test = 4393\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2027, Test = 1893\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.19\n",
      "  Test Accuracy (TNR): 0.85\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -1.6198020903460866\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.89189189 0.675     ]\n",
      " [1.         1.         0.91891892 0.8       ]\n",
      " [1.         1.         0.48648649 0.875     ]\n",
      " ...\n",
      " [1.         0.         0.64864865 0.95      ]\n",
      " [1.         1.         0.72972973 0.775     ]\n",
      " [1.         1.         0.7027027  0.825     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6329.0 4842.0\n",
      "base_pos unpriv:  0.2899628252788104\n",
      "base_pos priv:  0.30952757149628696\n",
      "number of favorable labels:  3363\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.019565\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3438\n",
      "Number of test samples (ntest): 3482\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1404\n",
      "Number of test samples (ntest): 1394\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4370\n",
      "Number of test samples (ntest): 4334\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1959\n",
      "Number of test samples (ntest): 1961\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.98      0.83      7808\n",
      "         1.0       0.68      0.11      0.19      3363\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.70      0.55      0.51     11171\n",
      "weighted avg       0.71      0.72      0.64     11171\n",
      "\n",
      "Train accuracy:  0.717303732879778\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.2992829841302609\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7808, Test = 7816\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.50\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3363, Test = 3355\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.2992829841302609\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3438, Test = 3482\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3993860620317823\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1404, Test = 1394\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.2992829841302609\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4370, Test = 4334\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.45\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.33085424431698973\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1959, Test = 1961\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.79\n",
      "  Optimal thershold: -1.2992829841302609\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11308\n",
      "after transf priv:  0.30952757149628696\n",
      "after transf unpriv:  0.30949989957822854\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000028\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3438\n",
      "Number of test samples (ntest): 3482\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1404\n",
      "Number of test samples (ntest): 1394\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4370\n",
      "Number of test samples (ntest): 4334\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1959\n",
      "Number of test samples (ntest): 1961\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.98      0.82      7808\n",
      "         1.0       0.73      0.11      0.20      3500\n",
      "\n",
      "    accuracy                           0.71     11308\n",
      "   macro avg       0.72      0.55      0.51     11308\n",
      "weighted avg       0.72      0.71      0.63     11308\n",
      "\n",
      "Train accuracy:  0.7124159886805801\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.34\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.38\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7808, Test = 7816\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3363, Test = 3355\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.1451323043030026\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3438, Test = 3482\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1404, Test = 1394\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.35\n",
      "  Test Accuracy (TNR): 0.70\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.916290731874155\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4370, Test = 4334\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.48\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1959, Test = 1961\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.0236492501946544\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3438\n",
      "Number of test samples (ntest): 3482\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1404\n",
      "Number of test samples (ntest): 1394\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4370\n",
      "Number of test samples (ntest): 4334\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1959\n",
      "Number of test samples (ntest): 1961\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.98      0.83      7808\n",
      "         1.0       0.69      0.12      0.20      3363\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.70      0.55      0.51     11171\n",
      "weighted avg       0.71      0.72      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7179303553844777\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -1.0586069540544105\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7808, Test = 7816\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.5690945318899665\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3363, Test = 3355\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -1.0586069540544105\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3438, Test = 3482\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4818380868927383\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1404, Test = 1394\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.4024672203654915\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4370, Test = 4334\n",
      "  AUC: 0.49\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.5690945318899665\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1959, Test = 1961\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.48\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.9748590860252225\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3438\n",
      "Number of test samples (ntest): 3482\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1404\n",
      "Number of test samples (ntest): 1394\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4370\n",
      "Number of test samples (ntest): 4334\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1959\n",
      "Number of test samples (ntest): 1961\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.83      7808\n",
      "         1.0       0.64      0.15      0.24      3363\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.56      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7185569778891774\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.1189929354079886\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7808, Test = 7816\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.45\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3018025580044258\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3363, Test = 3355\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -1.1189929354079886\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3438, Test = 3482\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4235317280800121\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1404, Test = 1394\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.1189929354079886\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4370, Test = 4334\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.45\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.31975124634359564\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1959, Test = 1961\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.79\n",
      "  Optimal thershold: -1.1189929354079886\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3438\n",
      "Number of test samples (ntest): 3482\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1404\n",
      "Number of test samples (ntest): 1394\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4370\n",
      "Number of test samples (ntest): 4334\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1959\n",
      "Number of test samples (ntest): 1961\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7808\n",
      "         1.0       0.58      0.14      0.23      3363\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.55      0.52     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7108584728314385\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -1.5640377167269364\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7808, Test = 7816\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3363, Test = 3355\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.19\n",
      "  Test Accuracy (TNR): 0.85\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -1.5640377167269364\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3438, Test = 3482\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.06\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.2862570251929672\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1404, Test = 1394\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.15\n",
      "  Test Accuracy (TNR): 0.88\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.2862570251929672\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4370, Test = 4334\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.50\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1959, Test = 1961\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.19\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -1.5640377167269364\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.75675676 0.825     ]\n",
      " [1.         1.         0.83783784 0.875     ]\n",
      " [0.         0.         0.56756757 0.85      ]\n",
      " ...\n",
      " [1.         1.         0.83783784 0.8       ]\n",
      " [1.         0.         0.78378378 0.775     ]\n",
      " [1.         0.         0.86486486 0.925     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6309.0 4862.0\n",
      "base_pos unpriv:  0.28691896338955164\n",
      "base_pos priv:  0.3124108416547789\n",
      "number of favorable labels:  3366\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.025492\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3467\n",
      "Number of test samples (ntest): 3453\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1395\n",
      "Number of test samples (ntest): 1403\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4338\n",
      "Number of test samples (ntest): 4366\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1971\n",
      "Number of test samples (ntest): 1949\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.98      0.83      7805\n",
      "         1.0       0.70      0.10      0.17      3366\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.71      0.54      0.50     11171\n",
      "weighted avg       0.71      0.71      0.63     11171\n",
      "\n",
      "Train accuracy:  0.7148867603616507\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.2237754316221157\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7805, Test = 7819\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4289956055183584\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3366, Test = 3352\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.78\n",
      "  Optimal thershold: -1.2237754316221157\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3467, Test = 3453\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3193083102903267\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1395, Test = 1403\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.35\n",
      "  Test Accuracy (TNR): 0.72\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.80\n",
      "  Optimal thershold: -0.9007865453381898\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4338, Test = 4366\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5212969236332861\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1971, Test = 1949\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -1.2878542883066382\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11351\n",
      "after transf priv:  0.3124108416547789\n",
      "after transf unpriv:  0.31237604125347085\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000035\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3467\n",
      "Number of test samples (ntest): 3453\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1395\n",
      "Number of test samples (ntest): 1403\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4338\n",
      "Number of test samples (ntest): 4366\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1971\n",
      "Number of test samples (ntest): 1949\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.98      0.82      7805\n",
      "         1.0       0.71      0.12      0.21      3546\n",
      "\n",
      "    accuracy                           0.71     11351\n",
      "   macro avg       0.71      0.55      0.51     11351\n",
      "weighted avg       0.71      0.71      0.63     11351\n",
      "\n",
      "Train accuracy:  0.7098053034974892\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.0539121097502027\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7805, Test = 7819\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5997731097824868\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3366, Test = 3352\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -1.0539121097502027\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3467, Test = 3453\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.34830669426821587\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1395, Test = 1403\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.0464265354975395\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4338, Test = 4366\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.04\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1971, Test = 1949\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.80\n",
      "  Optimal thershold: -1.1700712526502546\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3467\n",
      "Number of test samples (ntest): 3453\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1395\n",
      "Number of test samples (ntest): 1403\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4338\n",
      "Number of test samples (ntest): 4366\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1971\n",
      "Number of test samples (ntest): 1949\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.98      0.83      7805\n",
      "         1.0       0.68      0.10      0.18      3366\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.70      0.54      0.50     11171\n",
      "weighted avg       0.71      0.72      0.63     11171\n",
      "\n",
      "Train accuracy:  0.7151553128636648\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -1.1451323043030026\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7805, Test = 7819\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3366, Test = 3352\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.1451323043030026\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3467, Test = 3453\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.31585294941847714\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1395, Test = 1403\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.3397743454849977\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4338, Test = 4366\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.44183275227903934\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1971, Test = 1949\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.1394342831883648\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3467\n",
      "Number of test samples (ntest): 3453\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1395\n",
      "Number of test samples (ntest): 1403\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4338\n",
      "Number of test samples (ntest): 4366\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1971\n",
      "Number of test samples (ntest): 1949\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.98      0.83      7805\n",
      "         1.0       0.67      0.11      0.19      3366\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.70      0.54      0.51     11171\n",
      "weighted avg       0.70      0.72      0.63     11171\n",
      "\n",
      "Train accuracy:  0.7153343478650076\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.1853161334770796\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7805, Test = 7819\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4024757882105691\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3366, Test = 3352\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.1853161334770796\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3467, Test = 3453\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.34308005652208545\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1395, Test = 1403\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.42\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -0.9216902565517646\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4338, Test = 4366\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5862514535784181\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1971, Test = 1949\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.1853161334770796\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3467\n",
      "Number of test samples (ntest): 3453\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1395\n",
      "Number of test samples (ntest): 1403\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4338\n",
      "Number of test samples (ntest): 4366\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1971\n",
      "Number of test samples (ntest): 1949\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7805\n",
      "         1.0       0.59      0.12      0.20      3366\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.66      0.54      0.51     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7102318503267389\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.42236791692822157\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7805, Test = 7819\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.50\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.04\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.005923675700969556\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3366, Test = 3352\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.12\n",
      "  Test Accuracy (TNR): 0.91\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.42236791692822157\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3467, Test = 3453\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.50\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.03\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.005923675700969556\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1395, Test = 1403\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.12\n",
      "  Test Accuracy (TNR): 0.92\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.42236791692822157\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4338, Test = 4366\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1971, Test = 1949\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.12\n",
      "  Test Accuracy (TNR): 0.91\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.005923675700969556\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         0.         0.86486486 0.75      ]\n",
      " [1.         1.         0.78378378 0.925     ]\n",
      " [1.         1.         0.62162162 0.875     ]\n",
      " ...\n",
      " [1.         1.         0.78378378 0.675     ]\n",
      " [1.         0.         0.78378378 0.875     ]\n",
      " [1.         0.         0.7027027  0.775     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6382.0 4789.0\n",
      "base_pos unpriv:  0.28962205053247025\n",
      "base_pos priv:  0.3155750548417424\n",
      "number of favorable labels:  3401\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.025953\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3402\n",
      "Number of test samples (ntest): 3518\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1387\n",
      "Number of test samples (ntest): 1411\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4368\n",
      "Number of test samples (ntest): 4336\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2014\n",
      "Number of test samples (ntest): 1906\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.82      7770\n",
      "         1.0       0.64      0.14      0.22      3401\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.68      0.55      0.52     11171\n",
      "weighted avg       0.70      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7139020678542655\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.0360919316867756\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7770, Test = 7854\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4895482253187058\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3401, Test = 3317\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.0360919316867756\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3402, Test = 3518\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.381367556529104\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1387, Test = 1411\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.0296194171811581\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4368, Test = 4336\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.48550781578170077\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2014, Test = 1906\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.2286654169163076\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11352\n",
      "after transf priv:  0.3155750548417424\n",
      "after transf unpriv:  0.3154929577464789\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000082\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3402\n",
      "Number of test samples (ntest): 3518\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1387\n",
      "Number of test samples (ntest): 1411\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4368\n",
      "Number of test samples (ntest): 4336\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2014\n",
      "Number of test samples (ntest): 1906\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.98      0.82      7770\n",
      "         1.0       0.71      0.12      0.20      3582\n",
      "\n",
      "    accuracy                           0.71     11352\n",
      "   macro avg       0.71      0.55      0.51     11352\n",
      "weighted avg       0.71      0.71      0.63     11352\n",
      "\n",
      "Train accuracy:  0.7069238900634249\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.32\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4927528427062962\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7770, Test = 7854\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.4927528427062962\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3401, Test = 3317\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.0360919316867756\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3402, Test = 3518\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.4927528427062962\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1387, Test = 1411\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.78\n",
      "  Optimal thershold: -1.0326543208763121\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4368, Test = 4336\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.30\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.2635845208727204\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2014, Test = 1906\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.2039728043259361\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3402\n",
      "Number of test samples (ntest): 3518\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1387\n",
      "Number of test samples (ntest): 1411\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4368\n",
      "Number of test samples (ntest): 4336\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2014\n",
      "Number of test samples (ntest): 1906\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7770\n",
      "         1.0       0.66      0.13      0.22      3401\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.69      0.55      0.52     11171\n",
      "weighted avg       0.70      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7147972428609793\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -1.189888064444197\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7770, Test = 7854\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3401, Test = 3317\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -1.189888064444197\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3402, Test = 3518\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1387, Test = 1411\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.1895840668738362\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4368, Test = 4336\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2014, Test = 1906\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.3614791920001665\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3402\n",
      "Number of test samples (ntest): 3518\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1387\n",
      "Number of test samples (ntest): 1411\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4368\n",
      "Number of test samples (ntest): 4336\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2014\n",
      "Number of test samples (ntest): 1906\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7770\n",
      "         1.0       0.66      0.12      0.20      3401\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.69      0.55      0.51     11171\n",
      "weighted avg       0.70      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7136335153522514\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4658197231727902\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7770, Test = 7854\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4658197231727902\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3401, Test = 3317\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.3197762230929517\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3402, Test = 3518\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.5248308620518986\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1387, Test = 1411\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -0.937036409672698\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4368, Test = 4336\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4658197231727902\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2014, Test = 1906\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.2875414446936007\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3402\n",
      "Number of test samples (ntest): 3518\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1387\n",
      "Number of test samples (ntest): 1411\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4368\n",
      "Number of test samples (ntest): 4336\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2014\n",
      "Number of test samples (ntest): 1906\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7770\n",
      "         1.0       0.60      0.13      0.21      3401\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.66      0.55      0.52     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.708620535314654\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.04\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.03126250336972327\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7770, Test = 7854\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.0076381649276455405\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3401, Test = 3317\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.13\n",
      "  Test Accuracy (TNR): 0.90\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.03126250336972327\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3402, Test = 3518\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.023442455613366674\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1387, Test = 1411\n",
      "  AUC: 0.49\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.13\n",
      "  Test Accuracy (TNR): 0.91\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -0.03126250336972327\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4368, Test = 4336\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2014, Test = 1906\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.17\n",
      "  Test Accuracy (TNR): 0.86\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -4.878414548937673\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.64864865 0.675     ]\n",
      " [1.         1.         1.         0.7       ]\n",
      " [1.         1.         0.64864865 0.925     ]\n",
      " ...\n",
      " [0.         0.         0.47297297 0.55      ]\n",
      " [1.         1.         0.48648649 0.825     ]\n",
      " [1.         0.         0.78378378 0.875     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6255.0 4916.0\n",
      "base_pos unpriv:  0.2996338486574451\n",
      "base_pos priv:  0.31590727418065545\n",
      "number of favorable labels:  3449\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.016273\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3443\n",
      "Number of test samples (ntest): 3477\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1473\n",
      "Number of test samples (ntest): 1325\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4279\n",
      "Number of test samples (ntest): 4425\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1976\n",
      "Number of test samples (ntest): 1944\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7722\n",
      "         1.0       0.61      0.17      0.27      3449\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.67      0.56      0.55     11171\n",
      "weighted avg       0.69      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7107689553307671\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.39\n",
      "  Test Accuracy (TNR): 0.64\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.35482137528940944\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7722, Test = 7902\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.35482137528940944\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3449, Test = 3269\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.49\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.9694005571881036\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3443, Test = 3477\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.35482137528940944\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1473, Test = 1325\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -0.9461436950238362\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4279, Test = 4425\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.4754236967150748\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1976, Test = 1944\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.1382214267631554\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11287\n",
      "after transf priv:  0.31590727418065545\n",
      "after transf unpriv:  0.3157790143084261\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000128\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3443\n",
      "Number of test samples (ntest): 3477\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1473\n",
      "Number of test samples (ntest): 1325\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4279\n",
      "Number of test samples (ntest): 4425\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1976\n",
      "Number of test samples (ntest): 1944\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7722\n",
      "         1.0       0.62      0.19      0.29      3565\n",
      "\n",
      "    accuracy                           0.71     11287\n",
      "   macro avg       0.67      0.57      0.55     11287\n",
      "weighted avg       0.69      0.71      0.65     11287\n",
      "\n",
      "Train accuracy:  0.7068308673695402\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.36000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.36\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3378718169756361\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7722, Test = 7902\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.61\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3886579897917832\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3449, Test = 3269\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.1451323043030026\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3443, Test = 3477\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4700036292457356\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1473, Test = 1325\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -1.1451323043030026\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4279, Test = 4425\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3378718169756361\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1976, Test = 1944\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.0986122886681098\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3443\n",
      "Number of test samples (ntest): 3477\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1473\n",
      "Number of test samples (ntest): 1325\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4279\n",
      "Number of test samples (ntest): 4425\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1976\n",
      "Number of test samples (ntest): 1944\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7722\n",
      "         1.0       0.62      0.16      0.25      3449\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.67      0.56      0.54     11171\n",
      "weighted avg       0.69      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.710500402828753\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.24000000000000002\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -1.087801372563894\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7722, Test = 7902\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.6346509738783369\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3449, Test = 3269\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -1.0986122886681098\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3443, Test = 3477\n",
      "  AUC: 0.47\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.6346509738783369\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1473, Test = 1325\n",
      "  AUC: 0.62\n",
      "  Privacy Risk: 0.60\n",
      "  Accuracy: 0.60\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.19\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.0826119473216687\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4279, Test = 4425\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.41\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.2803019651541584\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1976, Test = 1944\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -1.1741198411762548\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3443\n",
      "Number of test samples (ntest): 3477\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1473\n",
      "Number of test samples (ntest): 1325\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4279\n",
      "Number of test samples (ntest): 4425\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1976\n",
      "Number of test samples (ntest): 1944\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.94      0.82      7722\n",
      "         1.0       0.61      0.19      0.29      3449\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.67      0.57      0.56     11171\n",
      "weighted avg       0.69      0.71      0.66     11171\n",
      "\n",
      "Train accuracy:  0.7122907528421807\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.36000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.40\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3613337971772566\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7722, Test = 7902\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3613337971772566\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3449, Test = 3269\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.1617398897743414\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3443, Test = 3477\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5161265588303328\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1473, Test = 1325\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.42\n",
      "  Test Accuracy (TNR): 0.68\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -0.8833760576131579\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4279, Test = 4425\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3613337971772566\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1976, Test = 1944\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.1617398897743414\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3443\n",
      "Number of test samples (ntest): 3477\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1473\n",
      "Number of test samples (ntest): 1325\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4279\n",
      "Number of test samples (ntest): 4425\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1976\n",
      "Number of test samples (ntest): 1944\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7722\n",
      "         1.0       0.58      0.15      0.24      3449\n",
      "\n",
      "    accuracy                           0.70     11171\n",
      "   macro avg       0.65      0.55      0.53     11171\n",
      "weighted avg       0.67      0.70      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7042341777817563\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.50\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.3285080436262976\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7722, Test = 7902\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3449, Test = 3269\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.24\n",
      "  Test Accuracy (TNR): 0.81\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -2.281445671584899\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3443, Test = 3477\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1473, Test = 1325\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.20\n",
      "  Test Accuracy (TNR): 0.84\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -0.3285080436262976\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4279, Test = 4425\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1976, Test = 1944\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.24\n",
      "  Test Accuracy (TNR): 0.80\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -2.281445671584899\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.91891892 0.875     ]\n",
      " [0.         0.         0.64864865 0.675     ]\n",
      " [1.         1.         0.86486486 0.8       ]\n",
      " ...\n",
      " [0.         0.         0.30540541 0.6       ]\n",
      " [1.         1.         0.72972973 0.975     ]\n",
      " [1.         1.         0.59459459 0.75      ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6297.0 4874.0\n",
      "base_pos unpriv:  0.28498153467377924\n",
      "base_pos priv:  0.3020485945688423\n",
      "number of favorable labels:  3291\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.017067\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3485\n",
      "Number of test samples (ntest): 3435\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1389\n",
      "Number of test samples (ntest): 1409\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4395\n",
      "Number of test samples (ntest): 4309\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1902\n",
      "Number of test samples (ntest): 2018\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.98      0.83      7880\n",
      "         1.0       0.67      0.12      0.21      3291\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.70      0.55      0.52     11171\n",
      "weighted avg       0.71      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7240175454301316\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.26\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.894431938061656\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7880, Test = 7744\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.37001835911241676\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3291, Test = 3427\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.46\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -0.9932517730102834\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3485, Test = 3435\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.37001835911241676\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1389, Test = 1409\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -1.0226263816901877\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4395, Test = 4309\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.37001835911241676\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1902, Test = 2018\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.48\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.9932517730102834\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11290\n",
      "after transf priv:  0.3020485945688423\n",
      "after transf unpriv:  0.30202283196475066\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000026\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3485\n",
      "Number of test samples (ntest): 3435\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1389\n",
      "Number of test samples (ntest): 1409\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4395\n",
      "Number of test samples (ntest): 4309\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1902\n",
      "Number of test samples (ntest): 2018\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7880\n",
      "         1.0       0.66      0.15      0.24      3410\n",
      "\n",
      "    accuracy                           0.72     11290\n",
      "   macro avg       0.69      0.56      0.54     11290\n",
      "weighted avg       0.70      0.72      0.65     11290\n",
      "\n",
      "Train accuracy:  0.7194862710363154\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5465437063680699\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7880, Test = 7744\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3817110221000572\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3291, Test = 3427\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.0755165738734604\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3485, Test = 3435\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.46430560813109784\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1389, Test = 1409\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.1959653701022348\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4395, Test = 4309\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.37001835911241676\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1902, Test = 2018\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.074942544582205\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3485\n",
      "Number of test samples (ntest): 3435\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1389\n",
      "Number of test samples (ntest): 1409\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4395\n",
      "Number of test samples (ntest): 4309\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1902\n",
      "Number of test samples (ntest): 2018\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.98      0.83      7880\n",
      "         1.0       0.66      0.12      0.20      3291\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.69      0.55      0.51     11171\n",
      "weighted avg       0.71      0.72      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7221376779160326\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.26\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -1.2836402070598072\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7880, Test = 7744\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4732877044469254\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3291, Test = 3427\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -1.2836402070598072\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3485, Test = 3435\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.30010459245033816\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1389, Test = 1409\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.61\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -1.1474024528375417\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4395, Test = 4309\n",
      "  AUC: 0.49\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.48550781578170077\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1902, Test = 2018\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.3729072803374314\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3485\n",
      "Number of test samples (ntest): 3435\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1389\n",
      "Number of test samples (ntest): 1409\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4395\n",
      "Number of test samples (ntest): 4309\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1902\n",
      "Number of test samples (ntest): 2018\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.97      0.83      7880\n",
      "         1.0       0.65      0.12      0.20      3291\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.69      0.55      0.52     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.721779607913347\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.670046549062725\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7880, Test = 7744\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.33191832045664965\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3291, Test = 3427\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.48\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.9968582686965772\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3485, Test = 3435\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4587802713695894\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1389, Test = 1409\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.1972993069494795\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4395, Test = 4309\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.33191832045664965\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1902, Test = 2018\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.48\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.9968582686965772\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3485\n",
      "Number of test samples (ntest): 3435\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1389\n",
      "Number of test samples (ntest): 1409\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4395\n",
      "Number of test samples (ntest): 4309\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1902\n",
      "Number of test samples (ntest): 2018\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83      7880\n",
      "         1.0       0.59      0.14      0.23      3291\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.66      0.55      0.53     11171\n",
      "weighted avg       0.69      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7183779428878345\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7880, Test = 7744\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3291, Test = 3427\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.18\n",
      "  Test Accuracy (TNR): 0.86\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -2.1664224944672217\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3485, Test = 3435\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1389, Test = 1409\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.13\n",
      "  Test Accuracy (TNR): 0.91\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.12170087229486759\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4395, Test = 4309\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.06\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1902, Test = 2018\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.14\n",
      "  Test Accuracy (TNR): 0.90\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.12170087229486759\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         0.         0.64864865 0.85      ]\n",
      " [1.         1.         0.83783784 0.925     ]\n",
      " [1.         1.         0.7027027  0.8       ]\n",
      " ...\n",
      " [1.         1.         0.67567568 0.775     ]\n",
      " [1.         1.         0.59459459 0.525     ]\n",
      " [1.         0.         0.75675676 0.85      ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6312.0 4859.0\n",
      "base_pos unpriv:  0.27680592714550317\n",
      "base_pos priv:  0.31653992395437264\n",
      "number of favorable labels:  3343\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.039734\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3514\n",
      "Number of test samples (ntest): 3406\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1345\n",
      "Number of test samples (ntest): 1453\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4314\n",
      "Number of test samples (ntest): 4390\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1998\n",
      "Number of test samples (ntest): 1922\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7828\n",
      "         1.0       0.66      0.14      0.23      3343\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.69      0.55      0.53     11171\n",
      "weighted avg       0.71      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7207949154059619\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.34\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.39\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.32892503098583\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7828, Test = 7796\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.32892503098583\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3343, Test = 3375\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.1616252564968437\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3514, Test = 3406\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.32892503098583\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1345, Test = 1453\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.0270027562899866\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4314, Test = 4390\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.46081520319132935\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1998, Test = 1922\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.45\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.9734491457141037\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11453\n",
      "after transf priv:  0.31653992395437264\n",
      "after transf unpriv:  0.3164753938922389\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000065\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3514\n",
      "Number of test samples (ntest): 3406\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1345\n",
      "Number of test samples (ntest): 1453\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4314\n",
      "Number of test samples (ntest): 4390\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1998\n",
      "Number of test samples (ntest): 1922\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.97      0.82      7828\n",
      "         1.0       0.68      0.15      0.25      3625\n",
      "\n",
      "    accuracy                           0.71     11453\n",
      "   macro avg       0.70      0.56      0.53     11453\n",
      "weighted avg       0.70      0.71      0.64     11453\n",
      "\n",
      "Train accuracy:  0.7095957391076574\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5447271754416719\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7828, Test = 7796\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5007752879124893\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3343, Test = 3375\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.44\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -0.9843441951191707\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3514, Test = 3406\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.49899116611898775\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1345, Test = 1453\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.46\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -0.9843441951191707\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4314, Test = 4390\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.46430560813109784\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1998, Test = 1922\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.40\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -0.9315582040049435\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3514\n",
      "Number of test samples (ntest): 3406\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1345\n",
      "Number of test samples (ntest): 1453\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4314\n",
      "Number of test samples (ntest): 4390\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1998\n",
      "Number of test samples (ntest): 1922\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7828\n",
      "         1.0       0.64      0.14      0.23      3343\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7194521528958912\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.31\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.47849024312305416\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7828, Test = 7796\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.47849024312305416\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3343, Test = 3375\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.0799201556559572\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3514, Test = 3406\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.34905101882807316\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1345, Test = 1453\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.0799201556559572\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4314, Test = 4390\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1998, Test = 1922\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.916922612182061\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3514\n",
      "Number of test samples (ntest): 3406\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1345\n",
      "Number of test samples (ntest): 1453\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4314\n",
      "Number of test samples (ntest): 4390\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1998\n",
      "Number of test samples (ntest): 1922\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83      7828\n",
      "         1.0       0.64      0.15      0.24      3343\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.56      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7196311878972339\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.5256526996811496\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7828, Test = 7796\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4730661868927241\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3343, Test = 3375\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.1754898178004165\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3514, Test = 3406\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.39080924711922116\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1345, Test = 1453\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.0662807729214012\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4314, Test = 4390\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.5256526996811499\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1998, Test = 1922\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.2184835608397504\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3514\n",
      "Number of test samples (ntest): 3406\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1345\n",
      "Number of test samples (ntest): 1453\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4314\n",
      "Number of test samples (ntest): 4390\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1998\n",
      "Number of test samples (ntest): 1922\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7828\n",
      "         1.0       0.59      0.14      0.22      3343\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.66      0.55      0.52     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7133649628502372\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.3379937256229077\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7828, Test = 7796\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3343, Test = 3375\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.15\n",
      "  Test Accuracy (TNR): 0.90\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -1.2489693430899897\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3514, Test = 3406\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1345, Test = 1453\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.13\n",
      "  Test Accuracy (TNR): 0.93\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -0.3379937256229077\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4314, Test = 4390\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.24713382805110212\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1998, Test = 1922\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.19\n",
      "  Test Accuracy (TNR): 0.85\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -2.6906563664276497\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         0.         0.81081081 0.875     ]\n",
      " [1.         1.         0.81081081 0.7       ]\n",
      " [1.         1.         0.64864865 0.775     ]\n",
      " ...\n",
      " [0.         0.         0.59459459 0.7       ]\n",
      " [1.         1.         0.77027027 0.775     ]\n",
      " [1.         0.         0.74324324 0.9       ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6336.0 4835.0\n",
      "base_pos unpriv:  0.2843846949327818\n",
      "base_pos priv:  0.3162878787878788\n",
      "number of favorable labels:  3379\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.031903\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3460\n",
      "Number of test samples (ntest): 3460\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1375\n",
      "Number of test samples (ntest): 1423\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4332\n",
      "Number of test samples (ntest): 4372\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2004\n",
      "Number of test samples (ntest): 1916\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.95      0.83      7792\n",
      "         1.0       0.62      0.20      0.30      3379\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.57      0.56     11171\n",
      "weighted avg       0.70      0.72      0.67     11171\n",
      "\n",
      "Train accuracy:  0.7203473279026049\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.0802631499999131\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7792, Test = 7832\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3429447511268303\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3379, Test = 3339\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.1451323043030026\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3460, Test = 3460\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3429447511268303\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1375, Test = 1423\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -1.0986122886681098\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4332, Test = 4372\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.28\n",
      "  Test Accuracy (TNR): 0.77\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.23440070583884415\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2004, Test = 1916\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.3217558399823195\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11396\n",
      "after transf priv:  0.3162878787878788\n",
      "after transf unpriv:  0.31620553359683795\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000082\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3460\n",
      "Number of test samples (ntest): 3460\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1375\n",
      "Number of test samples (ntest): 1423\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4332\n",
      "Number of test samples (ntest): 4372\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2004\n",
      "Number of test samples (ntest): 1916\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7792\n",
      "         1.0       0.66      0.18      0.28      3604\n",
      "\n",
      "    accuracy                           0.71     11396\n",
      "   macro avg       0.69      0.57      0.55     11396\n",
      "weighted avg       0.70      0.71      0.65     11396\n",
      "\n",
      "Train accuracy:  0.7114777114777114\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.0187150038116695\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7792, Test = 7832\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.322773392263051\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3379, Test = 3339\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.55\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.0187150038116695\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3460, Test = 3460\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.5425743220805709\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1375, Test = 1423\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.48\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.9257694758286987\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4332, Test = 4372\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.37\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.30246586863601793\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2004, Test = 1916\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.61\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.0360919316867756\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3460\n",
      "Number of test samples (ntest): 3460\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1375\n",
      "Number of test samples (ntest): 1423\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4332\n",
      "Number of test samples (ntest): 4372\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2004\n",
      "Number of test samples (ntest): 1916\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7792\n",
      "         1.0       0.66      0.14      0.23      3379\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.69      0.56      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.718019872885149\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.35000000000000003\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4462871026284195\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7792, Test = 7832\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4462871026284195\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3379, Test = 3339\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.2685113254635072\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3460, Test = 3460\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4779201873235867\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1375, Test = 1423\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -1.2685113254635072\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4332, Test = 4372\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.49899116611898775\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2004, Test = 1916\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.3350010667323402\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3460\n",
      "Number of test samples (ntest): 3460\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1375\n",
      "Number of test samples (ntest): 1423\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4332\n",
      "Number of test samples (ntest): 4372\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2004\n",
      "Number of test samples (ntest): 1916\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.95      0.82      7792\n",
      "         1.0       0.62      0.18      0.27      3379\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.56      0.55     11171\n",
      "weighted avg       0.69      0.72      0.66     11171\n",
      "\n",
      "Train accuracy:  0.7176618028824635\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.16\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.142162144776226\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7792, Test = 7832\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.36543066479530334\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3379, Test = 3339\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.142162144776226\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3460, Test = 3460\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.35121838714000314\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1375, Test = 1423\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.115469799366157\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4332, Test = 4372\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.44\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.31842779795500237\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2004, Test = 1916\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.78\n",
      "  Optimal thershold: -1.1896502184775823\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3460\n",
      "Number of test samples (ntest): 3460\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1375\n",
      "Number of test samples (ntest): 1423\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4332\n",
      "Number of test samples (ntest): 4372\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2004\n",
      "Number of test samples (ntest): 1916\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7792\n",
      "         1.0       0.59      0.16      0.25      3379\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.66      0.56      0.54     11171\n",
      "weighted avg       0.68      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7122012353415093\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.04\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.03994631329463816\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7792, Test = 7832\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.03586328662850127\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3379, Test = 3339\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.22\n",
      "  Test Accuracy (TNR): 0.83\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -3.240125563716314\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3460, Test = 3460\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.06\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.03586328662850127\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1375, Test = 1423\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.17\n",
      "  Test Accuracy (TNR): 0.88\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.03994631329463816\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4332, Test = 4372\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2004, Test = 1916\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.25\n",
      "  Test Accuracy (TNR): 0.78\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -3.240125563716314\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         0.         0.72972973 0.725     ]\n",
      " [1.         0.         0.86486486 0.85      ]\n",
      " [1.         0.         0.78378378 0.8       ]\n",
      " ...\n",
      " [1.         0.         1.         0.8       ]\n",
      " [1.         0.         0.43243243 0.8       ]\n",
      " [1.         0.         0.72972973 0.975     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6355.0 4816.0\n",
      "base_pos unpriv:  0.2933970099667774\n",
      "base_pos priv:  0.3092053501180173\n",
      "number of favorable labels:  3378\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.015808\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3403\n",
      "Number of test samples (ntest): 3517\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1413\n",
      "Number of test samples (ntest): 1385\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4390\n",
      "Number of test samples (ntest): 4314\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1965\n",
      "Number of test samples (ntest): 1955\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.98      0.83      7793\n",
      "         1.0       0.68      0.11      0.18      3378\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.70      0.54      0.51     11171\n",
      "weighted avg       0.71      0.71      0.63     11171\n",
      "\n",
      "Train accuracy:  0.7147077253603079\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.31\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.38\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.34994846117778144\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7793, Test = 7831\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.34994846117778144\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3378, Test = 3340\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.43\n",
      "  Test Accuracy (TNR): 0.64\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -0.9679921062510455\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3403, Test = 3517\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.49\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1413, Test = 1385\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.49\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -1.0296194171811581\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4390, Test = 4314\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3856624808119848\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1965, Test = 1955\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.42\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.9679921062510455\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11281\n",
      "after transf priv:  0.3092053501180173\n",
      "after transf unpriv:  0.3091758018676411\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000030\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3403\n",
      "Number of test samples (ntest): 3517\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1413\n",
      "Number of test samples (ntest): 1385\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4390\n",
      "Number of test samples (ntest): 4314\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1965\n",
      "Number of test samples (ntest): 1955\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.97      0.82      7793\n",
      "         1.0       0.66      0.13      0.22      3488\n",
      "\n",
      "    accuracy                           0.71     11281\n",
      "   macro avg       0.69      0.55      0.52     11281\n",
      "weighted avg       0.70      0.71      0.64     11281\n",
      "\n",
      "Train accuracy:  0.7107525928552433\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.31\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.32\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3184537311185346\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7793, Test = 7831\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.43\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.31332450306511855\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3378, Test = 3340\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.3862943611198906\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3403, Test = 3517\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.42\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.2785495888885084\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1413, Test = 1385\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -1.0715836162801904\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4390, Test = 4314\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.38077249551779285\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1965, Test = 1955\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -1.3862943611198906\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3403\n",
      "Number of test samples (ntest): 3517\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1413\n",
      "Number of test samples (ntest): 1385\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4390\n",
      "Number of test samples (ntest): 4314\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1965\n",
      "Number of test samples (ntest): 1955\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.98      0.83      7793\n",
      "         1.0       0.67      0.11      0.19      3378\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.69      0.54      0.51     11171\n",
      "weighted avg       0.70      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7148867603616507\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.34\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -1.1700712526502546\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7793, Test = 7831\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.4274440148269396\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3378, Test = 3340\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.1700712526502546\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3403, Test = 3517\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4219944100593748\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1413, Test = 1385\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.276293465905562\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4390, Test = 4314\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5645298027378518\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1965, Test = 1955\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.129864832172214\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3403\n",
      "Number of test samples (ntest): 3517\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1413\n",
      "Number of test samples (ntest): 1385\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4390\n",
      "Number of test samples (ntest): 4314\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1965\n",
      "Number of test samples (ntest): 1955\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7793\n",
      "         1.0       0.64      0.12      0.21      3378\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.68      0.55      0.52     11171\n",
      "weighted avg       0.70      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7142601378569511\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.26\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.9880233276547754\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7793, Test = 7831\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.46783632507098316\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3378, Test = 3340\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.1532629129626977\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3403, Test = 3517\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.5036396514908315\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1413, Test = 1385\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.49\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -0.9844518976658431\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4390, Test = 4314\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.37550055974616015\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1965, Test = 1955\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.1255758867472538\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3403\n",
      "Number of test samples (ntest): 3517\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1413\n",
      "Number of test samples (ntest): 1385\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4390\n",
      "Number of test samples (ntest): 4314\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1965\n",
      "Number of test samples (ntest): 1955\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7793\n",
      "         1.0       0.58      0.15      0.24      3378\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.55      0.53     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7096947453227106\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7793, Test = 7831\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3378, Test = 3340\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.32\n",
      "  Test Accuracy (TNR): 0.74\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -3.2477594565624814\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3403, Test = 3517\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1413, Test = 1385\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.50\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -3.2477594565624814\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4390, Test = 4314\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1965, Test = 1955\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.19\n",
      "  Test Accuracy (TNR): 0.86\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -3.2477594565624814\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.67567568 0.825     ]\n",
      " [1.         1.         0.75675676 0.85      ]\n",
      " [1.         0.         0.7027027  0.825     ]\n",
      " ...\n",
      " [1.         1.         0.75675676 0.575     ]\n",
      " [1.         0.         0.97297297 0.9       ]\n",
      " [1.         0.         0.89189189 0.825     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6349.0 4822.0\n",
      "base_pos unpriv:  0.2841144753214434\n",
      "base_pos priv:  0.3145377224759805\n",
      "number of favorable labels:  3367\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.030423\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3452\n",
      "Number of test samples (ntest): 3468\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1370\n",
      "Number of test samples (ntest): 1428\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4352\n",
      "Number of test samples (ntest): 4352\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1997\n",
      "Number of test samples (ntest): 1923\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7804\n",
      "         1.0       0.66      0.12      0.20      3367\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.69      0.55      0.51     11171\n",
      "weighted avg       0.70      0.72      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7156029003670218\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4434925036974035\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7804, Test = 7820\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4434925036974035\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3367, Test = 3351\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.1895840668738362\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3452, Test = 3468\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4462871026284195\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1370, Test = 1428\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -1.212271607140631\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4352, Test = 4352\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.34\n",
      "  Test Accuracy (TNR): 0.69\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.2811673914305873\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1997, Test = 1923\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.0266387890430204\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11385\n",
      "after transf priv:  0.3145377224759805\n",
      "after transf unpriv:  0.3145353455123114\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000002\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3452\n",
      "Number of test samples (ntest): 3468\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1370\n",
      "Number of test samples (ntest): 1428\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4352\n",
      "Number of test samples (ntest): 4352\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1997\n",
      "Number of test samples (ntest): 1923\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.97      0.82      7804\n",
      "         1.0       0.68      0.14      0.23      3581\n",
      "\n",
      "    accuracy                           0.71     11385\n",
      "   macro avg       0.70      0.55      0.53     11385\n",
      "weighted avg       0.70      0.71      0.64     11385\n",
      "\n",
      "Train accuracy:  0.7090030742204655\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.40904292945604825\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7804, Test = 7820\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4015358299682749\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3367, Test = 3351\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.2809338454620642\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3452, Test = 3468\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4265185173059967\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1370, Test = 1428\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.2858899267938226\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4352, Test = 4352\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4015358299682749\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1997, Test = 1923\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.2809338454620642\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3452\n",
      "Number of test samples (ntest): 3468\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1370\n",
      "Number of test samples (ntest): 1428\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4352\n",
      "Number of test samples (ntest): 4352\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1997\n",
      "Number of test samples (ntest): 1923\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.83      7804\n",
      "         1.0       0.62      0.14      0.24      3367\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.55      0.53     11171\n",
      "weighted avg       0.69      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7156029003670218\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -1.1349799328389847\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7804, Test = 7820\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.4541302800894454\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3367, Test = 3351\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.1349799328389845\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3452, Test = 3468\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.37320424588994294\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1370, Test = 1428\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.35\n",
      "  Test Accuracy (TNR): 0.76\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -0.916290731874155\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4352, Test = 4352\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.48905182421643006\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1997, Test = 1923\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -1.1394342831883648\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3452\n",
      "Number of test samples (ntest): 3468\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1370\n",
      "Number of test samples (ntest): 1428\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4352\n",
      "Number of test samples (ntest): 4352\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1997\n",
      "Number of test samples (ntest): 1923\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7804\n",
      "         1.0       0.63      0.13      0.22      3367\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.52     11171\n",
      "weighted avg       0.69      0.72      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7150657953629934\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.8348809881274655\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7804, Test = 7820\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.4003045864029505\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3367, Test = 3351\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.1938199173411326\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3452, Test = 3468\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.4921507839770113\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1370, Test = 1428\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.3187483770583925\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4352, Test = 4352\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.36\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.2754085682475081\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1997, Test = 1923\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.1844642234879479\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3452\n",
      "Number of test samples (ntest): 3468\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1370\n",
      "Number of test samples (ntest): 1428\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4352\n",
      "Number of test samples (ntest): 4352\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1997\n",
      "Number of test samples (ntest): 1923\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7804\n",
      "         1.0       0.57      0.12      0.20      3367\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.64      0.54      0.51     11171\n",
      "weighted avg       0.67      0.71      0.63     11171\n",
      "\n",
      "Train accuracy:  0.7070092203025692\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7804, Test = 7820\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3367, Test = 3351\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.28\n",
      "  Test Accuracy (TNR): 0.75\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -3.8742879767067357\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3452, Test = 3468\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1370, Test = 1428\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -3.8742879767067357\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4352, Test = 4352\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.06\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1997, Test = 1923\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.14\n",
      "  Test Accuracy (TNR): 0.89\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -2.7514999101832776\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.7027027  0.65      ]\n",
      " [0.         0.         0.59459459 0.875     ]\n",
      " [0.         1.         0.2972973  0.7       ]\n",
      " ...\n",
      " [1.         1.         0.59459459 0.675     ]\n",
      " [1.         0.         0.89189189 0.925     ]\n",
      " [1.         1.         0.75675676 0.9       ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6355.0 4816.0\n",
      "base_pos unpriv:  0.2929817275747508\n",
      "base_pos priv:  0.3161290322580645\n",
      "number of favorable labels:  3420\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.023147\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3405\n",
      "Number of test samples (ntest): 3515\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1411\n",
      "Number of test samples (ntest): 1387\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4346\n",
      "Number of test samples (ntest): 4358\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2009\n",
      "Number of test samples (ntest): 1911\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7751\n",
      "         1.0       0.63      0.14      0.23      3420\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.67      0.55      0.53     11171\n",
      "weighted avg       0.69      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7113060603347955\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.33\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.2237754316221159\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7751, Test = 7873\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.41\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.30538164955118174\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3420, Test = 3298\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.2119409739751128\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3405, Test = 3515\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5198754592859087\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1411, Test = 1387\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.2488944917174476\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4346, Test = 4358\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.46\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.3507211823627332\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2009, Test = 1911\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.2119409739751128\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11334\n",
      "after transf priv:  0.3161290322580645\n",
      "after transf unpriv:  0.31612773649327175\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000001\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3405\n",
      "Number of test samples (ntest): 3515\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1411\n",
      "Number of test samples (ntest): 1387\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4346\n",
      "Number of test samples (ntest): 4358\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2009\n",
      "Number of test samples (ntest): 1911\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.96      0.82      7751\n",
      "         1.0       0.64      0.16      0.26      3583\n",
      "\n",
      "    accuracy                           0.71     11334\n",
      "   macro avg       0.67      0.56      0.54     11334\n",
      "weighted avg       0.69      0.71      0.64     11334\n",
      "\n",
      "Train accuracy:  0.7061937533086289\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.36000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.2387589204113514\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7751, Test = 7873\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3420, Test = 3298\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.1069110914828049\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3405, Test = 3515\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3787968610260031\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1411, Test = 1387\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.0986122886681098\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4346, Test = 4358\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4744579795951158\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2009, Test = 1911\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.2387589204113514\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3405\n",
      "Number of test samples (ntest): 3515\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1411\n",
      "Number of test samples (ntest): 1387\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4346\n",
      "Number of test samples (ntest): 4358\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2009\n",
      "Number of test samples (ntest): 1911\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7751\n",
      "         1.0       0.64      0.15      0.25      3420\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.68      0.56      0.53     11171\n",
      "weighted avg       0.69      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7139915853549369\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.34\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.42\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3901976359773759\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7751, Test = 7873\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3901976359773759\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3420, Test = 3298\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.36\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -0.9382696385929302\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3405, Test = 3515\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.419853845560264\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1411, Test = 1387\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.300849155163006\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4346, Test = 4358\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3901976359773759\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2009, Test = 1911\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.38\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -0.9382696385929302\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3405\n",
      "Number of test samples (ntest): 3515\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1411\n",
      "Number of test samples (ntest): 1387\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4346\n",
      "Number of test samples (ntest): 4358\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2009\n",
      "Number of test samples (ntest): 1911\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7751\n",
      "         1.0       0.62      0.15      0.24      3420\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.67      0.55      0.53     11171\n",
      "weighted avg       0.69      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7115746128368096\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.34\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.193096274290305\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7751, Test = 7873\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.34112024393853724\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3420, Test = 3298\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.228963473403943\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3405, Test = 3515\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5126638846201296\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1411, Test = 1387\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.193096274290305\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4346, Test = 4358\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.44\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.32338841054555656\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2009, Test = 1911\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.228963473403943\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3405\n",
      "Number of test samples (ntest): 3515\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1411\n",
      "Number of test samples (ntest): 1387\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4346\n",
      "Number of test samples (ntest): 4358\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 2009\n",
      "Number of test samples (ntest): 1911\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7751\n",
      "         1.0       0.56      0.15      0.24      3420\n",
      "\n",
      "    accuracy                           0.70     11171\n",
      "   macro avg       0.64      0.55      0.53     11171\n",
      "weighted avg       0.67      0.70      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7036075552770567\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.08\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.08115011772103621\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7751, Test = 7873\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.04941495376320814\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3420, Test = 3298\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.16\n",
      "  Test Accuracy (TNR): 0.88\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.08115011772103621\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3405, Test = 3515\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.06\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.08115011772103621\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1411, Test = 1387\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.16\n",
      "  Test Accuracy (TNR): 0.88\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.08115011772103621\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4346, Test = 4358\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 2009, Test = 1911\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.15\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.08115011772103621\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         0.         0.75675676 1.        ]\n",
      " [1.         0.         0.67567568 0.725     ]\n",
      " [1.         0.         0.72972973 0.85      ]\n",
      " ...\n",
      " [1.         1.         0.62162162 0.825     ]\n",
      " [1.         0.         0.54054054 0.925     ]\n",
      " [1.         0.         0.61351351 0.75      ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6319.0 4852.0\n",
      "base_pos unpriv:  0.2893652102225886\n",
      "base_pos priv:  0.3073271087197341\n",
      "number of favorable labels:  3346\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.017962\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3448\n",
      "Number of test samples (ntest): 3472\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1404\n",
      "Number of test samples (ntest): 1394\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4377\n",
      "Number of test samples (ntest): 4327\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1942\n",
      "Number of test samples (ntest): 1978\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7825\n",
      "         1.0       0.65      0.12      0.20      3346\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.69      0.55      0.51     11171\n",
      "weighted avg       0.70      0.72      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7167666278757497\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.42\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3610133455373305\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7825, Test = 7799\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3610133455373305\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3346, Test = 3372\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.2455944790167555\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3448, Test = 3472\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3610133455373305\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1404, Test = 1394\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -1.2237754316221157\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4377, Test = 4327\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.55\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.35914103643392586\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1942, Test = 1978\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.0427318302736532\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11296\n",
      "after transf priv:  0.3073271087197341\n",
      "after transf unpriv:  0.30721318063090214\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000114\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3448\n",
      "Number of test samples (ntest): 3472\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1404\n",
      "Number of test samples (ntest): 1394\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4377\n",
      "Number of test samples (ntest): 4327\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1942\n",
      "Number of test samples (ntest): 1978\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7825\n",
      "         1.0       0.64      0.17      0.27      3471\n",
      "\n",
      "    accuracy                           0.72     11296\n",
      "   macro avg       0.68      0.56      0.55     11296\n",
      "weighted avg       0.70      0.72      0.65     11296\n",
      "\n",
      "Train accuracy:  0.7151203966005666\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.31\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.2286654169163076\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7825, Test = 7799\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3346, Test = 3372\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.2286654169163076\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3448, Test = 3472\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.16\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5221893824163059\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1404, Test = 1394\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.2237754316221157\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4377, Test = 4327\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.32340015505386027\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1942, Test = 1978\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.2809338454620642\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3448\n",
      "Number of test samples (ntest): 3472\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1404\n",
      "Number of test samples (ntest): 1394\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4377\n",
      "Number of test samples (ntest): 4327\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1942\n",
      "Number of test samples (ntest): 1978\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7825\n",
      "         1.0       0.65      0.12      0.20      3346\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.69      0.55      0.51     11171\n",
      "weighted avg       0.70      0.72      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7168561453764211\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.26\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.6286086594223742\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7825, Test = 7799\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.5705448584676128\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3346, Test = 3372\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.1986957472250923\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3448, Test = 3472\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3610133455373305\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1404, Test = 1394\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.1939224684724346\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4377, Test = 4327\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.6351038109100302\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1942, Test = 1978\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.2237754316221157\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3448\n",
      "Number of test samples (ntest): 3472\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1404\n",
      "Number of test samples (ntest): 1394\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4377\n",
      "Number of test samples (ntest): 4327\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1942\n",
      "Number of test samples (ntest): 1978\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.83      7825\n",
      "         1.0       0.63      0.14      0.23      3346\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7176618028824635\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.41\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3602529451183338\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7825, Test = 7799\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3602529451183338\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3346, Test = 3372\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.1148068092594543\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3448, Test = 3472\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3506925876739768\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1404, Test = 1394\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -1.1947553794297783\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4377, Test = 4327\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3602529451183338\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1942, Test = 1978\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.1148068092594543\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3448\n",
      "Number of test samples (ntest): 3472\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1404\n",
      "Number of test samples (ntest): 1394\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4377\n",
      "Number of test samples (ntest): 4327\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1942\n",
      "Number of test samples (ntest): 1978\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7825\n",
      "         1.0       0.56      0.15      0.24      3346\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.64      0.55      0.53     11171\n",
      "weighted avg       0.68      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7107689553307671\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.09046816548258572\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7825, Test = 7799\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3346, Test = 3372\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.23\n",
      "  Test Accuracy (TNR): 0.79\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -2.447650338406281\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3448, Test = 3472\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.09046816548258547\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1404, Test = 1394\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.10\n",
      "  Test Accuracy (TNR): 0.91\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.09046816548258572\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4377, Test = 4327\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1942, Test = 1978\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.24\n",
      "  Test Accuracy (TNR): 0.81\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -2.447650338406281\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         0.         0.81081081 0.975     ]\n",
      " [0.         0.         0.67567568 0.725     ]\n",
      " [1.         1.         0.78378378 0.775     ]\n",
      " ...\n",
      " [1.         1.         0.78378378 0.875     ]\n",
      " [1.         0.         0.81081081 0.825     ]\n",
      " [1.         1.         1.         0.875     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['gender']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'gender': 1}] [{'gender': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  6289.0 4882.0\n",
      "base_pos unpriv:  0.28390004096681687\n",
      "base_pos priv:  0.3043409127047225\n",
      "number of favorable labels:  3300\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.020441\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 3496\n",
      "Number of test samples (ntest): 3424\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1386\n",
      "Number of test samples (ntest): 1412\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4375\n",
      "Number of test samples (ntest): 4329\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1914\n",
      "Number of test samples (ntest): 2006\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83      7871\n",
      "         1.0       0.63      0.15      0.24      3300\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.56      0.53     11171\n",
      "weighted avg       0.70      0.72      0.66     11171\n",
      "\n",
      "Train accuracy:  0.7223167129173753\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.26\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4418327522790392\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7871, Test = 7753\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4144337780909248\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3300, Test = 3418\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.0360919316867756\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3496, Test = 3424\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.4144337780909248\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1386, Test = 1412\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.51787071890861\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4375, Test = 4329\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4382549309311553\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1914, Test = 2006\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.0360919316867756\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11314\n",
      "after transf priv:  0.3043409127047225\n",
      "after transf unpriv:  0.3042786069651741\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000062\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3496\n",
      "Number of test samples (ntest): 3424\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1386\n",
      "Number of test samples (ntest): 1412\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4375\n",
      "Number of test samples (ntest): 4329\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1914\n",
      "Number of test samples (ntest): 2006\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.98      0.83      7871\n",
      "         1.0       0.71      0.14      0.23      3443\n",
      "\n",
      "    accuracy                           0.72     11314\n",
      "   macro avg       0.71      0.56      0.53     11314\n",
      "weighted avg       0.72      0.72      0.65     11314\n",
      "\n",
      "Train accuracy:  0.7202580873254375\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.26\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.50\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.419853845560264\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7871, Test = 7753\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.419853845560264\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3300, Test = 3418\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.2443240998495033\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3496, Test = 3424\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.35667494393873245\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1386, Test = 1412\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.2443240998495033\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4375, Test = 4329\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4382549309311553\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1914, Test = 2006\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.0360919316867756\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3496\n",
      "Number of test samples (ntest): 3424\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1386\n",
      "Number of test samples (ntest): 1412\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4375\n",
      "Number of test samples (ntest): 4329\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1914\n",
      "Number of test samples (ntest): 2006\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.97      0.83      7871\n",
      "         1.0       0.64      0.13      0.22      3300\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7221376779160326\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7871, Test = 7753\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3300, Test = 3418\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.5664205273504095\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3496, Test = 3424\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.7221347174331975\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1386, Test = 1412\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.30421153033141\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4375, Test = 4329\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3522205935893521\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1914, Test = 2006\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -1.4395388756387029\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3496\n",
      "Number of test samples (ntest): 3424\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1386\n",
      "Number of test samples (ntest): 1412\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4375\n",
      "Number of test samples (ntest): 4329\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1914\n",
      "Number of test samples (ntest): 2006\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.97      0.83      7871\n",
      "         1.0       0.65      0.13      0.22      3300\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.69      0.55      0.52     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7223167129173753\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.4542582624714643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7871, Test = 7753\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.4542582624714643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3300, Test = 3418\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.30\n",
      "  Test Accuracy (TNR): 0.77\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -0.9256340558399131\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3496, Test = 3424\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.3257634986432895\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1386, Test = 1412\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.1596260147604809\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4375, Test = 4329\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.4542582624714643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1914, Test = 2006\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.40\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.86\n",
      "  Optimal thershold: -0.959186538956762\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 3496\n",
      "Number of test samples (ntest): 3424\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 1386\n",
      "Number of test samples (ntest): 1412\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 4375\n",
      "Number of test samples (ntest): 4329\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 1914\n",
      "Number of test samples (ntest): 2006\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.95      0.83      7871\n",
      "         1.0       0.58      0.15      0.24      3300\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.66      0.55      0.54     11171\n",
      "weighted avg       0.69      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7173932503804494\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.01\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.17198211192757226\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7871, Test = 7753\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3300, Test = 3418\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.22\n",
      "  Test Accuracy (TNR): 0.82\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -1.8451237573021702\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 3496, Test = 3424\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.05\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.7763142520163653\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 1386, Test = 1412\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.15\n",
      "  Test Accuracy (TNR): 0.88\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.35966932622490183\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 4375, Test = 4329\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 1914, Test = 2006\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.21\n",
      "  Test Accuracy (TNR): 0.84\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -1.8451237573021702\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# favorable and unfavorable labels and feature_names\n",
    "f_label = dataset_orig.favorable_label\n",
    "uf_label = dataset_orig.unfavorable_label\n",
    "feature_names = dataset_orig.feature_names\n",
    "\n",
    "# run mitigating algorithms\n",
    "for i in range(N):\n",
    "    if ATTACK == \"mia1\":\n",
    "        # split dataset into train, validation, and test\n",
    "        dataset_orig_train, dataset_orig_test = dataset_orig.split([p], shuffle=True)\n",
    "        dataset_orig_val = dataset_orig_test\n",
    "\n",
    "        print(\"#### Train dataset's features are as below:\")\n",
    "        print(dataset_orig_train.features)\n",
    "    elif ATTACK == \"mia2\":\n",
    "        train_index, test_index, population_index = get_unique_indices_reference()\n",
    "        \n",
    "        g_train = y_true[train_index] + (sensitive_features[train_index] + 1) * 2 # 2, 4, 3, 5\n",
    "        g_test = y_true[test_index] + (sensitive_features[test_index] + 1) * 2\n",
    "        g_pop_train = y_true[population_index] + (sensitive_features[population_index] + 1) * 2\n",
    "        \n",
    "        # for Audit\n",
    "        target_dataset, reference_dataset = create_datasets(train_index, test_index, population_index, g_train, g_test, g_pop_train)\n",
    "        \n",
    "        # for mitigators\n",
    "        privileged_value = [1]\n",
    "        unprivileged_value = [0]\n",
    "        # Convert train dataset\n",
    "        dataset_orig_train = create_binary_label_dataset(\n",
    "            dataset_orig=dataset_orig,\n",
    "            X=X[train_index],\n",
    "            y=y_true[train_index],\n",
    "            sensitive_features=sensitive_features[train_index],\n",
    "            sens_attr_name=sens_attr,\n",
    "            privileged_value=privileged_value,\n",
    "            unprivileged_value=unprivileged_value\n",
    "        )\n",
    "        \n",
    "        # Convert test dataset\n",
    "        dataset_orig_val = create_binary_label_dataset(\n",
    "            dataset_orig=dataset_orig,\n",
    "            X=X[test_index],\n",
    "            y=y_true[test_index],\n",
    "            sensitive_features=sensitive_features[test_index],\n",
    "            sens_attr_name=sens_attr,\n",
    "            privileged_value=privileged_value,\n",
    "            unprivileged_value=unprivileged_value\n",
    "        )\n",
    "        \n",
    "        # Since validation and testing datasets are the same\n",
    "        dataset_orig_test = dataset_orig_val\n",
    "        \n",
    "        # orig_metrics, orig_mia_metrics, priv_metric_orig, favor_metric_orig = run_MIA2(dataset_orig, target_dataset, reference_dataset, privileged_groups, unprivileged_groups, BASELINE, orig_metrics, orig_mia_metrics, f_label, uf_label, THRESH_ARR, DISPLAY, SCALER)\n",
    "        \n",
    "    # favorable and unfavorable labels and feature_names\n",
    "    f_label = dataset_orig.favorable_label\n",
    "    uf_label = dataset_orig.unfavorable_label\n",
    "    feature_names = dataset_orig.feature_names\n",
    "\n",
    "    # introduce label or selection biases, assuming the original data is fair\n",
    "    if BIAS_TYPE == 'label':\n",
    "        dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    elif BIAS_TYPE == 'selection':\n",
    "        dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    else:\n",
    "        print('no bias type specified')\n",
    "\n",
    "    # show data info\n",
    "    print(\"#### Training Dataset shape\")\n",
    "    print(dataset_orig_train.features.shape)\n",
    "    print(\"#### Favorable and unfavorable labels\")\n",
    "    print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "    print(\"#### Protected attribute names\")\n",
    "    print(dataset_orig_train.protected_attribute_names)\n",
    "    print(\"#### Privileged and unprivileged protected groups\")\n",
    "    print(privileged_groups, unprivileged_groups)\n",
    "    print(\"#### Privileged and unprivileged protected attribute values\")\n",
    "    print(dataset_orig_train.privileged_protected_attributes, dataset_orig_train.unprivileged_protected_attributes)\n",
    "    print(\"#### Dataset feature names\")\n",
    "    print(dataset_orig_train.feature_names)\n",
    "\n",
    "    # check fairness on the original data\n",
    "    metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    print(\"privileged vs. unprivileged: \", metric_orig_train.num_positives(privileged=True) + metric_orig_train.num_negatives(privileged=True), metric_orig_train.num_positives(privileged=False) + metric_orig_train.num_negatives(privileged=False)) \n",
    "    base_rate_unprivileged = metric_orig_train.base_rate(privileged=False)\n",
    "    base_rate_privileged = metric_orig_train.base_rate(privileged=True)\n",
    "    print('base_pos unpriv: ', base_rate_unprivileged)\n",
    "    print('base_pos priv: ', base_rate_privileged)\n",
    "    print('number of favorable labels: ', np.count_nonzero(dataset_orig_train.labels==f_label))\n",
    "    print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "    # statistics of favored/positive class BEFORE transf \n",
    "    priv_metric_orig['total_priv'] += metric_orig_train.num_instances(privileged = True) \n",
    "    priv_metric_orig['total_unpriv'] += metric_orig_train.num_instances(privileged = False) \n",
    "    favor_metric_orig['total_favor'] += metric_orig_train.base_rate()\n",
    "    favor_metric_orig['total_unfavor'] += 1 - metric_orig_train.base_rate()\n",
    "    favor_metric_orig['priv_favor'] += metric_orig_train.base_rate(privileged = True)\n",
    "    favor_metric_orig['priv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = True)\n",
    "    favor_metric_orig['unpriv_favor'] += metric_orig_train.base_rate(privileged = False)\n",
    "    favor_metric_orig['unpriv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = False)\n",
    "\n",
    "    print(\"#### Train shape, validation shape, test shape\")\n",
    "    print(dataset_orig_train.features.shape, dataset_orig_val.features.shape, dataset_orig_test.features.shape)\n",
    "\n",
    "    # testing mitigation methods \n",
    "    test_cases = TestAlgorithms(BASELINE)\n",
    "\n",
    "    # null mitigator\n",
    "    orig_metrics, orig_mia_metrics = test_cases.run_original(dataset_orig_train, dataset_orig_val, dataset_orig_test, BASELINE, orig_metrics, orig_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset) \n",
    "\n",
    "    # synthetic data mitigator\n",
    "    metric_transf_train, transf_metrics, transf_mia_metrics = test_cases.run_oversample(dataset_orig_train, dataset_orig_val, dataset_orig_test, privileged_groups, unprivileged_groups, base_rate_privileged, base_rate_unprivileged, BASELINE, transf_metrics, transf_mia_metrics, f_label, uf_label, ATTACK, THRESH_ARR, DISPLAY, OS_MODE, SCALER, target_dataset, reference_dataset)\n",
    "    \n",
    "    # statistics of favored/positive class AFTER transf\n",
    "    favor_metric_transf['total_favor'] += metric_transf_train.base_rate()\n",
    "    favor_metric_transf['total_unfavor'] += 1 - metric_transf_train.base_rate()\n",
    "    favor_metric_transf['priv_favor'] += metric_transf_train.base_rate(privileged = True)\n",
    "    favor_metric_transf['priv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = True)\n",
    "    favor_metric_transf['unpriv_favor'] += metric_transf_train.base_rate(privileged = False)\n",
    "    favor_metric_transf['unpriv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = False)\n",
    "\n",
    "    # dir mitigator\n",
    "    dir_metrics, dir_mia_metrics = test_cases.run_dir(dataset_orig_train, dataset_orig_val, dataset_orig_test,  sens_attr, BASELINE, dir_metrics, dir_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset) \n",
    "    \n",
    "    # reweigh mitigator\n",
    "    reweigh_metrics, reweigh_mia_metrics = test_cases.run_rew(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, reweigh_metrics, reweigh_mia_metrics, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "    # eg mitigator, in-processing\n",
    "    eg_metrics, eg_mia_metrics = test_cases.run_eg(dataset_orig_train, dataset_orig_val, dataset_orig_test, eg_metrics, eg_mia_metrics, BASELINE, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "#     # egr gave error so I replaced it with reweigh\n",
    "# #     eg_metrics, eg_mia_metrics = test_cases.run_rew(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, eg_metrics, eg_mia_metrics, THRESH_ARR, DISPLAY, SCALER)\n",
    "\n",
    "#     # cpp mitigator\n",
    "#     cpp_metrics = test_cases.run_cpp(dataset_orig_train, dataset_orig_val, dataset_orig_test, cpp_metrics, BASELINE, unprivileged_groups, privileged_groups, THRESH_ARR, SCALER)\n",
    "\n",
    "#     # ro mitigator\n",
    "#     # ro_metrics = test_cases.run_ro(dataset_orig_train, dataset_orig_val, dataset_orig_test, ro_metrics, BASELINE, unprivileged_groups, privileged_groups, THRESH_ARR, SCALER)\n",
    "\n",
    "#     if (BASELINE == 'lr'):\n",
    "#         pr_orig_metrics = test_cases.run_pr(dataset_orig_train, dataset_orig_val, dataset_orig_test, pr_orig_metrics, sens_attr, f_label, uf_label, unprivileged_groups, privileged_groups, THRESH_ARR, DISPLAY, SCALER) \n",
    "\n",
    "    delete_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e9f7847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_bank, _ = dataset_orig.convert_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2811a790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "1.0    12624\n",
       "0.0     9718\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bee0ec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Temp\\ipykernel_17452\\4087984120.py:11: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of privileged and unprivileged values\n",
    "gender_counts = df_bank['gender'].value_counts()\n",
    "\n",
    "# Plot the bar graph\n",
    "plt.figure(figsize=(6, 4))\n",
    "gender_counts.plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('Count of Privileged and Unprivileged Values in Gender')\n",
    "plt.xlabel('Gender Category (1=Privileged, 0=Unprivileged)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f013a728",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'y'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_counts \u001b[38;5;241m=\u001b[39m \u001b[43mdf_bank\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'y'"
     ]
    }
   ],
   "source": [
    "y_counts = df_bank['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3752774e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'y'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Count the occurrences of privileged and unprivileged values\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m label_counts \u001b[38;5;241m=\u001b[39m \u001b[43mdf_bank\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Plot the bar graph\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'y'"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of privileged and unprivileged values\n",
    "label_counts = df_bank['y'].value_counts()\n",
    "\n",
    "# Plot the bar graph\n",
    "plt.figure(figsize=(6, 4))\n",
    "age_counts.plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('Count of Favorable and Unfavorable Values in Dataset')\n",
    "plt.xlabel('Label Category (1=Favorable, 0=Unfavorable)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "900da4ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20798, 14)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90de2a9",
   "metadata": {},
   "source": [
    "## Display Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "72632350",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig_copy = priv_metric_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8530a47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float, {'total_priv': 126510.0, 'total_unpriv': 96910.0})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priv_metric_orig_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8b736dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float, {'total_priv': 126510.0, 'total_unpriv': 96910.0})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priv_metric_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c736a792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('total_priv', 126510.0), ('total_unpriv', 96910.0)])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priv_metric_orig.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c73a4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig = priv_metric_orig_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0ea4ee29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('bal_acc', [0.582757750470755, 0.5780368205774244, 0.5803396078895823, 0.588386979223922, 0.5902308891661411, 0.5867864551427748, 0.5814873719576052, 0.5829079397481427, 0.5880173193586621, 0.5870657379170315, 0.5862992797634305, 0.5822619146335204, 0.5881463883971958, 0.5778433574672672, 0.5752644406449792, 0.5862169161867811, 0.5896856189052243, 0.5851410509639188, 0.5898489434345158, 0.5892908100203496]), ('avg_odds_diff', [-0.05851334802094682, -0.10336953379572023, -0.05026744900418961, -0.04958553670821014, -0.07555875510115187, -0.03074352845912054, -0.01273648057742105, 0.014149874481387437, 0.06327532010349057, -0.02825305819600657, -0.13630515307657895, -0.006063094314015138, -0.0049712173426487705, -0.09197737683175938, -0.06759341207524855, -0.08075463029531907, -0.07757133169811464, -0.08174074636505871, -0.03403742907988405, -0.04760489966427228]), ('disp_imp', [0.11202545195915492, 0.22364637089800832, 0.09220108456139997, 0.11178788962550146, 0.16319689879584753, 0.08164197461048472, 0.05628385498642419, 0.007328556806550646, 0.10088915459014924, 0.08258663497265117, 0.23869527179594185, 0.03233717730972108, 0.029152164997589103, 0.2019416593830956, 0.12751555789276758, 0.185020944677163, 0.141666776183217, 0.1814470870981877, 0.08027454412683821, 0.09890354326122153]), ('stat_par_diff', [-0.06845704182270451, -0.11621922664045792, -0.06644009859251354, -0.06591661399397108, -0.08850482029301776, -0.04532225889119168, -0.02722805401205719, -0.0035908296156818564, 0.04852031737364643, -0.04337923487003703, -0.15101051398945442, -0.02157335003752625, -0.019222827938982445, -0.08785357995341897, -0.07339039504038258, -0.09503388767912985, -0.0842098924563186, -0.09392180533316624, -0.0537030970859641, -0.06207426803577221]), ('eq_opp_diff', [-0.04606452813187978, -0.08012248242549702, -0.018304568168125535, -0.016356849971922216, -0.05702280912364943, -0.003959134309403756, 0.01638075898585656, 0.04691340159505564, 0.08837686391082344, 0.0006385203297046838, -0.10838465273971642, 0.019199472008696317, 0.01863463041287039, -0.1044944150141836, -0.058198739174639136, -0.058035030053459224, -0.06765077325782098, -0.06126448139013807, 0.002627177285869031, -0.022042230249760597]), ('theil_ind', [0.15528196063213395, 0.19577046161687228, 0.11866863185051914, 0.15974539520094028, 0.17565635600060472, 0.1681771858603836, 0.19169986194142363, 0.18114960926191123, 0.19443603641314308, 0.17770698567966237, 0.15704393440149345, 0.1266254554871275, 0.1309104887745828, 0.21864700170946463, 0.17049169617071114, 0.18877275947749558, 0.15955219453900646, 0.1859664978321533, 0.13046482870581813, 0.14746380141604884]), ('unpriv_fpr', [0.4920863309352518, 0.3513824884792627, 0.5974734424346827, 0.4614050303555941, 0.3979942693409742, 0.45127610208816704, 0.39965397923875434, 0.42982704848313014, 0.4218839747271683, 0.42224152910512597, 0.42410460488914153, 0.5921771642220305, 0.5810771470160117, 0.3050499119201409, 0.4554913294797688, 0.3633778788740404, 0.45501730103806226, 0.36955903271692747, 0.5521313364055299, 0.5052570093457944]), ('unpriv_fnr', [0.33019551049963797, 0.4689265536723164, 0.20689655172413793, 0.3251576734407849, 0.40294117647058825, 0.34529791816223976, 0.40464461646727656, 0.36671575846833576, 0.3715925394548063, 0.3713471133285816, 0.37491141034727143, 0.21433962264150944, 0.2157558552164656, 0.5540261527873366, 0.3843991567111736, 0.4411552346570397, 0.3557422969187675, 0.4390771449170872, 0.22740315638450503, 0.28824362606232296]), ('priv_fpr', [0.5630484988452656, 0.4779990736452061, 0.6797037722749364, 0.5442192538000922, 0.4920889704196285, 0.5088040246970044, 0.441507699379453, 0.4484407011154109, 0.3837101984310106, 0.4793861658268438, 0.588330258302583, 0.6235028248587571, 0.6096542121141796, 0.3845102505694761, 0.5324794144556267, 0.4668521094112193, 0.5425091911764706, 0.4717760440569068, 0.622833371851167, 0.5784245784245784]), ('priv_fnr', [0.2841309823677582, 0.3888040712468193, 0.18859198355601234, 0.30880082346886256, 0.34591836734693876, 0.34133878385283595, 0.42102537545313307, 0.41362916006339145, 0.4599694033656298, 0.3719856336582863, 0.26652675760755506, 0.23353909465020575, 0.23439048562933598, 0.449531737773153, 0.32620041753653445, 0.38312020460358054, 0.2880915236609464, 0.37781266352694926, 0.23003033367037412, 0.2662013958125623])])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_metrics.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bf623751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)\n",
      "\n",
      "law_gender_aif\n",
      "11171\n",
      "2)\n",
      "\n",
      "              total_priv  total_unpriv\n",
      "num_instance                          \n",
      "orig              6325.5        4845.5\n",
      "3)\n",
      "\n",
      "         total_favor  total_unfavor  priv_favor  priv_unfavor  unpriv_favor  \\\n",
      "dataset                                                                       \n",
      "orig        0.301629       0.698371    0.311677      0.688323      0.288500   \n",
      "transf      0.311648       0.688352    0.311677      0.688323      0.311611   \n",
      "\n",
      "         unpriv_unfavor  \n",
      "dataset                  \n",
      "orig           0.711500  \n",
      "transf         0.688389  \n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "print('1)\\n')\n",
    "print(DATASET)\n",
    "print(dataset_orig_train.features.shape[0])\n",
    "\n",
    "print('2)\\n')\n",
    "priv_metric_orig = {k: [v/N] for (k,v) in priv_metric_orig.items()}\n",
    "results = [priv_metric_orig]\n",
    "tr = pd.Series(['orig'], name='num_instance')\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis = 0).set_index([tr])\n",
    "print(df)\n",
    "\n",
    "print('3)\\n')\n",
    "favor_metric_orig = {k: [v/N] for (k,v) in favor_metric_orig.items()}\n",
    "favor_metric_transf = {k: [v/N] for (k,v) in favor_metric_transf.items()}\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "results = [favor_metric_orig, favor_metric_transf]\n",
    "tr = pd.Series(['orig'] + ['transf'], name='dataset')\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis = 0).set_index([tr])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "23a78a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('4)\\n')\n",
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_error_metrics = {k: [statistics.stdev(v)] for (k,v) in orig_metrics.items()}\n",
    "transf_error_metrics = {k: [statistics.stdev(v)] for (k,v) in transf_metrics.items()}\n",
    "reweigh_error_metrics = {k: [statistics.stdev(v)] for (k,v) in reweigh_metrics.items()}\n",
    "dir_error_metrics = {k: [statistics.stdev(v)] for (k,v) in dir_metrics.items()}\n",
    "eg_error_metrics = {k: [statistics.stdev(v)] for (k,v) in eg_metrics.items()}\n",
    "# pr_orig_error_metrics = {k: [statistics.stdev(v)] for (k,v) in pr_orig_metrics.items()}\n",
    "# cpp_error_metrics = {k: [statistics.stdev(v)] for (k,v) in cpp_metrics.items()}\n",
    "# ro_error_metrics = {k: [statistics.stdev(v)] for (k,v) in ro_metrics.items()}\n",
    "\n",
    "# mean value metrics\n",
    "orig_metrics_mean = {k: [sum(v)/N] for (k,v) in orig_metrics.items()}\n",
    "transf_metrics_mean = {k: [sum(v)/N] for (k,v) in transf_metrics.items()}\n",
    "reweigh_metrics_mean = {k:[sum(v)/N] for (k,v) in reweigh_metrics.items()}\n",
    "dir_metrics_mean = {k:[sum(v)/N] for (k,v) in dir_metrics.items()}\n",
    "eg_metrics_mean = {k:[sum(v)/N] for (k,v) in eg_metrics.items()}\n",
    "# pr_orig_metrics_mean = {k: [sum(v)/N] for (k,v) in pr_orig_metrics.items()}\n",
    "# cpp_metrics_mean = {k: [sum(v)/N] for (k,v) in cpp_metrics.items()}\n",
    "# ro_metrics_mean = {k: [sum(v)/N] for (k,v) in ro_metrics.items()}\n",
    "\n",
    "# Python paired sample t-test\n",
    "from scipy.stats import ttest_rel\n",
    "def paired_t (a, b):\n",
    "    np_a = np.array(a)\n",
    "    np_b = np.array(b)\n",
    "    s, p = ttest_rel(np.absolute(np_a), np.absolute(np_b))\n",
    "    return p\n",
    "\n",
    "def acc_diff (a, b):\n",
    "    np_a = np.array(a)\n",
    "    np_b = np.array(b)\n",
    "    delta = np_a - np_b\n",
    "    m = statistics.mean(delta)\n",
    "    s = statistics.stdev(delta)\n",
    "    return [m, s]\n",
    "\n",
    "# if BASELINE == 'lr':\n",
    "#     plot_algo_lr(orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, eg_metrics_mean, pr_orig_metrics_mean, cpp_metrics_mean, ro_metrics_mean, orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, egr_error_metrics, pr_orig_error_metrics, cpp_error_metrics, ro_error_metrics, BASELINE)\n",
    "#     stat =  {k: [paired_t(transf_metrics[k], v)] for (k,v) in orig_metrics.items()}\n",
    "#     print(\"5)\")\n",
    "#     print(stat)\n",
    "# else:\n",
    "#     plot_algo(orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, eg_metrics_mean, cpp_metrics_mean, ro_metrics_mean, orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, egr_error_metrics, cpp_error_metrics, ro_error_metrics, BASELINE)\n",
    "#     stat =  {k: [paired_t(transf_metrics[k], v)] for (k,v) in orig_metrics.items()}\n",
    "#     print(stat)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1627a85",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f14ab",
   "metadata": {},
   "source": [
    "### Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "25c6d438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22bb4a53c90>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_type = BASELINE\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_metrics_mean,\n",
    "        transf_metrics_mean,\n",
    "        dir_metrics_mean,\n",
    "        reweigh_metrics_mean,\n",
    "        eg_metrics_mean]\n",
    "#         pr_orig_metrics_mean,\n",
    "#         cpp_metrics_mean,\n",
    "#         ro_metrics_mean]\n",
    "\n",
    "\n",
    "errors = [orig_error_metrics,\n",
    "        transf_error_metrics,\n",
    "        dir_error_metrics,\n",
    "        reweigh_error_metrics,\n",
    "        eg_error_metrics]\n",
    "#         pr_orig_error_metrics,\n",
    "#         cpp_error_metrics,\n",
    "#         ro_error_metrics]\n",
    "\n",
    "index = pd.Series([model_type+'_orig']+ [model_type+'_syn'] + [model_type+'_dir'] + [model_type+'_rew'] + [model_type+'_eg'], name='Classifier Bias Mitigator')\n",
    "#                   + [model_type+'_rew']+  + [model_type+'_cpp'], name='Classifier Bias Mitigator')\n",
    "\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis=0).set_index(index)\n",
    "df_error = pd.concat([pd.DataFrame(metrics) for metrics in errors], axis=0).set_index(index)\n",
    "ax = df.plot.bar(yerr=df_error, capsize=4, rot=0, subplots=True, title=['','','','','', '', '', '', '', ''], fontsize = 12, figsize=(10,10))\n",
    "plot1 = ax[0]\n",
    "plot1.set_ylim=([0, 0.8])\n",
    "plot2 = ax[1]\n",
    "plot2.set_ylim=([-0.5, 0])\n",
    "plot3 = ax[2]\n",
    "plot3.set_ylim=([0, 1])\n",
    "plot4 = ax[3]\n",
    "plot4.set_ylim=([-0.5, 0])\n",
    "plot5 = ax[4]\n",
    "plot5.set_ylim=([-0.5, 0])\n",
    "plot5 = ax[5]\n",
    "plot5.set_ylim=([0, 0.2])\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.5, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7aff8d",
   "metadata": {},
   "source": [
    "## Visualization of MIA results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588cc377",
   "metadata": {},
   "source": [
    "### Visualization of MIA Attacks against various Fairness Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a42bd",
   "metadata": {},
   "source": [
    "#### Privacy risk subpopulations vs Fairness with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8dddfde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "%matplotlib inline\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "eg_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in eg_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "# cpp_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in cpp_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "eg_mia_metrics_mean = {k:sum(v)/N for (k,v) in eg_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "# cpp_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d6882740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entire_dataset_mia_privacy_risk</th>\n",
       "      <th>entire_dataset_label_0.0_mia_privacy_risk</th>\n",
       "      <th>entire_dataset_label_1.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_0.0_label_0.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_0.0_label_1.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_1.0_label_0.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_1.0_label_1.0_mia_privacy_risk</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier MIA Attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>orig</th>\n",
       "      <td>0.518291</td>\n",
       "      <td>0.519704</td>\n",
       "      <td>0.542116</td>\n",
       "      <td>0.522190</td>\n",
       "      <td>0.544129</td>\n",
       "      <td>0.519646</td>\n",
       "      <td>0.542833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syn</th>\n",
       "      <td>0.515748</td>\n",
       "      <td>0.516428</td>\n",
       "      <td>0.536022</td>\n",
       "      <td>0.518921</td>\n",
       "      <td>0.537485</td>\n",
       "      <td>0.516918</td>\n",
       "      <td>0.537816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dir</th>\n",
       "      <td>0.524640</td>\n",
       "      <td>0.528835</td>\n",
       "      <td>0.549127</td>\n",
       "      <td>0.533153</td>\n",
       "      <td>0.553178</td>\n",
       "      <td>0.533770</td>\n",
       "      <td>0.554011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rew</th>\n",
       "      <td>0.518031</td>\n",
       "      <td>0.519035</td>\n",
       "      <td>0.541611</td>\n",
       "      <td>0.521112</td>\n",
       "      <td>0.544846</td>\n",
       "      <td>0.520046</td>\n",
       "      <td>0.543980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eg</th>\n",
       "      <td>0.511174</td>\n",
       "      <td>0.510634</td>\n",
       "      <td>0.519946</td>\n",
       "      <td>0.510543</td>\n",
       "      <td>0.521680</td>\n",
       "      <td>0.511596</td>\n",
       "      <td>0.520414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        entire_dataset_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                    \n",
       "orig                                           0.518291   \n",
       "syn                                            0.515748   \n",
       "dir                                            0.524640   \n",
       "rew                                            0.518031   \n",
       "eg                                             0.511174   \n",
       "\n",
       "                        entire_dataset_label_0.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                              \n",
       "orig                                                     0.519704   \n",
       "syn                                                      0.516428   \n",
       "dir                                                      0.528835   \n",
       "rew                                                      0.519035   \n",
       "eg                                                       0.510634   \n",
       "\n",
       "                        entire_dataset_label_1.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                              \n",
       "orig                                                     0.542116   \n",
       "syn                                                      0.536022   \n",
       "dir                                                      0.549127   \n",
       "rew                                                      0.541611   \n",
       "eg                                                       0.519946   \n",
       "\n",
       "                        subpopulation_0.0_label_0.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                                 \n",
       "orig                                                        0.522190   \n",
       "syn                                                         0.518921   \n",
       "dir                                                         0.533153   \n",
       "rew                                                         0.521112   \n",
       "eg                                                          0.510543   \n",
       "\n",
       "                        subpopulation_0.0_label_1.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                                 \n",
       "orig                                                        0.544129   \n",
       "syn                                                         0.537485   \n",
       "dir                                                         0.553178   \n",
       "rew                                                         0.544846   \n",
       "eg                                                          0.521680   \n",
       "\n",
       "                        subpopulation_1.0_label_0.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                                 \n",
       "orig                                                        0.519646   \n",
       "syn                                                         0.516918   \n",
       "dir                                                         0.533770   \n",
       "rew                                                         0.520046   \n",
       "eg                                                          0.511596   \n",
       "\n",
       "                        subpopulation_1.0_label_1.0_mia_privacy_risk  \n",
       "Classifier MIA Attacks                                                \n",
       "orig                                                        0.542833  \n",
       "syn                                                         0.537816  \n",
       "dir                                                         0.554011  \n",
       "rew                                                         0.543980  \n",
       "eg                                                          0.520414  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "           transf_mia_metrics_mean,\n",
    "           dir_mia_metrics_mean,\n",
    "           reweigh_mia_metrics_mean,\n",
    "           eg_mia_metrics_mean\n",
    "          ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "          transf_mia_error_metrics,\n",
    "          dir_mia_error_metrics,\n",
    "          reweigh_mia_error_metrics,\n",
    "          eg_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn'] + ['dir'] + ['rew'] + ['eg'], name='Classifier MIA Attacks')\n",
    "#                   + ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3881013e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'entire_dataset_mia_auc': [0.5288299000087674,\n",
       "              0.5270715474333652,\n",
       "              0.5261827911463755,\n",
       "              0.5258746445193216,\n",
       "              0.5228470001352099,\n",
       "              0.5274713391142573,\n",
       "              0.5232282528547015,\n",
       "              0.5193056618452894,\n",
       "              0.5214479155632405,\n",
       "              0.5183796232942344,\n",
       "              0.5196193938002428,\n",
       "              0.5187477060188863,\n",
       "              0.5287126762366279,\n",
       "              0.5300273277993925,\n",
       "              0.5296390433363829,\n",
       "              0.5228726830274892,\n",
       "              0.5213075771880495,\n",
       "              0.518685478093771,\n",
       "              0.5242987526664632,\n",
       "              0.5288147907752596],\n",
       "             'entire_dataset_mia_privacy_risk': [0.5213051651597888,\n",
       "              0.5184406051383046,\n",
       "              0.5207680601557605,\n",
       "              0.5184853638886402,\n",
       "              0.5152627338644705,\n",
       "              0.5209470951571031,\n",
       "              0.5204995076537463,\n",
       "              0.5144123176080924,\n",
       "              0.5179930176349477,\n",
       "              0.5148599051114493,\n",
       "              0.5157550801181631,\n",
       "              0.5149494226121207,\n",
       "              0.5221555814161668,\n",
       "              0.5206785426550891,\n",
       "              0.5202757139020678,\n",
       "              0.5158893563691702,\n",
       "              0.5156655626174917,\n",
       "              0.5153074926148062,\n",
       "              0.5196490913973681,\n",
       "              0.5225136514188524],\n",
       "             'entire_dataset_mia_ppv': [0.542713567839196,\n",
       "              0.5538922155688623,\n",
       "              0.5330668604651163,\n",
       "              0.542065491183879,\n",
       "              0.5331137943651665,\n",
       "              0.5413612565445026,\n",
       "              0.5349143610013175,\n",
       "              0.5271574303832368,\n",
       "              0.5294811320754716,\n",
       "              0.5327354260089686,\n",
       "              0.5252525252525252,\n",
       "              0.5204,\n",
       "              0.5298372513562387,\n",
       "              0.5418620227729404,\n",
       "              0.5449785816277963,\n",
       "              0.5405750798722044,\n",
       "              0.5273103041039268,\n",
       "              0.5363106796116505,\n",
       "              0.5358761329305136,\n",
       "              0.5431111111111111],\n",
       "             'entire_dataset_mia_attacker_advantage': [0.042610330319577505,\n",
       "              0.03688121027660907,\n",
       "              0.041536120311520985,\n",
       "              0.0369707277772805,\n",
       "              0.030525467728941047,\n",
       "              0.04189419031420638,\n",
       "              0.040999015307492614,\n",
       "              0.028824635216184724,\n",
       "              0.0359860352698953,\n",
       "              0.0297198102228986,\n",
       "              0.031510160236326246,\n",
       "              0.029898845224241355,\n",
       "              0.04431116283233372,\n",
       "              0.04135708531017818,\n",
       "              0.040551427804135676,\n",
       "              0.03177871273834032,\n",
       "              0.03133112523498338,\n",
       "              0.030614985229612368,\n",
       "              0.0392981827947364,\n",
       "              0.04502730283770484],\n",
       "             'entire_dataset_mia_result': [MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.06991317, 0.07143497, 0.07268821, 0.07456808,\n",
       "                     0.07940202, 0.08047623, 0.08101334, 0.08307224, 0.08423597,\n",
       "                     0.08960702, 0.09945394, 0.10303464, 0.10366127, 0.10598872,\n",
       "                     0.11708889, 0.11861069, 0.12675678, 0.13830454, 0.14295945,\n",
       "                     0.14421269, 0.14645063, 0.14868857, 0.15808791, 0.16166861,\n",
       "                     0.16220571, 0.166234  , 0.16874049, 0.17894548, 0.1810939 ,\n",
       "                     0.18333184, 0.18816579, 0.20141438, 0.20275714, 0.20526363,\n",
       "                     0.23328261, 0.23525199, 0.2383851 , 0.24080208, 0.24411422,\n",
       "                     0.24742637, 0.26165965, 0.27866798, 0.28448662, 0.28905201,\n",
       "                     0.29182705, 0.29469161, 0.30400143, 0.31796616, 0.3207412 ,\n",
       "                     0.33014054, 0.3339898 , 0.34267299, 0.35180378, 0.35842807,\n",
       "                     0.36558947, 0.36836452, 0.37722675, 0.37839048, 0.38993823,\n",
       "                     0.39262376, 0.39325038, 0.40300779, 0.42109032, 0.42520813,\n",
       "                     0.42860979, 0.429684  , 0.43460747, 0.43809865, 0.44069466,\n",
       "                     0.45456987, 0.46182079, 0.47247337, 0.47596455, 0.48724376,\n",
       "                     0.49163011, 0.49494226, 0.49744875, 0.49995524, 0.50335691,\n",
       "                     0.51588936, 0.52260317, 0.52358786, 0.52439352, 0.52681049,\n",
       "                     0.53182347, 0.53835825, 0.54596724, 0.54856324, 0.5488318 ,\n",
       "                     0.5524125 , 0.55357622, 0.55581416, 0.56807806, 0.56870468,\n",
       "                     0.57058455, 0.57434428, 0.58096858, 0.58320652, 0.58580252,\n",
       "                     0.58705577, 0.58768239, 0.59206875, 0.59350103, 0.59421717,\n",
       "                     0.60630203, 0.60782383, 0.60916659, 0.6132844 , 0.61623847,\n",
       "                     0.62017724, 0.62635395, 0.63065079, 0.631725  , 0.63960254,\n",
       "                     0.64085579, 0.64425745, 0.64765912, 0.65079223, 0.65356727,\n",
       "                     0.6552681 , 0.65938591, 0.66153433, 0.66457792, 0.66780056,\n",
       "                     0.66824814, 0.66896428, 0.67003849, 0.67200788, 0.67406678,\n",
       "                     0.67684182, 0.69170173, 0.6941187 , 0.69662519, 0.69940023,\n",
       "                     0.6997583 , 0.70083251, 0.7012801 , 0.70611405, 0.70808343,\n",
       "                     0.70951571, 0.71676663, 0.71837794, 0.72169009, 0.72356996,\n",
       "                     0.72455465, 0.72831439, 0.73073136, 0.7314475 , 0.73592337,\n",
       "                     0.73825083, 0.74192105, 0.74496464, 0.74675499, 0.74872438,\n",
       "                     0.74953003, 0.75194701, 0.75409543, 0.75633336, 0.76206248,\n",
       "                     0.76251007, 0.7642109 , 0.76707546, 0.76734402, 0.76859726,\n",
       "                     0.77029809, 0.77423686, 0.77942888, 0.78095068, 0.78220392,\n",
       "                     0.78292006, 0.78766449, 0.78990243, 0.79115567, 0.79258795,\n",
       "                     0.7928565 , 0.79455734, 0.80010742, 0.80279295, 0.80556799,\n",
       "                     0.80700027, 0.80789544, 0.80896965, 0.81058097, 0.8158625 ,\n",
       "                     0.81836899, 0.82069645, 0.82275535, 0.82418763, 0.82615701,\n",
       "                     0.83045385, 0.83448214, 0.84030078, 0.84343389, 0.84925253,\n",
       "                     0.85005819, 0.85229612, 0.85462358, 0.85489213, 0.85704055,\n",
       "                     0.85838331, 0.86643989, 0.86912541, 0.86984155, 0.87118432,\n",
       "                     0.87172142, 0.87888282, 0.88040462, 0.88371677, 0.88461194,\n",
       "                     0.88667084, 0.89007251, 0.8941008 , 0.89982992, 0.90108316,\n",
       "                     0.90403724, 0.90555904, 0.91137767, 0.91298899, 0.91424223,\n",
       "                     0.91603258, 0.91719631, 0.91907618, 0.92426819, 0.92829648,\n",
       "                     0.93142959, 0.93384657, 0.93626354, 0.93805389, 0.9391281 ,\n",
       "                     0.94646853, 0.94727419, 0.94772178, 0.95354042, 0.95586787,\n",
       "                     0.95667353, 0.95765822, 0.96088085, 0.96159699, 0.96311879,\n",
       "                     0.96347686, 0.96356638, 0.96464059, 0.96759466, 0.96813177,\n",
       "                     0.96813177, 0.9683108 , 0.96992212, 0.97162295, 0.97332378,\n",
       "                     0.97430848, 0.97735207, 0.97744159, 0.97788918, 0.97896339,\n",
       "                     0.9820965 , 0.98281264, 0.98370781, 0.98424492, 0.98451347,\n",
       "                     0.98487154, 0.98558768, 0.98576672, 0.98594575, 1.        ]), tpr=array([0.        , 0.08172948, 0.0838779 , 0.0859368 , 0.08790619,\n",
       "                     0.09336675, 0.09479903, 0.09605228, 0.09802166, 0.09990153,\n",
       "                     0.10634679, 0.11619372, 0.12066959, 0.12210187, 0.12344463,\n",
       "                     0.13535046, 0.1396473 , 0.14877809, 0.15880405, 0.16354847,\n",
       "                     0.16551786, 0.16739773, 0.17008325, 0.17912452, 0.18342136,\n",
       "                     0.18422702, 0.18780772, 0.18986662, 0.20213052, 0.20571122,\n",
       "                     0.20830722, 0.21475248, 0.2291648 , 0.23041805, 0.23256647,\n",
       "                     0.26112255, 0.26488228, 0.26891057, 0.27222272, 0.27607197,\n",
       "                     0.28072688, 0.29388595, 0.31044669, 0.31671292, 0.32083072,\n",
       "                     0.32467997, 0.32772357, 0.33631725, 0.34992391, 0.35251992,\n",
       "                     0.36147167, 0.3646943 , 0.37454122, 0.38358249, 0.38966968,\n",
       "                     0.39772626, 0.39987468, 0.40757318, 0.40990064, 0.42431295,\n",
       "                     0.42717751, 0.42798317, 0.43621878, 0.45707636, 0.46047802,\n",
       "                     0.46486438, 0.46665473, 0.47220482, 0.47659117, 0.47865008,\n",
       "                     0.4915406 , 0.49789634, 0.51007072, 0.51472563, 0.52591532,\n",
       "                     0.53083878, 0.53522514, 0.53889535, 0.54193895, 0.54596724,\n",
       "                     0.55769403, 0.56154328, 0.56333363, 0.56413929, 0.56655626,\n",
       "                     0.57103214, 0.57613463, 0.58472831, 0.58741384, 0.58804046,\n",
       "                     0.59036792, 0.59144213, 0.59412765, 0.60585444, 0.60657058,\n",
       "                     0.60827142, 0.61095694, 0.61713365, 0.62143049, 0.62429505,\n",
       "                     0.62635395, 0.62724913, 0.63181452, 0.63369439, 0.63432101,\n",
       "                     0.64542118, 0.64676394, 0.64882284, 0.65240354, 0.65535762,\n",
       "                     0.65768508, 0.66251902, 0.66780056, 0.66914332, 0.6756781 ,\n",
       "                     0.67711038, 0.68006445, 0.68436129, 0.68668875, 0.68973234,\n",
       "                     0.69098559, 0.69662519, 0.69805747, 0.70029541, 0.70351804,\n",
       "                     0.70441321, 0.70530839, 0.7063826 , 0.70871005, 0.71041089,\n",
       "                     0.71291738, 0.72795632, 0.73037329, 0.7319846 , 0.73413302,\n",
       "                     0.73511772, 0.73592337, 0.73672903, 0.73959359, 0.74156298,\n",
       "                     0.74281622, 0.74773968, 0.74881389, 0.7514099 , 0.75337929,\n",
       "                     0.75427446, 0.75695999, 0.75937696, 0.76054069, 0.76582222,\n",
       "                     0.76689643, 0.77101423, 0.77477397, 0.77656432, 0.77880226,\n",
       "                     0.77933936, 0.78148778, 0.78300958, 0.78399427, 0.79205085,\n",
       "                     0.79249843, 0.7938412 , 0.79706383, 0.79769045, 0.79912273,\n",
       "                     0.80109211, 0.80395667, 0.80798496, 0.80968579, 0.81076   ,\n",
       "                     0.81120759, 0.81845851, 0.82006982, 0.82069645, 0.82203921,\n",
       "                     0.82239728, 0.82391908, 0.82875302, 0.83161758, 0.83412407,\n",
       "                     0.83546683, 0.83591442, 0.83689911, 0.83895802, 0.84522424,\n",
       "                     0.84737266, 0.84898398, 0.85086384, 0.85310178, 0.85560827,\n",
       "                     0.86124787, 0.86357533, 0.86966252, 0.87279563, 0.87897234,\n",
       "                     0.87995703, 0.88201593, 0.88461194, 0.8854176 , 0.88738698,\n",
       "                     0.88890878, 0.8982186 , 0.90188882, 0.90224689, 0.90350013,\n",
       "                     0.90403724, 0.90967684, 0.91066153, 0.91388416, 0.91477934,\n",
       "                     0.91800197, 0.92041894, 0.92399964, 0.92784889, 0.92910214,\n",
       "                     0.9325038 , 0.9334885 , 0.93841196, 0.94145555, 0.94252976,\n",
       "                     0.94387253, 0.94530481, 0.94745323, 0.95309283, 0.95747919,\n",
       "                     0.95900098, 0.96025423, 0.96132844, 0.96258168, 0.96374541,\n",
       "                     0.97242861, 0.97305523, 0.9734133 , 0.97744159, 0.97923194,\n",
       "                     0.97994808, 0.98093277, 0.9841554 , 0.98469251, 0.98549816,\n",
       "                     0.98558768, 0.98576672, 0.98666189, 0.98854176, 0.98907886,\n",
       "                     0.98943693, 0.989795  , 0.99060066, 0.99230149, 0.99382329,\n",
       "                     0.99444991, 0.99615075, 0.99632978, 0.99650882, 0.99704592,\n",
       "                     0.99820965, 0.99892579, 0.99910482, 0.99919434, 0.99928386,\n",
       "                     0.99946289, 0.99973145, 0.99982096, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.08219945e-02, -4.25596144e-02,\n",
       "                     -4.44517626e-02, -4.80092192e-02, -6.06246218e-02, -6.89928715e-02,\n",
       "                     -8.70113770e-02, -9.09717782e-02, -1.05360516e-01, -1.11703990e-01,\n",
       "                     -1.13328685e-01, -1.17783036e-01, -1.25163143e-01, -1.33531393e-01,\n",
       "                     -1.36132174e-01, -1.54150680e-01, -1.56698452e-01, -1.56842471e-01,\n",
       "                     -1.67054085e-01, -1.74353387e-01, -1.82321557e-01, -1.88900528e-01,\n",
       "                     -1.89242000e-01, -2.00670695e-01, -2.23143551e-01, -2.31801614e-01,\n",
       "                     -2.33310669e-01, -2.42946179e-01, -2.43622083e-01, -2.45122458e-01,\n",
       "                     -2.46471804e-01, -2.51314428e-01, -2.55933374e-01, -2.65494157e-01,\n",
       "                     -2.69663567e-01, -2.70874954e-01, -2.80902385e-01, -2.81851152e-01,\n",
       "                     -2.82862786e-01, -2.87682072e-01, -2.93072921e-01, -2.94799540e-01,\n",
       "                     -2.98492989e-01, -2.99242895e-01, -3.02280872e-01, -3.03186259e-01,\n",
       "                     -3.08838272e-01, -3.21583624e-01, -3.22083499e-01, -3.28504067e-01,\n",
       "                     -3.29957556e-01, -3.33639374e-01, -3.34369186e-01, -3.36472237e-01,\n",
       "                     -3.48306694e-01, -3.49673748e-01, -3.52821375e-01, -3.56674944e-01,\n",
       "                     -3.62905494e-01, -3.67724780e-01, -3.68560551e-01, -3.69044477e-01,\n",
       "                     -3.69747026e-01, -3.70859579e-01, -3.71563556e-01, -3.83725121e-01,\n",
       "                     -3.84845821e-01, -3.90866309e-01, -3.91478866e-01, -4.00759217e-01,\n",
       "                     -4.05465108e-01, -4.05465108e-01, -4.08128226e-01, -4.11507423e-01,\n",
       "                     -4.12244795e-01, -4.13562318e-01, -4.24883194e-01, -4.27444015e-01,\n",
       "                     -4.28107585e-01, -4.28454626e-01, -4.38254931e-01, -4.41832752e-01,\n",
       "                     -4.41832752e-01, -4.44685821e-01, -4.45585102e-01, -4.46287103e-01,\n",
       "                     -4.48950220e-01, -4.51985124e-01, -4.55475529e-01, -4.59532329e-01,\n",
       "                     -4.70003629e-01, -4.81388951e-01, -4.85507816e-01, -4.89548225e-01,\n",
       "                     -4.90622916e-01, -5.02091944e-01, -5.10825624e-01, -5.23248144e-01,\n",
       "                     -5.28067430e-01, -5.30628251e-01, -5.34082486e-01, -5.38996501e-01,\n",
       "                     -5.38996501e-01, -5.45694449e-01, -5.50046337e-01, -5.53385238e-01,\n",
       "                     -5.59615788e-01, -5.63935449e-01, -5.70544858e-01, -5.75364145e-01,\n",
       "                     -5.76422906e-01, -5.87786665e-01, -5.92342481e-01, -5.94707108e-01,\n",
       "                     -5.97837001e-01, -6.06135804e-01, -6.13104473e-01, -6.16774202e-01,\n",
       "                     -6.19039208e-01, -6.27549898e-01, -6.28608659e-01, -6.31271777e-01,\n",
       "                     -6.35988767e-01, -6.41853886e-01, -6.41853886e-01, -6.50587566e-01,\n",
       "                     -6.53926467e-01, -6.66478933e-01, -6.75128675e-01, -6.93147181e-01,\n",
       "                     -7.11496319e-01, -7.20546155e-01, -7.33969175e-01, -7.37598943e-01,\n",
       "                     -7.47214402e-01, -7.47214402e-01, -7.53771802e-01, -7.59105148e-01,\n",
       "                     -7.62140052e-01, -7.63351439e-01, -7.73189888e-01, -7.75838896e-01,\n",
       "                     -7.80158558e-01, -7.88457360e-01, -7.88457360e-01, -7.98507696e-01,\n",
       "                     -8.02346473e-01, -8.05264479e-01, -8.10930216e-01, -8.25318954e-01,\n",
       "                     -8.26678573e-01, -8.32909123e-01, -8.41567186e-01, -8.47297860e-01,\n",
       "                     -8.47297860e-01, -8.55666110e-01, -8.60201265e-01, -8.66166345e-01,\n",
       "                     -8.75468737e-01, -8.75468737e-01, -8.82389180e-01, -8.87303195e-01,\n",
       "                     -8.90972924e-01, -8.97941593e-01, -9.16290732e-01, -9.29535959e-01,\n",
       "                     -9.47381319e-01, -9.49080555e-01, -9.55511445e-01, -9.62137120e-01,\n",
       "                     -9.80829253e-01, -9.98528830e-01, -1.00552187e+00, -1.01160091e+00,\n",
       "                     -1.01693426e+00, -1.02165125e+00, -1.02290047e+00, -1.02450432e+00,\n",
       "                     -1.02961942e+00, -1.02961942e+00, -1.03609193e+00, -1.05416053e+00,\n",
       "                     -1.05480967e+00, -1.05605267e+00, -1.06087196e+00, -1.08261195e+00,\n",
       "                     -1.08518927e+00, -1.08663610e+00, -1.09330724e+00, -1.09861229e+00,\n",
       "                     -1.09861229e+00, -1.10809103e+00, -1.12718566e+00, -1.12846525e+00,\n",
       "                     -1.14117190e+00, -1.14356368e+00, -1.17007125e+00, -1.17163742e+00,\n",
       "                     -1.17411984e+00, -1.17569203e+00, -1.17677706e+00, -1.17865500e+00,\n",
       "                     -1.18958407e+00, -1.20397280e+00, -1.20397280e+00, -1.21302264e+00,\n",
       "                     -1.22050211e+00, -1.22377543e+00, -1.25276297e+00, -1.25804003e+00,\n",
       "                     -1.25988044e+00, -1.26923781e+00, -1.27296568e+00, -1.28966753e+00,\n",
       "                     -1.29098418e+00, -1.32538561e+00, -1.34117393e+00, -1.34373475e+00,\n",
       "                     -1.35239281e+00, -1.35454566e+00, -1.36524095e+00, -1.37029402e+00,\n",
       "                     -1.38629436e+00, -1.40089316e+00, -1.40399394e+00, -1.40691365e+00,\n",
       "                     -1.43848011e+00, -1.44238383e+00, -1.45597428e+00, -1.48807706e+00,\n",
       "                     -1.50407740e+00, -1.52121368e+00, -1.52605630e+00, -1.53147637e+00,\n",
       "                     -1.53393036e+00, -1.56977266e+00, -1.57553636e+00, -1.60943791e+00,\n",
       "                     -1.60943791e+00, -1.70474809e+00, -1.75785792e+00, -1.75949861e+00,\n",
       "                     -1.79175947e+00, -1.83258146e+00, -1.87180218e+00, -1.92990981e+00,\n",
       "                     -1.93075834e+00, -1.94591015e+00, -2.06142304e+00, -2.07944154e+00,\n",
       "                     -2.14006616e+00, -2.19722458e+00, -2.23359222e+00, -2.24723500e+00,\n",
       "                     -2.30258509e+00, -2.44234704e+00, -2.48490665e+00, -2.48490665e+00,\n",
       "                     -2.83321334e+00, -3.06027079e+00, -3.13549422e+00, -3.21887582e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5288299000087674, privacy_risk=0.5213051651597888, accuracy=0.5213051651597888, tpr_ind=0.5459672365947543, tnr_ind=0.4966430937248232, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.06490019, 0.06669054, 0.06946558, 0.07967058,\n",
       "                     0.08137141, 0.08477307, 0.08692149, 0.0895175 , 0.09184496,\n",
       "                     0.09372482, 0.09426193, 0.09703697, 0.10097574, 0.11082267,\n",
       "                     0.11270253, 0.11547758, 0.11735744, 0.11905828, 0.12183332,\n",
       "                     0.12988989, 0.13123266, 0.13499239, 0.13678274, 0.13866261,\n",
       "                     0.16256378, 0.1677558 , 0.17142601, 0.17303733, 0.17670755,\n",
       "                     0.17939307, 0.18145197, 0.18422702, 0.1912989 , 0.1928207 ,\n",
       "                     0.20544266, 0.20651687, 0.20893385, 0.2097395 , 0.21376779,\n",
       "                     0.22021305, 0.22433086, 0.22647928, 0.23748993, 0.24035449,\n",
       "                     0.24903769, 0.25127562, 0.25315549, 0.2542297 , 0.26246531,\n",
       "                     0.27249127, 0.27535583, 0.27965267, 0.28269627, 0.29120043,\n",
       "                     0.29406499, 0.31626533, 0.32002506, 0.33649629, 0.3483126 ,\n",
       "                     0.35341509, 0.35565303, 0.35824904, 0.35869663, 0.36854355,\n",
       "                     0.38286635, 0.38385104, 0.39065437, 0.39942709, 0.4046191 ,\n",
       "                     0.40497717, 0.40855787, 0.41545072, 0.44436487, 0.45000448,\n",
       "                     0.45644974, 0.45716588, 0.45913526, 0.46504342, 0.47157819,\n",
       "                     0.48223078, 0.48357354, 0.50120849, 0.51024975, 0.51687405,\n",
       "                     0.5186644 , 0.52215558, 0.52457255, 0.52591532, 0.52886939,\n",
       "                     0.52985409, 0.53253961, 0.54614627, 0.54731   , 0.54793662,\n",
       "                     0.55187539, 0.55644078, 0.56020052, 0.56127473, 0.56449736,\n",
       "                     0.58347507, 0.58607108, 0.59251634, 0.59493331, 0.60325844,\n",
       "                     0.60567541, 0.60621251, 0.60692865, 0.61364247, 0.62644347,\n",
       "                     0.63441053, 0.63906544, 0.64031868, 0.64345179, 0.64855429,\n",
       "                     0.65016561, 0.65141885, 0.65929639, 0.66260854, 0.66404082,\n",
       "                     0.66511503, 0.66511503, 0.66583117, 0.66842718, 0.66923284,\n",
       "                     0.67102319, 0.67370871, 0.67711038, 0.69760988, 0.70002686,\n",
       "                     0.70199624, 0.7028019 , 0.70351804, 0.7063826 , 0.70736729,\n",
       "                     0.7079044 , 0.70915764, 0.71014233, 0.71318593, 0.71998926,\n",
       "                     0.72097395, 0.72160057, 0.72321189, 0.72473369, 0.72598693,\n",
       "                     0.72732969, 0.73073136, 0.73225316, 0.73646048, 0.74442754,\n",
       "                     0.74756065, 0.75060424, 0.75114135, 0.75302122, 0.76027213,\n",
       "                     0.76152538, 0.76564318, 0.76716498, 0.77835467, 0.78041357,\n",
       "                     0.78175633, 0.78435234, 0.78811208, 0.79008146, 0.79061857,\n",
       "                     0.79142422, 0.79912273, 0.8015397 , 0.80261391, 0.80520992,\n",
       "                     0.80655268, 0.808164  , 0.80950676, 0.80968579, 0.81541491,\n",
       "                     0.81953272, 0.82749978, 0.82946916, 0.83340793, 0.83743622,\n",
       "                     0.84101692, 0.84155402, 0.84227016, 0.8475517 , 0.85077433,\n",
       "                     0.86294871, 0.86429147, 0.86572375, 0.86608182, 0.86760362,\n",
       "                     0.87342225, 0.87601826, 0.87718199, 0.88219497, 0.88497001,\n",
       "                     0.88497001, 0.88586519, 0.88676036, 0.88926685, 0.89607018,\n",
       "                     0.9017993 , 0.90358965, 0.91066153, 0.91182526, 0.91656969,\n",
       "                     0.918181  , 0.92041894, 0.92229881, 0.92525289, 0.92731179,\n",
       "                     0.92784889, 0.9289231 , 0.92981828, 0.9340256 , 0.93527885,\n",
       "                     0.93903858, 0.93975472, 0.94109748, 0.94297735, 0.94440963,\n",
       "                     0.94521529, 0.94602095, 0.94664757, 0.95416704, 0.95470414,\n",
       "                     0.95712112, 0.95828484, 0.95864291, 0.95953809, 0.96052278,\n",
       "                     0.96123892, 0.96222361, 0.96329782, 0.964193  , 0.97063826,\n",
       "                     0.97162295, 0.97233909, 0.97323427, 0.97368185, 0.97556172,\n",
       "                     0.97556172, 0.97654641, 0.97681497, 0.97815773, 0.97833676,\n",
       "                     0.98048518, 0.98155939, 0.98200698, 0.98218602, 0.98290216,\n",
       "                     0.9841554 , 0.98496106, 0.98514009, 0.9856772 , 0.98585623,\n",
       "                     0.98639334, 0.98639334, 0.98684093, 1.        ]), tpr=array([0.        , 0.08002865, 0.08280369, 0.08495211, 0.09470952,\n",
       "                     0.09649987, 0.0997225 , 0.10115478, 0.10392982, 0.10661534,\n",
       "                     0.10921135, 0.1104646 , 0.11341867, 0.11708889, 0.12899472,\n",
       "                     0.130427  , 0.13356011, 0.13535046, 0.13767792, 0.13937875,\n",
       "                     0.14940471, 0.15101602, 0.1539701 , 0.15584997, 0.15808791,\n",
       "                     0.18234715, 0.18762868, 0.19147793, 0.19317877, 0.19613284,\n",
       "                     0.19854982, 0.20159341, 0.20481604, 0.21340972, 0.21511055,\n",
       "                     0.23310357, 0.23408826, 0.23668427, 0.23829559, 0.24214484,\n",
       "                     0.24778444, 0.25333453, 0.25503536, 0.26541939, 0.26846298,\n",
       "                     0.27625101, 0.27830991, 0.28010026, 0.2813535 , 0.28708262,\n",
       "                     0.29692955, 0.30033121, 0.30444902, 0.30901441, 0.31751857,\n",
       "                     0.32056217, 0.34365769, 0.34804404, 0.36532092, 0.37830096,\n",
       "                     0.38340346, 0.38626802, 0.3882374 , 0.38931161, 0.39906902,\n",
       "                     0.41240713, 0.41473458, 0.4189419 , 0.42878883, 0.43317519,\n",
       "                     0.43398084, 0.4383672 , 0.44391729, 0.47471131, 0.48061946,\n",
       "                     0.48966073, 0.49082446, 0.49234625, 0.49834393, 0.5043416 ,\n",
       "                     0.51383045, 0.51597887, 0.53200251, 0.53996956, 0.54659386,\n",
       "                     0.54757855, 0.55098022, 0.55339719, 0.55482947, 0.55921583,\n",
       "                     0.56091666, 0.56306508, 0.57694029, 0.57855161, 0.57971533,\n",
       "                     0.58374362, 0.59045743, 0.59394862, 0.59520186, 0.59806642,\n",
       "                     0.61632799, 0.61829738, 0.62411601, 0.62617492, 0.63512667,\n",
       "                     0.63754364, 0.63879688, 0.6404082 , 0.64676394, 0.65840122,\n",
       "                     0.66556262, 0.67003849, 0.67120222, 0.67361919, 0.67612568,\n",
       "                     0.67881121, 0.68024349, 0.69009041, 0.69331304, 0.69456629,\n",
       "                     0.69599857, 0.69680423, 0.6976994 , 0.70136962, 0.70235431,\n",
       "                     0.70351804, 0.70593501, 0.70826247, 0.7299257 , 0.73216364,\n",
       "                     0.73440158, 0.73547579, 0.73637096, 0.73968311, 0.74048877,\n",
       "                     0.74120491, 0.74245815, 0.74353236, 0.74621789, 0.7534688 ,\n",
       "                     0.75427446, 0.75543819, 0.75758661, 0.75955599, 0.76143586,\n",
       "                     0.76233104, 0.7657327 , 0.76680691, 0.77110375, 0.77978695,\n",
       "                     0.78444186, 0.78560559, 0.78650076, 0.78820159, 0.79446782,\n",
       "                     0.7959001 , 0.79992839, 0.80127115, 0.81344553, 0.8153254 ,\n",
       "                     0.81613105, 0.81836899, 0.82266583, 0.82517232, 0.82588846,\n",
       "                     0.82687315, 0.83519828, 0.83645153, 0.83743622, 0.83994271,\n",
       "                     0.84074837, 0.84209113, 0.843971  , 0.8445081 , 0.8480888 ,\n",
       "                     0.85238564, 0.8608898 , 0.86196401, 0.86670844, 0.86966252,\n",
       "                     0.87252708, 0.87324322, 0.87378032, 0.87789813, 0.88058365,\n",
       "                     0.89454838, 0.89705487, 0.89902426, 0.89938233, 0.9012622 ,\n",
       "                     0.90546952, 0.90725987, 0.90824456, 0.91388416, 0.91800197,\n",
       "                     0.91844956, 0.91925521, 0.92041894, 0.92247784, 0.92766986,\n",
       "                     0.93438367, 0.9360845 , 0.94503625, 0.94619998, 0.94942261,\n",
       "                     0.95112344, 0.95264524, 0.95389849, 0.95747919, 0.95953809,\n",
       "                     0.95998568, 0.9606123 , 0.96132844, 0.96392445, 0.96490914,\n",
       "                     0.96822129, 0.96875839, 0.97036971, 0.97198102, 0.97305523,\n",
       "                     0.97350282, 0.97421896, 0.97448751, 0.97923194, 0.97967953,\n",
       "                     0.98191746, 0.98254409, 0.98272312, 0.98343926, 0.98397637,\n",
       "                     0.98460299, 0.98496106, 0.98576672, 0.98684093, 0.99176439,\n",
       "                     0.99221198, 0.99257005, 0.99310715, 0.9933757 , 0.99498702,\n",
       "                     0.99525557, 0.99561364, 0.99588219, 0.99632978, 0.99650882,\n",
       "                     0.99776206, 0.99812013, 0.99838868, 0.9984782 , 0.99865724,\n",
       "                     0.99883627, 0.99901531, 0.99910482, 0.99928386, 0.99937338,\n",
       "                     0.99982096, 0.99991048, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.17486983e-02, -4.08219945e-02,\n",
       "                     -4.48505662e-02, -4.87901642e-02, -5.40672213e-02, -6.06246218e-02,\n",
       "                     -6.25203570e-02, -6.45385211e-02, -6.66913745e-02, -6.89928715e-02,\n",
       "                     -8.70113770e-02, -9.30904231e-02, -1.00083459e-01, -1.17783036e-01,\n",
       "                     -1.33531393e-01, -1.39761942e-01, -1.43100844e-01, -1.46603474e-01,\n",
       "                     -1.49035579e-01, -1.54150680e-01, -1.67054085e-01, -1.74353387e-01,\n",
       "                     -1.82321557e-01, -1.84778560e-01, -1.85142433e-01, -1.90043603e-01,\n",
       "                     -1.91055237e-01, -1.92371893e-01, -2.00670695e-01, -2.11309094e-01,\n",
       "                     -2.23143551e-01, -2.31442354e-01, -2.33614851e-01, -2.34029359e-01,\n",
       "                     -2.41162057e-01, -2.43622083e-01, -2.45122458e-01, -2.46133070e-01,\n",
       "                     -2.51314428e-01, -2.54892250e-01, -2.74436846e-01, -2.76847730e-01,\n",
       "                     -2.80301965e-01, -2.87682072e-01, -2.98492989e-01, -3.00104592e-01,\n",
       "                     -3.05381650e-01, -3.07025035e-01, -3.10154928e-01, -3.13657559e-01,\n",
       "                     -3.14493330e-01, -3.16669609e-01, -3.21320432e-01, -3.23787077e-01,\n",
       "                     -3.27573401e-01, -3.27687407e-01, -3.28296792e-01, -3.36472237e-01,\n",
       "                     -3.38975367e-01, -3.40926587e-01, -3.42944751e-01, -3.48306694e-01,\n",
       "                     -3.52077235e-01, -3.52639969e-01, -3.52821375e-01, -3.54545018e-01,\n",
       "                     -3.55765440e-01, -3.56674944e-01, -3.67724780e-01, -3.70859579e-01,\n",
       "                     -3.72675285e-01, -3.73966441e-01, -3.74693449e-01, -3.75312070e-01,\n",
       "                     -3.79489622e-01, -3.85662481e-01, -3.90427231e-01, -4.00477567e-01,\n",
       "                     -4.05465108e-01, -4.05465108e-01, -4.25742301e-01, -4.31344556e-01,\n",
       "                     -4.32133355e-01, -4.35318071e-01, -4.39951284e-01, -4.41832752e-01,\n",
       "                     -4.46287103e-01, -4.51985124e-01, -4.56758402e-01, -4.59532329e-01,\n",
       "                     -4.70003629e-01, -4.76924072e-01, -4.79573080e-01, -4.83796951e-01,\n",
       "                     -4.94696242e-01, -4.95321437e-01, -4.96436886e-01, -5.04556011e-01,\n",
       "                     -5.10825624e-01, -5.19875459e-01, -5.26093096e-01, -5.28067430e-01,\n",
       "                     -5.30628251e-01, -5.32804530e-01, -5.38996501e-01, -5.43615447e-01,\n",
       "                     -5.49504478e-01, -5.57415567e-01, -5.59615788e-01, -5.65313809e-01,\n",
       "                     -5.70544858e-01, -5.75364145e-01, -5.79818495e-01, -5.87786665e-01,\n",
       "                     -5.94707108e-01, -5.97837001e-01, -6.06135804e-01, -6.19039208e-01,\n",
       "                     -6.28608659e-01, -6.35988767e-01, -6.41853886e-01, -6.43136760e-01,\n",
       "                     -6.46627165e-01, -6.53926467e-01, -6.55406853e-01, -6.73729095e-01,\n",
       "                     -6.93147181e-01, -7.12949808e-01, -7.32367894e-01, -7.33969175e-01,\n",
       "                     -7.41937345e-01, -7.45790914e-01, -7.47214402e-01, -7.53771802e-01,\n",
       "                     -7.62140052e-01, -7.73189888e-01, -7.88457360e-01, -7.98507696e-01,\n",
       "                     -7.98507696e-01, -8.02346473e-01, -8.10930216e-01, -8.20980552e-01,\n",
       "                     -8.26678573e-01, -8.32909123e-01, -8.39750655e-01, -8.47297860e-01,\n",
       "                     -8.47297860e-01, -8.50239039e-01, -8.60940637e-01, -8.69037847e-01,\n",
       "                     -8.75468737e-01, -8.84202417e-01, -8.87303195e-01, -8.90972924e-01,\n",
       "                     -8.93817876e-01, -9.02867712e-01, -9.16290732e-01, -9.25769476e-01,\n",
       "                     -9.38269639e-01, -9.40007258e-01, -9.40983344e-01, -9.58254931e-01,\n",
       "                     -9.65080896e-01, -9.69400557e-01, -9.80829253e-01, -9.98528830e-01,\n",
       "                     -1.00330211e+00, -1.01160091e+00, -1.02165125e+00, -1.02961942e+00,\n",
       "                     -1.03301501e+00, -1.04145387e+00, -1.04731899e+00, -1.04877991e+00,\n",
       "                     -1.05925121e+00, -1.09861229e+00, -1.09861229e+00, -1.10866262e+00,\n",
       "                     -1.12938395e+00, -1.13943428e+00, -1.15267951e+00, -1.16179119e+00,\n",
       "                     -1.16315081e+00, -1.16475209e+00, -1.16760516e+00, -1.17163742e+00,\n",
       "                     -1.17865500e+00, -1.20397280e+00, -1.20609820e+00, -1.20896035e+00,\n",
       "                     -1.21302264e+00, -1.21345155e+00, -1.21478372e+00, -1.22377543e+00,\n",
       "                     -1.23676263e+00, -1.24171313e+00, -1.24653242e+00, -1.25276297e+00,\n",
       "                     -1.27349887e+00, -1.27506873e+00, -1.27536280e+00, -1.28519824e+00,\n",
       "                     -1.29167838e+00, -1.30405626e+00, -1.30992138e+00, -1.31218639e+00,\n",
       "                     -1.32175584e+00, -1.33041390e+00, -1.33500107e+00, -1.34992672e+00,\n",
       "                     -1.35454566e+00, -1.38629436e+00, -1.40876722e+00, -1.41952001e+00,\n",
       "                     -1.42711636e+00, -1.49165488e+00, -1.50407740e+00, -1.52242654e+00,\n",
       "                     -1.52605630e+00, -1.53147637e+00, -1.54044504e+00, -1.56704235e+00,\n",
       "                     -1.56861592e+00, -1.57691472e+00, -1.60943791e+00, -1.60943791e+00,\n",
       "                     -1.65822808e+00, -1.70474809e+00, -1.74296931e+00, -1.74919985e+00,\n",
       "                     -1.75401914e+00, -1.77777323e+00, -1.77956420e+00, -1.79175947e+00,\n",
       "                     -1.83258146e+00, -1.87180218e+00, -1.94591015e+00, -1.97716269e+00,\n",
       "                     -1.99243016e+00, -2.01490302e+00, -2.03688193e+00, -2.07944154e+00,\n",
       "                     -2.19722458e+00, -2.35137526e+00, -2.42036813e+00, -2.48490665e+00,\n",
       "                     -2.70805020e+00, -2.74084002e+00, -2.77258872e+00, -2.80336038e+00,\n",
       "                     -2.83321334e+00, -2.94443898e+00, -3.04452244e+00, -3.12676054e+00,\n",
       "                     -3.21887582e+00, -3.46573590e+00, -3.45387764e+01]), auc_score=0.5270715474333652, privacy_risk=0.5184406051383046, accuracy=0.5184406051383046, tpr_ind=0.7844418583833139, tnr_ind=0.25243935189329514, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.07707457, 0.08199803, 0.08351983, 0.08504163,\n",
       "                     0.0874586 , 0.08915943, 0.0925611 , 0.09453048, 0.09658938,\n",
       "                     0.10482499, 0.10572017, 0.10625727, 0.10715245, 0.10939039,\n",
       "                     0.10983797, 0.11502999, 0.11950586, 0.12183332, 0.12675678,\n",
       "                     0.13391818, 0.14081103, 0.14286993, 0.14591353, 0.14788291,\n",
       "                     0.15182168, 0.16542834, 0.16757676, 0.17124698, 0.17366395,\n",
       "                     0.17625996, 0.17993018, 0.18288425, 0.18592785, 0.19174649,\n",
       "                     0.19881837, 0.2127831 , 0.21654283, 0.22119774, 0.22343568,\n",
       "                     0.22361472, 0.22433086, 0.23050756, 0.25485632, 0.26532987,\n",
       "                     0.26631456, 0.26756781, 0.27105899, 0.27607197, 0.28027929,\n",
       "                     0.28314385, 0.29343837, 0.30113687, 0.30561275, 0.30937248,\n",
       "                     0.3099991 , 0.31026766, 0.31268463, 0.31349029, 0.31635485,\n",
       "                     0.31787664, 0.32092024, 0.32503804, 0.32960344, 0.33318414,\n",
       "                     0.33479545, 0.36558947, 0.36657417, 0.37158715, 0.37364605,\n",
       "                     0.37642109, 0.38206069, 0.38537284, 0.40658849, 0.41285471,\n",
       "                     0.41795721, 0.42180646, 0.42332826, 0.42413392, 0.42637186,\n",
       "                     0.43040014, 0.43317519, 0.43577119, 0.44114224, 0.45331662,\n",
       "                     0.4542118 , 0.47184675, 0.47453227, 0.47784442, 0.49091397,\n",
       "                     0.49189867, 0.49485274, 0.49700116, 0.50836989, 0.51042879,\n",
       "                     0.51705308, 0.51893295, 0.52448304, 0.5258258 , 0.52976457,\n",
       "                     0.53835825, 0.53988005, 0.54122281, 0.54256557, 0.5478471 ,\n",
       "                     0.54945842, 0.5565303 , 0.56324411, 0.59197923, 0.59681318,\n",
       "                     0.60191567, 0.60388506, 0.60558589, 0.60862949, 0.61059887,\n",
       "                     0.61167308, 0.61373198, 0.61426909, 0.61776027, 0.61937159,\n",
       "                     0.61990869, 0.62527974, 0.63646943, 0.64443649, 0.64712201,\n",
       "                     0.64855429, 0.65052368, 0.65365679, 0.65410438, 0.66126578,\n",
       "                     0.66323516, 0.66448841, 0.66511503, 0.66663683, 0.66950139,\n",
       "                     0.67272402, 0.67594665, 0.67863217, 0.6941187 , 0.69447677,\n",
       "                     0.69608809, 0.69948975, 0.70351804, 0.7048608 , 0.70665115,\n",
       "                     0.70772536, 0.70942619, 0.71345448, 0.71372303, 0.71757229,\n",
       "                     0.72034733, 0.72079492, 0.72177961, 0.72312237, 0.73162653,\n",
       "                     0.74174201, 0.74344284, 0.7463074 , 0.74693403, 0.74818727,\n",
       "                     0.74979859, 0.75042521, 0.75158894, 0.75185749, 0.75364784,\n",
       "                     0.75490108, 0.75624385, 0.7565124 , 0.76089876, 0.76385283,\n",
       "                     0.78300958, 0.78578462, 0.79088712, 0.79214036, 0.79509444,\n",
       "                     0.7964372 , 0.79652672, 0.79724286, 0.80341957, 0.80431474,\n",
       "                     0.80467281, 0.80744786, 0.8087011 , 0.81335601, 0.81371408,\n",
       "                     0.8179214 , 0.81863754, 0.81971175, 0.81998031, 0.82678364,\n",
       "                     0.8286635 , 0.82946916, 0.83752574, 0.8403903 , 0.84737266,\n",
       "                     0.85095336, 0.8516695 , 0.85238564, 0.85489213, 0.85542924,\n",
       "                     0.85623489, 0.85641393, 0.85909945, 0.86106884, 0.86285919,\n",
       "                     0.87297467, 0.87566019, 0.87843523, 0.8787933 , 0.879778  ,\n",
       "                     0.88121028, 0.88174738, 0.8910572 , 0.89177334, 0.89338466,\n",
       "                     0.89705487, 0.89803957, 0.90009847, 0.90090413, 0.90206785,\n",
       "                     0.90269448, 0.90367917, 0.9038582 , 0.90430579, 0.90663325,\n",
       "                     0.90779697, 0.91173574, 0.91773342, 0.92041894, 0.92220929,\n",
       "                     0.92426819, 0.92596903, 0.92668517, 0.92704324, 0.93151911,\n",
       "                     0.9396652 , 0.94091845, 0.94190314, 0.94261928, 0.94396204,\n",
       "                     0.94485722, 0.94611046, 0.95085489, 0.95282428, 0.95425656,\n",
       "                     0.95622594, 0.95676305, 0.9575687 , 0.95882195, 0.96052278,\n",
       "                     0.96088085, 0.96186554, 0.96240265, 0.96741563, 0.96750515,\n",
       "                     0.96875839, 0.96938501, 0.9698326 , 0.97010115, 0.97126488,\n",
       "                     0.97377137, 0.97386089, 0.97421896, 0.97502462, 0.97609883,\n",
       "                     0.97672545, 0.97753111, 0.97887387, 0.97914242, 0.97923194,\n",
       "                     0.97941097, 0.97967953, 0.9800376 , 0.9805747 , 0.98093277,\n",
       "                     0.98164891, 0.98173843, 0.98191746, 0.9820965 , 0.98254409,\n",
       "                     0.9826336 , 1.        ]), tpr=array([0.        , 0.08307224, 0.0879957 , 0.08996509, 0.09166592,\n",
       "                     0.09497807, 0.09658938, 0.10196043, 0.10428789, 0.10643631,\n",
       "                     0.11485095, 0.11682034, 0.11771551, 0.11932683, 0.12219139,\n",
       "                     0.12353415, 0.13132217, 0.13445529, 0.13740936, 0.14072151,\n",
       "                     0.14931519, 0.15656611, 0.15862501, 0.16157909, 0.16345896,\n",
       "                     0.166234  , 0.18100439, 0.18360039, 0.18744965, 0.19085131,\n",
       "                     0.19649091, 0.20042968, 0.20347328, 0.20678543, 0.21394683,\n",
       "                     0.22057112, 0.23561006, 0.23865366, 0.24268194, 0.24635216,\n",
       "                     0.24733685, 0.24796348, 0.25163369, 0.27499776, 0.28636648,\n",
       "                     0.28726166, 0.28815683, 0.29227464, 0.29630293, 0.29997314,\n",
       "                     0.3043595 , 0.31563871, 0.32512756, 0.32852923, 0.33264703,\n",
       "                     0.33390028, 0.33488497, 0.3365858 , 0.33873422, 0.34133023,\n",
       "                     0.3432101 , 0.34625369, 0.34992391, 0.35663772, 0.36039746,\n",
       "                     0.36236684, 0.39325038, 0.39432459, 0.39817384, 0.40094889,\n",
       "                     0.40327634, 0.41061678, 0.41437651, 0.43827768, 0.44409632,\n",
       "                     0.44794557, 0.45358518, 0.45537553, 0.45636022, 0.45868767,\n",
       "                     0.46405872, 0.46728135, 0.46898219, 0.47453227, 0.48867604,\n",
       "                     0.49064542, 0.50443112, 0.50702712, 0.51096589, 0.52305076,\n",
       "                     0.52403545, 0.5258258 , 0.52743711, 0.53683645, 0.53853728,\n",
       "                     0.54498254, 0.54757855, 0.55348671, 0.55482947, 0.55867872,\n",
       "                     0.56816758, 0.5693313 , 0.57004744, 0.57174828, 0.57667174,\n",
       "                     0.57890968, 0.58804046, 0.59520186, 0.6230418 , 0.62796527,\n",
       "                     0.63306776, 0.63503715, 0.63673798, 0.63987109, 0.6424671 ,\n",
       "                     0.64363083, 0.64542118, 0.6460478 , 0.64980754, 0.65141885,\n",
       "                     0.65276161, 0.65956494, 0.67164981, 0.67997494, 0.6818548 ,\n",
       "                     0.68328708, 0.68597261, 0.68928476, 0.68991138, 0.69528243,\n",
       "                     0.69743085, 0.69895265, 0.70056396, 0.70226479, 0.70575598,\n",
       "                     0.70879957, 0.71085847, 0.71211172, 0.72697162, 0.72813535,\n",
       "                     0.73001522, 0.73279026, 0.73592337, 0.73744517, 0.73887745,\n",
       "                     0.74022021, 0.74210008, 0.74675499, 0.7472921 , 0.75006714,\n",
       "                     0.75185749, 0.75230508, 0.7534688 , 0.7549906 , 0.76170441,\n",
       "                     0.7713723 , 0.77271507, 0.7764748 , 0.77745949, 0.77862322,\n",
       "                     0.78130875, 0.78175633, 0.78300958, 0.78381524, 0.78560559,\n",
       "                     0.78775401, 0.78891773, 0.7902605 , 0.79366216, 0.79688479,\n",
       "                     0.81505684, 0.81971175, 0.82561991, 0.82705219, 0.8301853 ,\n",
       "                     0.83125951, 0.8317071 , 0.83242324, 0.83824188, 0.84056933,\n",
       "                     0.84137499, 0.84486617, 0.84638797, 0.8501477 , 0.8511324 ,\n",
       "                     0.85650345, 0.85739862, 0.85838331, 0.85892042, 0.8654552 ,\n",
       "                     0.8675141 , 0.86885686, 0.87583923, 0.87682392, 0.8838958 ,\n",
       "                     0.88658133, 0.88738698, 0.88890878, 0.89141527, 0.89248948,\n",
       "                     0.89293707, 0.89374273, 0.89624922, 0.89795005, 0.90045654,\n",
       "                     0.91075105, 0.91236237, 0.91549548, 0.91648017, 0.9176439 ,\n",
       "                     0.91925521, 0.9197028 , 0.9325038 , 0.93330946, 0.93483126,\n",
       "                     0.93751678, 0.93894906, 0.94011279, 0.94082893, 0.94181362,\n",
       "                     0.94261928, 0.9432459 , 0.94360397, 0.94405156, 0.94548384,\n",
       "                     0.94664757, 0.9498702 , 0.95362993, 0.95506221, 0.95622594,\n",
       "                     0.95747919, 0.95873243, 0.95900098, 0.95926954, 0.9626712 ,\n",
       "                     0.96956405, 0.97063826, 0.97081729, 0.97108585, 0.97207054,\n",
       "                     0.97314475, 0.97395041, 0.97788918, 0.97959001, 0.98093277,\n",
       "                     0.98138036, 0.98218602, 0.98290216, 0.98379733, 0.98505058,\n",
       "                     0.98576672, 0.98657237, 0.98710948, 0.98997404, 0.99006356,\n",
       "                     0.99060066, 0.99095873, 0.99149584, 0.99185391, 0.99310715,\n",
       "                     0.99453943, 0.99507654, 0.99552412, 0.99597171, 0.99704592,\n",
       "                     0.99722496, 0.99731447, 0.99758303, 0.99776206, 0.99785158,\n",
       "                     0.9979411 , 0.99803061, 0.99874675, 0.99892579, 0.99910482,\n",
       "                     0.99946289, 0.99955241, 0.99973145, 0.99982096, 0.99991048,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.80185055e-02, -4.44517626e-02,\n",
       "                     -5.12932944e-02, -5.26437335e-02, -5.40672213e-02, -6.45385211e-02,\n",
       "                     -7.41079722e-02, -8.00427077e-02, -8.16780310e-02, -8.70113770e-02,\n",
       "                     -9.53101798e-02, -1.05360516e-01, -1.17783036e-01, -1.25163143e-01,\n",
       "                     -1.29211731e-01, -1.33531393e-01, -1.41078598e-01, -1.50282203e-01,\n",
       "                     -1.54150680e-01, -1.59427737e-01, -1.60342650e-01, -1.67054085e-01,\n",
       "                     -1.74353387e-01, -1.76930708e-01, -1.82321557e-01, -1.88052232e-01,\n",
       "                     -1.90043603e-01, -1.91055237e-01, -2.00670695e-01, -2.04794413e-01,\n",
       "                     -2.11309094e-01, -2.17723484e-01, -2.23143551e-01, -2.28534400e-01,\n",
       "                     -2.32622295e-01, -2.34839591e-01, -2.36388778e-01, -2.37671652e-01,\n",
       "                     -2.41162057e-01, -2.51314428e-01, -2.56719847e-01, -2.58525488e-01,\n",
       "                     -2.61758387e-01, -2.62364264e-01, -2.62364264e-01, -2.65703166e-01,\n",
       "                     -2.70874954e-01, -2.75411980e-01, -2.82566972e-01, -2.87682072e-01,\n",
       "                     -2.92387963e-01, -2.94239473e-01, -2.98492989e-01, -3.05381650e-01,\n",
       "                     -3.10154928e-01, -3.13657559e-01, -3.18453731e-01, -3.21583624e-01,\n",
       "                     -3.22773392e-01, -3.23787077e-01, -3.29479201e-01, -3.36472237e-01,\n",
       "                     -3.39867826e-01, -3.42944751e-01, -3.46770989e-01, -3.48306694e-01,\n",
       "                     -3.49673748e-01, -3.50202429e-01, -3.52821375e-01, -3.55454688e-01,\n",
       "                     -3.56674944e-01, -3.58171950e-01, -3.58212223e-01, -3.65934269e-01,\n",
       "                     -3.67724780e-01, -3.71563556e-01, -3.74693449e-01, -3.79489622e-01,\n",
       "                     -3.82992252e-01, -3.86772975e-01, -3.87765531e-01, -3.94654192e-01,\n",
       "                     -4.05465108e-01, -4.05465108e-01, -4.09784769e-01, -4.16893804e-01,\n",
       "                     -4.20502985e-01, -4.32263301e-01, -4.35318071e-01, -4.38254931e-01,\n",
       "                     -4.41832752e-01, -4.51985124e-01, -4.56758402e-01, -4.59532329e-01,\n",
       "                     -4.61345567e-01, -4.64305608e-01, -4.70003629e-01, -4.72906389e-01,\n",
       "                     -4.78224462e-01, -4.79573080e-01, -4.85507816e-01, -4.89548225e-01,\n",
       "                     -4.92476485e-01, -4.94696242e-01, -4.98991166e-01, -5.00775288e-01,\n",
       "                     -5.02430353e-01, -5.03526321e-01, -5.10825624e-01, -5.19875459e-01,\n",
       "                     -5.21296924e-01, -5.22189382e-01, -5.24524468e-01, -5.26093096e-01,\n",
       "                     -5.30628251e-01, -5.38996501e-01, -5.38996501e-01, -5.43615447e-01,\n",
       "                     -5.50046337e-01, -5.59615788e-01, -5.87786665e-01, -5.91364486e-01,\n",
       "                     -5.93063722e-01, -5.94707108e-01, -6.06135804e-01, -6.08589793e-01,\n",
       "                     -6.19039208e-01, -6.24154309e-01, -6.28608659e-01, -6.32522559e-01,\n",
       "                     -6.35988767e-01, -6.39079959e-01, -6.40503447e-01, -6.48026745e-01,\n",
       "                     -6.48695418e-01, -6.56779536e-01, -6.93147181e-01, -7.30887509e-01,\n",
       "                     -7.39667196e-01, -7.40400065e-01, -7.48717032e-01, -7.50305594e-01,\n",
       "                     -7.53771802e-01, -7.57685702e-01, -7.62140052e-01, -7.67255153e-01,\n",
       "                     -7.73189888e-01, -7.85520501e-01, -7.88457360e-01, -7.88457360e-01,\n",
       "                     -8.02346473e-01, -8.04372816e-01, -8.06475866e-01, -8.10930216e-01,\n",
       "                     -8.47297860e-01, -8.47297860e-01, -8.60201265e-01, -8.69037847e-01,\n",
       "                     -8.75468737e-01, -8.75468737e-01, -8.87303195e-01, -8.93817876e-01,\n",
       "                     -8.96088025e-01, -8.99483614e-01, -9.00786545e-01, -9.02867712e-01,\n",
       "                     -9.16290732e-01, -9.27340568e-01, -9.29017286e-01, -9.31558204e-01,\n",
       "                     -9.34309237e-01, -9.40983344e-01, -9.44461609e-01, -9.49080555e-01,\n",
       "                     -9.55511445e-01, -9.65080896e-01, -9.67276287e-01, -9.76009967e-01,\n",
       "                     -9.80829253e-01, -9.90398704e-01, -9.95428052e-01, -9.98528830e-01,\n",
       "                     -1.00330211e+00, -1.01160091e+00, -1.02961942e+00, -1.03609193e+00,\n",
       "                     -1.04145387e+00, -1.04707864e+00, -1.06919840e+00, -1.07613943e+00,\n",
       "                     -1.09002854e+00, -1.09861229e+00, -1.09861229e+00, -1.12059120e+00,\n",
       "                     -1.13497993e+00, -1.13707857e+00, -1.14513230e+00, -1.15267951e+00,\n",
       "                     -1.16315081e+00, -1.17007125e+00, -1.17865500e+00, -1.18269541e+00,\n",
       "                     -1.20039498e+00, -1.20048848e+00, -1.20397280e+00, -1.20682587e+00,\n",
       "                     -1.21302264e+00, -1.21924028e+00, -1.22050211e+00, -1.22377543e+00,\n",
       "                     -1.22747078e+00, -1.23676263e+00, -1.24432410e+00, -1.25276297e+00,\n",
       "                     -1.27046255e+00, -1.28519824e+00, -1.28785429e+00, -1.29098418e+00,\n",
       "                     -1.29928298e+00, -1.31218639e+00, -1.32175584e+00, -1.33500107e+00,\n",
       "                     -1.35454566e+00, -1.36687628e+00, -1.37230812e+00, -1.38629436e+00,\n",
       "                     -1.40179855e+00, -1.42403469e+00, -1.43848011e+00, -1.45528723e+00,\n",
       "                     -1.46633707e+00, -1.46633707e+00, -1.46835931e+00, -1.47924047e+00,\n",
       "                     -1.48538526e+00, -1.50407740e+00, -1.54044504e+00, -1.55334845e+00,\n",
       "                     -1.55814462e+00, -1.56397554e+00, -1.57239664e+00, -1.58816051e+00,\n",
       "                     -1.60943791e+00, -1.60943791e+00, -1.63141682e+00, -1.65822808e+00,\n",
       "                     -1.68639895e+00, -1.70474809e+00, -1.74919985e+00, -1.75401914e+00,\n",
       "                     -1.76358859e+00, -1.79175947e+00, -1.79175947e+00, -1.81915844e+00,\n",
       "                     -1.83258146e+00, -1.87180218e+00, -1.90954250e+00, -1.91481956e+00,\n",
       "                     -1.94591015e+00, -1.96944065e+00, -2.02814825e+00, -2.07944154e+00,\n",
       "                     -2.11021320e+00, -2.14006616e+00, -2.19722458e+00, -2.19722458e+00,\n",
       "                     -2.30258509e+00, -2.39789527e+00, -2.48490665e+00, -2.48490665e+00,\n",
       "                     -2.54553127e+00, -2.56494936e+00, -2.63905733e+00, -2.77258872e+00,\n",
       "                     -2.94443898e+00, -2.97041447e+00, -2.99573227e+00, -3.13549422e+00,\n",
       "                     -4.02535169e+00, -3.45387764e+01]), auc_score=0.5261827911463755, privacy_risk=0.5207680601557605, accuracy=0.5207680601557605, tpr_ind=0.933309461999821, tnr_ind=0.10822665831169993, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.0567541 , 0.07071883, 0.07340435, 0.0772536 ,\n",
       "                     0.07814878, 0.08137141, 0.09086026, 0.09470952, 0.09542566,\n",
       "                     0.09605228, 0.10070719, 0.10401934, 0.10625727, 0.10786859,\n",
       "                     0.11297109, 0.11547758, 0.11771551, 0.12407126, 0.12792051,\n",
       "                     0.12827858, 0.13078507, 0.1381255 , 0.13902068, 0.14143765,\n",
       "                     0.14197476, 0.14224331, 0.15074747, 0.15119506, 0.15253782,\n",
       "                     0.15692418, 0.16345896, 0.18351088, 0.18628592, 0.1897771 ,\n",
       "                     0.19810223, 0.21018709, 0.21439441, 0.22263002, 0.23158177,\n",
       "                     0.23247695, 0.23820607, 0.23892221, 0.2414287 , 0.24599409,\n",
       "                     0.25100707, 0.25440874, 0.25539343, 0.26506132, 0.26792588,\n",
       "                     0.27607197, 0.29487065, 0.29827231, 0.30301674, 0.3207412 ,\n",
       "                     0.32709695, 0.32951392, 0.33416883, 0.34124071, 0.34446334,\n",
       "                     0.34643273, 0.35010295, 0.35699579, 0.3575329 , 0.36326202,\n",
       "                     0.36496285, 0.37310894, 0.3795542 , 0.38555188, 0.38743174,\n",
       "                     0.39602542, 0.40085937, 0.40882643, 0.42664041, 0.44884075,\n",
       "                     0.45000448, 0.45886671, 0.46763942, 0.46987736, 0.47829201,\n",
       "                     0.47918718, 0.48124608, 0.48249933, 0.48428968, 0.48625906,\n",
       "                     0.49476323, 0.50049235, 0.50720616, 0.50765375, 0.51007072,\n",
       "                     0.51078686, 0.51454659, 0.52412497, 0.53101781, 0.53227106,\n",
       "                     0.53495658, 0.54193895, 0.54954794, 0.5565303 , 0.56279653,\n",
       "                     0.57067407, 0.57371766, 0.59296392, 0.59627607, 0.5989616 ,\n",
       "                     0.60030436, 0.60146809, 0.60298988, 0.60603348, 0.60782383,\n",
       "                     0.61068839, 0.61104646, 0.61650703, 0.62134097, 0.6266225 ,\n",
       "                     0.63691702, 0.63843881, 0.6460478 , 0.64927043, 0.65079223,\n",
       "                     0.65338824, 0.654731  , 0.65634231, 0.65902784, 0.66090771,\n",
       "                     0.66269806, 0.66511503, 0.66708442, 0.66860621, 0.67173933,\n",
       "                     0.67451437, 0.67505147, 0.67666279, 0.67872169, 0.68095963,\n",
       "                     0.69313401, 0.69438725, 0.69510339, 0.69581953, 0.69698326,\n",
       "                     0.70002686, 0.70459225, 0.70584549, 0.70745681, 0.70951571,\n",
       "                     0.71014233, 0.71193268, 0.71309641, 0.71417062, 0.71524483,\n",
       "                     0.71694566, 0.71757229, 0.7176618 , 0.72231671, 0.72876197,\n",
       "                     0.73001522, 0.73771372, 0.74281622, 0.74514368, 0.74881389,\n",
       "                     0.74970907, 0.75158894, 0.75230508, 0.75382687, 0.75534867,\n",
       "                     0.75543819, 0.75660192, 0.75830275, 0.75937696, 0.76358428,\n",
       "                     0.77790708, 0.77996598, 0.78390475, 0.7866798 , 0.78972339,\n",
       "                     0.7928565 , 0.79760093, 0.79903321, 0.80091308, 0.80503088,\n",
       "                     0.80861158, 0.81058097, 0.81219228, 0.81407215, 0.81496733,\n",
       "                     0.81908513, 0.82078596, 0.82544087, 0.82776833, 0.82955868,\n",
       "                     0.83063289, 0.83296034, 0.83627249, 0.84191209, 0.84271775,\n",
       "                     0.84549279, 0.84943156, 0.84952108, 0.856772  , 0.86635037,\n",
       "                     0.86930445, 0.87216901, 0.87700295, 0.87780861, 0.88121028,\n",
       "                     0.88470146, 0.88846119, 0.88908782, 0.89168382, 0.89231045,\n",
       "                     0.89660729, 0.89777101, 0.89786053, 0.90063557, 0.90188882,\n",
       "                     0.90412676, 0.90546952, 0.90761794, 0.91227285, 0.91442127,\n",
       "                     0.91621162, 0.92391012, 0.92704324, 0.92928117, 0.93259332,\n",
       "                     0.93268284, 0.9340256 , 0.93581595, 0.93742727, 0.93769582,\n",
       "                     0.93841196, 0.94011279, 0.94047086, 0.9432459 , 0.94557336,\n",
       "                     0.94700564, 0.95318235, 0.95667353, 0.95828484, 0.95873243,\n",
       "                     0.95980664, 0.964193  , 0.96652045, 0.96723659, 0.96741563,\n",
       "                     0.96786322, 0.96956405, 0.96974308, 0.9698326 , 0.97019067,\n",
       "                     0.97045922, 0.97233909, 0.97305523, 0.97359234, 0.97377137,\n",
       "                     0.97466655, 0.97565124, 0.97636738, 0.9764569 , 0.97726255,\n",
       "                     0.97824725, 0.97950049, 0.97976904, 0.9805747 , 0.98075374,\n",
       "                     0.98182795, 0.98254409, 0.98281264, 0.98308119, 0.98388685,\n",
       "                     0.98451347, 0.98549816, 1.        ]), tpr=array([0.        , 0.06588488, 0.08199803, 0.0853997 , 0.09041268,\n",
       "                     0.09202399, 0.09632083, 0.10509355, 0.10974846, 0.11082267,\n",
       "                     0.11162832, 0.11592516, 0.11852117, 0.12102766, 0.12219139,\n",
       "                     0.12792051, 0.13015845, 0.13284397, 0.1396473 , 0.14376511,\n",
       "                     0.1447498 , 0.14743532, 0.15540238, 0.15665563, 0.15952019,\n",
       "                     0.16032584, 0.1611315 , 0.1682929 , 0.17026229, 0.17142601,\n",
       "                     0.17446961, 0.18198908, 0.20114582, 0.2040999 , 0.20875481,\n",
       "                     0.21860174, 0.23301405, 0.23722138, 0.24590457, 0.25548295,\n",
       "                     0.25646764, 0.26067496, 0.26192821, 0.26470325, 0.26944768,\n",
       "                     0.27651956, 0.27974219, 0.28144302, 0.29146898, 0.29657148,\n",
       "                     0.30373288, 0.32360576, 0.32799212, 0.33443738, 0.34849163,\n",
       "                     0.35305702, 0.35583207, 0.36174022, 0.36800645, 0.37257184,\n",
       "                     0.37400412, 0.37883806, 0.3846567 , 0.3861785 , 0.39298183,\n",
       "                     0.39530928, 0.40533524, 0.41303375, 0.41921046, 0.42064274,\n",
       "                     0.42816221, 0.43380181, 0.44176887, 0.45815057, 0.47766538,\n",
       "                     0.47865008, 0.48625906, 0.49485274, 0.49726972, 0.50711664,\n",
       "                     0.50980217, 0.5120401 , 0.51391997, 0.5156208 , 0.5171426 ,\n",
       "                     0.52484111, 0.52877988, 0.53629935, 0.5380897 , 0.54131233,\n",
       "                     0.54274461, 0.54731   , 0.55420285, 0.56091666, 0.56261749,\n",
       "                     0.56584012, 0.57353863, 0.57980485, 0.58445976, 0.59126309,\n",
       "                     0.59726076, 0.60030436, 0.62152001, 0.62581685, 0.62877092,\n",
       "                     0.63002417, 0.63190404, 0.63333632, 0.63637991, 0.63754364,\n",
       "                     0.64112434, 0.64193   , 0.64721153, 0.64971802, 0.65508907,\n",
       "                     0.66520455, 0.66708442, 0.67424582, 0.67952735, 0.68167577,\n",
       "                     0.68391371, 0.68561454, 0.68677827, 0.68856862, 0.69161221,\n",
       "                     0.69286546, 0.69501388, 0.69653567, 0.69814699, 0.70163817,\n",
       "                     0.70521887, 0.70656163, 0.7079044 , 0.70933668, 0.71103751,\n",
       "                     0.72589741, 0.72750873, 0.72885149, 0.73010474, 0.73135798,\n",
       "                     0.73458061, 0.73771372, 0.739146  , 0.74048877, 0.74236863,\n",
       "                     0.74344284, 0.74603885, 0.74756065, 0.74854534, 0.74997762,\n",
       "                     0.75185749, 0.75275266, 0.75364784, 0.7580342 , 0.76385283,\n",
       "                     0.76537463, 0.77352072, 0.77781756, 0.77978695, 0.78390475,\n",
       "                     0.78453138, 0.78730642, 0.78820159, 0.79052905, 0.79133471,\n",
       "                     0.79160326, 0.79294602, 0.7938412 , 0.7959001 , 0.79876466,\n",
       "                     0.81281891, 0.81478829, 0.81863754, 0.82293438, 0.82579894,\n",
       "                     0.82955868, 0.83412407, 0.83600394, 0.83698863, 0.84083788,\n",
       "                     0.84477665, 0.84737266, 0.84817832, 0.84996867, 0.85095336,\n",
       "                     0.85507117, 0.85721959, 0.86133739, 0.86214305, 0.86303822,\n",
       "                     0.86402292, 0.86518664, 0.86652941, 0.87145287, 0.8726166 ,\n",
       "                     0.87664488, 0.88013607, 0.88058365, 0.88944589, 0.89687584,\n",
       "                     0.90045654, 0.90296303, 0.90627518, 0.9069018 , 0.90958732,\n",
       "                     0.91289947, 0.91719631, 0.918181  , 0.92104556, 0.92167219,\n",
       "                     0.92399964, 0.92587951, 0.92641661, 0.92811745, 0.9304449 ,\n",
       "                     0.93259332, 0.93357801, 0.93518933, 0.94011279, 0.94235073,\n",
       "                     0.94387253, 0.95076537, 0.95318235, 0.95488318, 0.95819533,\n",
       "                     0.95873243, 0.95971712, 0.96186554, 0.96329782, 0.96410348,\n",
       "                     0.96446155, 0.96562528, 0.96589383, 0.96840032, 0.97063826,\n",
       "                     0.97171247, 0.97538269, 0.97788918, 0.97887387, 0.9790529 ,\n",
       "                     0.97976904, 0.98433444, 0.98612479, 0.98684093, 0.98710948,\n",
       "                     0.98755707, 0.98916838, 0.98934742, 0.98952645, 0.99015307,\n",
       "                     0.99042163, 0.99203294, 0.99248053, 0.99257005, 0.99274908,\n",
       "                     0.99346522, 0.99462895, 0.99507654, 0.99543461, 0.99632978,\n",
       "                     0.99650882, 0.99686689, 0.99722496, 0.99776206, 0.9979411 ,\n",
       "                     0.99829917, 0.99892579, 0.99919434, 0.99928386, 0.99955241,\n",
       "                     0.99973145, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.65293020e-02, -5.12932944e-02,\n",
       "                     -5.21857532e-02, -5.40672213e-02, -6.06246218e-02, -6.89928715e-02,\n",
       "                     -7.41079722e-02, -8.00427077e-02, -1.05360516e-01, -1.17783036e-01,\n",
       "                     -1.29211731e-01, -1.33531393e-01, -1.43100844e-01, -1.45182010e-01,\n",
       "                     -1.48420005e-01, -1.54150680e-01, -1.57903029e-01, -1.60342650e-01,\n",
       "                     -1.67054085e-01, -1.82321557e-01, -1.84192465e-01, -1.94156014e-01,\n",
       "                     -1.97825743e-01, -2.00670695e-01, -2.00670695e-01, -2.02940844e-01,\n",
       "                     -2.04794413e-01, -2.07639365e-01, -2.11309094e-01, -2.13574100e-01,\n",
       "                     -2.13753811e-01, -2.17064505e-01, -2.23143551e-01, -2.26773319e-01,\n",
       "                     -2.26863332e-01, -2.27389842e-01, -2.29310066e-01, -2.32445944e-01,\n",
       "                     -2.41162057e-01, -2.44196961e-01, -2.51314428e-01, -2.54892250e-01,\n",
       "                     -2.63814591e-01, -2.65281136e-01, -2.66628663e-01, -2.74436846e-01,\n",
       "                     -2.85447435e-01, -2.87682072e-01, -2.90802200e-01, -2.97766192e-01,\n",
       "                     -2.97834444e-01, -2.98044859e-01, -3.00340469e-01, -3.02280872e-01,\n",
       "                     -3.03682414e-01, -3.10154928e-01, -3.15852949e-01, -3.16669609e-01,\n",
       "                     -3.18453731e-01, -3.28504067e-01, -3.36472237e-01, -3.44840486e-01,\n",
       "                     -3.51397887e-01, -3.52821375e-01, -3.56674944e-01, -3.57837059e-01,\n",
       "                     -3.61013346e-01, -3.62905494e-01, -3.64973747e-01, -3.67724780e-01,\n",
       "                     -3.71176035e-01, -3.74010156e-01, -3.74406711e-01, -3.74693449e-01,\n",
       "                     -3.77630309e-01, -3.84411699e-01, -3.93042588e-01, -4.05465108e-01,\n",
       "                     -4.05465108e-01, -4.18710335e-01, -4.21213465e-01, -4.22856851e-01,\n",
       "                     -4.24883194e-01, -4.28454626e-01, -4.35318071e-01, -4.36717652e-01,\n",
       "                     -4.38254931e-01, -4.41832752e-01, -4.46287103e-01, -4.50201002e-01,\n",
       "                     -4.51985124e-01, -4.53196511e-01, -4.56758402e-01, -4.59532329e-01,\n",
       "                     -4.65633630e-01, -4.70003629e-01, -4.79573080e-01, -4.89548225e-01,\n",
       "                     -4.95787746e-01, -4.98991166e-01, -5.08290768e-01, -5.10825624e-01,\n",
       "                     -5.28844129e-01, -5.38996501e-01, -5.38996501e-01, -5.59615788e-01,\n",
       "                     -5.67984038e-01, -5.70544858e-01, -5.73800423e-01, -5.75364145e-01,\n",
       "                     -5.76422906e-01, -5.79818495e-01, -5.87786665e-01, -5.90732175e-01,\n",
       "                     -5.93063722e-01, -5.94707108e-01, -6.04593783e-01, -6.06135804e-01,\n",
       "                     -6.09765572e-01, -6.10909082e-01, -6.13104473e-01, -6.15185639e-01,\n",
       "                     -6.16774202e-01, -6.19039208e-01, -6.28608659e-01, -6.32522559e-01,\n",
       "                     -6.35988767e-01, -6.40503447e-01, -6.41853886e-01, -6.59245629e-01,\n",
       "                     -6.59245629e-01, -6.61398482e-01, -6.66478933e-01, -6.93147181e-01,\n",
       "                     -7.20546155e-01, -7.25937003e-01, -7.28238500e-01, -7.28238500e-01,\n",
       "                     -7.47214402e-01, -7.48717032e-01, -7.53771802e-01, -7.57685702e-01,\n",
       "                     -7.62140052e-01, -7.73189888e-01, -7.75838896e-01, -7.77704569e-01,\n",
       "                     -7.80158558e-01, -7.82759339e-01, -7.84118959e-01, -7.88457360e-01,\n",
       "                     -7.88457360e-01, -7.90310929e-01, -8.02346473e-01, -8.04372816e-01,\n",
       "                     -8.07260487e-01, -8.10930216e-01, -8.20980552e-01, -8.25318954e-01,\n",
       "                     -8.26678573e-01, -8.28692673e-01, -8.32909123e-01, -8.36248024e-01,\n",
       "                     -8.47297860e-01, -8.47297860e-01, -8.75468737e-01, -8.75468737e-01,\n",
       "                     -8.89857475e-01, -9.16290732e-01, -9.20105104e-01, -9.34309237e-01,\n",
       "                     -9.39280250e-01, -9.49080555e-01, -9.65080896e-01, -9.80829253e-01,\n",
       "                     -9.88155293e-01, -9.98528830e-01, -1.00330211e+00, -1.00948451e+00,\n",
       "                     -1.01160091e+00, -1.01473080e+00, -1.02165125e+00, -1.02961942e+00,\n",
       "                     -1.03609193e+00, -1.03889305e+00, -1.04145387e+00, -1.05416053e+00,\n",
       "                     -1.06087196e+00, -1.06471074e+00, -1.06784063e+00, -1.07263680e+00,\n",
       "                     -1.09861229e+00, -1.09861229e+00, -1.12393010e+00, -1.14209740e+00,\n",
       "                     -1.15671992e+00, -1.16315081e+00, -1.16378192e+00, -1.16465570e+00,\n",
       "                     -1.17093295e+00, -1.17865500e+00, -1.18487263e+00, -1.18958407e+00,\n",
       "                     -1.19392247e+00, -1.20126644e+00, -1.20397280e+00, -1.21302264e+00,\n",
       "                     -1.21639532e+00, -1.23214368e+00, -1.25276297e+00, -1.27296568e+00,\n",
       "                     -1.29928298e+00, -1.30405626e+00, -1.30625165e+00, -1.32175584e+00,\n",
       "                     -1.33977435e+00, -1.34373475e+00, -1.34925309e+00, -1.35583515e+00,\n",
       "                     -1.35644140e+00, -1.35663815e+00, -1.37699197e+00, -1.38629436e+00,\n",
       "                     -1.39302839e+00, -1.42711636e+00, -1.45225233e+00, -1.45667516e+00,\n",
       "                     -1.46151778e+00, -1.49165488e+00, -1.50407740e+00, -1.52939520e+00,\n",
       "                     -1.54044504e+00, -1.57307027e+00, -1.58514522e+00, -1.59263079e+00,\n",
       "                     -1.59469563e+00, -1.59504917e+00, -1.60943791e+00, -1.60943791e+00,\n",
       "                     -1.63413053e+00, -1.64790419e+00, -1.64865863e+00, -1.65822808e+00,\n",
       "                     -1.67397643e+00, -1.68639895e+00, -1.69459572e+00, -1.70474809e+00,\n",
       "                     -1.70474809e+00, -1.71765150e+00, -1.73460106e+00, -1.78245708e+00,\n",
       "                     -1.79175947e+00, -1.79175947e+00, -1.87180218e+00, -1.90954250e+00,\n",
       "                     -1.92368701e+00, -1.94591015e+00, -1.98100147e+00, -2.00148000e+00,\n",
       "                     -2.01490302e+00, -2.07944154e+00, -2.11021320e+00, -2.19722458e+00,\n",
       "                     -2.56494936e+00, -2.63905733e+00, -2.70805020e+00, -2.83321334e+00,\n",
       "                     -2.94443898e+00, -2.97892516e+00, -2.99573227e+00, -4.11087386e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5258746445193216, privacy_risk=0.5184853638886402, accuracy=0.5184853638886402, tpr_ind=0.8360039387700295, tnr_ind=0.20096678900725093, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.06937606, 0.07913347, 0.0808343 , 0.08262465,\n",
       "                     0.08638439, 0.08781667, 0.08906991, 0.09453048, 0.09676842,\n",
       "                     0.09721601, 0.10052815, 0.10115478, 0.10545162, 0.11001701,\n",
       "                     0.11064363, 0.11422433, 0.11699937, 0.11986393, 0.120222  ,\n",
       "                     0.12604064, 0.13293349, 0.13499239, 0.1360666 , 0.13776743,\n",
       "                     0.14081103, 0.1488676 , 0.15155313, 0.15522335, 0.15790887,\n",
       "                     0.16587593, 0.16909856, 0.17294781, 0.17536478, 0.179035  ,\n",
       "                     0.18225763, 0.18941903, 0.19425298, 0.20239907, 0.20875481,\n",
       "                     0.21260406, 0.22737445, 0.23014949, 0.24411422, 0.25002238,\n",
       "                     0.25861606, 0.26112255, 0.26622505, 0.27902605, 0.2813535 ,\n",
       "                     0.28189061, 0.28636648, 0.30955152, 0.31429594, 0.31859278,\n",
       "                     0.33927133, 0.3467908 , 0.35162474, 0.35511593, 0.36505237,\n",
       "                     0.39146003, 0.39235521, 0.39575687, 0.40166503, 0.40291827,\n",
       "                     0.41768866, 0.41795721, 0.41947901, 0.42144839, 0.43219049,\n",
       "                     0.43371229, 0.44015755, 0.44203742, 0.44481246, 0.4521529 ,\n",
       "                     0.4542118 , 0.46567004, 0.46844508, 0.475696  , 0.47757587,\n",
       "                     0.48106705, 0.48670665, 0.49046639, 0.49735923, 0.50389401,\n",
       "                     0.50496822, 0.50613195, 0.51947006, 0.52179751, 0.53307672,\n",
       "                     0.53773163, 0.54757855, 0.54901083, 0.55491899, 0.5550085 ,\n",
       "                     0.55644078, 0.55706741, 0.55867872, 0.56064811, 0.56539253,\n",
       "                     0.56870468, 0.57139021, 0.57255393, 0.57774595, 0.57882016,\n",
       "                     0.5800734 , 0.58096858, 0.58257989, 0.58741384, 0.59278489,\n",
       "                     0.59770835, 0.60451168, 0.61471668, 0.61632799, 0.61838689,\n",
       "                     0.6225047 , 0.62698057, 0.63038224, 0.6409453 , 0.64291469,\n",
       "                     0.64622684, 0.64667442, 0.65043416, 0.65276161, 0.65696894,\n",
       "                     0.66404082, 0.66439889, 0.66645779, 0.66985946, 0.67147077,\n",
       "                     0.67335064, 0.67791603, 0.68087011, 0.68427178, 0.69859458,\n",
       "                     0.70235431, 0.70414466, 0.70656163, 0.70683019, 0.7079044 ,\n",
       "                     0.71193268, 0.71309641, 0.71399159, 0.72034733, 0.7248232 ,\n",
       "                     0.72544983, 0.72652404, 0.7278668 , 0.72867246, 0.73082088,\n",
       "                     0.73475965, 0.7421896 , 0.74639692, 0.74863486, 0.75069376,\n",
       "                     0.75149942, 0.75248411, 0.75928744, 0.76340525, 0.76734402,\n",
       "                     0.76850774, 0.77181989, 0.77513204, 0.77611673, 0.7779966 ,\n",
       "                     0.77924984, 0.78095068, 0.78336765, 0.78435234, 0.78614269,\n",
       "                     0.78793304, 0.7923194 , 0.79446782, 0.79518396, 0.79572106,\n",
       "                     0.79625817, 0.79661624, 0.79858562, 0.79992839, 0.80583654,\n",
       "                     0.81040193, 0.81648912, 0.81720526, 0.82338197, 0.82365052,\n",
       "                     0.82382956, 0.82687315, 0.83036434, 0.83233372, 0.83448214,\n",
       "                     0.83645153, 0.83698863, 0.84083788, 0.84307582, 0.84952108,\n",
       "                     0.85095336, 0.85345985, 0.85533972, 0.856772  , 0.86008415,\n",
       "                     0.86062125, 0.86706651, 0.86823024, 0.86840927, 0.86939397,\n",
       "                     0.87637633, 0.87682392, 0.87691344, 0.88004655, 0.88094172,\n",
       "                     0.88156835, 0.89231045, 0.89633873, 0.89741294, 0.89812908,\n",
       "                     0.90081461, 0.90788649, 0.91030346, 0.91182526, 0.91988184,\n",
       "                     0.92113508, 0.92185122, 0.92292543, 0.92731179, 0.92981828,\n",
       "                     0.93098201, 0.93447319, 0.93742727, 0.94297735, 0.94405156,\n",
       "                     0.94879599, 0.94978068, 0.95246621, 0.95524125, 0.95658401,\n",
       "                     0.95774774, 0.95891147, 0.95989616, 0.96034375, 0.9611494 ,\n",
       "                     0.96168651, 0.96249217, 0.96455107, 0.96508817, 0.96714708,\n",
       "                     0.96759466, 0.97090681, 0.97153343, 0.97198102, 0.97216006,\n",
       "                     0.97260764, 0.97466655, 0.97511413, 0.97520365, 0.9754722 ,\n",
       "                     0.97636738, 0.97735207, 0.97753111, 0.97824725, 0.9800376 ,\n",
       "                     0.98012711, 0.98146988, 0.98218602, 0.98245457, 0.98290216,\n",
       "                     0.98388685, 0.98433444, 0.98442395, 0.98531913, 0.98558768,\n",
       "                     1.        ]), tpr=array([0.        , 0.07913347, 0.08826426, 0.09041268, 0.09238206,\n",
       "                     0.0961418 , 0.09775311, 0.09909587, 0.1038403 , 0.1068839 ,\n",
       "                     0.10786859, 0.11198639, 0.11279205, 0.11977442, 0.12559305,\n",
       "                     0.12630919, 0.130427  , 0.13239638, 0.13499239, 0.13561901,\n",
       "                     0.14054248, 0.14868857, 0.15092651, 0.15253782, 0.15459672,\n",
       "                     0.15826694, 0.16766628, 0.17106794, 0.17509623, 0.17778176,\n",
       "                     0.18503267, 0.18986662, 0.19353684, 0.19568526, 0.19944499,\n",
       "                     0.20275714, 0.20956047, 0.21555814, 0.22531555, 0.2322084 ,\n",
       "                     0.23587861, 0.25261839, 0.25557246, 0.27070092, 0.27884701,\n",
       "                     0.28770925, 0.29030525, 0.29639244, 0.30919345, 0.31143138,\n",
       "                     0.31241608, 0.31581774, 0.33685436, 0.3401665 , 0.34580611,\n",
       "                     0.36702175, 0.3739146 , 0.37642109, 0.37982276, 0.39011727,\n",
       "                     0.41670397, 0.41822576, 0.42100081, 0.42726703, 0.42869931,\n",
       "                     0.44463343, 0.44543908, 0.44722943, 0.44955689, 0.4613732 ,\n",
       "                     0.46271596, 0.46871363, 0.47113061, 0.47372661, 0.48052994,\n",
       "                     0.48232029, 0.49386805, 0.49682213, 0.50461015, 0.50666905,\n",
       "                     0.51060782, 0.51606839, 0.51964909, 0.52663146, 0.53262913,\n",
       "                     0.53343479, 0.53424044, 0.54659386, 0.54847373, 0.55688837,\n",
       "                     0.56270701, 0.57497091, 0.57613463, 0.58034196, 0.5810581 ,\n",
       "                     0.58275893, 0.58374362, 0.58526542, 0.58705577, 0.59135261,\n",
       "                     0.59359055, 0.59627607, 0.59779787, 0.60182616, 0.6030794 ,\n",
       "                     0.60433265, 0.60594396, 0.60755528, 0.6117626 , 0.61704413,\n",
       "                     0.62277325, 0.62796527, 0.63745412, 0.63861785, 0.64058723,\n",
       "                     0.64461552, 0.64855429, 0.65213499, 0.66296661, 0.66618924,\n",
       "                     0.66994898, 0.67138126, 0.67433533, 0.67702086, 0.68212336,\n",
       "                     0.68991138, 0.69062752, 0.69152269, 0.69599857, 0.69707278,\n",
       "                     0.69823651, 0.70145914, 0.70324949, 0.70736729, 0.72186913,\n",
       "                     0.72589741, 0.72759825, 0.73064184, 0.73171605, 0.73270074,\n",
       "                     0.73672903, 0.73753469, 0.73816131, 0.74487512, 0.74917196,\n",
       "                     0.74961955, 0.7514099 , 0.75382687, 0.7549906 , 0.7580342 ,\n",
       "                     0.7606302 , 0.7693134 , 0.77217796, 0.77531107, 0.77844419,\n",
       "                     0.77996598, 0.78086116, 0.78811208, 0.79205085, 0.79500492,\n",
       "                     0.79634769, 0.80019694, 0.80324053, 0.80440426, 0.80556799,\n",
       "                     0.80646316, 0.80735834, 0.8102229 , 0.81129711, 0.81317698,\n",
       "                     0.81469877, 0.81756333, 0.81872706, 0.81971175, 0.82033838,\n",
       "                     0.82141259, 0.82186017, 0.82445618, 0.82517232, 0.83269179,\n",
       "                     0.83618297, 0.84119595, 0.84227016, 0.84925253, 0.84970012,\n",
       "                     0.8501477 , 0.85337033, 0.85704055, 0.85892042, 0.86178498,\n",
       "                     0.86384388, 0.86491809, 0.86894638, 0.87046818, 0.87637633,\n",
       "                     0.87727151, 0.88067317, 0.88192642, 0.88309014, 0.8859547 ,\n",
       "                     0.88658133, 0.89204189, 0.8931161 , 0.89392176, 0.89427983,\n",
       "                     0.90135171, 0.90197834, 0.90224689, 0.90466386, 0.90582759,\n",
       "                     0.90645421, 0.91710679, 0.9212246 , 0.92256736, 0.92355205,\n",
       "                     0.92623758, 0.93438367, 0.93653209, 0.93778534, 0.94566288,\n",
       "                     0.94691612, 0.94727419, 0.94807985, 0.95264524, 0.95479366,\n",
       "                     0.95568884, 0.95864291, 0.96123892, 0.96589383, 0.96678901,\n",
       "                     0.97171247, 0.97278668, 0.97475606, 0.97753111, 0.97923194,\n",
       "                     0.98111181, 0.98200698, 0.98299167, 0.98326023, 0.98352878,\n",
       "                     0.98442395, 0.98558768, 0.98728851, 0.98791514, 0.98881031,\n",
       "                     0.98952645, 0.99140632, 0.99212246, 0.99248053, 0.99274908,\n",
       "                     0.99310715, 0.9943604 , 0.99507654, 0.99516605, 0.99552412,\n",
       "                     0.99579268, 0.99632978, 0.9964193 , 0.99713544, 0.9979411 ,\n",
       "                     0.99803061, 0.9984782 , 0.99856772, 0.99883627, 0.99919434,\n",
       "                     0.99928386, 0.99937338, 0.99955241, 0.99973145, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.89875369e-02, -4.08219945e-02,\n",
       "                     -4.44517626e-02, -4.65200156e-02, -5.40672213e-02, -6.45385211e-02,\n",
       "                     -7.27593543e-02, -8.45573880e-02, -8.70113770e-02, -1.03184236e-01,\n",
       "                     -1.05360516e-01, -1.09199292e-01, -1.16072171e-01, -1.17783036e-01,\n",
       "                     -1.22602322e-01, -1.27833372e-01, -1.29211731e-01, -1.33531393e-01,\n",
       "                     -1.35801541e-01, -1.43100844e-01, -1.48420005e-01, -1.54150680e-01,\n",
       "                     -1.60342650e-01, -1.78248231e-01, -1.82321557e-01, -1.91055237e-01,\n",
       "                     -2.00670695e-01, -2.09720531e-01, -2.10721031e-01, -2.15708573e-01,\n",
       "                     -2.18253566e-01, -2.23143551e-01, -2.32622295e-01, -2.39229689e-01,\n",
       "                     -2.43977638e-01, -2.49654677e-01, -2.50294540e-01, -2.51314428e-01,\n",
       "                     -2.56719847e-01, -2.57829109e-01, -2.64692554e-01, -2.68263987e-01,\n",
       "                     -2.76632236e-01, -2.87682072e-01, -2.96265816e-01, -3.02280872e-01,\n",
       "                     -3.05013529e-01, -3.07484700e-01, -3.10154928e-01, -3.13657559e-01,\n",
       "                     -3.18066809e-01, -3.20907720e-01, -3.22773392e-01, -3.24953467e-01,\n",
       "                     -3.29023413e-01, -3.31357136e-01, -3.32705754e-01, -3.36472237e-01,\n",
       "                     -3.36953121e-01, -3.44840486e-01, -3.50202429e-01, -3.56674944e-01,\n",
       "                     -3.62905494e-01, -3.67292535e-01, -3.67724780e-01, -3.71563556e-01,\n",
       "                     -3.79489622e-01, -3.79888266e-01, -3.82992252e-01, -3.90427231e-01,\n",
       "                     -3.93042588e-01, -3.93904286e-01, -4.05465108e-01, -4.05465108e-01,\n",
       "                     -4.13187154e-01, -4.15515444e-01, -4.16893804e-01, -4.19853846e-01,\n",
       "                     -4.20502985e-01, -4.21725629e-01, -4.21994410e-01, -4.22414666e-01,\n",
       "                     -4.30036369e-01, -4.41832752e-01, -4.41832752e-01, -4.48024723e-01,\n",
       "                     -4.51985124e-01, -4.67340512e-01, -4.70003629e-01, -4.78181776e-01,\n",
       "                     -4.79573080e-01, -4.80585739e-01, -4.85507816e-01, -4.89548225e-01,\n",
       "                     -4.92476485e-01, -4.98991166e-01, -5.00775288e-01, -5.10825624e-01,\n",
       "                     -5.18793793e-01, -5.30628251e-01, -5.34082486e-01, -5.37142932e-01,\n",
       "                     -5.38996501e-01, -5.38996501e-01, -5.43615447e-01, -5.43615447e-01,\n",
       "                     -5.44301553e-01, -5.47435369e-01, -5.59615788e-01, -5.64529803e-01,\n",
       "                     -5.67669523e-01, -5.70544858e-01, -5.72519193e-01, -5.75364145e-01,\n",
       "                     -5.85258219e-01, -5.87786665e-01, -5.88704517e-01, -5.90868331e-01,\n",
       "                     -5.93063722e-01, -5.94707108e-01, -5.97837001e-01, -6.06135804e-01,\n",
       "                     -6.10909082e-01, -6.21688217e-01, -6.28608659e-01, -6.41853886e-01,\n",
       "                     -6.41853886e-01, -6.50587566e-01, -6.53926467e-01, -6.64976304e-01,\n",
       "                     -6.67829373e-01, -6.82218110e-01, -6.93147181e-01, -7.04197017e-01,\n",
       "                     -7.19122667e-01, -7.22134717e-01, -7.33969175e-01, -7.37598943e-01,\n",
       "                     -7.47214402e-01, -7.47214402e-01, -7.62140052e-01, -7.70108222e-01,\n",
       "                     -7.82759339e-01, -7.88457360e-01, -7.88457360e-01, -7.98507696e-01,\n",
       "                     -8.02346473e-01, -8.04372816e-01, -8.07091440e-01, -8.09784084e-01,\n",
       "                     -8.10930216e-01, -8.14099791e-01, -8.26678573e-01, -8.30348302e-01,\n",
       "                     -8.32909123e-01, -8.36659462e-01, -8.40783179e-01, -8.47297860e-01,\n",
       "                     -8.47297860e-01, -8.63772698e-01, -8.68088630e-01, -8.69037847e-01,\n",
       "                     -8.69037847e-01, -8.75468737e-01, -8.75468737e-01, -8.78069519e-01,\n",
       "                     -8.82389180e-01, -8.87303195e-01, -9.04456274e-01, -9.16290732e-01,\n",
       "                     -9.31558204e-01, -9.34309237e-01, -9.44461609e-01, -9.49080555e-01,\n",
       "                     -9.55511445e-01, -9.63437510e-01, -9.65080896e-01, -9.67345903e-01,\n",
       "                     -9.80829253e-01, -9.85283603e-01, -1.01160091e+00, -1.01856958e+00,\n",
       "                     -1.02961942e+00, -1.02961942e+00, -1.05121005e+00, -1.06555143e+00,\n",
       "                     -1.06635143e+00, -1.06686359e+00, -1.06919840e+00, -1.07044141e+00,\n",
       "                     -1.07613943e+00, -1.07880966e+00, -1.08334482e+00, -1.09861229e+00,\n",
       "                     -1.09861229e+00, -1.12214279e+00, -1.12393010e+00, -1.12938395e+00,\n",
       "                     -1.14513230e+00, -1.15181632e+00, -1.15267951e+00, -1.17007125e+00,\n",
       "                     -1.17865500e+00, -1.17962823e+00, -1.18958407e+00, -1.20397280e+00,\n",
       "                     -1.20397280e+00, -1.21924028e+00, -1.23214368e+00, -1.25156177e+00,\n",
       "                     -1.25276297e+00, -1.26224171e+00, -1.26566637e+00, -1.27163145e+00,\n",
       "                     -1.28215410e+00, -1.28785429e+00, -1.29276830e+00, -1.30031551e+00,\n",
       "                     -1.31218639e+00, -1.32175584e+00, -1.32913595e+00, -1.33603253e+00,\n",
       "                     -1.34373475e+00, -1.36097655e+00, -1.38629436e+00, -1.42019591e+00,\n",
       "                     -1.44691898e+00, -1.45861502e+00, -1.48160454e+00, -1.48538526e+00,\n",
       "                     -1.50407740e+00, -1.50765522e+00, -1.50990832e+00, -1.53018854e+00,\n",
       "                     -1.54756251e+00, -1.57239664e+00, -1.60943791e+00, -1.60943791e+00,\n",
       "                     -1.62924054e+00, -1.63974326e+00, -1.66073121e+00, -1.66500776e+00,\n",
       "                     -1.70474809e+00, -1.74919985e+00, -1.79175947e+00, -1.81237876e+00,\n",
       "                     -1.90954250e+00, -1.94591015e+00, -1.98100147e+00, -2.01490302e+00,\n",
       "                     -2.06369318e+00, -2.07944154e+00, -2.11021320e+00, -2.12026354e+00,\n",
       "                     -2.15948425e+00, -2.19722458e+00, -2.21101790e+00, -2.26868354e+00,\n",
       "                     -2.30258509e+00, -2.32238772e+00, -2.48490665e+00, -2.51230562e+00,\n",
       "                     -2.65675691e+00, -2.77258872e+00, -2.94443898e+00, -3.09104245e+00,\n",
       "                     -3.21887582e+00, -3.55534806e+00, -3.45387764e+01]), auc_score=0.5228470001352099, privacy_risk=0.5152627338644705, accuracy=0.5152627338644705, tpr_ind=0.3124160773431206, tnr_ind=0.7181093903858204, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.07510518, 0.07582132, 0.07805926, 0.07841733,\n",
       "                     0.081819  , 0.08253514, 0.08405693, 0.08853281, 0.08996509,\n",
       "                     0.09399338, 0.09676842, 0.1023185 , 0.10410885, 0.10643631,\n",
       "                     0.10804762, 0.11216543, 0.12210187, 0.12774147, 0.12818906,\n",
       "                     0.13024796, 0.13150121, 0.13624564, 0.14421269, 0.14564497,\n",
       "                     0.14725629, 0.18279474, 0.18315281, 0.18664399, 0.19040372,\n",
       "                     0.19461105, 0.19658043, 0.20445797, 0.20526363, 0.21224599,\n",
       "                     0.21699042, 0.24178677, 0.24599409, 0.25136514, 0.25610957,\n",
       "                     0.25852654, 0.26273386, 0.26864202, 0.28690359, 0.2915585 ,\n",
       "                     0.2936174 , 0.31107331, 0.31232656, 0.31841375, 0.32190493,\n",
       "                     0.3488497 , 0.34992391, 0.35260944, 0.35583207, 0.36424671,\n",
       "                     0.36899114, 0.37042342, 0.37463074, 0.37651061, 0.37964372,\n",
       "                     0.39172858, 0.39280279, 0.39441411, 0.40157551, 0.40345538,\n",
       "                     0.40497717, 0.40846836, 0.43917286, 0.44150031, 0.44445439,\n",
       "                     0.44651329, 0.45161579, 0.4613732 , 0.46996688, 0.47202578,\n",
       "                     0.47399517, 0.48160415, 0.48858652, 0.48921314, 0.49225674,\n",
       "                     0.49494226, 0.50246173, 0.5043416 , 0.50577388, 0.5120401 ,\n",
       "                     0.51418852, 0.51553129, 0.52126041, 0.53271865, 0.53343479,\n",
       "                     0.53746307, 0.54140184, 0.54739952, 0.54990601, 0.5508907 ,\n",
       "                     0.55303912, 0.55778355, 0.56745144, 0.57318056, 0.5774774 ,\n",
       "                     0.57873064, 0.57971533, 0.58320652, 0.58356459, 0.5846388 ,\n",
       "                     0.5923373 , 0.59779787, 0.59851401, 0.5994987 , 0.60290037,\n",
       "                     0.60988273, 0.62707009, 0.62805478, 0.6311879 , 0.6347686 ,\n",
       "                     0.63539522, 0.63593232, 0.64184048, 0.64980754, 0.65159789,\n",
       "                     0.65177692, 0.65482052, 0.65517859, 0.65732701, 0.65858025,\n",
       "                     0.66054964, 0.66314564, 0.66377227, 0.66592069, 0.67478292,\n",
       "                     0.67711038, 0.69850506, 0.70029541, 0.70835198, 0.71023185,\n",
       "                     0.71058992, 0.71211172, 0.71309641, 0.71390207, 0.71649808,\n",
       "                     0.71676663, 0.71837794, 0.71882553, 0.72007878, 0.72553934,\n",
       "                     0.73117895, 0.7314475 , 0.73162653, 0.7335064 , 0.73574434,\n",
       "                     0.73655   , 0.74738161, 0.75337929, 0.75409543, 0.7565124 ,\n",
       "                     0.75875034, 0.76045117, 0.76268911, 0.7672545 , 0.76761257,\n",
       "                     0.7677916 , 0.77011906, 0.77065616, 0.77181989, 0.77432638,\n",
       "                     0.77763853, 0.7821144 , 0.78766449, 0.78891773, 0.79097664,\n",
       "                     0.79357264, 0.79751141, 0.79751141, 0.79974935, 0.80162922,\n",
       "                     0.80234536, 0.81138663, 0.81469877, 0.81595202, 0.81747382,\n",
       "                     0.82168114, 0.82239728, 0.82311342, 0.82669412, 0.8281264 ,\n",
       "                     0.82991675, 0.83099096, 0.83331841, 0.8368096 , 0.83770477,\n",
       "                     0.83833139, 0.84253872, 0.84683556, 0.84880494, 0.84970012,\n",
       "                     0.85086384, 0.85122191, 0.86473906, 0.86715603, 0.86787217,\n",
       "                     0.86849879, 0.86885686, 0.8731537 , 0.87395936, 0.87422791,\n",
       "                     0.8803151 , 0.88156835, 0.88300063, 0.88416435, 0.88568615,\n",
       "                     0.88702891, 0.89016203, 0.89168382, 0.892579  , 0.89392176,\n",
       "                     0.90600662, 0.9084236 , 0.91021395, 0.91075105, 0.9161221 ,\n",
       "                     0.91630114, 0.91871811, 0.92337302, 0.92561096, 0.92695372,\n",
       "                     0.92758034, 0.92829648, 0.93071345, 0.93223525, 0.93948617,\n",
       "                     0.94091845, 0.9432459 , 0.94387253, 0.94709516, 0.94718467,\n",
       "                     0.94906454, 0.95237669, 0.95416704, 0.95434607, 0.9549727 ,\n",
       "                     0.96508817, 0.96607287, 0.96669949, 0.9683108 , 0.96920598,\n",
       "                     0.96947453, 0.96965357, 0.96992212, 0.97001164, 0.97260764,\n",
       "                     0.97421896, 0.97448751, 0.97502462, 0.97583027, 0.97583027,\n",
       "                     0.97753111, 0.97869483, 0.9790529 , 0.97923194, 0.98012711,\n",
       "                     0.98093277, 0.98146988, 0.98164891, 0.98164891, 0.98290216,\n",
       "                     0.98290216, 1.        ]), tpr=array([0.        , 0.08701101, 0.08862233, 0.09130785, 0.0925611 ,\n",
       "                     0.0961418 , 0.09730552, 0.09829022, 0.10213947, 0.10303464,\n",
       "                     0.10563065, 0.10813714, 0.11690986, 0.11843165, 0.12066959,\n",
       "                     0.12281801, 0.12595112, 0.13481336, 0.14340704, 0.14394414,\n",
       "                     0.14698774, 0.1488676 , 0.15379107, 0.16256378, 0.16453317,\n",
       "                     0.16641303, 0.20275714, 0.20418942, 0.20732253, 0.21197744,\n",
       "                     0.21824367, 0.22021305, 0.23131322, 0.23292454, 0.24089159,\n",
       "                     0.24662071, 0.27141706, 0.27580342, 0.28269627, 0.28717214,\n",
       "                     0.29012622, 0.29540775, 0.30051025, 0.31769761, 0.3217259 ,\n",
       "                     0.32297914, 0.3381076 , 0.34007699, 0.34607466, 0.35108764,\n",
       "                     0.37865903, 0.38027034, 0.38232925, 0.38528332, 0.39360845,\n",
       "                     0.39808433, 0.40005371, 0.40354489, 0.40658849, 0.4091845 ,\n",
       "                     0.42064274, 0.42171695, 0.42341778, 0.43138484, 0.43389133,\n",
       "                     0.43532361, 0.43979948, 0.47130964, 0.47292096, 0.47551696,\n",
       "                     0.47865008, 0.48330499, 0.49485274, 0.50326739, 0.50478919,\n",
       "                     0.50649002, 0.51544177, 0.52260317, 0.52385641, 0.52824277,\n",
       "                     0.53083878, 0.53871632, 0.54104377, 0.54283412, 0.55026408,\n",
       "                     0.55268105, 0.55411333, 0.55912631, 0.57273297, 0.57318056,\n",
       "                     0.57711933, 0.58016292, 0.58804046, 0.59072599, 0.59224778,\n",
       "                     0.59430669, 0.59967774, 0.6081819 , 0.61265777, 0.61579089,\n",
       "                     0.61784979, 0.61874496, 0.62152001, 0.62214663, 0.62277325,\n",
       "                     0.62948706, 0.63342583, 0.6347686 , 0.63646943, 0.63897592,\n",
       "                     0.64622684, 0.66144481, 0.66225047, 0.66404082, 0.66645779,\n",
       "                     0.66744249, 0.66797959, 0.67433533, 0.68140722, 0.68328708,\n",
       "                     0.68400322, 0.68624116, 0.68704682, 0.69044848, 0.69232835,\n",
       "                     0.69340256, 0.6956405 , 0.69680423, 0.69931072, 0.70772536,\n",
       "                     0.70960523, 0.72750873, 0.72929908, 0.73726614, 0.73959359,\n",
       "                     0.7406678 , 0.7427267 , 0.7437114 , 0.74541223, 0.74845582,\n",
       "                     0.74917196, 0.75114135, 0.75176797, 0.75337929, 0.75937696,\n",
       "                     0.76474801, 0.7651956 , 0.76600125, 0.76797064, 0.76940292,\n",
       "                     0.77002954, 0.78166682, 0.78712738, 0.78739594, 0.78900725,\n",
       "                     0.7902605 , 0.79124519, 0.79410975, 0.79894369, 0.79939128,\n",
       "                     0.79983887, 0.80180825, 0.80243488, 0.80386716, 0.80601558,\n",
       "                     0.80905917, 0.81478829, 0.81836899, 0.81971175, 0.82069645,\n",
       "                     0.82239728, 0.82687315, 0.82732074, 0.82920061, 0.83161758,\n",
       "                     0.83188613, 0.83994271, 0.84280727, 0.84361293, 0.84495569,\n",
       "                     0.84907349, 0.85005819, 0.85131143, 0.85542924, 0.856772  ,\n",
       "                     0.85900994, 0.85963656, 0.86321726, 0.86760362, 0.86840927,\n",
       "                     0.86912541, 0.87306418, 0.87843523, 0.88058365, 0.88201593,\n",
       "                     0.88317966, 0.8838958 , 0.89786053, 0.89982992, 0.90045654,\n",
       "                     0.90099364, 0.90153075, 0.90493241, 0.90564855, 0.90609614,\n",
       "                     0.91084057, 0.91191478, 0.91316802, 0.9146003 , 0.91540596,\n",
       "                     0.91719631, 0.92050846, 0.92167219, 0.92247784, 0.92310447,\n",
       "                     0.9334885 , 0.93536836, 0.9376063 , 0.93832244, 0.94378301,\n",
       "                     0.9442306 , 0.94566288, 0.95157103, 0.95327186, 0.95488318,\n",
       "                     0.95577835, 0.95712112, 0.95918002, 0.96043326, 0.96750515,\n",
       "                     0.96911646, 0.9713544 , 0.97180199, 0.97484558, 0.97538269,\n",
       "                     0.97708352, 0.97833676, 0.97914242, 0.97941097, 0.97950049,\n",
       "                     0.98854176, 0.98898935, 0.98943693, 0.9913168 , 0.99221198,\n",
       "                     0.99230149, 0.99265956, 0.99319667, 0.99328619, 0.99471847,\n",
       "                     0.99606123, 0.99650882, 0.99677737, 0.99704592, 0.99722496,\n",
       "                     0.99820965, 0.9984782 , 0.99874675, 0.99883627, 0.99919434,\n",
       "                     0.99928386, 0.99937338, 0.99964193, 0.99973145, 0.99991048,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.40672213e-02, -6.45385211e-02,\n",
       "                     -6.89928715e-02, -7.23206616e-02, -7.41079722e-02, -8.70113770e-02,\n",
       "                     -8.89474860e-02, -9.53101798e-02, -9.84400728e-02, -1.01782694e-01,\n",
       "                     -1.06380404e-01, -1.11225635e-01, -1.13328685e-01, -1.17783036e-01,\n",
       "                     -1.33531393e-01, -1.41078598e-01, -1.54150680e-01, -1.54150680e-01,\n",
       "                     -1.62518929e-01, -1.74353387e-01, -1.82321557e-01, -1.94156014e-01,\n",
       "                     -2.04794413e-01, -2.13574100e-01, -2.22157844e-01, -2.23143551e-01,\n",
       "                     -2.28841572e-01, -2.38411023e-01, -2.40141128e-01, -2.41162057e-01,\n",
       "                     -2.42313467e-01, -2.45122458e-01, -2.47562079e-01, -2.47836164e-01,\n",
       "                     -2.50913225e-01, -2.51314428e-01, -2.61364764e-01, -2.62364264e-01,\n",
       "                     -2.64692554e-01, -2.66267978e-01, -2.87682072e-01, -2.95464213e-01,\n",
       "                     -3.04211374e-01, -3.05381650e-01, -3.08180594e-01, -3.10154928e-01,\n",
       "                     -3.17095958e-01, -3.18453731e-01, -3.19633672e-01, -3.28504067e-01,\n",
       "                     -3.30241687e-01, -3.32133835e-01, -3.34934957e-01, -3.36472237e-01,\n",
       "                     -3.42944751e-01, -3.43771539e-01, -3.44840486e-01, -3.46276237e-01,\n",
       "                     -3.46466767e-01, -3.48306694e-01, -3.51397887e-01, -3.55550717e-01,\n",
       "                     -3.56674944e-01, -3.62905494e-01, -3.64643114e-01, -3.66850272e-01,\n",
       "                     -3.67724780e-01, -3.70373788e-01, -3.76477571e-01, -3.79489622e-01,\n",
       "                     -3.81934611e-01, -3.83958903e-01, -3.85662481e-01, -3.87765531e-01,\n",
       "                     -3.98776120e-01, -4.05465108e-01, -4.05465108e-01, -4.12244795e-01,\n",
       "                     -4.16893804e-01, -4.20502985e-01, -4.30782916e-01, -4.38254931e-01,\n",
       "                     -4.40971797e-01, -4.41832752e-01, -4.46287103e-01, -4.51985124e-01,\n",
       "                     -4.65057205e-01, -4.70003629e-01, -4.78490243e-01, -4.80972661e-01,\n",
       "                     -4.85507816e-01, -4.90622916e-01, -4.98991166e-01, -5.02091944e-01,\n",
       "                     -5.10825624e-01, -5.15027311e-01, -5.18793793e-01, -5.22189382e-01,\n",
       "                     -5.28067430e-01, -5.30628251e-01, -5.36304709e-01, -5.38996501e-01,\n",
       "                     -5.38996501e-01, -5.42324291e-01, -5.46543706e-01, -5.50046337e-01,\n",
       "                     -5.52068582e-01, -5.59615788e-01, -5.61377903e-01, -5.67984038e-01,\n",
       "                     -5.75364145e-01, -5.87786665e-01, -5.95983432e-01, -5.97837001e-01,\n",
       "                     -6.06135804e-01, -6.12517446e-01, -6.14158769e-01, -6.19039208e-01,\n",
       "                     -6.28608659e-01, -6.31271777e-01, -6.35988767e-01, -6.39079959e-01,\n",
       "                     -6.44357016e-01, -6.50587566e-01, -6.52325186e-01, -6.53926467e-01,\n",
       "                     -6.56779536e-01, -6.66191371e-01, -6.69049629e-01, -6.93147181e-01,\n",
       "                     -7.17839793e-01, -7.20849783e-01, -7.30887509e-01, -7.33969175e-01,\n",
       "                     -7.35706795e-01, -7.37598943e-01, -7.44440475e-01, -7.50305594e-01,\n",
       "                     -7.53771802e-01, -7.59105148e-01, -7.62140052e-01, -7.73189888e-01,\n",
       "                     -7.78914002e-01, -7.80852761e-01, -7.88457360e-01, -7.98507696e-01,\n",
       "                     -8.00777845e-01, -8.10930216e-01, -8.26678573e-01, -8.36248024e-01,\n",
       "                     -8.44953193e-01, -8.47297860e-01, -8.47297860e-01, -8.57450232e-01,\n",
       "                     -8.60201265e-01, -8.64997437e-01, -8.70828358e-01, -8.75468737e-01,\n",
       "                     -8.75468737e-01, -8.79249460e-01, -8.87303195e-01, -8.90972924e-01,\n",
       "                     -8.99483614e-01, -9.04456274e-01, -9.10021119e-01, -9.16290732e-01,\n",
       "                     -9.29535959e-01, -9.34309237e-01, -9.47381319e-01, -9.55511445e-01,\n",
       "                     -9.55511445e-01, -9.62810748e-01, -9.66843011e-01, -9.80829253e-01,\n",
       "                     -9.89128056e-01, -1.01160091e+00, -1.02165125e+00, -1.02961942e+00,\n",
       "                     -1.03117101e+00, -1.03609193e+00, -1.04982212e+00, -1.06919840e+00,\n",
       "                     -1.07613943e+00, -1.08518927e+00, -1.09861229e+00, -1.09861229e+00,\n",
       "                     -1.11212601e+00, -1.13497993e+00, -1.13943428e+00, -1.14306405e+00,\n",
       "                     -1.14740245e+00, -1.15267951e+00, -1.15923691e+00, -1.17272026e+00,\n",
       "                     -1.17865500e+00, -1.18062544e+00, -1.18562367e+00, -1.18958407e+00,\n",
       "                     -1.20397280e+00, -1.20397280e+00, -1.20660093e+00, -1.21639532e+00,\n",
       "                     -1.22377543e+00, -1.22820512e+00, -1.22866542e+00, -1.23214368e+00,\n",
       "                     -1.23474446e+00, -1.23676263e+00, -1.25276297e+00, -1.25661654e+00,\n",
       "                     -1.26369204e+00, -1.26851133e+00, -1.27296568e+00, -1.29614326e+00,\n",
       "                     -1.29928298e+00, -1.30291275e+00, -1.32175584e+00, -1.32720544e+00,\n",
       "                     -1.33500107e+00, -1.33828514e+00, -1.36330484e+00, -1.38629436e+00,\n",
       "                     -1.45343366e+00, -1.45861502e+00, -1.46633707e+00, -1.46967597e+00,\n",
       "                     -1.50407740e+00, -1.50548288e+00, -1.51634749e+00, -1.51732262e+00,\n",
       "                     -1.52605630e+00, -1.53623451e+00, -1.54044504e+00, -1.54419739e+00,\n",
       "                     -1.55059741e+00, -1.58696506e+00, -1.60943791e+00, -1.60943791e+00,\n",
       "                     -1.61339049e+00, -1.64865863e+00, -1.68639895e+00, -1.73460106e+00,\n",
       "                     -1.79175947e+00, -1.79175947e+00, -1.83258146e+00, -1.89711998e+00,\n",
       "                     -1.94591015e+00, -1.94591015e+00, -2.02814825e+00, -2.07944154e+00,\n",
       "                     -2.19722458e+00, -2.23359222e+00, -2.25129180e+00, -2.29345261e+00,\n",
       "                     -2.33537492e+00, -2.36712361e+00, -2.39789527e+00, -2.46385324e+00,\n",
       "                     -2.48490665e+00, -2.63905733e+00, -2.66258783e+00, -2.70805020e+00,\n",
       "                     -2.77258872e+00, -2.94443898e+00, -3.45387764e+01]), auc_score=0.5274713391142573, privacy_risk=0.5209470951571031, accuracy=0.5209470951571032, tpr_ind=0.599677736997583, tnr_ind=0.4422164533166234, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.07277773, 0.0767165 , 0.07967058, 0.08208755,\n",
       "                     0.08405693, 0.08584728, 0.08656342, 0.08889088, 0.09059171,\n",
       "                     0.09363531, 0.09479903, 0.10133381, 0.10410885, 0.10607824,\n",
       "                     0.130427  , 0.13320204, 0.13893116, 0.14215379, 0.14582401,\n",
       "                     0.14716677, 0.15217975, 0.15540238, 0.15611852, 0.16184764,\n",
       "                     0.16444365, 0.17205264, 0.17402202, 0.17831886, 0.18351088,\n",
       "                     0.20508459, 0.2169009 , 0.21931788, 0.22988094, 0.23301405,\n",
       "                     0.2419658 , 0.24357712, 0.24832155, 0.25324501, 0.25476681,\n",
       "                     0.25995882, 0.26318145, 0.26470325, 0.26810491, 0.27123803,\n",
       "                     0.27902605, 0.28726166, 0.28994718, 0.29325933, 0.29522872,\n",
       "                     0.29782472, 0.3330051 , 0.33613822, 0.3375705 , 0.35592158,\n",
       "                     0.36245636, 0.3662161 , 0.36845403, 0.37051294, 0.38215021,\n",
       "                     0.39020679, 0.39262376, 0.39674156, 0.39933757, 0.40748366,\n",
       "                     0.41204906, 0.41401844, 0.4184048 , 0.42082177, 0.42574523,\n",
       "                     0.43872527, 0.45197386, 0.45394325, 0.46575956, 0.46808701,\n",
       "                     0.49145108, 0.49252529, 0.50317787, 0.50711664, 0.50828037,\n",
       "                     0.51517322, 0.51911199, 0.52152896, 0.52197655, 0.52269269,\n",
       "                     0.53003312, 0.53182347, 0.53916391, 0.54390833, 0.54659386,\n",
       "                     0.54793662, 0.54963745, 0.55778355, 0.5621699 , 0.56897323,\n",
       "                     0.57174828, 0.57318056, 0.57380718, 0.58070003, 0.59224778,\n",
       "                     0.59341151, 0.59636559, 0.59878256, 0.60048339, 0.60263181,\n",
       "                     0.60495927, 0.60880852, 0.61731268, 0.61874496, 0.61990869,\n",
       "                     0.62626443, 0.62742816, 0.62894996, 0.63056127, 0.63270969,\n",
       "                     0.63503715, 0.64273565, 0.64667442, 0.65249306, 0.65813266,\n",
       "                     0.6624295 , 0.66332468, 0.66806911, 0.66860621, 0.67254498,\n",
       "                     0.67487244, 0.67907976, 0.69071704, 0.69904216, 0.70539791,\n",
       "                     0.70960523, 0.71067944, 0.71479724, 0.71578194, 0.71775132,\n",
       "                     0.72079492, 0.72536031, 0.72759825, 0.73529675, 0.73655   ,\n",
       "                     0.73869842, 0.74039925, 0.74227912, 0.74290574, 0.74720258,\n",
       "                     0.74917196, 0.74953003, 0.75382687, 0.7580342 , 0.75901889,\n",
       "                     0.75982455, 0.76134634, 0.76224152, 0.76456897, 0.76626981,\n",
       "                     0.76797064, 0.77504252, 0.77862322, 0.77924984, 0.78032405,\n",
       "                     0.78229344, 0.78632173, 0.7887387 , 0.79312506, 0.79393071,\n",
       "                     0.79428878, 0.79563155, 0.79876466, 0.8030615 , 0.8035986 ,\n",
       "                     0.80700027, 0.80762689, 0.80798496, 0.80888014, 0.8102229 ,\n",
       "                     0.81389312, 0.81425119, 0.8173843 , 0.82239728, 0.8230239 ,\n",
       "                     0.83197565, 0.83287083, 0.83868946, 0.84253872, 0.84790977,\n",
       "                     0.85632441, 0.85784621, 0.85936801, 0.8639334 , 0.86527616,\n",
       "                     0.8659923 , 0.86984155, 0.87198997, 0.87306418, 0.87333274,\n",
       "                     0.87485453, 0.87727151, 0.88165786, 0.88228449, 0.88317966,\n",
       "                     0.88461194, 0.88711843, 0.89696536, 0.89777101, 0.89893474,\n",
       "                     0.91263092, 0.91343658, 0.91397368, 0.91567451, 0.91701728,\n",
       "                     0.92006087, 0.92516337, 0.92650613, 0.92793841, 0.92811745,\n",
       "                     0.9299078 , 0.93214573, 0.9325038 , 0.9334885 , 0.93536836,\n",
       "                     0.93599499, 0.93930713, 0.94038134, 0.94109748, 0.94602095,\n",
       "                     0.94664757, 0.94960165, 0.9575687 , 0.95918002, 0.96052278,\n",
       "                     0.96088085, 0.96311879, 0.96383493, 0.96526721, 0.96535673,\n",
       "                     0.96562528, 0.96687852, 0.96768418, 0.96848984, 0.96974308,\n",
       "                     0.97224957, 0.97305523, 0.97717304, 0.97896339, 0.97914242,\n",
       "                     0.98120132, 0.98155939, 0.98254409, 0.98317071, 0.9836183 ,\n",
       "                     0.9836183 , 0.98406588, 0.98460299, 0.98487154, 0.98558768,\n",
       "                     0.98585623, 1.        ]), tpr=array([0.        , 0.08307224, 0.08710053, 0.08960702, 0.09193447,\n",
       "                     0.09408289, 0.09712649, 0.09802166, 0.10052815, 0.10294513,\n",
       "                     0.10760004, 0.10903232, 0.11377674, 0.11646227, 0.11896876,\n",
       "                     0.14224331, 0.14555546, 0.15253782, 0.15620804, 0.15880405,\n",
       "                     0.16086295, 0.16650255, 0.17053084, 0.17151553, 0.17831886,\n",
       "                     0.1810939 , 0.18834482, 0.19013517, 0.19434249, 0.19935547,\n",
       "                     0.22110823, 0.23167129, 0.23435682, 0.24626264, 0.25020141,\n",
       "                     0.25789992, 0.25977979, 0.26470325, 0.26900009, 0.26989526,\n",
       "                     0.27481873, 0.27884701, 0.28027929, 0.28341241, 0.28699311,\n",
       "                     0.29773521, 0.30758213, 0.31071524, 0.31474353, 0.31671292,\n",
       "                     0.31984603, 0.35762242, 0.36120312, 0.36308298, 0.38098648,\n",
       "                     0.38850595, 0.39163907, 0.39441411, 0.39611494, 0.40587235,\n",
       "                     0.41383941, 0.41759914, 0.42126936, 0.42368633, 0.43183242,\n",
       "                     0.43487602, 0.43693492, 0.44212694, 0.44526005, 0.45018351,\n",
       "                     0.46405872, 0.4762331 , 0.4798138 , 0.4920777 , 0.49485274,\n",
       "                     0.51588936, 0.51794826, 0.52869036, 0.5335243 , 0.53468803,\n",
       "                     0.54184943, 0.54444544, 0.54605675, 0.54668338, 0.54775759,\n",
       "                     0.55536657, 0.55697789, 0.56512398, 0.57004744, 0.57318056,\n",
       "                     0.57416525, 0.57541849, 0.58222182, 0.58571301, 0.59144213,\n",
       "                     0.59403813, 0.59520186, 0.59636559, 0.6025423 , 0.61444812,\n",
       "                     0.61570137, 0.61883448, 0.62277325, 0.62411601, 0.62581685,\n",
       "                     0.62903948, 0.63414197, 0.64166144, 0.64282517, 0.64443649,\n",
       "                     0.65034464, 0.65204547, 0.65383582, 0.65589473, 0.65858025,\n",
       "                     0.6603706 , 0.66896428, 0.67272402, 0.67845314, 0.68292901,\n",
       "                     0.68525647, 0.68686778, 0.69295497, 0.69393967, 0.69814699,\n",
       "                     0.70262286, 0.70888909, 0.72142154, 0.72759825, 0.73180557,\n",
       "                     0.73574434, 0.73663951, 0.74210008, 0.74353236, 0.74559126,\n",
       "                     0.74953003, 0.7544535 , 0.75767613, 0.76501656, 0.76653836,\n",
       "                     0.7687763 , 0.77047713, 0.77190941, 0.77325217, 0.77790708,\n",
       "                     0.77916033, 0.7800555 , 0.78578462, 0.78963387, 0.79043953,\n",
       "                     0.79205085, 0.79330409, 0.79428878, 0.79715334, 0.79939128,\n",
       "                     0.80028646, 0.80861158, 0.81290842, 0.81371408, 0.81451974,\n",
       "                     0.81631009, 0.82024886, 0.82257631, 0.82696267, 0.82776833,\n",
       "                     0.82839495, 0.83036434, 0.83340793, 0.83842091, 0.8394056 ,\n",
       "                     0.843971  , 0.84459762, 0.84495569, 0.84585086, 0.84728314,\n",
       "                     0.85122191, 0.85184854, 0.85444454, 0.86008415, 0.86115836,\n",
       "                     0.87207949, 0.87351177, 0.87968848, 0.88147883, 0.88756602,\n",
       "                     0.89445887, 0.89687584, 0.89839764, 0.90090413, 0.90188882,\n",
       "                     0.9033211 , 0.90708083, 0.90815504, 0.90976636, 0.91003491,\n",
       "                     0.91137767, 0.91477934, 0.91889714, 0.91961328, 0.92077701,\n",
       "                     0.92203026, 0.92498433, 0.9319667 , 0.93268284, 0.9340256 ,\n",
       "                     0.94816937, 0.94933309, 0.95004923, 0.95148151, 0.95255572,\n",
       "                     0.95586787, 0.95944857, 0.9606123 , 0.96159699, 0.96204458,\n",
       "                     0.96329782, 0.96481962, 0.96508817, 0.96634142, 0.9677737 ,\n",
       "                     0.9683108 , 0.97045922, 0.97108585, 0.97144392, 0.97430848,\n",
       "                     0.9749351 , 0.97735207, 0.98218602, 0.98326023, 0.9841554 ,\n",
       "                     0.98451347, 0.98594575, 0.98648286, 0.9877361 , 0.98791514,\n",
       "                     0.98863128, 0.98961597, 0.98997404, 0.99042163, 0.99104825,\n",
       "                     0.99221198, 0.99274908, 0.99650882, 0.99686689, 0.99722496,\n",
       "                     0.99785158, 0.99803061, 0.99856772, 0.99883627, 0.99910482,\n",
       "                     0.99919434, 0.99946289, 0.99964193, 0.99982096, 0.99991048,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.19789067e-02, -3.50913198e-02,\n",
       "                     -7.41079722e-02, -8.00427077e-02, -8.45573880e-02, -9.53101798e-02,\n",
       "                     -1.01782694e-01, -1.05360516e-01, -1.09199292e-01, -1.17783036e-01,\n",
       "                     -1.24052649e-01, -1.25163143e-01, -1.33531393e-01, -1.49745386e-01,\n",
       "                     -1.50282203e-01, -1.54150680e-01, -1.57628944e-01, -1.59064695e-01,\n",
       "                     -1.60342650e-01, -1.60930367e-01, -1.63629424e-01, -1.67054085e-01,\n",
       "                     -1.69076330e-01, -1.76930708e-01, -1.80261824e-01, -1.82321557e-01,\n",
       "                     -1.92903666e-01, -1.94156014e-01, -2.00670695e-01, -2.06049118e-01,\n",
       "                     -2.09720531e-01, -2.15596346e-01, -2.23143551e-01, -2.46133070e-01,\n",
       "                     -2.51314428e-01, -2.55346692e-01, -2.55933374e-01, -2.62364264e-01,\n",
       "                     -2.69332934e-01, -2.70874954e-01, -2.71933715e-01, -2.73293335e-01,\n",
       "                     -2.81412459e-01, -2.87682072e-01, -2.89952221e-01, -2.94799540e-01,\n",
       "                     -3.04211374e-01, -3.10154928e-01, -3.15852949e-01, -3.18022790e-01,\n",
       "                     -3.18453731e-01, -3.22773392e-01, -3.29303747e-01, -3.31357136e-01,\n",
       "                     -3.36472237e-01, -3.50202429e-01, -3.51397887e-01, -3.52077235e-01,\n",
       "                     -3.55550717e-01, -3.56674944e-01, -3.63965377e-01, -3.67724780e-01,\n",
       "                     -3.79489622e-01, -3.85662481e-01, -3.90866309e-01, -3.93904286e-01,\n",
       "                     -3.95895657e-01, -3.99386062e-01, -4.03312255e-01, -4.05465108e-01,\n",
       "                     -4.05465108e-01, -4.07895243e-01, -4.16160397e-01, -4.18150268e-01,\n",
       "                     -4.19853846e-01, -4.21994410e-01, -4.29856561e-01, -4.30782916e-01,\n",
       "                     -4.38254931e-01, -4.39366660e-01, -4.41832752e-01, -4.51985124e-01,\n",
       "                     -4.59532329e-01, -4.70003629e-01, -4.76924072e-01, -4.79573080e-01,\n",
       "                     -4.81303184e-01, -4.87703206e-01, -4.92476485e-01, -4.96436886e-01,\n",
       "                     -4.97580397e-01, -5.10825624e-01, -5.23248144e-01, -5.24524468e-01,\n",
       "                     -5.26093096e-01, -5.26093096e-01, -5.28067430e-01, -5.30185871e-01,\n",
       "                     -5.38996501e-01, -5.38996501e-01, -5.46543706e-01, -5.50046337e-01,\n",
       "                     -5.52068582e-01, -5.59615788e-01, -5.62118918e-01, -5.66395475e-01,\n",
       "                     -5.70544858e-01, -5.75364145e-01, -5.81029882e-01, -5.81921545e-01,\n",
       "                     -5.87786665e-01, -6.02175402e-01, -6.06135804e-01, -6.15185639e-01,\n",
       "                     -6.17435359e-01, -6.19039208e-01, -6.20240410e-01, -6.31271777e-01,\n",
       "                     -6.33723760e-01, -6.35988767e-01, -6.40304699e-01, -6.46627165e-01,\n",
       "                     -6.60711905e-01, -6.62687973e-01, -6.85978691e-01, -6.93147181e-01,\n",
       "                     -7.00367429e-01, -7.24563377e-01, -7.26669873e-01, -7.41937345e-01,\n",
       "                     -7.48938540e-01, -7.53771802e-01, -7.56326082e-01, -7.59105148e-01,\n",
       "                     -7.71790308e-01, -7.73189888e-01, -7.75064303e-01, -7.77704569e-01,\n",
       "                     -7.88457360e-01, -7.93230639e-01, -8.10930216e-01, -8.18310324e-01,\n",
       "                     -8.19440906e-01, -8.26678573e-01, -8.32909123e-01, -8.38329190e-01,\n",
       "                     -8.43970070e-01, -8.47297860e-01, -8.47297860e-01, -8.57450232e-01,\n",
       "                     -8.60201265e-01, -8.64997437e-01, -8.75468737e-01, -8.75468737e-01,\n",
       "                     -8.87935506e-01, -8.90972924e-01, -8.93817876e-01, -8.93817876e-01,\n",
       "                     -8.96088025e-01, -8.97941593e-01, -9.16290732e-01, -9.36493439e-01,\n",
       "                     -9.38269639e-01, -9.44461609e-01, -9.52008814e-01, -9.62275845e-01,\n",
       "                     -9.65080896e-01, -9.69400557e-01, -9.80829253e-01, -9.98528830e-01,\n",
       "                     -1.01160091e+00, -1.02961942e+00, -1.03407377e+00, -1.03609193e+00,\n",
       "                     -1.04982212e+00, -1.05154478e+00, -1.06635143e+00, -1.07044141e+00,\n",
       "                     -1.07371474e+00, -1.07755888e+00, -1.09376966e+00, -1.09861229e+00,\n",
       "                     -1.09861229e+00, -1.10293195e+00, -1.11088238e+00, -1.11803037e+00,\n",
       "                     -1.12214279e+00, -1.12846525e+00, -1.13943428e+00, -1.15267951e+00,\n",
       "                     -1.17865500e+00, -1.18716569e+00, -1.20397280e+00, -1.20397280e+00,\n",
       "                     -1.20660093e+00, -1.21478372e+00, -1.21639532e+00, -1.21924028e+00,\n",
       "                     -1.25276297e+00, -1.26566637e+00, -1.27091229e+00, -1.28785429e+00,\n",
       "                     -1.29928298e+00, -1.30043307e+00, -1.30625165e+00, -1.32175584e+00,\n",
       "                     -1.33828514e+00, -1.36524095e+00, -1.37951467e+00, -1.38629436e+00,\n",
       "                     -1.40534256e+00, -1.43074612e+00, -1.43508453e+00, -1.43848011e+00,\n",
       "                     -1.44345277e+00, -1.46633707e+00, -1.48807706e+00, -1.49009115e+00,\n",
       "                     -1.50407740e+00, -1.52242654e+00, -1.60943791e+00, -1.60943791e+00,\n",
       "                     -1.64020957e+00, -1.66500776e+00, -1.68089688e+00, -1.70474809e+00,\n",
       "                     -1.73460106e+00, -1.74046617e+00, -1.79175947e+00, -1.80212226e+00,\n",
       "                     -1.81915844e+00, -1.86075234e+00, -1.87180218e+00, -1.89085037e+00,\n",
       "                     -1.90616982e+00, -1.90954250e+00, -1.91692261e+00, -1.92529086e+00,\n",
       "                     -1.94591015e+00, -1.96944065e+00, -1.97275740e+00, -2.07944154e+00,\n",
       "                     -2.14006616e+00, -2.14843441e+00, -2.19722458e+00, -2.26868354e+00,\n",
       "                     -2.30258509e+00, -2.33537492e+00, -2.39789527e+00, -2.51230562e+00,\n",
       "                     -2.56494936e+00, -2.63905733e+00, -3.36729583e+00, -3.82864140e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5232282528547015, privacy_risk=0.5204995076537463, accuracy=0.5204995076537463, tpr_ind=0.8796884790976636, tnr_ind=0.16131053620982902, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.07197207, 0.0823561 , 0.09112882, 0.09327724,\n",
       "                     0.09954346, 0.10724197, 0.10822666, 0.10876376, 0.11019604,\n",
       "                     0.11315012, 0.1145824 , 0.11699937, 0.11798407, 0.11932683,\n",
       "                     0.1217438 , 0.12245994, 0.12613016, 0.12648823, 0.1289052 ,\n",
       "                     0.13347059, 0.14036344, 0.15352251, 0.16077343, 0.17939307,\n",
       "                     0.18127294, 0.18243667, 0.19103035, 0.19452153, 0.19756512,\n",
       "                     0.19908692, 0.20338376, 0.20508459, 0.20687494, 0.21045564,\n",
       "                     0.23668427, 0.23775848, 0.23963835, 0.2414287 , 0.24984334,\n",
       "                     0.25449825, 0.26094351, 0.26720974, 0.27177513, 0.27508728,\n",
       "                     0.27786232, 0.28072688, 0.28189061, 0.28994718, 0.29245367,\n",
       "                     0.29442306, 0.30194253, 0.30239012, 0.30811924, 0.3115209 ,\n",
       "                     0.31805568, 0.33407931, 0.34231492, 0.34356817, 0.36612658,\n",
       "                     0.37230329, 0.38268732, 0.38349297, 0.39495121, 0.40166503,\n",
       "                     0.40631994, 0.40676752, 0.41151195, 0.4148241 , 0.43254856,\n",
       "                     0.43765106, 0.44570764, 0.44928834, 0.45188434, 0.45403276,\n",
       "                     0.4613732 , 0.4649539 , 0.46692328, 0.475696  , 0.48178319,\n",
       "                     0.48321547, 0.488497  , 0.50550533, 0.51096589, 0.51490466,\n",
       "                     0.51902247, 0.52206606, 0.52385641, 0.53012264, 0.53406141,\n",
       "                     0.53531465, 0.5386268 , 0.54471399, 0.55062215, 0.56601916,\n",
       "                     0.56834661, 0.56942082, 0.56968937, 0.57049503, 0.57819354,\n",
       "                     0.58070003, 0.58660818, 0.58786143, 0.59009936, 0.63414197,\n",
       "                     0.64067675, 0.64479456, 0.65491003, 0.65705845, 0.65813266,\n",
       "                     0.66493599, 0.66878525, 0.67021753, 0.67236595, 0.67397726,\n",
       "                     0.67487244, 0.67746845, 0.67800555, 0.68015397, 0.6828395 ,\n",
       "                     0.70718826, 0.7114851 , 0.71255931, 0.71381255, 0.71515531,\n",
       "                     0.71587145, 0.71703518, 0.7191836 , 0.72088443, 0.72213768,\n",
       "                     0.72920956, 0.73001522, 0.73099991, 0.73422254, 0.74165249,\n",
       "                     0.74406947, 0.74702354, 0.74944052, 0.77477397, 0.77584818,\n",
       "                     0.77754901, 0.78139826, 0.78274103, 0.785158  , 0.78542655,\n",
       "                     0.78641124, 0.78784352, 0.78945484, 0.8000179 , 0.80234536,\n",
       "                     0.80601558, 0.80780593, 0.80879062, 0.81093904, 0.81344553,\n",
       "                     0.8153254 , 0.81631009, 0.81810044, 0.82087548, 0.82400859,\n",
       "                     0.82893206, 0.83215469, 0.83331841, 0.83716767, 0.84307582,\n",
       "                     0.84334437, 0.84441858, 0.84746218, 0.84880494, 0.84987915,\n",
       "                     0.85399696, 0.85757766, 0.85936801, 0.86787217, 0.87064721,\n",
       "                     0.87225853, 0.87279563, 0.87404888, 0.87700295, 0.8803151 ,\n",
       "                     0.88067317, 0.8838958 , 0.88532808, 0.89571211, 0.89624922,\n",
       "                     0.89830812, 0.90717035, 0.91066153, 0.91307851, 0.91442127,\n",
       "                     0.91531644, 0.91853907, 0.92041894, 0.92220929, 0.9248053 ,\n",
       "                     0.92552144, 0.92650613, 0.92793841, 0.92910214, 0.93062394,\n",
       "                     0.93304091, 0.93501029, 0.9360845 , 0.93742727, 0.93778534,\n",
       "                     0.93796437, 0.93814341, 0.94700564, 0.9483484 , 0.94852744,\n",
       "                     0.94942261, 0.95157103, 0.95210814, 0.95291379, 0.95443559,\n",
       "                     0.95533077, 0.95631546, 0.9570316 , 0.95730015, 0.9606123 ,\n",
       "                     0.96392445, 0.96732611, 0.97019067, 0.97180199, 0.9734133 ,\n",
       "                     0.97377137, 0.97457703, 0.97502462, 0.97520365, 0.97574076,\n",
       "                     0.97663593, 0.97717304, 0.97788918, 0.97824725, 0.97860532,\n",
       "                     0.97869483, 0.97896339, 0.97994808, 0.98155939, 0.98182795,\n",
       "                     0.98379733, 0.98451347, 1.        ]), tpr=array([0.        , 0.0767165 , 0.0859368 , 0.0966789 , 0.09954346,\n",
       "                     0.10706293, 0.11431385, 0.11547758, 0.11655179, 0.11753648,\n",
       "                     0.120222  , 0.12272849, 0.12514547, 0.12657775, 0.12908424,\n",
       "                     0.13150121, 0.13266494, 0.13749888, 0.13803599, 0.14045296,\n",
       "                     0.14564497, 0.1554919 , 0.17115746, 0.17840838, 0.19631188,\n",
       "                     0.19908692, 0.20025065, 0.20857578, 0.21376779, 0.21779608,\n",
       "                     0.22066064, 0.22549458, 0.22755349, 0.2291648 , 0.23301405,\n",
       "                     0.25960075, 0.26103303, 0.26300242, 0.26524035, 0.27240175,\n",
       "                     0.27651956, 0.28269627, 0.2879778 , 0.2930803 , 0.29639244,\n",
       "                     0.30015218, 0.30239012, 0.30337481, 0.31161042, 0.31402739,\n",
       "                     0.31760809, 0.32629129, 0.32745502, 0.33219944, 0.33667532,\n",
       "                     0.34482141, 0.36191926, 0.37078149, 0.3718557 , 0.39396652,\n",
       "                     0.39969564, 0.40855787, 0.4091845 , 0.41938949, 0.42520813,\n",
       "                     0.43013159, 0.43093725, 0.43586071, 0.44051562, 0.46110465,\n",
       "                     0.4649539 , 0.47283144, 0.47641214, 0.47918718, 0.48106705,\n",
       "                     0.48661713, 0.49127204, 0.49288336, 0.50362546, 0.5094441 ,\n",
       "                     0.51069734, 0.51597887, 0.52815325, 0.53280816, 0.53817921,\n",
       "                     0.54158088, 0.54319219, 0.54551965, 0.55098022, 0.55438188,\n",
       "                     0.55536657, 0.55885776, 0.56351267, 0.56852565, 0.58374362,\n",
       "                     0.58642915, 0.58866708, 0.59009936, 0.59126309, 0.5974398 ,\n",
       "                     0.59923015, 0.60639155, 0.60898756, 0.61068839, 0.6481067 ,\n",
       "                     0.65455196, 0.65822218, 0.66833766, 0.67147077, 0.67308209,\n",
       "                     0.67961687, 0.68301853, 0.6848984 , 0.68731537, 0.68821055,\n",
       "                     0.68910572, 0.69107511, 0.69232835, 0.69376063, 0.69725181,\n",
       "                     0.72410706, 0.72750873, 0.72885149, 0.73001522, 0.73180557,\n",
       "                     0.73261123, 0.73341688, 0.7355653 , 0.73717662, 0.74004118,\n",
       "                     0.74550175, 0.74594933, 0.74684451, 0.749351  , 0.75740757,\n",
       "                     0.76018262, 0.76206248, 0.76501656, 0.79303554, 0.79428878,\n",
       "                     0.79616865, 0.80127115, 0.80252439, 0.80682123, 0.80762689,\n",
       "                     0.80861158, 0.81013338, 0.81192373, 0.82203921, 0.82535136,\n",
       "                     0.82839495, 0.83063289, 0.83125951, 0.83340793, 0.8368096 ,\n",
       "                     0.83824188, 0.83922657, 0.84128547, 0.8445081 , 0.84728314,\n",
       "                     0.85444454, 0.85748814, 0.85820428, 0.86151643, 0.86760362,\n",
       "                     0.86849879, 0.87100528, 0.87395936, 0.87494405, 0.87637633,\n",
       "                     0.87816668, 0.88210545, 0.88398532, 0.89356369, 0.89571211,\n",
       "                     0.89795005, 0.89830812, 0.90045654, 0.90296303, 0.90734939,\n",
       "                     0.90761794, 0.91137767, 0.91379465, 0.92301495, 0.92346254,\n",
       "                     0.92713275, 0.93420464, 0.93751678, 0.93930713, 0.941187  ,\n",
       "                     0.94163459, 0.94494674, 0.9462895 , 0.94718467, 0.95022827,\n",
       "                     0.95058634, 0.951392  , 0.95273476, 0.95389849, 0.95568884,\n",
       "                     0.95747919, 0.95953809, 0.96088085, 0.96320831, 0.96392445,\n",
       "                     0.96455107, 0.96499866, 0.97296571, 0.97403992, 0.97448751,\n",
       "                     0.97502462, 0.97627786, 0.97654641, 0.976994  , 0.97797869,\n",
       "                     0.97923194, 0.98120132, 0.98146988, 0.9820965 , 0.98612479,\n",
       "                     0.9877361 , 0.99113777, 0.99310715, 0.99409184, 0.99453943,\n",
       "                     0.99462895, 0.99543461, 0.99561364, 0.99597171, 0.99632978,\n",
       "                     0.99650882, 0.99677737, 0.99704592, 0.99731447, 0.99740399,\n",
       "                     0.99749351, 0.99758303, 0.99812013, 0.99865724, 0.99883627,\n",
       "                     0.99946289, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.66188940e-02, -5.66953437e-02,\n",
       "                     -6.06246218e-02, -6.89928715e-02, -7.14589640e-02, -7.41079722e-02,\n",
       "                     -8.00427077e-02, -8.70113770e-02, -9.53101798e-02, -1.01782694e-01,\n",
       "                     -1.05360516e-01, -1.17783036e-01, -1.33531393e-01, -1.38150338e-01,\n",
       "                     -1.43100844e-01, -1.54150680e-01, -1.54150680e-01, -1.69899037e-01,\n",
       "                     -1.73663494e-01, -1.82321557e-01, -1.96506192e-01, -2.00670695e-01,\n",
       "                     -2.02940844e-01, -2.03598955e-01, -2.07639365e-01, -2.12332635e-01,\n",
       "                     -2.16223108e-01, -2.18689201e-01, -2.23143551e-01, -2.30523659e-01,\n",
       "                     -2.31801614e-01, -2.45122458e-01, -2.46133070e-01, -2.62105231e-01,\n",
       "                     -2.71933715e-01, -2.76253377e-01, -2.77631737e-01, -2.81412459e-01,\n",
       "                     -2.82232468e-01, -2.87682072e-01, -2.91910409e-01, -3.00754154e-01,\n",
       "                     -3.01105093e-01, -3.05381650e-01, -3.07484700e-01, -3.10154928e-01,\n",
       "                     -3.14493330e-01, -3.15081047e-01, -3.18453731e-01, -3.23128821e-01,\n",
       "                     -3.25422400e-01, -3.33773180e-01, -3.36472237e-01, -3.41170757e-01,\n",
       "                     -3.46148531e-01, -3.46522572e-01, -3.48306694e-01, -3.48544818e-01,\n",
       "                     -3.51976423e-01, -3.53640040e-01, -3.56674944e-01, -3.57551752e-01,\n",
       "                     -3.58212223e-01, -3.62114667e-01, -3.67724780e-01, -3.74693449e-01,\n",
       "                     -3.79489622e-01, -3.82003621e-01, -3.97682968e-01, -4.05465108e-01,\n",
       "                     -4.05465108e-01, -4.16160397e-01, -4.21213465e-01, -4.26742507e-01,\n",
       "                     -4.30782916e-01, -4.41832752e-01, -4.48950220e-01, -4.50585543e-01,\n",
       "                     -4.51985124e-01, -4.55062049e-01, -4.62623522e-01, -4.67596889e-01,\n",
       "                     -4.70003629e-01, -4.73287704e-01, -4.76924072e-01, -4.79573080e-01,\n",
       "                     -4.84245986e-01, -4.89548225e-01, -4.92476485e-01, -4.95321437e-01,\n",
       "                     -5.03103578e-01, -5.07247802e-01, -5.09648461e-01, -5.10825624e-01,\n",
       "                     -5.18793793e-01, -5.23248144e-01, -5.26093096e-01, -5.28067430e-01,\n",
       "                     -5.30628251e-01, -5.37954291e-01, -5.44727175e-01, -5.52068582e-01,\n",
       "                     -5.58932027e-01, -5.59615788e-01, -5.63094052e-01, -5.85818160e-01,\n",
       "                     -5.87786665e-01, -6.06135804e-01, -6.07380359e-01, -6.10909082e-01,\n",
       "                     -6.19039208e-01, -6.35988767e-01, -6.41853886e-01, -6.41853886e-01,\n",
       "                     -6.46627165e-01, -6.56779536e-01, -6.61398482e-01, -6.80243776e-01,\n",
       "                     -6.93147181e-01, -7.06219262e-01, -7.25937003e-01, -7.30887509e-01,\n",
       "                     -7.41937345e-01, -7.47214402e-01, -7.47214402e-01, -7.53771802e-01,\n",
       "                     -7.73189888e-01, -7.82759339e-01, -7.86965936e-01, -7.88457360e-01,\n",
       "                     -7.88457360e-01, -8.10930216e-01, -8.13396309e-01, -8.42678915e-01,\n",
       "                     -8.47297860e-01, -8.47297860e-01, -8.48210269e-01, -8.57450232e-01,\n",
       "                     -8.67500568e-01, -8.76929658e-01, -8.87303195e-01, -8.90972924e-01,\n",
       "                     -8.93817876e-01, -8.97941593e-01, -9.04456274e-01, -9.16290732e-01,\n",
       "                     -9.18059079e-01, -9.21681581e-01, -9.27986772e-01, -9.40007258e-01,\n",
       "                     -9.44461609e-01, -9.49080555e-01, -9.57533690e-01, -9.65080896e-01,\n",
       "                     -9.69400557e-01, -9.75379648e-01, -9.80829253e-01, -9.84853403e-01,\n",
       "                     -9.93251773e-01, -1.00623897e+00, -1.01160091e+00, -1.01405490e+00,\n",
       "                     -1.01693426e+00, -1.02961942e+00, -1.04982212e+00, -1.05736933e+00,\n",
       "                     -1.06784063e+00, -1.07755888e+00, -1.09861229e+00, -1.09861229e+00,\n",
       "                     -1.11436065e+00, -1.14725410e+00, -1.15267951e+00, -1.16315081e+00,\n",
       "                     -1.17865500e+00, -1.19139402e+00, -1.20039498e+00, -1.20192990e+00,\n",
       "                     -1.20397280e+00, -1.21109027e+00, -1.21502264e+00, -1.22320417e+00,\n",
       "                     -1.22377543e+00, -1.22807036e+00, -1.22897411e+00, -1.24111235e+00,\n",
       "                     -1.25276297e+00, -1.25954266e+00, -1.28093385e+00, -1.28692189e+00,\n",
       "                     -1.29928298e+00, -1.30833282e+00, -1.30992138e+00, -1.32175584e+00,\n",
       "                     -1.32913595e+00, -1.33500107e+00, -1.34707365e+00, -1.34807315e+00,\n",
       "                     -1.37371558e+00, -1.38629436e+00, -1.40282366e+00, -1.40534256e+00,\n",
       "                     -1.41706602e+00, -1.42138568e+00, -1.43508453e+00, -1.46720100e+00,\n",
       "                     -1.52242654e+00, -1.52605630e+00, -1.57553636e+00, -1.58045038e+00,\n",
       "                     -1.60943791e+00, -1.60943791e+00, -1.62745642e+00, -1.63760879e+00,\n",
       "                     -1.65388968e+00, -1.67397643e+00, -1.69167601e+00, -1.69459572e+00,\n",
       "                     -1.70474809e+00, -1.72370601e+00, -1.79175947e+00, -1.83621123e+00,\n",
       "                     -1.85629799e+00, -1.94591015e+00, -1.94591015e+00, -2.01490302e+00,\n",
       "                     -2.04769284e+00, -2.07944154e+00, -2.19722458e+00, -2.30258509e+00,\n",
       "                     -2.33537492e+00, -2.39789527e+00, -2.48490665e+00, -2.56494936e+00,\n",
       "                     -2.63905733e+00, -2.67414865e+00, -2.70805020e+00, -2.83321334e+00,\n",
       "                     -2.89827694e+00, -2.89958841e+00, -3.45387764e+01]), auc_score=0.5193056618452894, privacy_risk=0.5144123176080924, accuracy=0.5144123176080924, tpr_ind=0.9271327544534956, tnr_ind=0.1016918807626891, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.08137141, 0.08736908, 0.08906991, 0.09112882,\n",
       "                     0.09238206, 0.09381434, 0.09641035, 0.09748456, 0.09936443,\n",
       "                     0.10446692, 0.10598872, 0.10697341, 0.10715245, 0.10974846,\n",
       "                     0.11207591, 0.11377674, 0.11511951, 0.11789455, 0.12237042,\n",
       "                     0.12550354, 0.12702533, 0.12935279, 0.13275445, 0.13463432,\n",
       "                     0.13794647, 0.13982634, 0.14278041, 0.14510787, 0.14671918,\n",
       "                     0.15209023, 0.15280637, 0.15584997, 0.15916212, 0.16533882,\n",
       "                     0.17375347, 0.18422702, 0.19702802, 0.21887029, 0.22853818,\n",
       "                     0.23722138, 0.25109659, 0.25154418, 0.25324501, 0.25548295,\n",
       "                     0.25951123, 0.26461373, 0.2685525 , 0.27311789, 0.29442306,\n",
       "                     0.30579178, 0.31554919, 0.31725002, 0.31778713, 0.32190493,\n",
       "                     0.32826067, 0.32906633, 0.33578015, 0.3416883 , 0.35932325,\n",
       "                     0.36773789, 0.37230329, 0.37364605, 0.38304539, 0.3867156 ,\n",
       "                     0.42467102, 0.4261033 , 0.42959449, 0.4327276 , 0.4378301 ,\n",
       "                     0.44418584, 0.44767702, 0.44955689, 0.45555456, 0.45761346,\n",
       "                     0.46307403, 0.46746039, 0.47130964, 0.47336854, 0.47936622,\n",
       "                     0.48411064, 0.4879599 , 0.48912362, 0.49306239, 0.49879151,\n",
       "                     0.49888103, 0.49977621, 0.5028198 , 0.50496822, 0.51696357,\n",
       "                     0.52099185, 0.52314027, 0.55160684, 0.55366574, 0.55903679,\n",
       "                     0.56073762, 0.56977889, 0.57407573, 0.57694029, 0.58016292,\n",
       "                     0.5953809 , 0.60111002, 0.60433265, 0.61391102, 0.61489571,\n",
       "                     0.62214663, 0.62447408, 0.62617492, 0.63002417, 0.63270969,\n",
       "                     0.6383493 , 0.63933399, 0.64255662, 0.64497359, 0.64748008,\n",
       "                     0.64971802, 0.65535762, 0.65607376, 0.65643183, 0.65822218,\n",
       "                     0.66028108, 0.66081819, 0.66565213, 0.66771104, 0.67173933,\n",
       "                     0.67433533, 0.67728941, 0.70853102, 0.71112703, 0.71282786,\n",
       "                     0.71542387, 0.71757229, 0.72195864, 0.72240623, 0.72464417,\n",
       "                     0.72625548, 0.72670307, 0.72732969, 0.73162653, 0.73520723,\n",
       "                     0.73690807, 0.7386089 , 0.74129442, 0.74210008, 0.74594933,\n",
       "                     0.74773968, 0.74800824, 0.75078328, 0.75114135, 0.75230508,\n",
       "                     0.75561722, 0.75606481, 0.76277862, 0.7636738 , 0.76707546,\n",
       "                     0.77728046, 0.77942888, 0.78148778, 0.78381524, 0.78775401,\n",
       "                     0.78847015, 0.79348313, 0.79428878, 0.81362456, 0.81416167,\n",
       "                     0.81666816, 0.82293438, 0.82391908, 0.82651508, 0.82651508,\n",
       "                     0.82705219, 0.83000627, 0.83233372, 0.8332289 , 0.83501925,\n",
       "                     0.83672008, 0.83931609, 0.84325486, 0.84486617, 0.84683556,\n",
       "                     0.8496106 , 0.84987915, 0.85310178, 0.85426551, 0.85578731,\n",
       "                     0.85909945, 0.86053173, 0.86214305, 0.8639334 , 0.86482857,\n",
       "                     0.88112076, 0.88300063, 0.8859547 , 0.88684988, 0.88855071,\n",
       "                     0.89007251, 0.89633873, 0.89759198, 0.89991943, 0.90045654,\n",
       "                     0.9017993 , 0.90341062, 0.90403724, 0.90475338, 0.90958732,\n",
       "                     0.91361561, 0.92399964, 0.92668517, 0.92856503, 0.93142959,\n",
       "                     0.93277236, 0.9334885 , 0.93411512, 0.93411512, 0.94020231,\n",
       "                     0.94217169, 0.94646853, 0.9519291 , 0.95470414, 0.95712112,\n",
       "                     0.9606123 , 0.96356638, 0.96356638, 0.96455107, 0.96490914,\n",
       "                     0.96508817, 0.96669949, 0.96786322, 0.96822129, 0.96893743,\n",
       "                     0.96920598, 0.96965357, 0.97045922, 0.97126488, 0.97180199,\n",
       "                     0.9718915 , 0.97242861, 0.9728762 , 0.97386089, 0.9749351 ,\n",
       "                     0.97591979, 0.97609883, 0.97609883, 0.97717304, 0.97878435,\n",
       "                     0.97914242, 0.97941097, 0.97950049, 0.97985856, 0.98012711,\n",
       "                     0.98030615, 0.98075374, 0.98084325, 0.98102229, 0.9820965 ,\n",
       "                     0.9826336 , 0.98299167, 1.        ]), tpr=array([0.        , 0.08763763, 0.09265061, 0.09497807, 0.09882732,\n",
       "                     0.10070719, 0.10249754, 0.10706293, 0.10849521, 0.11118074,\n",
       "                     0.11655179, 0.11825262, 0.11986393, 0.12058007, 0.12335512,\n",
       "                     0.12541402, 0.12675678, 0.12872617, 0.13257542, 0.13705129,\n",
       "                     0.13955778, 0.14188524, 0.1447498 , 0.14806195, 0.15074747,\n",
       "                     0.15370155, 0.15513383, 0.15835646, 0.16193716, 0.16453317,\n",
       "                     0.16999373, 0.17079939, 0.17357443, 0.1775132 , 0.18431653,\n",
       "                     0.19452153, 0.20427894, 0.21681139, 0.23874317, 0.24787396,\n",
       "                     0.25539343, 0.26738877, 0.26828395, 0.2700743 , 0.27240175,\n",
       "                     0.27526631, 0.28144302, 0.28618745, 0.29111091, 0.31375884,\n",
       "                     0.32557515, 0.33739146, 0.33918181, 0.34043506, 0.34437383,\n",
       "                     0.34938681, 0.35055053, 0.35968132, 0.36594754, 0.38223973,\n",
       "                     0.38886402, 0.39468266, 0.39575687, 0.40345538, 0.40811029,\n",
       "                     0.44517053, 0.4470504 , 0.45224241, 0.4557336 , 0.45958285,\n",
       "                     0.46602811, 0.46942977, 0.4705935 , 0.47659117, 0.47909766,\n",
       "                     0.48518485, 0.49010832, 0.49333095, 0.49655358, 0.5028198 ,\n",
       "                     0.50559484, 0.51007072, 0.51195059, 0.51526273, 0.52063378,\n",
       "                     0.52143944, 0.5222451 , 0.52618387, 0.52806374, 0.53961149,\n",
       "                     0.54319219, 0.5452511 , 0.57425477, 0.57613463, 0.58204279,\n",
       "                     0.58347507, 0.59090502, 0.59466476, 0.5979769 , 0.60111002,\n",
       "                     0.61722317, 0.62223615, 0.6240265 , 0.63512667, 0.63664846,\n",
       "                     0.644526  , 0.64676394, 0.6481067 , 0.65132933, 0.65401486,\n",
       "                     0.65911736, 0.66072867, 0.66359323, 0.66565213, 0.66735297,\n",
       "                     0.67048608, 0.67594665, 0.67693134, 0.67746845, 0.67934831,\n",
       "                     0.68149673, 0.68230239, 0.6884791 , 0.69134366, 0.69438725,\n",
       "                     0.69635664, 0.70011637, 0.73449109, 0.73816131, 0.74004118,\n",
       "                     0.74290574, 0.74550175, 0.75105183, 0.75176797, 0.75364784,\n",
       "                     0.75525915, 0.75570674, 0.7565124 , 0.76089876, 0.76340525,\n",
       "                     0.76474801, 0.76635932, 0.76859726, 0.76985051, 0.77378928,\n",
       "                     0.77584818, 0.77611673, 0.77826515, 0.77924984, 0.78086116,\n",
       "                     0.78650076, 0.78757497, 0.79536299, 0.79661624, 0.80010742,\n",
       "                     0.81084952, 0.81290842, 0.81505684, 0.81747382, 0.82212873,\n",
       "                     0.8230239 , 0.82669412, 0.82785785, 0.84567183, 0.84692507,\n",
       "                     0.84907349, 0.85569779, 0.856772  , 0.85900994, 0.85945752,\n",
       "                     0.85990511, 0.86285919, 0.86464954, 0.86563423, 0.86796169,\n",
       "                     0.86939397, 0.8726166 , 0.87422791, 0.87583923, 0.8782562 ,\n",
       "                     0.88112076, 0.88228449, 0.88505953, 0.88559663, 0.88711843,\n",
       "                     0.88998299, 0.89168382, 0.89320562, 0.89544356, 0.89624922,\n",
       "                     0.91209381, 0.9140632 , 0.91728583, 0.91773342, 0.92015039,\n",
       "                     0.92283591, 0.92937069, 0.93187718, 0.93545788, 0.93590547,\n",
       "                     0.93778534, 0.93921762, 0.9396652 , 0.94029183, 0.94440963,\n",
       "                     0.9483484 , 0.95586787, 0.95747919, 0.95900098, 0.96097037,\n",
       "                     0.96186554, 0.96258168, 0.96311879, 0.96338734, 0.96696804,\n",
       "                     0.96920598, 0.9718915 , 0.97788918, 0.98120132, 0.98370781,\n",
       "                     0.98630382, 0.98782562, 0.98800465, 0.98889983, 0.98952645,\n",
       "                     0.98970549, 0.99086921, 0.99140632, 0.99194342, 0.99212246,\n",
       "                     0.99274908, 0.99301763, 0.99355474, 0.99400233, 0.99453943,\n",
       "                     0.99498702, 0.99516605, 0.99534509, 0.99570316, 0.99632978,\n",
       "                     0.99686689, 0.99713544, 0.99731447, 0.99758303, 0.9979411 ,\n",
       "                     0.99803061, 0.99820965, 0.99838868, 0.99883627, 0.99901531,\n",
       "                     0.99910482, 0.99937338, 0.99946289, 0.99955241, 0.99973145,\n",
       "                     0.99982096, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.50913198e-02, -3.77403280e-02,\n",
       "                     -4.54623741e-02, -4.65200156e-02, -4.87901642e-02, -5.71584138e-02,\n",
       "                     -6.06246218e-02, -6.45385211e-02, -8.00427077e-02, -1.00083459e-01,\n",
       "                     -1.05360516e-01, -1.17783036e-01, -1.21360857e-01, -1.22602322e-01,\n",
       "                     -1.25163143e-01, -1.27833372e-01, -1.30620182e-01, -1.31028262e-01,\n",
       "                     -1.33531393e-01, -1.43100844e-01, -1.45182010e-01, -1.50282203e-01,\n",
       "                     -1.54150680e-01, -1.67054085e-01, -1.71850257e-01, -1.77681177e-01,\n",
       "                     -1.82321557e-01, -1.88052232e-01, -1.93191229e-01, -2.00670695e-01,\n",
       "                     -2.03598955e-01, -2.04794413e-01, -2.23143551e-01, -2.26646182e-01,\n",
       "                     -2.28633044e-01, -2.34507310e-01, -2.41744977e-01, -2.57829109e-01,\n",
       "                     -2.60531083e-01, -2.61215499e-01, -2.62364264e-01, -2.62364264e-01,\n",
       "                     -2.68263987e-01, -2.71933715e-01, -2.76753002e-01, -2.78203328e-01,\n",
       "                     -2.83126256e-01, -2.86693442e-01, -2.87682072e-01, -2.98981628e-01,\n",
       "                     -3.00104592e-01, -3.05381650e-01, -3.10154928e-01, -3.18453731e-01,\n",
       "                     -3.25422400e-01, -3.30854244e-01, -3.36472237e-01, -3.37256858e-01,\n",
       "                     -3.40325806e-01, -3.47401307e-01, -3.48306694e-01, -3.49673748e-01,\n",
       "                     -3.52821375e-01, -3.55950044e-01, -3.56674944e-01, -3.58397597e-01,\n",
       "                     -3.61790045e-01, -3.65934269e-01, -3.67724780e-01, -3.69747026e-01,\n",
       "                     -3.79489622e-01, -3.80274859e-01, -3.81367557e-01, -3.85662481e-01,\n",
       "                     -3.99386062e-01, -4.05465108e-01, -4.05465108e-01, -4.14943852e-01,\n",
       "                     -4.16160397e-01, -4.18710335e-01, -4.21213465e-01, -4.32133355e-01,\n",
       "                     -4.38254931e-01, -4.41832752e-01, -4.41832752e-01, -4.49916871e-01,\n",
       "                     -4.51985124e-01, -4.53393575e-01, -4.70003629e-01, -4.75423697e-01,\n",
       "                     -4.78837948e-01, -4.81838087e-01, -4.83174092e-01, -4.85507816e-01,\n",
       "                     -4.86434171e-01, -4.96436886e-01, -4.99955952e-01, -5.05094949e-01,\n",
       "                     -5.10825624e-01, -5.28525201e-01, -5.30628251e-01, -5.31576568e-01,\n",
       "                     -5.34082486e-01, -5.39943022e-01, -5.42324291e-01, -5.50046337e-01,\n",
       "                     -5.59615788e-01, -5.69094532e-01, -5.72069249e-01, -5.75364145e-01,\n",
       "                     -5.77315365e-01, -5.78077851e-01, -5.81921545e-01, -5.87786665e-01,\n",
       "                     -5.89606502e-01, -5.97837001e-01, -6.06135804e-01, -6.19039208e-01,\n",
       "                     -6.28608659e-01, -6.35988767e-01, -6.41090819e-01, -6.45137961e-01,\n",
       "                     -6.63294217e-01, -6.70157662e-01, -6.81170990e-01, -6.93147181e-01,\n",
       "                     -7.05268541e-01, -7.16677678e-01, -7.23918839e-01, -7.43578034e-01,\n",
       "                     -7.48062938e-01, -7.53771802e-01, -7.62140052e-01, -7.73189888e-01,\n",
       "                     -7.88457360e-01, -7.98507696e-01, -8.08660068e-01, -8.10930216e-01,\n",
       "                     -8.18310324e-01, -8.23200309e-01, -8.24175443e-01, -8.26678573e-01,\n",
       "                     -8.30930883e-01, -8.34797698e-01, -8.47297860e-01, -8.47297860e-01,\n",
       "                     -8.60201265e-01, -8.70828358e-01, -8.74145110e-01, -8.82389180e-01,\n",
       "                     -8.85950015e-01, -8.87303195e-01, -8.90315245e-01, -9.16290732e-01,\n",
       "                     -9.24948795e-01, -9.32820034e-01, -9.38269639e-01, -9.54031060e-01,\n",
       "                     -9.55511445e-01, -9.59256768e-01, -9.61411167e-01, -9.66276639e-01,\n",
       "                     -9.71860583e-01, -9.80829253e-01, -1.00914089e+00, -1.01160091e+00,\n",
       "                     -1.01523068e+00, -1.02961942e+00, -1.02961942e+00, -1.03609193e+00,\n",
       "                     -1.04731899e+00, -1.06784063e+00, -1.07263680e+00, -1.07755888e+00,\n",
       "                     -1.07992016e+00, -1.09861229e+00, -1.09861229e+00, -1.11088238e+00,\n",
       "                     -1.13943428e+00, -1.14862271e+00, -1.15098027e+00, -1.15267951e+00,\n",
       "                     -1.17411984e+00, -1.17865500e+00, -1.18269541e+00, -1.19213835e+00,\n",
       "                     -1.19996478e+00, -1.20397280e+00, -1.20566628e+00, -1.21302264e+00,\n",
       "                     -1.22050211e+00, -1.22377543e+00, -1.22595171e+00, -1.24319352e+00,\n",
       "                     -1.25080410e+00, -1.25276297e+00, -1.26694760e+00, -1.28093385e+00,\n",
       "                     -1.29928298e+00, -1.32175584e+00, -1.33500107e+00, -1.34992672e+00,\n",
       "                     -1.35314215e+00, -1.38629436e+00, -1.38926613e+00, -1.40008768e+00,\n",
       "                     -1.41528190e+00, -1.41981705e+00, -1.43508453e+00, -1.44691898e+00,\n",
       "                     -1.46633707e+00, -1.46633707e+00, -1.47017585e+00, -1.47247206e+00,\n",
       "                     -1.48160454e+00, -1.53831057e+00, -1.56523182e+00, -1.58777642e+00,\n",
       "                     -1.59554880e+00, -1.60943791e+00, -1.60943791e+00, -1.68639895e+00,\n",
       "                     -1.69167601e+00, -1.70474809e+00, -1.73911574e+00, -1.76358859e+00,\n",
       "                     -1.79175947e+00, -1.79175947e+00, -1.81528997e+00, -1.84582669e+00,\n",
       "                     -1.87180218e+00, -1.94591015e+00, -1.96944065e+00, -2.00148000e+00,\n",
       "                     -2.01490302e+00, -2.01490302e+00, -2.07944154e+00, -2.09714112e+00,\n",
       "                     -2.10006083e+00, -2.12026354e+00, -2.14006616e+00, -2.15948425e+00,\n",
       "                     -2.16905370e+00, -2.19722458e+00, -2.30258509e+00, -2.35137526e+00,\n",
       "                     -2.56494936e+00, -2.77258872e+00, -2.83321334e+00, -2.89037176e+00,\n",
       "                     -3.04452244e+00, -3.09104245e+00, -3.11351531e+00, -3.29583687e+00,\n",
       "                     -3.36729583e+00, -3.45387764e+01]), auc_score=0.5214479155632405, privacy_risk=0.5179930176349477, accuracy=0.5179930176349477, tpr_ind=0.9377853370333901, tnr_ind=0.09820069823650523, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.04663862, 0.06346791, 0.06678006, 0.0802972 ,\n",
       "                     0.08504163, 0.0853997 , 0.08557873, 0.08620535, 0.08978605,\n",
       "                     0.09112882, 0.09470952, 0.10876376, 0.11144929, 0.11494047,\n",
       "                     0.12344463, 0.12639871, 0.14161669, 0.1447498 , 0.14618208,\n",
       "                     0.14797243, 0.14931519, 0.17232119, 0.17357443, 0.18100439,\n",
       "                     0.18548026, 0.19174649, 0.19926596, 0.20589025, 0.20759108,\n",
       "                     0.21179841, 0.21215648, 0.21752753, 0.22782204, 0.23095515,\n",
       "                     0.23516247, 0.25673619, 0.26613553, 0.26882105, 0.27302838,\n",
       "                     0.28538179, 0.30552323, 0.30677647, 0.31411691, 0.31787664,\n",
       "                     0.32262107, 0.32306866, 0.35117716, 0.35260944, 0.35914421,\n",
       "                     0.35994987, 0.36048698, 0.36227733, 0.36863307, 0.37776385,\n",
       "                     0.38787933, 0.39656253, 0.40345538, 0.40578283, 0.41142243,\n",
       "                     0.42583475, 0.42735655, 0.44078417, 0.45564408, 0.46692328,\n",
       "                     0.47480082, 0.47578552, 0.48769134, 0.49556888, 0.49843344,\n",
       "                     0.50085042, 0.50568436, 0.50693761, 0.50854892, 0.51982813,\n",
       "                     0.52161848, 0.52502014, 0.52528869, 0.53853728, 0.55053263,\n",
       "                     0.55339719, 0.56539253, 0.5693313 , 0.57130069, 0.57398621,\n",
       "                     0.57882016, 0.57962582, 0.58078954, 0.58231134, 0.58598156,\n",
       "                     0.58750336, 0.5943962 , 0.59627607, 0.60182616, 0.60316892,\n",
       "                     0.60549637, 0.60701817, 0.6097037 , 0.6122997 , 0.61319488,\n",
       "                     0.62008773, 0.62581685, 0.62886044, 0.631725  , 0.63485811,\n",
       "                     0.64497359, 0.65231403, 0.6552681 , 0.67952735, 0.68525647,\n",
       "                     0.68552502, 0.68758392, 0.68892669, 0.69188076, 0.69662519,\n",
       "                     0.69832602, 0.70002686, 0.70163817, 0.70199624, 0.70593501,\n",
       "                     0.72321189, 0.72383851, 0.72518127, 0.73037329, 0.73986214,\n",
       "                     0.74389043, 0.74469609, 0.74765017, 0.75033569, 0.7549906 ,\n",
       "                     0.75588578, 0.75713902, 0.75848178, 0.75955599, 0.7606302 ,\n",
       "                     0.76322621, 0.76385283, 0.76609077, 0.76653836, 0.77065616,\n",
       "                     0.77253603, 0.77790708, 0.77862322, 0.77978695, 0.78104019,\n",
       "                     0.78184585, 0.78390475, 0.78471041, 0.78578462, 0.78766449,\n",
       "                     0.79500492, 0.79652672, 0.80476233, 0.81147614, 0.81156566,\n",
       "                     0.81246084, 0.81371408, 0.81648912, 0.81801092, 0.81899561,\n",
       "                     0.82194969, 0.82266583, 0.82490377, 0.82839495, 0.83600394,\n",
       "                     0.83725718, 0.84128547, 0.84710411, 0.85569779, 0.85972608,\n",
       "                     0.86008415, 0.86975204, 0.87181094, 0.87252708, 0.87700295,\n",
       "                     0.87950944, 0.88380628, 0.88801361, 0.88980396, 0.89025154,\n",
       "                     0.89069913, 0.89141527, 0.89472742, 0.89517501, 0.90672276,\n",
       "                     0.90717035, 0.90976636, 0.9110196 , 0.91316802, 0.91468982,\n",
       "                     0.92077701, 0.92444723, 0.92659565, 0.92704324, 0.93169815,\n",
       "                     0.94190314, 0.94342494, 0.94521529, 0.94897502, 0.95103393,\n",
       "                     0.95183958, 0.95237669, 0.95246621, 0.95461463, 0.95685256,\n",
       "                     0.95837436, 0.96025423, 0.96168651, 0.96499866, 0.96544624,\n",
       "                     0.97072778, 0.97081729, 0.97126488, 0.9718915 , 0.97216006,\n",
       "                     0.97618834, 0.97681497, 0.97896339, 0.98012711, 0.98048518,\n",
       "                     0.9820965 , 0.98254409, 0.9826336 , 0.98308119, 0.98433444,\n",
       "                     0.98451347, 0.98514009, 0.98531913, 0.98549816, 0.9862143 ,\n",
       "                     0.987199  , 0.98782562, 1.        ]), tpr=array([0.        , 0.0531734 , 0.07188255, 0.07492615, 0.08683198,\n",
       "                     0.0910393 , 0.09202399, 0.09291917, 0.09372482, 0.09829022,\n",
       "                     0.10043864, 0.1038403 , 0.11852117, 0.12049056, 0.12613016,\n",
       "                     0.13624564, 0.13946827, 0.15620804, 0.15817742, 0.16005729,\n",
       "                     0.16211619, 0.16292185, 0.18610688, 0.18727061, 0.19532719,\n",
       "                     0.20069824, 0.20589025, 0.21367827, 0.22075016, 0.22209292,\n",
       "                     0.22674783, 0.22773252, 0.23283502, 0.24411422, 0.24733685,\n",
       "                     0.25100707, 0.27150658, 0.28117447, 0.28350192, 0.28735118,\n",
       "                     0.30015218, 0.31680243, 0.31877182, 0.32629129, 0.33112523,\n",
       "                     0.33640677, 0.33712291, 0.36567899, 0.36755886, 0.37284039,\n",
       "                     0.37373557, 0.37480978, 0.3769582 , 0.38420911, 0.39378749,\n",
       "                     0.40748366, 0.41410796, 0.42288067, 0.42529765, 0.43084773,\n",
       "                     0.44687136, 0.44821413, 0.4598514 , 0.47399517, 0.48411064,\n",
       "                     0.4935995 , 0.49521081, 0.50854892, 0.51579984, 0.52027571,\n",
       "                     0.52233462, 0.52842181, 0.52976457, 0.53227106, 0.54050667,\n",
       "                     0.54211798, 0.54543013, 0.54605675, 0.55885776, 0.57165876,\n",
       "                     0.57479187, 0.58687673, 0.59036792, 0.59224778, 0.59368006,\n",
       "                     0.59851401, 0.5994987 , 0.60173664, 0.60424313, 0.60880852,\n",
       "                     0.61077791, 0.61758124, 0.61874496, 0.62259422, 0.62527974,\n",
       "                     0.62841285, 0.6296661 , 0.63253066, 0.63611136, 0.63763316,\n",
       "                     0.64282517, 0.64658491, 0.64953898, 0.65123982, 0.6552681 ,\n",
       "                     0.66726345, 0.67335064, 0.67549906, 0.70092203, 0.70512935,\n",
       "                     0.70575598, 0.70718826, 0.70879957, 0.71139558, 0.71837794,\n",
       "                     0.72079492, 0.7222272 , 0.72348044, 0.72401755, 0.72759825,\n",
       "                     0.74908245, 0.74953003, 0.7508728 , 0.75588578, 0.76555367,\n",
       "                     0.7687763 , 0.77011906, 0.77244651, 0.77540059, 0.77942888,\n",
       "                     0.78059261, 0.78166682, 0.78327813, 0.78533703, 0.78623221,\n",
       "                     0.78847015, 0.79035001, 0.79303554, 0.7938412 , 0.79849611,\n",
       "                     0.79983887, 0.80288246, 0.80368812, 0.80449378, 0.80592606,\n",
       "                     0.80655268, 0.80959628, 0.81049145, 0.81165518, 0.8138036 ,\n",
       "                     0.82114403, 0.8230239 , 0.83054337, 0.83797332, 0.83833139,\n",
       "                     0.84021126, 0.84110644, 0.84558231, 0.84692507, 0.84764121,\n",
       "                     0.85086384, 0.85193805, 0.85426551, 0.85802524, 0.86482857,\n",
       "                     0.86563423, 0.87037866, 0.87539164, 0.882374  , 0.88792409,\n",
       "                     0.88855071, 0.89589115, 0.89839764, 0.89947185, 0.9033211 ,\n",
       "                     0.90618566, 0.9120043 , 0.91603258, 0.91907618, 0.91997135,\n",
       "                     0.92041894, 0.92077701, 0.92283591, 0.92355205, 0.93429415,\n",
       "                     0.93456271, 0.93653209, 0.93832244, 0.94109748, 0.94181362,\n",
       "                     0.9478113 , 0.95237669, 0.95371945, 0.95452511, 0.95774774,\n",
       "                     0.96446155, 0.96562528, 0.96660997, 0.9698326 , 0.97126488,\n",
       "                     0.97153343, 0.97278668, 0.97314475, 0.97502462, 0.97708352,\n",
       "                     0.97842628, 0.97950049, 0.97976904, 0.98164891, 0.98191746,\n",
       "                     0.98710948, 0.98728851, 0.9877361 , 0.98809417, 0.98845224,\n",
       "                     0.9913168 , 0.99185391, 0.9933757 , 0.99418136, 0.99444991,\n",
       "                     0.9964193 , 0.99686689, 0.9969564 , 0.99713544, 0.99767254,\n",
       "                     0.99776206, 0.99785158, 0.9979411 , 0.99829917, 0.99919434,\n",
       "                     0.99937338, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.29441557e-02, -5.71584138e-02,\n",
       "                     -7.24955020e-02, -8.16780310e-02, -8.70113770e-02, -9.53101798e-02,\n",
       "                     -1.05360516e-01, -1.11225635e-01, -1.17783036e-01, -1.23613956e-01,\n",
       "                     -1.25880246e-01, -1.27833372e-01, -1.33531393e-01, -1.40146632e-01,\n",
       "                     -1.54150680e-01, -1.57963113e-01, -1.67054085e-01, -1.74353387e-01,\n",
       "                     -1.96710294e-01, -2.00670695e-01, -2.02073712e-01, -2.07639365e-01,\n",
       "                     -2.09720531e-01, -2.23143551e-01, -2.30016431e-01, -2.34572247e-01,\n",
       "                     -2.35722334e-01, -2.36388778e-01, -2.38411023e-01, -2.41162057e-01,\n",
       "                     -2.47408173e-01, -2.51314428e-01, -2.66628663e-01, -2.75411980e-01,\n",
       "                     -2.83305698e-01, -2.87682072e-01, -2.97251523e-01, -2.99242895e-01,\n",
       "                     -3.05013529e-01, -3.07642815e-01, -3.10154928e-01, -3.14115330e-01,\n",
       "                     -3.15081047e-01, -3.16911711e-01, -3.18453731e-01, -3.19308310e-01,\n",
       "                     -3.22773392e-01, -3.29181803e-01, -3.36472237e-01, -3.48306694e-01,\n",
       "                     -3.48306694e-01, -3.50482974e-01, -3.51051686e-01, -3.54057141e-01,\n",
       "                     -3.59374001e-01, -3.63792412e-01, -3.67724780e-01, -3.72675285e-01,\n",
       "                     -3.77134601e-01, -3.82992252e-01, -3.89960922e-01, -4.01236772e-01,\n",
       "                     -4.02510896e-01, -4.05465108e-01, -4.05465108e-01, -4.12154096e-01,\n",
       "                     -4.17735201e-01, -4.18710335e-01, -4.19853846e-01, -4.24883194e-01,\n",
       "                     -4.27444015e-01, -4.28995606e-01, -4.34038481e-01, -4.41832752e-01,\n",
       "                     -4.49525098e-01, -4.51985124e-01, -4.57690369e-01, -4.62105387e-01,\n",
       "                     -4.70003629e-01, -4.74622575e-01, -4.79573080e-01, -4.81838087e-01,\n",
       "                     -4.85507816e-01, -4.88352768e-01, -4.92476485e-01, -4.94696242e-01,\n",
       "                     -4.96436886e-01, -5.10825624e-01, -5.19875459e-01, -5.21296924e-01,\n",
       "                     -5.26093096e-01, -5.29259325e-01, -5.30628251e-01, -5.38996501e-01,\n",
       "                     -5.38996501e-01, -5.41597282e-01, -5.59615788e-01, -5.67984038e-01,\n",
       "                     -5.74285978e-01, -5.79818495e-01, -5.81029882e-01, -5.81921545e-01,\n",
       "                     -5.87786665e-01, -5.91097926e-01, -6.00773860e-01, -6.06135804e-01,\n",
       "                     -6.12517446e-01, -6.15760517e-01, -6.19039208e-01, -6.28608659e-01,\n",
       "                     -6.35988767e-01, -6.58055861e-01, -6.93147181e-01, -7.29514825e-01,\n",
       "                     -7.53771802e-01, -7.62140052e-01, -7.73189888e-01, -7.77028665e-01,\n",
       "                     -7.80852761e-01, -7.88457360e-01, -7.88457360e-01, -7.94929875e-01,\n",
       "                     -8.06806499e-01, -8.10930216e-01, -8.18310324e-01, -8.19440906e-01,\n",
       "                     -8.20980552e-01, -8.28066498e-01, -8.36248024e-01, -8.47297860e-01,\n",
       "                     -8.47297860e-01, -8.71838969e-01, -8.75468737e-01, -8.75468737e-01,\n",
       "                     -8.87303195e-01, -8.89262059e-01, -8.93817876e-01, -9.00786545e-01,\n",
       "                     -9.02867712e-01, -9.16290732e-01, -9.38269639e-01, -9.38269639e-01,\n",
       "                     -9.40983344e-01, -9.44461609e-01, -9.50976290e-01, -9.55511445e-01,\n",
       "                     -9.61411167e-01, -9.65080896e-01, -9.73178106e-01, -9.80829253e-01,\n",
       "                     -9.94133219e-01, -1.00169439e+00, -1.01160091e+00, -1.01592057e+00,\n",
       "                     -1.02961942e+00, -1.04380405e+00, -1.05314991e+00, -1.05605267e+00,\n",
       "                     -1.06087196e+00, -1.07044141e+00, -1.07263680e+00, -1.07451474e+00,\n",
       "                     -1.08536706e+00, -1.09861229e+00, -1.09861229e+00, -1.10454702e+00,\n",
       "                     -1.10712298e+00, -1.13036099e+00, -1.14513230e+00, -1.15780116e+00,\n",
       "                     -1.16760516e+00, -1.17865500e+00, -1.18755977e+00, -1.19770319e+00,\n",
       "                     -1.21010779e+00, -1.21721803e+00, -1.21857160e+00, -1.22377543e+00,\n",
       "                     -1.22377543e+00, -1.25276297e+00, -1.27122503e+00, -1.28785429e+00,\n",
       "                     -1.29700767e+00, -1.29928298e+00, -1.30340670e+00, -1.30833282e+00,\n",
       "                     -1.31094492e+00, -1.32175584e+00, -1.32869687e+00, -1.33603253e+00,\n",
       "                     -1.35239281e+00, -1.35812348e+00, -1.38629436e+00, -1.39953959e+00,\n",
       "                     -1.42403469e+00, -1.45225233e+00, -1.50407740e+00, -1.51787072e+00,\n",
       "                     -1.54044504e+00, -1.55059741e+00, -1.55814462e+00, -1.56064775e+00,\n",
       "                     -1.56498615e+00, -1.58240924e+00, -1.60943791e+00, -1.60943791e+00,\n",
       "                     -1.66500776e+00, -1.67397643e+00, -1.69845876e+00, -1.70474809e+00,\n",
       "                     -1.72276660e+00, -1.83258146e+00, -1.87180218e+00, -1.92333583e+00,\n",
       "                     -1.94591015e+00, -2.03432111e+00, -2.07944154e+00, -2.12026354e+00,\n",
       "                     -2.13470422e+00, -2.15176220e+00, -2.19722458e+00, -2.19722458e+00,\n",
       "                     -2.25129180e+00, -2.30258509e+00, -2.39789527e+00, -2.48490665e+00,\n",
       "                     -2.54553127e+00, -2.66025954e+00, -2.89037176e+00, -3.42936826e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5183796232942344, privacy_risk=0.5148599051114493, accuracy=0.5148599051114493, tpr_ind=0.9199713543997852, tnr_ind=0.10974845582311342, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.06901799, 0.0731358 , 0.07949154, 0.08253514,\n",
       "                     0.08423597, 0.08548921, 0.09112882, 0.09649987, 0.10169188,\n",
       "                     0.10285561, 0.10482499, 0.10527258, 0.10598872, 0.10939039,\n",
       "                     0.11064363, 0.1110017 , 0.11941635, 0.1355295 , 0.14304897,\n",
       "                     0.14609256, 0.14797243, 0.15047892, 0.16578641, 0.16766628,\n",
       "                     0.16945663, 0.17679706, 0.17715513, 0.17733417, 0.18548026,\n",
       "                     0.18888193, 0.19425298, 0.19783368, 0.20123534, 0.20517411,\n",
       "                     0.2097395 , 0.22039209, 0.22719542, 0.24679975, 0.25539343,\n",
       "                     0.27678811, 0.28305434, 0.29021574, 0.29415451, 0.29800376,\n",
       "                     0.30006266, 0.30194253, 0.30212156, 0.30256915, 0.30418047,\n",
       "                     0.30543371, 0.30892489, 0.309462  , 0.3145645 , 0.31742906,\n",
       "                     0.32566467, 0.33909229, 0.34150927, 0.34902874, 0.40811029,\n",
       "                     0.41258616, 0.41392892, 0.41679348, 0.42109032, 0.43917286,\n",
       "                     0.44409632, 0.44597619, 0.45680781, 0.46208934, 0.46925074,\n",
       "                     0.47220482, 0.48097753, 0.48715424, 0.49046639, 0.49261481,\n",
       "                     0.49807537, 0.4992391 , 0.50058186, 0.51105541, 0.52269269,\n",
       "                     0.53057023, 0.53137588, 0.53316623, 0.54113329, 0.54704145,\n",
       "                     0.55330767, 0.55491899, 0.55644078, 0.55814162, 0.57121117,\n",
       "                     0.57676126, 0.5846388 , 0.58893564, 0.59287441, 0.5979769 ,\n",
       "                     0.63091934, 0.63817026, 0.64237758, 0.64667442, 0.64748008,\n",
       "                     0.65249306, 0.65365679, 0.65634231, 0.65714797, 0.65813266,\n",
       "                     0.6583117 , 0.66063915, 0.66144481, 0.67218691, 0.67397726,\n",
       "                     0.67487244, 0.68221287, 0.69841554, 0.70871005, 0.71023185,\n",
       "                     0.71121654, 0.72186913, 0.72213768, 0.72374899, 0.72473369,\n",
       "                     0.72527079, 0.72607645, 0.72697162, 0.72920956, 0.73207412,\n",
       "                     0.73332737, 0.73753469, 0.73825083, 0.739146  , 0.74227912,\n",
       "                     0.76618029, 0.77092472, 0.77253603, 0.77459493, 0.77916033,\n",
       "                     0.78130875, 0.78632173, 0.78757497, 0.78891773, 0.78936532,\n",
       "                     0.79133471, 0.79393071, 0.79849611, 0.80171874, 0.80324053,\n",
       "                     0.8045833 , 0.80843255, 0.81443022, 0.81836899, 0.81971175,\n",
       "                     0.82033838, 0.82517232, 0.82633605, 0.82937964, 0.8317071 ,\n",
       "                     0.83725718, 0.84173306, 0.84585086, 0.84817832, 0.85354937,\n",
       "                     0.85435503, 0.85659296, 0.86429147, 0.86643989, 0.86930445,\n",
       "                     0.86984155, 0.8731537 , 0.89696536, 0.90018799, 0.90117268,\n",
       "                     0.90520097, 0.9084236 , 0.90967684, 0.91119864, 0.91155671,\n",
       "                     0.91388416, 0.91495837, 0.91603258, 0.91728583, 0.91800197,\n",
       "                     0.91898666, 0.91961328, 0.92032942, 0.92167219, 0.92453675,\n",
       "                     0.92659565, 0.93447319, 0.93841196, 0.9447677 , 0.94754274,\n",
       "                     0.95130248, 0.95327186, 0.95407752, 0.95559932, 0.95640498,\n",
       "                     0.95828484, 0.95971712, 0.95989616, 0.96159699, 0.96159699,\n",
       "                     0.96168651, 0.96455107, 0.96499866, 0.96535673, 0.96947453,\n",
       "                     0.97019067, 0.97153343, 0.97233909, 0.9728762 , 0.97448751,\n",
       "                     0.97878435, 0.98021663, 0.98030615, 0.98048518, 0.98129084,\n",
       "                     0.98138036, 0.98218602, 0.98245457, 0.9826336 , 0.98290216,\n",
       "                     0.98334974, 0.98460299, 0.98460299, 0.98540865, 0.98576672,\n",
       "                     0.98657237, 1.        ]), tpr=array([0.        , 0.07438904, 0.07850685, 0.08548921, 0.08960702,\n",
       "                     0.0910393 , 0.09238206, 0.09900636, 0.10375078, 0.11109122,\n",
       "                     0.11288157, 0.1145824 , 0.11538806, 0.1161042 , 0.12102766,\n",
       "                     0.12156477, 0.12210187, 0.13168024, 0.14967326, 0.15746128,\n",
       "                     0.16032584, 0.16220571, 0.16453317, 0.18019873, 0.18234715,\n",
       "                     0.18440605, 0.1933578 , 0.19416346, 0.19496912, 0.20293617,\n",
       "                     0.20723301, 0.21161937, 0.21564766, 0.21931788, 0.22397279,\n",
       "                     0.22835914, 0.23883269, 0.24635216, 0.26398711, 0.27347596,\n",
       "                     0.2936174 , 0.29943604, 0.30892489, 0.31340077, 0.31626533,\n",
       "                     0.31805568, 0.32002506, 0.32100976, 0.32271059, 0.32512756,\n",
       "                     0.32629129, 0.33023006, 0.33067765, 0.33586966, 0.33953988,\n",
       "                     0.34750694, 0.35842807, 0.36012891, 0.368275  , 0.42941545,\n",
       "                     0.43442843, 0.43657685, 0.44006803, 0.44508101, 0.46199982,\n",
       "                     0.46593859, 0.46799749, 0.47730731, 0.48321547, 0.48966073,\n",
       "                     0.49288336, 0.50210366, 0.50801182, 0.5130248 , 0.51472563,\n",
       "                     0.52134992, 0.52314027, 0.52555725, 0.534509  , 0.54551965,\n",
       "                     0.55321815, 0.5544714 , 0.55644078, 0.56539253, 0.57300152,\n",
       "                     0.57926775, 0.58213231, 0.58383314, 0.58535494, 0.59520186,\n",
       "                     0.59976725, 0.60746576, 0.61104646, 0.6138215 , 0.62062483,\n",
       "                     0.65159789, 0.65777459, 0.66046012, 0.6654731 , 0.66708442,\n",
       "                     0.67138126, 0.67317161, 0.67505147, 0.67612568, 0.67728941,\n",
       "                     0.67791603, 0.68015397, 0.68095963, 0.69385015, 0.69492436,\n",
       "                     0.69653567, 0.70548742, 0.72231671, 0.73091039, 0.73243219,\n",
       "                     0.73341688, 0.74505416, 0.7457703 , 0.74773968, 0.74827679,\n",
       "                     0.74926148, 0.75015666, 0.75167845, 0.75311073, 0.7565124 ,\n",
       "                     0.75776564, 0.76071972, 0.76152538, 0.76349476, 0.76797064,\n",
       "                     0.79017098, 0.79500492, 0.79697431, 0.7994808 , 0.80476233,\n",
       "                     0.80780593, 0.81425119, 0.81523588, 0.81631009, 0.81675768,\n",
       "                     0.81810044, 0.82194969, 0.8266046 , 0.83197565, 0.83313938,\n",
       "                     0.83385552, 0.83824188, 0.8445081 , 0.84952108, 0.85086384,\n",
       "                     0.85184854, 0.85542924, 0.85632441, 0.85892042, 0.86196401,\n",
       "                     0.86661892, 0.86823024, 0.87145287, 0.87431743, 0.8787933 ,\n",
       "                     0.879778  , 0.88165786, 0.88971444, 0.89204189, 0.89365321,\n",
       "                     0.8946379 , 0.89687584, 0.92382061, 0.92731179, 0.92802793,\n",
       "                     0.93259332, 0.93590547, 0.93742727, 0.93957569, 0.93975472,\n",
       "                     0.94127652, 0.94172411, 0.94261928, 0.9432459 , 0.94360397,\n",
       "                     0.94432011, 0.94494674, 0.94593143, 0.94745323, 0.95067586,\n",
       "                     0.95264524, 0.95935905, 0.96249217, 0.96813177, 0.97045922,\n",
       "                     0.97350282, 0.97475606, 0.97600931, 0.976994  , 0.97806821,\n",
       "                     0.97923194, 0.98012711, 0.98030615, 0.98218602, 0.98236505,\n",
       "                     0.98254409, 0.98451347, 0.98496106, 0.98540865, 0.98836272,\n",
       "                     0.98854176, 0.98898935, 0.98934742, 0.98988452, 0.9913168 ,\n",
       "                     0.99453943, 0.99624026, 0.99632978, 0.9964193 , 0.99704592,\n",
       "                     0.99713544, 0.99722496, 0.99740399, 0.99758303, 0.99829917,\n",
       "                     0.99874675, 0.99928386, 0.99946289, 0.99964193, 0.99991048,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.15062052e-02, -3.77403280e-02,\n",
       "                     -4.25596144e-02, -6.06246218e-02, -6.45385211e-02, -7.79615415e-02,\n",
       "                     -9.01510970e-02, -9.30904231e-02, -9.53101798e-02, -1.00083459e-01,\n",
       "                     -1.05360516e-01, -1.17783036e-01, -1.19801200e-01, -1.54150680e-01,\n",
       "                     -1.54150680e-01, -1.63453072e-01, -1.64755233e-01, -1.68820870e-01,\n",
       "                     -1.71850257e-01, -1.74353387e-01, -1.75890666e-01, -1.82321557e-01,\n",
       "                     -1.89242000e-01, -1.96710294e-01, -1.98850859e-01, -2.00670695e-01,\n",
       "                     -2.00670695e-01, -2.11843996e-01, -2.23143551e-01, -2.35314087e-01,\n",
       "                     -2.36388778e-01, -2.37671652e-01, -2.38411023e-01, -2.51314428e-01,\n",
       "                     -2.55105902e-01, -2.69663567e-01, -2.77477902e-01, -2.85320796e-01,\n",
       "                     -2.87682072e-01, -2.91520849e-01, -2.92387963e-01, -2.92669614e-01,\n",
       "                     -2.95464213e-01, -3.00104592e-01, -3.10154928e-01, -3.10154928e-01,\n",
       "                     -3.13657559e-01, -3.15081047e-01, -3.25422400e-01, -3.26684230e-01,\n",
       "                     -3.36472237e-01, -3.46276237e-01, -3.46870944e-01, -3.47645537e-01,\n",
       "                     -3.49270550e-01, -3.51397887e-01, -3.56674944e-01, -3.65131037e-01,\n",
       "                     -3.69097464e-01, -3.77294231e-01, -3.79489622e-01, -3.81367557e-01,\n",
       "                     -3.89464767e-01, -3.90197636e-01, -3.90866309e-01, -3.92561703e-01,\n",
       "                     -3.95312737e-01, -4.05465108e-01, -4.05465108e-01, -4.08696129e-01,\n",
       "                     -4.15515444e-01, -4.17299566e-01, -4.22856851e-01, -4.32133355e-01,\n",
       "                     -4.38254931e-01, -4.41832752e-01, -4.44685821e-01, -4.50505834e-01,\n",
       "                     -4.50927482e-01, -4.51985124e-01, -4.64305608e-01, -4.70003629e-01,\n",
       "                     -4.77329669e-01, -4.78892577e-01, -4.85507816e-01, -4.89548225e-01,\n",
       "                     -4.98991166e-01, -5.03526321e-01, -5.10825624e-01, -5.22386446e-01,\n",
       "                     -5.30628251e-01, -5.36304709e-01, -5.36801110e-01, -5.40440544e-01,\n",
       "                     -5.45016989e-01, -5.50046337e-01, -5.59615788e-01, -5.75364145e-01,\n",
       "                     -5.83146285e-01, -5.87786665e-01, -5.93063722e-01, -6.06135804e-01,\n",
       "                     -6.13104473e-01, -6.19039208e-01, -6.31271777e-01, -6.35988767e-01,\n",
       "                     -6.43314807e-01, -6.50587566e-01, -6.64976304e-01, -6.72944473e-01,\n",
       "                     -6.93147181e-01, -7.13766468e-01, -7.22134717e-01, -7.37598943e-01,\n",
       "                     -7.45593656e-01, -7.53771802e-01, -7.59105148e-01, -7.73189888e-01,\n",
       "                     -7.80158558e-01, -7.88457360e-01, -8.04372816e-01, -8.10930216e-01,\n",
       "                     -8.16761137e-01, -8.26678573e-01, -8.47297860e-01, -8.47297860e-01,\n",
       "                     -8.60201265e-01, -8.67100488e-01, -8.73450573e-01, -8.78550404e-01,\n",
       "                     -8.79249460e-01, -8.87303195e-01, -8.99196299e-01, -9.16290732e-01,\n",
       "                     -9.27340568e-01, -9.34309237e-01, -9.49080555e-01, -9.55511445e-01,\n",
       "                     -9.55511445e-01, -9.66187703e-01, -9.68737207e-01, -9.80829253e-01,\n",
       "                     -9.90398704e-01, -1.01160091e+00, -1.01345448e+00, -1.01419495e+00,\n",
       "                     -1.02450432e+00, -1.02961942e+00, -1.03609193e+00, -1.04731899e+00,\n",
       "                     -1.06471074e+00, -1.07535543e+00, -1.07880966e+00, -1.09218140e+00,\n",
       "                     -1.09861229e+00, -1.09861229e+00, -1.11923158e+00, -1.12492960e+00,\n",
       "                     -1.12846525e+00, -1.12986483e+00, -1.13140211e+00, -1.14862271e+00,\n",
       "                     -1.15267951e+00, -1.15745279e+00, -1.17557333e+00, -1.18451563e+00,\n",
       "                     -1.20397280e+00, -1.21639532e+00, -1.22146596e+00, -1.22536399e+00,\n",
       "                     -1.22722967e+00, -1.22866542e+00, -1.25276297e+00, -1.27766052e+00,\n",
       "                     -1.28093385e+00, -1.30833282e+00, -1.31218639e+00, -1.32175584e+00,\n",
       "                     -1.32175584e+00, -1.34992672e+00, -1.36330484e+00, -1.37147928e+00,\n",
       "                     -1.37230812e+00, -1.37486567e+00, -1.38629436e+00, -1.39341183e+00,\n",
       "                     -1.41754690e+00, -1.44238383e+00, -1.49091931e+00, -1.50407740e+00,\n",
       "                     -1.55059741e+00, -1.55334845e+00, -1.55814462e+00, -1.56218503e+00,\n",
       "                     -1.60943791e+00, -1.60943791e+00, -1.65595793e+00, -1.70474809e+00,\n",
       "                     -1.70474809e+00, -1.71297859e+00, -1.72276660e+00, -1.75785792e+00,\n",
       "                     -1.79175947e+00, -1.79175947e+00, -1.82454929e+00, -1.83258146e+00,\n",
       "                     -1.84582669e+00, -1.86214027e+00, -1.88454120e+00, -1.89184293e+00,\n",
       "                     -1.94591015e+00, -1.94591015e+00, -2.18122424e+00, -2.19722458e+00,\n",
       "                     -2.30258509e+00, -2.35137526e+00, -2.39789527e+00, -2.42036813e+00,\n",
       "                     -2.45100510e+00, -2.59026717e+00, -2.83321334e+00, -3.17805383e+00,\n",
       "                     -3.29583687e+00, -3.85014760e+00, -3.45387764e+01]), auc_score=0.5196193938002428, privacy_risk=0.5157550801181631, accuracy=0.5157550801181631, tpr_ind=0.851848536388864, tnr_ind=0.17966162384746218, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.06678006, 0.07286725, 0.07447856, 0.07537374,\n",
       "                     0.07582132, 0.08146093, 0.08754812, 0.09023364, 0.09587324,\n",
       "                     0.09766359, 0.09918539, 0.09990153, 0.11744696, 0.12004297,\n",
       "                     0.12460836, 0.12783099, 0.12899472, 0.130427  , 0.13069555,\n",
       "                     0.13884164, 0.1417062 , 0.14510787, 0.14707725, 0.15119506,\n",
       "                     0.15217975, 0.15495479, 0.15710321, 0.16095247, 0.18163101,\n",
       "                     0.18342136, 0.18834482, 0.19299973, 0.21511055, 0.22701638,\n",
       "                     0.23032853, 0.23256647, 0.23355116, 0.2342673 , 0.23963835,\n",
       "                     0.24447229, 0.24608361, 0.25073852, 0.25351356, 0.26380807,\n",
       "                     0.26747829, 0.27195417, 0.28126399, 0.28412855, 0.28726166,\n",
       "                     0.29164802, 0.29934652, 0.30149494, 0.30838779, 0.31187897,\n",
       "                     0.32199445, 0.33166234, 0.3330051 , 0.34204637, 0.34813356,\n",
       "                     0.35269895, 0.3544893 , 0.35807   , 0.36209829, 0.3667532 ,\n",
       "                     0.36809596, 0.37472026, 0.38438815, 0.38752126, 0.39557784,\n",
       "                     0.40685704, 0.40846836, 0.42234357, 0.42323874, 0.42995256,\n",
       "                     0.43362277, 0.45331662, 0.45465939, 0.4598514 , 0.4664757 ,\n",
       "                     0.47229433, 0.47650166, 0.48052994, 0.48473727, 0.48813893,\n",
       "                     0.48948169, 0.49189867, 0.49467371, 0.49700116, 0.50416256,\n",
       "                     0.50496822, 0.50577388, 0.50702712, 0.50890699, 0.51633694,\n",
       "                     0.51857488, 0.51955957, 0.52036523, 0.52716856, 0.53307672,\n",
       "                     0.53620983, 0.53746307, 0.54301316, 0.55133829, 0.55563513,\n",
       "                     0.55948438, 0.56020052, 0.583117  , 0.58437024, 0.58830901,\n",
       "                     0.60630203, 0.60907707, 0.61391102, 0.61641751, 0.62214663,\n",
       "                     0.62975562, 0.63065079, 0.63127741, 0.63208307, 0.63288873,\n",
       "                     0.63897592, 0.64336228, 0.64479456, 0.64721153, 0.6490914 ,\n",
       "                     0.65222451, 0.654731  , 0.65652135, 0.65813266, 0.65893832,\n",
       "                     0.6598335 , 0.66368275, 0.67048608, 0.67138126, 0.67397726,\n",
       "                     0.67630472, 0.6782741 , 0.68104915, 0.69519291, 0.69805747,\n",
       "                     0.70011637, 0.70298093, 0.71005282, 0.71085847, 0.71461821,\n",
       "                     0.71676663, 0.71828843, 0.7207054 , 0.72258527, 0.72455465,\n",
       "                     0.72706114, 0.72885149, 0.73019425, 0.73126846, 0.73395399,\n",
       "                     0.73484916, 0.739146  , 0.74210008, 0.74317429, 0.74380091,\n",
       "                     0.74460657, 0.74532271, 0.74979859, 0.75239459, 0.75248411,\n",
       "                     0.75409543, 0.75776564, 0.75973503, 0.76224152, 0.7713723 ,\n",
       "                     0.77334169, 0.77396831, 0.78954436, 0.79106615, 0.79258795,\n",
       "                     0.79428878, 0.79849611, 0.80234536, 0.80449378, 0.80565751,\n",
       "                     0.8087011 , 0.81040193, 0.81156566, 0.81237132, 0.81317698,\n",
       "                     0.82015934, 0.82141259, 0.82284487, 0.82311342, 0.82347149,\n",
       "                     0.82857399, 0.82929013, 0.83099096, 0.83233372, 0.83296034,\n",
       "                     0.83510876, 0.83609346, 0.83779429, 0.83976367, 0.84209113,\n",
       "                     0.84737266, 0.84880494, 0.85104288, 0.85900994, 0.86062125,\n",
       "                     0.86276967, 0.86411243, 0.87100528, 0.87216901, 0.87539164,\n",
       "                     0.8787933 , 0.87906186, 0.88309014, 0.88586519, 0.8874765 ,\n",
       "                     0.88935637, 0.88998299, 0.8910572 , 0.89275803, 0.89347417,\n",
       "                     0.89490645, 0.89678632, 0.90135171, 0.90251544, 0.90573807,\n",
       "                     0.91003491, 0.91155671, 0.91370513, 0.91468982, 0.91898666,\n",
       "                     0.92015039, 0.92265688, 0.92435771, 0.93062394, 0.93160863,\n",
       "                     0.93259332, 0.93689016, 0.9370692 , 0.9391281 , 0.93984424,\n",
       "                     0.94181362, 0.94351446, 0.94369349, 0.94432011, 0.94503625,\n",
       "                     0.94575239, 0.94969116, 0.95819533, 0.96025423, 0.96159699,\n",
       "                     0.9626712 , 0.96732611, 0.96795273, 0.96848984, 0.97010115,\n",
       "                     0.97028019, 0.9713544 , 0.97153343, 0.97305523, 0.97377137,\n",
       "                     0.97395041, 0.97538269, 0.9754722 , 0.97583027, 0.97672545,\n",
       "                     0.976994  , 0.97842628, 0.97914242, 0.98173843, 0.98191746,\n",
       "                     0.98290216, 0.98308119, 0.98326023, 0.98469251, 0.98487154,\n",
       "                     0.98639334, 0.98666189, 0.98701996, 0.98710948, 0.98746755,\n",
       "                     0.98755707, 1.        ]), tpr=array([0.        , 0.06678006, 0.07233014, 0.07447856, 0.07582132,\n",
       "                     0.07698505, 0.08271417, 0.09041268, 0.0925611 , 0.09846925,\n",
       "                     0.10088622, 0.1038403 , 0.10455644, 0.12156477, 0.12469788,\n",
       "                     0.12962134, 0.13418673, 0.13642467, 0.13794647, 0.13893116,\n",
       "                     0.14752484, 0.15065795, 0.15450721, 0.15620804, 0.16041536,\n",
       "                     0.16166861, 0.16489124, 0.16766628, 0.17115746, 0.19299973,\n",
       "                     0.19452153, 0.20042968, 0.20624832, 0.22880673, 0.24160773,\n",
       "                     0.24438278, 0.24679975, 0.24814251, 0.2491272 , 0.25494584,\n",
       "                     0.26130158, 0.26318145, 0.26837347, 0.26989526, 0.28269627,\n",
       "                     0.28690359, 0.29218512, 0.30212156, 0.30623937, 0.31125235,\n",
       "                     0.31528064, 0.32369528, 0.32602274, 0.33363173, 0.33774953,\n",
       "                     0.34938681, 0.35896518, 0.36120312, 0.3703339 , 0.37633157,\n",
       "                     0.38116552, 0.3831349 , 0.38796885, 0.39110196, 0.39521977,\n",
       "                     0.39665205, 0.40229165, 0.4112434 , 0.41401844, 0.42091129,\n",
       "                     0.43147435, 0.43281712, 0.44615522, 0.44767702, 0.45394325,\n",
       "                     0.45770298, 0.47614359, 0.47865008, 0.48321547, 0.49037687,\n",
       "                     0.49610599, 0.49968669, 0.50308835, 0.50747471, 0.51078686,\n",
       "                     0.51293528, 0.51606839, 0.51929102, 0.52152896, 0.52886939,\n",
       "                     0.52949602, 0.53057023, 0.53236058, 0.53486707, 0.54310268,\n",
       "                     0.54471399, 0.54587772, 0.54775759, 0.5524125 , 0.55832065,\n",
       "                     0.56136425, 0.56342315, 0.56798854, 0.57452332, 0.57810402,\n",
       "                     0.58150568, 0.58293796, 0.60522782, 0.60639155, 0.60934563,\n",
       "                     0.62510071, 0.62778623, 0.63315728, 0.63566377, 0.64201951,\n",
       "                     0.64801719, 0.64953898, 0.65070271, 0.65150837, 0.65276161,\n",
       "                     0.65670038, 0.66072867, 0.66269806, 0.66520455, 0.66672635,\n",
       "                     0.67102319, 0.6746934 , 0.67782652, 0.67916928, 0.68060156,\n",
       "                     0.68212336, 0.68454033, 0.68955331, 0.69044848, 0.69546146,\n",
       "                     0.69832602, 0.70047444, 0.70414466, 0.71739325, 0.72097395,\n",
       "                     0.72303285, 0.72571838, 0.73028377, 0.73108943, 0.7355653 ,\n",
       "                     0.73771372, 0.73905649, 0.74030973, 0.74147346, 0.74415898,\n",
       "                     0.7472921 , 0.74908245, 0.7508728 , 0.75212604, 0.75418494,\n",
       "                     0.75579626, 0.75901889, 0.762152  , 0.76313669, 0.76376332,\n",
       "                     0.76465849, 0.76582222, 0.77038761, 0.77522156, 0.77549011,\n",
       "                     0.77710142, 0.77907081, 0.78104019, 0.78292006, 0.79393071,\n",
       "                     0.79598962, 0.79679527, 0.81219228, 0.81317698, 0.81550443,\n",
       "                     0.8179214 , 0.82230776, 0.82535136, 0.82669412, 0.8286635 ,\n",
       "                     0.83242324, 0.83537732, 0.83654104, 0.83725718, 0.83824188,\n",
       "                     0.84325486, 0.84477665, 0.84585086, 0.84647749, 0.84683556,\n",
       "                     0.85095336, 0.85220661, 0.85399696, 0.85569779, 0.85686152,\n",
       "                     0.85865187, 0.86097932, 0.86276967, 0.86464954, 0.86760362,\n",
       "                     0.87127383, 0.87360129, 0.87485453, 0.88407484, 0.88586519,\n",
       "                     0.88881926, 0.8895354 , 0.89580163, 0.89642825, 0.90135171,\n",
       "                     0.90448483, 0.90573807, 0.90976636, 0.91227285, 0.91289947,\n",
       "                     0.91468982, 0.91522693, 0.91603258, 0.91809149, 0.91889714,\n",
       "                     0.92086653, 0.9232835 , 0.92695372, 0.92784889, 0.93160863,\n",
       "                     0.93617402, 0.93778534, 0.94073941, 0.94163459, 0.94485722,\n",
       "                     0.94637902, 0.94825888, 0.94978068, 0.95309283, 0.95479366,\n",
       "                     0.95613642, 0.96016471, 0.9606123 , 0.9621341 , 0.9626712 ,\n",
       "                     0.96446155, 0.96607287, 0.96634142, 0.96669949, 0.96732611,\n",
       "                     0.96804225, 0.97126488, 0.97690448, 0.97833676, 0.97976904,\n",
       "                     0.98012711, 0.98522961, 0.98603527, 0.98666189, 0.98737803,\n",
       "                     0.98764658, 0.98854176, 0.98889983, 0.98970549, 0.99015307,\n",
       "                     0.99033211, 0.99194342, 0.99212246, 0.99239101, 0.99274908,\n",
       "                     0.99346522, 0.99418136, 0.99462895, 0.99704592, 0.99713544,\n",
       "                     0.99749351, 0.99767254, 0.99776206, 0.99829917, 0.9984782 ,\n",
       "                     0.99910482, 0.99955241, 0.99964193, 0.99973145, 0.99982096,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.17486983e-02, -4.08219945e-02,\n",
       "                     -6.45385211e-02, -7.41079722e-02, -7.52234212e-02, -7.82521969e-02,\n",
       "                     -8.00427077e-02, -8.70113770e-02, -1.05360516e-01, -1.14410351e-01,\n",
       "                     -1.17783036e-01, -1.32873281e-01, -1.33531393e-01, -1.35801541e-01,\n",
       "                     -1.45711811e-01, -1.48420005e-01, -1.62518929e-01, -1.67054085e-01,\n",
       "                     -1.71850257e-01, -1.82321557e-01, -1.90043603e-01, -1.91055237e-01,\n",
       "                     -1.92903666e-01, -1.94156014e-01, -2.00670695e-01, -2.03598955e-01,\n",
       "                     -2.07639365e-01, -2.09942039e-01, -2.11309094e-01, -2.17064505e-01,\n",
       "                     -2.20061885e-01, -2.23143551e-01, -2.24541176e-01, -2.29574442e-01,\n",
       "                     -2.30523659e-01, -2.36388778e-01, -2.41162057e-01, -2.44453338e-01,\n",
       "                     -2.48179629e-01, -2.51314428e-01, -2.57045103e-01, -2.57829109e-01,\n",
       "                     -2.73597333e-01, -2.76986783e-01, -2.79171383e-01, -2.87682072e-01,\n",
       "                     -3.14493330e-01, -3.18453731e-01, -3.20471895e-01, -3.24239668e-01,\n",
       "                     -3.25422400e-01, -3.28033368e-01, -3.30241687e-01, -3.30962581e-01,\n",
       "                     -3.31117471e-01, -3.36472237e-01, -3.37871817e-01, -3.38602163e-01,\n",
       "                     -3.41749294e-01, -3.42944751e-01, -3.54821375e-01, -3.56674944e-01,\n",
       "                     -3.61013346e-01, -3.62905494e-01, -3.67724780e-01, -3.71563556e-01,\n",
       "                     -3.72675285e-01, -3.74693449e-01, -3.82606970e-01, -3.82992252e-01,\n",
       "                     -3.85125424e-01, -3.85662481e-01, -3.86233746e-01, -3.89464767e-01,\n",
       "                     -4.05465108e-01, -4.05465108e-01, -4.11979789e-01, -4.13763911e-01,\n",
       "                     -4.15827895e-01, -4.21994410e-01, -4.22856851e-01, -4.25667815e-01,\n",
       "                     -4.32133355e-01, -4.32864082e-01, -4.33635985e-01, -4.41832752e-01,\n",
       "                     -4.44685821e-01, -4.45311017e-01, -4.51985124e-01, -4.59532329e-01,\n",
       "                     -4.70003629e-01, -4.74457980e-01, -4.75423697e-01, -4.76924072e-01,\n",
       "                     -4.79573080e-01, -4.81838087e-01, -4.91407538e-01, -4.92476485e-01,\n",
       "                     -4.98991166e-01, -5.02091944e-01, -5.10825624e-01, -5.13561604e-01,\n",
       "                     -5.15813165e-01, -5.21296924e-01, -5.23248144e-01, -5.25179937e-01,\n",
       "                     -5.26093096e-01, -5.28844129e-01, -5.29959578e-01, -5.30628251e-01,\n",
       "                     -5.50046337e-01, -5.59615788e-01, -5.65633860e-01, -5.65992005e-01,\n",
       "                     -5.67984038e-01, -5.70544858e-01, -5.75364145e-01, -5.79818495e-01,\n",
       "                     -5.85258219e-01, -5.87786665e-01, -5.97837001e-01, -5.99621123e-01,\n",
       "                     -6.00773860e-01, -6.06135804e-01, -6.17161274e-01, -6.19039208e-01,\n",
       "                     -6.24154309e-01, -6.28608659e-01, -6.32522559e-01, -6.35988767e-01,\n",
       "                     -6.38087403e-01, -6.41853886e-01, -6.47477144e-01, -6.61398482e-01,\n",
       "                     -6.72093771e-01, -6.80877088e-01, -6.93147181e-01, -7.05569701e-01,\n",
       "                     -7.14653386e-01, -7.25937003e-01, -7.41003202e-01, -7.47214402e-01,\n",
       "                     -7.51416089e-01, -7.53771802e-01, -7.57685702e-01, -7.62140052e-01,\n",
       "                     -7.67255153e-01, -7.73189888e-01, -7.75385279e-01, -7.88457360e-01,\n",
       "                     -7.88457360e-01, -7.94929875e-01, -7.96331417e-01, -7.98507696e-01,\n",
       "                     -8.10930216e-01, -8.14099791e-01, -8.20980552e-01, -8.26678573e-01,\n",
       "                     -8.32909123e-01, -8.36248024e-01, -8.38858992e-01, -8.39329691e-01,\n",
       "                     -8.47297860e-01, -8.47297860e-01, -8.60201265e-01, -8.60201265e-01,\n",
       "                     -8.87303195e-01, -8.88259218e-01, -8.89857475e-01, -8.93817876e-01,\n",
       "                     -8.95138357e-01, -8.97941593e-01, -9.00786545e-01, -9.08855753e-01,\n",
       "                     -9.12200747e-01, -9.16290732e-01, -9.29535959e-01, -9.34309237e-01,\n",
       "                     -9.44461609e-01, -9.46143695e-01, -9.61411167e-01, -9.65080896e-01,\n",
       "                     -9.69400557e-01, -9.71860583e-01, -9.73449146e-01, -9.80829253e-01,\n",
       "                     -9.98528830e-01, -1.01160091e+00, -1.02338887e+00, -1.02450432e+00,\n",
       "                     -1.02961942e+00, -1.04454507e+00, -1.04596856e+00, -1.04731899e+00,\n",
       "                     -1.05939158e+00, -1.06471074e+00, -1.06635143e+00, -1.07820342e+00,\n",
       "                     -1.08221848e+00, -1.08570888e+00, -1.09861229e+00, -1.09861229e+00,\n",
       "                     -1.13140211e+00, -1.13822143e+00, -1.13943428e+00, -1.14057649e+00,\n",
       "                     -1.14513230e+00, -1.14595841e+00, -1.16315081e+00, -1.16760516e+00,\n",
       "                     -1.17007125e+00, -1.17865500e+00, -1.18958407e+00, -1.19392247e+00,\n",
       "                     -1.20397280e+00, -1.20397280e+00, -1.20831121e+00, -1.23676263e+00,\n",
       "                     -1.23969089e+00, -1.24745792e+00, -1.24927256e+00, -1.25276297e+00,\n",
       "                     -1.26627669e+00, -1.26667140e+00, -1.26851133e+00, -1.27417706e+00,\n",
       "                     -1.28093385e+00, -1.28401551e+00, -1.29392104e+00, -1.29928298e+00,\n",
       "                     -1.30992138e+00, -1.38629436e+00, -1.41226985e+00, -1.41908418e+00,\n",
       "                     -1.42977947e+00, -1.48160454e+00, -1.48427477e+00, -1.50407740e+00,\n",
       "                     -1.51512723e+00, -1.52846885e+00, -1.54044504e+00, -1.55814462e+00,\n",
       "                     -1.58045038e+00, -1.58412010e+00, -1.60386687e+00, -1.60943791e+00,\n",
       "                     -1.62186043e+00, -1.63413053e+00, -1.65822808e+00, -1.66405900e+00,\n",
       "                     -1.67397643e+00, -1.69167601e+00, -1.70474809e+00, -1.73460106e+00,\n",
       "                     -1.74046617e+00, -1.74919985e+00, -1.75401914e+00, -1.79175947e+00,\n",
       "                     -1.79175947e+00, -1.84582669e+00, -1.87180218e+00, -1.89711998e+00,\n",
       "                     -1.98100147e+00, -1.99809590e+00, -2.06369318e+00, -2.07944154e+00,\n",
       "                     -2.08406049e+00, -2.19722458e+00, -2.22462355e+00, -2.30258509e+00,\n",
       "                     -2.30258509e+00, -2.48490665e+00, -2.56494936e+00, -2.58668934e+00,\n",
       "                     -2.62466859e+00, -2.63905733e+00, -2.77258872e+00, -3.21887582e+00,\n",
       "                     -3.46573590e+00, -3.45387764e+01]), auc_score=0.5187477060188863, privacy_risk=0.5149494226121207, accuracy=0.5149494226121206, tpr_ind=0.3879688479097664, tnr_ind=0.641929997314475, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.04896607, 0.05353147, 0.05926059, 0.06105094,\n",
       "                     0.06454212, 0.07707457, 0.08262465, 0.08423597, 0.0889804 ,\n",
       "                     0.09050219, 0.09139737, 0.09220303, 0.0930982 , 0.11216543,\n",
       "                     0.11682034, 0.12595112, 0.1283681 , 0.13114314, 0.13517143,\n",
       "                     0.13705129, 0.13785695, 0.14242234, 0.15029988, 0.15101602,\n",
       "                     0.15593949, 0.15737177, 0.15996777, 0.16175812, 0.16757676,\n",
       "                     0.17634948, 0.1784979 , 0.18476412, 0.18753916, 0.18968758,\n",
       "                     0.19147793, 0.1954167 , 0.20114582, 0.20875481, 0.22683735,\n",
       "                     0.23686331, 0.23945931, 0.24223436, 0.24805299, 0.25243935,\n",
       "                     0.2536926 , 0.26828395, 0.28466565, 0.31581774, 0.3243219 ,\n",
       "                     0.32772357, 0.32861874, 0.33336317, 0.33891326, 0.37991227,\n",
       "                     0.38232925, 0.40157551, 0.40452959, 0.40811029, 0.41885239,\n",
       "                     0.42243309, 0.4261033 , 0.42923642, 0.43514457, 0.43881479,\n",
       "                     0.44239549, 0.44749799, 0.44928834, 0.46746039, 0.47032495,\n",
       "                     0.47184675, 0.48294692, 0.48724376, 0.49082446, 0.49279384,\n",
       "                     0.49673261, 0.4977173 , 0.50138752, 0.5022827 , 0.50380449,\n",
       "                     0.51069734, 0.51400949, 0.52519918, 0.53012264, 0.53173395,\n",
       "                     0.54247605, 0.54480351, 0.54668338, 0.55733596, 0.5652135 ,\n",
       "                     0.56557157, 0.58544445, 0.58696625, 0.59555993, 0.60486975,\n",
       "                     0.61516426, 0.6174022 , 0.61784979, 0.61964014, 0.62152001,\n",
       "                     0.6230418 , 0.62626443, 0.64130337, 0.64765912, 0.65106078,\n",
       "                     0.65294065, 0.65464148, 0.65643183, 0.6583117 , 0.65858025,\n",
       "                     0.66448841, 0.66609972, 0.66654731, 0.66771104, 0.67191836,\n",
       "                     0.67728941, 0.69044848, 0.69528243, 0.69957927, 0.70020589,\n",
       "                     0.70083251, 0.70154865, 0.70602453, 0.70665115, 0.70772536,\n",
       "                     0.70942619, 0.71229075, 0.71479724, 0.71587145, 0.71927312,\n",
       "                     0.73108943, 0.73216364, 0.73323785, 0.73458061, 0.73520723,\n",
       "                     0.73592337, 0.73619193, 0.73825083, 0.74281622, 0.7514099 ,\n",
       "                     0.75758661, 0.7606302 , 0.77208844, 0.77280458, 0.77781756,\n",
       "                     0.78354668, 0.78542655, 0.78730642, 0.79312506, 0.79366216,\n",
       "                     0.79715334, 0.80655268, 0.80744786, 0.81013338, 0.81183421,\n",
       "                     0.81317698, 0.81469877, 0.81568347, 0.81774237, 0.81899561,\n",
       "                     0.82168114, 0.82615701, 0.8322442 , 0.83296034, 0.83412407,\n",
       "                     0.84164354, 0.84253872, 0.84576135, 0.84665652, 0.84925253,\n",
       "                     0.85498165, 0.85516068, 0.85650345, 0.85847283, 0.8603527 ,\n",
       "                     0.86500761, 0.86670844, 0.86975204, 0.87610778, 0.87709247,\n",
       "                     0.89517501, 0.89884522, 0.90162027, 0.90206785, 0.9038582 ,\n",
       "                     0.9089607 , 0.92113508, 0.92641661, 0.93169815, 0.93393608,\n",
       "                     0.93590547, 0.93733775, 0.93823292, 0.93850148, 0.94244025,\n",
       "                     0.94691612, 0.94960165, 0.95183958, 0.953988  , 0.95443559,\n",
       "                     0.95542028, 0.95658401, 0.95721063, 0.95864291, 0.95882195,\n",
       "                     0.96186554, 0.96356638, 0.96365589, 0.96446155, 0.96526721,\n",
       "                     0.96607287, 0.96786322, 0.96884791, 0.97063826, 0.97216006,\n",
       "                     0.97260764, 0.9734133 , 0.97430848, 0.97457703, 0.97511413,\n",
       "                     0.97735207, 0.97967953, 0.9836183 , 0.98424492, 0.98424492,\n",
       "                     0.98496106, 0.98594575, 0.98603527, 0.98630382, 0.98701996,\n",
       "                     0.987199  , 0.9877361 , 0.98818369, 0.98836272, 1.        ]), tpr=array([0.        , 0.05433712, 0.0593501 , 0.0639155 , 0.06606392,\n",
       "                     0.0710769 , 0.08557873, 0.09041268, 0.09274013, 0.09837973,\n",
       "                     0.10061767, 0.10258706, 0.10348223, 0.10491451, 0.12523498,\n",
       "                     0.13087459, 0.14125862, 0.14304897, 0.14537642, 0.14877809,\n",
       "                     0.15253782, 0.15361203, 0.15835646, 0.16515979, 0.16659207,\n",
       "                     0.17169457, 0.17536478, 0.17894548, 0.1810939 , 0.18700206,\n",
       "                     0.19622236, 0.19810223, 0.20329424, 0.20723301, 0.21000806,\n",
       "                     0.21099275, 0.21546862, 0.22182437, 0.23059708, 0.24993286,\n",
       "                     0.26067496, 0.26273386, 0.26595649, 0.27177513, 0.27544535,\n",
       "                     0.27813087, 0.29200609, 0.309462  , 0.3401665 , 0.34938681,\n",
       "                     0.35359413, 0.35457882, 0.35923373, 0.36639513, 0.4133023 ,\n",
       "                     0.41607734, 0.43407036, 0.43809865, 0.44320115, 0.45242145,\n",
       "                     0.45546504, 0.45949333, 0.46325307, 0.47095157, 0.47685973,\n",
       "                     0.48070898, 0.48670665, 0.48769134, 0.50344642, 0.50649002,\n",
       "                     0.50819085, 0.51767971, 0.52340883, 0.52743711, 0.52931698,\n",
       "                     0.53334527, 0.534509  , 0.53746307, 0.53907439, 0.54149136,\n",
       "                     0.54802614, 0.55071166, 0.56333363, 0.56771999, 0.56924179,\n",
       "                     0.57935726, 0.58204279, 0.58544445, 0.595918  , 0.60433265,\n",
       "                     0.60504879, 0.62393698, 0.62823382, 0.63772267, 0.6455107 ,\n",
       "                     0.65508907, 0.65741652, 0.6583117 , 0.66046012, 0.66207143,\n",
       "                     0.66404082, 0.66726345, 0.68239191, 0.68892669, 0.69116462,\n",
       "                     0.6935816 , 0.69581953, 0.69778892, 0.69931072, 0.69984782,\n",
       "                     0.7048608 , 0.70620356, 0.70700922, 0.70817295, 0.71193268,\n",
       "                     0.71703518, 0.73099991, 0.73592337, 0.73950407, 0.74057828,\n",
       "                     0.74129442, 0.74245815, 0.74675499, 0.74720258, 0.74845582,\n",
       "                     0.75006714, 0.75185749, 0.75373736, 0.75543819, 0.76036165,\n",
       "                     0.77173037, 0.77253603, 0.77414735, 0.77557963, 0.77674335,\n",
       "                     0.77826515, 0.77889177, 0.78050309, 0.78712738, 0.79249843,\n",
       "                     0.79885418, 0.80171874, 0.81371408, 0.81416167, 0.81935368,\n",
       "                     0.82570943, 0.82776833, 0.82937964, 0.83537732, 0.83627249,\n",
       "                     0.83877898, 0.84594038, 0.84746218, 0.8511324 , 0.85247516,\n",
       "                     0.85337033, 0.85498165, 0.85560827, 0.85775669, 0.85874138,\n",
       "                     0.86080029, 0.86366485, 0.86840927, 0.86921493, 0.87064721,\n",
       "                     0.87798765, 0.87843523, 0.88112076, 0.88282159, 0.8854176 ,\n",
       "                     0.88872975, 0.8889983 , 0.89034106, 0.89204189, 0.89329514,\n",
       "                     0.89705487, 0.89911378, 0.90072509, 0.90779697, 0.90887118,\n",
       "                     0.92677468, 0.92946021, 0.93116104, 0.93151911, 0.93304091,\n",
       "                     0.93635306, 0.94736371, 0.95336138, 0.95810581, 0.95900098,\n",
       "                     0.96016471, 0.96195506, 0.96293975, 0.96356638, 0.96678901,\n",
       "                     0.97233909, 0.97484558, 0.97663593, 0.97788918, 0.97815773,\n",
       "                     0.97887387, 0.97967953, 0.97985856, 0.98111181, 0.98155939,\n",
       "                     0.98370781, 0.98496106, 0.98540865, 0.98585623, 0.98612479,\n",
       "                     0.98684093, 0.98782562, 0.98809417, 0.9892579 , 0.99006356,\n",
       "                     0.99024259, 0.99086921, 0.99140632, 0.99176439, 0.99203294,\n",
       "                     0.99355474, 0.9943604 , 0.99704592, 0.99722496, 0.99731447,\n",
       "                     0.99767254, 0.99812013, 0.99829917, 0.99865724, 0.99946289,\n",
       "                     0.99973145, 0.99982096, 0.99991048, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.76995771e-02, -1.94180859e-02,\n",
       "                     -4.08219945e-02, -5.21857532e-02, -5.40672213e-02, -7.14589640e-02,\n",
       "                     -7.41079722e-02, -7.63729788e-02, -7.69610411e-02, -8.70113770e-02,\n",
       "                     -9.53101798e-02, -1.17783036e-01, -1.24126067e-01, -1.33531393e-01,\n",
       "                     -1.36758937e-01, -1.39761942e-01, -1.43100844e-01, -1.46603474e-01,\n",
       "                     -1.54150680e-01, -1.54150680e-01, -1.56842471e-01, -1.57903029e-01,\n",
       "                     -1.71850257e-01, -1.76456437e-01, -1.78248231e-01, -1.82321557e-01,\n",
       "                     -1.89242000e-01, -1.92371893e-01, -2.09458098e-01, -2.13574100e-01,\n",
       "                     -2.16223108e-01, -2.23143551e-01, -2.29574442e-01, -2.41162057e-01,\n",
       "                     -2.46860078e-01, -2.48179629e-01, -2.51314428e-01, -2.52342706e-01,\n",
       "                     -2.62364264e-01, -2.65703166e-01, -2.66628663e-01, -2.68263987e-01,\n",
       "                     -2.75411980e-01, -2.87682072e-01, -2.94112963e-01, -2.95344945e-01,\n",
       "                     -3.06455187e-01, -3.06913434e-01, -3.08735482e-01, -3.10154928e-01,\n",
       "                     -3.11436158e-01, -3.18453731e-01, -3.23299708e-01, -3.27212911e-01,\n",
       "                     -3.31484695e-01, -3.36472237e-01, -3.38975367e-01, -3.42004754e-01,\n",
       "                     -3.44840486e-01, -3.52220594e-01, -3.56674944e-01, -3.57837059e-01,\n",
       "                     -3.64222150e-01, -3.65934269e-01, -3.70018359e-01, -3.74693449e-01,\n",
       "                     -3.82475590e-01, -3.85662481e-01, -3.87765531e-01, -4.05465108e-01,\n",
       "                     -4.05465108e-01, -4.12845215e-01, -4.21213465e-01, -4.27444015e-01,\n",
       "                     -4.30782916e-01, -4.35318071e-01, -4.41832752e-01, -4.41832752e-01,\n",
       "                     -4.45739007e-01, -4.48950220e-01, -4.49402811e-01, -4.51985124e-01,\n",
       "                     -4.62623522e-01, -4.65569032e-01, -4.70003629e-01, -4.73287704e-01,\n",
       "                     -4.74268028e-01, -4.80585739e-01, -4.85507816e-01, -4.91686284e-01,\n",
       "                     -5.10825624e-01, -5.12710638e-01, -5.24524468e-01, -5.25668197e-01,\n",
       "                     -5.26093096e-01, -5.30628251e-01, -5.35518236e-01, -5.43615447e-01,\n",
       "                     -5.46543706e-01, -5.59615788e-01, -5.60460739e-01, -5.61570823e-01,\n",
       "                     -5.65313809e-01, -5.75364145e-01, -5.87786665e-01, -5.97837001e-01,\n",
       "                     -6.00773860e-01, -6.06135804e-01, -6.19039208e-01, -6.24154309e-01,\n",
       "                     -6.35988767e-01, -6.53926467e-01, -6.69049629e-01, -6.75447603e-01,\n",
       "                     -6.93147181e-01, -7.11165686e-01, -7.17839793e-01, -7.33969175e-01,\n",
       "                     -7.53771802e-01, -7.67255153e-01, -7.73189888e-01, -7.88457360e-01,\n",
       "                     -7.94929875e-01, -7.98507696e-01, -8.10930216e-01, -8.26678573e-01,\n",
       "                     -8.39750655e-01, -8.44697079e-01, -8.46172368e-01, -8.47297860e-01,\n",
       "                     -8.47297860e-01, -8.64997437e-01, -8.69037847e-01, -8.80358723e-01,\n",
       "                     -8.87303195e-01, -8.93817876e-01, -8.94431938e-01, -8.96088025e-01,\n",
       "                     -9.13469856e-01, -9.16290732e-01, -9.45704617e-01, -9.55511445e-01,\n",
       "                     -9.63437510e-01, -9.73762086e-01, -9.75379648e-01, -9.80829253e-01,\n",
       "                     -9.88264231e-01, -9.93251773e-01, -1.01160091e+00, -1.01613607e+00,\n",
       "                     -1.01693426e+00, -1.02262638e+00, -1.02961942e+00, -1.02961942e+00,\n",
       "                     -1.04145387e+00, -1.04982212e+00, -1.05605267e+00, -1.06784063e+00,\n",
       "                     -1.08401349e+00, -1.09861229e+00, -1.09861229e+00, -1.13497993e+00,\n",
       "                     -1.13943428e+00, -1.14624034e+00, -1.16315081e+00, -1.17351360e+00,\n",
       "                     -1.18269541e+00, -1.18658106e+00, -1.20126644e+00, -1.20397280e+00,\n",
       "                     -1.20397280e+00, -1.21444410e+00, -1.23214368e+00, -1.23906412e+00,\n",
       "                     -1.24653242e+00, -1.25276297e+00, -1.26534175e+00, -1.27629347e+00,\n",
       "                     -1.28647403e+00, -1.29928298e+00, -1.31824090e+00, -1.32175584e+00,\n",
       "                     -1.32566974e+00, -1.33072451e+00, -1.33200128e+00, -1.36365188e+00,\n",
       "                     -1.36724617e+00, -1.38629436e+00, -1.42403469e+00, -1.44691898e+00,\n",
       "                     -1.45225233e+00, -1.45528723e+00, -1.46633707e+00, -1.50048673e+00,\n",
       "                     -1.50407740e+00, -1.51512723e+00, -1.51982575e+00, -1.54044504e+00,\n",
       "                     -1.58412010e+00, -1.60943791e+00, -1.60943791e+00, -1.63760879e+00,\n",
       "                     -1.64865863e+00, -1.66613326e+00, -1.74296931e+00, -1.75785792e+00,\n",
       "                     -1.79175947e+00, -1.79175947e+00, -1.81237876e+00, -1.82161243e+00,\n",
       "                     -1.84582669e+00, -1.92368701e+00, -1.92990981e+00, -1.94591015e+00,\n",
       "                     -1.94591015e+00, -1.99243016e+00, -2.01490302e+00, -2.03688193e+00,\n",
       "                     -2.05713578e+00, -2.07944154e+00, -2.14787870e+00, -2.19722458e+00,\n",
       "                     -2.39789527e+00, -2.60268969e+00, -2.61006979e+00, -2.63905733e+00,\n",
       "                     -2.67414865e+00, -2.94443898e+00, -2.97892516e+00, -3.21887582e+00,\n",
       "                     -3.95124372e+00, -4.04305127e+00, -3.45387764e+01]), auc_score=0.5287126762366279, privacy_risk=0.5221555814161668, accuracy=0.5221555814161669, tpr_ind=0.7871273834034553, tnr_ind=0.2571837794288783, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.06122997, 0.07304628, 0.0746576 , 0.07976009,\n",
       "                     0.08307224, 0.08942798, 0.09041268, 0.09130785, 0.09336675,\n",
       "                     0.09444096, 0.09524662, 0.0966789 , 0.09855877, 0.09963298,\n",
       "                     0.10213947, 0.10392982, 0.12013249, 0.12111718, 0.12299705,\n",
       "                     0.12621968, 0.12702533, 0.13293349, 0.13329156, 0.13499239,\n",
       "                     0.14967326, 0.17984066, 0.18127294, 0.18664399, 0.19192552,\n",
       "                     0.19765464, 0.2097395 , 0.21063468, 0.21090323, 0.21564766,\n",
       "                     0.23265598, 0.23498344, 0.23910124, 0.24062304, 0.24375615,\n",
       "                     0.24850058, 0.25082804, 0.26434518, 0.26559842, 0.26747829,\n",
       "                     0.27490824, 0.28099543, 0.28350192, 0.29675051, 0.30409095,\n",
       "                     0.30820875, 0.30973055, 0.33927133, 0.34464238, 0.34777549,\n",
       "                     0.36120312, 0.36388864, 0.36630561, 0.3948617 , 0.39584639,\n",
       "                     0.40542476, 0.40739415, 0.41545072, 0.4163459 , 0.41742011,\n",
       "                     0.41974756, 0.42207502, 0.439889  , 0.4542118 , 0.45582311,\n",
       "                     0.46558052, 0.49163011, 0.50380449, 0.5043416 , 0.51911199,\n",
       "                     0.5222451 , 0.52555725, 0.52609435, 0.52985409, 0.54149136,\n",
       "                     0.54945842, 0.55223346, 0.55384478, 0.55617223, 0.55921583,\n",
       "                     0.56055859, 0.57479187, 0.58266941, 0.58812998, 0.58983081,\n",
       "                     0.59394862, 0.59555993, 0.59672366, 0.61614896, 0.61677558,\n",
       "                     0.62644347, 0.62877092, 0.63897592, 0.64013965, 0.64121386,\n",
       "                     0.64461552, 0.64721153, 0.65231403, 0.65499955, 0.66171336,\n",
       "                     0.66287709, 0.66771104, 0.66797959, 0.66878525, 0.67102319,\n",
       "                     0.67120222, 0.67558858, 0.67657327, 0.6797959 , 0.68122818,\n",
       "                     0.6818548 , 0.69385015, 0.69573002, 0.69680423, 0.69877361,\n",
       "                     0.69993734, 0.70414466, 0.70575598, 0.70656163, 0.70727777,\n",
       "                     0.7079044 , 0.71058992, 0.71166413, 0.71730373, 0.72160057,\n",
       "                     0.72536031, 0.72831439, 0.73064184, 0.73082088, 0.73153702,\n",
       "                     0.73610241, 0.7370871 , 0.74308477, 0.74380091, 0.75490108,\n",
       "                     0.75516964, 0.75830275, 0.76385283, 0.76555367, 0.76904485,\n",
       "                     0.7764748 , 0.78202489, 0.78336765, 0.785158  , 0.7856951 ,\n",
       "                     0.78650076, 0.78757497, 0.78811208, 0.79500492, 0.80207681,\n",
       "                     0.80413571, 0.80485185, 0.80637365, 0.80825351, 0.8138036 ,\n",
       "                     0.81469877, 0.82293438, 0.83779429, 0.84235968, 0.84316534,\n",
       "                     0.84880494, 0.85507117, 0.85542924, 0.85721959, 0.85838331,\n",
       "                     0.8588309 , 0.86196401, 0.86357533, 0.86796169, 0.86894638,\n",
       "                     0.86894638, 0.8803151 , 0.88129979, 0.88156835, 0.88774505,\n",
       "                     0.88837168, 0.89302659, 0.90305255, 0.90493241, 0.90725987,\n",
       "                     0.90958732, 0.91477934, 0.91665921, 0.9191657 , 0.92194074,\n",
       "                     0.92283591, 0.92399964, 0.92937069, 0.93125056, 0.93313043,\n",
       "                     0.93429415, 0.93581595, 0.93921762, 0.94047086, 0.94646853,\n",
       "                     0.94861695, 0.94897502, 0.94915406, 0.95210814, 0.95416704,\n",
       "                     0.9570316 , 0.95962761, 0.96034375, 0.96911646, 0.9728762 ,\n",
       "                     0.97314475, 0.97323427, 0.97520365, 0.97627786, 0.97797869,\n",
       "                     0.97842628, 0.9785158 , 0.98120132, 0.98281264, 0.98308119,\n",
       "                     0.98334974, 0.9841554 , 0.9841554 , 0.98451347, 0.98496106,\n",
       "                     0.98496106, 0.98514009, 0.98531913, 0.9856772 , 0.98612479,\n",
       "                     0.98684093, 1.        ]), tpr=array([0.        , 0.07241966, 0.08369886, 0.08575777, 0.08960702,\n",
       "                     0.09318772, 0.09954346, 0.10097574, 0.1023185 , 0.10473548,\n",
       "                     0.10670486, 0.10760004, 0.10930087, 0.11261302, 0.11341867,\n",
       "                     0.11565661, 0.11780503, 0.13579805, 0.13714081, 0.1391102 ,\n",
       "                     0.1447498 , 0.14654015, 0.15298541, 0.15352251, 0.15495479,\n",
       "                     0.16927759, 0.20660639, 0.20857578, 0.21672187, 0.2235252 ,\n",
       "                     0.2291648 , 0.2414287 , 0.24241339, 0.24304001, 0.24832155,\n",
       "                     0.26461373, 0.26729926, 0.27267031, 0.2751768 , 0.2787575 ,\n",
       "                     0.2828753 , 0.28609793, 0.29970459, 0.30176349, 0.30355384,\n",
       "                     0.31169994, 0.31742906, 0.32065169, 0.33416883, 0.34150927,\n",
       "                     0.34652225, 0.34911825, 0.3774953 , 0.38599946, 0.38913258,\n",
       "                     0.40238117, 0.40390296, 0.4056038 , 0.43147435, 0.4327276 ,\n",
       "                     0.44230597, 0.44472294, 0.45277952, 0.45394325, 0.45528601,\n",
       "                     0.45815057, 0.4598514 , 0.47685973, 0.48939218, 0.49171963,\n",
       "                     0.50040283, 0.53065974, 0.54238654, 0.54319219, 0.55635127,\n",
       "                     0.55948438, 0.56243846, 0.56351267, 0.56718288, 0.58016292,\n",
       "                     0.58777191, 0.5902784 , 0.59188971, 0.59332199, 0.59600752,\n",
       "                     0.59752932, 0.61077791, 0.62017724, 0.62581685, 0.6281443 ,\n",
       "                     0.63351535, 0.63602184, 0.63700653, 0.65374631, 0.65508907,\n",
       "                     0.66323516, 0.66502551, 0.67218691, 0.67335064, 0.6741563 ,\n",
       "                     0.67702086, 0.6792588 , 0.68436129, 0.68838958, 0.69573002,\n",
       "                     0.69680423, 0.69957927, 0.70020589, 0.70101155, 0.70271238,\n",
       "                     0.70369707, 0.70808343, 0.70933668, 0.71211172, 0.713544  ,\n",
       "                     0.7150658 , 0.72652404, 0.72795632, 0.72929908, 0.73189509,\n",
       "                     0.73305881, 0.7370871 , 0.73798228, 0.73950407, 0.74022021,\n",
       "                     0.74075732, 0.74308477, 0.74397995, 0.75006714, 0.75337929,\n",
       "                     0.75749709, 0.75928744, 0.76152538, 0.762152  , 0.76304718,\n",
       "                     0.76850774, 0.76985051, 0.77584818, 0.77683287, 0.78909677,\n",
       "                     0.78981291, 0.79160326, 0.79536299, 0.79697431, 0.80082356,\n",
       "                     0.80708979, 0.81577298, 0.81675768, 0.81845851, 0.8189061 ,\n",
       "                     0.81935368, 0.82033838, 0.82186017, 0.82642557, 0.83412407,\n",
       "                     0.83627249, 0.83689911, 0.83859995, 0.8403903 , 0.84773073,\n",
       "                     0.84817832, 0.85462358, 0.87037866, 0.87476502, 0.87592874,\n",
       "                     0.88219497, 0.89043058, 0.89123624, 0.892579  , 0.89320562,\n",
       "                     0.89374273, 0.89741294, 0.89848715, 0.90260496, 0.90287351,\n",
       "                     0.90314206, 0.9140632 , 0.91477934, 0.91540596, 0.92077701,\n",
       "                     0.92203026, 0.9253424 , 0.93617402, 0.93715871, 0.93903858,\n",
       "                     0.94172411, 0.94664757, 0.9478113 , 0.9498702 , 0.95273476,\n",
       "                     0.95336138, 0.95407752, 0.95873243, 0.95980664, 0.9611494 ,\n",
       "                     0.96231313, 0.96311879, 0.96481962, 0.96562528, 0.97045922,\n",
       "                     0.97198102, 0.97216006, 0.97242861, 0.97556172, 0.976994  ,\n",
       "                     0.97869483, 0.9805747 , 0.98102229, 0.98907886, 0.99194342,\n",
       "                     0.99221198, 0.99230149, 0.9933757 , 0.99364426, 0.99444991,\n",
       "                     0.99471847, 0.9948975 , 0.99722496, 0.99776206, 0.99785158,\n",
       "                     0.99820965, 0.99838868, 0.9984782 , 0.99865724, 0.99883627,\n",
       "                     0.99901531, 0.99937338, 0.99955241, 0.99973145, 0.99982096,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.57483570e-02, -4.25596144e-02,\n",
       "                     -4.54623741e-02, -4.87901642e-02, -5.48082365e-02, -6.06246218e-02,\n",
       "                     -6.45385211e-02, -7.14589640e-02, -8.70113770e-02, -9.53101798e-02,\n",
       "                     -1.00083459e-01, -1.02654154e-01, -1.05360516e-01, -1.13328685e-01,\n",
       "                     -1.17783036e-01, -1.21645109e-01, -1.25163143e-01, -1.27833372e-01,\n",
       "                     -1.33531393e-01, -1.39761942e-01, -1.54150680e-01, -1.54150680e-01,\n",
       "                     -1.71850257e-01, -1.82321557e-01, -1.95424782e-01, -2.04794413e-01,\n",
       "                     -2.07639365e-01, -2.23143551e-01, -2.26313126e-01, -2.27513551e-01,\n",
       "                     -2.41162057e-01, -2.51314428e-01, -2.53195896e-01, -2.59825118e-01,\n",
       "                     -2.62364264e-01, -2.75103290e-01, -2.78713402e-01, -2.81412459e-01,\n",
       "                     -2.82232468e-01, -2.87682072e-01, -2.94239473e-01, -2.98492989e-01,\n",
       "                     -3.00104592e-01, -3.01324849e-01, -3.07025035e-01, -3.08301360e-01,\n",
       "                     -3.10596332e-01, -3.11779624e-01, -3.18453731e-01, -3.21583624e-01,\n",
       "                     -3.23317136e-01, -3.28925031e-01, -3.36472237e-01, -3.40325806e-01,\n",
       "                     -3.44840486e-01, -3.51397887e-01, -3.52166526e-01, -3.56674944e-01,\n",
       "                     -3.57609087e-01, -3.67724780e-01, -3.75387653e-01, -3.79489622e-01,\n",
       "                     -3.82992252e-01, -3.84411699e-01, -3.87765531e-01, -3.94882999e-01,\n",
       "                     -4.05465108e-01, -4.05465108e-01, -4.08895643e-01, -4.19177370e-01,\n",
       "                     -4.38008656e-01, -4.41832752e-01, -4.43289417e-01, -4.51985124e-01,\n",
       "                     -4.54736157e-01, -4.59532329e-01, -4.60815203e-01, -4.65683968e-01,\n",
       "                     -4.70003629e-01, -4.74457980e-01, -4.76924072e-01, -4.85507816e-01,\n",
       "                     -4.90622916e-01, -4.98991166e-01, -5.04045937e-01, -5.10825624e-01,\n",
       "                     -5.20304368e-01, -5.26093096e-01, -5.30628251e-01, -5.38996501e-01,\n",
       "                     -5.46543706e-01, -5.49634899e-01, -5.50046337e-01, -5.51735527e-01,\n",
       "                     -5.59615788e-01, -5.66733256e-01, -5.70544858e-01, -5.75364145e-01,\n",
       "                     -5.77315365e-01, -5.87786665e-01, -5.91677720e-01, -6.00056757e-01,\n",
       "                     -6.03916047e-01, -6.06135804e-01, -6.09064063e-01, -6.19039208e-01,\n",
       "                     -6.35988767e-01, -6.39079959e-01, -6.46627165e-01, -6.51474484e-01,\n",
       "                     -6.56779536e-01, -6.60357358e-01, -6.61398482e-01, -6.63294217e-01,\n",
       "                     -6.93147181e-01, -7.23918839e-01, -7.25937003e-01, -7.27048732e-01,\n",
       "                     -7.30887509e-01, -7.36632292e-01, -7.41937345e-01, -7.50305594e-01,\n",
       "                     -7.53771802e-01, -7.73189888e-01, -7.84954730e-01, -7.88457360e-01,\n",
       "                     -7.91127589e-01, -7.95801335e-01, -8.06087592e-01, -8.10930216e-01,\n",
       "                     -8.24175443e-01, -8.26678573e-01, -8.32909123e-01, -8.37886026e-01,\n",
       "                     -8.47297860e-01, -8.57902414e-01, -8.60201265e-01, -8.60762590e-01,\n",
       "                     -8.64997437e-01, -8.75468737e-01, -8.87303195e-01, -8.93817876e-01,\n",
       "                     -9.02238978e-01, -9.16290732e-01, -9.26547232e-01, -9.34309237e-01,\n",
       "                     -9.47381319e-01, -9.55511445e-01, -9.55511445e-01, -9.69400557e-01,\n",
       "                     -9.73449146e-01, -9.80829253e-01, -9.88070414e-01, -9.96333440e-01,\n",
       "                     -9.98528830e-01, -1.00680474e+00, -1.01160091e+00, -1.02700276e+00,\n",
       "                     -1.02961942e+00, -1.03653986e+00, -1.07173927e+00, -1.09178632e+00,\n",
       "                     -1.09861229e+00, -1.09861229e+00, -1.12011849e+00, -1.13497993e+00,\n",
       "                     -1.14209740e+00, -1.14513230e+00, -1.15267951e+00, -1.16162526e+00,\n",
       "                     -1.17865500e+00, -1.20179652e+00, -1.20397280e+00, -1.20397280e+00,\n",
       "                     -1.21457217e+00, -1.21639532e+00, -1.23214368e+00, -1.24319352e+00,\n",
       "                     -1.25276297e+00, -1.27188401e+00, -1.28642836e+00, -1.29098418e+00,\n",
       "                     -1.29928298e+00, -1.31730149e+00, -1.32054298e+00, -1.32687094e+00,\n",
       "                     -1.33041390e+00, -1.34644845e+00, -1.34992672e+00, -1.35454566e+00,\n",
       "                     -1.36687628e+00, -1.38629436e+00, -1.40282366e+00, -1.40534256e+00,\n",
       "                     -1.41369334e+00, -1.42500887e+00, -1.46633707e+00, -1.47484776e+00,\n",
       "                     -1.49752000e+00, -1.50407740e+00, -1.54044504e+00, -1.59214642e+00,\n",
       "                     -1.59685913e+00, -1.60943791e+00, -1.67397643e+00, -1.68639895e+00,\n",
       "                     -1.72870133e+00, -1.79175947e+00, -1.84582669e+00, -1.94591015e+00,\n",
       "                     -1.94591015e+00, -2.03688193e+00, -2.07944154e+00, -2.12026354e+00,\n",
       "                     -2.14006616e+00, -2.16685348e+00, -2.23359222e+00, -2.30258509e+00,\n",
       "                     -2.32727771e+00, -2.35137526e+00, -2.39789527e+00, -2.48490665e+00,\n",
       "                     -2.67414865e+00, -2.83321334e+00, -2.93119375e+00, -3.04452244e+00,\n",
       "                     -3.11351531e+00, -3.17805383e+00, -4.15888308e+00, -3.45387764e+01]), auc_score=0.5300273277993925, privacy_risk=0.5206785426550891, accuracy=0.5206785426550891, tpr_ind=0.385999462894996, tnr_ind=0.6553576224151821, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.05711217, 0.06633247, 0.06857041, 0.08432549,\n",
       "                     0.08486259, 0.08557873, 0.08710053, 0.09963298, 0.10061767,\n",
       "                     0.10267657, 0.10849521, 0.10921135, 0.1125235 , 0.11485095,\n",
       "                     0.1161042 , 0.12040104, 0.12371319, 0.12425029, 0.12827858,\n",
       "                     0.12899472, 0.13848357, 0.14645063, 0.1468087 , 0.14707725,\n",
       "                     0.14788291, 0.1503894 , 0.15665563, 0.15969922, 0.16372751,\n",
       "                     0.16891952, 0.16972518, 0.17411154, 0.17760272, 0.18145197,\n",
       "                     0.18861337, 0.19765464, 0.20696446, 0.21135082, 0.21421538,\n",
       "                     0.21797511, 0.22325665, 0.22943335, 0.23265598, 0.23337212,\n",
       "                     0.23677379, 0.237848  , 0.24966431, 0.25378211, 0.25897413,\n",
       "                     0.26040641, 0.27714618, 0.30623937, 0.30973055, 0.32503804,\n",
       "                     0.32611225, 0.33040909, 0.3396294 , 0.34535852, 0.35807   ,\n",
       "                     0.35842807, 0.36084505, 0.36836452, 0.37436219, 0.37507833,\n",
       "                     0.38134455, 0.42270164, 0.42449199, 0.42538716, 0.43192194,\n",
       "                     0.44740847, 0.44812461, 0.45251097, 0.45483842, 0.46316355,\n",
       "                     0.46593859, 0.47659117, 0.47945573, 0.48267836, 0.48751231,\n",
       "                     0.488497  , 0.49136156, 0.49171963, 0.49315191, 0.52672097,\n",
       "                     0.52886939, 0.53110733, 0.53236058, 0.53755259, 0.53898487,\n",
       "                     0.5401486 , 0.54560917, 0.55733596, 0.56503446, 0.56646674,\n",
       "                     0.57917823, 0.57962582, 0.58061051, 0.61659654, 0.62035628,\n",
       "                     0.62322084, 0.63002417, 0.63315728, 0.6353057 , 0.64380986,\n",
       "                     0.64416793, 0.64721153, 0.64998657, 0.65428341, 0.65562617,\n",
       "                     0.65598424, 0.65893832, 0.66404082, 0.66663683, 0.66815863,\n",
       "                     0.6705756 , 0.67639424, 0.68946379, 0.6961776 , 0.70038493,\n",
       "                     0.70110107, 0.70423418, 0.71014233, 0.71739325, 0.71793036,\n",
       "                     0.71828843, 0.71945215, 0.72213768, 0.7258079 , 0.72903053,\n",
       "                     0.72974667, 0.73655   , 0.73816131, 0.74075732, 0.74174201,\n",
       "                     0.74738161, 0.74845582, 0.75060424, 0.77146182, 0.77271507,\n",
       "                     0.77352072, 0.78023454, 0.7821144 , 0.78605317, 0.79366216,\n",
       "                     0.79769045, 0.797959  , 0.79840659, 0.80234536, 0.80386716,\n",
       "                     0.80404619, 0.80637365, 0.81989079, 0.82132307, 0.82177066,\n",
       "                     0.82311342, 0.82320294, 0.82579894, 0.82830543, 0.82911109,\n",
       "                     0.83206517, 0.83627249, 0.83949512, 0.84065885, 0.84262823,\n",
       "                     0.84289679, 0.85086384, 0.85587682, 0.85713007, 0.85802524,\n",
       "                     0.87503357, 0.87798765, 0.87950944, 0.88147883, 0.88586519,\n",
       "                     0.88676036, 0.88684988, 0.88989347, 0.89159431, 0.89544356,\n",
       "                     0.89839764, 0.89920329, 0.90430579, 0.90511145, 0.91701728,\n",
       "                     0.92462626, 0.92543192, 0.92874407, 0.92954973, 0.93268284,\n",
       "                     0.93339898, 0.93536836, 0.93590547, 0.9376063 , 0.93850148,\n",
       "                     0.93948617, 0.94100797, 0.94217169, 0.94378301, 0.94906454,\n",
       "                     0.95166055, 0.9519291 , 0.95371945, 0.95488318, 0.95595739,\n",
       "                     0.9575687 , 0.95765822, 0.95944857, 0.96105989, 0.9626712 ,\n",
       "                     0.96285024, 0.96464059, 0.96517769, 0.96589383, 0.96607287,\n",
       "                     0.96643094, 0.96857936, 0.97090681, 0.97117536, 0.9718915 ,\n",
       "                     0.9718915 , 0.97269716, 0.97448751, 0.97627786, 0.9764569 ,\n",
       "                     0.97690448, 0.97744159, 0.97815773, 0.97833676, 0.97914242,\n",
       "                     0.98021663, 0.9805747 , 0.98120132, 0.98164891, 0.98182795,\n",
       "                     0.98236505, 0.98334974, 0.98442395, 0.98522961, 1.        ]), tpr=array([0.        , 0.06830185, 0.07832781, 0.08065527, 0.09909587,\n",
       "                     0.10097574, 0.10249754, 0.1038403 , 0.11798407, 0.11923731,\n",
       "                     0.12138573, 0.12604064, 0.12783099, 0.13123266, 0.13364963,\n",
       "                     0.13517143, 0.14027392, 0.14457076, 0.14591353, 0.14913616,\n",
       "                     0.14976278, 0.15871453, 0.16757676, 0.16811387, 0.16865097,\n",
       "                     0.17017277, 0.17312685, 0.18091487, 0.18404798, 0.1882553 ,\n",
       "                     0.19514815, 0.19595381, 0.2025781 , 0.2056217 , 0.20902336,\n",
       "                     0.21672187, 0.22459941, 0.23552054, 0.24026497, 0.24259243,\n",
       "                     0.24644168, 0.25020141, 0.2557515 , 0.25942172, 0.26094351,\n",
       "                     0.26515084, 0.26694119, 0.27938412, 0.28260675, 0.28941008,\n",
       "                     0.29218512, 0.31017814, 0.3401665 , 0.34312058, 0.36003939,\n",
       "                     0.36209829, 0.36702175, 0.37686868, 0.38188166, 0.39360845,\n",
       "                     0.39423507, 0.3969206 , 0.40452959, 0.40999015, 0.41160147,\n",
       "                     0.41661445, 0.45546504, 0.45725539, 0.45922478, 0.46746039,\n",
       "                     0.48249933, 0.48384209, 0.48840748, 0.49064542, 0.49744875,\n",
       "                     0.50156656, 0.51114493, 0.5135619 , 0.51732164, 0.52161848,\n",
       "                     0.52260317, 0.52537821, 0.52618387, 0.52761615, 0.56002148,\n",
       "                     0.56252797, 0.56404977, 0.56601916, 0.57094262, 0.57246442,\n",
       "                     0.57398621, 0.5800734 , 0.59162116, 0.59931967, 0.60128905,\n",
       "                     0.61212067, 0.61274729, 0.61462716, 0.64730105, 0.65052368,\n",
       "                     0.65285113, 0.66019157, 0.66413034, 0.66672635, 0.67478292,\n",
       "                     0.67558858, 0.67952735, 0.68355564, 0.68722585, 0.68874765,\n",
       "                     0.68982186, 0.69581953, 0.70190672, 0.70503984, 0.70620356,\n",
       "                     0.71005282, 0.71479724, 0.72589741, 0.73055232, 0.73431206,\n",
       "                     0.73538627, 0.73807179, 0.74326381, 0.74836631, 0.74881389,\n",
       "                     0.74926148, 0.75051473, 0.7534688 , 0.75669143, 0.75982455,\n",
       "                     0.76045117, 0.76662788, 0.76859726, 0.77074568, 0.77155134,\n",
       "                     0.77701191, 0.77871274, 0.78104019, 0.80440426, 0.80574702,\n",
       "                     0.80619461, 0.8138036 , 0.81514636, 0.82033838, 0.82803688,\n",
       "                     0.83206517, 0.83304986, 0.83403455, 0.83698863, 0.83815236,\n",
       "                     0.83904753, 0.84047981, 0.8588309 , 0.85963656, 0.86008415,\n",
       "                     0.86160594, 0.86214305, 0.8644705 , 0.86643989, 0.86769313,\n",
       "                     0.8726166 , 0.8746755 , 0.87807716, 0.87915137, 0.88129979,\n",
       "                     0.88192642, 0.88890878, 0.89266852, 0.89356369, 0.89436935,\n",
       "                     0.91173574, 0.91397368, 0.91468982, 0.91710679, 0.92041894,\n",
       "                     0.92158267, 0.92185122, 0.92677468, 0.92883359, 0.93286187,\n",
       "                     0.93483126, 0.93563692, 0.94208218, 0.94315639, 0.95336138,\n",
       "                     0.95935905, 0.96025423, 0.96240265, 0.96338734, 0.96714708,\n",
       "                     0.96768418, 0.96893743, 0.96938501, 0.97045922, 0.97207054,\n",
       "                     0.97314475, 0.97421896, 0.97484558, 0.97609883, 0.97896339,\n",
       "                     0.98075374, 0.98093277, 0.98281264, 0.9836183 , 0.98433444,\n",
       "                     0.98585623, 0.98603527, 0.98755707, 0.98845224, 0.98889983,\n",
       "                     0.98907886, 0.99060066, 0.99113777, 0.99140632, 0.99149584,\n",
       "                     0.99158535, 0.99292812, 0.99427088, 0.9943604 , 0.99480798,\n",
       "                     0.99498702, 0.99507654, 0.99552412, 0.99615075, 0.99632978,\n",
       "                     0.99650882, 0.99659833, 0.9969564 , 0.99713544, 0.99758303,\n",
       "                     0.99776206, 0.99785158, 0.99883627, 0.99892579, 0.99901531,\n",
       "                     0.99910482, 0.99982096, 0.99991048, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -8.88894742e-03, -3.77403280e-02,\n",
       "                     -3.80998462e-02, -4.65200156e-02, -5.71584138e-02, -6.45385211e-02,\n",
       "                     -6.73036819e-02, -6.89928715e-02, -8.00427077e-02, -9.18075493e-02,\n",
       "                     -9.53101798e-02, -1.00083459e-01, -1.05360516e-01, -1.11225635e-01,\n",
       "                     -1.15831816e-01, -1.17783036e-01, -1.25163143e-01, -1.30053128e-01,\n",
       "                     -1.33531393e-01, -1.39761942e-01, -1.41078598e-01, -1.54150680e-01,\n",
       "                     -1.54150680e-01, -1.62518929e-01, -1.67054085e-01, -1.78482780e-01,\n",
       "                     -1.82321557e-01, -1.92903666e-01, -1.99489360e-01, -2.00670695e-01,\n",
       "                     -2.06794413e-01, -2.11309094e-01, -2.12561442e-01, -2.18481538e-01,\n",
       "                     -2.23143551e-01, -2.32931558e-01, -2.34400706e-01, -2.38411023e-01,\n",
       "                     -2.46133070e-01, -2.51314428e-01, -2.54892250e-01, -2.56719847e-01,\n",
       "                     -2.57829109e-01, -2.60726262e-01, -2.62364264e-01, -2.64023098e-01,\n",
       "                     -2.66628663e-01, -2.74436846e-01, -2.79584862e-01, -2.87682072e-01,\n",
       "                     -2.92892356e-01, -3.10154928e-01, -3.22773392e-01, -3.30241687e-01,\n",
       "                     -3.36472237e-01, -3.42944751e-01, -3.44096162e-01, -3.50549351e-01,\n",
       "                     -3.56674944e-01, -3.60002734e-01, -3.61369788e-01, -3.66462950e-01,\n",
       "                     -3.67724780e-01, -3.69097464e-01, -3.69495632e-01, -3.71563556e-01,\n",
       "                     -3.74693449e-01, -3.76051223e-01, -3.81367557e-01, -3.82992252e-01,\n",
       "                     -3.85662481e-01, -3.92042088e-01, -4.05465108e-01, -4.05465108e-01,\n",
       "                     -4.14767501e-01, -4.17735201e-01, -4.21213465e-01, -4.32864082e-01,\n",
       "                     -4.35318071e-01, -4.37213806e-01, -4.41832752e-01, -4.46287103e-01,\n",
       "                     -4.48715092e-01, -4.51985124e-01, -4.62623522e-01, -4.64305608e-01,\n",
       "                     -4.70003629e-01, -4.98991166e-01, -4.98991166e-01, -5.07880114e-01,\n",
       "                     -5.10825624e-01, -5.15466003e-01, -5.19875459e-01, -5.32085623e-01,\n",
       "                     -5.38996501e-01, -5.38996501e-01, -5.39453018e-01, -5.43615447e-01,\n",
       "                     -5.48565952e-01, -5.56125383e-01, -5.59615788e-01, -5.64529803e-01,\n",
       "                     -5.69094532e-01, -5.75364145e-01, -5.85258219e-01, -5.87786665e-01,\n",
       "                     -5.90493026e-01, -6.00773860e-01, -6.06135804e-01, -6.15588946e-01,\n",
       "                     -6.16774202e-01, -6.19039208e-01, -6.53926467e-01, -6.81451141e-01,\n",
       "                     -6.83668437e-01, -6.93147181e-01, -7.02716632e-01, -7.04981638e-01,\n",
       "                     -7.33969175e-01, -7.73189888e-01, -7.75838896e-01, -7.77230298e-01,\n",
       "                     -7.88457360e-01, -7.88457360e-01, -7.94929875e-01, -8.07557532e-01,\n",
       "                     -8.10930216e-01, -8.14099791e-01, -8.26678573e-01, -8.34797698e-01,\n",
       "                     -8.40783179e-01, -8.47297860e-01, -8.47297860e-01, -8.51970766e-01,\n",
       "                     -8.62223511e-01, -8.69037847e-01, -8.74829964e-01, -8.75468737e-01,\n",
       "                     -8.75468737e-01, -8.85224912e-01, -9.02867712e-01, -9.09370289e-01,\n",
       "                     -9.16290732e-01, -9.20725329e-01, -9.34309237e-01, -9.34309237e-01,\n",
       "                     -9.80829253e-01, -9.90398704e-01, -9.93251773e-01, -1.01160091e+00,\n",
       "                     -1.01734932e+00, -1.02165125e+00, -1.02961942e+00, -1.03798767e+00,\n",
       "                     -1.04145387e+00, -1.04596856e+00, -1.06784063e+00, -1.07451474e+00,\n",
       "                     -1.08026315e+00, -1.09861229e+00, -1.09861229e+00, -1.12601126e+00,\n",
       "                     -1.13943428e+00, -1.14513230e+00, -1.14862271e+00, -1.16017018e+00,\n",
       "                     -1.16315081e+00, -1.17007125e+00, -1.17468201e+00, -1.17557333e+00,\n",
       "                     -1.17865500e+00, -1.18149995e+00, -1.19310313e+00, -1.19625076e+00,\n",
       "                     -1.20397280e+00, -1.21841349e+00, -1.23395364e+00, -1.23676263e+00,\n",
       "                     -1.25276297e+00, -1.26851133e+00, -1.28785429e+00, -1.32175584e+00,\n",
       "                     -1.37082444e+00, -1.38629436e+00, -1.41098697e+00, -1.42711636e+00,\n",
       "                     -1.45225233e+00, -1.46082741e+00, -1.46633707e+00, -1.47181653e+00,\n",
       "                     -1.48160454e+00, -1.48538526e+00, -1.49165488e+00, -1.50407740e+00,\n",
       "                     -1.52242654e+00, -1.55059741e+00, -1.56563529e+00, -1.57121670e+00,\n",
       "                     -1.60943791e+00, -1.60943791e+00, -1.62830640e+00, -1.65292302e+00,\n",
       "                     -1.65822808e+00, -1.67764616e+00, -1.70474809e+00, -1.71008144e+00,\n",
       "                     -1.74046617e+00, -1.79175947e+00, -1.79175947e+00, -1.81117756e+00,\n",
       "                     -1.87180218e+00, -1.89711998e+00, -1.94591015e+00, -1.94591015e+00,\n",
       "                     -2.02814825e+00, -2.03688193e+00, -2.07944154e+00, -2.10413415e+00,\n",
       "                     -2.14006616e+00, -2.19722458e+00, -2.19722458e+00, -2.21297293e+00,\n",
       "                     -2.25129180e+00, -2.30258509e+00, -2.30258509e+00, -2.35137526e+00,\n",
       "                     -2.39789527e+00, -2.43361336e+00, -2.56494936e+00, -2.70805020e+00,\n",
       "                     -2.73200344e+00, -2.77258872e+00, -2.89037176e+00, -3.09104245e+00,\n",
       "                     -3.28653447e+00, -3.29583687e+00, -4.72738782e+00, -3.45387764e+01]), auc_score=0.5296390433363829, privacy_risk=0.5202757139020678, accuracy=0.5202757139020678, tpr_ind=0.8726165965446244, tnr_ind=0.16793483125951122, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.06096142, 0.06373646, 0.06436308, 0.06883896,\n",
       "                     0.0700922 , 0.07967058, 0.08110286, 0.08307224, 0.08611584,\n",
       "                     0.0910393 , 0.09265061, 0.09345627, 0.09524662, 0.10258706,\n",
       "                     0.10392982, 0.11377674, 0.12290753, 0.12362367, 0.1283681 ,\n",
       "                     0.13078507, 0.13257542, 0.13338108, 0.13839406, 0.13928923,\n",
       "                     0.14242234, 0.14582401, 0.1498523 , 0.15092651, 0.15558142,\n",
       "                     0.15978874, 0.16301137, 0.16596545, 0.16811387, 0.16999373,\n",
       "                     0.18601737, 0.20803867, 0.20964999, 0.21546862, 0.21949691,\n",
       "                     0.24160773, 0.2485901 , 0.25351356, 0.25566198, 0.2670307 ,\n",
       "                     0.27267031, 0.2787575 , 0.28063736, 0.28251723, 0.28323337,\n",
       "                     0.28475517, 0.28770925, 0.29334885, 0.30328529, 0.30525468,\n",
       "                     0.35046102, 0.37131859, 0.37740578, 0.38931161, 0.40139647,\n",
       "                     0.40685704, 0.41339182, 0.41652493, 0.41867335, 0.41885239,\n",
       "                     0.42431295, 0.4291469 , 0.43075821, 0.43559216, 0.43774058,\n",
       "                     0.44060514, 0.44615522, 0.45233193, 0.45761346, 0.46056754,\n",
       "                     0.48411064, 0.48760183, 0.50156656, 0.50192463, 0.5028198 ,\n",
       "                     0.51078686, 0.51400949, 0.51633694, 0.51750067, 0.5192015 ,\n",
       "                     0.52314027, 0.53701549, 0.53835825, 0.54543013, 0.55151732,\n",
       "                     0.55491899, 0.56145376, 0.56915227, 0.57407573, 0.57506042,\n",
       "                     0.58213231, 0.5882195 , 0.59645511, 0.59940918, 0.60093098,\n",
       "                     0.60853997, 0.608719  , 0.61507475, 0.61784979, 0.62277325,\n",
       "                     0.6240265 , 0.63136693, 0.63709605, 0.63790171, 0.64918091,\n",
       "                     0.65204547, 0.65947543, 0.66260854, 0.6690538 , 0.67934831,\n",
       "                     0.67988542, 0.68078059, 0.6818548 , 0.7012801 , 0.70351804,\n",
       "                     0.7048608 , 0.70611405, 0.71318593, 0.71981022, 0.72177961,\n",
       "                     0.72625548, 0.72724018, 0.72876197, 0.73807179, 0.73941456,\n",
       "                     0.74138394, 0.74559126, 0.74738161, 0.75078328, 0.75266315,\n",
       "                     0.75337929, 0.75642288, 0.75740757, 0.76492704, 0.76644884,\n",
       "                     0.76895533, 0.77173037, 0.77477397, 0.77772805, 0.77924984,\n",
       "                     0.78032405, 0.78372572, 0.78676931, 0.78855966, 0.79088712,\n",
       "                     0.79554203, 0.79822755, 0.80843255, 0.81040193, 0.81219228,\n",
       "                     0.81371408, 0.81559395, 0.81657864, 0.82069645, 0.82132307,\n",
       "                     0.82186017, 0.83108048, 0.83331841, 0.84504521, 0.84701459,\n",
       "                     0.84943156, 0.85256468, 0.85363889, 0.85480261, 0.8552502 ,\n",
       "                     0.85641393, 0.85704055, 0.86097932, 0.86518664, 0.86581327,\n",
       "                     0.8675141 , 0.86796169, 0.87037866, 0.87270611, 0.87807716,\n",
       "                     0.88291111, 0.88640229, 0.89195238, 0.9104825 , 0.91137767,\n",
       "                     0.91567451, 0.91692776, 0.9191657 , 0.91961328, 0.9212246 ,\n",
       "                     0.92220929, 0.9232835 , 0.92507385, 0.92811745, 0.93304091,\n",
       "                     0.93411512, 0.93518933, 0.93751678, 0.94414108, 0.94611046,\n",
       "                     0.94960165, 0.95022827, 0.95801629, 0.96276072, 0.96320831,\n",
       "                     0.96392445, 0.96490914, 0.96535673, 0.96580431, 0.96669949,\n",
       "                     0.96866887, 0.96875839, 0.96956405, 0.97090681, 0.97153343,\n",
       "                     0.97198102, 0.97207054, 0.9734133 , 0.97386089, 0.97395041,\n",
       "                     0.97439799, 0.97529317, 0.97529317, 0.97762062, 0.9800376 ,\n",
       "                     0.9805747 , 0.98290216, 0.98308119, 0.98308119, 0.98352878,\n",
       "                     0.98379733, 0.98424492, 0.98442395, 0.98460299, 0.98496106,\n",
       "                     0.98505058, 0.98558768, 0.98576672, 0.98603527, 1.        ]), tpr=array([0.        , 0.07152448, 0.07376242, 0.07573181, 0.08065527,\n",
       "                     0.08226658, 0.09112882, 0.0925611 , 0.09506759, 0.09855877,\n",
       "                     0.10196043, 0.10401934, 0.10500403, 0.10679438, 0.11565661,\n",
       "                     0.11798407, 0.12863665, 0.1375884 , 0.13830454, 0.14233283,\n",
       "                     0.14358607, 0.14636111, 0.14743532, 0.1539701 , 0.15495479,\n",
       "                     0.15853549, 0.16274282, 0.16650255, 0.16730821, 0.17330588,\n",
       "                     0.17724465, 0.18037776, 0.18306329, 0.18610688, 0.18789723,\n",
       "                     0.20418942, 0.22791156, 0.23014949, 0.23704234, 0.2429505 ,\n",
       "                     0.26568794, 0.27150658, 0.27660908, 0.27857846, 0.29299078,\n",
       "                     0.3002417 , 0.30749261, 0.30955152, 0.31125235, 0.31268463,\n",
       "                     0.3145645 , 0.3181452 , 0.32190493, 0.33264703, 0.33416883,\n",
       "                     0.38223973, 0.39951661, 0.40452959, 0.41562976, 0.42753558,\n",
       "                     0.43317519, 0.43899382, 0.4419479 , 0.44409632, 0.44526005,\n",
       "                     0.45358518, 0.45967237, 0.4613732 , 0.46513293, 0.46754991,\n",
       "                     0.47068302, 0.47453227, 0.48052994, 0.48608003, 0.48894459,\n",
       "                     0.511503  , 0.51579984, 0.52895891, 0.5299436 , 0.5309283 ,\n",
       "                     0.5386268 , 0.54104377, 0.54328171, 0.54471399, 0.54722048,\n",
       "                     0.55071166, 0.56566109, 0.56834661, 0.57488139, 0.58204279,\n",
       "                     0.58553397, 0.59126309, 0.59851401, 0.60191567, 0.60316892,\n",
       "                     0.60925611, 0.61516426, 0.62080387, 0.62313132, 0.62554829,\n",
       "                     0.6332468 , 0.63387342, 0.63906544, 0.64264614, 0.64846477,\n",
       "                     0.64998657, 0.65652135, 0.66046012, 0.66135529, 0.67182884,\n",
       "                     0.67505147, 0.6818548 , 0.68373467, 0.69170173, 0.70110107,\n",
       "                     0.70199624, 0.70360756, 0.70530839, 0.72410706, 0.72571838,\n",
       "                     0.72724018, 0.72804583, 0.73637096, 0.74326381, 0.74487512,\n",
       "                     0.75069376, 0.75158894, 0.75337929, 0.76197297, 0.76268911,\n",
       "                     0.76582222, 0.7708352 , 0.77199893, 0.77638528, 0.7779966 ,\n",
       "                     0.77907081, 0.78283054, 0.78327813, 0.7887387 , 0.79043953,\n",
       "                     0.79205085, 0.7959001 , 0.79983887, 0.80377764, 0.8045833 ,\n",
       "                     0.80673172, 0.81129711, 0.81487781, 0.81702623, 0.82141259,\n",
       "                     0.82535136, 0.82696267, 0.8358249 , 0.83788381, 0.83931609,\n",
       "                     0.84012174, 0.84137499, 0.84271775, 0.84692507, 0.84746218,\n",
       "                     0.84799928, 0.85507117, 0.8573091 , 0.86885686, 0.87028914,\n",
       "                     0.87306418, 0.87601826, 0.87789813, 0.87941993, 0.88058365,\n",
       "                     0.882374  , 0.88317966, 0.88604422, 0.88989347, 0.89043058,\n",
       "                     0.89141527, 0.89275803, 0.89535404, 0.89786053, 0.90314206,\n",
       "                     0.90797601, 0.91012443, 0.91737535, 0.93751678, 0.93814341,\n",
       "                     0.94252976, 0.94405156, 0.94548384, 0.94619998, 0.94673709,\n",
       "                     0.94736371, 0.94807985, 0.95058634, 0.95300331, 0.95774774,\n",
       "                     0.95837436, 0.95998568, 0.96177603, 0.96866887, 0.97045922,\n",
       "                     0.97251813, 0.97314475, 0.97959001, 0.98397637, 0.98433444,\n",
       "                     0.98442395, 0.98514009, 0.98576672, 0.98648286, 0.98737803,\n",
       "                     0.98872079, 0.98889983, 0.98970549, 0.99060066, 0.99113777,\n",
       "                     0.9913168 , 0.99149584, 0.99265956, 0.9928386 , 0.99328619,\n",
       "                     0.99346522, 0.99400233, 0.99409184, 0.99516605, 0.9964193 ,\n",
       "                     0.99668785, 0.99767254, 0.99776206, 0.9979411 , 0.99812013,\n",
       "                     0.99838868, 0.99865724, 0.99883627, 0.99892579, 0.99946289,\n",
       "                     0.99955241, 0.99982096, 0.99991048, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.92207132e-02, -4.44517626e-02,\n",
       "                     -5.31098253e-02, -5.40672213e-02, -5.88405000e-02, -6.06246218e-02,\n",
       "                     -6.89928715e-02, -7.41079722e-02, -7.59859070e-02, -8.33816089e-02,\n",
       "                     -8.70113770e-02, -9.53101798e-02, -1.05360516e-01, -1.09199292e-01,\n",
       "                     -1.11225635e-01, -1.13328685e-01, -1.17783036e-01, -1.25163143e-01,\n",
       "                     -1.33531393e-01, -1.49531734e-01, -1.54150680e-01, -1.63887855e-01,\n",
       "                     -1.67054085e-01, -1.82321557e-01, -1.92903666e-01, -1.94156014e-01,\n",
       "                     -2.00670695e-01, -2.02026628e-01, -2.04794413e-01, -2.05852054e-01,\n",
       "                     -2.09720531e-01, -2.11309094e-01, -2.23143551e-01, -2.38411023e-01,\n",
       "                     -2.40353104e-01, -2.46860078e-01, -2.61364764e-01, -2.64692554e-01,\n",
       "                     -2.64784108e-01, -2.68263987e-01, -2.74436846e-01, -2.76253377e-01,\n",
       "                     -2.84571650e-01, -2.87682072e-01, -2.96898728e-01, -2.98492989e-01,\n",
       "                     -3.13657559e-01, -3.18453731e-01, -3.22773392e-01, -3.36472237e-01,\n",
       "                     -3.39867826e-01, -3.42406972e-01, -3.44840486e-01, -3.49948461e-01,\n",
       "                     -3.50437917e-01, -3.56674944e-01, -3.61501985e-01, -3.67146244e-01,\n",
       "                     -3.67724780e-01, -3.68907512e-01, -3.74693449e-01, -3.77294231e-01,\n",
       "                     -3.79489622e-01, -3.80055393e-01, -3.85662481e-01, -3.87765531e-01,\n",
       "                     -3.89464767e-01, -3.93042588e-01, -3.95895657e-01, -3.97682968e-01,\n",
       "                     -4.00477567e-01, -4.05465108e-01, -4.05465108e-01, -4.13370288e-01,\n",
       "                     -4.19258430e-01, -4.30102412e-01, -4.35318071e-01, -4.35318071e-01,\n",
       "                     -4.36001832e-01, -4.41832752e-01, -4.44685821e-01, -4.46287103e-01,\n",
       "                     -4.51985124e-01, -4.63572739e-01, -4.65502496e-01, -4.70003629e-01,\n",
       "                     -4.71714494e-01, -4.77785770e-01, -4.79573080e-01, -4.85507816e-01,\n",
       "                     -4.88352768e-01, -4.89548225e-01, -4.96436886e-01, -4.98991166e-01,\n",
       "                     -5.10825624e-01, -5.20304368e-01, -5.26093096e-01, -5.32804530e-01,\n",
       "                     -5.36085291e-01, -5.38996501e-01, -5.44727175e-01, -5.59615788e-01,\n",
       "                     -5.61811178e-01, -5.67984038e-01, -5.69352963e-01, -5.85258219e-01,\n",
       "                     -5.87786665e-01, -5.99118231e-01, -6.06135804e-01, -6.18026550e-01,\n",
       "                     -6.19039208e-01, -6.23351419e-01, -6.34306681e-01, -6.41853886e-01,\n",
       "                     -6.64976304e-01, -6.66478933e-01, -6.93147181e-01, -7.20546155e-01,\n",
       "                     -7.22134717e-01, -7.47214402e-01, -7.55667538e-01, -7.68182367e-01,\n",
       "                     -7.73189888e-01, -7.74372620e-01, -7.88457360e-01, -7.88457360e-01,\n",
       "                     -7.96943974e-01, -8.10930216e-01, -8.14099791e-01, -8.34460714e-01,\n",
       "                     -8.36248024e-01, -8.44378150e-01, -8.47297860e-01, -8.47297860e-01,\n",
       "                     -8.67500568e-01, -8.75468737e-01, -8.79558723e-01, -8.84202417e-01,\n",
       "                     -8.93817876e-01, -9.02238978e-01, -9.16290732e-01, -9.34309237e-01,\n",
       "                     -9.38269639e-01, -9.49080555e-01, -9.50976290e-01, -9.55511445e-01,\n",
       "                     -9.65080896e-01, -9.67992106e-01, -9.77984301e-01, -9.80829253e-01,\n",
       "                     -9.88376459e-01, -9.91640169e-01, -1.01160091e+00, -1.02165125e+00,\n",
       "                     -1.02450432e+00, -1.02961942e+00, -1.04020153e+00, -1.04145387e+00,\n",
       "                     -1.04145387e+00, -1.05108715e+00, -1.07158362e+00, -1.08298697e+00,\n",
       "                     -1.09861229e+00, -1.09861229e+00, -1.10866262e+00, -1.11436065e+00,\n",
       "                     -1.11803037e+00, -1.12393010e+00, -1.13140211e+00, -1.13497993e+00,\n",
       "                     -1.13943428e+00, -1.15145477e+00, -1.15267951e+00, -1.15745279e+00,\n",
       "                     -1.16315081e+00, -1.17599895e+00, -1.17865500e+00, -1.17995793e+00,\n",
       "                     -1.19279950e+00, -1.20397280e+00, -1.21867895e+00, -1.21984615e+00,\n",
       "                     -1.23214368e+00, -1.23807842e+00, -1.24432410e+00, -1.25276297e+00,\n",
       "                     -1.28785429e+00, -1.29928298e+00, -1.31218639e+00, -1.35454566e+00,\n",
       "                     -1.35914337e+00, -1.38629436e+00, -1.39568410e+00, -1.42138568e+00,\n",
       "                     -1.42711636e+00, -1.44691898e+00, -1.45831295e+00, -1.45861502e+00,\n",
       "                     -1.46967597e+00, -1.51982575e+00, -1.54341681e+00, -1.55059741e+00,\n",
       "                     -1.60943791e+00, -1.60943791e+00, -1.65822808e+00, -1.66500776e+00,\n",
       "                     -1.68175857e+00, -1.68639895e+00, -1.69866905e+00, -1.70474809e+00,\n",
       "                     -1.73460106e+00, -1.74046617e+00, -1.79175947e+00, -1.79175947e+00,\n",
       "                     -1.87180218e+00, -1.88939794e+00, -1.94591015e+00, -1.97408103e+00,\n",
       "                     -2.07944154e+00, -2.14006616e+00, -2.19722458e+00, -2.23359222e+00,\n",
       "                     -2.25129180e+00, -2.26868354e+00, -2.30258509e+00, -2.39789527e+00,\n",
       "                     -2.48490665e+00, -2.52572864e+00, -2.61495978e+00, -2.63905733e+00,\n",
       "                     -2.70805020e+00, -2.83321334e+00, -2.86220088e+00, -2.94443898e+00,\n",
       "                     -2.96183072e+00, -3.13549422e+00, -3.25809654e+00, -3.45387764e+01]), auc_score=0.5228726830274892, privacy_risk=0.5158893563691702, accuracy=0.5158893563691702, tpr_ind=0.38223972786679794, tnr_ind=0.6495389848715424, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.06006624, 0.07143497, 0.07779071, 0.08065527,\n",
       "                     0.08289321, 0.08414645, 0.09238206, 0.09444096, 0.09927491,\n",
       "                     0.10061767, 0.10267657, 0.10267657, 0.10527258, 0.11359771,\n",
       "                     0.11538806, 0.11690986, 0.11735744, 0.12254946, 0.1247874 ,\n",
       "                     0.13141169, 0.13543998, 0.13714081, 0.14090055, 0.14331752,\n",
       "                     0.14636111, 0.15128458, 0.1826157 , 0.18753916, 0.19344732,\n",
       "                     0.19416346, 0.19658043, 0.20365231, 0.2112613 , 0.21242503,\n",
       "                     0.21269358, 0.21681139, 0.22459941, 0.24644168, 0.24903769,\n",
       "                     0.25557246, 0.26246531, 0.30033121, 0.30507564, 0.31366932,\n",
       "                     0.31519112, 0.31742906, 0.31912989, 0.3243219 , 0.32978247,\n",
       "                     0.3360487 , 0.34043506, 0.34231492, 0.35269895, 0.35887566,\n",
       "                     0.36684272, 0.36809596, 0.3769582 , 0.37794289, 0.38590995,\n",
       "                     0.38922209, 0.39665205, 0.40649897, 0.40685704, 0.41903142,\n",
       "                     0.42583475, 0.42986304, 0.43165339, 0.43657685, 0.45546504,\n",
       "                     0.45734491, 0.47104109, 0.47309999, 0.47748635, 0.47820249,\n",
       "                     0.48070898, 0.48411064, 0.48509534, 0.50022379, 0.5022827 ,\n",
       "                     0.50425208, 0.51168203, 0.51535225, 0.51678453, 0.5237669 ,\n",
       "                     0.53119685, 0.53817921, 0.54229702, 0.55169636, 0.55205443,\n",
       "                     0.55724644, 0.56252797, 0.56906275, 0.57532898, 0.59376958,\n",
       "                     0.59493331, 0.59582848, 0.59806642, 0.60003581, 0.64201951,\n",
       "                     0.64300421, 0.64586877, 0.65258258, 0.6567899 , 0.65759556,\n",
       "                     0.65956494, 0.66269806, 0.66493599, 0.66887477, 0.67075463,\n",
       "                     0.67388775, 0.67523051, 0.67666279, 0.67782652, 0.67970638,\n",
       "                     0.68113866, 0.70065348, 0.70262286, 0.70557694, 0.70700922,\n",
       "                     0.70817295, 0.70924716, 0.71246979, 0.71318593, 0.71703518,\n",
       "                     0.71900457, 0.72052636, 0.72294334, 0.72339092, 0.7258079 ,\n",
       "                     0.72929908, 0.73073136, 0.73261123, 0.76233104, 0.76438994,\n",
       "                     0.76626981, 0.76743353, 0.7693134 , 0.78104019, 0.78417331,\n",
       "                     0.79017098, 0.79402023, 0.79652672, 0.797959  , 0.80386716,\n",
       "                     0.8066422 , 0.81058097, 0.81290842, 0.81666816, 0.8173843 ,\n",
       "                     0.8194432 , 0.82230776, 0.82311342, 0.82374004, 0.82937964,\n",
       "                     0.8301853 , 0.83287083, 0.83466118, 0.83627249, 0.83842091,\n",
       "                     0.84056933, 0.846567  , 0.84826784, 0.85668248, 0.86026318,\n",
       "                     0.86124787, 0.86223257, 0.86518664, 0.87073673, 0.87145287,\n",
       "                     0.87539164, 0.87986751, 0.88112076, 0.8854176 , 0.88568615,\n",
       "                     0.88828216, 0.89034106, 0.89392176, 0.8966968 , 0.90072509,\n",
       "                     0.90144123, 0.9033211 , 0.90502193, 0.9084236 , 0.91030346,\n",
       "                     0.91057202, 0.91164623, 0.91218333, 0.915585  , 0.91871811,\n",
       "                     0.93116104, 0.93429415, 0.93751678, 0.93957569, 0.94673709,\n",
       "                     0.94879599, 0.94978068, 0.94978068, 0.95067586, 0.95336138,\n",
       "                     0.95604691, 0.95640498, 0.95649449, 0.95694208, 0.95792677,\n",
       "                     0.95944857, 0.96714708, 0.96822129, 0.96875839, 0.96992212,\n",
       "                     0.97099633, 0.97108585, 0.97207054, 0.97359234, 0.9749351 ,\n",
       "                     0.97529317, 0.97815773, 0.97860532, 0.97887387, 0.97896339,\n",
       "                     0.98155939, 0.9826336 , 0.9826336 , 0.98281264, 0.98334974,\n",
       "                     0.98487154, 0.98487154, 0.98585623, 0.98603527, 0.98684093,\n",
       "                     0.98737803, 0.98809417, 0.98889983, 1.        ]), tpr=array([0.        , 0.06516874, 0.07788023, 0.08369886, 0.0874586 ,\n",
       "                     0.09059171, 0.09265061, 0.10052815, 0.1023185 , 0.10760004,\n",
       "                     0.10912183, 0.1104646 , 0.11109122, 0.1140453 , 0.12344463,\n",
       "                     0.12577209, 0.12801003, 0.12854713, 0.13436577, 0.13749888,\n",
       "                     0.14582401, 0.1503894 , 0.15217975, 0.15647659, 0.15987826,\n",
       "                     0.16283233, 0.16659207, 0.19926596, 0.20445797, 0.21027661,\n",
       "                     0.21206696, 0.21448393, 0.22191388, 0.23023901, 0.23247695,\n",
       "                     0.23310357, 0.23775848, 0.24715782, 0.26926864, 0.27231224,\n",
       "                     0.27920508, 0.28681407, 0.32065169, 0.32700743, 0.33407931,\n",
       "                     0.33667532, 0.33846567, 0.33971892, 0.34544804, 0.35108764,\n",
       "                     0.35627965, 0.36048698, 0.36281443, 0.37418315, 0.38027034,\n",
       "                     0.38922209, 0.39092293, 0.39853191, 0.39915854, 0.4076627 ,\n",
       "                     0.41195954, 0.42171695, 0.43165339, 0.43245905, 0.44427536,\n",
       "                     0.45107869, 0.45546504, 0.45743443, 0.46352162, 0.48357354,\n",
       "                     0.48625906, 0.49932862, 0.50273028, 0.50729568, 0.5084594 ,\n",
       "                     0.51177155, 0.51535225, 0.51615791, 0.53155492, 0.5329872 ,\n",
       "                     0.53424044, 0.53970101, 0.5437293 , 0.54543013, 0.55169636,\n",
       "                     0.55751499, 0.56485543, 0.56968937, 0.57846209, 0.57971533,\n",
       "                     0.58499687, 0.5902784 , 0.59645511, 0.60093098, 0.62080387,\n",
       "                     0.62313132, 0.62438457, 0.62653299, 0.62948706, 0.66789007,\n",
       "                     0.6690538 , 0.67191836, 0.67809507, 0.68167577, 0.68266046,\n",
       "                     0.68534599, 0.68758392, 0.68946379, 0.69402918, 0.69537195,\n",
       "                     0.69823651, 0.6997583 , 0.70056396, 0.70226479, 0.70441321,\n",
       "                     0.70611405, 0.72509176, 0.72670307, 0.72867246, 0.73019425,\n",
       "                     0.73091039, 0.73225316, 0.73475965, 0.73592337, 0.73986214,\n",
       "                     0.74147346, 0.74335333, 0.74559126, 0.74639692, 0.74926148,\n",
       "                     0.75409543, 0.75633336, 0.75722854, 0.78659028, 0.78882822,\n",
       "                     0.79043953, 0.79133471, 0.79294602, 0.80646316, 0.80950676,\n",
       "                     0.81362456, 0.81711575, 0.82051741, 0.82132307, 0.82678364,\n",
       "                     0.82973771, 0.83421359, 0.83770477, 0.84137499, 0.84235968,\n",
       "                     0.84468714, 0.84782025, 0.84853639, 0.84934205, 0.85793573,\n",
       "                     0.85838331, 0.8603527 , 0.86214305, 0.86276967, 0.86518664,\n",
       "                     0.86688748, 0.87342225, 0.8746755 , 0.8838958 , 0.88667084,\n",
       "                     0.88756602, 0.8895354 , 0.892579  , 0.89786053, 0.8982186 ,\n",
       "                     0.90260496, 0.9069018 , 0.90878167, 0.91245188, 0.91272044,\n",
       "                     0.91594307, 0.91665921, 0.92023991, 0.92265688, 0.92704324,\n",
       "                     0.92793841, 0.92954973, 0.93151911, 0.93357801, 0.93563692,\n",
       "                     0.9360845 , 0.93671113, 0.9376063 , 0.94002327, 0.94217169,\n",
       "                     0.9534509 , 0.95595739, 0.95819533, 0.95918002, 0.96616238,\n",
       "                     0.96893743, 0.97028019, 0.97045922, 0.97108585, 0.9734133 ,\n",
       "                     0.97538269, 0.97600931, 0.97618834, 0.9764569 , 0.97788918,\n",
       "                     0.97914242, 0.98657237, 0.98737803, 0.98800465, 0.98872079,\n",
       "                     0.98961597, 0.989795  , 0.98997404, 0.99086921, 0.99230149,\n",
       "                     0.9928386 , 0.99382329, 0.99391281, 0.99427088, 0.99462895,\n",
       "                     0.99606123, 0.99650882, 0.99659833, 0.99677737, 0.9969564 ,\n",
       "                     0.99749351, 0.99767254, 0.99838868, 0.99856772, 0.99883627,\n",
       "                     0.99910482, 0.99946289, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.13852162e-02, -5.97192347e-02,\n",
       "                     -6.89928715e-02, -8.22380982e-02, -8.33816089e-02, -8.70113770e-02,\n",
       "                     -9.53101798e-02, -9.68498260e-02, -1.11225635e-01, -1.25163143e-01,\n",
       "                     -1.33531393e-01, -1.41078598e-01, -1.41830195e-01, -1.43100844e-01,\n",
       "                     -1.48420005e-01, -1.54150680e-01, -1.56346070e-01, -1.58224005e-01,\n",
       "                     -1.58748389e-01, -1.79048231e-01, -1.82321557e-01, -1.89242000e-01,\n",
       "                     -1.91055237e-01, -1.92371893e-01, -1.94156014e-01, -2.04895879e-01,\n",
       "                     -2.16223108e-01, -2.20061885e-01, -2.23143551e-01, -2.30523659e-01,\n",
       "                     -2.35119742e-01, -2.46524000e-01, -2.46860078e-01, -2.51314428e-01,\n",
       "                     -2.53448901e-01, -2.58694536e-01, -2.74436846e-01, -2.80301965e-01,\n",
       "                     -2.81167391e-01, -2.84736562e-01, -2.87682072e-01, -2.91197015e-01,\n",
       "                     -2.93991242e-01, -2.96265816e-01, -3.00104592e-01, -3.05381650e-01,\n",
       "                     -3.07025035e-01, -3.11212570e-01, -3.21583624e-01, -3.24239668e-01,\n",
       "                     -3.25422400e-01, -3.26296909e-01, -3.34369186e-01, -3.36472237e-01,\n",
       "                     -3.51397887e-01, -3.53139289e-01, -3.56674944e-01, -3.58777994e-01,\n",
       "                     -3.62905494e-01, -3.64897923e-01, -3.65643614e-01, -3.67724780e-01,\n",
       "                     -3.69471505e-01, -3.69747026e-01, -3.70859579e-01, -3.74693449e-01,\n",
       "                     -3.75612145e-01, -3.78314119e-01, -3.82992252e-01, -4.05465108e-01,\n",
       "                     -4.05465108e-01, -4.24883194e-01, -4.30782916e-01, -4.32133355e-01,\n",
       "                     -4.38254931e-01, -4.41832752e-01, -4.43492504e-01, -4.46287103e-01,\n",
       "                     -4.51985124e-01, -4.53474327e-01, -4.56017387e-01, -4.56758402e-01,\n",
       "                     -4.61034959e-01, -4.70003629e-01, -4.76082675e-01, -4.76924072e-01,\n",
       "                     -4.83936724e-01, -4.96436886e-01, -4.97173535e-01, -5.07430035e-01,\n",
       "                     -5.10825624e-01, -5.18793793e-01, -5.18901038e-01, -5.26093096e-01,\n",
       "                     -5.38996501e-01, -5.59615788e-01, -5.63935449e-01, -5.67906335e-01,\n",
       "                     -5.70544858e-01, -5.77315365e-01, -5.78077851e-01, -5.87786665e-01,\n",
       "                     -5.97837001e-01, -6.06135804e-01, -6.09765572e-01, -6.19039208e-01,\n",
       "                     -6.22051259e-01, -6.24154309e-01, -6.28608659e-01, -6.32522559e-01,\n",
       "                     -6.35988767e-01, -6.39079959e-01, -6.50587566e-01, -6.66478933e-01,\n",
       "                     -6.93147181e-01, -7.20546155e-01, -7.37598943e-01, -7.50305594e-01,\n",
       "                     -7.53771802e-01, -7.57685702e-01, -7.62140052e-01, -7.67255153e-01,\n",
       "                     -7.69687258e-01, -7.73189888e-01, -7.84118959e-01, -7.88457360e-01,\n",
       "                     -7.98507696e-01, -8.10930216e-01, -8.23200309e-01, -8.24175443e-01,\n",
       "                     -8.32909123e-01, -8.36349645e-01, -8.41567186e-01, -8.47297860e-01,\n",
       "                     -8.75468737e-01, -8.93817876e-01, -9.04298583e-01, -9.04456274e-01,\n",
       "                     -9.16290732e-01, -9.21405833e-01, -9.37124819e-01, -9.38269639e-01,\n",
       "                     -9.58030338e-01, -9.69400557e-01, -9.70778917e-01, -9.80829253e-01,\n",
       "                     -9.95958135e-01, -1.00330211e+00, -1.00458334e+00, -1.00900013e+00,\n",
       "                     -1.01160091e+00, -1.02165125e+00, -1.02663879e+00, -1.02961942e+00,\n",
       "                     -1.03609193e+00, -1.04731899e+00, -1.04982212e+00, -1.06087196e+00,\n",
       "                     -1.09861229e+00, -1.09861229e+00, -1.14513230e+00, -1.15523118e+00,\n",
       "                     -1.16113265e+00, -1.16315081e+00, -1.17163742e+00, -1.17411984e+00,\n",
       "                     -1.17473598e+00, -1.17865500e+00, -1.18335352e+00, -1.18504479e+00,\n",
       "                     -1.18958407e+00, -1.19908282e+00, -1.20397280e+00, -1.21227161e+00,\n",
       "                     -1.21639532e+00, -1.25276297e+00, -1.25804003e+00, -1.27866370e+00,\n",
       "                     -1.28093385e+00, -1.28401551e+00, -1.29098418e+00, -1.31885308e+00,\n",
       "                     -1.33041390e+00, -1.33500107e+00, -1.34992672e+00, -1.36097655e+00,\n",
       "                     -1.36760223e+00, -1.37582306e+00, -1.38629436e+00, -1.39518331e+00,\n",
       "                     -1.40609699e+00, -1.40876722e+00, -1.42711636e+00, -1.47866768e+00,\n",
       "                     -1.49664242e+00, -1.50407740e+00, -1.51982575e+00, -1.52102696e+00,\n",
       "                     -1.56291790e+00, -1.58045038e+00, -1.60943791e+00, -1.60943791e+00,\n",
       "                     -1.62186043e+00, -1.63760879e+00, -1.68595262e+00, -1.73460106e+00,\n",
       "                     -1.74296931e+00, -1.74919985e+00, -1.75785792e+00, -1.79175947e+00,\n",
       "                     -1.79175947e+00, -1.80828877e+00, -1.91875916e+00, -1.92181260e+00,\n",
       "                     -1.93283807e+00, -1.94591015e+00, -1.98100147e+00, -2.01490302e+00,\n",
       "                     -2.02320182e+00, -2.02814825e+00, -2.07944154e+00, -2.14006616e+00,\n",
       "                     -2.25129180e+00, -2.38262780e+00, -2.39789527e+00, -2.48490665e+00,\n",
       "                     -2.52572864e+00, -2.53897387e+00, -2.70805020e+00, -2.84781214e+00,\n",
       "                     -3.20545280e+00, -3.45387764e+01]), auc_score=0.5213075771880495, privacy_risk=0.5156655626174917, accuracy=0.5156655626174917, tpr_ind=0.5315549189866619, tnr_ind=0.49977620624832153, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.05639603, 0.06060335, 0.06624295, 0.0772536 ,\n",
       "                     0.08074479, 0.08405693, 0.08504163, 0.08701101, 0.08889088,\n",
       "                     0.08969654, 0.09247158, 0.0951571 , 0.09658938, 0.09981201,\n",
       "                     0.10366127, 0.1068839 , 0.11261302, 0.11332916, 0.1161042 ,\n",
       "                     0.11753648, 0.11977442, 0.12272849, 0.12308656, 0.13033748,\n",
       "                     0.14358607, 0.14868857, 0.15074747, 0.15146361, 0.15459672,\n",
       "                     0.15889356, 0.17223167, 0.18798675, 0.1954167 , 0.19649091,\n",
       "                     0.19828126, 0.20025065, 0.22370423, 0.2312237 , 0.237848  ,\n",
       "                     0.2393698 , 0.24644168, 0.24814251, 0.2562886 , 0.25960075,\n",
       "                     0.26121207, 0.26926864, 0.26989526, 0.27866798, 0.28054785,\n",
       "                     0.29102139, 0.29146898, 0.29263271, 0.29460209, 0.30104735,\n",
       "                     0.3207412 , 0.32691791, 0.32772357, 0.34723839, 0.36406768,\n",
       "                     0.36899114, 0.37292991, 0.37472026, 0.37668964, 0.38089697,\n",
       "                     0.38188166, 0.39190762, 0.39360845, 0.39683108, 0.40157551,\n",
       "                     0.40247068, 0.40515621, 0.41169099, 0.41419748, 0.41652493,\n",
       "                     0.42314923, 0.42520813, 0.43102677, 0.44329066, 0.44409632,\n",
       "                     0.45179483, 0.45385373, 0.4583296 , 0.46593859, 0.46772894,\n",
       "                     0.48232029, 0.48706472, 0.49547937, 0.49744875, 0.50299884,\n",
       "                     0.5048787 , 0.53594128, 0.55679885, 0.56029004, 0.56243846,\n",
       "                     0.56396025, 0.57407573, 0.57541849, 0.57694029, 0.5918002 ,\n",
       "                     0.60424313, 0.60603348, 0.60809238, 0.60997225, 0.61149405,\n",
       "                     0.61901352, 0.6225047 , 0.62465312, 0.63136693, 0.63718557,\n",
       "                     0.65365679, 0.65598424, 0.6598335 , 0.66574165, 0.66609972,\n",
       "                     0.66654731, 0.6685167 , 0.66914332, 0.66968042, 0.67657327,\n",
       "                     0.67863217, 0.68203384, 0.6848984 , 0.6992212 , 0.70324949,\n",
       "                     0.70665115, 0.70871005, 0.71703518, 0.71891505, 0.71981022,\n",
       "                     0.72374899, 0.7242861 , 0.72491272, 0.72947811, 0.73135798,\n",
       "                     0.73216364, 0.73395399, 0.74550175, 0.74953003, 0.75320025,\n",
       "                     0.7549906 , 0.75678095, 0.75785516, 0.76233104, 0.76304718,\n",
       "                     0.7642109 , 0.7651956 , 0.76698595, 0.77656432, 0.78802256,\n",
       "                     0.78990243, 0.79070808, 0.79607913, 0.7974219 , 0.79822755,\n",
       "                     0.79876466, 0.80127115, 0.8158625 , 0.82633605, 0.82723122,\n",
       "                     0.82991675, 0.83116999, 0.83573539, 0.83725718, 0.84209113,\n",
       "                     0.84325486, 0.84916301, 0.85086384, 0.85193805, 0.85444454,\n",
       "                     0.85498165, 0.86106884, 0.86330678, 0.86420195, 0.86760362,\n",
       "                     0.87028914, 0.87136335, 0.87333274, 0.87404888, 0.87422791,\n",
       "                     0.87736102, 0.87816668, 0.87870379, 0.88094172, 0.88094172,\n",
       "                     0.88228449, 0.88255304, 0.88309014, 0.88407484, 0.88604422,\n",
       "                     0.88738698, 0.89401128, 0.90170978, 0.90188882, 0.90654373,\n",
       "                     0.91236237, 0.91603258, 0.91746486, 0.91791245, 0.91862859,\n",
       "                     0.92203026, 0.9232835 , 0.92704324, 0.92749082, 0.93089249,\n",
       "                     0.93187718, 0.93384657, 0.93644257, 0.93742727, 0.93948617,\n",
       "                     0.94020231, 0.94297735, 0.9468266 , 0.953988  , 0.95479366,\n",
       "                     0.9555098 , 0.9555098 , 0.95586787, 0.95846388, 0.9621341 ,\n",
       "                     0.96526721, 0.96687852, 0.96804225, 0.96840032, 0.96956405,\n",
       "                     0.96956405, 0.9713544 , 0.9734133 , 0.97520365, 0.97529317,\n",
       "                     0.97618834, 0.97681497, 0.97690448, 0.97771014, 0.97779966,\n",
       "                     0.97932146, 0.97932146, 0.9805747 , 0.98146988, 0.98173843,\n",
       "                     0.9826336 , 0.98281264, 0.98326023, 0.98379733, 0.98397637,\n",
       "                     0.98433444, 0.98469251, 0.98514009, 0.98514009, 0.98558768,\n",
       "                     0.98666189, 0.98791514, 0.98818369, 1.        ]), tpr=array([0.        , 0.06409453, 0.06839137, 0.07617939, 0.0874586 ,\n",
       "                     0.09059171, 0.09300868, 0.09417241, 0.09623131, 0.09918539,\n",
       "                     0.10097574, 0.10348223, 0.10751052, 0.10974846, 0.1140453 ,\n",
       "                     0.1196849 , 0.12362367, 0.12872617, 0.12935279, 0.13239638,\n",
       "                     0.13481336, 0.13776743, 0.14152717, 0.14206427, 0.14994181,\n",
       "                     0.16104198, 0.16515979, 0.16918808, 0.17088891, 0.17455913,\n",
       "                     0.179035  , 0.19344732, 0.20624832, 0.2133202 , 0.21448393,\n",
       "                     0.21707994, 0.22030257, 0.24402471, 0.25243935, 0.26076448,\n",
       "                     0.26228628, 0.26891057, 0.27070092, 0.27956315, 0.28278578,\n",
       "                     0.28502372, 0.29549727, 0.29675051, 0.30489661, 0.30659744,\n",
       "                     0.31626533, 0.31698147, 0.3181452 , 0.32065169, 0.32691791,\n",
       "                     0.34338913, 0.35153523, 0.35260944, 0.37221377, 0.38662609,\n",
       "                     0.39190762, 0.39611494, 0.39799481, 0.39942709, 0.40470862,\n",
       "                     0.40551428, 0.41195954, 0.41312327, 0.41562976, 0.42234357,\n",
       "                     0.4240444 , 0.42592427, 0.43192194, 0.4347865 , 0.43711396,\n",
       "                     0.44418584, 0.44624474, 0.45188434, 0.46352162, 0.46450631,\n",
       "                     0.4700564 , 0.47327903, 0.47757587, 0.48527437, 0.48715424,\n",
       "                     0.50201414, 0.50559484, 0.51436756, 0.51741115, 0.52269269,\n",
       "                     0.52403545, 0.55017456, 0.57219586, 0.57550801, 0.57765643,\n",
       "                     0.57935726, 0.58866708, 0.59063647, 0.59287441, 0.61122549,\n",
       "                     0.62384746, 0.62635395, 0.62832334, 0.62975562, 0.63091934,\n",
       "                     0.63709605, 0.63960254, 0.64184048, 0.6475696 , 0.65401486,\n",
       "                     0.67039656, 0.6726345 , 0.67585713, 0.68158625, 0.68230239,\n",
       "                     0.68310805, 0.68597261, 0.6869573 , 0.68812103, 0.6956405 ,\n",
       "                     0.69814699, 0.70101155, 0.70477128, 0.71784084, 0.72151106,\n",
       "                     0.7242861 , 0.72670307, 0.73368544, 0.73475965, 0.73565482,\n",
       "                     0.73825083, 0.73896697, 0.73959359, 0.74442754, 0.7457703 ,\n",
       "                     0.74711306, 0.74890341, 0.76152538, 0.76644884, 0.76859726,\n",
       "                     0.77074568, 0.772357  , 0.77414735, 0.77844419, 0.77924984,\n",
       "                     0.78023454, 0.7815773 , 0.78327813, 0.79169278, 0.8035986 ,\n",
       "                     0.80503088, 0.80628413, 0.81219228, 0.81326649, 0.81416167,\n",
       "                     0.81460926, 0.81666816, 0.8301853 , 0.84611942, 0.84692507,\n",
       "                     0.85005819, 0.85184854, 0.85695103, 0.85900994, 0.8675141 ,\n",
       "                     0.86858831, 0.87297467, 0.87539164, 0.87718199, 0.88022558,\n",
       "                     0.88076269, 0.88702891, 0.88998299, 0.8910572 , 0.8946379 ,\n",
       "                     0.89580163, 0.89723391, 0.90009847, 0.90099364, 0.9017993 ,\n",
       "                     0.90493241, 0.90609614, 0.90663325, 0.90958732, 0.90994539,\n",
       "                     0.91227285, 0.91289947, 0.91316802, 0.91370513, 0.91549548,\n",
       "                     0.91773342, 0.92382061, 0.93205622, 0.9325038 , 0.93581595,\n",
       "                     0.94244025, 0.94494674, 0.94593143, 0.94637902, 0.94664757,\n",
       "                     0.95022827, 0.95085489, 0.95380897, 0.95425656, 0.95774774,\n",
       "                     0.95846388, 0.95944857, 0.9621341 , 0.9626712 , 0.96464059,\n",
       "                     0.96508817, 0.96750515, 0.96992212, 0.97600931, 0.97654641,\n",
       "                     0.97681497, 0.97744159, 0.97771014, 0.97932146, 0.98218602,\n",
       "                     0.98540865, 0.98639334, 0.987199  , 0.98755707, 0.98818369,\n",
       "                     0.98836272, 0.98916838, 0.99122728, 0.99257005, 0.99265956,\n",
       "                     0.99328619, 0.99373377, 0.99409184, 0.99453943, 0.99462895,\n",
       "                     0.99534509, 0.99588219, 0.99659833, 0.99713544, 0.99740399,\n",
       "                     0.99776206, 0.99785158, 0.99812013, 0.99820965, 0.99829917,\n",
       "                     0.99856772, 0.99874675, 0.99883627, 0.99901531, 0.99919434,\n",
       "                     0.99973145, 0.99991048, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.06192872e-02, -2.27282511e-02,\n",
       "                     -4.65200156e-02, -5.55698512e-02, -7.14589640e-02, -7.41079722e-02,\n",
       "                     -8.33816089e-02, -8.70113770e-02, -9.53101798e-02, -1.01782694e-01,\n",
       "                     -1.05360516e-01, -1.13328685e-01, -1.17783036e-01, -1.19545151e-01,\n",
       "                     -1.27833372e-01, -1.31336002e-01, -1.33531393e-01, -1.37201122e-01,\n",
       "                     -1.38150338e-01, -1.41078598e-01, -1.54150680e-01, -1.54150680e-01,\n",
       "                     -1.57392174e-01, -1.70151021e-01, -1.78691789e-01, -1.82321557e-01,\n",
       "                     -1.91055237e-01, -1.98450939e-01, -1.98850859e-01, -2.01799364e-01,\n",
       "                     -2.01941344e-01, -2.05263126e-01, -2.07639365e-01, -2.16223108e-01,\n",
       "                     -2.23143551e-01, -2.28412664e-01, -2.52495763e-01, -2.54892250e-01,\n",
       "                     -2.57829109e-01, -2.60283098e-01, -2.62364264e-01, -2.64692554e-01,\n",
       "                     -2.66628663e-01, -2.77631737e-01, -2.87682072e-01, -3.05381650e-01,\n",
       "                     -3.09422059e-01, -3.13657559e-01, -3.15081047e-01, -3.18453731e-01,\n",
       "                     -3.25422400e-01, -3.31357136e-01, -3.36472237e-01, -3.38023827e-01,\n",
       "                     -3.41170757e-01, -3.48306694e-01, -3.50721182e-01, -3.52317639e-01,\n",
       "                     -3.53279355e-01, -3.54545018e-01, -3.56674944e-01, -3.62905494e-01,\n",
       "                     -3.65113813e-01, -3.67724780e-01, -3.77294231e-01, -3.79489622e-01,\n",
       "                     -3.81367557e-01, -3.82992252e-01, -3.87765531e-01, -3.89464767e-01,\n",
       "                     -3.90427231e-01, -4.05465108e-01, -4.05465108e-01, -4.09675641e-01,\n",
       "                     -4.19853846e-01, -4.21213465e-01, -4.30782916e-01, -4.35318071e-01,\n",
       "                     -4.37213806e-01, -4.41832752e-01, -4.46287103e-01, -4.50927482e-01,\n",
       "                     -4.51985124e-01, -4.52532619e-01, -4.54255272e-01, -4.58457638e-01,\n",
       "                     -4.62623522e-01, -4.65757338e-01, -4.70003629e-01, -4.75978892e-01,\n",
       "                     -4.78604745e-01, -4.83426650e-01, -4.85507816e-01, -4.89548225e-01,\n",
       "                     -4.91407538e-01, -4.92476485e-01, -4.94696242e-01, -5.00035916e-01,\n",
       "                     -5.10825624e-01, -5.17943092e-01, -5.19875459e-01, -5.23248144e-01,\n",
       "                     -5.26093096e-01, -5.28067430e-01, -5.38996501e-01, -5.42324291e-01,\n",
       "                     -5.59615788e-01, -5.67520967e-01, -5.71257363e-01, -5.87786665e-01,\n",
       "                     -6.06135804e-01, -6.11801541e-01, -6.28608659e-01, -6.35988767e-01,\n",
       "                     -6.45137961e-01, -6.46627165e-01, -6.53926467e-01, -6.56779536e-01,\n",
       "                     -6.75128675e-01, -6.77398824e-01, -6.81170990e-01, -6.93147181e-01,\n",
       "                     -7.05268541e-01, -7.09147522e-01, -7.11496319e-01, -7.30887509e-01,\n",
       "                     -7.33969175e-01, -7.41937345e-01, -7.43578034e-01, -7.53771802e-01,\n",
       "                     -7.62140052e-01, -7.81700578e-01, -7.88457360e-01, -7.88457360e-01,\n",
       "                     -8.10930216e-01, -8.31983625e-01, -8.36853901e-01, -8.47297860e-01,\n",
       "                     -8.47297860e-01, -8.70828358e-01, -8.75468737e-01, -8.90972924e-01,\n",
       "                     -8.93817876e-01, -8.97941593e-01, -9.02867712e-01, -9.05708623e-01,\n",
       "                     -9.16290732e-01, -9.32696767e-01, -9.40983344e-01, -9.44461609e-01,\n",
       "                     -9.46143695e-01, -9.49080555e-01, -9.55511445e-01, -9.55511445e-01,\n",
       "                     -9.58850346e-01, -9.66656444e-01, -9.70949144e-01, -9.80829253e-01,\n",
       "                     -9.87946721e-01, -9.93251773e-01, -1.00037385e+00, -1.00764051e+00,\n",
       "                     -1.01064352e+00, -1.01160091e+00, -1.01345448e+00, -1.02165125e+00,\n",
       "                     -1.02961942e+00, -1.03798767e+00, -1.04145387e+00, -1.04982212e+00,\n",
       "                     -1.06784063e+00, -1.07044141e+00, -1.09024404e+00, -1.09861229e+00,\n",
       "                     -1.09861229e+00, -1.12938395e+00, -1.13140211e+00, -1.13497993e+00,\n",
       "                     -1.14513230e+00, -1.14862271e+00, -1.15267951e+00, -1.15745279e+00,\n",
       "                     -1.17865500e+00, -1.18455472e+00, -1.18958407e+00, -1.20397280e+00,\n",
       "                     -1.20397280e+00, -1.20896035e+00, -1.21194097e+00, -1.21421430e+00,\n",
       "                     -1.21800434e+00, -1.22377543e+00, -1.24111235e+00, -1.24889449e+00,\n",
       "                     -1.25276297e+00, -1.26566637e+00, -1.28093385e+00, -1.29928298e+00,\n",
       "                     -1.30833282e+00, -1.31218639e+00, -1.32377400e+00, -1.33500107e+00,\n",
       "                     -1.38629436e+00, -1.41706602e+00, -1.45225233e+00, -1.45861502e+00,\n",
       "                     -1.46633707e+00, -1.47330574e+00, -1.48160454e+00, -1.49165488e+00,\n",
       "                     -1.49995368e+00, -1.58863478e+00, -1.60943791e+00, -1.60943791e+00,\n",
       "                     -1.63760879e+00, -1.67397643e+00, -1.68433922e+00, -1.69905007e+00,\n",
       "                     -1.69968479e+00, -1.71297859e+00, -1.71479843e+00, -1.74919985e+00,\n",
       "                     -1.79175947e+00, -1.79175947e+00, -1.81010861e+00, -1.85493837e+00,\n",
       "                     -1.92667879e+00, -1.94591015e+00, -1.94591015e+00, -2.02814825e+00,\n",
       "                     -2.04769284e+00, -2.05412373e+00, -2.07944154e+00, -2.09494573e+00,\n",
       "                     -2.12026354e+00, -2.18323834e+00, -2.19722458e+00, -2.23359222e+00,\n",
       "                     -2.30258509e+00, -2.30258509e+00, -2.33537492e+00, -2.39789527e+00,\n",
       "                     -2.39789527e+00, -2.48490665e+00, -2.52572864e+00, -2.63905733e+00,\n",
       "                     -2.67414865e+00, -2.91777073e+00, -3.09104245e+00, -3.79548919e+00,\n",
       "                     -3.89182030e+00, -3.45387764e+01]), auc_score=0.518685478093771, privacy_risk=0.5153074926148062, accuracy=0.5153074926148062, tpr_ind=0.9325038044937786, tnr_ind=0.09811118073583386, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.07868588, 0.08325128, 0.08504163, 0.08629487,\n",
       "                     0.08763763, 0.09077075, 0.0930982 , 0.09587324, 0.09900636,\n",
       "                     0.09945394, 0.10196043, 0.10258706, 0.1038403 , 0.10473548,\n",
       "                     0.10500403, 0.10616776, 0.10697341, 0.11001701, 0.11261302,\n",
       "                     0.11485095, 0.11547758, 0.120222  , 0.12389222, 0.12621968,\n",
       "                     0.16596545, 0.16739773, 0.17026229, 0.17384299, 0.17778176,\n",
       "                     0.18046728, 0.1861964 , 0.18861337, 0.21215648, 0.22030257,\n",
       "                     0.22647928, 0.22719542, 0.23614717, 0.23829559, 0.25619909,\n",
       "                     0.2613911 , 0.27938412, 0.28744069, 0.29173753, 0.3109838 ,\n",
       "                     0.32118879, 0.32351625, 0.3288873 , 0.32987199, 0.34007699,\n",
       "                     0.34750694, 0.35574255, 0.35780145, 0.36487333, 0.36952824,\n",
       "                     0.37301943, 0.37874855, 0.38018083, 0.3841196 , 0.38698416,\n",
       "                     0.40551428, 0.40873691, 0.41383941, 0.41938949, 0.42798317,\n",
       "                     0.43496554, 0.43595023, 0.43962045, 0.44427536, 0.44919882,\n",
       "                     0.4506311 , 0.46262644, 0.46683377, 0.46808701, 0.48679617,\n",
       "                     0.49753827, 0.49861248, 0.498702  , 0.50326739, 0.50666905,\n",
       "                     0.50881747, 0.51042879, 0.54301316, 0.55008504, 0.55053263,\n",
       "                     0.55930534, 0.55939486, 0.56440784, 0.57174828, 0.57667174,\n",
       "                     0.58571301, 0.59063647, 0.59752932, 0.6025423 , 0.62196759,\n",
       "                     0.62268373, 0.62474264, 0.62617492, 0.62769671, 0.62975562,\n",
       "                     0.63145645, 0.63333632, 0.63521618, 0.63861785, 0.64067675,\n",
       "                     0.64425745, 0.64819622, 0.65365679, 0.65419389, 0.66627876,\n",
       "                     0.66726345, 0.66842718, 0.67630472, 0.68033301, 0.68301853,\n",
       "                     0.69608809, 0.69760988, 0.69948975, 0.70387611, 0.70620356,\n",
       "                     0.70718826, 0.71855698, 0.7191836 , 0.72410706, 0.72876197,\n",
       "                     0.73377495, 0.73583386, 0.73834035, 0.73905649, 0.74022021,\n",
       "                     0.74057828, 0.74210008, 0.74389043, 0.74532271, 0.74711306,\n",
       "                     0.74881389, 0.74908245, 0.76036165, 0.76340525, 0.76823919,\n",
       "                     0.77199893, 0.77754901, 0.78175633, 0.7902605 , 0.79222988,\n",
       "                     0.79258795, 0.7964372 , 0.79688479, 0.80037597, 0.81962224,\n",
       "                     0.82006982, 0.82123355, 0.82356101, 0.82570943, 0.8260675 ,\n",
       "                     0.82624653, 0.83116999, 0.83851043, 0.83904753, 0.84173306,\n",
       "                     0.84782025, 0.84889446, 0.8501477 , 0.85211709, 0.8537284 ,\n",
       "                     0.85453406, 0.85704055, 0.86178498, 0.86375436, 0.86635037,\n",
       "                     0.86778265, 0.87413839, 0.8752126 , 0.87664488, 0.87745054,\n",
       "                     0.88174738, 0.88344821, 0.88434339, 0.88514905, 0.8874765 ,\n",
       "                     0.88801361, 0.89159431, 0.89571211, 0.90144123, 0.90197834,\n",
       "                     0.90358965, 0.90466386, 0.9089607 , 0.91988184, 0.92265688,\n",
       "                     0.92570047, 0.93053442, 0.93268284, 0.93850148, 0.93903858,\n",
       "                     0.94369349, 0.94378301, 0.94557336, 0.94799033, 0.95595739,\n",
       "                     0.95730015, 0.95891147, 0.95926954, 0.96052278, 0.96123892,\n",
       "                     0.96231313, 0.96365589, 0.96410348, 0.97395041, 0.97484558,\n",
       "                     0.9764569 , 0.97726255, 0.97744159, 0.97753111, 0.97771014,\n",
       "                     0.97824725, 0.97842628, 0.9785158 , 0.97896339, 0.97896339,\n",
       "                     0.97932146, 0.9800376 , 0.98102229, 0.98129084, 0.98138036,\n",
       "                     0.98191746, 0.9826336 , 0.98334974, 0.98370781, 0.98442395,\n",
       "                     0.98460299, 1.        ]), tpr=array([0.        , 0.08969654, 0.09399338, 0.09748456, 0.09900636,\n",
       "                     0.10043864, 0.10366127, 0.10724197, 0.10885328, 0.11180736,\n",
       "                     0.1125235 , 0.11601468, 0.11726793, 0.11959538, 0.12013249,\n",
       "                     0.12066959, 0.12219139, 0.12317608, 0.12702533, 0.12935279,\n",
       "                     0.13159073, 0.13284397, 0.13696178, 0.14179572, 0.14457076,\n",
       "                     0.18494316, 0.18610688, 0.18915048, 0.19291021, 0.19756512,\n",
       "                     0.20034017, 0.20544266, 0.20848626, 0.23167129, 0.23972787,\n",
       "                     0.24644168, 0.2470683 , 0.25754185, 0.25906365, 0.27732522,\n",
       "                     0.28385999, 0.30418047, 0.31277415, 0.31760809, 0.34294155,\n",
       "                     0.3544893 , 0.35744338, 0.36209829, 0.36353057, 0.37400412,\n",
       "                     0.38295587, 0.3918181 , 0.39396652, 0.40184406, 0.40623042,\n",
       "                     0.41016919, 0.41742011, 0.41947901, 0.42297019, 0.42520813,\n",
       "                     0.4404261 , 0.4440068 , 0.4491093 , 0.45367469, 0.46334258,\n",
       "                     0.46889267, 0.46996688, 0.47399517, 0.4762331 , 0.4798138 ,\n",
       "                     0.48151464, 0.49198818, 0.49637454, 0.49753827, 0.51266673,\n",
       "                     0.52331931, 0.52412497, 0.52493062, 0.52869036, 0.53101781,\n",
       "                     0.53379286, 0.53486707, 0.56780951, 0.57452332, 0.57568705,\n",
       "                     0.5836541 , 0.58437024, 0.58902515, 0.59815594, 0.60388506,\n",
       "                     0.61104646, 0.61641751, 0.62483215, 0.62948706, 0.64828574,\n",
       "                     0.64944947, 0.65213499, 0.65428341, 0.65553666, 0.65777459,\n",
       "                     0.65911736, 0.66090771, 0.66278757, 0.66744249, 0.66968042,\n",
       "                     0.67442485, 0.67836362, 0.68364515, 0.68436129, 0.69626712,\n",
       "                     0.6971623 , 0.69823651, 0.70521887, 0.70897861, 0.71103751,\n",
       "                     0.72249575, 0.72446513, 0.72795632, 0.73440158, 0.73538627,\n",
       "                     0.73619193, 0.74675499, 0.74738161, 0.75194701, 0.75525915,\n",
       "                     0.75919792, 0.76098827, 0.76456897, 0.76600125, 0.76680691,\n",
       "                     0.76734402, 0.76832871, 0.76994002, 0.7708352 , 0.772357  ,\n",
       "                     0.77423686, 0.77504252, 0.78802256, 0.79115567, 0.79679527,\n",
       "                     0.80037597, 0.80503088, 0.8087011 , 0.81451974, 0.81747382,\n",
       "                     0.8179214 , 0.82284487, 0.82356101, 0.82758929, 0.84710411,\n",
       "                     0.84773073, 0.84934205, 0.85068481, 0.85283323, 0.85328082,\n",
       "                     0.8537284 , 0.85963656, 0.86787217, 0.86849879, 0.87082625,\n",
       "                     0.87637633, 0.87727151, 0.87915137, 0.8803151 , 0.882374  ,\n",
       "                     0.88291111, 0.88568615, 0.89034106, 0.89248948, 0.89481694,\n",
       "                     0.89642825, 0.90314206, 0.90412676, 0.90564855, 0.90654373,\n",
       "                     0.90967684, 0.91137767, 0.91191478, 0.91325754, 0.91656969,\n",
       "                     0.91746486, 0.92104556, 0.92462626, 0.92865455, 0.92919166,\n",
       "                     0.93089249, 0.9319667 , 0.93599499, 0.9447677 , 0.94637902,\n",
       "                     0.94915406, 0.95559932, 0.9575687 , 0.96302927, 0.96347686,\n",
       "                     0.96652045, 0.96669949, 0.96857936, 0.97072778, 0.97690448,\n",
       "                     0.97771014, 0.9790529 , 0.97976904, 0.98075374, 0.98093277,\n",
       "                     0.98182795, 0.98254409, 0.98281264, 0.99212246, 0.99274908,\n",
       "                     0.99382329, 0.99471847, 0.99498702, 0.99543461, 0.99588219,\n",
       "                     0.99659833, 0.99677737, 0.99704592, 0.99713544, 0.99722496,\n",
       "                     0.99758303, 0.99776206, 0.99820965, 0.99829917, 0.99865724,\n",
       "                     0.99883627, 0.99919434, 0.99946289, 0.99964193, 0.99982096,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.08219945e-02, -5.00104206e-02,\n",
       "                     -5.71584138e-02, -6.06246218e-02, -8.00427077e-02, -9.53101798e-02,\n",
       "                     -1.05360516e-01, -1.14410351e-01, -1.17783036e-01, -1.20627988e-01,\n",
       "                     -1.33531393e-01, -1.43100844e-01, -1.54150680e-01, -1.54150680e-01,\n",
       "                     -1.62518929e-01, -1.67054085e-01, -1.70625517e-01, -1.75890666e-01,\n",
       "                     -1.82321557e-01, -1.94156014e-01, -1.96710294e-01, -2.00670695e-01,\n",
       "                     -2.03598955e-01, -2.07500774e-01, -2.07639365e-01, -2.11309094e-01,\n",
       "                     -2.13574100e-01, -2.23143551e-01, -2.29574442e-01, -2.33614851e-01,\n",
       "                     -2.34839591e-01, -2.36185547e-01, -2.36388778e-01, -2.46860078e-01,\n",
       "                     -2.51314428e-01, -2.55105902e-01, -2.57829109e-01, -2.61609832e-01,\n",
       "                     -2.63417450e-01, -2.75493556e-01, -2.79838895e-01, -2.87682072e-01,\n",
       "                     -2.97352477e-01, -2.99242895e-01, -3.10154928e-01, -3.11436158e-01,\n",
       "                     -3.18453731e-01, -3.25422400e-01, -3.36472237e-01, -3.39354083e-01,\n",
       "                     -3.48306694e-01, -3.50976923e-01, -3.56674944e-01, -3.58945092e-01,\n",
       "                     -3.59141036e-01, -3.61013346e-01, -3.61790045e-01, -3.64643114e-01,\n",
       "                     -3.65459773e-01, -3.71563556e-01, -3.75789340e-01, -3.85662481e-01,\n",
       "                     -3.93042588e-01, -4.05465108e-01, -4.05465108e-01, -4.12845215e-01,\n",
       "                     -4.18710335e-01, -4.21994410e-01, -4.22856851e-01, -4.25211871e-01,\n",
       "                     -4.25667815e-01, -4.30782916e-01, -4.34621692e-01, -4.41232332e-01,\n",
       "                     -4.41832752e-01, -4.41832752e-01, -4.51985124e-01, -4.55475529e-01,\n",
       "                     -4.57833094e-01, -4.59532329e-01, -4.65236851e-01, -4.70003629e-01,\n",
       "                     -4.79573080e-01, -4.81176930e-01, -4.85507816e-01, -4.91407538e-01,\n",
       "                     -4.93020999e-01, -4.95077267e-01, -5.00775288e-01, -5.10825624e-01,\n",
       "                     -5.12951023e-01, -5.14664400e-01, -5.25010259e-01, -5.26093096e-01,\n",
       "                     -5.30628251e-01, -5.35518236e-01, -5.38996501e-01, -5.42324291e-01,\n",
       "                     -5.50046337e-01, -5.59615788e-01, -5.66395475e-01, -5.70544858e-01,\n",
       "                     -5.87786665e-01, -6.04419065e-01, -6.10259521e-01, -6.22942922e-01,\n",
       "                     -6.28608659e-01, -6.35103811e-01, -6.41853886e-01, -6.50587566e-01,\n",
       "                     -6.53926467e-01, -6.56779536e-01, -6.71168274e-01, -6.93147181e-01,\n",
       "                     -7.15620036e-01, -7.30887509e-01, -7.33969175e-01, -7.37598943e-01,\n",
       "                     -7.47214402e-01, -7.54768315e-01, -7.62140052e-01, -7.68654733e-01,\n",
       "                     -7.83531242e-01, -7.90521345e-01, -8.10930216e-01, -8.32909123e-01,\n",
       "                     -8.38329190e-01, -8.47297860e-01, -8.47297860e-01, -8.60201265e-01,\n",
       "                     -8.70828358e-01, -8.75468737e-01, -8.80358723e-01, -8.87303195e-01,\n",
       "                     -8.93817876e-01, -8.95384047e-01, -9.10560057e-01, -9.13111079e-01,\n",
       "                     -9.16290732e-01, -9.31558204e-01, -9.40388283e-01, -9.43606543e-01,\n",
       "                     -9.46143695e-01, -9.55511445e-01, -9.62480114e-01, -9.65080896e-01,\n",
       "                     -9.80829253e-01, -9.88824727e-01, -9.98528830e-01, -1.00144854e+00,\n",
       "                     -1.00552187e+00, -1.01160091e+00, -1.02961942e+00, -1.02961942e+00,\n",
       "                     -1.03070108e+00, -1.04273183e+00, -1.04982212e+00, -1.05939158e+00,\n",
       "                     -1.06025142e+00, -1.06471074e+00, -1.06635143e+00, -1.07263680e+00,\n",
       "                     -1.08401349e+00, -1.09861229e+00, -1.09861229e+00, -1.12393010e+00,\n",
       "                     -1.13943428e+00, -1.16074407e+00, -1.17007125e+00, -1.18377010e+00,\n",
       "                     -1.18562367e+00, -1.19213835e+00, -1.19392247e+00, -1.19824213e+00,\n",
       "                     -1.19869575e+00, -1.20397280e+00, -1.20397280e+00, -1.21739582e+00,\n",
       "                     -1.22377543e+00, -1.24559448e+00, -1.25276297e+00, -1.28093385e+00,\n",
       "                     -1.29928298e+00, -1.31824090e+00, -1.32175584e+00, -1.35239281e+00,\n",
       "                     -1.35783190e+00, -1.38629436e+00, -1.41019988e+00, -1.42377745e+00,\n",
       "                     -1.46283444e+00, -1.46885596e+00, -1.48160454e+00, -1.49091931e+00,\n",
       "                     -1.50407740e+00, -1.51982575e+00, -1.55814462e+00, -1.55890710e+00,\n",
       "                     -1.56397554e+00, -1.56861592e+00, -1.58412010e+00, -1.60943791e+00,\n",
       "                     -1.60943791e+00, -1.64865863e+00, -1.65822808e+00, -1.67397643e+00,\n",
       "                     -1.67457721e+00, -1.69167601e+00, -1.70474809e+00, -1.72276660e+00,\n",
       "                     -1.73460106e+00, -1.79175947e+00, -1.82454929e+00, -1.85238409e+00,\n",
       "                     -1.87180218e+00, -1.89711998e+00, -1.94591015e+00, -1.94591015e+00,\n",
       "                     -2.01490302e+00, -2.07944154e+00, -2.17475172e+00, -2.19722458e+00,\n",
       "                     -2.22462355e+00, -2.30258509e+00, -2.39789527e+00, -2.56494936e+00,\n",
       "                     -2.89037176e+00, -3.02042489e+00, -3.21887582e+00, -3.45387764e+01]), auc_score=0.5242987526664632, privacy_risk=0.5196490913973681, accuracy=0.5196490913973681, tpr_ind=0.41947900814609257, tnr_ind=0.6198191746486438, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.046012  , 0.09148689, 0.09238206, 0.09462   ,\n",
       "                     0.09990153, 0.1089428 , 0.11064363, 0.11476144, 0.12058007,\n",
       "                     0.12165428, 0.12362367, 0.12657775, 0.13141169, 0.13418673,\n",
       "                     0.13615612, 0.14403366, 0.1519112 , 0.16515979, 0.16802435,\n",
       "                     0.1682929 , 0.19765464, 0.20445797, 0.20535315, 0.20947095,\n",
       "                     0.21054516, 0.21179841, 0.21582669, 0.21878077, 0.22782204,\n",
       "                     0.23131322, 0.25252887, 0.27025333, 0.27356548, 0.31590726,\n",
       "                     0.31966699, 0.32154686, 0.32244204, 0.32467997, 0.33291558,\n",
       "                     0.33533256, 0.33846567, 0.3401665 , 0.3652314 , 0.3688121 ,\n",
       "                     0.37292991, 0.39280279, 0.39316086, 0.42234357, 0.42458151,\n",
       "                     0.42717751, 0.43433891, 0.4368454 , 0.439889  , 0.44597619,\n",
       "                     0.44955689, 0.45868767, 0.462895  , 0.46513293, 0.46567004,\n",
       "                     0.47077254, 0.47587503, 0.4792767 , 0.48232029, 0.48276788,\n",
       "                     0.4843792 , 0.48545341, 0.48590099, 0.48804941, 0.52895891,\n",
       "                     0.53334527, 0.53486707, 0.53603079, 0.53817921, 0.54346075,\n",
       "                     0.54650434, 0.54766807, 0.55357622, 0.55536657, 0.55751499,\n",
       "                     0.55778355, 0.56297556, 0.56619819, 0.58616059, 0.58884612,\n",
       "                     0.60003581, 0.60728672, 0.60898756, 0.61086742, 0.61355295,\n",
       "                     0.61856593, 0.61964014, 0.62357891, 0.62474264, 0.62599588,\n",
       "                     0.62796527, 0.63136693, 0.6337839 , 0.63870737, 0.64210903,\n",
       "                     0.64560021, 0.64667442, 0.65544714, 0.65840122, 0.65974398,\n",
       "                     0.66180288, 0.66493599, 0.66663683, 0.66815863, 0.67299257,\n",
       "                     0.67711038, 0.69125414, 0.69698326, 0.70226479, 0.70369707,\n",
       "                     0.70441321, 0.70727777, 0.70888909, 0.71014233, 0.71238027,\n",
       "                     0.71855698, 0.71936264, 0.72186913, 0.72500224, 0.72544983,\n",
       "                     0.72724018, 0.73279026, 0.73467013, 0.73753469, 0.73798228,\n",
       "                     0.73825083, 0.73905649, 0.74174201, 0.74344284, 0.74648644,\n",
       "                     0.75006714, 0.75078328, 0.75275266, 0.75731806, 0.76537463,\n",
       "                     0.7672545 , 0.77907081, 0.78104019, 0.78184585, 0.78551607,\n",
       "                     0.78605317, 0.78685883, 0.78820159, 0.7923194 , 0.79348313,\n",
       "                     0.79652672, 0.79939128, 0.79992839, 0.80073404, 0.80180825,\n",
       "                     0.80431474, 0.82168114, 0.82221824, 0.82320294, 0.82409811,\n",
       "                     0.82535136, 0.82588846, 0.82920061, 0.83072241, 0.83260227,\n",
       "                     0.83573539, 0.83645153, 0.83806284, 0.84128547, 0.84585086,\n",
       "                     0.84701459, 0.84978963, 0.85077433, 0.85238564, 0.85256468,\n",
       "                     0.85605586, 0.85865187, 0.85927849, 0.87198997, 0.87216901,\n",
       "                     0.88040462, 0.88264256, 0.88559663, 0.89777101, 0.89902426,\n",
       "                     0.90054606, 0.90144123, 0.90367917, 0.90573807, 0.90663325,\n",
       "                     0.90770746, 0.90905022, 0.9232835 , 0.92605854, 0.93107152,\n",
       "                     0.93975472, 0.94109748, 0.94235073, 0.94306687, 0.9442306 ,\n",
       "                     0.94566288, 0.94611046, 0.94790081, 0.94897502, 0.95309283,\n",
       "                     0.95327186, 0.96088085, 0.96097037, 0.96249217, 0.96437203,\n",
       "                     0.9662519 , 0.96786322, 0.96813177, 0.96857936, 0.97001164,\n",
       "                     0.97207054, 0.97323427, 0.97412944, 0.97421896, 0.97753111,\n",
       "                     0.97860532, 0.98021663, 0.98245457, 0.98379733, 0.98442395,\n",
       "                     0.98469251, 0.98737803, 1.        ]), tpr=array([0.        , 0.05469519, 0.09846925, 0.09945394, 0.10213947,\n",
       "                     0.10858473, 0.11789455, 0.12165428, 0.12756244, 0.13382866,\n",
       "                     0.13499239, 0.13714081, 0.14125862, 0.14734581, 0.15119506,\n",
       "                     0.153433  , 0.16095247, 0.1677558 , 0.18163101, 0.18530123,\n",
       "                     0.18610688, 0.21314117, 0.22209292, 0.22415182, 0.23023901,\n",
       "                     0.2322084 , 0.23444633, 0.23954883, 0.24268194, 0.25100707,\n",
       "                     0.25512488, 0.27947364, 0.29827231, 0.3028377 , 0.34696983,\n",
       "                     0.35144571, 0.35323606, 0.35422075, 0.35789097, 0.36693224,\n",
       "                     0.36908066, 0.37310894, 0.37472026, 0.39987468, 0.40372393,\n",
       "                     0.40846836, 0.42977352, 0.43111628, 0.46316355, 0.465491  ,\n",
       "                     0.4690717 , 0.47659117, 0.47999284, 0.48294692, 0.48813893,\n",
       "                     0.49100349, 0.49879151, 0.50371498, 0.50729568, 0.50854892,\n",
       "                     0.51517322, 0.51830633, 0.52134992, 0.52519918, 0.5263629 ,\n",
       "                     0.52833229, 0.53012264, 0.5309283 , 0.53253961, 0.56771999,\n",
       "                     0.57121117, 0.57246442, 0.57353863, 0.57506042, 0.57989437,\n",
       "                     0.58481783, 0.58732432, 0.59350103, 0.59511234, 0.59627607,\n",
       "                     0.59699221, 0.60137857, 0.60531734, 0.62635395, 0.62886044,\n",
       "                     0.63987109, 0.64685346, 0.64935995, 0.65079223, 0.65374631,\n",
       "                     0.65804315, 0.65929639, 0.6624295 , 0.66421985, 0.66538358,\n",
       "                     0.66896428, 0.67173933, 0.67630472, 0.68060156, 0.68391371,\n",
       "                     0.68749441, 0.68812103, 0.69653567, 0.6992212 , 0.700743  ,\n",
       "                     0.70235431, 0.7043237 , 0.70539791, 0.70674067, 0.71112703,\n",
       "                     0.71614001, 0.72849342, 0.73332737, 0.73753469, 0.73878793,\n",
       "                     0.73977263, 0.74156298, 0.74299526, 0.74433802, 0.74666547,\n",
       "                     0.75391639, 0.7544535 , 0.75749709, 0.76027213, 0.76116731,\n",
       "                     0.76385283, 0.76761257, 0.76985051, 0.77271507, 0.77361024,\n",
       "                     0.77387879, 0.774953  , 0.77719094, 0.77808612, 0.78112971,\n",
       "                     0.78318861, 0.78417331, 0.78587414, 0.79052905, 0.79769045,\n",
       "                     0.79930176, 0.81272939, 0.81460926, 0.81523588, 0.81801092,\n",
       "                     0.81845851, 0.81917465, 0.82015934, 0.82391908, 0.82544087,\n",
       "                     0.82839495, 0.83125951, 0.83215469, 0.83278131, 0.83349745,\n",
       "                     0.83546683, 0.85507117, 0.85596634, 0.85641393, 0.85739862,\n",
       "                     0.85847283, 0.85909945, 0.86115836, 0.86276967, 0.86438099,\n",
       "                     0.86778265, 0.86840927, 0.87019962, 0.8726166 , 0.87628681,\n",
       "                     0.87762958, 0.88004655, 0.88138931, 0.88291111, 0.88317966,\n",
       "                     0.88613374, 0.88765554, 0.88864023, 0.90215737, 0.90269448,\n",
       "                     0.91119864, 0.91307851, 0.9146003 , 0.92453675, 0.92516337,\n",
       "                     0.92668517, 0.92749082, 0.93080297, 0.93214573, 0.9325038 ,\n",
       "                     0.93313043, 0.93465222, 0.94951213, 0.95103393, 0.95721063,\n",
       "                     0.96490914, 0.96616238, 0.96866887, 0.96956405, 0.97099633,\n",
       "                     0.97162295, 0.97216006, 0.97377137, 0.97430848, 0.9764569 ,\n",
       "                     0.97654641, 0.98272312, 0.98290216, 0.98370781, 0.98666189,\n",
       "                     0.98809417, 0.98961597, 0.98997404, 0.99006356, 0.9907797 ,\n",
       "                     0.99185391, 0.99257005, 0.99292812, 0.99310715, 0.99400233,\n",
       "                     0.99480798, 0.99525557, 0.99632978, 0.99704592, 0.99731447,\n",
       "                     0.99740399, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.76127528e-02, -8.70113770e-02,\n",
       "                     -9.53101798e-02, -1.05360516e-01, -1.09199292e-01, -1.12477983e-01,\n",
       "                     -1.27833372e-01, -1.33531393e-01, -1.43100844e-01, -1.54150680e-01,\n",
       "                     -1.60342650e-01, -1.62518929e-01, -1.70625517e-01, -1.82321557e-01,\n",
       "                     -1.84303718e-01, -1.91055237e-01, -1.93016846e-01, -1.98450939e-01,\n",
       "                     -2.00670695e-01, -2.05775045e-01, -2.23143551e-01, -2.31801614e-01,\n",
       "                     -2.34839591e-01, -2.41162057e-01, -2.46860078e-01, -2.47408173e-01,\n",
       "                     -2.51314428e-01, -2.63191052e-01, -2.65703166e-01, -2.74730920e-01,\n",
       "                     -2.84104251e-01, -2.87682072e-01, -2.90214360e-01, -2.92669614e-01,\n",
       "                     -3.00104592e-01, -3.10154928e-01, -3.11779624e-01, -3.12133168e-01,\n",
       "                     -3.18453731e-01, -3.20471895e-01, -3.28504067e-01, -3.32907170e-01,\n",
       "                     -3.33144447e-01, -3.33773180e-01, -3.35871816e-01, -3.36472237e-01,\n",
       "                     -3.51915030e-01, -3.52821375e-01, -3.54171814e-01, -3.56674944e-01,\n",
       "                     -3.69747026e-01, -3.74693449e-01, -3.82208246e-01, -3.84411699e-01,\n",
       "                     -3.86122145e-01, -3.99386062e-01, -4.05465108e-01, -4.05465108e-01,\n",
       "                     -4.14433778e-01, -4.14943852e-01, -4.24883194e-01, -4.28454626e-01,\n",
       "                     -4.30782916e-01, -4.35318071e-01, -4.38254931e-01, -4.41832752e-01,\n",
       "                     -4.41832752e-01, -4.42922671e-01, -4.47312218e-01, -4.51985124e-01,\n",
       "                     -4.59532329e-01, -4.62623522e-01, -4.65363250e-01, -4.70003629e-01,\n",
       "                     -4.74457980e-01, -4.75423697e-01, -4.76924072e-01, -4.79573080e-01,\n",
       "                     -4.85507816e-01, -4.90206337e-01, -4.92476485e-01, -4.93657820e-01,\n",
       "                     -4.96436886e-01, -5.01021624e-01, -5.10825624e-01, -5.17943092e-01,\n",
       "                     -5.23248144e-01, -5.28844129e-01, -5.35518236e-01, -5.38996501e-01,\n",
       "                     -5.38996501e-01, -5.59615788e-01, -5.70544858e-01, -5.87786665e-01,\n",
       "                     -5.91364486e-01, -6.00773860e-01, -6.06135804e-01, -6.08589793e-01,\n",
       "                     -6.15185639e-01, -6.19039208e-01, -6.21491192e-01, -6.24154309e-01,\n",
       "                     -6.32522559e-01, -6.35988767e-01, -6.46627165e-01, -6.50587566e-01,\n",
       "                     -6.59245629e-01, -6.72527893e-01, -6.75128675e-01, -6.93147181e-01,\n",
       "                     -7.11496319e-01, -7.14200590e-01, -7.28238500e-01, -7.37598943e-01,\n",
       "                     -7.41937345e-01, -7.53771802e-01, -7.57685702e-01, -7.67255153e-01,\n",
       "                     -7.70336819e-01, -7.73189888e-01, -7.77704569e-01, -7.85520501e-01,\n",
       "                     -7.88457360e-01, -7.88457360e-01, -7.94929875e-01, -8.06475866e-01,\n",
       "                     -8.10930216e-01, -8.32909123e-01, -8.47297860e-01, -8.47297860e-01,\n",
       "                     -8.75468737e-01, -8.75468737e-01, -8.80358723e-01, -8.89857475e-01,\n",
       "                     -8.97941593e-01, -9.05708623e-01, -9.16290732e-01, -9.31179344e-01,\n",
       "                     -9.38269639e-01, -9.42608040e-01, -9.44461609e-01, -9.44461609e-01,\n",
       "                     -9.48039430e-01, -9.55511445e-01, -9.65080896e-01, -9.69400557e-01,\n",
       "                     -9.71860583e-01, -9.73449146e-01, -9.80829253e-01, -9.88611393e-01,\n",
       "                     -9.93251773e-01, -9.98528830e-01, -1.01160091e+00, -1.01983141e+00,\n",
       "                     -1.02766055e+00, -1.02961942e+00, -1.02961942e+00, -1.03609193e+00,\n",
       "                     -1.04145387e+00, -1.04982212e+00, -1.05416053e+00, -1.06087196e+00,\n",
       "                     -1.07992016e+00, -1.08091271e+00, -1.09861229e+00, -1.09861229e+00,\n",
       "                     -1.11088238e+00, -1.13845820e+00, -1.14209740e+00, -1.14681439e+00,\n",
       "                     -1.16315081e+00, -1.17411984e+00, -1.20397280e+00, -1.20397280e+00,\n",
       "                     -1.20983792e+00, -1.21302264e+00, -1.21516818e+00, -1.25276297e+00,\n",
       "                     -1.25426560e+00, -1.25954266e+00, -1.26113122e+00, -1.26173164e+00,\n",
       "                     -1.27296568e+00, -1.29392104e+00, -1.29928298e+00, -1.31633577e+00,\n",
       "                     -1.31730149e+00, -1.32175584e+00, -1.34992672e+00, -1.37147928e+00,\n",
       "                     -1.37873575e+00, -1.38629436e+00, -1.39710528e+00, -1.42618569e+00,\n",
       "                     -1.45528723e+00, -1.46358604e+00, -1.50407740e+00, -1.51787072e+00,\n",
       "                     -1.51982575e+00, -1.54044504e+00, -1.56397554e+00, -1.57553636e+00,\n",
       "                     -1.60943791e+00, -1.60943791e+00, -1.68209556e+00, -1.70474809e+00,\n",
       "                     -1.71479843e+00, -1.73993440e+00, -1.74919985e+00, -1.78190717e+00,\n",
       "                     -1.79175947e+00, -1.79175947e+00, -1.85238409e+00, -1.89711998e+00,\n",
       "                     -1.90954250e+00, -1.94591015e+00, -2.01490302e+00, -2.07944154e+00,\n",
       "                     -2.12026354e+00, -2.24070969e+00, -2.26868354e+00, -2.30258509e+00,\n",
       "                     -2.39789527e+00, -2.48490665e+00, -2.88267941e+00, -3.45387764e+01]), auc_score=0.5288147907752596, privacy_risk=0.5225136514188524, accuracy=0.5225136514188524, tpr_ind=0.5309282964819623, tnr_ind=0.5140990063557426, test_train_ratio=1.0, dataset_size=[11171, 11171])],\n",
       "             'entire_dataset_label_0.0_mia_auc': [0.5314090932590082,\n",
       "              0.5244885776525288,\n",
       "              0.521979465576706,\n",
       "              0.5230642233221066,\n",
       "              0.5276933913697486,\n",
       "              0.5278550014605767,\n",
       "              0.5213806953101886,\n",
       "              0.5286336397463733,\n",
       "              0.5162836721280014,\n",
       "              0.5137493968887199,\n",
       "              0.5202611265636475,\n",
       "              0.5260778304627962,\n",
       "              0.5199174668058062,\n",
       "              0.5315037233957484,\n",
       "              0.5316979332932024,\n",
       "              0.5264168474459896,\n",
       "              0.5215602104501463,\n",
       "              0.5243946840062249,\n",
       "              0.5255987107382901,\n",
       "              0.5239229283141252],\n",
       "             'entire_dataset_label_0.0_mia_privacy_risk': [0.5246284633785587,\n",
       "              0.5181604788448889,\n",
       "              0.518978954985377,\n",
       "              0.5182207619048962,\n",
       "              0.5202946464155018,\n",
       "              0.5228709503160907,\n",
       "              0.515901991068095,\n",
       "              0.5234695081657699,\n",
       "              0.5124762467070489,\n",
       "              0.5124929099348087,\n",
       "              0.5169147757383051,\n",
       "              0.5228316987998081,\n",
       "              0.5174057138062675,\n",
       "              0.5248137679451459,\n",
       "              0.5238699155572988,\n",
       "              0.520250476744033,\n",
       "              0.5173087511027855,\n",
       "              0.5179216661718037,\n",
       "              0.5237790132019056,\n",
       "              0.5214930428117931],\n",
       "             'entire_dataset_label_0.0_mia_ppv': [0.5338427947598253,\n",
       "              0.5425867507886436,\n",
       "              0.5226748654880861,\n",
       "              0.5318471337579618,\n",
       "              0.5278093076049943,\n",
       "              0.5305895439377085,\n",
       "              0.5280222325150532,\n",
       "              0.5210374639769453,\n",
       "              0.5209019508487458,\n",
       "              0.5174581005586593,\n",
       "              0.5190367718841523,\n",
       "              0.516482013404459,\n",
       "              0.5240567670474212,\n",
       "              0.533689126084056,\n",
       "              0.5352676338169083,\n",
       "              0.5333787465940055,\n",
       "              0.522378908645003,\n",
       "              0.5299539170506913,\n",
       "              0.5289223454833597,\n",
       "              0.5306513409961685],\n",
       "             'entire_dataset_label_0.0_mia_attacker_advantage': [0.04925692675711746,\n",
       "              0.036320957689777944,\n",
       "              0.0379579099707541,\n",
       "              0.036441523809792264,\n",
       "              0.04058929283100371,\n",
       "              0.04574190063218142,\n",
       "              0.03180398213618996,\n",
       "              0.04693901633153963,\n",
       "              0.024952493414098054,\n",
       "              0.024985819869617343,\n",
       "              0.033829551476610376,\n",
       "              0.045663397599616296,\n",
       "              0.034811427612535195,\n",
       "              0.049627535890291896,\n",
       "              0.047739831114597564,\n",
       "              0.04050095348806615,\n",
       "              0.03461750220557103,\n",
       "              0.03584333234360737,\n",
       "              0.04755802640381113,\n",
       "              0.0429860856235863],\n",
       "             'entire_dataset_label_0.0_mia_result': [MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.09570788, 0.09788597, 0.09967969, 0.10237028,\n",
       "                     0.10928892, 0.11082639, 0.11159513, 0.11326073, 0.11492633,\n",
       "                     0.12261371, 0.13670724, 0.14183216, 0.14272902, 0.14606022,\n",
       "                     0.16194747, 0.16412556, 0.17578475, 0.19231262, 0.19897502,\n",
       "                     0.20076874, 0.20397181, 0.20717489, 0.2206278 , 0.22575272,\n",
       "                     0.23126201, 0.23484946, 0.24945548, 0.25253043, 0.2557335 ,\n",
       "                     0.26265215, 0.28161435, 0.28353619, 0.28712364, 0.32722614,\n",
       "                     0.33004484, 0.33452915, 0.33798847, 0.34272902, 0.34746957,\n",
       "                     0.36502242, 0.38936579, 0.39769379, 0.40422806, 0.40819987,\n",
       "                     0.41229981, 0.4256246 , 0.44561179, 0.4495836 , 0.46303652,\n",
       "                     0.4685458 , 0.48097373, 0.49404228, 0.50352338, 0.5136451 ,\n",
       "                     0.51761691, 0.53030109, 0.53196669, 0.54785394, 0.55169763,\n",
       "                     0.56566304, 0.59154388, 0.59743754, 0.60230621, 0.60384369,\n",
       "                     0.61089045, 0.61588725, 0.61960282, 0.63946188, 0.64983985,\n",
       "                     0.66508648, 0.68122998, 0.68750801, 0.69224856, 0.695836  ,\n",
       "                     0.69942345, 0.70429212, 0.72222934, 0.73183857, 0.73324792,\n",
       "                     0.73670724, 0.74388213, 0.75323511, 0.76412556, 0.76784113,\n",
       "                     0.7682255 , 0.77335042, 0.77501602, 0.77629725, 0.7938501 ,\n",
       "                     0.79474696, 0.79743754, 0.80281871, 0.81229981, 0.81268418,\n",
       "                     0.81639974, 0.81819347, 0.81909033, 0.82536835, 0.82639334,\n",
       "                     0.84368994, 0.84586803, 0.85099295, 0.85522101, 0.86085842,\n",
       "                     0.86828956, 0.87443946, 0.88571429, 0.88750801, 0.89237668,\n",
       "                     0.89634849, 0.9008328 , 0.90237028, 0.90544523, 0.90608584,\n",
       "                     0.91005766, 0.92453555, 0.928123  , 0.93209481, 0.9326073 ,\n",
       "                     0.93414478, 0.94106342, 0.94388213, 0.95426009, 0.9554132 ,\n",
       "                     0.96015375, 0.9615631 , 0.9648943 , 0.96591928, 0.96707239,\n",
       "                     0.97014734, 0.97258168, 0.97629725, 0.97834721, 0.97962844,\n",
       "                     0.98539398, 0.98641896, 0.9871877 , 0.98731582, 0.98923767,\n",
       "                     0.98975016, 0.98987828, 0.99064702, 1.        ]), tpr=array([0.        , 0.10627958, 0.10934902, 0.11229057, 0.11510423,\n",
       "                     0.12290574, 0.12495204, 0.12674255, 0.12814938, 0.13083515,\n",
       "                     0.14004348, 0.15411178, 0.16050646, 0.16255276, 0.16447116,\n",
       "                     0.18148101, 0.1876199 , 0.20066505, 0.21498913, 0.22176749,\n",
       "                     0.22458115, 0.22726691, 0.23110372, 0.24402097, 0.25015987,\n",
       "                     0.25476404, 0.25770559, 0.27522701, 0.28034275, 0.28405167,\n",
       "                     0.29326001, 0.31385088, 0.31564139, 0.31871083, 0.35950889,\n",
       "                     0.36488042, 0.37063563, 0.37536769, 0.38086712, 0.38751759,\n",
       "                     0.40363218, 0.42729249, 0.43624504, 0.44212815, 0.44762757,\n",
       "                     0.45197596, 0.46425374, 0.48369357, 0.48740248, 0.50019184,\n",
       "                     0.50479601, 0.5188643 , 0.53178156, 0.54047832, 0.55134928,\n",
       "                     0.55441872, 0.56541757, 0.56874281, 0.58754316, 0.59163576,\n",
       "                     0.60340197, 0.63320118, 0.63806113, 0.64432792, 0.64688579,\n",
       "                     0.65481519, 0.66108198, 0.66402353, 0.68244021, 0.69152065,\n",
       "                     0.70891418, 0.72490088, 0.73193503, 0.73820182, 0.74344545,\n",
       "                     0.74779384, 0.75354905, 0.77030311, 0.77580253, 0.7783604 ,\n",
       "                     0.78181353, 0.78820821, 0.79549815, 0.80777593, 0.81161274,\n",
       "                     0.81250799, 0.81583323, 0.81736795, 0.81864689, 0.83540095,\n",
       "                     0.8364241 , 0.83885407, 0.84269088, 0.85151554, 0.85305026,\n",
       "                     0.85714286, 0.86008441, 0.86136335, 0.86788592, 0.86878117,\n",
       "                     0.88463998, 0.88655838, 0.89065098, 0.89487147, 0.8981967 ,\n",
       "                     0.90395191, 0.91149763, 0.92083387, 0.92288016, 0.92710065,\n",
       "                     0.93170482, 0.93503005, 0.93592531, 0.93797161, 0.93925054,\n",
       "                     0.94283156, 0.95357463, 0.95587671, 0.95894616, 0.96035299,\n",
       "                     0.96150403, 0.96559662, 0.96841028, 0.97544443, 0.97621179,\n",
       "                     0.97992071, 0.98119964, 0.98273437, 0.98362962, 0.98439698,\n",
       "                     0.98657117, 0.98848958, 0.99155902, 0.99309375, 0.99373321,\n",
       "                     0.99705845, 0.99757002, 0.99833738, 0.99859317, 0.99948843,\n",
       "                     0.99961632, 0.99987211, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.08219945e-02, -4.25596144e-02,\n",
       "                     -4.44517626e-02, -4.80092192e-02, -6.06246218e-02, -6.89928715e-02,\n",
       "                     -8.70113770e-02, -9.09717782e-02, -1.05360516e-01, -1.11703990e-01,\n",
       "                     -1.13328685e-01, -1.17783036e-01, -1.25163143e-01, -1.33531393e-01,\n",
       "                     -1.36132174e-01, -1.54150680e-01, -1.56698452e-01, -1.56842471e-01,\n",
       "                     -1.67054085e-01, -1.74353387e-01, -1.82321557e-01, -1.88900528e-01,\n",
       "                     -1.89242000e-01, -2.23143551e-01, -2.31801614e-01, -2.33310669e-01,\n",
       "                     -2.42946179e-01, -2.43622083e-01, -2.45122458e-01, -2.46471804e-01,\n",
       "                     -2.51314428e-01, -2.55933374e-01, -2.65494157e-01, -2.69663567e-01,\n",
       "                     -2.70874954e-01, -2.80902385e-01, -2.81851152e-01, -2.82862786e-01,\n",
       "                     -2.87682072e-01, -2.93072921e-01, -2.94799540e-01, -2.98492989e-01,\n",
       "                     -2.99242895e-01, -3.02280872e-01, -3.03186259e-01, -3.08838272e-01,\n",
       "                     -3.21583624e-01, -3.22083499e-01, -3.28504067e-01, -3.29957556e-01,\n",
       "                     -3.33639374e-01, -3.34369186e-01, -3.36472237e-01, -3.48306694e-01,\n",
       "                     -3.49673748e-01, -3.52821375e-01, -3.56674944e-01, -3.62905494e-01,\n",
       "                     -3.68560551e-01, -3.69044477e-01, -3.69747026e-01, -3.70859579e-01,\n",
       "                     -3.71563556e-01, -3.83725121e-01, -3.84845821e-01, -3.90866309e-01,\n",
       "                     -3.91478866e-01, -4.00759217e-01, -4.05465108e-01, -4.08128226e-01,\n",
       "                     -4.11507423e-01, -4.12244795e-01, -4.13562318e-01, -4.24883194e-01,\n",
       "                     -4.27444015e-01, -4.28107585e-01, -4.28454626e-01, -4.38254931e-01,\n",
       "                     -4.41832752e-01, -4.44685821e-01, -4.45585102e-01, -4.46287103e-01,\n",
       "                     -4.48950220e-01, -4.51985124e-01, -4.55475529e-01, -4.59532329e-01,\n",
       "                     -4.70003629e-01, -4.81388951e-01, -4.85507816e-01, -4.89548225e-01,\n",
       "                     -4.90622916e-01, -5.02091944e-01, -5.10825624e-01, -5.23248144e-01,\n",
       "                     -5.28067430e-01, -5.30628251e-01, -5.34082486e-01, -5.38996501e-01,\n",
       "                     -5.45694449e-01, -5.50046337e-01, -5.59615788e-01, -5.63935449e-01,\n",
       "                     -5.70544858e-01, -5.75364145e-01, -5.76422906e-01, -5.92342481e-01,\n",
       "                     -5.94707108e-01, -5.97837001e-01, -6.06135804e-01, -6.13104473e-01,\n",
       "                     -6.19039208e-01, -6.28608659e-01, -6.41853886e-01, -6.75128675e-01,\n",
       "                     -6.93147181e-01, -7.20546155e-01, -7.33969175e-01, -7.37598943e-01,\n",
       "                     -7.47214402e-01, -7.53771802e-01, -7.59105148e-01, -7.63351439e-01,\n",
       "                     -7.73189888e-01, -7.75838896e-01, -7.88457360e-01, -8.10930216e-01,\n",
       "                     -8.26678573e-01, -8.47297860e-01, -8.55666110e-01, -8.75468737e-01,\n",
       "                     -9.16290732e-01, -9.80829253e-01, -1.02961942e+00, -1.09861229e+00,\n",
       "                     -1.17865500e+00, -1.20397280e+00, -1.25276297e+00, -1.38629436e+00,\n",
       "                     -1.60943791e+00, -1.70474809e+00, -2.48490665e+00, -3.45387764e+01]), auc_score=0.5314090932590082, privacy_risk=0.5246284633785587, accuracy=0.5248335893497184, tpr_ind=0.7535490471927356, tnr_ind=0.2957078795643818, test_train_ratio=0.9982094897045658, dataset_size=[7819, 7805]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.09050064, 0.09306804, 0.0970475 , 0.11168164,\n",
       "                     0.11412067, 0.11899872, 0.12207959, 0.12580231, 0.12913992,\n",
       "                     0.13183569, 0.13260591, 0.13658537, 0.14223363, 0.1563543 ,\n",
       "                     0.15905006, 0.16264442, 0.16534018, 0.1677792 , 0.17175866,\n",
       "                     0.18331194, 0.18523748, 0.19062901, 0.19319641, 0.19589217,\n",
       "                     0.23016688, 0.23761232, 0.24287548, 0.24518614, 0.25044929,\n",
       "                     0.25430039, 0.25725289, 0.2605905 , 0.27073171, 0.27291399,\n",
       "                     0.29101412, 0.29255456, 0.29602054, 0.29717587, 0.3029525 ,\n",
       "                     0.31219512, 0.31810013, 0.321181  , 0.33697047, 0.34107831,\n",
       "                     0.35044929, 0.35365854, 0.3563543 , 0.35789474, 0.36970475,\n",
       "                     0.38408216, 0.38818999, 0.39435173, 0.3987163 , 0.41091142,\n",
       "                     0.41501926, 0.44685494, 0.45224647, 0.4758665 , 0.49255456,\n",
       "                     0.49987163, 0.50308087, 0.50680359, 0.50744544, 0.52156611,\n",
       "                     0.54210526, 0.54351733, 0.55327343, 0.56585366, 0.5732991 ,\n",
       "                     0.57843389, 0.58831836, 0.62978177, 0.63658537, 0.64582798,\n",
       "                     0.64685494, 0.64967908, 0.65815148, 0.66752246, 0.68279846,\n",
       "                     0.70808729, 0.72105263, 0.73055199, 0.73311938, 0.7381258 ,\n",
       "                     0.74159178, 0.74351733, 0.7465982 , 0.74801027, 0.75186136,\n",
       "                     0.76996149, 0.7716303 , 0.77727856, 0.7801027 , 0.78549422,\n",
       "                     0.79011553, 0.81450578, 0.8182285 , 0.82747112, 0.8309371 ,\n",
       "                     0.84030809, 0.84377407, 0.84454429, 0.85417202, 0.87252888,\n",
       "                     0.88267009, 0.88934531, 0.89383825, 0.90115533, 0.90192555,\n",
       "                     0.90372272, 0.91373556, 0.91848524, 0.91976893, 0.92349166,\n",
       "                     0.92605905, 0.92991014, 0.93478819, 0.95160462, 0.95263158,\n",
       "                     0.95404365, 0.95481386, 0.95571245, 0.95712452, 0.95853659,\n",
       "                     0.96020539, 0.96213094, 0.96431322, 0.96867779, 0.97368421,\n",
       "                     0.97637997, 0.97830552, 0.98215661, 0.98292683, 0.98408216,\n",
       "                     0.98562259, 0.98844673, 0.98870347, 0.98921694, 0.98985879,\n",
       "                     0.99268293, 0.99319641, 0.99332478, 1.        ]), tpr=array([0.        , 0.10582078, 0.10977789, 0.11284146, 0.12675517,\n",
       "                     0.12930814, 0.1339035 , 0.13594588, 0.13990299, 0.14373245,\n",
       "                     0.14743426, 0.14922134, 0.15343375, 0.15866735, 0.17564463,\n",
       "                     0.17768701, 0.18126117, 0.18381414, 0.18713301, 0.18955834,\n",
       "                     0.20385499, 0.20615267, 0.21036508, 0.2130457 , 0.21623692,\n",
       "                     0.25082972, 0.25836099, 0.26384989, 0.26627521, 0.27048762,\n",
       "                     0.27393413, 0.27827419, 0.28184835, 0.29410263, 0.29652796,\n",
       "                     0.32218535, 0.32358948, 0.32729129, 0.32958897, 0.33507787,\n",
       "                     0.34311973, 0.35103395, 0.35345928, 0.36826653, 0.37260659,\n",
       "                     0.3810314 , 0.38396732, 0.3865203 , 0.38830738, 0.3964769 ,\n",
       "                     0.41051825, 0.4153689 , 0.42124075, 0.42775083, 0.43987746,\n",
       "                     0.44421751, 0.47715088, 0.48340567, 0.50804187, 0.52527444,\n",
       "                     0.53255042, 0.53663518, 0.53944345, 0.54097524, 0.55488895,\n",
       "                     0.5739086 , 0.57722747, 0.58322696, 0.59726832, 0.6035231 ,\n",
       "                     0.60977789, 0.61769211, 0.66160327, 0.66862395, 0.68151647,\n",
       "                     0.6831759 , 0.68534593, 0.69389839, 0.70245086, 0.71598162,\n",
       "                     0.73883074, 0.75019147, 0.75963748, 0.76104161, 0.76589226,\n",
       "                     0.76933878, 0.77138116, 0.77584886, 0.77827419, 0.78133776,\n",
       "                     0.79920858, 0.80150625, 0.80725045, 0.81044166, 0.81541996,\n",
       "                     0.81950472, 0.84209854, 0.84490682, 0.85320398, 0.8561399 ,\n",
       "                     0.8663518 , 0.86979832, 0.8715854 , 0.88064846, 0.89724279,\n",
       "                     0.90541231, 0.91179474, 0.91524126, 0.91881542, 0.92009191,\n",
       "                     0.92213429, 0.93477151, 0.93936686, 0.94038805, 0.94562165,\n",
       "                     0.94728108, 0.9507276 , 0.95404646, 0.96949196, 0.97076845,\n",
       "                     0.97191728, 0.97293847, 0.97383201, 0.9753638 , 0.97651264,\n",
       "                     0.97855502, 0.9798315 , 0.98136329, 0.98302272, 0.9848098 ,\n",
       "                     0.98710748, 0.98825632, 0.99234108, 0.99336227, 0.99451111,\n",
       "                     0.9955323 , 0.99706408, 0.99770232, 0.99821292, 0.99872351,\n",
       "                     0.99961705, 0.99987235, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.17486983e-02, -4.08219945e-02,\n",
       "                     -4.48505662e-02, -4.87901642e-02, -5.40672213e-02, -6.06246218e-02,\n",
       "                     -6.25203570e-02, -6.45385211e-02, -6.66913745e-02, -6.89928715e-02,\n",
       "                     -8.70113770e-02, -9.30904231e-02, -1.00083459e-01, -1.17783036e-01,\n",
       "                     -1.33531393e-01, -1.39761942e-01, -1.43100844e-01, -1.46603474e-01,\n",
       "                     -1.49035579e-01, -1.54150680e-01, -1.67054085e-01, -1.74353387e-01,\n",
       "                     -1.82321557e-01, -1.84778560e-01, -1.85142433e-01, -1.90043603e-01,\n",
       "                     -1.91055237e-01, -1.92371893e-01, -2.00670695e-01, -2.11309094e-01,\n",
       "                     -2.23143551e-01, -2.31442354e-01, -2.33614851e-01, -2.34029359e-01,\n",
       "                     -2.41162057e-01, -2.43622083e-01, -2.45122458e-01, -2.46133070e-01,\n",
       "                     -2.51314428e-01, -2.54892250e-01, -2.74436846e-01, -2.76847730e-01,\n",
       "                     -2.80301965e-01, -2.87682072e-01, -2.98492989e-01, -3.00104592e-01,\n",
       "                     -3.05381650e-01, -3.07025035e-01, -3.10154928e-01, -3.13657559e-01,\n",
       "                     -3.14493330e-01, -3.16669609e-01, -3.21320432e-01, -3.23787077e-01,\n",
       "                     -3.27573401e-01, -3.27687407e-01, -3.28296792e-01, -3.36472237e-01,\n",
       "                     -3.38975367e-01, -3.40926587e-01, -3.42944751e-01, -3.48306694e-01,\n",
       "                     -3.52077235e-01, -3.52639969e-01, -3.52821375e-01, -3.54545018e-01,\n",
       "                     -3.55765440e-01, -3.56674944e-01, -3.70859579e-01, -3.72675285e-01,\n",
       "                     -3.73966441e-01, -3.74693449e-01, -3.75312070e-01, -3.79489622e-01,\n",
       "                     -3.85662481e-01, -3.90427231e-01, -4.00477567e-01, -4.05465108e-01,\n",
       "                     -4.25742301e-01, -4.31344556e-01, -4.32133355e-01, -4.35318071e-01,\n",
       "                     -4.39951284e-01, -4.41832752e-01, -4.46287103e-01, -4.51985124e-01,\n",
       "                     -4.56758402e-01, -4.59532329e-01, -4.70003629e-01, -4.76924072e-01,\n",
       "                     -4.83796951e-01, -4.94696242e-01, -4.95321437e-01, -5.04556011e-01,\n",
       "                     -5.10825624e-01, -5.19875459e-01, -5.26093096e-01, -5.28067430e-01,\n",
       "                     -5.30628251e-01, -5.32804530e-01, -5.38996501e-01, -5.49504478e-01,\n",
       "                     -5.57415567e-01, -5.59615788e-01, -5.65313809e-01, -5.75364145e-01,\n",
       "                     -5.79818495e-01, -5.87786665e-01, -5.94707108e-01, -5.97837001e-01,\n",
       "                     -6.06135804e-01, -6.28608659e-01, -6.43136760e-01, -6.53926467e-01,\n",
       "                     -6.55406853e-01, -6.73729095e-01, -6.93147181e-01, -7.41937345e-01,\n",
       "                     -7.47214402e-01, -7.53771802e-01, -7.62140052e-01, -7.73189888e-01,\n",
       "                     -7.98507696e-01, -8.10930216e-01, -8.32909123e-01, -8.47297860e-01,\n",
       "                     -8.69037847e-01, -8.87303195e-01, -9.16290732e-01, -9.38269639e-01,\n",
       "                     -9.40983344e-01, -9.65080896e-01, -9.80829253e-01, -1.01160091e+00,\n",
       "                     -1.09861229e+00, -1.16315081e+00, -1.17865500e+00, -1.25276297e+00,\n",
       "                     -1.38629436e+00, -1.60943791e+00, -2.07944154e+00, -3.45387764e+01]), auc_score=0.5244885776525288, privacy_risk=0.5181604788448889, accuracy=0.5186251920122887, tpr_ind=0.6831758999234108, tnr_ind=0.3531450577663671, test_train_ratio=0.9943834567270871, dataset_size=[7834, 7790]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.10558688, 0.11263455, 0.11481292, 0.11699129,\n",
       "                     0.12045105, 0.1228857 , 0.127755  , 0.13057406, 0.13352127,\n",
       "                     0.1453101 , 0.14607893, 0.14684777, 0.14812916, 0.15107637,\n",
       "                     0.15171707, 0.15914915, 0.16555613, 0.16888775, 0.17593542,\n",
       "                     0.18618657, 0.19605331, 0.19900051, 0.20335725, 0.20617632,\n",
       "                     0.21181445, 0.23065095, 0.23372629, 0.23898001, 0.24243977,\n",
       "                     0.24615582, 0.25140953, 0.25563813, 0.25999487, 0.26665812,\n",
       "                     0.27678114, 0.29677089, 0.30215274, 0.30881599, 0.31201948,\n",
       "                     0.31227576, 0.31330087, 0.32214249, 0.35699641, 0.37198872,\n",
       "                     0.37378268, 0.37878011, 0.38595592, 0.39197847, 0.39607893,\n",
       "                     0.41017427, 0.42119426, 0.42760123, 0.43298309, 0.43388006,\n",
       "                     0.43426448, 0.43772424, 0.4388775 , 0.44297796, 0.44515633,\n",
       "                     0.44951307, 0.45540748, 0.46078934, 0.46591492, 0.46822142,\n",
       "                     0.51230138, 0.51371092, 0.52088672, 0.52383393, 0.52780625,\n",
       "                     0.53587904, 0.54062019, 0.57098924, 0.579959  , 0.58726294,\n",
       "                     0.59161968, 0.59379805, 0.59700154, 0.60276781, 0.60674013,\n",
       "                     0.61045618, 0.61814454, 0.6355715 , 0.66081497, 0.66465915,\n",
       "                     0.66940031, 0.68810866, 0.6895182 , 0.6937468 , 0.69682214,\n",
       "                     0.71309585, 0.71604305, 0.72552537, 0.7282163 , 0.73616094,\n",
       "                     0.73808303, 0.74372117, 0.75602255, 0.75820092, 0.76012301,\n",
       "                     0.76204511, 0.76960533, 0.77191184, 0.78203485, 0.79164531,\n",
       "                     0.83277806, 0.83969759, 0.84443875, 0.84725782, 0.84969247,\n",
       "                     0.85404921, 0.85686827, 0.85840595, 0.85994362, 0.86494106,\n",
       "                     0.86724757, 0.87365454, 0.88749359, 0.898898  , 0.90274218,\n",
       "                     0.90479241, 0.90517683, 0.91542799, 0.91722194, 0.92183496,\n",
       "                     0.92644798, 0.93029216, 0.94387494, 0.94964121, 0.9515633 ,\n",
       "                     0.95412609, 0.95656074, 0.95694516, 0.96245515, 0.96642747,\n",
       "                     0.96899026, 0.97142491, 0.97232189, 0.97321886, 0.97437212,\n",
       "                     0.97706304, 0.98116351, 0.98231676, 0.98321374, 0.98552025,\n",
       "                     0.98616094, 0.9866735 , 0.98949257, 0.98962071, 0.99077396,\n",
       "                     0.99103024, 1.        ]), tpr=array([0.        , 0.10741688, 0.11445013, 0.11726343, 0.11969309,\n",
       "                     0.12442455, 0.12672634, 0.13439898, 0.13772379, 0.14079284,\n",
       "                     0.1528133 , 0.15421995, 0.15549872, 0.15780051, 0.16086957,\n",
       "                     0.16278772, 0.17391304, 0.17838875, 0.1826087 , 0.18734015,\n",
       "                     0.19961637, 0.20997442, 0.2129156 , 0.21713555, 0.21982097,\n",
       "                     0.22378517, 0.24424552, 0.24795396, 0.25345269, 0.25831202,\n",
       "                     0.26636829, 0.27199488, 0.27634271, 0.28107417, 0.2887468 ,\n",
       "                     0.29820972, 0.31969309, 0.32404092, 0.3297954 , 0.33503836,\n",
       "                     0.33644501, 0.33734015, 0.34258312, 0.37595908, 0.39219949,\n",
       "                     0.39347826, 0.39936061, 0.40511509, 0.41035806, 0.41662404,\n",
       "                     0.43196931, 0.4455243 , 0.45038363, 0.45626598, 0.45805627,\n",
       "                     0.45946292, 0.46189258, 0.46496164, 0.46867008, 0.4713555 ,\n",
       "                     0.47570332, 0.48094629, 0.48861893, 0.49398977, 0.49680307,\n",
       "                     0.54092072, 0.54245524, 0.54795396, 0.55191816, 0.55524297,\n",
       "                     0.5657289 , 0.57109974, 0.60524297, 0.61355499, 0.61905371,\n",
       "                     0.62480818, 0.62736573, 0.63069054, 0.63836317, 0.64296675,\n",
       "                     0.64539642, 0.65332481, 0.67352941, 0.69322251, 0.69693095,\n",
       "                     0.70255754, 0.71982097, 0.72122762, 0.72378517, 0.72608696,\n",
       "                     0.73951407, 0.74194373, 0.7511509 , 0.75485934, 0.76329923,\n",
       "                     0.76521739, 0.77071611, 0.7842711 , 0.7859335 , 0.78695652,\n",
       "                     0.78938619, 0.79641944, 0.79961637, 0.81265985, 0.82289003,\n",
       "                     0.86265985, 0.86969309, 0.87429668, 0.87710997, 0.87953964,\n",
       "                     0.88401535, 0.88772379, 0.88938619, 0.89066496, 0.89603581,\n",
       "                     0.8983376 , 0.90549872, 0.9202046 , 0.93209719, 0.93478261,\n",
       "                     0.93682864, 0.93759591, 0.94526854, 0.94744246, 0.95179028,\n",
       "                     0.95473146, 0.95652174, 0.96713555, 0.97161125, 0.97378517,\n",
       "                     0.9758312 , 0.97851662, 0.97928389, 0.98324808, 0.98580563,\n",
       "                     0.98785166, 0.98976982, 0.99117647, 0.99181586, 0.992711  ,\n",
       "                     0.99450128, 0.99590793, 0.99654731, 0.99757033, 0.9983376 ,\n",
       "                     0.99859335, 0.99897698, 0.99961637, 0.99974425, 0.99987212,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.80185055e-02, -4.44517626e-02,\n",
       "                     -5.12932944e-02, -5.26437335e-02, -5.40672213e-02, -6.45385211e-02,\n",
       "                     -7.41079722e-02, -8.00427077e-02, -8.16780310e-02, -8.70113770e-02,\n",
       "                     -9.53101798e-02, -1.05360516e-01, -1.17783036e-01, -1.25163143e-01,\n",
       "                     -1.29211731e-01, -1.33531393e-01, -1.41078598e-01, -1.50282203e-01,\n",
       "                     -1.54150680e-01, -1.59427737e-01, -1.60342650e-01, -1.67054085e-01,\n",
       "                     -1.74353387e-01, -1.76930708e-01, -1.82321557e-01, -1.88052232e-01,\n",
       "                     -1.90043603e-01, -1.91055237e-01, -2.00670695e-01, -2.04794413e-01,\n",
       "                     -2.11309094e-01, -2.17723484e-01, -2.23143551e-01, -2.28534400e-01,\n",
       "                     -2.32622295e-01, -2.34839591e-01, -2.36388778e-01, -2.37671652e-01,\n",
       "                     -2.41162057e-01, -2.51314428e-01, -2.56719847e-01, -2.58525488e-01,\n",
       "                     -2.61758387e-01, -2.62364264e-01, -2.65703166e-01, -2.70874954e-01,\n",
       "                     -2.75411980e-01, -2.82566972e-01, -2.87682072e-01, -2.92387963e-01,\n",
       "                     -2.94239473e-01, -2.98492989e-01, -3.05381650e-01, -3.10154928e-01,\n",
       "                     -3.13657559e-01, -3.18453731e-01, -3.21583624e-01, -3.22773392e-01,\n",
       "                     -3.23787077e-01, -3.29479201e-01, -3.36472237e-01, -3.39867826e-01,\n",
       "                     -3.42944751e-01, -3.46770989e-01, -3.48306694e-01, -3.49673748e-01,\n",
       "                     -3.50202429e-01, -3.52821375e-01, -3.55454688e-01, -3.56674944e-01,\n",
       "                     -3.58171950e-01, -3.58212223e-01, -3.65934269e-01, -3.67724780e-01,\n",
       "                     -3.71563556e-01, -3.79489622e-01, -3.82992252e-01, -3.86772975e-01,\n",
       "                     -3.87765531e-01, -3.94654192e-01, -4.05465108e-01, -4.09784769e-01,\n",
       "                     -4.16893804e-01, -4.20502985e-01, -4.32263301e-01, -4.35318071e-01,\n",
       "                     -4.38254931e-01, -4.41832752e-01, -4.51985124e-01, -4.56758402e-01,\n",
       "                     -4.59532329e-01, -4.61345567e-01, -4.64305608e-01, -4.70003629e-01,\n",
       "                     -4.72906389e-01, -4.78224462e-01, -4.79573080e-01, -4.85507816e-01,\n",
       "                     -4.89548225e-01, -4.92476485e-01, -4.94696242e-01, -4.98991166e-01,\n",
       "                     -5.00775288e-01, -5.02430353e-01, -5.03526321e-01, -5.10825624e-01,\n",
       "                     -5.19875459e-01, -5.21296924e-01, -5.22189382e-01, -5.24524468e-01,\n",
       "                     -5.26093096e-01, -5.30628251e-01, -5.38996501e-01, -5.43615447e-01,\n",
       "                     -5.59615788e-01, -5.87786665e-01, -5.91364486e-01, -5.93063722e-01,\n",
       "                     -5.94707108e-01, -6.06135804e-01, -6.24154309e-01, -6.32522559e-01,\n",
       "                     -6.48026745e-01, -6.48695418e-01, -6.56779536e-01, -6.93147181e-01,\n",
       "                     -7.48717032e-01, -7.50305594e-01, -7.53771802e-01, -7.62140052e-01,\n",
       "                     -7.73189888e-01, -7.85520501e-01, -7.88457360e-01, -8.10930216e-01,\n",
       "                     -8.47297860e-01, -8.60201265e-01, -8.75468737e-01, -8.87303195e-01,\n",
       "                     -9.16290732e-01, -1.09861229e+00, -1.16315081e+00, -1.17865500e+00,\n",
       "                     -1.25276297e+00, -1.38629436e+00, -1.46633707e+00, -1.60943791e+00,\n",
       "                     -1.79175947e+00, -2.19722458e+00, -2.48490665e+00, -3.45387764e+01]), auc_score=0.521979465576706, privacy_risk=0.518978954985377, accuracy=0.5191372247823861, tpr_ind=0.6735294117647059, tnr_ind=0.36442849820604817, test_train_ratio=0.9979539641943734, dataset_size=[7820, 7804]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.07781054, 0.09780797, 0.10165363, 0.10716575,\n",
       "                     0.10844763, 0.11306243, 0.12665043, 0.13216254, 0.13318805,\n",
       "                     0.13408537, 0.14075119, 0.14549417, 0.14805794, 0.15036534,\n",
       "                     0.15767209, 0.16126138, 0.16446609, 0.17356749, 0.17907961,\n",
       "                     0.17959236, 0.18202795, 0.19253942, 0.1938213 , 0.1972824 ,\n",
       "                     0.19766697, 0.20984489, 0.21048584, 0.21240867, 0.21868991,\n",
       "                     0.22804769, 0.25676195, 0.2607358 , 0.26509422, 0.27701577,\n",
       "                     0.29432124, 0.30034611, 0.31213947, 0.32495834, 0.33316242,\n",
       "                     0.33418792, 0.33777721, 0.34431483, 0.3514934 , 0.35636457,\n",
       "                     0.35777464, 0.37161902, 0.37482374, 0.38648891, 0.41340854,\n",
       "                     0.41827971, 0.42507371, 0.45045507, 0.45955647, 0.46301756,\n",
       "                     0.46968337, 0.47981028, 0.48442507, 0.48724522, 0.49250096,\n",
       "                     0.50160236, 0.50980644, 0.51224202, 0.52390719, 0.53313678,\n",
       "                     0.54172542, 0.54441738, 0.5567235 , 0.56364569, 0.57505448,\n",
       "                     0.60056403, 0.63235483, 0.63402128, 0.64671196, 0.65927445,\n",
       "                     0.66247917, 0.67452891, 0.67747725, 0.67927189, 0.68183566,\n",
       "                     0.68465581, 0.69683374, 0.70503782, 0.71465197, 0.71529291,\n",
       "                     0.71875401, 0.72413793, 0.73785412, 0.74772465, 0.75157031,\n",
       "                     0.76156903, 0.77246507, 0.78246379, 0.791437  , 0.8027176 ,\n",
       "                     0.80707602, 0.83463659, 0.83873862, 0.84258428, 0.84425074,\n",
       "                     0.84540444, 0.84976285, 0.85232662, 0.85642866, 0.86424817,\n",
       "                     0.87117036, 0.87706704, 0.89180874, 0.89962825, 0.90065376,\n",
       "                     0.90437123, 0.90629406, 0.90860146, 0.91244712, 0.91513908,\n",
       "                     0.91770286, 0.91898475, 0.9218049 , 0.9239841 , 0.92847071,\n",
       "                     0.93077811, 0.93372645, 0.93693116, 0.94757082, 0.94923728,\n",
       "                     0.95359569, 0.9557749 , 0.95667222, 0.96333803, 0.96654275,\n",
       "                     0.96833739, 0.97077298, 0.97205486, 0.97423407, 0.97666966,\n",
       "                     0.9773106 , 0.98000256, 0.98230996, 0.98705294, 0.98795026,\n",
       "                     0.98833483, 0.9897449 , 0.99025766, 0.9908986 , 0.99102679,\n",
       "                     0.99179592, 0.99282143, 1.        ]), tpr=array([0.        , 0.08462227, 0.10763134, 0.11248882, 0.11964719,\n",
       "                     0.1219481 , 0.12808386, 0.14061102, 0.14725809, 0.14879202,\n",
       "                     0.14994248, 0.15607823, 0.15978525, 0.16246964, 0.16413141,\n",
       "                     0.17231241, 0.17550812, 0.17934296, 0.18905791, 0.194938  ,\n",
       "                     0.19634411, 0.19953982, 0.21091653, 0.21270612, 0.21679663,\n",
       "                     0.21794708, 0.22817334, 0.23098556, 0.23264732, 0.23699348,\n",
       "                     0.24773105, 0.27508628, 0.27930461, 0.28492906, 0.29899016,\n",
       "                     0.3195705 , 0.32557842, 0.33797776, 0.35165538, 0.3576633 ,\n",
       "                     0.3594529 , 0.36341557, 0.37019046, 0.38028889, 0.38489071,\n",
       "                     0.38731944, 0.4016362 , 0.40585453, 0.41608079, 0.44445865,\n",
       "                     0.45072223, 0.45992586, 0.47999489, 0.48651413, 0.4904768 ,\n",
       "                     0.49891346, 0.50786143, 0.51438067, 0.51642592, 0.52332865,\n",
       "                     0.53099834, 0.54071328, 0.54403681, 0.55835357, 0.5693468 ,\n",
       "                     0.57816694, 0.58021219, 0.59094976, 0.59900294, 0.61037965,\n",
       "                     0.63377221, 0.66163876, 0.66304487, 0.67391026, 0.68618177,\n",
       "                     0.68963313, 0.70369423, 0.70688994, 0.70957433, 0.71200307,\n",
       "                     0.71417615, 0.72516937, 0.73079381, 0.74153138, 0.74408795,\n",
       "                     0.74868976, 0.755209  , 0.76505177, 0.77463889, 0.7792407 ,\n",
       "                     0.79023393, 0.7991819 , 0.80582897, 0.81554391, 0.8241084 ,\n",
       "                     0.82845456, 0.85874984, 0.86411862, 0.86833696, 0.87102135,\n",
       "                     0.87153266, 0.87587882, 0.87754059, 0.88265371, 0.89019558,\n",
       "                     0.89377477, 0.90016618, 0.91461076, 0.92279177, 0.92432571,\n",
       "                     0.92752141, 0.92995015, 0.93161191, 0.93416848, 0.93851464,\n",
       "                     0.94030423, 0.94132686, 0.94349994, 0.94580084, 0.95078614,\n",
       "                     0.95270357, 0.95474882, 0.95717755, 0.96778729, 0.96957689,\n",
       "                     0.9741787 , 0.9759683 , 0.97724658, 0.98351016, 0.98517193,\n",
       "                     0.98734501, 0.98836763, 0.98926243, 0.99041289, 0.99169117,\n",
       "                     0.99220248, 0.99360859, 0.99475904, 0.99667647, 0.99757126,\n",
       "                     0.99782692, 0.99884955, 0.99923303, 0.99948869, 0.99974434,\n",
       "                     0.99987217, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.65293020e-02, -5.12932944e-02,\n",
       "                     -5.21857532e-02, -5.40672213e-02, -6.06246218e-02, -6.89928715e-02,\n",
       "                     -7.41079722e-02, -8.00427077e-02, -1.05360516e-01, -1.17783036e-01,\n",
       "                     -1.29211731e-01, -1.33531393e-01, -1.43100844e-01, -1.45182010e-01,\n",
       "                     -1.48420005e-01, -1.54150680e-01, -1.57903029e-01, -1.60342650e-01,\n",
       "                     -1.67054085e-01, -1.82321557e-01, -1.84192465e-01, -1.94156014e-01,\n",
       "                     -1.97825743e-01, -2.00670695e-01, -2.02940844e-01, -2.04794413e-01,\n",
       "                     -2.07639365e-01, -2.11309094e-01, -2.13574100e-01, -2.13753811e-01,\n",
       "                     -2.17064505e-01, -2.23143551e-01, -2.26773319e-01, -2.26863332e-01,\n",
       "                     -2.27389842e-01, -2.29310066e-01, -2.32445944e-01, -2.44196961e-01,\n",
       "                     -2.51314428e-01, -2.54892250e-01, -2.63814591e-01, -2.65281136e-01,\n",
       "                     -2.66628663e-01, -2.74436846e-01, -2.85447435e-01, -2.87682072e-01,\n",
       "                     -2.90802200e-01, -2.97766192e-01, -2.97834444e-01, -2.98044859e-01,\n",
       "                     -3.00340469e-01, -3.02280872e-01, -3.03682414e-01, -3.10154928e-01,\n",
       "                     -3.15852949e-01, -3.16669609e-01, -3.18453731e-01, -3.28504067e-01,\n",
       "                     -3.36472237e-01, -3.51397887e-01, -3.52821375e-01, -3.56674944e-01,\n",
       "                     -3.57837059e-01, -3.61013346e-01, -3.62905494e-01, -3.64973747e-01,\n",
       "                     -3.67724780e-01, -3.71176035e-01, -3.74010156e-01, -3.74406711e-01,\n",
       "                     -3.74693449e-01, -3.77630309e-01, -3.84411699e-01, -3.93042588e-01,\n",
       "                     -4.05465108e-01, -4.18710335e-01, -4.21213465e-01, -4.22856851e-01,\n",
       "                     -4.24883194e-01, -4.28454626e-01, -4.35318071e-01, -4.36717652e-01,\n",
       "                     -4.38254931e-01, -4.41832752e-01, -4.50201002e-01, -4.51985124e-01,\n",
       "                     -4.53196511e-01, -4.59532329e-01, -4.65633630e-01, -4.70003629e-01,\n",
       "                     -4.79573080e-01, -4.89548225e-01, -4.95787746e-01, -4.98991166e-01,\n",
       "                     -5.08290768e-01, -5.10825624e-01, -5.28844129e-01, -5.38996501e-01,\n",
       "                     -5.59615788e-01, -5.67984038e-01, -5.70544858e-01, -5.73800423e-01,\n",
       "                     -5.76422906e-01, -5.79818495e-01, -5.87786665e-01, -5.90732175e-01,\n",
       "                     -5.94707108e-01, -6.06135804e-01, -6.09765572e-01, -6.10909082e-01,\n",
       "                     -6.13104473e-01, -6.15185639e-01, -6.16774202e-01, -6.19039208e-01,\n",
       "                     -6.28608659e-01, -6.32522559e-01, -6.35988767e-01, -6.40503447e-01,\n",
       "                     -6.59245629e-01, -6.61398482e-01, -6.66478933e-01, -6.93147181e-01,\n",
       "                     -7.28238500e-01, -7.47214402e-01, -7.62140052e-01, -7.88457360e-01,\n",
       "                     -7.90310929e-01, -8.02346473e-01, -8.04372816e-01, -8.10930216e-01,\n",
       "                     -8.26678573e-01, -8.47297860e-01, -8.75468737e-01, -9.16290732e-01,\n",
       "                     -1.00330211e+00, -1.02165125e+00, -1.09861229e+00, -1.23214368e+00,\n",
       "                     -1.25276297e+00, -1.38629436e+00, -1.54044504e+00, -1.60943791e+00,\n",
       "                     -1.70474809e+00, -1.79175947e+00, -2.07944154e+00, -3.45387764e+01]), auc_score=0.5230642233221066, privacy_risk=0.5182207619048962, accuracy=0.518305171530978, tpr_ind=0.5781669436277643, tnr_ind=0.45827458018202794, test_train_ratio=0.9971877796241851, dataset_size=[7823, 7801]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.09514712, 0.1090307 , 0.11145077, 0.11399822,\n",
       "                     0.11934785, 0.12138581, 0.12316902, 0.13093873, 0.13412304,\n",
       "                     0.1347599 , 0.13947268, 0.14036428, 0.14647816, 0.15297414,\n",
       "                     0.15386575, 0.15896064, 0.16290918, 0.1669851 , 0.1752643 ,\n",
       "                     0.18507197, 0.18800153, 0.18953   , 0.19195007, 0.19628073,\n",
       "                     0.20774424, 0.21156541, 0.21678767, 0.22060884, 0.23194498,\n",
       "                     0.23653038, 0.24200739, 0.24468221, 0.24990447, 0.25448987,\n",
       "                     0.26467966, 0.27155776, 0.28314864, 0.29219208, 0.29766909,\n",
       "                     0.31868552, 0.32263406, 0.34250414, 0.35091071, 0.3619921 ,\n",
       "                     0.36555853, 0.37281875, 0.39103299, 0.39434467, 0.40071328,\n",
       "                     0.43370271, 0.44045345, 0.44656732, 0.47599032, 0.48668959,\n",
       "                     0.4935677 , 0.49853522, 0.51216406, 0.54973889, 0.55101261,\n",
       "                     0.55585276, 0.56413196, 0.56591517, 0.5869316 , 0.58909693,\n",
       "                     0.59189912, 0.6071838 , 0.60934913, 0.61851993, 0.62119475,\n",
       "                     0.62514329, 0.63558782, 0.65189148, 0.65584002, 0.66615718,\n",
       "                     0.668832  , 0.67379952, 0.68182397, 0.68717361, 0.69698128,\n",
       "                     0.70627945, 0.70793529, 0.72691377, 0.73022545, 0.74627436,\n",
       "                     0.75085976, 0.76487072, 0.76690867, 0.77531525, 0.7773532 ,\n",
       "                     0.7796459 , 0.7824481 , 0.78677875, 0.79009043, 0.79174627,\n",
       "                     0.79913387, 0.80091708, 0.80320978, 0.81008789, 0.81773023,\n",
       "                     0.82040504, 0.83008534, 0.84460578, 0.84689848, 0.84982805,\n",
       "                     0.85543243, 0.86180104, 0.86345688, 0.87848682, 0.88319959,\n",
       "                     0.88383645, 0.88918609, 0.89198828, 0.90205069, 0.90498026,\n",
       "                     0.90727296, 0.90994778, 0.91644377, 0.92064705, 0.93262005,\n",
       "                     0.93796969, 0.94370144, 0.94497516, 0.95134378, 0.95223538,\n",
       "                     0.95783977, 0.96204305, 0.96293466, 0.96853904, 0.97121386,\n",
       "                     0.97363393, 0.97452554, 0.97707298, 0.97936569, 0.98012992,\n",
       "                     0.98063941, 0.98382372, 0.98407846, 0.98611642, 0.98751751,\n",
       "                     0.98764489, 0.98917335, 0.99019233, 0.99197554, 0.9931219 ,\n",
       "                     0.99324927, 1.        ]), tpr=array([0.        , 0.10575068, 0.11887302, 0.12196063, 0.12479094,\n",
       "                     0.13019426, 0.13250997, 0.13443973, 0.1412582 , 0.14563232,\n",
       "                     0.14704747, 0.15296539, 0.15412325, 0.16415798, 0.17252026,\n",
       "                     0.17354947, 0.17946739, 0.1822977 , 0.18602856, 0.19310434,\n",
       "                     0.20481153, 0.20802779, 0.2103435 , 0.21330246, 0.21857713,\n",
       "                     0.23208542, 0.23697414, 0.24276341, 0.24662293, 0.25704361,\n",
       "                     0.26399074, 0.26926541, 0.27080921, 0.27621253, 0.2809726 ,\n",
       "                     0.29075003, 0.29936961, 0.31339251, 0.3232986 , 0.32857327,\n",
       "                     0.3526309 , 0.35687637, 0.37861829, 0.39032549, 0.40074617,\n",
       "                     0.40447704, 0.41322527, 0.43162228, 0.43483854, 0.43972726,\n",
       "                     0.46996012, 0.47472019, 0.48282516, 0.51331532, 0.52322141,\n",
       "                     0.52682362, 0.53171234, 0.54522064, 0.58342982, 0.58561688,\n",
       "                     0.58960504, 0.59771002, 0.59976843, 0.62266821, 0.62524122,\n",
       "                     0.62858613, 0.64556799, 0.64749775, 0.65611733, 0.65959089,\n",
       "                     0.66332175, 0.67309919, 0.6896951 , 0.69394056, 0.70513315,\n",
       "                     0.70809211, 0.71375273, 0.72160041, 0.72674643, 0.73678117,\n",
       "                     0.74540075, 0.7465586 , 0.76431236, 0.76701402, 0.77910717,\n",
       "                     0.78425318, 0.8018783 , 0.80355075, 0.80959732, 0.81204168,\n",
       "                     0.81422874, 0.81680175, 0.82104721, 0.82362022, 0.82580728,\n",
       "                     0.83159655, 0.83339766, 0.83571337, 0.84175994, 0.84935032,\n",
       "                     0.85192332, 0.85938505, 0.873022  , 0.87469446, 0.87752477,\n",
       "                     0.88215618, 0.8878168 , 0.88910331, 0.90467001, 0.91007333,\n",
       "                     0.91213174, 0.9163772 , 0.91946481, 0.9306574 , 0.93194391,\n",
       "                     0.93348771, 0.93516017, 0.93979159, 0.9423646 , 0.95278528,\n",
       "                     0.95857455, 0.96436382, 0.96526438, 0.9714396 , 0.97208285,\n",
       "                     0.97581371, 0.97890133, 0.97980188, 0.98404734, 0.9857198 ,\n",
       "                     0.9870063 , 0.98790686, 0.99009391, 0.99138042, 0.99228097,\n",
       "                     0.99292422, 0.99485398, 0.99549723, 0.99678374, 0.99729834,\n",
       "                     0.99768429, 0.99819889, 0.9987135 , 0.9994854 , 0.99987135,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.89875369e-02, -4.08219945e-02,\n",
       "                     -4.44517626e-02, -4.65200156e-02, -5.40672213e-02, -6.45385211e-02,\n",
       "                     -7.27593543e-02, -8.45573880e-02, -8.70113770e-02, -1.03184236e-01,\n",
       "                     -1.05360516e-01, -1.09199292e-01, -1.16072171e-01, -1.17783036e-01,\n",
       "                     -1.22602322e-01, -1.27833372e-01, -1.29211731e-01, -1.35801541e-01,\n",
       "                     -1.43100844e-01, -1.48420005e-01, -1.54150680e-01, -1.60342650e-01,\n",
       "                     -1.78248231e-01, -1.82321557e-01, -1.91055237e-01, -2.00670695e-01,\n",
       "                     -2.09720531e-01, -2.10721031e-01, -2.15708573e-01, -2.18253566e-01,\n",
       "                     -2.23143551e-01, -2.32622295e-01, -2.39229689e-01, -2.43977638e-01,\n",
       "                     -2.49654677e-01, -2.50294540e-01, -2.51314428e-01, -2.56719847e-01,\n",
       "                     -2.57829109e-01, -2.64692554e-01, -2.68263987e-01, -2.76632236e-01,\n",
       "                     -2.87682072e-01, -2.96265816e-01, -3.02280872e-01, -3.05013529e-01,\n",
       "                     -3.07484700e-01, -3.13657559e-01, -3.18066809e-01, -3.20907720e-01,\n",
       "                     -3.22773392e-01, -3.24953467e-01, -3.29023413e-01, -3.31357136e-01,\n",
       "                     -3.32705754e-01, -3.36472237e-01, -3.36953121e-01, -3.44840486e-01,\n",
       "                     -3.50202429e-01, -3.56674944e-01, -3.62905494e-01, -3.67292535e-01,\n",
       "                     -3.71563556e-01, -3.79489622e-01, -3.79888266e-01, -3.82992252e-01,\n",
       "                     -3.90427231e-01, -3.93042588e-01, -3.93904286e-01, -4.05465108e-01,\n",
       "                     -4.13187154e-01, -4.15515444e-01, -4.16893804e-01, -4.19853846e-01,\n",
       "                     -4.20502985e-01, -4.21725629e-01, -4.21994410e-01, -4.22414666e-01,\n",
       "                     -4.30036369e-01, -4.41832752e-01, -4.48024723e-01, -4.51985124e-01,\n",
       "                     -4.67340512e-01, -4.70003629e-01, -4.78181776e-01, -4.79573080e-01,\n",
       "                     -4.80585739e-01, -4.89548225e-01, -4.98991166e-01, -5.00775288e-01,\n",
       "                     -5.10825624e-01, -5.30628251e-01, -5.34082486e-01, -5.37142932e-01,\n",
       "                     -5.38996501e-01, -5.43615447e-01, -5.44301553e-01, -5.47435369e-01,\n",
       "                     -5.59615788e-01, -5.64529803e-01, -5.67669523e-01, -5.70544858e-01,\n",
       "                     -5.72519193e-01, -5.75364145e-01, -5.85258219e-01, -5.87786665e-01,\n",
       "                     -5.88704517e-01, -5.93063722e-01, -5.94707108e-01, -5.97837001e-01,\n",
       "                     -6.06135804e-01, -6.21688217e-01, -6.41853886e-01, -6.50587566e-01,\n",
       "                     -6.53926467e-01, -6.64976304e-01, -6.67829373e-01, -6.93147181e-01,\n",
       "                     -7.04197017e-01, -7.47214402e-01, -7.62140052e-01, -7.82759339e-01,\n",
       "                     -7.88457360e-01, -8.07091440e-01, -8.10930216e-01, -8.26678573e-01,\n",
       "                     -8.47297860e-01, -8.69037847e-01, -8.75468737e-01, -8.87303195e-01,\n",
       "                     -9.04456274e-01, -9.16290732e-01, -9.44461609e-01, -9.55511445e-01,\n",
       "                     -9.80829253e-01, -1.02961942e+00, -1.09861229e+00, -1.17865500e+00,\n",
       "                     -1.20397280e+00, -1.25276297e+00, -1.32175584e+00, -1.38629436e+00,\n",
       "                     -1.60943791e+00, -2.07944154e+00, -3.45387764e+01]), auc_score=0.5276933913697486, privacy_risk=0.5202946464155018, accuracy=0.5207373271889401, tpr_ind=0.43162228225910204, tnr_ind=0.6089670105719017, test_train_ratio=1.0100347356233115, dataset_size=[7773, 7851]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.10318374, 0.10420662, 0.10740315, 0.10791459,\n",
       "                     0.1127733 , 0.11494694, 0.12133998, 0.12338576, 0.1291395 ,\n",
       "                     0.13310318, 0.14103056, 0.14358778, 0.14691216, 0.14921366,\n",
       "                     0.15471167, 0.16890423, 0.17695947, 0.17990027, 0.18169032,\n",
       "                     0.18821123, 0.19959085, 0.20163662, 0.20393812, 0.25469889,\n",
       "                     0.25508247, 0.26006904, 0.2654392 , 0.27144866, 0.2742616 ,\n",
       "                     0.28551336, 0.29548651, 0.30226314, 0.3376806 , 0.34369007,\n",
       "                     0.35136172, 0.35813835, 0.36159059, 0.36760005, 0.3752717 ,\n",
       "                     0.40135533, 0.40800409, 0.41094489, 0.43587776, 0.43766782,\n",
       "                     0.44636236, 0.45096535, 0.48945148, 0.49098581, 0.49482163,\n",
       "                     0.49942463, 0.51144355, 0.51655798, 0.51860376, 0.52461322,\n",
       "                     0.5272983 , 0.53177343, 0.54903465, 0.55056898, 0.55287048,\n",
       "                     0.56309935, 0.56463368, 0.56680731, 0.57038742, 0.6142437 ,\n",
       "                     0.61756809, 0.6217875 , 0.6247283 , 0.63201637, 0.6459532 ,\n",
       "                     0.65822785, 0.66116865, 0.66398159, 0.67484976, 0.68482291,\n",
       "                     0.68917018, 0.69300601, 0.70374632, 0.7064314 , 0.70847718,\n",
       "                     0.71742744, 0.7204961 , 0.72241401, 0.72816775, 0.74453395,\n",
       "                     0.74555683, 0.75131057, 0.75693645, 0.76511955, 0.76869965,\n",
       "                     0.77176832, 0.77355837, 0.78736734, 0.79555044, 0.80168776,\n",
       "                     0.80347782, 0.80488429, 0.80987086, 0.81140519, 0.82240123,\n",
       "                     0.83020074, 0.83454801, 0.84452116, 0.86907045, 0.87047692,\n",
       "                     0.87444061, 0.87955504, 0.88045007, 0.88121724, 0.88965605,\n",
       "                     0.90103567, 0.90320931, 0.90346503, 0.9078123 , 0.90832374,\n",
       "                     0.9101138 , 0.91292674, 0.9166347 , 0.91752973, 0.93018796,\n",
       "                     0.93351234, 0.95345864, 0.95614372, 0.95985168, 0.96087457,\n",
       "                     0.96125815, 0.96228104, 0.96547756, 0.96790692, 0.96816264,\n",
       "                     0.97378852, 0.97672932, 0.97672932, 0.97928654, 0.98082087,\n",
       "                     0.98273878, 0.98363381, 0.98478455, 0.98516814, 0.9859353 ,\n",
       "                     0.98683033, 0.98772535, 0.98810894, 0.98836466, 0.98913182,\n",
       "                     1.        ]), tpr=array([0.        , 0.11431501, 0.11662181, 0.12046649, 0.12226067,\n",
       "                     0.1273869 , 0.12879662, 0.13430732, 0.13558888, 0.1393054 ,\n",
       "                     0.14289376, 0.15545303, 0.15763168, 0.16083558, 0.16391132,\n",
       "                     0.16749968, 0.18018711, 0.19249007, 0.19684737, 0.19953864,\n",
       "                     0.20594643, 0.2185057 , 0.22132513, 0.2240164 , 0.27604767,\n",
       "                     0.27758554, 0.282071  , 0.2887351 , 0.29770601, 0.30052544,\n",
       "                     0.31641676, 0.32782263, 0.33602461, 0.37152377, 0.37780341,\n",
       "                     0.38767141, 0.3940792 , 0.39830834, 0.40586954, 0.41202102,\n",
       "                     0.43662694, 0.44239395, 0.44418813, 0.46584647, 0.4686659 ,\n",
       "                     0.47725234, 0.48340382, 0.52287582, 0.52518262, 0.52813021,\n",
       "                     0.53235935, 0.54427784, 0.5487633 , 0.55158272, 0.5565808 ,\n",
       "                     0.5609381 , 0.56465462, 0.58105857, 0.58259644, 0.5850314 ,\n",
       "                     0.59643727, 0.59823145, 0.60028194, 0.60348584, 0.64859669,\n",
       "                     0.6509035 , 0.65462002, 0.65910547, 0.66576958, 0.68230168,\n",
       "                     0.69434833, 0.69652698, 0.69896194, 0.71177752, 0.72202999,\n",
       "                     0.72830962, 0.73202614, 0.74330386, 0.74663591, 0.74919903,\n",
       "                     0.75983596, 0.76329617, 0.76534666, 0.76983212, 0.7893118 ,\n",
       "                     0.78995258, 0.79559144, 0.79994874, 0.8102012 , 0.81404588,\n",
       "                     0.81699346, 0.81930027, 0.83147507, 0.83788287, 0.84236832,\n",
       "                     0.8453159 , 0.84659746, 0.85057029, 0.85146738, 0.86107907,\n",
       "                     0.86671793, 0.86979367, 0.88017429, 0.90196078, 0.90311419,\n",
       "                     0.90503652, 0.90849673, 0.90990645, 0.91067538, 0.91977445,\n",
       "                     0.92989876, 0.93169294, 0.93271819, 0.93592208, 0.93707548,\n",
       "                     0.93976676, 0.94130463, 0.94450852, 0.94617455, 0.9582212 ,\n",
       "                     0.96091247, 0.97372805, 0.97706011, 0.9814174 , 0.98218634,\n",
       "                     0.98269896, 0.98308343, 0.98487761, 0.98628733, 0.9869281 ,\n",
       "                     0.99051647, 0.99192618, 0.99256696, 0.99410483, 0.99500192,\n",
       "                     0.99641164, 0.99718057, 0.99794951, 0.99833397, 0.99871844,\n",
       "                     0.99935922, 0.99948738, 0.99961553, 0.99987184, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.40672213e-02, -6.45385211e-02,\n",
       "                     -6.89928715e-02, -7.23206616e-02, -8.70113770e-02, -8.89474860e-02,\n",
       "                     -9.53101798e-02, -9.84400728e-02, -1.01782694e-01, -1.06380404e-01,\n",
       "                     -1.11225635e-01, -1.13328685e-01, -1.17783036e-01, -1.33531393e-01,\n",
       "                     -1.41078598e-01, -1.54150680e-01, -1.62518929e-01, -1.74353387e-01,\n",
       "                     -1.82321557e-01, -1.94156014e-01, -2.04794413e-01, -2.13574100e-01,\n",
       "                     -2.22157844e-01, -2.23143551e-01, -2.28841572e-01, -2.38411023e-01,\n",
       "                     -2.40141128e-01, -2.41162057e-01, -2.42313467e-01, -2.47562079e-01,\n",
       "                     -2.47836164e-01, -2.50913225e-01, -2.51314428e-01, -2.61364764e-01,\n",
       "                     -2.62364264e-01, -2.64692554e-01, -2.66267978e-01, -2.87682072e-01,\n",
       "                     -2.95464213e-01, -3.04211374e-01, -3.05381650e-01, -3.08180594e-01,\n",
       "                     -3.10154928e-01, -3.17095958e-01, -3.18453731e-01, -3.19633672e-01,\n",
       "                     -3.28504067e-01, -3.30241687e-01, -3.32133835e-01, -3.34934957e-01,\n",
       "                     -3.36472237e-01, -3.42944751e-01, -3.43771539e-01, -3.44840486e-01,\n",
       "                     -3.46276237e-01, -3.46466767e-01, -3.48306694e-01, -3.51397887e-01,\n",
       "                     -3.55550717e-01, -3.56674944e-01, -3.62905494e-01, -3.64643114e-01,\n",
       "                     -3.66850272e-01, -3.67724780e-01, -3.70373788e-01, -3.76477571e-01,\n",
       "                     -3.79489622e-01, -3.81934611e-01, -3.83958903e-01, -3.85662481e-01,\n",
       "                     -3.87765531e-01, -3.98776120e-01, -4.05465108e-01, -4.12244795e-01,\n",
       "                     -4.16893804e-01, -4.20502985e-01, -4.30782916e-01, -4.38254931e-01,\n",
       "                     -4.40971797e-01, -4.41832752e-01, -4.46287103e-01, -4.51985124e-01,\n",
       "                     -4.65057205e-01, -4.70003629e-01, -4.78490243e-01, -4.80972661e-01,\n",
       "                     -4.85507816e-01, -4.90622916e-01, -5.02091944e-01, -5.10825624e-01,\n",
       "                     -5.15027311e-01, -5.18793793e-01, -5.22189382e-01, -5.28067430e-01,\n",
       "                     -5.30628251e-01, -5.36304709e-01, -5.38996501e-01, -5.42324291e-01,\n",
       "                     -5.46543706e-01, -5.59615788e-01, -5.61377903e-01, -5.67984038e-01,\n",
       "                     -5.75364145e-01, -5.87786665e-01, -5.95983432e-01, -5.97837001e-01,\n",
       "                     -6.06135804e-01, -6.12517446e-01, -6.14158769e-01, -6.19039208e-01,\n",
       "                     -6.28608659e-01, -6.31271777e-01, -6.35988767e-01, -6.44357016e-01,\n",
       "                     -6.50587566e-01, -6.52325186e-01, -6.53926467e-01, -6.66191371e-01,\n",
       "                     -6.69049629e-01, -6.93147181e-01, -7.30887509e-01, -7.50305594e-01,\n",
       "                     -7.73189888e-01, -8.10930216e-01, -8.47297860e-01, -8.57450232e-01,\n",
       "                     -8.60201265e-01, -8.75468737e-01, -9.16290732e-01, -9.34309237e-01,\n",
       "                     -9.55511445e-01, -1.01160091e+00, -1.09861229e+00, -1.18562367e+00,\n",
       "                     -1.20397280e+00, -1.25276297e+00, -1.29928298e+00, -1.38629436e+00,\n",
       "                     -1.52605630e+00, -1.60943791e+00, -1.79175947e+00, -2.07944154e+00,\n",
       "                     -2.63905733e+00, -3.45387764e+01]), auc_score=0.5278550014605767, privacy_risk=0.5228709503160907, accuracy=0.5225294418842806, tpr_ind=0.8193002691272587, tnr_ind=0.22644163150492264, test_train_ratio=1.0023068050749713, dataset_size=[7803, 7821]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.09886175, 0.10448907, 0.10870955, 0.11216268,\n",
       "                     0.11497634, 0.11753421, 0.11855736, 0.12188259, 0.12431257,\n",
       "                     0.12866095, 0.13032357, 0.1396598 , 0.1436245 , 0.14528712,\n",
       "                     0.18007418, 0.18403888, 0.19222407, 0.19682824, 0.20207188,\n",
       "                     0.20399028, 0.21115232, 0.21575649, 0.21677964, 0.22496483,\n",
       "                     0.22867374, 0.2395447 , 0.24235836, 0.24849725, 0.25591508,\n",
       "                     0.28673743, 0.30361939, 0.30707252, 0.32216396, 0.32472183,\n",
       "                     0.33751119, 0.33981328, 0.34659164, 0.35362578, 0.35579997,\n",
       "                     0.3632178 , 0.36782197, 0.36999616, 0.37485612, 0.3793324 ,\n",
       "                     0.39007546, 0.40184167, 0.40567848, 0.41041054, 0.4132242 ,\n",
       "                     0.41693311, 0.46719529, 0.47167157, 0.47371787, 0.49993605,\n",
       "                     0.50927229, 0.51323699, 0.51643433, 0.51937588, 0.53600205,\n",
       "                     0.54751247, 0.55045402, 0.55633713, 0.558895  , 0.57053332,\n",
       "                     0.57705589, 0.57986955, 0.58613633, 0.58958946, 0.59662361,\n",
       "                     0.61516818, 0.63409643, 0.65097839, 0.65430362, 0.68768385,\n",
       "                     0.68921857, 0.70443791, 0.71006523, 0.71172784, 0.72157565,\n",
       "                     0.72720297, 0.73065609, 0.73129556, 0.74127126, 0.74382913,\n",
       "                     0.75431641, 0.76109477, 0.76493158, 0.76684998, 0.76927996,\n",
       "                     0.78091828, 0.78488298, 0.79460289, 0.79856759, 0.79946285,\n",
       "                     0.80931065, 0.82580893, 0.83002942, 0.83348254, 0.83591252,\n",
       "                     0.83898197, 0.84166773, 0.84716716, 0.85931705, 0.86136335,\n",
       "                     0.86302596, 0.87210641, 0.87376902, 0.87402481, 0.87735004,\n",
       "                     0.88834889, 0.89397621, 0.9022893 , 0.91034659, 0.91648548,\n",
       "                     0.91725285, 0.92403121, 0.92965852, 0.94091316, 0.95280726,\n",
       "                     0.96188771, 0.96342243, 0.96418979, 0.96725924, 0.96968922,\n",
       "                     0.97173552, 0.97314235, 0.97557232, 0.97710705, 0.97864177,\n",
       "                     0.97953703, 0.98503645, 0.98669907, 0.98708275, 0.98746643,\n",
       "                     0.9881059 , 0.98912904, 0.99117534, 1.        ]), tpr=array([0.        , 0.10890455, 0.11467008, 0.11825753, 0.12158873,\n",
       "                     0.12466368, 0.12901986, 0.13030109, 0.13388853, 0.13734785,\n",
       "                     0.14401025, 0.14606022, 0.15285074, 0.15669443, 0.15848815,\n",
       "                     0.19180013, 0.19654068, 0.20653427, 0.21178732, 0.21550288,\n",
       "                     0.21844971, 0.22652146, 0.232287  , 0.23369635, 0.2434337 ,\n",
       "                     0.24740551, 0.25778347, 0.26034593, 0.26636771, 0.2735426 ,\n",
       "                     0.30467649, 0.319795  , 0.32363869, 0.34067905, 0.3442665 ,\n",
       "                     0.35528507, 0.35797566, 0.36502242, 0.37117233, 0.37245356,\n",
       "                     0.37950032, 0.38526586, 0.38731582, 0.39180013, 0.39692505,\n",
       "                     0.4111467 , 0.42524023, 0.42972454, 0.43549007, 0.43830878,\n",
       "                     0.44279308, 0.49686099, 0.50198591, 0.50467649, 0.53030109,\n",
       "                     0.54106342, 0.5442665 , 0.54823831, 0.55067265, 0.56463805,\n",
       "                     0.576041  , 0.5805253 , 0.58577835, 0.58808456, 0.59974375,\n",
       "                     0.60409994, 0.60704676, 0.6144779 , 0.6189622 , 0.62600897,\n",
       "                     0.64586803, 0.66329276, 0.68084561, 0.68481742, 0.71492633,\n",
       "                     0.71787316, 0.73324792, 0.74016656, 0.74183216, 0.752082  ,\n",
       "                     0.75579757, 0.75810378, 0.75900064, 0.76860987, 0.77091608,\n",
       "                     0.78257527, 0.78962204, 0.79410634, 0.7955157 , 0.79730942,\n",
       "                     0.80704676, 0.81089045, 0.81909033, 0.82280589, 0.82447149,\n",
       "                     0.83331198, 0.85035234, 0.85483664, 0.86047406, 0.8623959 ,\n",
       "                     0.86483024, 0.86790519, 0.8752082 , 0.88597053, 0.88763613,\n",
       "                     0.88994234, 0.89839846, 0.9008328 , 0.90147341, 0.90403587,\n",
       "                     0.91633568, 0.92171685, 0.92991672, 0.93632287, 0.93965407,\n",
       "                     0.94080717, 0.94951954, 0.95554132, 0.96450993, 0.97335042,\n",
       "                     0.9793722 , 0.98065343, 0.98167841, 0.98488149, 0.98731582,\n",
       "                     0.9888533 , 0.99000641, 0.99128764, 0.99244074, 0.99397822,\n",
       "                     0.99487508, 0.99743754, 0.99795003, 0.9983344 , 0.99884689,\n",
       "                     0.99923126, 0.99974375, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.19789067e-02, -3.50913198e-02,\n",
       "                     -7.41079722e-02, -8.00427077e-02, -8.45573880e-02, -9.53101798e-02,\n",
       "                     -1.01782694e-01, -1.05360516e-01, -1.09199292e-01, -1.17783036e-01,\n",
       "                     -1.24052649e-01, -1.25163143e-01, -1.33531393e-01, -1.49745386e-01,\n",
       "                     -1.50282203e-01, -1.54150680e-01, -1.57628944e-01, -1.59064695e-01,\n",
       "                     -1.60342650e-01, -1.60930367e-01, -1.63629424e-01, -1.67054085e-01,\n",
       "                     -1.69076330e-01, -1.76930708e-01, -1.80261824e-01, -1.82321557e-01,\n",
       "                     -1.92903666e-01, -1.94156014e-01, -2.00670695e-01, -2.06049118e-01,\n",
       "                     -2.09720531e-01, -2.15596346e-01, -2.23143551e-01, -2.46133070e-01,\n",
       "                     -2.51314428e-01, -2.55346692e-01, -2.55933374e-01, -2.62364264e-01,\n",
       "                     -2.69332934e-01, -2.70874954e-01, -2.71933715e-01, -2.73293335e-01,\n",
       "                     -2.81412459e-01, -2.87682072e-01, -2.89952221e-01, -2.94799540e-01,\n",
       "                     -3.04211374e-01, -3.10154928e-01, -3.15852949e-01, -3.18022790e-01,\n",
       "                     -3.18453731e-01, -3.22773392e-01, -3.29303747e-01, -3.31357136e-01,\n",
       "                     -3.36472237e-01, -3.50202429e-01, -3.51397887e-01, -3.52077235e-01,\n",
       "                     -3.55550717e-01, -3.56674944e-01, -3.63965377e-01, -3.67724780e-01,\n",
       "                     -3.79489622e-01, -3.85662481e-01, -3.90866309e-01, -3.93904286e-01,\n",
       "                     -3.95895657e-01, -3.99386062e-01, -4.03312255e-01, -4.05465108e-01,\n",
       "                     -4.07895243e-01, -4.16160397e-01, -4.18150268e-01, -4.19853846e-01,\n",
       "                     -4.21994410e-01, -4.29856561e-01, -4.30782916e-01, -4.38254931e-01,\n",
       "                     -4.39366660e-01, -4.41832752e-01, -4.51985124e-01, -4.70003629e-01,\n",
       "                     -4.76924072e-01, -4.79573080e-01, -4.81303184e-01, -4.87703206e-01,\n",
       "                     -4.92476485e-01, -4.96436886e-01, -4.97580397e-01, -5.10825624e-01,\n",
       "                     -5.23248144e-01, -5.24524468e-01, -5.26093096e-01, -5.28067430e-01,\n",
       "                     -5.30185871e-01, -5.38996501e-01, -5.46543706e-01, -5.50046337e-01,\n",
       "                     -5.52068582e-01, -5.59615788e-01, -5.62118918e-01, -5.66395475e-01,\n",
       "                     -5.70544858e-01, -5.75364145e-01, -5.81029882e-01, -5.81921545e-01,\n",
       "                     -5.87786665e-01, -6.15185639e-01, -6.17435359e-01, -6.19039208e-01,\n",
       "                     -6.20240410e-01, -6.31271777e-01, -6.33723760e-01, -6.35988767e-01,\n",
       "                     -6.40304699e-01, -6.60711905e-01, -6.93147181e-01, -7.00367429e-01,\n",
       "                     -7.24563377e-01, -7.41937345e-01, -7.53771802e-01, -7.88457360e-01,\n",
       "                     -7.93230639e-01, -8.10930216e-01, -8.47297860e-01, -8.75468737e-01,\n",
       "                     -8.93817876e-01, -9.80829253e-01, -9.98528830e-01, -1.09861229e+00,\n",
       "                     -1.17865500e+00, -1.20397280e+00, -1.25276297e+00, -1.38629436e+00,\n",
       "                     -1.60943791e+00, -2.07944154e+00, -3.45387764e+01]), auc_score=0.5213806953101886, privacy_risk=0.515901991068095, accuracy=0.5158730158730159, tpr_ind=0.5482383087764253, tnr_ind=0.4835656733597647, test_train_ratio=1.0017937219730941, dataset_size=[7805, 7819]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.09633838, 0.11098485, 0.12335859, 0.12638889,\n",
       "                     0.13522727, 0.14608586, 0.14747475, 0.14823232, 0.15025253,\n",
       "                     0.15441919, 0.15643939, 0.15984848, 0.16123737, 0.16313131,\n",
       "                     0.1665404 , 0.17171717, 0.17512626, 0.18156566, 0.19128788,\n",
       "                     0.20984848, 0.22007576, 0.24633838, 0.2489899 , 0.25063131,\n",
       "                     0.26275253, 0.26767677, 0.2719697 , 0.27310606, 0.27916667,\n",
       "                     0.28156566, 0.28409091, 0.28914141, 0.32613636, 0.32765152,\n",
       "                     0.33030303, 0.33282828, 0.34469697, 0.35126263, 0.35871212,\n",
       "                     0.36755051, 0.3739899 , 0.37866162, 0.38257576, 0.38661616,\n",
       "                     0.38825758, 0.39962121, 0.40315657, 0.40429293, 0.41489899,\n",
       "                     0.4229798 , 0.42727273, 0.4364899 , 0.45909091, 0.47070707,\n",
       "                     0.47247475, 0.50429293, 0.51300505, 0.52765152, 0.54381313,\n",
       "                     0.55328283, 0.55984848, 0.5665404 , 0.57020202, 0.59520202,\n",
       "                     0.60239899, 0.61376263, 0.61742424, 0.62045455, 0.63080808,\n",
       "                     0.63585859, 0.63863636, 0.6510101 , 0.65959596, 0.66161616,\n",
       "                     0.66906566, 0.69305556, 0.70075758, 0.70555556, 0.71136364,\n",
       "                     0.71565657, 0.71818182, 0.7270202 , 0.73257576, 0.73434343,\n",
       "                     0.73901515, 0.74760101, 0.75593434, 0.77765152, 0.78017677,\n",
       "                     0.78055556, 0.78169192, 0.79255051, 0.79608586, 0.80441919,\n",
       "                     0.80757576, 0.86969697, 0.87575758, 0.88156566, 0.89583333,\n",
       "                     0.89646465, 0.89709596, 0.90669192, 0.91212121, 0.91338384,\n",
       "                     0.91527778, 0.91755051, 0.92121212, 0.92424242, 0.94431818,\n",
       "                     0.95037879, 0.95214646, 0.95315657, 0.95479798, 0.95681818,\n",
       "                     0.95795455, 0.96224747, 0.96641414, 0.96881313, 0.97083333,\n",
       "                     0.97171717, 0.97386364, 0.97967172, 0.98156566, 0.98232323,\n",
       "                     0.98282828, 0.98383838, 0.98510101, 0.9875    , 0.98838384,\n",
       "                     0.9895202 , 0.99002525, 0.99065657, 1.        ]), tpr=array([0.        , 0.10020768, 0.11357736, 0.12915369, 0.13330737,\n",
       "                     0.1442108 , 0.15472482, 0.15641225, 0.15796989, 0.15939772,\n",
       "                     0.1632918 , 0.16692627, 0.17043094, 0.17250779, 0.17614226,\n",
       "                     0.17964694, 0.18665628, 0.19016096, 0.19768951, 0.21196781,\n",
       "                     0.23468328, 0.2451973 , 0.27115784, 0.27518172, 0.27686916,\n",
       "                     0.28894081, 0.29646937, 0.30231049, 0.30386812, 0.31087747,\n",
       "                     0.31386293, 0.31619938, 0.32178089, 0.36033229, 0.36240914,\n",
       "                     0.3652648 , 0.36850987, 0.37889408, 0.38486501, 0.39265317,\n",
       "                     0.40031153, 0.40771028, 0.41251298, 0.41796469, 0.42120976,\n",
       "                     0.42263759, 0.43457944, 0.43808411, 0.44016096, 0.45275182,\n",
       "                     0.45963136, 0.46482347, 0.47663551, 0.50142783, 0.5142783 ,\n",
       "                     0.51583593, 0.5478972 , 0.55620457, 0.56905504, 0.58385254,\n",
       "                     0.59228972, 0.59942887, 0.60656802, 0.61163032, 0.64148494,\n",
       "                     0.64706646, 0.6584891 , 0.66251298, 0.66523884, 0.6732866 ,\n",
       "                     0.68003634, 0.68237279, 0.69794912, 0.70638629, 0.70820353,\n",
       "                     0.71586189, 0.73351506, 0.7402648 , 0.74545691, 0.75038941,\n",
       "                     0.75272586, 0.75610073, 0.76401869, 0.76895119, 0.77037902,\n",
       "                     0.77544133, 0.78219107, 0.78946002, 0.81152648, 0.81386293,\n",
       "                     0.81593977, 0.81762721, 0.82658359, 0.82917965, 0.83956386,\n",
       "                     0.84203011, 0.89628764, 0.90199896, 0.90732087, 0.92198858,\n",
       "                     0.92263759, 0.92419522, 0.93367082, 0.93860332, 0.93951194,\n",
       "                     0.94184839, 0.94314642, 0.94600208, 0.94807892, 0.96754933,\n",
       "                     0.97248183, 0.97416926, 0.97533749, 0.97637591, 0.97793354,\n",
       "                     0.97858255, 0.98169782, 0.98442368, 0.98714953, 0.98935618,\n",
       "                     0.9903946 , 0.99195223, 0.99454829, 0.9953271 , 0.99584631,\n",
       "                     0.99623572, 0.99675493, 0.99740395, 0.99857217, 0.99896158,\n",
       "                     0.99961059, 0.99974039, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.66188940e-02, -5.66953437e-02,\n",
       "                     -6.06246218e-02, -6.89928715e-02, -7.14589640e-02, -7.41079722e-02,\n",
       "                     -8.00427077e-02, -8.70113770e-02, -9.53101798e-02, -1.01782694e-01,\n",
       "                     -1.05360516e-01, -1.17783036e-01, -1.33531393e-01, -1.38150338e-01,\n",
       "                     -1.54150680e-01, -1.69899037e-01, -1.73663494e-01, -1.82321557e-01,\n",
       "                     -1.96506192e-01, -2.00670695e-01, -2.02940844e-01, -2.03598955e-01,\n",
       "                     -2.07639365e-01, -2.12332635e-01, -2.16223108e-01, -2.18689201e-01,\n",
       "                     -2.23143551e-01, -2.30523659e-01, -2.31801614e-01, -2.45122458e-01,\n",
       "                     -2.46133070e-01, -2.62105231e-01, -2.71933715e-01, -2.76253377e-01,\n",
       "                     -2.77631737e-01, -2.81412459e-01, -2.82232468e-01, -2.87682072e-01,\n",
       "                     -2.91910409e-01, -3.00754154e-01, -3.01105093e-01, -3.05381650e-01,\n",
       "                     -3.07484700e-01, -3.10154928e-01, -3.14493330e-01, -3.15081047e-01,\n",
       "                     -3.18453731e-01, -3.23128821e-01, -3.33773180e-01, -3.36472237e-01,\n",
       "                     -3.41170757e-01, -3.46148531e-01, -3.46522572e-01, -3.48306694e-01,\n",
       "                     -3.48544818e-01, -3.51976423e-01, -3.53640040e-01, -3.57551752e-01,\n",
       "                     -3.58212223e-01, -3.62114667e-01, -3.74693449e-01, -3.79489622e-01,\n",
       "                     -3.82003621e-01, -3.97682968e-01, -4.05465108e-01, -4.16160397e-01,\n",
       "                     -4.21213465e-01, -4.26742507e-01, -4.30782916e-01, -4.41832752e-01,\n",
       "                     -4.48950220e-01, -4.50585543e-01, -4.51985124e-01, -4.55062049e-01,\n",
       "                     -4.62623522e-01, -4.67596889e-01, -4.70003629e-01, -4.73287704e-01,\n",
       "                     -4.76924072e-01, -4.79573080e-01, -4.84245986e-01, -4.89548225e-01,\n",
       "                     -4.92476485e-01, -4.95321437e-01, -5.03103578e-01, -5.07247802e-01,\n",
       "                     -5.09648461e-01, -5.10825624e-01, -5.23248144e-01, -5.26093096e-01,\n",
       "                     -5.28067430e-01, -5.30628251e-01, -5.37954291e-01, -5.52068582e-01,\n",
       "                     -5.58932027e-01, -5.59615788e-01, -5.63094052e-01, -5.85818160e-01,\n",
       "                     -5.87786665e-01, -6.06135804e-01, -6.07380359e-01, -6.10909082e-01,\n",
       "                     -6.19039208e-01, -6.35988767e-01, -6.41853886e-01, -6.46627165e-01,\n",
       "                     -6.61398482e-01, -6.93147181e-01, -7.06219262e-01, -7.30887509e-01,\n",
       "                     -7.47214402e-01, -7.53771802e-01, -7.73189888e-01, -7.88457360e-01,\n",
       "                     -8.10930216e-01, -8.47297860e-01, -8.67500568e-01, -9.04456274e-01,\n",
       "                     -9.16290732e-01, -9.80829253e-01, -1.09861229e+00, -1.15267951e+00,\n",
       "                     -1.17865500e+00, -1.20397280e+00, -1.25276297e+00, -1.28093385e+00,\n",
       "                     -1.29928298e+00, -1.38629436e+00, -1.60943791e+00, -1.94591015e+00,\n",
       "                     -2.01490302e+00, -3.45387764e+01]), auc_score=0.5286336397463733, privacy_risk=0.5234695081657699, accuracy=0.5210573476702509, tpr_ind=0.6979491173416407, tnr_ind=0.348989898989899, test_train_ratio=1.02803738317757, dataset_size=[7704, 7920]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.11233367, 0.12090583, 0.12333675, 0.12627943,\n",
       "                     0.12807062, 0.13011771, 0.13382805, 0.13536336, 0.13805015,\n",
       "                     0.14534289, 0.14751791, 0.14892528, 0.15263562, 0.15596213,\n",
       "                     0.15839304, 0.16031218, 0.1642784 , 0.17067554, 0.17515353,\n",
       "                     0.17630502, 0.17963153, 0.18449335, 0.18718014, 0.19191402,\n",
       "                     0.19460082, 0.19882293, 0.20138178, 0.20368475, 0.21136131,\n",
       "                     0.21238485, 0.2167349 , 0.22146878, 0.229913  , 0.24193961,\n",
       "                     0.2569089 , 0.27520471, 0.30642272, 0.32024053, 0.33265097,\n",
       "                     0.35248209, 0.354913  , 0.35811157, 0.36386899, 0.37116172,\n",
       "                     0.3767912 , 0.38331627, 0.41376663, 0.42809621, 0.44204197,\n",
       "                     0.44447288, 0.44524053, 0.4511259 , 0.45944217, 0.46059365,\n",
       "                     0.47018936, 0.47863357, 0.50383828, 0.51586489, 0.52238997,\n",
       "                     0.52430911, 0.53774309, 0.54298874, 0.59723644, 0.59928352,\n",
       "                     0.60427329, 0.60875128, 0.61604401, 0.62512794, 0.63011771,\n",
       "                     0.6328045 , 0.64137666, 0.64431934, 0.65212385, 0.65839304,\n",
       "                     0.66389458, 0.67246673, 0.6792477 , 0.68474923, 0.69037871,\n",
       "                     0.69856704, 0.69984647, 0.70419652, 0.70675537, 0.72389969,\n",
       "                     0.72786592, 0.73093654, 0.77162231, 0.77456499, 0.78224156,\n",
       "                     0.78467247, 0.79759468, 0.80373593, 0.80783009, 0.81243603,\n",
       "                     0.8312436 , 0.83943193, 0.84224667, 0.85593654, 0.8662999 ,\n",
       "                     0.86962641, 0.87205732, 0.87704708, 0.88088536, 0.88894575,\n",
       "                     0.89035312, 0.89495906, 0.89841351, 0.90199591, 0.91005629,\n",
       "                     0.91107984, 0.91274309, 0.91479017, 0.91555783, 0.92246673,\n",
       "                     0.92822416, 0.93193449, 0.9361566 , 0.959826  , 0.96289662,\n",
       "                     0.96443193, 0.96571136, 0.96635107, 0.97146878, 0.97185261,\n",
       "                     0.97249232, 0.97351586, 0.97773797, 0.97876151, 0.97952917,\n",
       "                     0.98029683, 0.98157625, 0.98720573, 0.9877175 , 0.98938076,\n",
       "                     0.98938076, 0.98938076, 0.9904043 , 0.99104401, 0.99155578,\n",
       "                     1.        ]), tpr=array([0.        , 0.11539447, 0.1225666 , 0.12589652, 0.13140369,\n",
       "                     0.13409324, 0.13665471, 0.14318648, 0.14523566, 0.14907787,\n",
       "                     0.1567623 , 0.1591957 , 0.16150102, 0.16547131, 0.16841701,\n",
       "                     0.17033811, 0.17315574, 0.17866291, 0.1850666 , 0.18865266,\n",
       "                     0.19031762, 0.19441598, 0.19915471, 0.20299693, 0.20722336,\n",
       "                     0.20927254, 0.2138832 , 0.21772541, 0.22143955, 0.22925205,\n",
       "                     0.23040471, 0.234375  , 0.24001025, 0.24871926, 0.26331967,\n",
       "                     0.27727971, 0.29521004, 0.32658811, 0.33965164, 0.35040984,\n",
       "                     0.36757172, 0.3701332 , 0.37346311, 0.37756148, 0.38639857,\n",
       "                     0.39318648, 0.40023053, 0.4326332 , 0.44684939, 0.46375512,\n",
       "                     0.4663166 , 0.46810963, 0.47374488, 0.47989242, 0.48155738,\n",
       "                     0.4946209 , 0.50358607, 0.52689549, 0.53637295, 0.54469775,\n",
       "                     0.54623463, 0.55724898, 0.56390881, 0.61693135, 0.6196209 ,\n",
       "                     0.62704918, 0.63204406, 0.63755123, 0.64677254, 0.65163934,\n",
       "                     0.6533043 , 0.66188525, 0.66547131, 0.67418033, 0.68122439,\n",
       "                     0.68583504, 0.6948002 , 0.69877049, 0.70517418, 0.70991291,\n",
       "                     0.71759734, 0.71875   , 0.72438525, 0.72617828, 0.7426998 ,\n",
       "                     0.74654201, 0.7494877 , 0.79098361, 0.79367316, 0.80212602,\n",
       "                     0.8041752 , 0.81480533, 0.82018443, 0.82492316, 0.82940574,\n",
       "                     0.84938525, 0.85655738, 0.85783811, 0.87371926, 0.88498975,\n",
       "                     0.8881916 , 0.8901127 , 0.89421107, 0.89805328, 0.90535348,\n",
       "                     0.90765881, 0.91175717, 0.91470287, 0.91713627, 0.92494877,\n",
       "                     0.92635758, 0.92815061, 0.9301998 , 0.93135246, 0.94018955,\n",
       "                     0.94454406, 0.94736168, 0.95274078, 0.97733094, 0.98104508,\n",
       "                     0.9819416 , 0.98271004, 0.98335041, 0.98693648, 0.9873207 ,\n",
       "                     0.98885758, 0.9897541 , 0.99180328, 0.99257172, 0.99308402,\n",
       "                     0.99372439, 0.9951332 , 0.99743852, 0.99782275, 0.99871926,\n",
       "                     0.99910348, 0.99935963, 0.99961578, 0.99987193, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.50913198e-02, -3.77403280e-02,\n",
       "                     -4.54623741e-02, -4.65200156e-02, -4.87901642e-02, -5.71584138e-02,\n",
       "                     -6.06246218e-02, -6.45385211e-02, -8.00427077e-02, -1.00083459e-01,\n",
       "                     -1.05360516e-01, -1.21360857e-01, -1.22602322e-01, -1.25163143e-01,\n",
       "                     -1.27833372e-01, -1.30620182e-01, -1.31028262e-01, -1.33531393e-01,\n",
       "                     -1.43100844e-01, -1.45182010e-01, -1.50282203e-01, -1.54150680e-01,\n",
       "                     -1.67054085e-01, -1.71850257e-01, -1.77681177e-01, -1.82321557e-01,\n",
       "                     -1.88052232e-01, -1.93191229e-01, -2.00670695e-01, -2.03598955e-01,\n",
       "                     -2.04794413e-01, -2.23143551e-01, -2.26646182e-01, -2.28633044e-01,\n",
       "                     -2.34507310e-01, -2.41744977e-01, -2.57829109e-01, -2.60531083e-01,\n",
       "                     -2.61215499e-01, -2.62364264e-01, -2.68263987e-01, -2.71933715e-01,\n",
       "                     -2.76753002e-01, -2.78203328e-01, -2.83126256e-01, -2.86693442e-01,\n",
       "                     -2.87682072e-01, -2.98981628e-01, -3.00104592e-01, -3.05381650e-01,\n",
       "                     -3.10154928e-01, -3.18453731e-01, -3.25422400e-01, -3.30854244e-01,\n",
       "                     -3.36472237e-01, -3.37256858e-01, -3.40325806e-01, -3.47401307e-01,\n",
       "                     -3.48306694e-01, -3.49673748e-01, -3.52821375e-01, -3.55950044e-01,\n",
       "                     -3.56674944e-01, -3.58397597e-01, -3.61790045e-01, -3.65934269e-01,\n",
       "                     -3.67724780e-01, -3.69747026e-01, -3.79489622e-01, -3.80274859e-01,\n",
       "                     -3.81367557e-01, -3.85662481e-01, -3.99386062e-01, -4.05465108e-01,\n",
       "                     -4.14943852e-01, -4.16160397e-01, -4.18710335e-01, -4.32133355e-01,\n",
       "                     -4.38254931e-01, -4.41832752e-01, -4.49916871e-01, -4.51985124e-01,\n",
       "                     -4.53393575e-01, -4.70003629e-01, -4.75423697e-01, -4.78837948e-01,\n",
       "                     -4.81838087e-01, -4.83174092e-01, -4.85507816e-01, -4.86434171e-01,\n",
       "                     -4.96436886e-01, -4.99955952e-01, -5.05094949e-01, -5.10825624e-01,\n",
       "                     -5.28525201e-01, -5.30628251e-01, -5.31576568e-01, -5.39943022e-01,\n",
       "                     -5.42324291e-01, -5.50046337e-01, -5.59615788e-01, -5.69094532e-01,\n",
       "                     -5.72069249e-01, -5.75364145e-01, -5.77315365e-01, -5.78077851e-01,\n",
       "                     -5.81921545e-01, -5.89606502e-01, -5.97837001e-01, -6.19039208e-01,\n",
       "                     -6.28608659e-01, -6.35988767e-01, -6.41090819e-01, -6.63294217e-01,\n",
       "                     -6.70157662e-01, -6.81170990e-01, -6.93147181e-01, -7.43578034e-01,\n",
       "                     -7.62140052e-01, -7.73189888e-01, -7.88457360e-01, -8.10930216e-01,\n",
       "                     -8.47297860e-01, -8.82389180e-01, -8.87303195e-01, -9.16290732e-01,\n",
       "                     -9.80829253e-01, -1.01160091e+00, -1.02961942e+00, -1.06784063e+00,\n",
       "                     -1.09861229e+00, -1.29928298e+00, -1.38629436e+00, -1.46633707e+00,\n",
       "                     -1.60943791e+00, -1.79175947e+00, -2.01490302e+00, -2.19722458e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5162836721280014, privacy_risk=0.5124762467070489, accuracy=0.5124807987711214, tpr_ind=0.5035860655737705, tnr_ind=0.5213664278403275, test_train_ratio=1.0010245901639345, dataset_size=[7808, 7816]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.06433048, 0.08837447, 0.09310654, 0.11241847,\n",
       "                     0.11919683, 0.11945262, 0.12034787, 0.12546361, 0.12712623,\n",
       "                     0.13224197, 0.15232127, 0.15615808, 0.16063435, 0.17278424,\n",
       "                     0.17700473, 0.19874664, 0.20322292, 0.20526922, 0.20782709,\n",
       "                     0.20974549, 0.24261415, 0.24440466, 0.25501982, 0.26051925,\n",
       "                     0.2694718 , 0.28021486, 0.28967899, 0.29210897, 0.29811996,\n",
       "                     0.29863154, 0.30630515, 0.32101292, 0.32548919, 0.33150019,\n",
       "                     0.36232255, 0.37383297, 0.37766978, 0.38368078, 0.40133009,\n",
       "                     0.43010615, 0.43189666, 0.44238394, 0.44775547, 0.45453383,\n",
       "                     0.49469242, 0.49673871, 0.50607495, 0.50671441, 0.50927229,\n",
       "                     0.51835273, 0.53139788, 0.54584985, 0.55825553, 0.56810334,\n",
       "                     0.56989385, 0.57795114, 0.59854201, 0.6007162 , 0.61990024,\n",
       "                     0.64113058, 0.65724517, 0.66849981, 0.68550966, 0.69676429,\n",
       "                     0.70085689, 0.70431001, 0.71121627, 0.71300678, 0.71530886,\n",
       "                     0.73142346, 0.73398133, 0.73884128, 0.75776954, 0.77490728,\n",
       "                     0.77861619, 0.79575393, 0.80138125, 0.80419491, 0.80803172,\n",
       "                     0.81493797, 0.81660059, 0.81787952, 0.81954214, 0.82171633,\n",
       "                     0.83156414, 0.8342499 , 0.84217931, 0.84409771, 0.8462719 ,\n",
       "                     0.85010871, 0.85241079, 0.85368973, 0.86353754, 0.87172273,\n",
       "                     0.87607111, 0.8801637 , 0.88246579, 0.89691776, 0.90740504,\n",
       "                     0.91034659, 0.94500576, 0.95319095, 0.95357463, 0.95651618,\n",
       "                     0.95843458, 0.96265507, 0.96661977, 0.96751503, 0.96994501,\n",
       "                     0.97173552, 0.97544443, 0.981967  , 0.98362962, 0.98478066,\n",
       "                     0.98490856, 0.98503645, 0.98682696, 0.98721064, 0.98785011,\n",
       "                     0.98836168, 0.98900115, 0.99015219, 0.99219849, 0.99245428,\n",
       "                     0.99258217, 0.99283796, 1.        ]), tpr=array([0.        , 0.06816143, 0.09493914, 0.09929532, 0.11633568,\n",
       "                     0.12235746, 0.12363869, 0.1247918 , 0.13132607, 0.13337604,\n",
       "                     0.13824471, 0.15925689, 0.16207559, 0.16835362, 0.18283152,\n",
       "                     0.18744395, 0.21140295, 0.21422165, 0.21691224, 0.21985906,\n",
       "                     0.22101217, 0.25419603, 0.25586163, 0.2673927 , 0.2735426 ,\n",
       "                     0.28097373, 0.29212044, 0.30224215, 0.304164  , 0.31082639,\n",
       "                     0.31223575, 0.31953876, 0.33568225, 0.34029468, 0.34554773,\n",
       "                     0.37488789, 0.38757207, 0.39090327, 0.39641256, 0.41473414,\n",
       "                     0.43856502, 0.44138373, 0.45214606, 0.4590647 , 0.46662396,\n",
       "                     0.5074952 , 0.51018578, 0.51774504, 0.51838565, 0.5214606 ,\n",
       "                     0.53183857, 0.54554773, 0.56515054, 0.57463165, 0.5871877 ,\n",
       "                     0.58949391, 0.59743754, 0.62037156, 0.6222934 , 0.63894939,\n",
       "                     0.65919283, 0.67367072, 0.68725176, 0.70634209, 0.71672005,\n",
       "                     0.7231262 , 0.72607303, 0.73478539, 0.73670724, 0.74029468,\n",
       "                     0.752082  , 0.75438821, 0.75912876, 0.77745035, 0.79577194,\n",
       "                     0.79961563, 0.81691224, 0.82190903, 0.82459962, 0.82664958,\n",
       "                     0.83356823, 0.8367713 , 0.83856502, 0.8401025 , 0.8429212 ,\n",
       "                     0.85265855, 0.85432415, 0.85983344, 0.86367713, 0.86547085,\n",
       "                     0.86957079, 0.87264574, 0.87482383, 0.88225496, 0.88763613,\n",
       "                     0.89186419, 0.89429853, 0.8975016 , 0.91467008, 0.92338245,\n",
       "                     0.92568866, 0.96207559, 0.96809737, 0.96899423, 0.9710442 ,\n",
       "                     0.97335042, 0.97706598, 0.98206278, 0.9827034 , 0.98475336,\n",
       "                     0.98629084, 0.98949391, 0.99282511, 0.99397822, 0.99487508,\n",
       "                     0.99525945, 0.99577194, 0.99692505, 0.99743754, 0.99807816,\n",
       "                     0.9983344 , 0.99871877, 0.99910314, 0.99948751, 0.99974375,\n",
       "                     0.99987188, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.29441557e-02, -5.71584138e-02,\n",
       "                     -7.24955020e-02, -8.16780310e-02, -9.53101798e-02, -1.05360516e-01,\n",
       "                     -1.11225635e-01, -1.17783036e-01, -1.23613956e-01, -1.25880246e-01,\n",
       "                     -1.27833372e-01, -1.33531393e-01, -1.40146632e-01, -1.54150680e-01,\n",
       "                     -1.57963113e-01, -1.67054085e-01, -1.74353387e-01, -1.96710294e-01,\n",
       "                     -2.00670695e-01, -2.02073712e-01, -2.07639365e-01, -2.09720531e-01,\n",
       "                     -2.23143551e-01, -2.30016431e-01, -2.34572247e-01, -2.35722334e-01,\n",
       "                     -2.36388778e-01, -2.38411023e-01, -2.41162057e-01, -2.47408173e-01,\n",
       "                     -2.51314428e-01, -2.66628663e-01, -2.75411980e-01, -2.83305698e-01,\n",
       "                     -2.87682072e-01, -2.97251523e-01, -2.99242895e-01, -3.05013529e-01,\n",
       "                     -3.07642815e-01, -3.10154928e-01, -3.14115330e-01, -3.15081047e-01,\n",
       "                     -3.16911711e-01, -3.19308310e-01, -3.22773392e-01, -3.29181803e-01,\n",
       "                     -3.36472237e-01, -3.48306694e-01, -3.50482974e-01, -3.51051686e-01,\n",
       "                     -3.54057141e-01, -3.59374001e-01, -3.63792412e-01, -3.67724780e-01,\n",
       "                     -3.72675285e-01, -3.77134601e-01, -3.82992252e-01, -3.89960922e-01,\n",
       "                     -4.01236772e-01, -4.02510896e-01, -4.05465108e-01, -4.12154096e-01,\n",
       "                     -4.17735201e-01, -4.18710335e-01, -4.19853846e-01, -4.24883194e-01,\n",
       "                     -4.27444015e-01, -4.28995606e-01, -4.34038481e-01, -4.41832752e-01,\n",
       "                     -4.49525098e-01, -4.57690369e-01, -4.62105387e-01, -4.70003629e-01,\n",
       "                     -4.74622575e-01, -4.79573080e-01, -4.81838087e-01, -4.85507816e-01,\n",
       "                     -4.88352768e-01, -4.94696242e-01, -4.96436886e-01, -5.10825624e-01,\n",
       "                     -5.19875459e-01, -5.21296924e-01, -5.26093096e-01, -5.29259325e-01,\n",
       "                     -5.30628251e-01, -5.38996501e-01, -5.41597282e-01, -5.59615788e-01,\n",
       "                     -5.67984038e-01, -5.74285978e-01, -5.79818495e-01, -5.81029882e-01,\n",
       "                     -5.81921545e-01, -5.87786665e-01, -5.91097926e-01, -6.00773860e-01,\n",
       "                     -6.06135804e-01, -6.12517446e-01, -6.15760517e-01, -6.19039208e-01,\n",
       "                     -6.28608659e-01, -6.35988767e-01, -6.58055861e-01, -6.93147181e-01,\n",
       "                     -7.88457360e-01, -8.10930216e-01, -8.47297860e-01, -8.75468737e-01,\n",
       "                     -9.16290732e-01, -9.38269639e-01, -9.44461609e-01, -9.80829253e-01,\n",
       "                     -1.01160091e+00, -1.09861229e+00, -1.17865500e+00, -1.22377543e+00,\n",
       "                     -1.25276297e+00, -1.29928298e+00, -1.38629436e+00, -1.60943791e+00,\n",
       "                     -2.07944154e+00, -2.19722458e+00, -2.48490665e+00, -3.45387764e+01]), auc_score=0.5137493968887199, privacy_risk=0.5124929099348087, accuracy=0.5122887864823349, tpr_ind=0.7402946828955798, tnr_ind=0.2846911369740376, test_train_ratio=1.0017937219730941, dataset_size=[7805, 7819]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.09409218, 0.09994907, 0.10898905, 0.11331805,\n",
       "                     0.1157372 , 0.11751974, 0.12554113, 0.13318054, 0.14056532,\n",
       "                     0.14222052, 0.14502165, 0.14565826, 0.14667685, 0.15151515,\n",
       "                     0.15329768, 0.16526611, 0.18818436, 0.19887955, 0.20320856,\n",
       "                     0.20588235, 0.20944742, 0.23045582, 0.23312962, 0.23567609,\n",
       "                     0.24611663, 0.24637128, 0.25795773, 0.26241406, 0.27005348,\n",
       "                     0.27514642, 0.27998472, 0.28558696, 0.29208047, 0.30723198,\n",
       "                     0.31690858, 0.34479246, 0.35701553, 0.3864273 , 0.39533995,\n",
       "                     0.40552585, 0.41112809, 0.416603  , 0.41953145, 0.42220525,\n",
       "                     0.42398778, 0.4289534 , 0.43621085, 0.4402852 , 0.45199898,\n",
       "                     0.47109753, 0.47453527, 0.48523046, 0.56926407, 0.57563025,\n",
       "                     0.57754011, 0.58161446, 0.587726  , 0.61344538, 0.62044818,\n",
       "                     0.62312198, 0.63852814, 0.64604023, 0.65622613, 0.66870385,\n",
       "                     0.67748918, 0.68220015, 0.68525592, 0.69302266, 0.69467787,\n",
       "                     0.69658773, 0.71148459, 0.72803667, 0.73924115, 0.74178762,\n",
       "                     0.75235549, 0.76075885, 0.7696715 , 0.76992615, 0.77209065,\n",
       "                     0.7745098 , 0.79309906, 0.80061115, 0.81181564, 0.81792717,\n",
       "                     0.82352941, 0.83078686, 0.87764197, 0.88795518, 0.89393939,\n",
       "                     0.89521263, 0.89584925, 0.90297937, 0.90425261, 0.90807232,\n",
       "                     0.90947288, 0.9127833 , 0.91392921, 0.92920805, 0.93175452,\n",
       "                     0.94576012, 0.96040234, 0.96256684, 0.96396741, 0.96511332,\n",
       "                     0.9666412 , 0.96765979, 0.973644  , 0.9741533 , 0.97695442,\n",
       "                     0.97720907, 0.97911892, 0.9854851 , 0.9859944 , 0.98752228,\n",
       "                     0.98930481, 0.9903234 , 0.99159664, 0.99185129, 0.99197861,\n",
       "                     0.9929972 , 0.99312452, 1.        ]), tpr=array([0.        , 0.0978121 , 0.1037323 , 0.11377091, 0.11969112,\n",
       "                     0.12175032, 0.12368082, 0.13320463, 0.14002574, 0.15057915,\n",
       "                     0.15315315, 0.15559846, 0.15675676, 0.15778636, 0.16486486,\n",
       "                     0.16563707, 0.17940798, 0.20527671, 0.21647362, 0.22059202,\n",
       "                     0.22329472, 0.22664093, 0.24787645, 0.25096525, 0.25392535,\n",
       "                     0.26679537, 0.26795367, 0.27940798, 0.28455598, 0.29086229,\n",
       "                     0.2966538 , 0.3019305 , 0.30862291, 0.31492921, 0.32998713,\n",
       "                     0.34079794, 0.36615187, 0.37979408, 0.40682111, 0.41518662,\n",
       "                     0.42882883, 0.43526384, 0.43938224, 0.44195624, 0.44478764,\n",
       "                     0.44646075, 0.45212355, 0.45958816, 0.46486486, 0.47631918,\n",
       "                     0.49202059, 0.49446589, 0.50617761, 0.59407979, 0.601287  ,\n",
       "                     0.6043758 , 0.60939511, 0.61660232, 0.64092664, 0.64658945,\n",
       "                     0.64954955, 0.66293436, 0.67142857, 0.68069498, 0.69395109,\n",
       "                     0.7024453 , 0.70965251, 0.71209781, 0.72162162, 0.72419562,\n",
       "                     0.72767053, 0.74054054, 0.75637066, 0.76743887, 0.77027027,\n",
       "                     0.78249678, 0.79343629, 0.8024453 , 0.8034749 , 0.80592021,\n",
       "                     0.80810811, 0.82226512, 0.82844273, 0.83951094, 0.84465894,\n",
       "                     0.84864865, 0.85842986, 0.9029601 , 0.91184041, 0.91570142,\n",
       "                     0.91724582, 0.91840412, 0.92458172, 0.92586873, 0.92857143,\n",
       "                     0.93024453, 0.93346203, 0.93462033, 0.95315315, 0.95469755,\n",
       "                     0.96679537, 0.97915058, 0.98133848, 0.98211068, 0.98339768,\n",
       "                     0.98442728, 0.98532819, 0.98957529, 0.98983269, 0.99176319,\n",
       "                     0.99214929, 0.99317889, 0.9954955 , 0.9957529 , 0.9970399 ,\n",
       "                     0.9979408 , 0.9984556 , 0.9990991 , 0.9993565 , 0.9996139 ,\n",
       "                     0.9998713 , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.15062052e-02, -3.77403280e-02,\n",
       "                     -4.25596144e-02, -6.06246218e-02, -6.45385211e-02, -7.79615415e-02,\n",
       "                     -9.01510970e-02, -9.30904231e-02, -9.53101798e-02, -1.00083459e-01,\n",
       "                     -1.05360516e-01, -1.17783036e-01, -1.19801200e-01, -1.54150680e-01,\n",
       "                     -1.63453072e-01, -1.64755233e-01, -1.68820870e-01, -1.71850257e-01,\n",
       "                     -1.74353387e-01, -1.75890666e-01, -1.82321557e-01, -1.89242000e-01,\n",
       "                     -1.96710294e-01, -1.98850859e-01, -2.00670695e-01, -2.11843996e-01,\n",
       "                     -2.23143551e-01, -2.35314087e-01, -2.36388778e-01, -2.37671652e-01,\n",
       "                     -2.38411023e-01, -2.51314428e-01, -2.55105902e-01, -2.69663567e-01,\n",
       "                     -2.77477902e-01, -2.85320796e-01, -2.87682072e-01, -2.91520849e-01,\n",
       "                     -2.92387963e-01, -2.92669614e-01, -2.95464213e-01, -3.00104592e-01,\n",
       "                     -3.10154928e-01, -3.25422400e-01, -3.26684230e-01, -3.46276237e-01,\n",
       "                     -3.46870944e-01, -3.47645537e-01, -3.49270550e-01, -3.51397887e-01,\n",
       "                     -3.56674944e-01, -3.65131037e-01, -3.69097464e-01, -3.77294231e-01,\n",
       "                     -3.79489622e-01, -3.81367557e-01, -3.89464767e-01, -3.90197636e-01,\n",
       "                     -3.90866309e-01, -3.92561703e-01, -3.95312737e-01, -4.05465108e-01,\n",
       "                     -4.08696129e-01, -4.15515444e-01, -4.17299566e-01, -4.22856851e-01,\n",
       "                     -4.32133355e-01, -4.38254931e-01, -4.41832752e-01, -4.44685821e-01,\n",
       "                     -4.50505834e-01, -4.50927482e-01, -4.64305608e-01, -4.70003629e-01,\n",
       "                     -4.77329669e-01, -4.78892577e-01, -4.85507816e-01, -4.89548225e-01,\n",
       "                     -4.98991166e-01, -5.03526321e-01, -5.10825624e-01, -5.22386446e-01,\n",
       "                     -5.30628251e-01, -5.36304709e-01, -5.36801110e-01, -5.40440544e-01,\n",
       "                     -5.45016989e-01, -5.50046337e-01, -5.59615788e-01, -5.75364145e-01,\n",
       "                     -5.83146285e-01, -5.87786665e-01, -5.93063722e-01, -6.13104473e-01,\n",
       "                     -6.31271777e-01, -6.35988767e-01, -6.43314807e-01, -6.50587566e-01,\n",
       "                     -6.93147181e-01, -7.13766468e-01, -7.22134717e-01, -7.73189888e-01,\n",
       "                     -7.88457360e-01, -8.10930216e-01, -8.26678573e-01, -8.47297860e-01,\n",
       "                     -9.16290732e-01, -9.55511445e-01, -9.80829253e-01, -1.01160091e+00,\n",
       "                     -1.09861229e+00, -1.25276297e+00, -1.30833282e+00, -1.31218639e+00,\n",
       "                     -1.32175584e+00, -1.38629436e+00, -1.60943791e+00, -1.70474809e+00,\n",
       "                     -1.79175947e+00, -1.94591015e+00, -3.45387764e+01]), auc_score=0.5202611265636475, privacy_risk=0.5169147757383051, accuracy=0.5153609831029186, tpr_ind=0.805920205920206, tnr_ind=0.22790934555640438, test_train_ratio=1.0108108108108107, dataset_size=[7770, 7854]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.09086307, 0.09946849, 0.10174639, 0.1030119 ,\n",
       "                     0.10364465, 0.11161731, 0.12022273, 0.12401924, 0.1319919 ,\n",
       "                     0.1337636 , 0.13591496, 0.13692736, 0.16173121, 0.16540116,\n",
       "                     0.17185523, 0.17641104, 0.17805619, 0.18008099, 0.18046064,\n",
       "                     0.19197671, 0.19463427, 0.19944318, 0.20222728, 0.2080486 ,\n",
       "                     0.20944065, 0.21336371, 0.21640091, 0.22184257, 0.25107568,\n",
       "                     0.25360668, 0.26056695, 0.26714756, 0.29840547, 0.31523665,\n",
       "                     0.31991901, 0.32308276, 0.32447482, 0.32548722, 0.33308023,\n",
       "                     0.33991395, 0.3418122 , 0.34839281, 0.35231587, 0.36686915,\n",
       "                     0.37205771, 0.37838522, 0.39028094, 0.39433055, 0.39825361,\n",
       "                     0.40445457, 0.41533789, 0.41837509, 0.42811946, 0.43305492,\n",
       "                     0.4473551 , 0.46102253, 0.46241458, 0.47519615, 0.48380157,\n",
       "                     0.49025563, 0.49278664, 0.49784865, 0.5012655 , 0.50784611,\n",
       "                     0.50974437, 0.51910909, 0.53277651, 0.53720577, 0.54859529,\n",
       "                     0.56454062, 0.56681853, 0.58643381, 0.58769932, 0.59719058,\n",
       "                     0.60237914, 0.6302202 , 0.63756011, 0.64692483, 0.65515059,\n",
       "                     0.66109846, 0.66679322, 0.67274108, 0.67754999, 0.67944824,\n",
       "                     0.6828651 , 0.68678815, 0.69007846, 0.70020248, 0.70134143,\n",
       "                     0.70248038, 0.70349279, 0.70615034, 0.71665401, 0.71981777,\n",
       "                     0.72120982, 0.73082764, 0.73917995, 0.74360921, 0.74930397,\n",
       "                     0.76107315, 0.76714756, 0.77258922, 0.80498608, 0.80675778,\n",
       "                     0.81232599, 0.83776259, 0.83991395, 0.843837  , 0.84712731,\n",
       "                     0.85522652, 0.8659833 , 0.86712225, 0.8682612 , 0.87686662,\n",
       "                     0.87990382, 0.88192863, 0.88458618, 0.88762339, 0.89116679,\n",
       "                     0.89331815, 0.8939509 , 0.89939256, 0.90901038, 0.91027588,\n",
       "                     0.91305998, 0.92571501, 0.92976462, 0.93381422, 0.94381169,\n",
       "                     0.94596305, 0.94798785, 0.95064541, 0.95165781, 0.95418881,\n",
       "                     0.95798532, 0.96038977, 0.96152873, 0.96254113, 0.96266768,\n",
       "                     0.96785624, 0.97064034, 0.9727917 , 0.97443685, 0.97747406,\n",
       "                     0.97911921, 0.98013161, 0.98329537, 0.98418122, 0.98519362,\n",
       "                     0.98645912, 0.98987598, 0.99076183, 0.99101493, 0.99126803,\n",
       "                     1.        ]), tpr=array([0.        , 0.08793059, 0.0959596 , 0.0990676 , 0.1010101 ,\n",
       "                     0.1026936 , 0.11098161, 0.12211862, 0.12522663, 0.13377363,\n",
       "                     0.13610464, 0.14037814, 0.14141414, 0.16601917, 0.17055167,\n",
       "                     0.17767418, 0.18427868, 0.18751619, 0.18971769, 0.19114219,\n",
       "                     0.2035742 , 0.20681171, 0.21238021, 0.21484071, 0.22092722,\n",
       "                     0.22274022, 0.22740223, 0.23141673, 0.23646724, 0.26806527,\n",
       "                     0.27026677, 0.27881378, 0.28723129, 0.31986532, 0.33838384,\n",
       "                     0.34239834, 0.34589485, 0.34783735, 0.34926185, 0.35767936,\n",
       "                     0.36687387, 0.36868687, 0.37619788, 0.37839938, 0.3969179 ,\n",
       "                     0.4030044 , 0.41064491, 0.42268842, 0.42864543, 0.43382543,\n",
       "                     0.43965294, 0.45182595, 0.45519296, 0.46620047, 0.47215747,\n",
       "                     0.48899249, 0.502849  , 0.5047915 , 0.51800052, 0.52667703,\n",
       "                     0.53367003, 0.53651904, 0.54351204, 0.54623155, 0.55218855,\n",
       "                     0.55426055, 0.56241906, 0.57536908, 0.57938358, 0.58935509,\n",
       "                     0.6046361 , 0.60657861, 0.62587413, 0.62807563, 0.63714064,\n",
       "                     0.64257964, 0.66925667, 0.67586118, 0.68622119, 0.69450919,\n",
       "                     0.6996892 , 0.7046102 , 0.71095571, 0.71574722, 0.71885522,\n",
       "                     0.72338772, 0.72804973, 0.73128723, 0.74190624, 0.74281274,\n",
       "                     0.74436674, 0.74566175, 0.74928775, 0.76120176, 0.76353276,\n",
       "                     0.76521627, 0.77195027, 0.78049728, 0.78490028, 0.78917379,\n",
       "                     0.7986273 , 0.8038073 , 0.80872831, 0.84097384, 0.84265734,\n",
       "                     0.84693085, 0.86972287, 0.87101787, 0.87490287, 0.87801088,\n",
       "                     0.88720539, 0.8958819 , 0.8970474 , 0.8988604 , 0.9045584 ,\n",
       "                     0.90779591, 0.91064491, 0.91284641, 0.91595442, 0.92126392,\n",
       "                     0.92488992, 0.92592593, 0.92942243, 0.93667444, 0.93796944,\n",
       "                     0.94107744, 0.95066045, 0.95584046, 0.95972546, 0.96632997,\n",
       "                     0.96827247, 0.96917897, 0.97086247, 0.97163947, 0.97422947,\n",
       "                     0.97720798, 0.97927998, 0.98057498, 0.98225848, 0.98264698,\n",
       "                     0.98549599, 0.98730899, 0.98873349, 0.99028749, 0.99222999,\n",
       "                     0.99391349, 0.99469049, 0.9965035 , 0.9972805 , 0.9977985 ,\n",
       "                     0.9985755 , 0.9993525 , 0.9996115 , 0.9998705 , 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.17486983e-02, -4.08219945e-02,\n",
       "                     -6.45385211e-02, -7.41079722e-02, -7.52234212e-02, -7.82521969e-02,\n",
       "                     -8.00427077e-02, -8.70113770e-02, -1.05360516e-01, -1.14410351e-01,\n",
       "                     -1.17783036e-01, -1.32873281e-01, -1.33531393e-01, -1.35801541e-01,\n",
       "                     -1.45711811e-01, -1.48420005e-01, -1.62518929e-01, -1.67054085e-01,\n",
       "                     -1.71850257e-01, -1.82321557e-01, -1.90043603e-01, -1.91055237e-01,\n",
       "                     -1.92903666e-01, -1.94156014e-01, -2.00670695e-01, -2.03598955e-01,\n",
       "                     -2.07639365e-01, -2.09942039e-01, -2.11309094e-01, -2.17064505e-01,\n",
       "                     -2.20061885e-01, -2.23143551e-01, -2.24541176e-01, -2.29574442e-01,\n",
       "                     -2.30523659e-01, -2.36388778e-01, -2.41162057e-01, -2.44453338e-01,\n",
       "                     -2.48179629e-01, -2.51314428e-01, -2.57045103e-01, -2.57829109e-01,\n",
       "                     -2.73597333e-01, -2.76986783e-01, -2.79171383e-01, -2.87682072e-01,\n",
       "                     -3.14493330e-01, -3.18453731e-01, -3.20471895e-01, -3.24239668e-01,\n",
       "                     -3.25422400e-01, -3.28033368e-01, -3.30241687e-01, -3.30962581e-01,\n",
       "                     -3.31117471e-01, -3.36472237e-01, -3.37871817e-01, -3.38602163e-01,\n",
       "                     -3.41749294e-01, -3.42944751e-01, -3.54821375e-01, -3.56674944e-01,\n",
       "                     -3.61013346e-01, -3.62905494e-01, -3.67724780e-01, -3.71563556e-01,\n",
       "                     -3.72675285e-01, -3.74693449e-01, -3.82606970e-01, -3.82992252e-01,\n",
       "                     -3.85125424e-01, -3.85662481e-01, -3.86233746e-01, -3.89464767e-01,\n",
       "                     -4.05465108e-01, -4.11979789e-01, -4.13763911e-01, -4.15827895e-01,\n",
       "                     -4.21994410e-01, -4.22856851e-01, -4.25667815e-01, -4.32133355e-01,\n",
       "                     -4.32864082e-01, -4.33635985e-01, -4.41832752e-01, -4.44685821e-01,\n",
       "                     -4.45311017e-01, -4.51985124e-01, -4.59532329e-01, -4.70003629e-01,\n",
       "                     -4.74457980e-01, -4.75423697e-01, -4.76924072e-01, -4.79573080e-01,\n",
       "                     -4.91407538e-01, -4.92476485e-01, -4.98991166e-01, -5.10825624e-01,\n",
       "                     -5.13561604e-01, -5.15813165e-01, -5.21296924e-01, -5.25179937e-01,\n",
       "                     -5.26093096e-01, -5.28844129e-01, -5.29959578e-01, -5.30628251e-01,\n",
       "                     -5.50046337e-01, -5.59615788e-01, -5.65633860e-01, -5.65992005e-01,\n",
       "                     -5.75364145e-01, -5.79818495e-01, -5.85258219e-01, -5.87786665e-01,\n",
       "                     -5.97837001e-01, -6.00773860e-01, -6.06135804e-01, -6.17161274e-01,\n",
       "                     -6.19039208e-01, -6.28608659e-01, -6.35988767e-01, -6.38087403e-01,\n",
       "                     -6.41853886e-01, -6.72093771e-01, -6.93147181e-01, -7.05569701e-01,\n",
       "                     -7.25937003e-01, -7.41003202e-01, -7.57685702e-01, -7.62140052e-01,\n",
       "                     -7.67255153e-01, -7.73189888e-01, -7.88457360e-01, -7.96331417e-01,\n",
       "                     -8.10930216e-01, -8.32909123e-01, -8.36248024e-01, -8.47297860e-01,\n",
       "                     -8.60201265e-01, -8.87303195e-01, -8.97941593e-01, -9.16290732e-01,\n",
       "                     -9.29535959e-01, -9.61411167e-01, -9.80829253e-01, -1.09861229e+00,\n",
       "                     -1.20397280e+00, -1.25276297e+00, -1.29928298e+00, -1.38629436e+00,\n",
       "                     -1.50407740e+00, -1.79175947e+00, -2.30258509e+00, -3.45387764e+01]), auc_score=0.5260778304627962, privacy_risk=0.5228316987998081, accuracy=0.5225934459805428, tpr_ind=0.5435120435120435, tnr_ind=0.5021513540875727, test_train_ratio=1.0233100233100234, dataset_size=[7722, 7902]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.06753616, 0.0741219 , 0.08238636, 0.08496901,\n",
       "                     0.09000517, 0.10808368, 0.11608988, 0.11841426, 0.12525826,\n",
       "                     0.12745351, 0.12874483, 0.12990702, 0.13119835, 0.15870351,\n",
       "                     0.16438533, 0.17755682, 0.18104339, 0.18504649, 0.19085744,\n",
       "                     0.19356921, 0.20015496, 0.2115186 , 0.21255165, 0.21965393,\n",
       "                     0.22172004, 0.22469008, 0.22727273, 0.23566632, 0.24832128,\n",
       "                     0.25142045, 0.26045971, 0.26407541, 0.26717459, 0.26975723,\n",
       "                     0.27543905, 0.28370351, 0.29467975, 0.32076446, 0.33522727,\n",
       "                     0.33897211, 0.34297521, 0.3513688 , 0.35769628, 0.35834194,\n",
       "                     0.3793905 , 0.40302169, 0.44795971, 0.46022727, 0.4651343 ,\n",
       "                     0.46642562, 0.47326963, 0.48101756, 0.54016012, 0.54364669,\n",
       "                     0.57141012, 0.57554236, 0.58070764, 0.59620351, 0.6013688 ,\n",
       "                     0.60666322, 0.61105372, 0.61957645, 0.62487087, 0.63003616,\n",
       "                     0.63739669, 0.63997934, 0.66619318, 0.67032541, 0.67252066,\n",
       "                     0.68853306, 0.69369835, 0.69653926, 0.70222107, 0.70364153,\n",
       "                     0.70893595, 0.7111312 , 0.72107438, 0.72585227, 0.7419938 ,\n",
       "                     0.74909607, 0.75142045, 0.76691632, 0.76936983, 0.78473657,\n",
       "                     0.79610021, 0.79661674, 0.82528409, 0.82618802, 0.83858471,\n",
       "                     0.85201446, 0.86686467, 0.87009298, 0.87073864, 0.87332128,\n",
       "                     0.87603306, 0.8790031 , 0.90069731, 0.9098657 , 0.91477273,\n",
       "                     0.91567665, 0.91606405, 0.91877583, 0.91916322, 0.92768595,\n",
       "                     0.93001033, 0.93168905, 0.93775826, 0.9455062 , 0.9571281 ,\n",
       "                     0.95803202, 0.96048554, 0.96345558, 0.96629649, 0.96784607,\n",
       "                     0.96978306, 0.97301136, 0.97572314, 0.9767562 , 0.97869318,\n",
       "                     0.98514979, 0.98540806, 0.98592459, 0.98657025, 0.98850723,\n",
       "                     0.98941116, 0.99057335, 0.99121901, 0.99212293, 1.        ]), tpr=array([0.        , 0.06979695, 0.07690355, 0.08337563, 0.08642132,\n",
       "                     0.09352792, 0.11408629, 0.12093909, 0.12423858, 0.1322335 ,\n",
       "                     0.13540609, 0.13819797, 0.13946701, 0.14149746, 0.17030457,\n",
       "                     0.17741117, 0.19213198, 0.19467005, 0.19796954, 0.20279188,\n",
       "                     0.20812183, 0.21484772, 0.22449239, 0.22652284, 0.23375635,\n",
       "                     0.23895939, 0.24213198, 0.24517766, 0.2535533 , 0.26662437,\n",
       "                     0.26928934, 0.27664975, 0.28121827, 0.28515228, 0.28654822,\n",
       "                     0.2928934 , 0.30190355, 0.3143401 , 0.34175127, 0.3569797 ,\n",
       "                     0.35989848, 0.36446701, 0.37271574, 0.37791878, 0.37906091,\n",
       "                     0.39873096, 0.42347716, 0.46700508, 0.48007614, 0.48604061,\n",
       "                     0.48743655, 0.49403553, 0.50317259, 0.56967005, 0.57360406,\n",
       "                     0.59911168, 0.60418782, 0.61142132, 0.62449239, 0.62880711,\n",
       "                     0.63451777, 0.63895939, 0.6498731 , 0.65824873, 0.66370558,\n",
       "                     0.67220812, 0.67360406, 0.69593909, 0.70025381, 0.70266497,\n",
       "                     0.71611675, 0.72182741, 0.72449239, 0.73020305, 0.73185279,\n",
       "                     0.73604061, 0.73946701, 0.74873096, 0.75253807, 0.77043147,\n",
       "                     0.77664975, 0.77880711, 0.79314721, 0.79568528, 0.81053299,\n",
       "                     0.82246193, 0.82347716, 0.85025381, 0.85253807, 0.86598985,\n",
       "                     0.87703046, 0.89060914, 0.89390863, 0.89517766, 0.89822335,\n",
       "                     0.90050761, 0.9035533 , 0.925     , 0.93426396, 0.93743655,\n",
       "                     0.93857868, 0.9392132 , 0.94137056, 0.94213198, 0.94923858,\n",
       "                     0.95114213, 0.95279188, 0.95812183, 0.96535533, 0.97525381,\n",
       "                     0.97626904, 0.9785533 , 0.98058376, 0.98236041, 0.98350254,\n",
       "                     0.98553299, 0.98807107, 0.99098985, 0.99175127, 0.9930203 ,\n",
       "                     0.99708122, 0.99746193, 0.99771574, 0.99809645, 0.99898477,\n",
       "                     0.99923858, 0.99961929, 0.9998731 , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.76995771e-02, -1.94180859e-02,\n",
       "                     -4.08219945e-02, -5.21857532e-02, -5.40672213e-02, -7.14589640e-02,\n",
       "                     -7.41079722e-02, -7.63729788e-02, -7.69610411e-02, -8.70113770e-02,\n",
       "                     -9.53101798e-02, -1.17783036e-01, -1.24126067e-01, -1.33531393e-01,\n",
       "                     -1.36758937e-01, -1.39761942e-01, -1.43100844e-01, -1.46603474e-01,\n",
       "                     -1.54150680e-01, -1.56842471e-01, -1.57903029e-01, -1.71850257e-01,\n",
       "                     -1.76456437e-01, -1.78248231e-01, -1.82321557e-01, -1.89242000e-01,\n",
       "                     -1.92371893e-01, -2.09458098e-01, -2.13574100e-01, -2.16223108e-01,\n",
       "                     -2.23143551e-01, -2.29574442e-01, -2.41162057e-01, -2.46860078e-01,\n",
       "                     -2.48179629e-01, -2.51314428e-01, -2.52342706e-01, -2.62364264e-01,\n",
       "                     -2.65703166e-01, -2.66628663e-01, -2.68263987e-01, -2.75411980e-01,\n",
       "                     -2.87682072e-01, -2.94112963e-01, -2.95344945e-01, -3.06455187e-01,\n",
       "                     -3.06913434e-01, -3.08735482e-01, -3.10154928e-01, -3.11436158e-01,\n",
       "                     -3.18453731e-01, -3.23299708e-01, -3.27212911e-01, -3.31484695e-01,\n",
       "                     -3.36472237e-01, -3.38975367e-01, -3.42004754e-01, -3.44840486e-01,\n",
       "                     -3.52220594e-01, -3.56674944e-01, -3.57837059e-01, -3.64222150e-01,\n",
       "                     -3.65934269e-01, -3.70018359e-01, -3.74693449e-01, -3.82475590e-01,\n",
       "                     -3.85662481e-01, -3.87765531e-01, -4.05465108e-01, -4.12845215e-01,\n",
       "                     -4.21213465e-01, -4.27444015e-01, -4.30782916e-01, -4.35318071e-01,\n",
       "                     -4.41832752e-01, -4.45739007e-01, -4.48950220e-01, -4.49402811e-01,\n",
       "                     -4.51985124e-01, -4.62623522e-01, -4.65569032e-01, -4.70003629e-01,\n",
       "                     -4.74268028e-01, -4.80585739e-01, -4.85507816e-01, -4.91686284e-01,\n",
       "                     -5.10825624e-01, -5.12710638e-01, -5.24524468e-01, -5.25668197e-01,\n",
       "                     -5.26093096e-01, -5.30628251e-01, -5.35518236e-01, -5.43615447e-01,\n",
       "                     -5.59615788e-01, -5.60460739e-01, -5.61570823e-01, -5.65313809e-01,\n",
       "                     -5.75364145e-01, -5.87786665e-01, -6.00773860e-01, -6.06135804e-01,\n",
       "                     -6.19039208e-01, -6.24154309e-01, -6.53926467e-01, -6.69049629e-01,\n",
       "                     -6.75447603e-01, -6.93147181e-01, -7.53771802e-01, -7.98507696e-01,\n",
       "                     -8.10930216e-01, -8.26678573e-01, -8.47297860e-01, -8.64997437e-01,\n",
       "                     -9.16290732e-01, -9.75379648e-01, -9.80829253e-01, -1.02961942e+00,\n",
       "                     -1.09861229e+00, -1.20397280e+00, -1.25276297e+00, -1.29928298e+00,\n",
       "                     -1.38629436e+00, -1.60943791e+00, -1.79175947e+00, -1.94591015e+00,\n",
       "                     -2.07944154e+00, -3.45387764e+01]), auc_score=0.5199174668058062, privacy_risk=0.5174057138062675, accuracy=0.5187532002048131, tpr_ind=0.6722081218274112, tnr_ind=0.36260330578512395, test_train_ratio=0.9827411167512691, dataset_size=[7880, 7744]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.08260646, 0.09953822, 0.1018471 , 0.10915854,\n",
       "                     0.11390457, 0.1230118 , 0.12442278, 0.12570549, 0.12865572,\n",
       "                     0.13019497, 0.13134941, 0.13340174, 0.13609543, 0.13763468,\n",
       "                     0.14122627, 0.14379169, 0.16700872, 0.1684197 , 0.17111339,\n",
       "                     0.17534633, 0.17650077, 0.18496665, 0.1874038 , 0.20844023,\n",
       "                     0.25166752, 0.25371986, 0.26141611, 0.26898409, 0.27719343,\n",
       "                     0.29451001, 0.29579271, 0.29617753, 0.30297589, 0.32734736,\n",
       "                     0.3306824 , 0.33658286, 0.33876347, 0.34325295, 0.35005131,\n",
       "                     0.35236018, 0.37172909, 0.37352488, 0.37621857, 0.38686506,\n",
       "                     0.39558748, 0.39917907, 0.41816316, 0.42868138, 0.43265777,\n",
       "                     0.43483838, 0.47716778, 0.48486403, 0.48845562, 0.50769625,\n",
       "                     0.51154438, 0.5150077 , 0.55592612, 0.55695228, 0.57067727,\n",
       "                     0.57247306, 0.58401744, 0.58530015, 0.5868394 , 0.59017445,\n",
       "                     0.61570036, 0.6362237 , 0.65020523, 0.68753207, 0.70497691,\n",
       "                     0.70574654, 0.72691124, 0.73140072, 0.73614674, 0.74153412,\n",
       "                     0.75820934, 0.76898409, 0.77296049, 0.77526937, 0.77706516,\n",
       "                     0.78142637, 0.78335044, 0.80374551, 0.81400718, 0.82183171,\n",
       "                     0.82349923, 0.85133402, 0.86518728, 0.86852232, 0.8831452 ,\n",
       "                     0.88481272, 0.88635198, 0.89122627, 0.89353515, 0.90084659,\n",
       "                     0.91046691, 0.91213443, 0.91906106, 0.91944587, 0.92060031,\n",
       "                     0.92380708, 0.93009236, 0.93150334, 0.93612109, 0.93817342,\n",
       "                     0.94856337, 0.95125705, 0.95356593, 0.95972293, 0.96062083,\n",
       "                     0.961647  , 0.96613648, 0.97408928, 0.97652642, 0.9779374 ,\n",
       "                     0.97909184, 0.98063109, 0.98165726, 0.9828117 , 0.98537712,\n",
       "                     0.98614674, 0.98755772, 0.98768599, 0.98948179, 0.99127758,\n",
       "                     0.99140585, 0.99191893, 1.        ]), tpr=array([0.        , 0.09261625, 0.10871231, 0.11165049, 0.11714359,\n",
       "                     0.12225345, 0.13132345, 0.1333674 , 0.1352836 , 0.13873275,\n",
       "                     0.14154318, 0.14282064, 0.14524783, 0.14997445, 0.15112417,\n",
       "                     0.15431783, 0.15738375, 0.18306081, 0.18497701, 0.18778743,\n",
       "                     0.19494124, 0.19749617, 0.20669392, 0.20873786, 0.22917731,\n",
       "                     0.28244762, 0.28525805, 0.29688298, 0.30659172, 0.31463975,\n",
       "                     0.33214103, 0.33354624, 0.33444047, 0.34197752, 0.36522739,\n",
       "                     0.36905979, 0.37672458, 0.38030148, 0.38541134, 0.39128769,\n",
       "                     0.39397036, 0.41338784, 0.41632601, 0.41888094, 0.43050588,\n",
       "                     0.43868166, 0.44328053, 0.46257026, 0.47304548, 0.47815534,\n",
       "                     0.48185999, 0.52235565, 0.53449157, 0.53768523, 0.55659172,\n",
       "                     0.55876341, 0.5611906 , 0.59810935, 0.59900358, 0.61267246,\n",
       "                     0.6149719 , 0.62646909, 0.62812979, 0.63004599, 0.63247317,\n",
       "                     0.65674502, 0.67462954, 0.68702095, 0.73019928, 0.74693408,\n",
       "                     0.7480838 , 0.76686254, 0.77133367, 0.77554931, 0.78078692,\n",
       "                     0.79931017, 0.80952989, 0.8131068 , 0.81540623, 0.81642821,\n",
       "                     0.8202606 , 0.82243229, 0.84133878, 0.85321921, 0.86126725,\n",
       "                     0.86267246, 0.88656106, 0.898186  , 0.90074093, 0.91096065,\n",
       "                     0.91262136, 0.91377108, 0.91785897, 0.91977517, 0.92705672,\n",
       "                     0.93753194, 0.9390649 , 0.94302504, 0.94391926, 0.94506898,\n",
       "                     0.94749617, 0.95375575, 0.9555442 , 0.95950434, 0.96154829,\n",
       "                     0.96972407, 0.97176801, 0.97304548, 0.9777721 , 0.97879407,\n",
       "                     0.98019928, 0.98275422, 0.98811957, 0.99041901, 0.99144098,\n",
       "                     0.99207971, 0.99246295, 0.99335718, 0.99501788, 0.99693408,\n",
       "                     0.99744507, 0.99782831, 0.99833929, 0.99910577, 0.99974451,\n",
       "                     0.99987225, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.57483570e-02, -4.25596144e-02,\n",
       "                     -4.54623741e-02, -4.87901642e-02, -5.48082365e-02, -6.06246218e-02,\n",
       "                     -6.45385211e-02, -7.14589640e-02, -8.70113770e-02, -9.53101798e-02,\n",
       "                     -1.00083459e-01, -1.02654154e-01, -1.05360516e-01, -1.13328685e-01,\n",
       "                     -1.17783036e-01, -1.21645109e-01, -1.25163143e-01, -1.27833372e-01,\n",
       "                     -1.33531393e-01, -1.39761942e-01, -1.54150680e-01, -1.71850257e-01,\n",
       "                     -1.82321557e-01, -1.95424782e-01, -2.04794413e-01, -2.07639365e-01,\n",
       "                     -2.23143551e-01, -2.26313126e-01, -2.27513551e-01, -2.41162057e-01,\n",
       "                     -2.51314428e-01, -2.53195896e-01, -2.59825118e-01, -2.62364264e-01,\n",
       "                     -2.75103290e-01, -2.78713402e-01, -2.81412459e-01, -2.82232468e-01,\n",
       "                     -2.87682072e-01, -2.94239473e-01, -2.98492989e-01, -3.00104592e-01,\n",
       "                     -3.01324849e-01, -3.07025035e-01, -3.08301360e-01, -3.10596332e-01,\n",
       "                     -3.11779624e-01, -3.18453731e-01, -3.21583624e-01, -3.23317136e-01,\n",
       "                     -3.28925031e-01, -3.36472237e-01, -3.40325806e-01, -3.44840486e-01,\n",
       "                     -3.51397887e-01, -3.52166526e-01, -3.56674944e-01, -3.57609087e-01,\n",
       "                     -3.67724780e-01, -3.75387653e-01, -3.79489622e-01, -3.82992252e-01,\n",
       "                     -3.87765531e-01, -3.94882999e-01, -4.05465108e-01, -4.08895643e-01,\n",
       "                     -4.19177370e-01, -4.38008656e-01, -4.41832752e-01, -4.43289417e-01,\n",
       "                     -4.51985124e-01, -4.54736157e-01, -4.60815203e-01, -4.65683968e-01,\n",
       "                     -4.70003629e-01, -4.74457980e-01, -4.76924072e-01, -4.85507816e-01,\n",
       "                     -4.90622916e-01, -4.98991166e-01, -5.04045937e-01, -5.10825624e-01,\n",
       "                     -5.20304368e-01, -5.46543706e-01, -5.49634899e-01, -5.51735527e-01,\n",
       "                     -5.59615788e-01, -5.66733256e-01, -5.70544858e-01, -5.75364145e-01,\n",
       "                     -5.77315365e-01, -5.87786665e-01, -5.91677720e-01, -6.03916047e-01,\n",
       "                     -6.06135804e-01, -6.09064063e-01, -6.19039208e-01, -6.35988767e-01,\n",
       "                     -6.39079959e-01, -6.51474484e-01, -6.56779536e-01, -6.60357358e-01,\n",
       "                     -6.61398482e-01, -6.93147181e-01, -7.23918839e-01, -7.41937345e-01,\n",
       "                     -7.95801335e-01, -8.10930216e-01, -8.60201265e-01, -8.75468737e-01,\n",
       "                     -8.87303195e-01, -8.93817876e-01, -9.16290732e-01, -9.55511445e-01,\n",
       "                     -9.80829253e-01, -9.98528830e-01, -1.09861229e+00, -1.14209740e+00,\n",
       "                     -1.17865500e+00, -1.20397280e+00, -1.25276297e+00, -1.29928298e+00,\n",
       "                     -1.38629436e+00, -1.94591015e+00, -2.07944154e+00, -3.45387764e+01]), auc_score=0.5315037233957484, privacy_risk=0.5248137679451459, accuracy=0.5248335893497184, tpr_ind=0.5344915687276444, tnr_ind=0.5151359671626475, test_train_ratio=0.99591211037302, dataset_size=[7828, 7796]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.07801328, 0.09116445, 0.09435649, 0.1168284 ,\n",
       "                     0.11759448, 0.11861593, 0.12078652, 0.1386619 , 0.14006639,\n",
       "                     0.14300306, 0.15130235, 0.1523238 , 0.15704801, 0.15883555,\n",
       "                     0.16062308, 0.16675179, 0.17096527, 0.17173136, 0.17747702,\n",
       "                     0.17849847, 0.19203269, 0.20339632, 0.20390705, 0.20505618,\n",
       "                     0.20863126, 0.21756895, 0.22127171, 0.22701736, 0.23442288,\n",
       "                     0.23557201, 0.2418284 , 0.24680797, 0.25229826, 0.26251277,\n",
       "                     0.27400409, 0.28728294, 0.29353933, 0.29762513, 0.30298774,\n",
       "                     0.31052094, 0.31933095, 0.32392748, 0.32494893, 0.32980082,\n",
       "                     0.33133299, 0.34818693, 0.35406027, 0.36146578, 0.36350868,\n",
       "                     0.38623596, 0.42773238, 0.43271195, 0.45454545, 0.45607763,\n",
       "                     0.46156793, 0.4747191 , 0.4828907 , 0.50102145, 0.50153218,\n",
       "                     0.50497957, 0.5157048 , 0.52425945, 0.53319714, 0.5921859 ,\n",
       "                     0.59473953, 0.60406027, 0.62614913, 0.62717058, 0.63342697,\n",
       "                     0.63674668, 0.64862104, 0.66381512, 0.66790092, 0.67249745,\n",
       "                     0.67939224, 0.68079673, 0.68488253, 0.68539326, 0.73327375,\n",
       "                     0.7342952 , 0.73748723, 0.73927477, 0.74399898, 0.74604188,\n",
       "                     0.75383044, 0.77030133, 0.78128192, 0.79941267, 0.80081716,\n",
       "                     0.85214505, 0.85750766, 0.86159346, 0.87129724, 0.87308478,\n",
       "                     0.87614913, 0.88827886, 0.89262002, 0.89427988, 0.90040858,\n",
       "                     0.9023238 , 0.90257916, 0.90589888, 0.90806946, 0.91956078,\n",
       "                     0.92913687, 0.9351379 , 0.93615935, 0.94458631, 0.9549285 ,\n",
       "                     0.95569459, 0.95952503, 0.96054648, 0.96424923, 0.96539837,\n",
       "                     0.96807967, 0.97025026, 0.9706333 , 0.97395301, 0.9761236 ,\n",
       "                     0.9781665 , 0.98416752, 0.98595506, 0.98812564, 0.98850868,\n",
       "                     0.99004086, 0.9904239 , 0.99067926, 0.99093463, 0.99208376,\n",
       "                     0.99284985, 1.        ]), tpr=array([0.        , 0.08829569, 0.1026694 , 0.10600616, 0.13244353,\n",
       "                     0.1351386 , 0.13732033, 0.13924538, 0.15952259, 0.1613193 ,\n",
       "                     0.16439938, 0.1710729 , 0.17363963, 0.17851643, 0.18082649,\n",
       "                     0.18300821, 0.19032341, 0.19545688, 0.19738193, 0.20200205,\n",
       "                     0.20290041, 0.21573409, 0.22843943, 0.22920945, 0.23139117,\n",
       "                     0.23562628, 0.24679158, 0.25      , 0.25603183, 0.26591376,\n",
       "                     0.26706879, 0.27656571, 0.28092916, 0.28580595, 0.29684292,\n",
       "                     0.30710986, 0.32276694, 0.32956879, 0.33290554, 0.33842402,\n",
       "                     0.34381417, 0.35177105, 0.35703285, 0.35921458, 0.36524641,\n",
       "                     0.36781314, 0.38565195, 0.39027207, 0.40002567, 0.40400411,\n",
       "                     0.42748973, 0.47048255, 0.47471766, 0.49897331, 0.50192505,\n",
       "                     0.50834189, 0.52245893, 0.52964579, 0.54645791, 0.54735626,\n",
       "                     0.55120637, 0.56211499, 0.56994353, 0.57713039, 0.63282854,\n",
       "                     0.63539528, 0.64720226, 0.66876283, 0.67068789, 0.67723306,\n",
       "                     0.68044148, 0.69019507, 0.7039271 , 0.7073922 , 0.71278234,\n",
       "                     0.71894251, 0.72035421, 0.72433265, 0.72548768, 0.77194559,\n",
       "                     0.77284394, 0.77502567, 0.77784908, 0.78105749, 0.78323922,\n",
       "                     0.79196612, 0.80736653, 0.81840349, 0.83393224, 0.83662731,\n",
       "                     0.88347023, 0.88809035, 0.8914271 , 0.90195072, 0.90349076,\n",
       "                     0.90721253, 0.91876283, 0.92440965, 0.9263347 , 0.93159651,\n",
       "                     0.93377823, 0.93454825, 0.93814168, 0.93981006, 0.94776694,\n",
       "                     0.95444045, 0.9598306 , 0.96060062, 0.96804415, 0.97535934,\n",
       "                     0.97600103, 0.97908111, 0.97997947, 0.98305955, 0.98370123,\n",
       "                     0.98562628, 0.9863963 , 0.98780801, 0.99011807, 0.99165811,\n",
       "                     0.99281314, 0.99576489, 0.99704825, 0.99807495, 0.99833162,\n",
       "                     0.99910164, 0.99935832, 0.99961499, 0.99974333, 0.99987166,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -8.88894742e-03, -3.77403280e-02,\n",
       "                     -3.80998462e-02, -4.65200156e-02, -5.71584138e-02, -6.45385211e-02,\n",
       "                     -6.73036819e-02, -6.89928715e-02, -8.00427077e-02, -9.18075493e-02,\n",
       "                     -9.53101798e-02, -1.00083459e-01, -1.05360516e-01, -1.11225635e-01,\n",
       "                     -1.15831816e-01, -1.17783036e-01, -1.25163143e-01, -1.30053128e-01,\n",
       "                     -1.33531393e-01, -1.39761942e-01, -1.41078598e-01, -1.54150680e-01,\n",
       "                     -1.62518929e-01, -1.67054085e-01, -1.78482780e-01, -1.82321557e-01,\n",
       "                     -1.92903666e-01, -1.99489360e-01, -2.00670695e-01, -2.06794413e-01,\n",
       "                     -2.11309094e-01, -2.12561442e-01, -2.18481538e-01, -2.23143551e-01,\n",
       "                     -2.32931558e-01, -2.34400706e-01, -2.38411023e-01, -2.46133070e-01,\n",
       "                     -2.51314428e-01, -2.54892250e-01, -2.56719847e-01, -2.57829109e-01,\n",
       "                     -2.60726262e-01, -2.62364264e-01, -2.64023098e-01, -2.66628663e-01,\n",
       "                     -2.74436846e-01, -2.79584862e-01, -2.87682072e-01, -2.92892356e-01,\n",
       "                     -3.10154928e-01, -3.22773392e-01, -3.30241687e-01, -3.36472237e-01,\n",
       "                     -3.42944751e-01, -3.44096162e-01, -3.50549351e-01, -3.56674944e-01,\n",
       "                     -3.60002734e-01, -3.61369788e-01, -3.66462950e-01, -3.69097464e-01,\n",
       "                     -3.69495632e-01, -3.71563556e-01, -3.76051223e-01, -3.81367557e-01,\n",
       "                     -3.82992252e-01, -3.85662481e-01, -3.92042088e-01, -4.05465108e-01,\n",
       "                     -4.14767501e-01, -4.17735201e-01, -4.21213465e-01, -4.32864082e-01,\n",
       "                     -4.35318071e-01, -4.37213806e-01, -4.41832752e-01, -4.48715092e-01,\n",
       "                     -4.51985124e-01, -4.62623522e-01, -4.64305608e-01, -4.70003629e-01,\n",
       "                     -4.98991166e-01, -5.07880114e-01, -5.10825624e-01, -5.15466003e-01,\n",
       "                     -5.32085623e-01, -5.38996501e-01, -5.39453018e-01, -5.43615447e-01,\n",
       "                     -5.48565952e-01, -5.56125383e-01, -5.59615788e-01, -5.64529803e-01,\n",
       "                     -5.69094532e-01, -5.85258219e-01, -5.87786665e-01, -5.90493026e-01,\n",
       "                     -6.00773860e-01, -6.06135804e-01, -6.19039208e-01, -6.53926467e-01,\n",
       "                     -6.93147181e-01, -7.02716632e-01, -7.04981638e-01, -7.73189888e-01,\n",
       "                     -7.75838896e-01, -7.77230298e-01, -7.88457360e-01, -8.10930216e-01,\n",
       "                     -8.26678573e-01, -8.47297860e-01, -8.75468737e-01, -9.02867712e-01,\n",
       "                     -9.16290732e-01, -9.34309237e-01, -9.80829253e-01, -1.01160091e+00,\n",
       "                     -1.02165125e+00, -1.09861229e+00, -1.16315081e+00, -1.17865500e+00,\n",
       "                     -1.25276297e+00, -1.38629436e+00, -1.60943791e+00, -1.79175947e+00,\n",
       "                     -1.94591015e+00, -2.19722458e+00, -2.30258509e+00, -3.45387764e+01]), auc_score=0.5316979332932024, privacy_risk=0.5238699155572988, accuracy=0.523873527905786, tpr_ind=0.5224589322381931, tnr_ind=0.5252808988764045, test_train_ratio=1.0051334702258727, dataset_size=[7792, 7832]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.08262035, 0.08657898, 0.08747286, 0.09385774,\n",
       "                     0.09564551, 0.10930916, 0.11135232, 0.11416167, 0.11850338,\n",
       "                     0.12552675, 0.12782531, 0.12897459, 0.13089005, 0.14136126,\n",
       "                     0.14327672, 0.15732346, 0.17034861, 0.1713702 , 0.17813817,\n",
       "                     0.181586  , 0.18413996, 0.19129102, 0.192568  , 0.19550504,\n",
       "                     0.20035755, 0.20610395, 0.20763632, 0.21427659, 0.22027838,\n",
       "                     0.22487549, 0.22908952, 0.23215426, 0.23458051, 0.25743839,\n",
       "                     0.288852  , 0.29115056, 0.2994509 , 0.30519729, 0.3367386 ,\n",
       "                     0.34669902, 0.35372239, 0.35678713, 0.37300472, 0.38079428,\n",
       "                     0.38947772, 0.39215937, 0.39484102, 0.39701188, 0.40058741,\n",
       "                     0.40863236, 0.42280679, 0.42561614, 0.49010344, 0.51985698,\n",
       "                     0.52854042, 0.5455242 , 0.56276338, 0.57029754, 0.57961946,\n",
       "                     0.58408888, 0.58715362, 0.58740902, 0.59519857, 0.60209424,\n",
       "                     0.6043928 , 0.61128847, 0.61435321, 0.61843954, 0.62635679,\n",
       "                     0.63516792, 0.64270208, 0.67628655, 0.68126676, 0.70118759,\n",
       "                     0.70246456, 0.71382965, 0.71842677, 0.7217469 , 0.72340697,\n",
       "                     0.72902567, 0.7488188 , 0.75890691, 0.76759035, 0.77244286,\n",
       "                     0.78176478, 0.79274678, 0.79977014, 0.80117482, 0.81126293,\n",
       "                     0.81905248, 0.83080066, 0.83501469, 0.84586898, 0.85493551,\n",
       "                     0.85672328, 0.86374665, 0.87421785, 0.8823905 , 0.88315668,\n",
       "                     0.89924658, 0.90218363, 0.91278253, 0.91725195, 0.92644618,\n",
       "                     0.9411314 , 0.94189759, 0.94317456, 0.95926446, 0.9624569 ,\n",
       "                     0.96386158, 0.96488316, 0.96743711, 0.97011876, 0.97152343,\n",
       "                     0.97369429, 0.97433278, 0.97816371, 0.97956838, 0.98173924,\n",
       "                     0.98250543, 0.98531477, 0.98633636, 0.98684715, 0.9891457 ,\n",
       "                     0.99055038, 0.99157196, 0.99284893, 0.99310433, 1.        ]), tpr=array([0.        , 0.09444373, 0.09765174, 0.10047479, 0.1075324 ,\n",
       "                     0.10984217, 0.12254587, 0.124599  , 0.12819197, 0.13319646,\n",
       "                     0.13807263, 0.141024  , 0.14243552, 0.14371872, 0.15642243,\n",
       "                     0.15975876, 0.17502887, 0.1878609 , 0.18888746, 0.19466188,\n",
       "                     0.19645836, 0.20043629, 0.20980367, 0.21121519, 0.2150648 ,\n",
       "                     0.22109586, 0.22648531, 0.22764019, 0.23623765, 0.24188374,\n",
       "                     0.24637495, 0.25022456, 0.25458745, 0.25664057, 0.27999487,\n",
       "                     0.31399974, 0.31720775, 0.32708841, 0.33555755, 0.3681509 ,\n",
       "                     0.37649172, 0.38380598, 0.38662903, 0.40728859, 0.41575773,\n",
       "                     0.42615167, 0.42910304, 0.43154113, 0.43423585, 0.43872706,\n",
       "                     0.44411651, 0.45951495, 0.46169639, 0.53060439, 0.5553702 ,\n",
       "                     0.56255614, 0.57846786, 0.59553445, 0.60246375, 0.61080457,\n",
       "                     0.61503914, 0.61811882, 0.61978699, 0.63172078, 0.64044655,\n",
       "                     0.64288464, 0.64827409, 0.65173874, 0.65622995, 0.66174772,\n",
       "                     0.67034518, 0.67830104, 0.71063775, 0.71679713, 0.73566021,\n",
       "                     0.73707173, 0.74810728, 0.75157192, 0.75477993, 0.75747466,\n",
       "                     0.76247915, 0.78390864, 0.79327602, 0.80354164, 0.80854613,\n",
       "                     0.81675863, 0.82715257, 0.83202874, 0.83382523, 0.84255101,\n",
       "                     0.84986526, 0.85794944, 0.86128577, 0.87232131, 0.87976389,\n",
       "                     0.88181702, 0.89015783, 0.89952521, 0.90517131, 0.90581291,\n",
       "                     0.92082638, 0.92390607, 0.93365841, 0.93635314, 0.94777364,\n",
       "                     0.96124727, 0.96253048, 0.96484024, 0.97831387, 0.98062364,\n",
       "                     0.98190684, 0.98242012, 0.98408828, 0.98639805, 0.98703965,\n",
       "                     0.98947774, 0.99024766, 0.99255742, 0.9930707 , 0.99422559,\n",
       "                     0.99499551, 0.99704863, 0.99756191, 0.99781856, 0.99858848,\n",
       "                     0.99923008, 0.9993584 , 0.99987168, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.92207132e-02, -4.44517626e-02,\n",
       "                     -5.31098253e-02, -5.40672213e-02, -5.88405000e-02, -6.06246218e-02,\n",
       "                     -6.89928715e-02, -7.41079722e-02, -7.59859070e-02, -8.33816089e-02,\n",
       "                     -8.70113770e-02, -9.53101798e-02, -1.05360516e-01, -1.09199292e-01,\n",
       "                     -1.11225635e-01, -1.13328685e-01, -1.17783036e-01, -1.25163143e-01,\n",
       "                     -1.33531393e-01, -1.49531734e-01, -1.63887855e-01, -1.67054085e-01,\n",
       "                     -1.82321557e-01, -1.92903666e-01, -1.94156014e-01, -2.00670695e-01,\n",
       "                     -2.02026628e-01, -2.04794413e-01, -2.05852054e-01, -2.09720531e-01,\n",
       "                     -2.11309094e-01, -2.23143551e-01, -2.38411023e-01, -2.40353104e-01,\n",
       "                     -2.46860078e-01, -2.61364764e-01, -2.64692554e-01, -2.64784108e-01,\n",
       "                     -2.68263987e-01, -2.74436846e-01, -2.76253377e-01, -2.84571650e-01,\n",
       "                     -2.87682072e-01, -2.96898728e-01, -2.98492989e-01, -3.13657559e-01,\n",
       "                     -3.22773392e-01, -3.36472237e-01, -3.39867826e-01, -3.42406972e-01,\n",
       "                     -3.44840486e-01, -3.49948461e-01, -3.50437917e-01, -3.56674944e-01,\n",
       "                     -3.61501985e-01, -3.67146244e-01, -3.67724780e-01, -3.68907512e-01,\n",
       "                     -3.74693449e-01, -3.77294231e-01, -3.79489622e-01, -3.80055393e-01,\n",
       "                     -3.85662481e-01, -3.87765531e-01, -3.89464767e-01, -3.93042588e-01,\n",
       "                     -3.95895657e-01, -3.97682968e-01, -4.00477567e-01, -4.05465108e-01,\n",
       "                     -4.13370288e-01, -4.19258430e-01, -4.30102412e-01, -4.35318071e-01,\n",
       "                     -4.36001832e-01, -4.41832752e-01, -4.44685821e-01, -4.51985124e-01,\n",
       "                     -4.63572739e-01, -4.65502496e-01, -4.71714494e-01, -4.77785770e-01,\n",
       "                     -4.79573080e-01, -4.85507816e-01, -4.88352768e-01, -4.89548225e-01,\n",
       "                     -4.96436886e-01, -4.98991166e-01, -5.10825624e-01, -5.20304368e-01,\n",
       "                     -5.26093096e-01, -5.36085291e-01, -5.44727175e-01, -5.59615788e-01,\n",
       "                     -5.61811178e-01, -5.69352963e-01, -5.85258219e-01, -5.87786665e-01,\n",
       "                     -5.99118231e-01, -6.06135804e-01, -6.18026550e-01, -6.19039208e-01,\n",
       "                     -6.23351419e-01, -6.34306681e-01, -6.41853886e-01, -6.64976304e-01,\n",
       "                     -6.93147181e-01, -7.20546155e-01, -7.88457360e-01, -8.10930216e-01,\n",
       "                     -8.36248024e-01, -8.47297860e-01, -8.75468737e-01, -8.84202417e-01,\n",
       "                     -9.16290732e-01, -9.80829253e-01, -1.01160091e+00, -1.02165125e+00,\n",
       "                     -1.04145387e+00, -1.09861229e+00, -1.17865500e+00, -1.25276297e+00,\n",
       "                     -1.29928298e+00, -1.38629436e+00, -1.60943791e+00, -1.94591015e+00,\n",
       "                     -2.39789527e+00, -3.45387764e+01]), auc_score=0.5264168474459896, privacy_risk=0.520250476744033, accuracy=0.5202252944188428, tpr_ind=0.5306043885538304, tnr_ind=0.5098965649342357, test_train_ratio=1.0048761709226228, dataset_size=[7793, 7831]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.08132992, 0.09757033, 0.10664962, 0.11074169,\n",
       "                     0.11393862, 0.1157289 , 0.12749361, 0.13043478, 0.13734015,\n",
       "                     0.13925831, 0.14219949, 0.14219949, 0.14590793, 0.15780051,\n",
       "                     0.16035806, 0.16253197, 0.16317136, 0.17058824, 0.17378517,\n",
       "                     0.18324808, 0.18900256, 0.19040921, 0.19578005, 0.19923274,\n",
       "                     0.20358056, 0.21061381, 0.25537084, 0.26240409, 0.27084399,\n",
       "                     0.27186701, 0.27531969, 0.28542199, 0.29629156, 0.29795396,\n",
       "                     0.30383632, 0.31496164, 0.34616368, 0.34987212, 0.35920716,\n",
       "                     0.36905371, 0.42148338, 0.42826087, 0.44053708, 0.442711  ,\n",
       "                     0.44590793, 0.4483376 , 0.45575448, 0.46355499, 0.47250639,\n",
       "                     0.47877238, 0.4814578 , 0.49629156, 0.50511509, 0.51611253,\n",
       "                     0.51790281, 0.53056266, 0.53196931, 0.54335038, 0.54808184,\n",
       "                     0.55869565, 0.57276215, 0.59015345, 0.59987212, 0.6056266 ,\n",
       "                     0.60818414, 0.61521739, 0.64219949, 0.64488491, 0.66445013,\n",
       "                     0.67071611, 0.67557545, 0.6971867 , 0.70012788, 0.70294118,\n",
       "                     0.71355499, 0.71879795, 0.72084399, 0.73081841, 0.74143223,\n",
       "                     0.75140665, 0.757289  , 0.77071611, 0.77813299, 0.78567775,\n",
       "                     0.79232737, 0.80127877, 0.82762148, 0.82928389, 0.83056266,\n",
       "                     0.83375959, 0.83657289, 0.89654731, 0.90063939, 0.91023018,\n",
       "                     0.91317136, 0.91432225, 0.91713555, 0.92161125, 0.92250639,\n",
       "                     0.92813299, 0.93081841, 0.93273657, 0.93478261, 0.93682864,\n",
       "                     0.95473146, 0.95895141, 0.96099744, 0.96560102, 0.96790281,\n",
       "                     0.96969309, 0.97237852, 0.9758312 , 0.97787724, 0.97902813,\n",
       "                     0.98158568, 0.98388747, 0.98695652, 0.98797954, 0.98823529,\n",
       "                     0.98964194, 0.98964194, 0.99028133, 0.99168798, 1.        ]), tpr=array([0.        , 0.08405946, 0.10225525, 0.11058432, 0.11596617,\n",
       "                     0.12045105, 0.12339826, 0.13467453, 0.13723731, 0.14479754,\n",
       "                     0.14697591, 0.148898  , 0.14979498, 0.15402358, 0.16747822,\n",
       "                     0.17080984, 0.17401333, 0.17478216, 0.18311123, 0.1875961 ,\n",
       "                     0.19951307, 0.20604818, 0.20732957, 0.21348027, 0.21834956,\n",
       "                     0.22257817, 0.22796002, 0.27473091, 0.28216299, 0.29049206,\n",
       "                     0.29151717, 0.29497693, 0.30561251, 0.31752947, 0.32073296,\n",
       "                     0.32739621, 0.34085085, 0.37250128, 0.37685802, 0.38672476,\n",
       "                     0.39761661, 0.44413121, 0.45322911, 0.46335213, 0.46706817,\n",
       "                     0.46963096, 0.47142491, 0.47962583, 0.48769862, 0.4951307 ,\n",
       "                     0.50115325, 0.50448488, 0.52075859, 0.52947207, 0.54164531,\n",
       "                     0.54407996, 0.55497181, 0.55586879, 0.56804203, 0.57419272,\n",
       "                     0.58815992, 0.60238339, 0.6192978 , 0.62903639, 0.63531522,\n",
       "                     0.63813429, 0.64684777, 0.675551  , 0.67939518, 0.69810354,\n",
       "                     0.70463865, 0.70976422, 0.7318042 , 0.73385443, 0.73564839,\n",
       "                     0.74346489, 0.74923116, 0.75166581, 0.76063557, 0.76896463,\n",
       "                     0.77947207, 0.78639159, 0.79894926, 0.80650948, 0.81406971,\n",
       "                     0.81906715, 0.82547412, 0.85392107, 0.85725269, 0.85904664,\n",
       "                     0.86212199, 0.86635059, 0.9213224 , 0.92542286, 0.93426448,\n",
       "                     0.93682727, 0.9382368 , 0.94208098, 0.94528447, 0.94618145,\n",
       "                     0.95271656, 0.95463865, 0.95681702, 0.95797027, 0.96040492,\n",
       "                     0.9739877 , 0.97680677, 0.97898514, 0.98257304, 0.98411071,\n",
       "                     0.98616094, 0.98744234, 0.99000513, 0.99115838, 0.99179908,\n",
       "                     0.99436187, 0.99525884, 0.99769349, 0.99820605, 0.99846233,\n",
       "                     0.99910302, 0.9993593 , 0.99974372, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.13852162e-02, -5.97192347e-02,\n",
       "                     -6.89928715e-02, -8.22380982e-02, -8.33816089e-02, -8.70113770e-02,\n",
       "                     -9.53101798e-02, -9.68498260e-02, -1.11225635e-01, -1.25163143e-01,\n",
       "                     -1.33531393e-01, -1.41078598e-01, -1.41830195e-01, -1.43100844e-01,\n",
       "                     -1.48420005e-01, -1.54150680e-01, -1.56346070e-01, -1.58224005e-01,\n",
       "                     -1.58748389e-01, -1.79048231e-01, -1.82321557e-01, -1.89242000e-01,\n",
       "                     -1.91055237e-01, -1.92371893e-01, -1.94156014e-01, -2.04895879e-01,\n",
       "                     -2.16223108e-01, -2.20061885e-01, -2.23143551e-01, -2.30523659e-01,\n",
       "                     -2.35119742e-01, -2.46524000e-01, -2.46860078e-01, -2.53448901e-01,\n",
       "                     -2.58694536e-01, -2.74436846e-01, -2.80301965e-01, -2.81167391e-01,\n",
       "                     -2.84736562e-01, -2.87682072e-01, -2.91197015e-01, -2.93991242e-01,\n",
       "                     -2.96265816e-01, -3.00104592e-01, -3.05381650e-01, -3.07025035e-01,\n",
       "                     -3.11212570e-01, -3.21583624e-01, -3.24239668e-01, -3.25422400e-01,\n",
       "                     -3.26296909e-01, -3.34369186e-01, -3.36472237e-01, -3.51397887e-01,\n",
       "                     -3.53139289e-01, -3.56674944e-01, -3.58777994e-01, -3.62905494e-01,\n",
       "                     -3.64897923e-01, -3.65643614e-01, -3.69471505e-01, -3.69747026e-01,\n",
       "                     -3.70859579e-01, -3.74693449e-01, -3.75612145e-01, -3.78314119e-01,\n",
       "                     -3.82992252e-01, -4.05465108e-01, -4.24883194e-01, -4.38254931e-01,\n",
       "                     -4.43492504e-01, -4.46287103e-01, -4.51985124e-01, -4.53474327e-01,\n",
       "                     -4.56017387e-01, -4.56758402e-01, -4.61034959e-01, -4.70003629e-01,\n",
       "                     -4.76082675e-01, -4.76924072e-01, -4.83936724e-01, -4.97173535e-01,\n",
       "                     -5.07430035e-01, -5.10825624e-01, -5.18793793e-01, -5.18901038e-01,\n",
       "                     -5.26093096e-01, -5.38996501e-01, -5.59615788e-01, -5.63935449e-01,\n",
       "                     -5.67906335e-01, -5.77315365e-01, -5.78077851e-01, -5.87786665e-01,\n",
       "                     -5.97837001e-01, -6.06135804e-01, -6.09765572e-01, -6.19039208e-01,\n",
       "                     -6.22051259e-01, -6.24154309e-01, -6.32522559e-01, -6.35988767e-01,\n",
       "                     -6.66478933e-01, -6.93147181e-01, -7.37598943e-01, -7.50305594e-01,\n",
       "                     -7.62140052e-01, -7.73189888e-01, -8.10930216e-01, -8.32909123e-01,\n",
       "                     -9.16290732e-01, -9.38269639e-01, -1.02961942e+00, -1.04731899e+00,\n",
       "                     -1.04982212e+00, -1.09861229e+00, -1.17865500e+00, -1.25276297e+00,\n",
       "                     -1.38629436e+00, -1.50407740e+00, -1.60943791e+00, -1.79175947e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5215602104501463, privacy_risk=0.5173087511027855, accuracy=0.517089093701997, tpr_ind=0.7318042029728344, tnr_ind=0.3028132992327366, test_train_ratio=1.0020502306509482, dataset_size=[7804, 7820]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.07557475, 0.08154452, 0.08954655, 0.10516957,\n",
       "                     0.11012321, 0.11482281, 0.11621999, 0.11901435, 0.1216817 ,\n",
       "                     0.12231678, 0.12625429, 0.12930268, 0.13133494, 0.13590753,\n",
       "                     0.14136924, 0.14594183, 0.15407088, 0.15508701, 0.15902451,\n",
       "                     0.16105678, 0.16423219, 0.16842373, 0.17871205, 0.19751048,\n",
       "                     0.20475041, 0.20754477, 0.2085609 , 0.21300648, 0.21910326,\n",
       "                     0.23802871, 0.26038359, 0.27092595, 0.27245015, 0.27499047,\n",
       "                     0.27727677, 0.31055506, 0.32122444, 0.33062365, 0.33278293,\n",
       "                     0.34281722, 0.34523053, 0.35678903, 0.36148863, 0.36377493,\n",
       "                     0.37469834, 0.37558745, 0.38803506, 0.3907024 , 0.40556332,\n",
       "                     0.4061984 , 0.40784961, 0.41064397, 0.41877302, 0.44671663,\n",
       "                     0.45548076, 0.48317033, 0.50704941, 0.51403531, 0.51962403,\n",
       "                     0.52140226, 0.52419662, 0.53016639, 0.53156357, 0.54578941,\n",
       "                     0.54820272, 0.55277531, 0.55950718, 0.56077734, 0.56458783,\n",
       "                     0.57386003, 0.57741649, 0.5868157 , 0.58973708, 0.59799314,\n",
       "                     0.61539439, 0.61653753, 0.62746094, 0.63038232, 0.63673314,\n",
       "                     0.64752953, 0.64981583, 0.6705195 , 0.67725137, 0.68919091,\n",
       "                     0.69198527, 0.69986028, 0.70176553, 0.74584021, 0.77543503,\n",
       "                     0.78038867, 0.78242093, 0.78458021, 0.79893306, 0.80083831,\n",
       "                     0.82192303, 0.83652991, 0.83907024, 0.84199162, 0.84465896,\n",
       "                     0.84681824, 0.85748762, 0.86244125, 0.86548965, 0.87196748,\n",
       "                     0.88022355, 0.90359456, 0.90651594, 0.90943732, 0.9178204 ,\n",
       "                     0.91845548, 0.9193446 , 0.92417122, 0.92823574, 0.94169948,\n",
       "                     0.94462086, 0.95643338, 0.95910072, 0.96468944, 0.96557856,\n",
       "                     0.9682459 , 0.969008  , 0.97421567, 0.97866125, 0.98132859,\n",
       "                     0.98209069, 0.98234472, 0.98272577, 0.98653626, 0.98729836,\n",
       "                     0.98755239, 0.98869554, 0.98945764, 0.99047377, 0.99047377,\n",
       "                     0.99060079, 0.99085482, 0.99161692, 1.        ]), tpr=array([0.        , 0.08373113, 0.08992388, 0.10114824, 0.11740421,\n",
       "                     0.12191975, 0.12540317, 0.12708038, 0.13004774, 0.13430525,\n",
       "                     0.13559541, 0.13920784, 0.14385241, 0.1470778 , 0.15327055,\n",
       "                     0.16139853, 0.16707522, 0.17442911, 0.17533222, 0.17971875,\n",
       "                     0.18320217, 0.18745968, 0.19287834, 0.20423171, 0.22022965,\n",
       "                     0.22616437, 0.23067991, 0.23313121, 0.23842085, 0.24487163,\n",
       "                     0.26564314, 0.28409238, 0.29428461, 0.29596181, 0.29970326,\n",
       "                     0.30279964, 0.33698878, 0.34911624, 0.36111469, 0.36330796,\n",
       "                     0.37285512, 0.37543543, 0.38820797, 0.39285254, 0.39607793,\n",
       "                     0.40962456, 0.41143078, 0.4231712 , 0.4256225 , 0.43955619,\n",
       "                     0.44058831, 0.44226551, 0.44587795, 0.45361889, 0.47735776,\n",
       "                     0.48909818, 0.5173526 , 0.53812411, 0.54573603, 0.55179977,\n",
       "                     0.55360599, 0.55567024, 0.56328216, 0.5644433 , 0.57373242,\n",
       "                     0.57540962, 0.57902206, 0.58869823, 0.59114953, 0.59385886,\n",
       "                     0.6025029 , 0.6066314 , 0.61682364, 0.61979099, 0.62791898,\n",
       "                     0.64469101, 0.64611018, 0.65410915, 0.65875371, 0.66494646,\n",
       "                     0.6760418 , 0.67784802, 0.69926461, 0.70442524, 0.71706877,\n",
       "                     0.7214553 , 0.72906722, 0.73035737, 0.76802993, 0.79976777,\n",
       "                     0.80454135, 0.8066056 , 0.8090569 , 0.82247452, 0.82531286,\n",
       "                     0.85176106, 0.8660818 , 0.86969423, 0.87253258, 0.87459683,\n",
       "                     0.87627403, 0.88517611, 0.88878854, 0.89201393, 0.89614243,\n",
       "                     0.90543156, 0.92904141, 0.93162173, 0.93394401, 0.94220101,\n",
       "                     0.94336215, 0.94478132, 0.94890982, 0.95432847, 0.96374661,\n",
       "                     0.96723003, 0.97729325, 0.97884144, 0.98258289, 0.983486  ,\n",
       "                     0.98542124, 0.9859373 , 0.98903367, 0.99161399, 0.99367824,\n",
       "                     0.99432331, 0.99471036, 0.99522642, 0.99690363, 0.99729067,\n",
       "                     0.99793575, 0.99845181, 0.99896788, 0.99935492, 0.99961295,\n",
       "                     0.99974197, 0.99987098, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.06192872e-02, -2.27282511e-02,\n",
       "                     -4.65200156e-02, -5.55698512e-02, -7.14589640e-02, -7.41079722e-02,\n",
       "                     -8.33816089e-02, -8.70113770e-02, -9.53101798e-02, -1.01782694e-01,\n",
       "                     -1.05360516e-01, -1.13328685e-01, -1.17783036e-01, -1.19545151e-01,\n",
       "                     -1.27833372e-01, -1.31336002e-01, -1.33531393e-01, -1.37201122e-01,\n",
       "                     -1.38150338e-01, -1.41078598e-01, -1.54150680e-01, -1.57392174e-01,\n",
       "                     -1.70151021e-01, -1.78691789e-01, -1.82321557e-01, -1.91055237e-01,\n",
       "                     -1.98450939e-01, -1.98850859e-01, -2.01799364e-01, -2.01941344e-01,\n",
       "                     -2.05263126e-01, -2.07639365e-01, -2.16223108e-01, -2.23143551e-01,\n",
       "                     -2.28412664e-01, -2.52495763e-01, -2.54892250e-01, -2.57829109e-01,\n",
       "                     -2.60283098e-01, -2.62364264e-01, -2.64692554e-01, -2.66628663e-01,\n",
       "                     -2.77631737e-01, -2.87682072e-01, -3.05381650e-01, -3.09422059e-01,\n",
       "                     -3.13657559e-01, -3.15081047e-01, -3.18453731e-01, -3.25422400e-01,\n",
       "                     -3.31357136e-01, -3.36472237e-01, -3.38023827e-01, -3.41170757e-01,\n",
       "                     -3.50721182e-01, -3.52317639e-01, -3.53279355e-01, -3.54545018e-01,\n",
       "                     -3.56674944e-01, -3.62905494e-01, -3.65113813e-01, -3.67724780e-01,\n",
       "                     -3.77294231e-01, -3.79489622e-01, -3.81367557e-01, -3.82992252e-01,\n",
       "                     -3.87765531e-01, -3.89464767e-01, -3.90427231e-01, -4.05465108e-01,\n",
       "                     -4.09675641e-01, -4.19853846e-01, -4.21213465e-01, -4.30782916e-01,\n",
       "                     -4.35318071e-01, -4.37213806e-01, -4.41832752e-01, -4.46287103e-01,\n",
       "                     -4.50927482e-01, -4.51985124e-01, -4.52532619e-01, -4.54255272e-01,\n",
       "                     -4.58457638e-01, -4.62623522e-01, -4.65757338e-01, -4.70003629e-01,\n",
       "                     -4.75978892e-01, -4.78604745e-01, -4.83426650e-01, -4.85507816e-01,\n",
       "                     -4.89548225e-01, -4.91407538e-01, -4.92476485e-01, -5.00035916e-01,\n",
       "                     -5.10825624e-01, -5.17943092e-01, -5.19875459e-01, -5.23248144e-01,\n",
       "                     -5.26093096e-01, -5.28067430e-01, -5.38996501e-01, -5.42324291e-01,\n",
       "                     -5.59615788e-01, -5.67520967e-01, -5.71257363e-01, -5.87786665e-01,\n",
       "                     -6.06135804e-01, -6.11801541e-01, -6.35988767e-01, -6.46627165e-01,\n",
       "                     -6.77398824e-01, -6.81170990e-01, -6.93147181e-01, -7.11496319e-01,\n",
       "                     -7.30887509e-01, -7.33969175e-01, -7.43578034e-01, -7.62140052e-01,\n",
       "                     -7.88457360e-01, -8.10930216e-01, -8.47297860e-01, -9.16290732e-01,\n",
       "                     -9.40983344e-01, -9.55511445e-01, -9.80829253e-01, -1.01160091e+00,\n",
       "                     -1.09861229e+00, -1.20397280e+00, -1.22377543e+00, -1.25276297e+00,\n",
       "                     -1.38629436e+00, -1.60943791e+00, -1.79175947e+00, -1.94591015e+00,\n",
       "                     -2.30258509e+00, -2.39789527e+00, -3.45387764e+01]), auc_score=0.5243946840062249, privacy_risk=0.5179216661718037, accuracy=0.5187532002048131, tpr_ind=0.4114307831247581, tnr_ind=0.6244125492188493, test_train_ratio=1.0157399045284479, dataset_size=[7751, 7873]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.10834722, 0.11488652, 0.11745096, 0.11924606,\n",
       "                     0.12116938, 0.12565714, 0.1289909 , 0.13296576, 0.13745352,\n",
       "                     0.13809463, 0.14168483, 0.14219772, 0.14399282, 0.14527504,\n",
       "                     0.14694192, 0.14809591, 0.15245544, 0.15617387, 0.15937941,\n",
       "                     0.16027696, 0.1670727 , 0.17232979, 0.17566355, 0.23259392,\n",
       "                     0.23464547, 0.23874856, 0.24387742, 0.24836518, 0.25221182,\n",
       "                     0.260418  , 0.26387998, 0.29760226, 0.30927042, 0.31811771,\n",
       "                     0.33093986, 0.33401718, 0.3596615 , 0.36709835, 0.39287088,\n",
       "                     0.40441082, 0.40864213, 0.43620977, 0.45082703, 0.45416079,\n",
       "                     0.46185408, 0.46326452, 0.47788178, 0.48737018, 0.49916656,\n",
       "                     0.50211566, 0.51224516, 0.51775869, 0.52275933, 0.53096551,\n",
       "                     0.53301705, 0.5386588 , 0.54276189, 0.56930376, 0.57391973,\n",
       "                     0.58122836, 0.5891781 , 0.60148737, 0.61148865, 0.61674574,\n",
       "                     0.62341326, 0.63046544, 0.63251699, 0.64969868, 0.65572509,\n",
       "                     0.65752019, 0.6843185 , 0.69970509, 0.69983331, 0.7057315 ,\n",
       "                     0.71060392, 0.71368124, 0.71598923, 0.76266188, 0.77176561,\n",
       "                     0.78433132, 0.78445955, 0.79163995, 0.80215412, 0.80920631,\n",
       "                     0.82215669, 0.82856777, 0.83844083, 0.84562123, 0.87344531,\n",
       "                     0.87639441, 0.87857418, 0.88152327, 0.8822926 , 0.88498525,\n",
       "                     0.88985767, 0.89216566, 0.89998718, 0.90075651, 0.91806642,\n",
       "                     0.92934992, 0.93511989, 0.93896653, 0.95076292, 0.95409668,\n",
       "                     0.95550712, 0.96217464, 0.96935505, 0.97012437, 0.97179126,\n",
       "                     0.97397102, 0.97653545, 0.97692012, 0.97820233, 0.97884344,\n",
       "                     0.97948455, 0.98025388, 0.98051032, 0.98166432, 0.98422875,\n",
       "                     0.98756251, 0.98769073, 0.9887165 , 0.98935761, 0.98948583,\n",
       "                     1.        ]), tpr=array([0.        , 0.11897764, 0.12511182, 0.13009585, 0.13226837,\n",
       "                     0.1343131 , 0.13891374, 0.14402556, 0.14632588, 0.15054313,\n",
       "                     0.1515655 , 0.15654952, 0.15744409, 0.16076677, 0.16153355,\n",
       "                     0.16370607, 0.16511182, 0.17060703, 0.17392971, 0.1771246 ,\n",
       "                     0.17891374, 0.18479233, 0.19169329, 0.19565495, 0.25329073,\n",
       "                     0.25495208, 0.25929712, 0.26466454, 0.27028754, 0.2742492 ,\n",
       "                     0.28153355, 0.28587859, 0.31897764, 0.33047923, 0.3400639 ,\n",
       "                     0.35501597, 0.3571885 , 0.38325879, 0.39258786, 0.42159744,\n",
       "                     0.43386581, 0.43884984, 0.47501597, 0.4915016 , 0.49571885,\n",
       "                     0.50236422, 0.50440895, 0.51936102, 0.53022364, 0.5428754 ,\n",
       "                     0.54594249, 0.5571885 , 0.56166134, 0.56728435, 0.57763578,\n",
       "                     0.58057508, 0.58555911, 0.58875399, 0.61047923, 0.61559105,\n",
       "                     0.6228754 , 0.62939297, 0.64319489, 0.65111821, 0.65686901,\n",
       "                     0.6600639 , 0.66517572, 0.66760383, 0.68255591, 0.68881789,\n",
       "                     0.69047923, 0.71207668, 0.72728435, 0.7284345 , 0.73290735,\n",
       "                     0.73623003, 0.74019169, 0.74172524, 0.78875399, 0.79769968,\n",
       "                     0.80907348, 0.81009585, 0.81674121, 0.82977636, 0.83795527,\n",
       "                     0.84817891, 0.85392971, 0.86594249, 0.87258786, 0.89942492,\n",
       "                     0.90325879, 0.90504792, 0.90824281, 0.90926518, 0.91194888,\n",
       "                     0.91859425, 0.92115016, 0.9286901 , 0.92971246, 0.94670927,\n",
       "                     0.95667732, 0.96204473, 0.96498403, 0.97316294, 0.97456869,\n",
       "                     0.97571885, 0.98044728, 0.98607029, 0.98658147, 0.98773163,\n",
       "                     0.98913738, 0.9913099 , 0.99246006, 0.99373802, 0.99476038,\n",
       "                     0.99514377, 0.99565495, 0.99629393, 0.9970607 , 0.99859425,\n",
       "                     0.99923323, 0.99948882, 0.99974441, 0.9998722 , 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.08219945e-02, -5.00104206e-02,\n",
       "                     -5.71584138e-02, -6.06246218e-02, -8.00427077e-02, -9.53101798e-02,\n",
       "                     -1.05360516e-01, -1.14410351e-01, -1.17783036e-01, -1.20627988e-01,\n",
       "                     -1.33531393e-01, -1.43100844e-01, -1.54150680e-01, -1.62518929e-01,\n",
       "                     -1.67054085e-01, -1.70625517e-01, -1.75890666e-01, -1.82321557e-01,\n",
       "                     -1.94156014e-01, -1.96710294e-01, -2.00670695e-01, -2.03598955e-01,\n",
       "                     -2.07500774e-01, -2.07639365e-01, -2.11309094e-01, -2.13574100e-01,\n",
       "                     -2.23143551e-01, -2.29574442e-01, -2.33614851e-01, -2.34839591e-01,\n",
       "                     -2.36185547e-01, -2.36388778e-01, -2.46860078e-01, -2.55105902e-01,\n",
       "                     -2.57829109e-01, -2.61609832e-01, -2.63417450e-01, -2.75493556e-01,\n",
       "                     -2.79838895e-01, -2.87682072e-01, -2.97352477e-01, -2.99242895e-01,\n",
       "                     -3.10154928e-01, -3.11436158e-01, -3.18453731e-01, -3.25422400e-01,\n",
       "                     -3.36472237e-01, -3.39354083e-01, -3.48306694e-01, -3.50976923e-01,\n",
       "                     -3.56674944e-01, -3.58945092e-01, -3.59141036e-01, -3.61013346e-01,\n",
       "                     -3.61790045e-01, -3.64643114e-01, -3.65459773e-01, -3.71563556e-01,\n",
       "                     -3.75789340e-01, -3.85662481e-01, -3.93042588e-01, -4.05465108e-01,\n",
       "                     -4.12845215e-01, -4.18710335e-01, -4.21994410e-01, -4.22856851e-01,\n",
       "                     -4.25211871e-01, -4.25667815e-01, -4.30782916e-01, -4.34621692e-01,\n",
       "                     -4.41232332e-01, -4.41832752e-01, -4.51985124e-01, -4.55475529e-01,\n",
       "                     -4.57833094e-01, -4.59532329e-01, -4.65236851e-01, -4.70003629e-01,\n",
       "                     -4.81176930e-01, -4.85507816e-01, -4.91407538e-01, -4.93020999e-01,\n",
       "                     -4.95077267e-01, -5.00775288e-01, -5.10825624e-01, -5.12951023e-01,\n",
       "                     -5.14664400e-01, -5.25010259e-01, -5.30628251e-01, -5.38996501e-01,\n",
       "                     -5.42324291e-01, -5.59615788e-01, -5.66395475e-01, -5.70544858e-01,\n",
       "                     -5.87786665e-01, -6.22942922e-01, -6.28608659e-01, -6.35103811e-01,\n",
       "                     -6.53926467e-01, -6.56779536e-01, -6.71168274e-01, -6.93147181e-01,\n",
       "                     -7.37598943e-01, -7.47214402e-01, -7.83531242e-01, -7.90521345e-01,\n",
       "                     -8.10930216e-01, -8.47297860e-01, -8.60201265e-01, -8.80358723e-01,\n",
       "                     -8.93817876e-01, -9.16290732e-01, -9.65080896e-01, -9.80829253e-01,\n",
       "                     -1.01160091e+00, -1.02961942e+00, -1.09861229e+00, -1.25276297e+00,\n",
       "                     -1.38629436e+00, -1.50407740e+00, -1.60943791e+00, -1.94591015e+00,\n",
       "                     -2.07944154e+00, -3.45387764e+01]), auc_score=0.5255987107382901, privacy_risk=0.5237790132019056, accuracy=0.523873527905786, tpr_ind=0.5805750798722045, tnr_ind=0.4669829465316066, test_train_ratio=0.9966773162939297, dataset_size=[7825, 7799]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.06320134, 0.12872436, 0.13001419, 0.13323875,\n",
       "                     0.1408487 , 0.15387592, 0.15632658, 0.16225977, 0.16922482,\n",
       "                     0.1707726 , 0.17361022, 0.17786663, 0.18483168, 0.18883013,\n",
       "                     0.19128079, 0.20263124, 0.21398168, 0.23307107, 0.2371985 ,\n",
       "                     0.23758545, 0.27989165, 0.28943635, 0.29072617, 0.29665936,\n",
       "                     0.29820715, 0.3000129 , 0.3058171 , 0.30891268, 0.32193989,\n",
       "                     0.32697021, 0.35753902, 0.38307752, 0.38475429, 0.44576293,\n",
       "                     0.45118019, 0.45388882, 0.45517864, 0.4584032 , 0.47026957,\n",
       "                     0.4737521 , 0.47826648, 0.48071714, 0.51683219, 0.52199149,\n",
       "                     0.52792467, 0.55655875, 0.55707468, 0.59912292, 0.60234748,\n",
       "                     0.60608797, 0.61485876, 0.61847027, 0.62285567, 0.63162647,\n",
       "                     0.63678576, 0.64994196, 0.65600413, 0.65922869, 0.66658068,\n",
       "                     0.67393267, 0.678834  , 0.6832194 , 0.68554108, 0.68708887,\n",
       "                     0.69018444, 0.74912937, 0.7554495 , 0.7576422 , 0.75931897,\n",
       "                     0.76241455, 0.77002451, 0.77247517, 0.77415194, 0.78266477,\n",
       "                     0.78524442, 0.78834   , 0.79582097, 0.79891655, 0.82767961,\n",
       "                     0.83154908, 0.84767187, 0.85682961, 0.85928028, 0.86198891,\n",
       "                     0.86585838, 0.87308139, 0.87875661, 0.8803044 , 0.88211015,\n",
       "                     0.88352896, 0.88843029, 0.89449245, 0.89952277, 0.90107055,\n",
       "                     0.91371082, 0.91641945, 0.91835419, 0.92286857, 0.92531923,\n",
       "                     0.93228428, 0.94415065, 0.95240552, 0.95446924, 0.95679092,\n",
       "                     0.95820973, 0.96272411, 0.96336902, 0.97136592, 0.97381659,\n",
       "                     0.97420353, 0.9766542 , 0.97871792, 0.97987876, 0.98065265,\n",
       "                     0.9832323 , 0.9846511 , 0.985425  , 0.98645686, 0.98671482,\n",
       "                     0.9868438 , 0.99058429, 0.99148717, 0.99174513, 0.99239004,\n",
       "                     0.9941958 , 1.        ]), tpr=array([0.        , 0.07038496, 0.13251175, 0.13390929, 0.13772075,\n",
       "                     0.14686825, 0.16008131, 0.16541735, 0.17380257, 0.18002795,\n",
       "                     0.18167958, 0.18472875, 0.19057299, 0.1992123 , 0.20467539,\n",
       "                     0.20721636, 0.21788845, 0.22754415, 0.24723669, 0.25244569,\n",
       "                     0.25358912, 0.29195782, 0.30415449, 0.30707661, 0.31571592,\n",
       "                     0.31851099, 0.32168721, 0.32892898, 0.33070766, 0.34252319,\n",
       "                     0.34836742, 0.38292466, 0.40960488, 0.41151061, 0.4741456 ,\n",
       "                     0.48049803, 0.483039  , 0.48443654, 0.48964553, 0.50247745,\n",
       "                     0.50552662, 0.51124381, 0.51353068, 0.54923136, 0.55469445,\n",
       "                     0.56142803, 0.59166561, 0.59293609, 0.63841951, 0.64172278,\n",
       "                     0.64680473, 0.65658747, 0.66141532, 0.66560793, 0.67297675,\n",
       "                     0.67704231, 0.68809554, 0.69508322, 0.70016516, 0.70956676,\n",
       "                     0.71401347, 0.71833312, 0.72379621, 0.72659128, 0.72913226,\n",
       "                     0.73141913, 0.78134926, 0.78630415, 0.78808284, 0.78960742,\n",
       "                     0.79176725, 0.79862787, 0.80307458, 0.80663194, 0.8153983 ,\n",
       "                     0.81768517, 0.81933681, 0.82556219, 0.8297548 , 0.85961123,\n",
       "                     0.86316859, 0.87879558, 0.88679964, 0.89035701, 0.89238979,\n",
       "                     0.89658239, 0.90268073, 0.90712743, 0.90916021, 0.91081184,\n",
       "                     0.91335281, 0.91729132, 0.92186507, 0.92694702, 0.92783636,\n",
       "                     0.93977894, 0.94168467, 0.94384449, 0.94663956, 0.94816415,\n",
       "                     0.95438953, 0.96315589, 0.97001652, 0.9717952 , 0.97382798,\n",
       "                     0.97547961, 0.97941812, 0.9806886 , 0.98602465, 0.98805743,\n",
       "                     0.98843857, 0.98970906, 0.99097955, 0.99186889, 0.99250413,\n",
       "                     0.99402871, 0.99466396, 0.9955533 , 0.99644264, 0.99682378,\n",
       "                     0.99707788, 0.99860246, 0.99936476, 0.99949181, 0.99961885,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.76127528e-02, -8.70113770e-02,\n",
       "                     -9.53101798e-02, -1.05360516e-01, -1.09199292e-01, -1.12477983e-01,\n",
       "                     -1.27833372e-01, -1.33531393e-01, -1.43100844e-01, -1.54150680e-01,\n",
       "                     -1.60342650e-01, -1.62518929e-01, -1.70625517e-01, -1.82321557e-01,\n",
       "                     -1.84303718e-01, -1.91055237e-01, -1.93016846e-01, -1.98450939e-01,\n",
       "                     -2.00670695e-01, -2.05775045e-01, -2.23143551e-01, -2.31801614e-01,\n",
       "                     -2.34839591e-01, -2.41162057e-01, -2.46860078e-01, -2.47408173e-01,\n",
       "                     -2.51314428e-01, -2.63191052e-01, -2.65703166e-01, -2.74730920e-01,\n",
       "                     -2.84104251e-01, -2.87682072e-01, -2.90214360e-01, -2.92669614e-01,\n",
       "                     -3.00104592e-01, -3.10154928e-01, -3.11779624e-01, -3.12133168e-01,\n",
       "                     -3.18453731e-01, -3.20471895e-01, -3.28504067e-01, -3.32907170e-01,\n",
       "                     -3.33144447e-01, -3.33773180e-01, -3.35871816e-01, -3.36472237e-01,\n",
       "                     -3.51915030e-01, -3.52821375e-01, -3.54171814e-01, -3.56674944e-01,\n",
       "                     -3.69747026e-01, -3.74693449e-01, -3.82208246e-01, -3.84411699e-01,\n",
       "                     -3.86122145e-01, -3.99386062e-01, -4.05465108e-01, -4.14433778e-01,\n",
       "                     -4.14943852e-01, -4.24883194e-01, -4.28454626e-01, -4.35318071e-01,\n",
       "                     -4.38254931e-01, -4.41832752e-01, -4.42922671e-01, -4.47312218e-01,\n",
       "                     -4.51985124e-01, -4.59532329e-01, -4.62623522e-01, -4.65363250e-01,\n",
       "                     -4.70003629e-01, -4.74457980e-01, -4.75423697e-01, -4.76924072e-01,\n",
       "                     -4.79573080e-01, -4.90206337e-01, -4.92476485e-01, -4.93657820e-01,\n",
       "                     -4.96436886e-01, -5.01021624e-01, -5.10825624e-01, -5.17943092e-01,\n",
       "                     -5.23248144e-01, -5.28844129e-01, -5.35518236e-01, -5.38996501e-01,\n",
       "                     -5.59615788e-01, -5.70544858e-01, -5.87786665e-01, -5.91364486e-01,\n",
       "                     -6.06135804e-01, -6.15185639e-01, -6.19039208e-01, -6.21491192e-01,\n",
       "                     -6.24154309e-01, -6.32522559e-01, -6.46627165e-01, -6.50587566e-01,\n",
       "                     -6.72527893e-01, -6.93147181e-01, -7.11496319e-01, -7.28238500e-01,\n",
       "                     -7.53771802e-01, -7.67255153e-01, -7.85520501e-01, -7.88457360e-01,\n",
       "                     -7.94929875e-01, -8.10930216e-01, -8.47297860e-01, -8.75468737e-01,\n",
       "                     -9.16290732e-01, -9.44461609e-01, -9.55511445e-01, -9.80829253e-01,\n",
       "                     -1.02961942e+00, -1.04982212e+00, -1.09861229e+00, -1.20397280e+00,\n",
       "                     -1.25276297e+00, -1.38629436e+00, -1.50407740e+00, -1.60943791e+00,\n",
       "                     -1.79175947e+00, -2.07944154e+00, -3.45387764e+01]), auc_score=0.5239229283141252, privacy_risk=0.5214930428117931, accuracy=0.5229134664618535, tpr_ind=0.709566764070639, tnr_ind=0.33341932155294723, test_train_ratio=0.9850082581628764, dataset_size=[7871, 7753])],\n",
       "             'entire_dataset_label_1.0_mia_auc': [0.5553982812116673,\n",
       "              0.5684543807490554,\n",
       "              0.5673022526200683,\n",
       "              0.5644170841177159,\n",
       "              0.5592618265882836,\n",
       "              0.5598567731414188,\n",
       "              0.5714121685052123,\n",
       "              0.5600973701420175,\n",
       "              0.5666796509574474,\n",
       "              0.5561928512274222,\n",
       "              0.5606069416707583,\n",
       "              0.5590806597485131,\n",
       "              0.5608507591199597,\n",
       "              0.5626887359989364,\n",
       "              0.5763426944835981,\n",
       "              0.5523531090571965,\n",
       "              0.5491317904030527,\n",
       "              0.5526427056624784,\n",
       "              0.5449788579199752,\n",
       "              0.554026898593897],\n",
       "             'entire_dataset_label_1.0_mia_privacy_risk': [0.5401839715418966,\n",
       "              0.5454314362453299,\n",
       "              0.5525402033906958,\n",
       "              0.5444790104548887,\n",
       "              0.5386750356340015,\n",
       "              0.5395357535363562,\n",
       "              0.5523778072739185,\n",
       "              0.5414010749682132,\n",
       "              0.5483774732747401,\n",
       "              0.5381317385564192,\n",
       "              0.5422923102384276,\n",
       "              0.5388272730086731,\n",
       "              0.5420342877449946,\n",
       "              0.5437422142453552,\n",
       "              0.5539418147480151,\n",
       "              0.5355669655360682,\n",
       "              0.5348814928045009,\n",
       "              0.5442743963202934,\n",
       "              0.5305869723520373,\n",
       "              0.535040959625512],\n",
       "             'entire_dataset_label_1.0_mia_ppv': [0.706896551724138,\n",
       "              0.7647058823529412,\n",
       "              0.7133333333333333,\n",
       "              0.7326732673267327,\n",
       "              0.6903553299492385,\n",
       "              0.7142857142857143,\n",
       "              0.6610169491525424,\n",
       "              0.6746031746031745,\n",
       "              0.7226890756302521,\n",
       "              0.775,\n",
       "              0.6995305164319249,\n",
       "              0.7052631578947369,\n",
       "              0.7037037037037037,\n",
       "              0.6791044776119403,\n",
       "              0.7352941176470588,\n",
       "              0.6517857142857143,\n",
       "              0.6870748299319728,\n",
       "              0.6847826086956522,\n",
       "              0.6782608695652174,\n",
       "              0.7037037037037037],\n",
       "             'entire_dataset_label_1.0_mia_attacker_advantage': [0.08036794308379314,\n",
       "              0.09086287249065961,\n",
       "              0.10508040678139163,\n",
       "              0.08895802090977739,\n",
       "              0.0773500712680032,\n",
       "              0.07907150707271238,\n",
       "              0.10475561454783688,\n",
       "              0.08280214993642654,\n",
       "              0.09675494654948003,\n",
       "              0.07626347711283832,\n",
       "              0.08458462047685528,\n",
       "              0.07765454601734617,\n",
       "              0.08406857548998925,\n",
       "              0.08748442849071025,\n",
       "              0.10788362949603014,\n",
       "              0.07113393107213639,\n",
       "              0.06976298560900174,\n",
       "              0.08854879264058668,\n",
       "              0.06117394470407467,\n",
       "              0.07008191925102403],\n",
       "             'entire_dataset_label_1.0_mia_result': [MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.01010101, 0.0130719 , 0.01485443, 0.0154486 ,\n",
       "                     0.02198455, 0.02228164, 0.02376708, 0.0258467 , 0.03743316,\n",
       "                     0.04010695, 0.04456328, 0.05109923, 0.05585264, 0.06030897,\n",
       "                     0.0620915 , 0.06535948, 0.06892454, 0.07100416, 0.0802139 ,\n",
       "                     0.08229352, 0.0959596 , 0.10606061, 0.11675579, 0.1191325 ,\n",
       "                     0.12269756, 0.12923351, 0.13606655, 0.15181224, 0.15983363,\n",
       "                     0.16131907, 0.16607249, 0.16874629, 0.17498515, 0.18746286,\n",
       "                     0.19548425, 0.19786096, 0.21271539, 0.22489602, 0.23262032,\n",
       "                     0.23856209, 0.24509804, 0.25311943, 0.26054664, 0.27956031,\n",
       "                     0.28104575, 0.29055258, 0.29144385, 0.29560309, 0.30124777,\n",
       "                     0.3057041 , 0.32293523, 0.32798574, 0.33214498, 0.33452169,\n",
       "                     0.35026738, 0.35294118, 0.35710042, 0.36185383, 0.3627451 ,\n",
       "                     0.36838978, 0.38680927, 0.39572193, 0.40493167, 0.40968509,\n",
       "                     0.41325015, 0.41859774, 0.43612597, 0.44444444, 0.45216875,\n",
       "                     0.45900178, 0.4637552 , 0.47029115, 0.4845514 , 0.50386215,\n",
       "                     0.51426025, 0.533571  , 0.5362448 , 0.54367201, 0.55139632,\n",
       "                     0.55228758, 0.55941771, 0.56387403, 0.590612  , 0.59952466,\n",
       "                     0.60398099, 0.62774807, 0.63279857, 0.64379085, 0.64676173,\n",
       "                     0.65329768, 0.66458705, 0.67795603, 0.6969697 , 0.70112894,\n",
       "                     0.71093286, 0.71598336, 0.73529412, 0.74064171, 0.74480095,\n",
       "                     0.75074272, 0.75460487, 0.76084373, 0.77807487, 0.78698752,\n",
       "                     0.79738562, 0.80540701, 0.8134284 , 0.81937017, 0.82293523,\n",
       "                     0.84729649, 0.84997029, 0.85145573, 0.87076649, 0.87849079,\n",
       "                     0.88116459, 0.88443256, 0.89512775, 0.89750446, 0.90255496,\n",
       "                     0.90612002, 0.91592395, 0.91770648, 0.91770648, 0.91830065,\n",
       "                     0.92364825, 0.92929293, 0.93493761, 0.93820559, 0.9483066 ,\n",
       "                     0.94860368, 0.95008913, 0.95365419, 0.96405229, 0.966429  ,\n",
       "                     0.96939988, 0.97029115, 0.9714795 , 0.97385621, 0.97445039,\n",
       "                     0.97504456, 1.        ]), tpr=array([0.        , 0.02446301, 0.02774463, 0.03042959, 0.03162291,\n",
       "                     0.03788783, 0.03937947, 0.04355609, 0.04624105, 0.06175418,\n",
       "                     0.06443914, 0.07040573, 0.08114558, 0.0874105 , 0.09427208,\n",
       "                     0.09665871, 0.09934368, 0.10381862, 0.10739857, 0.11754177,\n",
       "                     0.11963007, 0.13842482, 0.14588305, 0.15662291, 0.15960621,\n",
       "                     0.16318616, 0.17094272, 0.17661098, 0.20167064, 0.20972554,\n",
       "                     0.2124105 , 0.21658711, 0.21837709, 0.22494033, 0.23389021,\n",
       "                     0.24194511, 0.24582339, 0.26342482, 0.27714797, 0.2875895 ,\n",
       "                     0.29355609, 0.30101432, 0.30817422, 0.31145585, 0.33830549,\n",
       "                     0.33979714, 0.35053699, 0.3526253 , 0.35739857, 0.36396181,\n",
       "                     0.36634845, 0.37977327, 0.38544153, 0.38902148, 0.39051313,\n",
       "                     0.4146778 , 0.41646778, 0.41855609, 0.42303103, 0.42422434,\n",
       "                     0.42929594, 0.44540573, 0.45495227, 0.46330549, 0.46778043,\n",
       "                     0.47106205, 0.47792363, 0.49880668, 0.50596659, 0.51133652,\n",
       "                     0.51760143, 0.52505967, 0.53341289, 0.55220764, 0.57249403,\n",
       "                     0.58293556, 0.60352029, 0.60680191, 0.61366348, 0.62231504,\n",
       "                     0.625     , 0.63156325, 0.63663484, 0.6676611 , 0.6798926 ,\n",
       "                     0.68406921, 0.70286396, 0.70614558, 0.71688544, 0.71986874,\n",
       "                     0.73001193, 0.73806683, 0.75      , 0.76282816, 0.76700477,\n",
       "                     0.77834129, 0.78162291, 0.79803103, 0.80817422, 0.81175418,\n",
       "                     0.81622912, 0.82100239, 0.82816229, 0.84695704, 0.85948687,\n",
       "                     0.86455847, 0.86873508, 0.87231504, 0.87649165, 0.88036993,\n",
       "                     0.90930788, 0.91139618, 0.9125895 , 0.92601432, 0.93198091,\n",
       "                     0.93436754, 0.93764916, 0.94838902, 0.950179  , 0.95286396,\n",
       "                     0.95584726, 0.96211217, 0.96390215, 0.96509547, 0.96628878,\n",
       "                     0.96897375, 0.974642  , 0.9797136 , 0.98180191, 0.98747017,\n",
       "                     0.98806683, 0.98866348, 0.99045346, 0.99433174, 0.99671838,\n",
       "                     0.99731504, 0.99761337, 0.99821002, 0.99910501, 0.99940334,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -8.70113770e-02, -2.00670695e-01,\n",
       "                     -2.23143551e-01, -2.87682072e-01, -3.36472237e-01, -3.56674944e-01,\n",
       "                     -3.67724780e-01, -4.05465108e-01, -4.41832752e-01, -4.70003629e-01,\n",
       "                     -5.10825624e-01, -5.38996501e-01, -5.53385238e-01, -5.59615788e-01,\n",
       "                     -5.75364145e-01, -5.87786665e-01, -6.06135804e-01, -6.16774202e-01,\n",
       "                     -6.19039208e-01, -6.27549898e-01, -6.31271777e-01, -6.35988767e-01,\n",
       "                     -6.41853886e-01, -6.50587566e-01, -6.53926467e-01, -6.66478933e-01,\n",
       "                     -6.93147181e-01, -7.11496319e-01, -7.47214402e-01, -7.62140052e-01,\n",
       "                     -7.73189888e-01, -7.80158558e-01, -7.88457360e-01, -7.98507696e-01,\n",
       "                     -8.02346473e-01, -8.05264479e-01, -8.25318954e-01, -8.26678573e-01,\n",
       "                     -8.32909123e-01, -8.41567186e-01, -8.47297860e-01, -8.60201265e-01,\n",
       "                     -8.66166345e-01, -8.75468737e-01, -8.82389180e-01, -8.87303195e-01,\n",
       "                     -8.90972924e-01, -8.97941593e-01, -9.16290732e-01, -9.29535959e-01,\n",
       "                     -9.47381319e-01, -9.49080555e-01, -9.55511445e-01, -9.62137120e-01,\n",
       "                     -9.80829253e-01, -9.98528830e-01, -1.00552187e+00, -1.01160091e+00,\n",
       "                     -1.01693426e+00, -1.02165125e+00, -1.02290047e+00, -1.02450432e+00,\n",
       "                     -1.02961942e+00, -1.03609193e+00, -1.05416053e+00, -1.05480967e+00,\n",
       "                     -1.05605267e+00, -1.06087196e+00, -1.08261195e+00, -1.08518927e+00,\n",
       "                     -1.08663610e+00, -1.09330724e+00, -1.09861229e+00, -1.10809103e+00,\n",
       "                     -1.12718566e+00, -1.12846525e+00, -1.14117190e+00, -1.14356368e+00,\n",
       "                     -1.17007125e+00, -1.17163742e+00, -1.17411984e+00, -1.17569203e+00,\n",
       "                     -1.17677706e+00, -1.18958407e+00, -1.20397280e+00, -1.21302264e+00,\n",
       "                     -1.22050211e+00, -1.22377543e+00, -1.25276297e+00, -1.25804003e+00,\n",
       "                     -1.25988044e+00, -1.26923781e+00, -1.27296568e+00, -1.28966753e+00,\n",
       "                     -1.29098418e+00, -1.32538561e+00, -1.34117393e+00, -1.34373475e+00,\n",
       "                     -1.35239281e+00, -1.35454566e+00, -1.36524095e+00, -1.37029402e+00,\n",
       "                     -1.38629436e+00, -1.40089316e+00, -1.40399394e+00, -1.40691365e+00,\n",
       "                     -1.43848011e+00, -1.44238383e+00, -1.45597428e+00, -1.48807706e+00,\n",
       "                     -1.50407740e+00, -1.52121368e+00, -1.52605630e+00, -1.53147637e+00,\n",
       "                     -1.53393036e+00, -1.56977266e+00, -1.57553636e+00, -1.60943791e+00,\n",
       "                     -1.75785792e+00, -1.75949861e+00, -1.79175947e+00, -1.83258146e+00,\n",
       "                     -1.87180218e+00, -1.92990981e+00, -1.93075834e+00, -1.94591015e+00,\n",
       "                     -2.06142304e+00, -2.07944154e+00, -2.14006616e+00, -2.19722458e+00,\n",
       "                     -2.23359222e+00, -2.24723500e+00, -2.30258509e+00, -2.44234704e+00,\n",
       "                     -2.48490665e+00, -2.83321334e+00, -3.06027079e+00, -3.13549422e+00,\n",
       "                     -3.21887582e+00, -3.45387764e+01]), auc_score=0.5553982812116673, privacy_risk=0.5401839715418966, accuracy=0.5398928252456088, tpr_ind=0.6798926014319809, tnr_ind=0.40047534165181226, test_train_ratio=1.0041766109785202, dataset_size=[3352, 3366]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00591541, 0.00680272, 0.00828157, 0.01538007,\n",
       "                     0.01597161, 0.01715469, 0.02011239, 0.02454895, 0.02721088,\n",
       "                     0.03046436, 0.03253475, 0.0411121 , 0.04466134, 0.05116829,\n",
       "                     0.0570837 , 0.05944987, 0.06240757, 0.06654836, 0.0700976 ,\n",
       "                     0.07305531, 0.07778764, 0.07837918, 0.07837918, 0.08074534,\n",
       "                     0.08340728, 0.11239278, 0.12037859, 0.12688554, 0.12954747,\n",
       "                     0.13901213, 0.14108252, 0.15113872, 0.17361727, 0.17568767,\n",
       "                     0.17716652, 0.18219462, 0.1863354 , 0.19757468, 0.21147589,\n",
       "                     0.23779947, 0.24815143, 0.24992606, 0.25613724, 0.2685596 ,\n",
       "                     0.27270038, 0.28630583, 0.29133392, 0.32209406, 0.32889678,\n",
       "                     0.33747412, 0.34102337, 0.34753032, 0.35019225, 0.37296658,\n",
       "                     0.38095238, 0.38450163, 0.38952972, 0.39396628, 0.39929015,\n",
       "                     0.40372671, 0.40431825, 0.42324756, 0.436853  , 0.46317657,\n",
       "                     0.47619048, 0.48950015, 0.50133097, 0.50310559, 0.50547175,\n",
       "                     0.52292221, 0.53297841, 0.57320319, 0.57763975, 0.58237208,\n",
       "                     0.58740018, 0.60662526, 0.6152026 , 0.61904762, 0.63561077,\n",
       "                     0.64477965, 0.64477965, 0.64773736, 0.65069506, 0.65897663,\n",
       "                     0.67997634, 0.69890565, 0.70482106, 0.72818693, 0.73203194,\n",
       "                     0.74770778, 0.75303165, 0.76042591, 0.76663709, 0.77639752,\n",
       "                     0.78320024, 0.78497486, 0.78852411, 0.79148181, 0.79887607,\n",
       "                     0.80301686, 0.81543922, 0.81780538, 0.82224194, 0.82845312,\n",
       "                     0.83318545, 0.83584738, 0.83850932, 0.84057971, 0.86542443,\n",
       "                     0.86719905, 0.87518486, 0.87902987, 0.88198758, 0.88524105,\n",
       "                     0.88760722, 0.89086069, 0.89440994, 0.89736764, 0.91866312,\n",
       "                     0.92191659, 0.92428276, 0.92724046, 0.92871931, 0.93493049,\n",
       "                     0.93493049, 0.93818397, 0.93907128, 0.94321207, 0.94380361,\n",
       "                     0.9509021 , 0.95445135, 0.9559302 , 0.95652174, 0.9588879 ,\n",
       "                     0.96302869, 0.96569062, 0.96628217, 0.96805679, 0.96864833,\n",
       "                     0.97042295, 0.97042295, 0.9719018 , 1.        ]), tpr=array([0.        , 0.01947857, 0.02157627, 0.02397363, 0.03026671,\n",
       "                     0.03326341, 0.03596044, 0.03925682, 0.04644891, 0.05064429,\n",
       "                     0.05513935, 0.05903506, 0.07401858, 0.07821396, 0.08630506,\n",
       "                     0.09229847, 0.09769254, 0.10248726, 0.10638298, 0.11237639,\n",
       "                     0.11567276, 0.11986815, 0.12226551, 0.12496254, 0.12795924,\n",
       "                     0.13125562, 0.16751573, 0.17500749, 0.18249925, 0.1860953 ,\n",
       "                     0.1971831 , 0.19928079, 0.2082709 , 0.2325442 , 0.23643992,\n",
       "                     0.23883728, 0.24543003, 0.2517231 , 0.26311058, 0.27749476,\n",
       "                     0.30656278, 0.32214564, 0.32514234, 0.33083608, 0.34761762,\n",
       "                     0.35241235, 0.36589751, 0.37039257, 0.40575367, 0.41204675,\n",
       "                     0.41953851, 0.42433323, 0.432724  , 0.43602038, 0.46119269,\n",
       "                     0.46538807, 0.46868445, 0.47467785, 0.47737489, 0.48186994,\n",
       "                     0.48816302, 0.48996104, 0.50194786, 0.51633203, 0.54480072,\n",
       "                     0.56068325, 0.57057237, 0.58016182, 0.58255918, 0.58435721,\n",
       "                     0.59814204, 0.6056338 , 0.65238238, 0.66077315, 0.6673659 ,\n",
       "                     0.67365898, 0.68774348, 0.69373689, 0.69703326, 0.7159125 ,\n",
       "                     0.72969733, 0.73119568, 0.73389272, 0.73778843, 0.74468085,\n",
       "                     0.76086305, 0.78333833, 0.78903206, 0.8189991 , 0.82289482,\n",
       "                     0.83368295, 0.83937669, 0.84447108, 0.84866647, 0.86065328,\n",
       "                     0.8675457 , 0.86904405, 0.87114174, 0.87353911, 0.88013185,\n",
       "                     0.88342823, 0.89451603, 0.89631405, 0.90170812, 0.90710219,\n",
       "                     0.91069823, 0.91219658, 0.91459395, 0.91549296, 0.93137549,\n",
       "                     0.93287384, 0.9403656 , 0.94246329, 0.94486065, 0.94665868,\n",
       "                     0.94875637, 0.94995505, 0.95265208, 0.95624813, 0.97273   ,\n",
       "                     0.97422835, 0.97542703, 0.97722505, 0.97812406, 0.98351813,\n",
       "                     0.98441714, 0.98561582, 0.98651483, 0.98771352, 0.98831286,\n",
       "                     0.99250824, 0.99370692, 0.99460593, 0.9949056 , 0.99550494,\n",
       "                     0.99610429, 0.99670363, 0.9970033 , 0.99760264, 0.99790231,\n",
       "                     0.99940066, 0.99970033, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -2.23143551e-01,\n",
       "                     -2.87682072e-01, -3.36472237e-01, -3.67724780e-01, -3.74693449e-01,\n",
       "                     -4.05465108e-01, -4.51985124e-01, -4.70003629e-01, -4.79573080e-01,\n",
       "                     -4.94696242e-01, -4.96436886e-01, -5.10825624e-01, -5.30628251e-01,\n",
       "                     -5.43615447e-01, -5.59615788e-01, -5.70544858e-01, -5.87786665e-01,\n",
       "                     -5.97837001e-01, -6.19039208e-01, -6.28608659e-01, -6.35988767e-01,\n",
       "                     -6.41853886e-01, -6.46627165e-01, -6.93147181e-01, -7.12949808e-01,\n",
       "                     -7.32367894e-01, -7.33969175e-01, -7.45790914e-01, -7.62140052e-01,\n",
       "                     -7.88457360e-01, -7.98507696e-01, -8.02346473e-01, -8.10930216e-01,\n",
       "                     -8.20980552e-01, -8.26678573e-01, -8.39750655e-01, -8.47297860e-01,\n",
       "                     -8.50239039e-01, -8.60940637e-01, -8.75468737e-01, -8.84202417e-01,\n",
       "                     -8.87303195e-01, -8.90972924e-01, -8.93817876e-01, -9.02867712e-01,\n",
       "                     -9.16290732e-01, -9.25769476e-01, -9.40007258e-01, -9.40983344e-01,\n",
       "                     -9.58254931e-01, -9.69400557e-01, -9.80829253e-01, -9.98528830e-01,\n",
       "                     -1.00330211e+00, -1.01160091e+00, -1.02165125e+00, -1.02961942e+00,\n",
       "                     -1.03301501e+00, -1.04145387e+00, -1.04731899e+00, -1.04877991e+00,\n",
       "                     -1.05925121e+00, -1.09861229e+00, -1.10866262e+00, -1.12938395e+00,\n",
       "                     -1.13943428e+00, -1.15267951e+00, -1.16179119e+00, -1.16315081e+00,\n",
       "                     -1.16475209e+00, -1.16760516e+00, -1.17163742e+00, -1.20397280e+00,\n",
       "                     -1.20609820e+00, -1.20896035e+00, -1.21302264e+00, -1.21345155e+00,\n",
       "                     -1.21478372e+00, -1.22377543e+00, -1.23676263e+00, -1.24171313e+00,\n",
       "                     -1.24653242e+00, -1.25276297e+00, -1.27349887e+00, -1.27506873e+00,\n",
       "                     -1.27536280e+00, -1.28519824e+00, -1.29167838e+00, -1.30405626e+00,\n",
       "                     -1.30992138e+00, -1.31218639e+00, -1.32175584e+00, -1.33041390e+00,\n",
       "                     -1.33500107e+00, -1.34992672e+00, -1.35454566e+00, -1.38629436e+00,\n",
       "                     -1.40876722e+00, -1.41952001e+00, -1.42711636e+00, -1.49165488e+00,\n",
       "                     -1.50407740e+00, -1.52242654e+00, -1.52605630e+00, -1.53147637e+00,\n",
       "                     -1.54044504e+00, -1.56704235e+00, -1.56861592e+00, -1.57691472e+00,\n",
       "                     -1.60943791e+00, -1.65822808e+00, -1.70474809e+00, -1.74296931e+00,\n",
       "                     -1.74919985e+00, -1.75401914e+00, -1.77777323e+00, -1.77956420e+00,\n",
       "                     -1.79175947e+00, -1.83258146e+00, -1.87180218e+00, -1.94591015e+00,\n",
       "                     -1.97716269e+00, -1.99243016e+00, -2.01490302e+00, -2.03688193e+00,\n",
       "                     -2.07944154e+00, -2.19722458e+00, -2.35137526e+00, -2.42036813e+00,\n",
       "                     -2.48490665e+00, -2.70805020e+00, -2.74084002e+00, -2.77258872e+00,\n",
       "                     -2.80336038e+00, -2.83321334e+00, -2.94443898e+00, -3.04452244e+00,\n",
       "                     -3.12676054e+00, -3.21887582e+00, -3.46573590e+00, -3.45387764e+01]), auc_score=0.5684543807490554, privacy_risk=0.5454314362453299, accuracy=0.5436141708841917, tpr_ind=0.822894815702727, tnr_ind=0.26796805678793256, test_train_ratio=1.0131854959544502, dataset_size=[3337, 3381]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.01098901, 0.01217701, 0.01277101, 0.01425601,\n",
       "                     0.01811702, 0.02138402, 0.02286902, 0.02554203, 0.02821503,\n",
       "                     0.03088803, 0.03385803, 0.03979804, 0.04306504, 0.04484704,\n",
       "                     0.04662905, 0.04959905, 0.05464805, 0.06029106, 0.07068607,\n",
       "                     0.07217107, 0.07870508, 0.08078408, 0.08583309, 0.0953371 ,\n",
       "                     0.11523612, 0.11642412, 0.12177012, 0.13305613, 0.13662014,\n",
       "                     0.14998515, 0.15147015, 0.15473715, 0.15919216, 0.18740719,\n",
       "                     0.21502822, 0.22453222, 0.22869023, 0.23403623, 0.23522424,\n",
       "                     0.23611524, 0.24205524, 0.24621325, 0.25066825, 0.25155925,\n",
       "                     0.25987526, 0.26967627, 0.33323433, 0.34244134, 0.35937036,\n",
       "                     0.36352836, 0.37332937, 0.37778438, 0.37808138, 0.38045738,\n",
       "                     0.4009504 , 0.4039204 , 0.40510841, 0.41431541, 0.41847342,\n",
       "                     0.43391743, 0.43510544, 0.44906445, 0.45144045, 0.45500446,\n",
       "                     0.45589546, 0.47846748, 0.48470448, 0.48737749, 0.51410751,\n",
       "                     0.53727354, 0.54915355, 0.55152955, 0.55390555, 0.56222156,\n",
       "                     0.56400356, 0.56459756, 0.57142857, 0.57796258, 0.58390258,\n",
       "                     0.61746362, 0.62637363, 0.63558064, 0.63676864, 0.64003564,\n",
       "                     0.64478764, 0.64656965, 0.67745768, 0.67983368, 0.68517969,\n",
       "                     0.69201069, 0.6952777 , 0.7021087 , 0.7047817 , 0.70864271,\n",
       "                     0.71072171, 0.71398871, 0.71458271, 0.71606772, 0.72378972,\n",
       "                     0.72765073, 0.74071874, 0.75913276, 0.76804277, 0.77398277,\n",
       "                     0.78081378, 0.78645679, 0.78883279, 0.8036828 , 0.83070983,\n",
       "                     0.83486783, 0.83813484, 0.84051084, 0.84496584, 0.84793585,\n",
       "                     0.85209385, 0.86783487, 0.87436887, 0.87912088, 0.88090288,\n",
       "                     0.88357588, 0.88773389, 0.89337689, 0.89456489, 0.8978319 ,\n",
       "                     0.8996139 , 0.91624592, 0.92040392, 0.92248292, 0.92396792,\n",
       "                     0.92485892, 0.92871993, 0.93703594, 0.93733294, 0.93852094,\n",
       "                     0.94119394, 0.94475794, 0.94683695, 0.95129195, 0.95218295,\n",
       "                     0.95247995, 0.95337095, 0.95455895, 0.95634096, 0.95752896,\n",
       "                     0.95990496, 0.96020196, 0.96079596, 0.96138996, 0.96287496,\n",
       "                     0.96317196, 1.        ]), tpr=array([0.        , 0.02626082, 0.02954342, 0.03193077, 0.03342286,\n",
       "                     0.03939123, 0.04237541, 0.04416592, 0.0486422 , 0.05401373,\n",
       "                     0.05729633, 0.06386153, 0.07012832, 0.0731125 , 0.07520143,\n",
       "                     0.07967771, 0.08564608, 0.09161444, 0.09877648, 0.10981796,\n",
       "                     0.11190689, 0.11906893, 0.12444047, 0.13011041, 0.14174873,\n",
       "                     0.16651746, 0.1703969 , 0.17666368, 0.18591465, 0.19039093,\n",
       "                     0.20590868, 0.20740078, 0.21128021, 0.21635333, 0.23873471,\n",
       "                     0.2661892 , 0.27872277, 0.28260221, 0.29155476, 0.29364369,\n",
       "                     0.29632945, 0.30229782, 0.30945986, 0.3133393 , 0.31781558,\n",
       "                     0.32497762, 0.33572068, 0.39629961, 0.41181737, 0.43151298,\n",
       "                     0.43628768, 0.44673232, 0.45031334, 0.45180543, 0.45419278,\n",
       "                     0.47358997, 0.48134885, 0.48403462, 0.49567293, 0.50074605,\n",
       "                     0.51327962, 0.51656222, 0.53446732, 0.53745151, 0.54073411,\n",
       "                     0.54252462, 0.56430916, 0.57117278, 0.57564906, 0.59892569,\n",
       "                     0.62250075, 0.6314533 , 0.63413906, 0.63921218, 0.64756789,\n",
       "                     0.65114891, 0.65383468, 0.65980304, 0.66547299, 0.67382871,\n",
       "                     0.70814682, 0.71351835, 0.723963  , 0.7272456 , 0.73112504,\n",
       "                     0.73649657, 0.73798866, 0.78066249, 0.78334825, 0.78842137,\n",
       "                     0.79558341, 0.8003581 , 0.80423754, 0.80662489, 0.80990749,\n",
       "                     0.81259326, 0.81468218, 0.81587586, 0.81736795, 0.82214264,\n",
       "                     0.82602208, 0.83676514, 0.84870188, 0.85347657, 0.85735601,\n",
       "                     0.86153387, 0.86571173, 0.86660698, 0.87794688, 0.9009251 ,\n",
       "                     0.90450612, 0.90510295, 0.90599821, 0.90928081, 0.91286183,\n",
       "                     0.9155476 , 0.92867801, 0.93434796, 0.93882423, 0.94151   ,\n",
       "                     0.94389734, 0.94688153, 0.95105939, 0.95344673, 0.9561325 ,\n",
       "                     0.95792301, 0.9674724 , 0.96926291, 0.97045658, 0.97224709,\n",
       "                     0.97344076, 0.97761862, 0.98239332, 0.98418383, 0.98567592,\n",
       "                     0.98716801, 0.99074903, 0.99134587, 0.99224112, 0.99283796,\n",
       "                     0.99313638, 0.9934348 , 0.99582214, 0.99641898, 0.99701582,\n",
       "                     0.99820949, 0.99850791, 0.99910474, 0.99940316, 0.99970158,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -8.70113770e-02, -1.17783036e-01,\n",
       "                     -1.82321557e-01, -2.23143551e-01, -2.62364264e-01, -2.87682072e-01,\n",
       "                     -3.36472237e-01, -3.67724780e-01, -3.74693449e-01, -4.05465108e-01,\n",
       "                     -5.10825624e-01, -5.30628251e-01, -5.38996501e-01, -5.50046337e-01,\n",
       "                     -5.59615788e-01, -5.87786665e-01, -6.06135804e-01, -6.08589793e-01,\n",
       "                     -6.19039208e-01, -6.28608659e-01, -6.35988767e-01, -6.39079959e-01,\n",
       "                     -6.40503447e-01, -6.93147181e-01, -7.30887509e-01, -7.39667196e-01,\n",
       "                     -7.40400065e-01, -7.57685702e-01, -7.67255153e-01, -7.88457360e-01,\n",
       "                     -8.02346473e-01, -8.04372816e-01, -8.06475866e-01, -8.10930216e-01,\n",
       "                     -8.47297860e-01, -8.69037847e-01, -8.75468737e-01, -8.87303195e-01,\n",
       "                     -8.93817876e-01, -8.96088025e-01, -8.99483614e-01, -9.00786545e-01,\n",
       "                     -9.02867712e-01, -9.16290732e-01, -9.27340568e-01, -9.29017286e-01,\n",
       "                     -9.31558204e-01, -9.34309237e-01, -9.40983344e-01, -9.44461609e-01,\n",
       "                     -9.49080555e-01, -9.55511445e-01, -9.65080896e-01, -9.67276287e-01,\n",
       "                     -9.76009967e-01, -9.80829253e-01, -9.90398704e-01, -9.95428052e-01,\n",
       "                     -9.98528830e-01, -1.00330211e+00, -1.01160091e+00, -1.02961942e+00,\n",
       "                     -1.03609193e+00, -1.04145387e+00, -1.04707864e+00, -1.06919840e+00,\n",
       "                     -1.07613943e+00, -1.09002854e+00, -1.09861229e+00, -1.12059120e+00,\n",
       "                     -1.13497993e+00, -1.13707857e+00, -1.14513230e+00, -1.15267951e+00,\n",
       "                     -1.17007125e+00, -1.17865500e+00, -1.18269541e+00, -1.20039498e+00,\n",
       "                     -1.20048848e+00, -1.20397280e+00, -1.20682587e+00, -1.21302264e+00,\n",
       "                     -1.21924028e+00, -1.22050211e+00, -1.22377543e+00, -1.22747078e+00,\n",
       "                     -1.23676263e+00, -1.24432410e+00, -1.25276297e+00, -1.27046255e+00,\n",
       "                     -1.28519824e+00, -1.28785429e+00, -1.29098418e+00, -1.29928298e+00,\n",
       "                     -1.31218639e+00, -1.32175584e+00, -1.33500107e+00, -1.35454566e+00,\n",
       "                     -1.36687628e+00, -1.37230812e+00, -1.38629436e+00, -1.40179855e+00,\n",
       "                     -1.42403469e+00, -1.43848011e+00, -1.45528723e+00, -1.46633707e+00,\n",
       "                     -1.46835931e+00, -1.47924047e+00, -1.48538526e+00, -1.50407740e+00,\n",
       "                     -1.54044504e+00, -1.55334845e+00, -1.55814462e+00, -1.56397554e+00,\n",
       "                     -1.57239664e+00, -1.58816051e+00, -1.60943791e+00, -1.63141682e+00,\n",
       "                     -1.65822808e+00, -1.68639895e+00, -1.70474809e+00, -1.74919985e+00,\n",
       "                     -1.75401914e+00, -1.76358859e+00, -1.79175947e+00, -1.81915844e+00,\n",
       "                     -1.83258146e+00, -1.87180218e+00, -1.90954250e+00, -1.91481956e+00,\n",
       "                     -1.94591015e+00, -1.96944065e+00, -2.02814825e+00, -2.07944154e+00,\n",
       "                     -2.11021320e+00, -2.14006616e+00, -2.19722458e+00, -2.30258509e+00,\n",
       "                     -2.39789527e+00, -2.48490665e+00, -2.54553127e+00, -2.56494936e+00,\n",
       "                     -2.63905733e+00, -2.77258872e+00, -2.94443898e+00, -2.97041447e+00,\n",
       "                     -2.99573227e+00, -3.13549422e+00, -4.02535169e+00, -3.45387764e+01]), auc_score=0.5673022526200683, privacy_risk=0.5525402033906958, accuracy=0.5519499851146175, tpr_ind=0.8003581020590869, tnr_ind=0.3047223047223047, test_train_ratio=1.004774694121158, dataset_size=[3351, 3367]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00801187, 0.00949555, 0.01216617, 0.01394659,\n",
       "                     0.01543027, 0.01839763, 0.02047478, 0.02225519, 0.02403561,\n",
       "                     0.02700297, 0.02937685, 0.03353116, 0.03501484, 0.03946588,\n",
       "                     0.04183976, 0.04302671, 0.04688427, 0.05192878, 0.05905045,\n",
       "                     0.06973294, 0.07240356, 0.07744807, 0.08664688, 0.0884273 ,\n",
       "                     0.1041543 , 0.10830861, 0.11068249, 0.11305638, 0.12818991,\n",
       "                     0.13234421, 0.13768546, 0.13946588, 0.14154303, 0.14747774,\n",
       "                     0.15133531, 0.15489614, 0.15845697, 0.16409496, 0.16439169,\n",
       "                     0.17833828, 0.20385757, 0.21513353, 0.22284866, 0.23501484,\n",
       "                     0.24124629, 0.24362018, 0.24866469, 0.24896142, 0.25281899,\n",
       "                     0.25637982, 0.26884273, 0.31632047, 0.3231454 , 0.33620178,\n",
       "                     0.34540059, 0.35548961, 0.36587537, 0.38160237, 0.38635015,\n",
       "                     0.4       , 0.41186944, 0.41839763, 0.42462908, 0.42759644,\n",
       "                     0.44124629, 0.44688427, 0.46231454, 0.47002967, 0.47596439,\n",
       "                     0.47952522, 0.48724036, 0.50593472, 0.50860534, 0.51780415,\n",
       "                     0.53086053, 0.53115727, 0.55519288, 0.58694362, 0.59673591,\n",
       "                     0.60623145, 0.62225519, 0.62492582, 0.63620178, 0.64777448,\n",
       "                     0.66023739, 0.66231454, 0.67091988, 0.684273  , 0.68813056,\n",
       "                     0.6884273 , 0.69762611, 0.70178042, 0.70919881, 0.71364985,\n",
       "                     0.72077151, 0.73620178, 0.74332344, 0.74925816, 0.77477745,\n",
       "                     0.7851632 , 0.78931751, 0.80029674, 0.80059347, 0.80504451,\n",
       "                     0.81097923, 0.81632047, 0.81721068, 0.81958457, 0.82522255,\n",
       "                     0.83442136, 0.8421365 , 0.84688427, 0.86735905, 0.87893175,\n",
       "                     0.884273  , 0.88783383, 0.90237389, 0.91008902, 0.91246291,\n",
       "                     0.91305638, 0.91454006, 0.92017804, 0.92077151, 0.92195846,\n",
       "                     0.92284866, 0.92908012, 0.93145401, 0.93204748, 0.93501484,\n",
       "                     0.93827893, 0.94065282, 0.94094955, 0.94362018, 0.94688427,\n",
       "                     0.94866469, 0.9495549 , 0.95222552, 0.95281899, 0.95637982,\n",
       "                     0.95875371, 0.95964392, 0.96053412, 0.96320475, 0.9652819 ,\n",
       "                     0.96854599, 1.        ]), tpr=array([0.        , 0.02210275, 0.02419355, 0.02568698, 0.02837515,\n",
       "                     0.03076464, 0.03405018, 0.04121864, 0.04271207, 0.04778973,\n",
       "                     0.0567503 , 0.06152927, 0.0672043 , 0.06899642, 0.07317802,\n",
       "                     0.07676225, 0.07945042, 0.08243728, 0.08870968, 0.09348865,\n",
       "                     0.11111111, 0.11469534, 0.11947431, 0.13142174, 0.13590203,\n",
       "                     0.16069295, 0.1660693 , 0.17054958, 0.17473118, 0.18518519,\n",
       "                     0.18996416, 0.19444444, 0.19653524, 0.20011947, 0.20878136,\n",
       "                     0.21385902, 0.21714456, 0.22192354, 0.22819594, 0.2311828 ,\n",
       "                     0.24671446, 0.27389486, 0.28584229, 0.29241338, 0.30615293,\n",
       "                     0.31541219, 0.31839904, 0.32616487, 0.32706093, 0.33154122,\n",
       "                     0.33841099, 0.34677419, 0.39366786, 0.40023895, 0.41308244,\n",
       "                     0.42741935, 0.4369773 , 0.4495221 , 0.46475508, 0.47102748,\n",
       "                     0.48387097, 0.49701314, 0.50567503, 0.51164875, 0.51493429,\n",
       "                     0.52867384, 0.53584229, 0.54958184, 0.55227001, 0.55525687,\n",
       "                     0.55854241, 0.56242533, 0.57885305, 0.58273596, 0.59617682,\n",
       "                     0.60782557, 0.609319  , 0.63888889, 0.66367981, 0.67562724,\n",
       "                     0.68399044, 0.69504182, 0.69713262, 0.70609319, 0.71714456,\n",
       "                     0.73148148, 0.73476703, 0.74432497, 0.75149343, 0.75776583,\n",
       "                     0.75955795, 0.76523297, 0.77299881, 0.78016726, 0.78345281,\n",
       "                     0.78882915, 0.80525687, 0.81272401, 0.81780167, 0.84080048,\n",
       "                     0.84886499, 0.85215054, 0.86320191, 0.86499403, 0.86827957,\n",
       "                     0.87544803, 0.880227  , 0.88291517, 0.88410992, 0.88799283,\n",
       "                     0.89635603, 0.90382318, 0.90740741, 0.91965352, 0.92801673,\n",
       "                     0.93130227, 0.93369176, 0.94892473, 0.95489845, 0.95728793,\n",
       "                     0.95818399, 0.95967742, 0.96505376, 0.96565114, 0.96774194,\n",
       "                     0.96863799, 0.97401434, 0.97550777, 0.97610514, 0.97849462,\n",
       "                     0.98237754, 0.98387097, 0.98506571, 0.98805257, 0.98864994,\n",
       "                     0.989546  , 0.99074074, 0.99253286, 0.99313023, 0.99432497,\n",
       "                     0.99641577, 0.99731183, 0.99761051, 0.99850657, 0.99910394,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -1.82321557e-01,\n",
       "                     -2.00670695e-01, -2.23143551e-01, -2.41162057e-01, -2.87682072e-01,\n",
       "                     -3.36472237e-01, -3.44840486e-01, -4.05465108e-01, -4.46287103e-01,\n",
       "                     -4.56758402e-01, -5.10825624e-01, -5.38996501e-01, -5.59615788e-01,\n",
       "                     -5.75364145e-01, -5.87786665e-01, -5.93063722e-01, -5.94707108e-01,\n",
       "                     -6.04593783e-01, -6.06135804e-01, -6.28608659e-01, -6.41853886e-01,\n",
       "                     -6.59245629e-01, -6.93147181e-01, -7.20546155e-01, -7.25937003e-01,\n",
       "                     -7.28238500e-01, -7.48717032e-01, -7.53771802e-01, -7.57685702e-01,\n",
       "                     -7.62140052e-01, -7.73189888e-01, -7.75838896e-01, -7.77704569e-01,\n",
       "                     -7.80158558e-01, -7.82759339e-01, -7.84118959e-01, -7.88457360e-01,\n",
       "                     -8.02346473e-01, -8.07260487e-01, -8.10930216e-01, -8.20980552e-01,\n",
       "                     -8.25318954e-01, -8.28692673e-01, -8.32909123e-01, -8.36248024e-01,\n",
       "                     -8.47297860e-01, -8.75468737e-01, -8.89857475e-01, -9.16290732e-01,\n",
       "                     -9.20105104e-01, -9.34309237e-01, -9.39280250e-01, -9.49080555e-01,\n",
       "                     -9.65080896e-01, -9.80829253e-01, -9.88155293e-01, -9.98528830e-01,\n",
       "                     -1.00948451e+00, -1.01160091e+00, -1.01473080e+00, -1.02961942e+00,\n",
       "                     -1.03609193e+00, -1.03889305e+00, -1.04145387e+00, -1.05416053e+00,\n",
       "                     -1.06087196e+00, -1.06471074e+00, -1.06784063e+00, -1.07263680e+00,\n",
       "                     -1.09861229e+00, -1.12393010e+00, -1.14209740e+00, -1.15671992e+00,\n",
       "                     -1.16315081e+00, -1.16378192e+00, -1.16465570e+00, -1.17093295e+00,\n",
       "                     -1.17865500e+00, -1.18487263e+00, -1.18958407e+00, -1.19392247e+00,\n",
       "                     -1.20126644e+00, -1.20397280e+00, -1.21302264e+00, -1.21639532e+00,\n",
       "                     -1.25276297e+00, -1.27296568e+00, -1.29928298e+00, -1.30405626e+00,\n",
       "                     -1.30625165e+00, -1.32175584e+00, -1.33977435e+00, -1.34373475e+00,\n",
       "                     -1.34925309e+00, -1.35583515e+00, -1.35644140e+00, -1.35663815e+00,\n",
       "                     -1.37699197e+00, -1.38629436e+00, -1.39302839e+00, -1.42711636e+00,\n",
       "                     -1.45225233e+00, -1.45667516e+00, -1.46151778e+00, -1.49165488e+00,\n",
       "                     -1.50407740e+00, -1.52939520e+00, -1.57307027e+00, -1.58514522e+00,\n",
       "                     -1.59263079e+00, -1.59469563e+00, -1.59504917e+00, -1.60943791e+00,\n",
       "                     -1.63413053e+00, -1.64790419e+00, -1.64865863e+00, -1.65822808e+00,\n",
       "                     -1.67397643e+00, -1.68639895e+00, -1.69459572e+00, -1.70474809e+00,\n",
       "                     -1.71765150e+00, -1.73460106e+00, -1.78245708e+00, -1.79175947e+00,\n",
       "                     -1.87180218e+00, -1.90954250e+00, -1.92368701e+00, -1.94591015e+00,\n",
       "                     -1.98100147e+00, -2.00148000e+00, -2.01490302e+00, -2.07944154e+00,\n",
       "                     -2.11021320e+00, -2.19722458e+00, -2.56494936e+00, -2.63905733e+00,\n",
       "                     -2.70805020e+00, -2.83321334e+00, -2.94443898e+00, -2.97892516e+00,\n",
       "                     -2.99573227e+00, -4.11087386e+00, -3.45387764e+01]), auc_score=0.5644170841177159, privacy_risk=0.5444790104548887, accuracy=0.5445072938374517, tpr_ind=0.53584229390681, tnr_ind=0.5531157270029674, test_train_ratio=1.0065710872162486, dataset_size=[3348, 3370]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00843373, 0.00963855, 0.01144578, 0.01415663,\n",
       "                     0.01596386, 0.01716867, 0.01746988, 0.01837349, 0.0253012 ,\n",
       "                     0.02891566, 0.03373494, 0.03403614, 0.03614458, 0.04186747,\n",
       "                     0.05301205, 0.05421687, 0.05783133, 0.06084337, 0.07108434,\n",
       "                     0.07168675, 0.07921687, 0.08584337, 0.08704819, 0.10120482,\n",
       "                     0.10240964, 0.11385542, 0.1253012 , 0.14518072, 0.15120482,\n",
       "                     0.15933735, 0.16024096, 0.16385542, 0.16777108, 0.18915663,\n",
       "                     0.19277108, 0.19728916, 0.2       , 0.20722892, 0.23222892,\n",
       "                     0.23644578, 0.2439759 , 0.24879518, 0.25150602, 0.25481928,\n",
       "                     0.27771084, 0.29156627, 0.29548193, 0.30662651, 0.31777108,\n",
       "                     0.32108434, 0.3253012 , 0.33343373, 0.33674699, 0.34066265,\n",
       "                     0.35      , 0.35722892, 0.35963855, 0.36144578, 0.36807229,\n",
       "                     0.37259036, 0.39246988, 0.4003012 , 0.42078313, 0.42319277,\n",
       "                     0.4439759 , 0.44487952, 0.45512048, 0.46686747, 0.47349398,\n",
       "                     0.48072289, 0.4873494 , 0.48915663, 0.50210843, 0.50963855,\n",
       "                     0.5313253 , 0.53975904, 0.54608434, 0.55090361, 0.56204819,\n",
       "                     0.56385542, 0.58554217, 0.58945783, 0.59006024, 0.61355422,\n",
       "                     0.61506024, 0.62560241, 0.62861446, 0.63072289, 0.66686747,\n",
       "                     0.67680723, 0.68042169, 0.68283133, 0.69186747, 0.71566265,\n",
       "                     0.72379518, 0.72891566, 0.7560241 , 0.76024096, 0.76385542,\n",
       "                     0.77861446, 0.78704819, 0.79096386, 0.79849398, 0.80843373,\n",
       "                     0.82710843, 0.83072289, 0.84668675, 0.85      , 0.85903614,\n",
       "                     0.86837349, 0.87289157, 0.87680723, 0.88072289, 0.88403614,\n",
       "                     0.88554217, 0.8873494 , 0.89006024, 0.89698795, 0.89879518,\n",
       "                     0.90572289, 0.90722892, 0.91837349, 0.92048193, 0.92198795,\n",
       "                     0.92259036, 0.92409639, 0.9310241 , 0.93253012, 0.93343373,\n",
       "                     0.93644578, 0.93975904, 0.94036145, 0.94277108, 0.94879518,\n",
       "                     0.94909639, 0.95361446, 0.9560241 , 0.95692771, 0.95843373,\n",
       "                     0.96174699, 0.96325301, 0.96355422, 0.96656627, 0.96746988,\n",
       "                     1.        ]), tpr=array([0.        , 0.01824603, 0.02030606, 0.02383755, 0.02913479,\n",
       "                     0.03237198, 0.03531489, 0.03737493, 0.04002354, 0.04590936,\n",
       "                     0.04855798, 0.05591524, 0.05826957, 0.06150677, 0.06592113,\n",
       "                     0.0732784 , 0.07622131, 0.08034138, 0.08563861, 0.0985874 ,\n",
       "                     0.10123602, 0.11006474, 0.12065921, 0.12242496, 0.13919953,\n",
       "                     0.14155386, 0.15626839, 0.16980577, 0.19364332, 0.19923484,\n",
       "                     0.20924073, 0.21277222, 0.21600942, 0.21865803, 0.24072984,\n",
       "                     0.24661566, 0.25456151, 0.25838729, 0.26839317, 0.29693938,\n",
       "                     0.2992937 , 0.30959388, 0.31783402, 0.32283696, 0.32577987,\n",
       "                     0.34961742, 0.36256622, 0.36698058, 0.37963508, 0.38964097,\n",
       "                     0.39346675, 0.39640965, 0.40582696, 0.40935845, 0.41347852,\n",
       "                     0.41995291, 0.42377869, 0.42701589, 0.43054738, 0.43908181,\n",
       "                     0.44143614, 0.46615656, 0.47321954, 0.48969982, 0.49323131,\n",
       "                     0.51618599, 0.51765745, 0.52825191, 0.54031783, 0.54649794,\n",
       "                     0.55591524, 0.56268393, 0.56621542, 0.57945851, 0.58446145,\n",
       "                     0.60388464, 0.61506769, 0.61918776, 0.62301354, 0.63243084,\n",
       "                     0.63449088, 0.65244261, 0.6559741 , 0.65862272, 0.68187169,\n",
       "                     0.68393172, 0.69187758, 0.69570335, 0.69776339, 0.73278399,\n",
       "                     0.7451442 , 0.74955856, 0.75279576, 0.76162448, 0.78840494,\n",
       "                     0.79546792, 0.79958799, 0.82548558, 0.82960565, 0.83225427,\n",
       "                     0.8472631 , 0.85432607, 0.85726898, 0.86521483, 0.87374926,\n",
       "                     0.88905238, 0.89199529, 0.90818128, 0.91171277, 0.91818717,\n",
       "                     0.92731018, 0.93290171, 0.93908181, 0.94202472, 0.94526192,\n",
       "                     0.94614479, 0.9490877 , 0.95291348, 0.958505  , 0.96056504,\n",
       "                     0.96350795, 0.96586227, 0.97204238, 0.9743967 , 0.97557387,\n",
       "                     0.97645674, 0.9776339 , 0.98175397, 0.9841083 , 0.98528546,\n",
       "                     0.98616833, 0.98793408, 0.98822837, 0.9905827 , 0.99323131,\n",
       "                     0.9935256 , 0.99499706, 0.99529135, 0.99617422, 0.99735138,\n",
       "                     0.99764567, 0.99793996, 0.99852855, 0.99911713, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -2.23143551e-01,\n",
       "                     -2.87682072e-01, -3.10154928e-01, -3.36472237e-01, -3.56674944e-01,\n",
       "                     -3.67724780e-01, -4.05465108e-01, -4.41832752e-01, -4.70003629e-01,\n",
       "                     -4.85507816e-01, -4.92476485e-01, -5.10825624e-01, -5.18793793e-01,\n",
       "                     -5.30628251e-01, -5.38996501e-01, -5.43615447e-01, -5.59615788e-01,\n",
       "                     -5.75364145e-01, -5.87786665e-01, -5.90868331e-01, -6.06135804e-01,\n",
       "                     -6.10909082e-01, -6.28608659e-01, -6.41853886e-01, -6.82218110e-01,\n",
       "                     -6.93147181e-01, -7.19122667e-01, -7.22134717e-01, -7.33969175e-01,\n",
       "                     -7.37598943e-01, -7.47214402e-01, -7.70108222e-01, -7.88457360e-01,\n",
       "                     -7.98507696e-01, -8.02346473e-01, -8.04372816e-01, -8.09784084e-01,\n",
       "                     -8.10930216e-01, -8.14099791e-01, -8.26678573e-01, -8.30348302e-01,\n",
       "                     -8.32909123e-01, -8.36659462e-01, -8.40783179e-01, -8.47297860e-01,\n",
       "                     -8.63772698e-01, -8.68088630e-01, -8.69037847e-01, -8.75468737e-01,\n",
       "                     -8.78069519e-01, -8.82389180e-01, -8.87303195e-01, -9.16290732e-01,\n",
       "                     -9.31558204e-01, -9.34309237e-01, -9.49080555e-01, -9.63437510e-01,\n",
       "                     -9.65080896e-01, -9.67345903e-01, -9.80829253e-01, -9.85283603e-01,\n",
       "                     -1.01160091e+00, -1.01856958e+00, -1.02961942e+00, -1.05121005e+00,\n",
       "                     -1.06555143e+00, -1.06635143e+00, -1.06686359e+00, -1.06919840e+00,\n",
       "                     -1.07044141e+00, -1.07613943e+00, -1.07880966e+00, -1.08334482e+00,\n",
       "                     -1.09861229e+00, -1.12214279e+00, -1.12393010e+00, -1.12938395e+00,\n",
       "                     -1.14513230e+00, -1.15181632e+00, -1.15267951e+00, -1.17007125e+00,\n",
       "                     -1.17962823e+00, -1.18958407e+00, -1.20397280e+00, -1.21924028e+00,\n",
       "                     -1.23214368e+00, -1.25156177e+00, -1.25276297e+00, -1.26224171e+00,\n",
       "                     -1.26566637e+00, -1.27163145e+00, -1.28215410e+00, -1.28785429e+00,\n",
       "                     -1.29276830e+00, -1.30031551e+00, -1.31218639e+00, -1.32913595e+00,\n",
       "                     -1.33603253e+00, -1.34373475e+00, -1.36097655e+00, -1.38629436e+00,\n",
       "                     -1.42019591e+00, -1.44691898e+00, -1.45861502e+00, -1.48160454e+00,\n",
       "                     -1.48538526e+00, -1.50407740e+00, -1.50765522e+00, -1.50990832e+00,\n",
       "                     -1.53018854e+00, -1.54756251e+00, -1.57239664e+00, -1.60943791e+00,\n",
       "                     -1.62924054e+00, -1.63974326e+00, -1.66073121e+00, -1.66500776e+00,\n",
       "                     -1.70474809e+00, -1.74919985e+00, -1.79175947e+00, -1.81237876e+00,\n",
       "                     -1.90954250e+00, -1.94591015e+00, -1.98100147e+00, -2.01490302e+00,\n",
       "                     -2.06369318e+00, -2.11021320e+00, -2.12026354e+00, -2.15948425e+00,\n",
       "                     -2.19722458e+00, -2.21101790e+00, -2.26868354e+00, -2.30258509e+00,\n",
       "                     -2.32238772e+00, -2.48490665e+00, -2.51230562e+00, -2.65675691e+00,\n",
       "                     -2.77258872e+00, -2.94443898e+00, -3.09104245e+00, -3.21887582e+00,\n",
       "                     -3.55534806e+00, -3.45387764e+01]), auc_score=0.5592618265882836, privacy_risk=0.5386750356340015, accuracy=0.5391485561178923, tpr_ind=0.5794585050029429, tnr_ind=0.49789156626506026, test_train_ratio=0.9770453207769276, dataset_size=[3398, 3320]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00955224, 0.0119403 , 0.01283582, 0.01432836,\n",
       "                     0.01492537, 0.01522388, 0.01791045, 0.01970149, 0.02059701,\n",
       "                     0.02447761, 0.02716418, 0.03044776, 0.03253731, 0.03820896,\n",
       "                     0.03910448, 0.04238806, 0.05402985, 0.05522388, 0.05761194,\n",
       "                     0.06089552, 0.06208955, 0.06328358, 0.0641791 , 0.07134328,\n",
       "                     0.07850746, 0.10328358, 0.10925373, 0.1361194 , 0.13731343,\n",
       "                     0.14238806, 0.14567164, 0.14835821, 0.14925373, 0.15462687,\n",
       "                     0.1561194 , 0.15791045, 0.1761194 , 0.19492537, 0.1958209 ,\n",
       "                     0.19641791, 0.20268657, 0.20925373, 0.2119403 , 0.2480597 ,\n",
       "                     0.2680597 , 0.2761194 , 0.28358209, 0.29880597, 0.3       ,\n",
       "                     0.30776119, 0.30955224, 0.31343284, 0.32179104, 0.33283582,\n",
       "                     0.34776119, 0.35313433, 0.35731343, 0.36597015, 0.37910448,\n",
       "                     0.38656716, 0.39283582, 0.39522388, 0.42537313, 0.43044776,\n",
       "                     0.43462687, 0.43970149, 0.45373134, 0.4561194 , 0.45850746,\n",
       "                     0.47044776, 0.47522388, 0.48119403, 0.48895522, 0.50059701,\n",
       "                     0.50358209, 0.50567164, 0.51970149, 0.53402985, 0.54059701,\n",
       "                     0.54358209, 0.54746269, 0.54865672, 0.59373134, 0.59731343,\n",
       "                     0.59970149, 0.60089552, 0.61522388, 0.61791045, 0.61880597,\n",
       "                     0.63910448, 0.64328358, 0.6480597 , 0.6519403 , 0.65701493,\n",
       "                     0.65880597, 0.66925373, 0.67432836, 0.67731343, 0.68179104,\n",
       "                     0.72208955, 0.72925373, 0.73522388, 0.73701493, 0.75492537,\n",
       "                     0.75552239, 0.76358209, 0.77910448, 0.78477612, 0.78925373,\n",
       "                     0.79134328, 0.79373134, 0.80179104, 0.80686567, 0.83104478,\n",
       "                     0.8358209 , 0.84358209, 0.85432836, 0.85462687, 0.86089552,\n",
       "                     0.8719403 , 0.87791045, 0.87850746, 0.91223881, 0.91552239,\n",
       "                     0.91761194, 0.92298507, 0.92597015, 0.92656716, 0.92746269,\n",
       "                     0.9361194 , 0.94149254, 0.94208955, 0.9438806 , 0.94656716,\n",
       "                     0.94656716, 0.95223881, 0.9561194 , 0.95731343, 0.95791045,\n",
       "                     0.96089552, 0.96358209, 0.9641791 , 0.9641791 , 0.96835821,\n",
       "                     0.96835821, 1.        ]), tpr=array([0.        , 0.02375297, 0.02761283, 0.02969121, 0.03147268,\n",
       "                     0.03295724, 0.03414489, 0.03948931, 0.04216152, 0.04453682,\n",
       "                     0.0489905 , 0.05314727, 0.06057007, 0.06472684, 0.070962  ,\n",
       "                     0.07333729, 0.0783848 , 0.09085511, 0.09293349, 0.09738717,\n",
       "                     0.1030285 , 0.10421615, 0.10570071, 0.1077791 , 0.11906176,\n",
       "                     0.1273753 , 0.15706651, 0.16300475, 0.18942993, 0.19299287,\n",
       "                     0.19982185, 0.20308789, 0.20872922, 0.21110451, 0.21763658,\n",
       "                     0.21971496, 0.22327791, 0.24317102, 0.26098575, 0.26247031,\n",
       "                     0.26514252, 0.27167458, 0.27523753, 0.27731591, 0.31591449,\n",
       "                     0.33402613, 0.33937055, 0.34887173, 0.36490499, 0.36638955,\n",
       "                     0.37292162, 0.375     , 0.37975059, 0.38687648, 0.3969715 ,\n",
       "                     0.41597387, 0.41953682, 0.4239905 , 0.42963183, 0.44447743,\n",
       "                     0.45071259, 0.45872922, 0.45961995, 0.48634204, 0.49228029,\n",
       "                     0.49495249, 0.49940618, 0.51306413, 0.51633017, 0.52048694,\n",
       "                     0.53414489, 0.53859857, 0.54602138, 0.55789786, 0.57244656,\n",
       "                     0.57511876, 0.57749406, 0.59055819, 0.60837292, 0.61549881,\n",
       "                     0.62024941, 0.62410926, 0.62648456, 0.67280285, 0.67606888,\n",
       "                     0.67814727, 0.67992874, 0.6912114 , 0.6935867 , 0.69507126,\n",
       "                     0.7108076 , 0.71437055, 0.71852732, 0.72327791, 0.72595012,\n",
       "                     0.73010689, 0.74109264, 0.74495249, 0.7476247 , 0.74970309,\n",
       "                     0.78414489, 0.78948931, 0.79691211, 0.79928741, 0.81739905,\n",
       "                     0.81888361, 0.8236342 , 0.8432304 , 0.847981  , 0.85332542,\n",
       "                     0.85629454, 0.86074822, 0.8675772 , 0.87173397, 0.89519002,\n",
       "                     0.90053444, 0.90795724, 0.91805226, 0.91983373, 0.92547506,\n",
       "                     0.92963183, 0.93230404, 0.93319477, 0.9631829 , 0.96466746,\n",
       "                     0.96615202, 0.97238717, 0.97535629, 0.97654394, 0.97832542,\n",
       "                     0.98307601, 0.98752969, 0.98871734, 0.98960808, 0.99049881,\n",
       "                     0.99109264, 0.99435867, 0.99524941, 0.99614014, 0.99643705,\n",
       "                     0.9976247 , 0.99792162, 0.99881235, 0.99910926, 0.99970309,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -7.41079722e-02, -1.33531393e-01,\n",
       "                     -1.54150680e-01, -1.82321557e-01, -2.23143551e-01, -2.45122458e-01,\n",
       "                     -2.87682072e-01, -3.18453731e-01, -3.36472237e-01, -3.56674944e-01,\n",
       "                     -3.64643114e-01, -4.05465108e-01, -4.51985124e-01, -4.85507816e-01,\n",
       "                     -4.98991166e-01, -5.10825624e-01, -5.38996501e-01, -5.50046337e-01,\n",
       "                     -5.52068582e-01, -5.59615788e-01, -5.87786665e-01, -6.19039208e-01,\n",
       "                     -6.39079959e-01, -6.56779536e-01, -6.93147181e-01, -7.17839793e-01,\n",
       "                     -7.20849783e-01, -7.33969175e-01, -7.35706795e-01, -7.37598943e-01,\n",
       "                     -7.44440475e-01, -7.53771802e-01, -7.59105148e-01, -7.62140052e-01,\n",
       "                     -7.73189888e-01, -7.78914002e-01, -7.80852761e-01, -7.88457360e-01,\n",
       "                     -7.98507696e-01, -8.00777845e-01, -8.10930216e-01, -8.26678573e-01,\n",
       "                     -8.36248024e-01, -8.44953193e-01, -8.47297860e-01, -8.64997437e-01,\n",
       "                     -8.70828358e-01, -8.75468737e-01, -8.79249460e-01, -8.87303195e-01,\n",
       "                     -8.90972924e-01, -8.99483614e-01, -9.04456274e-01, -9.10021119e-01,\n",
       "                     -9.16290732e-01, -9.29535959e-01, -9.47381319e-01, -9.55511445e-01,\n",
       "                     -9.62810748e-01, -9.66843011e-01, -9.80829253e-01, -9.89128056e-01,\n",
       "                     -1.01160091e+00, -1.02165125e+00, -1.02961942e+00, -1.03117101e+00,\n",
       "                     -1.03609193e+00, -1.04982212e+00, -1.06919840e+00, -1.07613943e+00,\n",
       "                     -1.08518927e+00, -1.09861229e+00, -1.11212601e+00, -1.13497993e+00,\n",
       "                     -1.13943428e+00, -1.14306405e+00, -1.14740245e+00, -1.15267951e+00,\n",
       "                     -1.15923691e+00, -1.17272026e+00, -1.17865500e+00, -1.18062544e+00,\n",
       "                     -1.18562367e+00, -1.18958407e+00, -1.20397280e+00, -1.20660093e+00,\n",
       "                     -1.21639532e+00, -1.22377543e+00, -1.22820512e+00, -1.22866542e+00,\n",
       "                     -1.23214368e+00, -1.23474446e+00, -1.23676263e+00, -1.25276297e+00,\n",
       "                     -1.25661654e+00, -1.26369204e+00, -1.26851133e+00, -1.27296568e+00,\n",
       "                     -1.29614326e+00, -1.29928298e+00, -1.30291275e+00, -1.32175584e+00,\n",
       "                     -1.32720544e+00, -1.33500107e+00, -1.33828514e+00, -1.36330484e+00,\n",
       "                     -1.38629436e+00, -1.45343366e+00, -1.45861502e+00, -1.46633707e+00,\n",
       "                     -1.46967597e+00, -1.50407740e+00, -1.50548288e+00, -1.51634749e+00,\n",
       "                     -1.51732262e+00, -1.53623451e+00, -1.54044504e+00, -1.54419739e+00,\n",
       "                     -1.55059741e+00, -1.58696506e+00, -1.60943791e+00, -1.61339049e+00,\n",
       "                     -1.64865863e+00, -1.68639895e+00, -1.73460106e+00, -1.79175947e+00,\n",
       "                     -1.83258146e+00, -1.89711998e+00, -1.94591015e+00, -2.02814825e+00,\n",
       "                     -2.07944154e+00, -2.19722458e+00, -2.23359222e+00, -2.25129180e+00,\n",
       "                     -2.29345261e+00, -2.33537492e+00, -2.36712361e+00, -2.39789527e+00,\n",
       "                     -2.46385324e+00, -2.48490665e+00, -2.66258783e+00, -2.70805020e+00,\n",
       "                     -2.77258872e+00, -2.94443898e+00, -3.45387764e+01]), auc_score=0.5598567731414188, privacy_risk=0.5395357535363562, accuracy=0.5398928252456088, tpr_ind=0.6728028503562945, tnr_ind=0.40626865671641793, test_train_ratio=0.9946555819477435, dataset_size=[3368, 3350]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.01193317, 0.01461814, 0.01909308, 0.01998807,\n",
       "                     0.02326969, 0.02446301, 0.02714797, 0.03371122, 0.03609785,\n",
       "                     0.03729117, 0.0426611 , 0.04743437, 0.05131265, 0.0528043 ,\n",
       "                     0.05727924, 0.06264916, 0.06980907, 0.07100239, 0.07279236,\n",
       "                     0.08054893, 0.09457041, 0.10710024, 0.12112172, 0.13484487,\n",
       "                     0.13633652, 0.14289976, 0.15304296, 0.16825776, 0.17571599,\n",
       "                     0.20137232, 0.20554893, 0.20704057, 0.20912888, 0.22344869,\n",
       "                     0.23001193, 0.23120525, 0.24552506, 0.25954654, 0.2622315 ,\n",
       "                     0.2673031 , 0.2702864 , 0.27804296, 0.28371122, 0.30727924,\n",
       "                     0.31921241, 0.32130072, 0.32786396, 0.34128878, 0.3475537 ,\n",
       "                     0.36217184, 0.3648568 , 0.36605012, 0.37052506, 0.38096659,\n",
       "                     0.3952864 , 0.39707637, 0.40662291, 0.40781623, 0.41079952,\n",
       "                     0.41527446, 0.42750597, 0.42869928, 0.43914081, 0.45584726,\n",
       "                     0.45793556, 0.4877685 , 0.49075179, 0.5101432 , 0.52804296,\n",
       "                     0.55608592, 0.56115752, 0.56622912, 0.58144391, 0.58591885,\n",
       "                     0.58830549, 0.60113365, 0.60441527, 0.60799523, 0.61306683,\n",
       "                     0.62112172, 0.63573986, 0.63782816, 0.64081146, 0.64468974,\n",
       "                     0.65304296, 0.68585919, 0.68854415, 0.69242243, 0.73806683,\n",
       "                     0.74075179, 0.74254177, 0.74821002, 0.75268496, 0.76282816,\n",
       "                     0.77834129, 0.78281623, 0.7875895 , 0.78818616, 0.79415274,\n",
       "                     0.80161098, 0.8028043 , 0.80608592, 0.81235084, 0.81443914,\n",
       "                     0.82547733, 0.82905728, 0.84546539, 0.8475537 , 0.85739857,\n",
       "                     0.88394988, 0.88931981, 0.89379475, 0.89498807, 0.9024463 ,\n",
       "                     0.90483294, 0.90960621, 0.90990453, 0.91079952, 0.91497613,\n",
       "                     0.9176611 , 0.92034606, 0.92452267, 0.93287589, 0.93556086,\n",
       "                     0.94928401, 0.95047733, 0.95107399, 0.95793556, 0.95912888,\n",
       "                     0.9624105 , 0.96449881, 0.96599045, 0.96599045, 0.9674821 ,\n",
       "                     0.96927208, 0.97016706, 0.9725537 , 0.97344869, 1.        ]), tpr=array([0.        , 0.02317291, 0.02733214, 0.03208556, 0.03475936,\n",
       "                     0.03773024, 0.03980986, 0.04248366, 0.0543672 , 0.05793226,\n",
       "                     0.06090315, 0.06357695, 0.0674391 , 0.07159834, 0.0751634 ,\n",
       "                     0.07961973, 0.08645276, 0.09536542, 0.09803922, 0.10130719,\n",
       "                     0.11616162, 0.13695781, 0.15775401, 0.17082591, 0.18894831,\n",
       "                     0.19132501, 0.19815805, 0.21122995, 0.22756982, 0.238265  ,\n",
       "                     0.26262626, 0.26767677, 0.26886512, 0.27332145, 0.28877005,\n",
       "                     0.29292929, 0.29590018, 0.31491384, 0.32768865, 0.33303624,\n",
       "                     0.33719548, 0.34046346, 0.34997029, 0.3573975 , 0.38502674,\n",
       "                     0.39928699, 0.40196078, 0.40790255, 0.42097445, 0.42691622,\n",
       "                     0.44147356, 0.44414736, 0.44622698, 0.45276292, 0.46286393,\n",
       "                     0.47950089, 0.48276887, 0.49613785, 0.4973262 , 0.50029709,\n",
       "                     0.50505051, 0.5181224 , 0.52020202, 0.52881759, 0.54753417,\n",
       "                     0.55109923, 0.58734403, 0.59209745, 0.61259655, 0.63279857,\n",
       "                     0.65567439, 0.66369578, 0.66874629, 0.67706477, 0.68033274,\n",
       "                     0.68508616, 0.69756387, 0.69994058, 0.70528818, 0.7097445 ,\n",
       "                     0.72103387, 0.73469994, 0.73707665, 0.7409388 , 0.74390969,\n",
       "                     0.75371361, 0.77688651, 0.77926322, 0.78371955, 0.83065954,\n",
       "                     0.83452169, 0.8368984 , 0.84165181, 0.84521687, 0.85620915,\n",
       "                     0.86720143, 0.87106358, 0.87433155, 0.87581699, 0.87997623,\n",
       "                     0.88502674, 0.885918  , 0.89007724, 0.89483066, 0.89661319,\n",
       "                     0.90374332, 0.90582294, 0.91532977, 0.91740939, 0.92543078,\n",
       "                     0.94147356, 0.94503862, 0.94800951, 0.94919786, 0.95395128,\n",
       "                     0.95573381, 0.95989305, 0.96048723, 0.96286393, 0.96613191,\n",
       "                     0.96732026, 0.9688057 , 0.97088532, 0.97474747, 0.97653001,\n",
       "                     0.98900772, 0.9896019 , 0.99079026, 0.99286988, 0.99346405,\n",
       "                     0.99524658, 0.99613785, 0.99702911, 0.9973262 , 0.99821747,\n",
       "                     0.99881165, 0.99940582, 0.99970291, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -2.23143551e-01,\n",
       "                     -2.87682072e-01, -3.36472237e-01, -3.56674944e-01, -3.67724780e-01,\n",
       "                     -4.05465108e-01, -4.59532329e-01, -4.70003629e-01, -5.10825624e-01,\n",
       "                     -5.26093096e-01, -5.38996501e-01, -5.59615788e-01, -5.87786665e-01,\n",
       "                     -6.02175402e-01, -6.06135804e-01, -6.35988767e-01, -6.46627165e-01,\n",
       "                     -6.62687973e-01, -6.85978691e-01, -6.93147181e-01, -7.26669873e-01,\n",
       "                     -7.48938540e-01, -7.53771802e-01, -7.56326082e-01, -7.59105148e-01,\n",
       "                     -7.71790308e-01, -7.73189888e-01, -7.75064303e-01, -7.77704569e-01,\n",
       "                     -8.10930216e-01, -8.18310324e-01, -8.19440906e-01, -8.26678573e-01,\n",
       "                     -8.32909123e-01, -8.38329190e-01, -8.43970070e-01, -8.47297860e-01,\n",
       "                     -8.57450232e-01, -8.60201265e-01, -8.64997437e-01, -8.75468737e-01,\n",
       "                     -8.87935506e-01, -8.90972924e-01, -8.93817876e-01, -8.96088025e-01,\n",
       "                     -8.97941593e-01, -9.16290732e-01, -9.36493439e-01, -9.38269639e-01,\n",
       "                     -9.44461609e-01, -9.52008814e-01, -9.62275845e-01, -9.65080896e-01,\n",
       "                     -9.69400557e-01, -9.80829253e-01, -1.01160091e+00, -1.02961942e+00,\n",
       "                     -1.03407377e+00, -1.03609193e+00, -1.04982212e+00, -1.05154478e+00,\n",
       "                     -1.06635143e+00, -1.07044141e+00, -1.07371474e+00, -1.07755888e+00,\n",
       "                     -1.09376966e+00, -1.09861229e+00, -1.10293195e+00, -1.11088238e+00,\n",
       "                     -1.11803037e+00, -1.12214279e+00, -1.12846525e+00, -1.13943428e+00,\n",
       "                     -1.15267951e+00, -1.17865500e+00, -1.18716569e+00, -1.20397280e+00,\n",
       "                     -1.20660093e+00, -1.21478372e+00, -1.21639532e+00, -1.21924028e+00,\n",
       "                     -1.25276297e+00, -1.26566637e+00, -1.27091229e+00, -1.28785429e+00,\n",
       "                     -1.29928298e+00, -1.30043307e+00, -1.30625165e+00, -1.32175584e+00,\n",
       "                     -1.33828514e+00, -1.36524095e+00, -1.37951467e+00, -1.38629436e+00,\n",
       "                     -1.40534256e+00, -1.43074612e+00, -1.43508453e+00, -1.43848011e+00,\n",
       "                     -1.44345277e+00, -1.46633707e+00, -1.48807706e+00, -1.49009115e+00,\n",
       "                     -1.50407740e+00, -1.52242654e+00, -1.60943791e+00, -1.64020957e+00,\n",
       "                     -1.66500776e+00, -1.68089688e+00, -1.70474809e+00, -1.73460106e+00,\n",
       "                     -1.74046617e+00, -1.79175947e+00, -1.80212226e+00, -1.81915844e+00,\n",
       "                     -1.86075234e+00, -1.87180218e+00, -1.89085037e+00, -1.90616982e+00,\n",
       "                     -1.90954250e+00, -1.91692261e+00, -1.92529086e+00, -1.94591015e+00,\n",
       "                     -1.96944065e+00, -1.97275740e+00, -2.07944154e+00, -2.14006616e+00,\n",
       "                     -2.14843441e+00, -2.19722458e+00, -2.26868354e+00, -2.30258509e+00,\n",
       "                     -2.33537492e+00, -2.39789527e+00, -2.51230562e+00, -2.56494936e+00,\n",
       "                     -2.63905733e+00, -3.36729583e+00, -3.82864140e+00, -3.45387764e+01]), auc_score=0.5714121685052123, privacy_risk=0.5523778072739185, accuracy=0.5525454004167907, tpr_ind=0.6327985739750446, tnr_ind=0.47195704057279236, test_train_ratio=0.995840760546643, dataset_size=[3366, 3352]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.0126115 , 0.01507229, 0.01630268, 0.01876346,\n",
       "                     0.02276223, 0.026761  , 0.02829898, 0.02952938, 0.03229775,\n",
       "                     0.03383574, 0.03629652, 0.04860043, 0.05044602, 0.0522916 ,\n",
       "                     0.05598277, 0.06028914, 0.06797908, 0.07382344, 0.07597662,\n",
       "                     0.07782221, 0.08059059, 0.08366656, 0.08551215, 0.09474008,\n",
       "                     0.12949862, 0.13318979, 0.13780375, 0.14180252, 0.1451861 ,\n",
       "                     0.14610889, 0.15041526, 0.17471547, 0.17809905, 0.17871424,\n",
       "                     0.20424485, 0.21254998, 0.22085512, 0.30790526, 0.31159643,\n",
       "                     0.32482313, 0.3294371 , 0.33774223, 0.33866503, 0.3420486 ,\n",
       "                     0.34543217, 0.3817287 , 0.38972624, 0.40233774, 0.4084897 ,\n",
       "                     0.41187327, 0.41925561, 0.42786835, 0.4343279 , 0.43771147,\n",
       "                     0.44386343, 0.44816979, 0.45893571, 0.47585358, 0.4869271 ,\n",
       "                     0.49092587, 0.50415257, 0.52445401, 0.52537681, 0.52906798,\n",
       "                     0.5395263 , 0.54414026, 0.54783144, 0.56013534, 0.5662873 ,\n",
       "                     0.59550907, 0.60043064, 0.60596739, 0.61027376, 0.62042448,\n",
       "                     0.6318056 , 0.64287911, 0.64780068, 0.68348201, 0.68532759,\n",
       "                     0.69240234, 0.72285451, 0.73485082, 0.74069517, 0.74530914,\n",
       "                     0.75638265, 0.75699785, 0.7631498 , 0.77207013, 0.77453091,\n",
       "                     0.77791449, 0.78283605, 0.78683482, 0.79206398, 0.80036912,\n",
       "                     0.80498308, 0.80867425, 0.81328822, 0.81451861, 0.8151338 ,\n",
       "                     0.815749  , 0.84620117, 0.85081513, 0.85143033, 0.85450631,\n",
       "                     0.86188865, 0.86373424, 0.8689634 , 0.87203937, 0.87542295,\n",
       "                     0.87788373, 0.87880652, 0.89018763, 0.90156875, 0.91325746,\n",
       "                     0.92310058, 0.92863734, 0.9341741 , 0.93694248, 0.93755767,\n",
       "                     0.93940326, 0.94247924, 0.94432482, 0.9467856 , 0.948016  ,\n",
       "                     0.94924639, 0.94955398, 0.95047678, 0.95386035, 0.95939711,\n",
       "                     0.9603199 , 0.96708705, 0.96954783, 1.        ]), tpr=array([0.        , 0.02451687, 0.02826651, 0.02999712, 0.03576579,\n",
       "                     0.0383617 , 0.04528411, 0.04903375, 0.05191808, 0.05393712,\n",
       "                     0.05653303, 0.06028267, 0.07182002, 0.07758869, 0.0810499 ,\n",
       "                     0.08826074, 0.09662532, 0.10470147, 0.11335449, 0.11508509,\n",
       "                     0.11912316, 0.12171907, 0.1246034 , 0.12864148, 0.1398904 ,\n",
       "                     0.18315547, 0.18748197, 0.19325065, 0.19584655, 0.20046149,\n",
       "                     0.2021921 , 0.21142198, 0.22901644, 0.23190078, 0.23305451,\n",
       "                     0.25901356, 0.267955  , 0.27747332, 0.3677531 , 0.37179117,\n",
       "                     0.3882319 , 0.39226997, 0.4061148 , 0.4087107 , 0.41188347,\n",
       "                     0.41534468, 0.4479377 , 0.45860975, 0.4684165 , 0.47562734,\n",
       "                     0.47764638, 0.48456879, 0.49552928, 0.50014422, 0.50331699,\n",
       "                     0.50995097, 0.51687338, 0.52581483, 0.54888953, 0.55869628,\n",
       "                     0.56100375, 0.5716758 , 0.5912893 , 0.59417364, 0.60224978,\n",
       "                     0.6117681 , 0.61494087, 0.61955581, 0.6322469 , 0.63830401,\n",
       "                     0.66916643, 0.67435823, 0.68156908, 0.68849149, 0.69656764,\n",
       "                     0.71070089, 0.72281511, 0.73060283, 0.76031151, 0.76175368,\n",
       "                     0.77357946, 0.79636573, 0.80703778, 0.81165273, 0.81770984,\n",
       "                     0.82838189, 0.83011249, 0.83299683, 0.84280358, 0.84395731,\n",
       "                     0.84655322, 0.85087972, 0.85462936, 0.86039804, 0.86616671,\n",
       "                     0.87193539, 0.8762619 , 0.88376118, 0.88606865, 0.88808768,\n",
       "                     0.88952985, 0.91520046, 0.91866167, 0.92010384, 0.92183444,\n",
       "                     0.92587251, 0.92673781, 0.92991059, 0.93394866, 0.9402942 ,\n",
       "                     0.9411595 , 0.94317854, 0.95615806, 0.96134987, 0.97231035,\n",
       "                     0.9786559 , 0.98182867, 0.98327084, 0.98586674, 0.98702048,\n",
       "                     0.98817421, 0.98875108, 0.98961638, 0.99048168, 0.99134699,\n",
       "                     0.99163542, 0.99192385, 0.99221229, 0.99394289, 0.99567349,\n",
       "                     0.99625036, 0.9982694 , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.43100844e-01, -1.54150680e-01,\n",
       "                     -2.23143551e-01, -2.87682072e-01, -3.18453731e-01, -3.25422400e-01,\n",
       "                     -3.36472237e-01, -3.56674944e-01, -3.67724780e-01, -3.79489622e-01,\n",
       "                     -4.05465108e-01, -4.70003629e-01, -5.10825624e-01, -5.18793793e-01,\n",
       "                     -5.44727175e-01, -5.59615788e-01, -5.87786665e-01, -6.06135804e-01,\n",
       "                     -6.19039208e-01, -6.35988767e-01, -6.41853886e-01, -6.56779536e-01,\n",
       "                     -6.80243776e-01, -6.93147181e-01, -7.25937003e-01, -7.41937345e-01,\n",
       "                     -7.47214402e-01, -7.53771802e-01, -7.73189888e-01, -7.82759339e-01,\n",
       "                     -7.86965936e-01, -7.88457360e-01, -8.10930216e-01, -8.13396309e-01,\n",
       "                     -8.42678915e-01, -8.47297860e-01, -8.48210269e-01, -8.57450232e-01,\n",
       "                     -8.76929658e-01, -8.87303195e-01, -8.90972924e-01, -8.93817876e-01,\n",
       "                     -8.97941593e-01, -9.16290732e-01, -9.18059079e-01, -9.21681581e-01,\n",
       "                     -9.27986772e-01, -9.40007258e-01, -9.44461609e-01, -9.49080555e-01,\n",
       "                     -9.57533690e-01, -9.65080896e-01, -9.69400557e-01, -9.75379648e-01,\n",
       "                     -9.80829253e-01, -9.84853403e-01, -9.93251773e-01, -1.00623897e+00,\n",
       "                     -1.01160091e+00, -1.01405490e+00, -1.01693426e+00, -1.02961942e+00,\n",
       "                     -1.04982212e+00, -1.05736933e+00, -1.06784063e+00, -1.07755888e+00,\n",
       "                     -1.09861229e+00, -1.11436065e+00, -1.14725410e+00, -1.15267951e+00,\n",
       "                     -1.16315081e+00, -1.19139402e+00, -1.20039498e+00, -1.20192990e+00,\n",
       "                     -1.21109027e+00, -1.21502264e+00, -1.22320417e+00, -1.22377543e+00,\n",
       "                     -1.22807036e+00, -1.22897411e+00, -1.24111235e+00, -1.25276297e+00,\n",
       "                     -1.25954266e+00, -1.28692189e+00, -1.29928298e+00, -1.30833282e+00,\n",
       "                     -1.30992138e+00, -1.32175584e+00, -1.32913595e+00, -1.33500107e+00,\n",
       "                     -1.34707365e+00, -1.34807315e+00, -1.37371558e+00, -1.38629436e+00,\n",
       "                     -1.40282366e+00, -1.40534256e+00, -1.41706602e+00, -1.42138568e+00,\n",
       "                     -1.43508453e+00, -1.46720100e+00, -1.52242654e+00, -1.52605630e+00,\n",
       "                     -1.57553636e+00, -1.58045038e+00, -1.60943791e+00, -1.62745642e+00,\n",
       "                     -1.63760879e+00, -1.65388968e+00, -1.67397643e+00, -1.69167601e+00,\n",
       "                     -1.69459572e+00, -1.70474809e+00, -1.72370601e+00, -1.79175947e+00,\n",
       "                     -1.83621123e+00, -1.85629799e+00, -1.94591015e+00, -2.04769284e+00,\n",
       "                     -2.07944154e+00, -2.19722458e+00, -2.30258509e+00, -2.33537492e+00,\n",
       "                     -2.39789527e+00, -2.48490665e+00, -2.56494936e+00, -2.63905733e+00,\n",
       "                     -2.67414865e+00, -2.70805020e+00, -2.83321334e+00, -2.89827694e+00,\n",
       "                     -2.89958841e+00, -3.45387764e+01]), auc_score=0.5600973701420175, privacy_risk=0.5414010749682132, accuracy=0.547484370348318, tpr_ind=0.7306028266512835, tnr_ind=0.35219932328514303, test_train_ratio=0.9376982982405538, dataset_size=[3467, 3251]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00923994, 0.00983607, 0.01222057, 0.01400894,\n",
       "                     0.01490313, 0.01639344, 0.02086438, 0.02265276, 0.0295082 ,\n",
       "                     0.03338301, 0.03368107, 0.03487332, 0.0390462 , 0.04590164,\n",
       "                     0.05007452, 0.0533532 , 0.05454545, 0.06199702, 0.06318927,\n",
       "                     0.06527571, 0.06736215, 0.07421759, 0.12309985, 0.13174367,\n",
       "                     0.13740686, 0.14605067, 0.16065574, 0.16214605, 0.16602086,\n",
       "                     0.16840537, 0.1704918 , 0.18479881, 0.190462  , 0.19612519,\n",
       "                     0.20506706, 0.20774963, 0.22056632, 0.22652757, 0.23576751,\n",
       "                     0.23695976, 0.24083458, 0.25186289, 0.27421759, 0.27481371,\n",
       "                     0.28614009, 0.31028316, 0.31743666, 0.3242921 , 0.33204173,\n",
       "                     0.34515648, 0.34754098, 0.36423249, 0.36691505, 0.43129657,\n",
       "                     0.43308495, 0.4390462 , 0.45991058, 0.46140089, 0.47004471,\n",
       "                     0.47004471, 0.47988077, 0.4876304 , 0.49359165, 0.49925484,\n",
       "                     0.50789866, 0.51326379, 0.51982116, 0.5290611 , 0.52995529,\n",
       "                     0.54068554, 0.54456036, 0.54962742, 0.56065574, 0.56542474,\n",
       "                     0.57078987, 0.57675112, 0.57973174, 0.63397914, 0.64023845,\n",
       "                     0.65007452, 0.65305514, 0.65871833, 0.66378539, 0.68464978,\n",
       "                     0.68882265, 0.69657228, 0.69836066, 0.70163934, 0.70700447,\n",
       "                     0.70909091, 0.71147541, 0.72757079, 0.73710879, 0.77168405,\n",
       "                     0.78062593, 0.78688525, 0.79642325, 0.80089419, 0.80327869,\n",
       "                     0.80536513, 0.82563338, 0.83219076, 0.84649776, 0.86467958,\n",
       "                     0.87391952, 0.88196721, 0.89359165, 0.90342772, 0.90670641,\n",
       "                     0.90789866, 0.90849478, 0.91385991, 0.91773472, 0.91892697,\n",
       "                     0.91982116, 0.92131148, 0.92399404, 0.9266766 , 0.92846498,\n",
       "                     0.92876304, 0.93055142, 0.9338301 , 0.93740686, 0.94068554,\n",
       "                     0.94128167, 0.94128167, 0.94485842, 0.95022355, 0.95111773,\n",
       "                     0.9514158 , 0.95260805, 0.95350224, 0.95409836, 0.95558867,\n",
       "                     0.95588674, 0.95648286, 0.96005961, 0.96184799, 0.96304024,\n",
       "                     1.        ]), tpr=array([0.        , 0.02319358, 0.02557241, 0.029438  , 0.03241154,\n",
       "                     0.03479037, 0.0377639 , 0.04400833, 0.04638715, 0.05709188,\n",
       "                     0.06333631, 0.06601249, 0.06809396, 0.0710675 , 0.07820398,\n",
       "                     0.08117752, 0.08623253, 0.08742194, 0.09782932, 0.09961344,\n",
       "                     0.10169492, 0.10407374, 0.11358906, 0.17068094, 0.18287244,\n",
       "                     0.18911686, 0.19863217, 0.21706809, 0.21944692, 0.22360987,\n",
       "                     0.22717811, 0.2298543 , 0.24442462, 0.24888492, 0.25423729,\n",
       "                     0.26167113, 0.26583408, 0.27891763, 0.28575676, 0.29289325,\n",
       "                     0.29616414, 0.3015165 , 0.32024978, 0.34611954, 0.34820101,\n",
       "                     0.3597978 , 0.39072257, 0.3975617 , 0.40469819, 0.41272673,\n",
       "                     0.42818912, 0.43116265, 0.44335415, 0.44721974, 0.5063931 ,\n",
       "                     0.51055605, 0.51590842, 0.53791258, 0.54029141, 0.54772525,\n",
       "                     0.54921201, 0.55902468, 0.56497175, 0.57270294, 0.5774606 ,\n",
       "                     0.58816533, 0.59351769, 0.60154624, 0.61106155, 0.61492715,\n",
       "                     0.62414511, 0.62592923, 0.63098424, 0.64049955, 0.64614927,\n",
       "                     0.65120428, 0.65863812, 0.6613143 , 0.71394588, 0.72048766,\n",
       "                     0.73119239, 0.73267916, 0.7407077 , 0.74962831, 0.77133512,\n",
       "                     0.77966102, 0.79155516, 0.79304193, 0.79839429, 0.80315195,\n",
       "                     0.80463872, 0.80672019, 0.82039845, 0.83140054, 0.85637823,\n",
       "                     0.8617306 , 0.86678561, 0.87332739, 0.87630092, 0.87867975,\n",
       "                     0.88046387, 0.89235801, 0.89979185, 0.90871246, 0.92863515,\n",
       "                     0.93963723, 0.94796313, 0.95658638, 0.96164139, 0.96461493,\n",
       "                     0.9666964 , 0.96729111, 0.97115671, 0.97294083, 0.97472495,\n",
       "                     0.97680642, 0.97769848, 0.9794826 , 0.98096937, 0.98275349,\n",
       "                     0.98424026, 0.98483497, 0.98602438, 0.98810586, 0.98988998,\n",
       "                     0.99078204, 0.99137675, 0.99226881, 0.99345822, 0.99405293,\n",
       "                     0.99464764, 0.9961344 , 0.99672911, 0.99702646, 0.99791853,\n",
       "                     0.99821588, 0.99851323, 0.99910794, 0.99940529, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.17783036e-01, -1.43100844e-01,\n",
       "                     -1.82321557e-01, -2.23143551e-01, -2.62364264e-01, -2.87682072e-01,\n",
       "                     -3.18453731e-01, -4.05465108e-01, -4.21213465e-01, -4.41832752e-01,\n",
       "                     -4.51985124e-01, -4.70003629e-01, -5.10825624e-01, -5.30628251e-01,\n",
       "                     -5.34082486e-01, -5.59615788e-01, -5.87786665e-01, -6.06135804e-01,\n",
       "                     -6.19039208e-01, -6.28608659e-01, -6.45137961e-01, -6.93147181e-01,\n",
       "                     -7.05268541e-01, -7.16677678e-01, -7.23918839e-01, -7.48062938e-01,\n",
       "                     -7.53771802e-01, -7.62140052e-01, -7.73189888e-01, -7.98507696e-01,\n",
       "                     -8.08660068e-01, -8.18310324e-01, -8.23200309e-01, -8.24175443e-01,\n",
       "                     -8.26678573e-01, -8.30930883e-01, -8.34797698e-01, -8.47297860e-01,\n",
       "                     -8.60201265e-01, -8.70828358e-01, -8.74145110e-01, -8.85950015e-01,\n",
       "                     -8.87303195e-01, -8.90315245e-01, -9.16290732e-01, -9.24948795e-01,\n",
       "                     -9.32820034e-01, -9.38269639e-01, -9.54031060e-01, -9.55511445e-01,\n",
       "                     -9.59256768e-01, -9.61411167e-01, -9.66276639e-01, -9.71860583e-01,\n",
       "                     -9.80829253e-01, -1.00914089e+00, -1.01160091e+00, -1.01523068e+00,\n",
       "                     -1.02961942e+00, -1.03609193e+00, -1.04731899e+00, -1.07263680e+00,\n",
       "                     -1.07755888e+00, -1.07992016e+00, -1.09861229e+00, -1.11088238e+00,\n",
       "                     -1.13943428e+00, -1.14862271e+00, -1.15098027e+00, -1.15267951e+00,\n",
       "                     -1.17411984e+00, -1.17865500e+00, -1.18269541e+00, -1.19213835e+00,\n",
       "                     -1.19996478e+00, -1.20397280e+00, -1.20566628e+00, -1.21302264e+00,\n",
       "                     -1.22050211e+00, -1.22377543e+00, -1.22595171e+00, -1.24319352e+00,\n",
       "                     -1.25080410e+00, -1.25276297e+00, -1.26694760e+00, -1.28093385e+00,\n",
       "                     -1.29928298e+00, -1.32175584e+00, -1.33500107e+00, -1.34992672e+00,\n",
       "                     -1.35314215e+00, -1.38629436e+00, -1.38926613e+00, -1.40008768e+00,\n",
       "                     -1.41528190e+00, -1.41981705e+00, -1.43508453e+00, -1.44691898e+00,\n",
       "                     -1.46633707e+00, -1.47017585e+00, -1.47247206e+00, -1.48160454e+00,\n",
       "                     -1.53831057e+00, -1.56523182e+00, -1.58777642e+00, -1.59554880e+00,\n",
       "                     -1.60943791e+00, -1.68639895e+00, -1.69167601e+00, -1.70474809e+00,\n",
       "                     -1.73911574e+00, -1.76358859e+00, -1.79175947e+00, -1.81528997e+00,\n",
       "                     -1.84582669e+00, -1.87180218e+00, -1.94591015e+00, -1.96944065e+00,\n",
       "                     -2.00148000e+00, -2.01490302e+00, -2.07944154e+00, -2.09714112e+00,\n",
       "                     -2.10006083e+00, -2.12026354e+00, -2.14006616e+00, -2.15948425e+00,\n",
       "                     -2.16905370e+00, -2.30258509e+00, -2.35137526e+00, -2.56494936e+00,\n",
       "                     -2.77258872e+00, -2.83321334e+00, -2.89037176e+00, -3.04452244e+00,\n",
       "                     -3.09104245e+00, -3.11351531e+00, -3.29583687e+00, -3.36729583e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5666796509574474, privacy_risk=0.5483774732747401, accuracy=0.5486752009526645, tpr_ind=0.7983942908117752, tnr_ind=0.2983606557377049, test_train_ratio=0.9976211715730003, dataset_size=[3363, 3355]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00536993, 0.00656325, 0.0071599 , 0.00835322,\n",
       "                     0.01044153, 0.01491647, 0.01640811, 0.01760143, 0.01939141,\n",
       "                     0.02297136, 0.02625298, 0.02714797, 0.02804296, 0.03072792,\n",
       "                     0.03281623, 0.04116945, 0.04892601, 0.05220764, 0.05727924,\n",
       "                     0.06026253, 0.06682578, 0.07249403, 0.07816229, 0.08353222,\n",
       "                     0.08472554, 0.09785203, 0.15542959, 0.15990453, 0.17720764,\n",
       "                     0.20883055, 0.21658711, 0.21927208, 0.22911695, 0.23806683,\n",
       "                     0.25357995, 0.25656325, 0.26103819, 0.26461814, 0.26819809,\n",
       "                     0.2702864 , 0.27774463, 0.27923628, 0.29295943, 0.29922434,\n",
       "                     0.30190931, 0.30429594, 0.30847255, 0.31533413, 0.31801909,\n",
       "                     0.32159905, 0.32786396, 0.35232697, 0.35710024, 0.38454654,\n",
       "                     0.40692124, 0.40990453, 0.41408115, 0.42332936, 0.42840095,\n",
       "                     0.43168258, 0.44152745, 0.44391408, 0.45137232, 0.46300716,\n",
       "                     0.48836516, 0.50178998, 0.52118138, 0.549821  , 0.56324582,\n",
       "                     0.56443914, 0.59665871, 0.60352029, 0.60501193, 0.6199284 ,\n",
       "                     0.62828162, 0.64260143, 0.65662291, 0.6625895 , 0.66408115,\n",
       "                     0.66527446, 0.67631265, 0.6778043 , 0.71628878, 0.72494033,\n",
       "                     0.72911695, 0.73627685, 0.74134845, 0.76163484, 0.77386635,\n",
       "                     0.78102625, 0.7825179 , 0.79534606, 0.82935561, 0.83442721,\n",
       "                     0.84039379, 0.85292363, 0.8597852 , 0.86247017, 0.86426014,\n",
       "                     0.86455847, 0.87171838, 0.87917661, 0.88424821, 0.89051313,\n",
       "                     0.90155131, 0.90304296, 0.92064439, 0.92094272, 0.92243437,\n",
       "                     0.92452267, 0.92541766, 0.93884248, 0.94093079, 0.94809069,\n",
       "                     0.95137232, 0.95256563, 0.95793556, 0.95942721, 0.96091885,\n",
       "                     0.96509547, 0.96569212, 0.96778043, 0.96837709, 0.97076372,\n",
       "                     0.97404535, 0.97613365, 1.        ]), tpr=array([0.        , 0.01841949, 0.02168746, 0.02406417, 0.02822341,\n",
       "                     0.03178847, 0.03446227, 0.03683898, 0.03832442, 0.04188948,\n",
       "                     0.04456328, 0.04991087, 0.05199049, 0.05347594, 0.05674391,\n",
       "                     0.06090315, 0.0724896 , 0.0828877 , 0.08764112, 0.09358289,\n",
       "                     0.09536542, 0.10695187, 0.11497326, 0.11972668, 0.12388592,\n",
       "                     0.12566845, 0.13755199, 0.20885324, 0.21330957, 0.22994652,\n",
       "                     0.26203209, 0.26797386, 0.27243018, 0.28015449, 0.28995841,\n",
       "                     0.30332739, 0.30718954, 0.31253714, 0.31937017, 0.32234106,\n",
       "                     0.32857992, 0.33749257, 0.34016637, 0.35561497, 0.3600713 ,\n",
       "                     0.36244801, 0.36512181, 0.36987522, 0.37997623, 0.38294712,\n",
       "                     0.38680927, 0.39393939, 0.41830065, 0.42364825, 0.44860368,\n",
       "                     0.47326203, 0.47950089, 0.48247178, 0.4973262 , 0.50178253,\n",
       "                     0.50415924, 0.51485443, 0.51841949, 0.52614379, 0.53862151,\n",
       "                     0.56120024, 0.57694593, 0.59358289, 0.61675579, 0.63517528,\n",
       "                     0.6372549 , 0.66161616, 0.66993464, 0.67231135, 0.68508616,\n",
       "                     0.69459299, 0.71390374, 0.72727273, 0.73737374, 0.74034462,\n",
       "                     0.7409388 , 0.74777184, 0.75014854, 0.78579917, 0.79233512,\n",
       "                     0.79827689, 0.80748663, 0.80986334, 0.82976827, 0.84491979,\n",
       "                     0.84937611, 0.85204991, 0.86185383, 0.88413547, 0.88799762,\n",
       "                     0.8912656 , 0.90196078, 0.9067142 , 0.90760547, 0.91176471,\n",
       "                     0.91295306, 0.91919192, 0.92602496, 0.93048128, 0.93404635,\n",
       "                     0.9402852 , 0.94117647, 0.95840761, 0.95900178, 0.96048723,\n",
       "                     0.96167558, 0.96286393, 0.97237077, 0.9741533 , 0.9792038 ,\n",
       "                     0.98128342, 0.98217469, 0.98871064, 0.99019608, 0.99079026,\n",
       "                     0.99257279, 0.99286988, 0.99316696, 0.99435532, 0.9973262 ,\n",
       "                     0.99792038, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -8.70113770e-02, -1.17783036e-01,\n",
       "                     -1.33531393e-01, -2.23143551e-01, -2.87682072e-01, -3.18453731e-01,\n",
       "                     -3.36472237e-01, -3.48306694e-01, -3.67724780e-01, -4.05465108e-01,\n",
       "                     -4.51985124e-01, -4.70003629e-01, -4.92476485e-01, -4.96436886e-01,\n",
       "                     -5.10825624e-01, -5.38996501e-01, -5.59615788e-01, -5.87786665e-01,\n",
       "                     -6.06135804e-01, -6.93147181e-01, -7.29514825e-01, -7.53771802e-01,\n",
       "                     -7.62140052e-01, -7.73189888e-01, -7.77028665e-01, -7.80852761e-01,\n",
       "                     -7.88457360e-01, -7.94929875e-01, -8.06806499e-01, -8.10930216e-01,\n",
       "                     -8.18310324e-01, -8.19440906e-01, -8.20980552e-01, -8.28066498e-01,\n",
       "                     -8.36248024e-01, -8.47297860e-01, -8.71838969e-01, -8.75468737e-01,\n",
       "                     -8.87303195e-01, -8.89262059e-01, -8.93817876e-01, -9.00786545e-01,\n",
       "                     -9.02867712e-01, -9.16290732e-01, -9.38269639e-01, -9.40983344e-01,\n",
       "                     -9.50976290e-01, -9.55511445e-01, -9.61411167e-01, -9.65080896e-01,\n",
       "                     -9.73178106e-01, -9.80829253e-01, -9.94133219e-01, -1.00169439e+00,\n",
       "                     -1.01592057e+00, -1.02961942e+00, -1.04380405e+00, -1.05314991e+00,\n",
       "                     -1.05605267e+00, -1.06087196e+00, -1.07044141e+00, -1.07263680e+00,\n",
       "                     -1.07451474e+00, -1.08536706e+00, -1.09861229e+00, -1.10454702e+00,\n",
       "                     -1.10712298e+00, -1.13036099e+00, -1.14513230e+00, -1.15780116e+00,\n",
       "                     -1.16760516e+00, -1.17865500e+00, -1.18755977e+00, -1.19770319e+00,\n",
       "                     -1.21010779e+00, -1.21721803e+00, -1.21857160e+00, -1.22377543e+00,\n",
       "                     -1.25276297e+00, -1.27122503e+00, -1.28785429e+00, -1.29700767e+00,\n",
       "                     -1.30340670e+00, -1.30833282e+00, -1.31094492e+00, -1.32175584e+00,\n",
       "                     -1.32869687e+00, -1.33603253e+00, -1.35239281e+00, -1.35812348e+00,\n",
       "                     -1.38629436e+00, -1.39953959e+00, -1.42403469e+00, -1.45225233e+00,\n",
       "                     -1.50407740e+00, -1.51787072e+00, -1.54044504e+00, -1.55059741e+00,\n",
       "                     -1.55814462e+00, -1.56064775e+00, -1.56498615e+00, -1.58240924e+00,\n",
       "                     -1.60943791e+00, -1.66500776e+00, -1.67397643e+00, -1.69845876e+00,\n",
       "                     -1.70474809e+00, -1.72276660e+00, -1.83258146e+00, -1.87180218e+00,\n",
       "                     -1.92333583e+00, -1.94591015e+00, -2.03432111e+00, -2.07944154e+00,\n",
       "                     -2.12026354e+00, -2.13470422e+00, -2.15176220e+00, -2.19722458e+00,\n",
       "                     -2.25129180e+00, -2.30258509e+00, -2.39789527e+00, -2.54553127e+00,\n",
       "                     -2.66025954e+00, -2.89037176e+00, -3.42936826e+00, -3.45387764e+01]), auc_score=0.5561928512274222, privacy_risk=0.5381317385564192, accuracy=0.5385531408157189, tpr_ind=0.7403446226975638, tnr_ind=0.33591885441527447, test_train_ratio=0.995840760546643, dataset_size=[3366, 3352]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00964727, 0.01085318, 0.01266204, 0.01386795,\n",
       "                     0.01477238, 0.0171842 , 0.01778716, 0.01929454, 0.02472113,\n",
       "                     0.02653   , 0.03647875, 0.03919204, 0.0410009 , 0.04582454,\n",
       "                     0.04672897, 0.05818511, 0.05939102, 0.06029545, 0.06300874,\n",
       "                     0.0636117 , 0.06662647, 0.0913476 , 0.11275249, 0.11606874,\n",
       "                     0.15194453, 0.15284896, 0.15827555, 0.16008441, 0.16309919,\n",
       "                     0.16701839, 0.17666566, 0.17847453, 0.18088634, 0.18390112,\n",
       "                     0.19445282, 0.27494724, 0.29092554, 0.29635213, 0.3032861 ,\n",
       "                     0.31866144, 0.32469099, 0.34157371, 0.34579439, 0.35031655,\n",
       "                     0.35182394, 0.36056678, 0.37594212, 0.38619234, 0.39131746,\n",
       "                     0.40428098, 0.42447995, 0.43774495, 0.44226711, 0.44437745,\n",
       "                     0.46065722, 0.46457642, 0.47482665, 0.48266506, 0.50135665,\n",
       "                     0.5152246 , 0.52306301, 0.54115164, 0.54386494, 0.55140187,\n",
       "                     0.57732891, 0.58456437, 0.59421164, 0.5960205 , 0.60717516,\n",
       "                     0.6873681 , 0.69822128, 0.70153753, 0.71510401, 0.72595719,\n",
       "                     0.73017787, 0.73530298, 0.74314139, 0.74675912, 0.75007537,\n",
       "                     0.75218571, 0.75459753, 0.75911969, 0.76876696, 0.77570093,\n",
       "                     0.79921616, 0.81248116, 0.83388604, 0.84323184, 0.85589388,\n",
       "                     0.86252638, 0.86523967, 0.87036479, 0.87307808, 0.8794091 ,\n",
       "                     0.88423274, 0.88996081, 0.88996081, 0.89960808, 0.90111547,\n",
       "                     0.90232137, 0.91618933, 0.92071149, 0.92342478, 0.92523364,\n",
       "                     0.93066024, 0.94513114, 0.94995478, 0.95055773, 0.95327103,\n",
       "                     0.95357251, 0.9562858 , 0.95719023, 0.95779319, 0.95869762,\n",
       "                     0.960205  , 0.96442569, 0.96442569, 0.96713898, 0.96834489,\n",
       "                     0.97105819, 1.        ]), tpr=array([0.        , 0.02087621, 0.0226404 , 0.02558071, 0.02822699,\n",
       "                     0.03057924, 0.03498971, 0.03822405, 0.04381064, 0.05174949,\n",
       "                     0.05321964, 0.06380476, 0.0679212 , 0.06939136, 0.0764481 ,\n",
       "                     0.0773302 , 0.09026757, 0.09291385, 0.09585416, 0.09938253,\n",
       "                     0.10144075, 0.10673331, 0.13613643, 0.16377536, 0.1670097 ,\n",
       "                     0.20523375, 0.207586  , 0.21405469, 0.21728903, 0.22228756,\n",
       "                     0.22463981, 0.235813  , 0.23787121, 0.24051749, 0.24698618,\n",
       "                     0.26168774, 0.33460747, 0.35048515, 0.35695384, 0.36518671,\n",
       "                     0.38253455, 0.39194355, 0.41311379, 0.41634813, 0.41987651,\n",
       "                     0.42134666, 0.43399   , 0.44927962, 0.4660394 , 0.46986181,\n",
       "                     0.48426933, 0.50485151, 0.52131726, 0.52572773, 0.52896207,\n",
       "                     0.54072332, 0.54366363, 0.55219053, 0.56218759, 0.57747721,\n",
       "                     0.58806233, 0.59747133, 0.61217289, 0.61540723, 0.62158189,\n",
       "                     0.64804469, 0.6556895 , 0.66098206, 0.66421641, 0.67156719,\n",
       "                     0.76007057, 0.77153778, 0.77389003, 0.78888562, 0.79976478,\n",
       "                     0.8047633 , 0.81182005, 0.81681858, 0.81828874, 0.82064099,\n",
       "                     0.82269921, 0.82593355, 0.83093208, 0.8415172 , 0.84798589,\n",
       "                     0.86856807, 0.87885916, 0.89738312, 0.90502793, 0.91502499,\n",
       "                     0.91914143, 0.92325787, 0.92649221, 0.93002058, 0.93384299,\n",
       "                     0.9367833 , 0.94295795, 0.94354602, 0.9500147 , 0.95148486,\n",
       "                     0.95295501, 0.96265804, 0.9641282 , 0.96530432, 0.96706851,\n",
       "                     0.97177301, 0.98235813, 0.98794472, 0.98823875, 0.99029697,\n",
       "                     0.990591  , 0.99088503, 0.9914731 , 0.99206116, 0.99441341,\n",
       "                     0.99588356, 0.99764775, 0.99823581, 0.99882388, 0.99970597,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.54150680e-01, -1.82321557e-01,\n",
       "                     -2.00670695e-01, -2.23143551e-01, -2.87682072e-01, -3.10154928e-01,\n",
       "                     -3.13657559e-01, -3.15081047e-01, -3.36472237e-01, -4.05465108e-01,\n",
       "                     -4.51985124e-01, -4.70003629e-01, -4.85507816e-01, -5.10825624e-01,\n",
       "                     -5.59615788e-01, -5.75364145e-01, -5.87786665e-01, -6.06135804e-01,\n",
       "                     -6.19039208e-01, -6.64976304e-01, -6.72944473e-01, -6.93147181e-01,\n",
       "                     -7.37598943e-01, -7.45593656e-01, -7.53771802e-01, -7.59105148e-01,\n",
       "                     -7.80158558e-01, -8.04372816e-01, -8.10930216e-01, -8.16761137e-01,\n",
       "                     -8.26678573e-01, -8.47297860e-01, -8.60201265e-01, -8.67100488e-01,\n",
       "                     -8.73450573e-01, -8.78550404e-01, -8.79249460e-01, -8.87303195e-01,\n",
       "                     -8.99196299e-01, -9.16290732e-01, -9.27340568e-01, -9.34309237e-01,\n",
       "                     -9.49080555e-01, -9.55511445e-01, -9.66187703e-01, -9.68737207e-01,\n",
       "                     -9.80829253e-01, -9.90398704e-01, -1.01345448e+00, -1.01419495e+00,\n",
       "                     -1.02450432e+00, -1.02961942e+00, -1.03609193e+00, -1.04731899e+00,\n",
       "                     -1.06471074e+00, -1.07535543e+00, -1.07880966e+00, -1.09218140e+00,\n",
       "                     -1.09861229e+00, -1.11923158e+00, -1.12492960e+00, -1.12846525e+00,\n",
       "                     -1.12986483e+00, -1.13140211e+00, -1.14862271e+00, -1.15267951e+00,\n",
       "                     -1.15745279e+00, -1.17557333e+00, -1.18451563e+00, -1.20397280e+00,\n",
       "                     -1.21639532e+00, -1.22146596e+00, -1.22536399e+00, -1.22722967e+00,\n",
       "                     -1.22866542e+00, -1.27766052e+00, -1.28093385e+00, -1.32175584e+00,\n",
       "                     -1.34992672e+00, -1.36330484e+00, -1.37147928e+00, -1.37230812e+00,\n",
       "                     -1.37486567e+00, -1.38629436e+00, -1.39341183e+00, -1.41754690e+00,\n",
       "                     -1.44238383e+00, -1.49091931e+00, -1.50407740e+00, -1.55059741e+00,\n",
       "                     -1.55334845e+00, -1.55814462e+00, -1.56218503e+00, -1.60943791e+00,\n",
       "                     -1.65595793e+00, -1.70474809e+00, -1.71297859e+00, -1.72276660e+00,\n",
       "                     -1.75785792e+00, -1.79175947e+00, -1.82454929e+00, -1.83258146e+00,\n",
       "                     -1.84582669e+00, -1.86214027e+00, -1.88454120e+00, -1.89184293e+00,\n",
       "                     -1.94591015e+00, -2.18122424e+00, -2.19722458e+00, -2.30258509e+00,\n",
       "                     -2.35137526e+00, -2.39789527e+00, -2.42036813e+00, -2.45100510e+00,\n",
       "                     -2.59026717e+00, -2.83321334e+00, -3.17805383e+00, -3.29583687e+00,\n",
       "                     -3.85014760e+00, -3.45387764e+01]), auc_score=0.5606069416707583, privacy_risk=0.5422923102384276, accuracy=0.5421256326287586, tpr_ind=0.5289620699794179, tnr_ind=0.5556225504974375, test_train_ratio=0.9753013819464863, dataset_size=[3401, 3317]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00856531, 0.01040073, 0.01376568, 0.01468339,\n",
       "                     0.01774243, 0.01896604, 0.02018966, 0.02569593, 0.03028449,\n",
       "                     0.03211991, 0.03487305, 0.03915571, 0.04435607, 0.0468033 ,\n",
       "                     0.05108596, 0.05812175, 0.05873356, 0.0617926 , 0.06393392,\n",
       "                     0.07158152, 0.07984093, 0.08320587, 0.08412359, 0.08962986,\n",
       "                     0.09085347, 0.09391251, 0.10278373, 0.11073723, 0.12022025,\n",
       "                     0.13796268, 0.14499847, 0.14775161, 0.16059957, 0.16794127,\n",
       "                     0.17130621, 0.17558887, 0.18415418, 0.18874273, 0.19241358,\n",
       "                     0.19547262, 0.20434384, 0.21443867, 0.21810951, 0.22025084,\n",
       "                     0.23554604, 0.24441725, 0.24992352, 0.25665341, 0.25848883,\n",
       "                     0.28969104, 0.29642092, 0.29856225, 0.35178954, 0.35698991,\n",
       "                     0.36280208, 0.37717957, 0.38635668, 0.39033344, 0.40073417,\n",
       "                     0.40654634, 0.40929948, 0.41205262, 0.43591312, 0.44019578,\n",
       "                     0.44264301, 0.44356072, 0.44478434, 0.46222086, 0.46466809,\n",
       "                     0.47048027, 0.47506883, 0.47721016, 0.48455185, 0.48791679,\n",
       "                     0.49372897, 0.50045886, 0.50841236, 0.52646069, 0.53135515,\n",
       "                     0.55858061, 0.56408688, 0.57142857, 0.57601713, 0.59957173,\n",
       "                     0.60354849, 0.61456103, 0.62618538, 0.62710309, 0.64086877,\n",
       "                     0.65035179, 0.65585806, 0.66228204, 0.66595289, 0.67176507,\n",
       "                     0.6742123 , 0.67910676, 0.68553074, 0.70113184, 0.70266136,\n",
       "                     0.71367391, 0.7283573 , 0.73355766, 0.74089936, 0.7442643 ,\n",
       "                     0.75894769, 0.76292444, 0.76843071, 0.77424289, 0.78739676,\n",
       "                     0.7907617 , 0.79412664, 0.80881003, 0.80942184, 0.81645763,\n",
       "                     0.81676354, 0.82349342, 0.8293056 , 0.82991741, 0.83205873,\n",
       "                     0.83450597, 0.8369532 , 0.85041297, 0.87947385, 0.88650964,\n",
       "                     0.8910982 , 0.89476904, 0.91067605, 0.91281738, 0.9146528 ,\n",
       "                     0.92015907, 0.92077088, 0.92444173, 0.92505353, 0.9302539 ,\n",
       "                     0.93270113, 0.93759559, 0.9379015 , 0.93912511, 0.94218415,\n",
       "                     0.94310187, 0.94799633, 0.95044356, 0.95931478, 0.95992658,\n",
       "                     0.96329153, 0.96390333, 0.9687978 , 0.96940961, 0.97460997,\n",
       "                     0.97552768, 0.9767513 , 0.9770572 , 0.97828082, 0.97858672,\n",
       "                     1.        ]), tpr=array([0.        , 0.01942592, 0.02203537, 0.02493476, 0.02696434,\n",
       "                     0.03218324, 0.03682227, 0.03972166, 0.04378081, 0.0518991 ,\n",
       "                     0.05479849, 0.06088721, 0.06755581, 0.07277472, 0.07741374,\n",
       "                     0.08321253, 0.0919107 , 0.09307046, 0.09799942, 0.10176863,\n",
       "                     0.10756741, 0.11568571, 0.12264424, 0.12467382, 0.12902291,\n",
       "                     0.13134242, 0.13627138, 0.15250797, 0.16178602, 0.17367353,\n",
       "                     0.19512902, 0.20179762, 0.20440707, 0.21890403, 0.22586257,\n",
       "                     0.22789214, 0.23485068, 0.24499855, 0.25079733, 0.25485648,\n",
       "                     0.26007538, 0.26587417, 0.27602204, 0.27921137, 0.28124094,\n",
       "                     0.29602783, 0.31168455, 0.31690345, 0.32328211, 0.32531168,\n",
       "                     0.3609742 , 0.3676428 , 0.37025225, 0.42012177, 0.42766019,\n",
       "                     0.43548855, 0.44969556, 0.45607422, 0.46245288, 0.47463033,\n",
       "                     0.48419832, 0.48651783, 0.48970716, 0.50594375, 0.51087272,\n",
       "                     0.51261235, 0.51464193, 0.51580168, 0.52913888, 0.53319803,\n",
       "                     0.53899681, 0.54450565, 0.54827486, 0.55407364, 0.56161206,\n",
       "                     0.56741084, 0.57349957, 0.58306756, 0.59495506, 0.60249348,\n",
       "                     0.6323572 , 0.63815599, 0.64772398, 0.65004349, 0.67033923,\n",
       "                     0.6723688 , 0.68831545, 0.69846332, 0.70252247, 0.71556973,\n",
       "                     0.72368803, 0.7257176 , 0.73151638, 0.73412583, 0.74079443,\n",
       "                     0.74340389, 0.74978255, 0.7576109 , 0.76949841, 0.77123804,\n",
       "                     0.78341548, 0.79820238, 0.80342128, 0.81298927, 0.81588866,\n",
       "                     0.82632647, 0.83125544, 0.83560452, 0.84053349, 0.8495216 ,\n",
       "                     0.85503044, 0.85937953, 0.87242679, 0.87387649, 0.87880545,\n",
       "                     0.87996521, 0.88576399, 0.89098289, 0.89185271, 0.89301247,\n",
       "                     0.89504204, 0.89736155, 0.90779936, 0.92606553, 0.93070455,\n",
       "                     0.93534358, 0.93650333, 0.95302986, 0.95563932, 0.95766889,\n",
       "                     0.9599884 , 0.96085822, 0.96375761, 0.96491737, 0.96752682,\n",
       "                     0.96897651, 0.97419542, 0.9747753 , 0.97564511, 0.97680487,\n",
       "                     0.97912438, 0.9814439 , 0.98289359, 0.99072195, 0.99101189,\n",
       "                     0.99217164, 0.99275152, 0.99449116, 0.99507104, 0.99710061,\n",
       "                     0.9985503 , 0.99884024, 0.99913018, 0.99942012, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.05360516e-01, -1.82321557e-01,\n",
       "                     -2.51314428e-01, -2.87682072e-01, -3.18453731e-01, -3.36472237e-01,\n",
       "                     -3.56674944e-01, -4.05465108e-01, -4.70003629e-01, -4.81838087e-01,\n",
       "                     -5.02091944e-01, -5.10825624e-01, -5.23248144e-01, -5.30628251e-01,\n",
       "                     -5.50046337e-01, -5.59615788e-01, -5.67984038e-01, -5.70544858e-01,\n",
       "                     -5.87786665e-01, -5.99621123e-01, -6.06135804e-01, -6.19039208e-01,\n",
       "                     -6.24154309e-01, -6.28608659e-01, -6.32522559e-01, -6.47477144e-01,\n",
       "                     -6.61398482e-01, -6.80877088e-01, -6.93147181e-01, -7.14653386e-01,\n",
       "                     -7.47214402e-01, -7.51416089e-01, -7.53771802e-01, -7.62140052e-01,\n",
       "                     -7.73189888e-01, -7.75385279e-01, -7.88457360e-01, -7.94929875e-01,\n",
       "                     -7.98507696e-01, -8.10930216e-01, -8.14099791e-01, -8.20980552e-01,\n",
       "                     -8.26678573e-01, -8.38858992e-01, -8.39329691e-01, -8.47297860e-01,\n",
       "                     -8.60201265e-01, -8.87303195e-01, -8.88259218e-01, -8.89857475e-01,\n",
       "                     -8.93817876e-01, -8.95138357e-01, -9.00786545e-01, -9.08855753e-01,\n",
       "                     -9.12200747e-01, -9.16290732e-01, -9.34309237e-01, -9.44461609e-01,\n",
       "                     -9.46143695e-01, -9.65080896e-01, -9.69400557e-01, -9.71860583e-01,\n",
       "                     -9.73449146e-01, -9.80829253e-01, -9.98528830e-01, -1.01160091e+00,\n",
       "                     -1.02338887e+00, -1.02450432e+00, -1.02961942e+00, -1.04454507e+00,\n",
       "                     -1.04596856e+00, -1.04731899e+00, -1.05939158e+00, -1.06471074e+00,\n",
       "                     -1.06635143e+00, -1.07820342e+00, -1.08221848e+00, -1.08570888e+00,\n",
       "                     -1.09861229e+00, -1.13140211e+00, -1.13822143e+00, -1.13943428e+00,\n",
       "                     -1.14057649e+00, -1.14513230e+00, -1.14595841e+00, -1.16315081e+00,\n",
       "                     -1.16760516e+00, -1.17007125e+00, -1.17865500e+00, -1.18958407e+00,\n",
       "                     -1.19392247e+00, -1.20397280e+00, -1.20831121e+00, -1.23676263e+00,\n",
       "                     -1.23969089e+00, -1.24745792e+00, -1.24927256e+00, -1.25276297e+00,\n",
       "                     -1.26627669e+00, -1.26667140e+00, -1.26851133e+00, -1.27417706e+00,\n",
       "                     -1.28093385e+00, -1.28401551e+00, -1.29392104e+00, -1.29928298e+00,\n",
       "                     -1.30992138e+00, -1.38629436e+00, -1.41226985e+00, -1.41908418e+00,\n",
       "                     -1.42977947e+00, -1.48160454e+00, -1.48427477e+00, -1.50407740e+00,\n",
       "                     -1.51512723e+00, -1.52846885e+00, -1.54044504e+00, -1.55814462e+00,\n",
       "                     -1.58045038e+00, -1.58412010e+00, -1.60386687e+00, -1.60943791e+00,\n",
       "                     -1.62186043e+00, -1.63413053e+00, -1.65822808e+00, -1.66405900e+00,\n",
       "                     -1.67397643e+00, -1.69167601e+00, -1.70474809e+00, -1.73460106e+00,\n",
       "                     -1.74046617e+00, -1.74919985e+00, -1.75401914e+00, -1.79175947e+00,\n",
       "                     -1.84582669e+00, -1.87180218e+00, -1.89711998e+00, -1.98100147e+00,\n",
       "                     -1.99809590e+00, -2.06369318e+00, -2.07944154e+00, -2.08406049e+00,\n",
       "                     -2.19722458e+00, -2.22462355e+00, -2.30258509e+00, -2.48490665e+00,\n",
       "                     -2.56494936e+00, -2.58668934e+00, -2.62466859e+00, -2.63905733e+00,\n",
       "                     -2.77258872e+00, -3.21887582e+00, -3.46573590e+00, -3.45387764e+01]), auc_score=0.5590806597485131, privacy_risk=0.5388272730086731, accuracy=0.5375111640369158, tpr_ind=0.48970716149608584, tnr_ind=0.5879473845212603, test_train_ratio=0.9478109596984633, dataset_size=[3449, 3269]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00700321, 0.00933761, 0.01196382, 0.01371462,\n",
       "                     0.01459002, 0.01721622, 0.01779982, 0.01809163, 0.01838343,\n",
       "                     0.03238985, 0.03530785, 0.03735045, 0.04347826, 0.04639626,\n",
       "                     0.05135687, 0.05515028, 0.05923548, 0.06390429, 0.0697403 ,\n",
       "                     0.0711993 , 0.08783192, 0.10358915, 0.11759556, 0.11963817,\n",
       "                     0.12197257, 0.13656259, 0.13860519, 0.1421068 , 0.144733  ,\n",
       "                     0.14648381, 0.14998541, 0.16107383, 0.19959148, 0.20309308,\n",
       "                     0.20513569, 0.20747009, 0.20834549, 0.2150569 , 0.22993872,\n",
       "                     0.25795156, 0.27808579, 0.28071199, 0.31806245, 0.32039685,\n",
       "                     0.33673767, 0.3554129 , 0.3592063 , 0.37817333, 0.37992413,\n",
       "                     0.39130435, 0.42194339, 0.42486139, 0.43361541, 0.43915961,\n",
       "                     0.44412022, 0.44733003, 0.45404144, 0.45812664, 0.46688065,\n",
       "                     0.48672308, 0.48905748, 0.49285089, 0.51736212, 0.52028013,\n",
       "                     0.53078494, 0.53370295, 0.54216516, 0.56084039, 0.56521739,\n",
       "                     0.571637  , 0.57776481, 0.59293843, 0.59848264, 0.60723665,\n",
       "                     0.62795448, 0.63116428, 0.69010797, 0.70061278, 0.70965859,\n",
       "                     0.7111176 , 0.7169536 , 0.73358623, 0.77327108, 0.79048731,\n",
       "                     0.80770353, 0.81062153, 0.81704114, 0.82170995, 0.82462795,\n",
       "                     0.82550336, 0.83834257, 0.85293259, 0.86168661, 0.86898162,\n",
       "                     0.87598483, 0.87744383, 0.88065363, 0.88444704, 0.88911584,\n",
       "                     0.88969945, 0.89962066, 0.90516487, 0.90545667, 0.90808287,\n",
       "                     0.91070907, 0.91654508, 0.91975489, 0.9255909 , 0.9305515 ,\n",
       "                     0.93317771, 0.93609571, 0.93697111, 0.93872191, 0.94601692,\n",
       "                     0.95156113, 0.96440035, 0.96644295, 0.96644295, 0.96877736,\n",
       "                     0.97198716, 0.97227896, 0.97315436, 0.97548877, 0.97607237,\n",
       "                     0.97782317, 0.97928217, 0.97986577, 1.        ]), tpr=array([0.        , 0.01731996, 0.01944698, 0.02309328, 0.02765117,\n",
       "                     0.03008204, 0.03646308, 0.03889395, 0.04041325, 0.04254026,\n",
       "                     0.06198724, 0.0674567 , 0.07049529, 0.08204193, 0.0911577 ,\n",
       "                     0.0978426 , 0.10148891, 0.10695837, 0.11303555, 0.11972045,\n",
       "                     0.12245518, 0.14615618, 0.16286843, 0.17502279, 0.1786691 ,\n",
       "                     0.18261926, 0.1972045 , 0.19872379, 0.20297782, 0.20419325,\n",
       "                     0.20632027, 0.21209359, 0.22880583, 0.26739593, 0.27286539,\n",
       "                     0.27681556, 0.28198116, 0.28410817, 0.28957764, 0.3120632 ,\n",
       "                     0.33029474, 0.35186873, 0.35551504, 0.39623215, 0.39775144,\n",
       "                     0.41537527, 0.43694926, 0.44059556, 0.46095412, 0.46399271,\n",
       "                     0.47250076, 0.49680948, 0.50197508, 0.5144333 , 0.51899119,\n",
       "                     0.52446065, 0.52658766, 0.53388028, 0.53722273, 0.54421149,\n",
       "                     0.56031601, 0.56305074, 0.56791249, 0.59282893, 0.59434822,\n",
       "                     0.60346399, 0.60923731, 0.61804923, 0.62929201, 0.63384989,\n",
       "                     0.63962321, 0.64387724, 0.65663932, 0.66362808, 0.66848982,\n",
       "                     0.69249468, 0.69614099, 0.75691279, 0.76511699, 0.77089031,\n",
       "                     0.77210574, 0.77727135, 0.78851413, 0.82588879, 0.84624734,\n",
       "                     0.86235187, 0.86326345, 0.86721361, 0.87329079, 0.87663324,\n",
       "                     0.87876026, 0.88969918, 0.90853844, 0.91704649, 0.92312367,\n",
       "                     0.9273777 , 0.92828927, 0.93072015, 0.93345488, 0.9377089 ,\n",
       "                     0.9392282 , 0.94652081, 0.95077484, 0.95229414, 0.95381343,\n",
       "                     0.9562443 , 0.95958675, 0.96049833, 0.9644485 , 0.96718323,\n",
       "                     0.96931024, 0.97113339, 0.97234883, 0.97326041, 0.97842601,\n",
       "                     0.98085688, 0.98997265, 0.99058037, 0.99088423, 0.99209967,\n",
       "                     0.99361896, 0.99422668, 0.99544211, 0.99817685, 0.99908842,\n",
       "                     0.99939228, 0.99969614, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -1.54150680e-01,\n",
       "                     -1.82321557e-01, -2.23143551e-01, -2.87682072e-01, -3.18453731e-01,\n",
       "                     -3.36472237e-01, -3.56674944e-01, -4.05465108e-01, -4.41832752e-01,\n",
       "                     -4.70003629e-01, -4.73287704e-01, -5.10825624e-01, -5.46543706e-01,\n",
       "                     -5.59615788e-01, -5.75364145e-01, -5.87786665e-01, -5.97837001e-01,\n",
       "                     -6.35988767e-01, -6.93147181e-01, -7.11165686e-01, -7.17839793e-01,\n",
       "                     -7.33969175e-01, -7.67255153e-01, -7.73189888e-01, -7.88457360e-01,\n",
       "                     -7.94929875e-01, -8.10930216e-01, -8.26678573e-01, -8.39750655e-01,\n",
       "                     -8.44697079e-01, -8.46172368e-01, -8.47297860e-01, -8.69037847e-01,\n",
       "                     -8.80358723e-01, -8.87303195e-01, -8.93817876e-01, -8.94431938e-01,\n",
       "                     -8.96088025e-01, -9.13469856e-01, -9.16290732e-01, -9.45704617e-01,\n",
       "                     -9.55511445e-01, -9.63437510e-01, -9.73762086e-01, -9.80829253e-01,\n",
       "                     -9.88264231e-01, -9.93251773e-01, -1.01160091e+00, -1.01613607e+00,\n",
       "                     -1.01693426e+00, -1.02262638e+00, -1.02961942e+00, -1.04145387e+00,\n",
       "                     -1.04982212e+00, -1.05605267e+00, -1.06784063e+00, -1.08401349e+00,\n",
       "                     -1.09861229e+00, -1.13497993e+00, -1.13943428e+00, -1.14624034e+00,\n",
       "                     -1.16315081e+00, -1.17351360e+00, -1.18269541e+00, -1.18658106e+00,\n",
       "                     -1.20126644e+00, -1.20397280e+00, -1.21444410e+00, -1.23214368e+00,\n",
       "                     -1.23906412e+00, -1.24653242e+00, -1.25276297e+00, -1.26534175e+00,\n",
       "                     -1.27629347e+00, -1.28647403e+00, -1.29928298e+00, -1.31824090e+00,\n",
       "                     -1.32175584e+00, -1.32566974e+00, -1.33072451e+00, -1.33200128e+00,\n",
       "                     -1.36365188e+00, -1.36724617e+00, -1.38629436e+00, -1.42403469e+00,\n",
       "                     -1.44691898e+00, -1.45225233e+00, -1.45528723e+00, -1.46633707e+00,\n",
       "                     -1.50048673e+00, -1.50407740e+00, -1.51512723e+00, -1.51982575e+00,\n",
       "                     -1.54044504e+00, -1.58412010e+00, -1.60943791e+00, -1.63760879e+00,\n",
       "                     -1.64865863e+00, -1.66613326e+00, -1.74296931e+00, -1.75785792e+00,\n",
       "                     -1.79175947e+00, -1.81237876e+00, -1.82161243e+00, -1.84582669e+00,\n",
       "                     -1.92368701e+00, -1.92990981e+00, -1.94591015e+00, -1.99243016e+00,\n",
       "                     -2.01490302e+00, -2.03688193e+00, -2.05713578e+00, -2.07944154e+00,\n",
       "                     -2.14787870e+00, -2.19722458e+00, -2.39789527e+00, -2.60268969e+00,\n",
       "                     -2.61006979e+00, -2.63905733e+00, -2.67414865e+00, -2.94443898e+00,\n",
       "                     -2.97892516e+00, -3.21887582e+00, -3.95124372e+00, -4.04305127e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5608507591199597, privacy_risk=0.5420342877449946, accuracy=0.5436141708841917, tpr_ind=0.4639927073837739, tnr_ind=0.6200758681062154, test_train_ratio=1.0413248252810696, dataset_size=[3291, 3427]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.01185185, 0.01274074, 0.01392593, 0.0162963 ,\n",
       "                     0.02074074, 0.02281481, 0.0237037 , 0.02607407, 0.03377778,\n",
       "                     0.03911111, 0.04088889, 0.04237037, 0.04592593, 0.0482963 ,\n",
       "                     0.05392593, 0.06755556, 0.07288889, 0.07496296, 0.07822222,\n",
       "                     0.08711111, 0.0877037 , 0.08977778, 0.10548148, 0.10903704,\n",
       "                     0.11555556, 0.11940741, 0.13333333, 0.136     , 0.13837037,\n",
       "                     0.14044444, 0.14933333, 0.15288889, 0.17155556, 0.184     ,\n",
       "                     0.1917037 , 0.19940741, 0.2       , 0.20237037, 0.21748148,\n",
       "                     0.22074074, 0.24059259, 0.27733333, 0.27822222, 0.28977778,\n",
       "                     0.31111111, 0.32948148, 0.33392593, 0.33985185, 0.34162963,\n",
       "                     0.34518519, 0.34696296, 0.36622222, 0.38962963, 0.39644444,\n",
       "                     0.40148148, 0.4077037 , 0.42607407, 0.42903704, 0.4562963 ,\n",
       "                     0.50548148, 0.52059259, 0.53925926, 0.56      , 0.56118519,\n",
       "                     0.56503704, 0.56651852, 0.57688889, 0.58044444, 0.59496296,\n",
       "                     0.59496296, 0.63259259, 0.63585185, 0.63674074, 0.65718519,\n",
       "                     0.65896296, 0.67437037, 0.70755556, 0.71377778, 0.71733333,\n",
       "                     0.72503704, 0.74222222, 0.74844444, 0.75674074, 0.76592593,\n",
       "                     0.76888889, 0.77274074, 0.79051852, 0.79259259, 0.79881481,\n",
       "                     0.80266667, 0.8077037 , 0.81896296, 0.82311111, 0.84296296,\n",
       "                     0.85007407, 0.85125926, 0.85185185, 0.86162963, 0.86844444,\n",
       "                     0.87792593, 0.88651852, 0.88888889, 0.91792593, 0.93037037,\n",
       "                     0.93125926, 0.93777778, 0.94133333, 0.94577778, 0.94725926,\n",
       "                     0.94755556, 0.95644444, 0.96177778, 0.96266667, 0.96355556,\n",
       "                     0.96622222, 0.96622222, 0.96740741, 0.96888889, 0.96888889,\n",
       "                     0.96948148, 0.97007407, 0.97125926, 0.97274074, 0.97511111,\n",
       "                     1.        ]), tpr=array([0.        , 0.02512713, 0.02722106, 0.02901585, 0.03350284,\n",
       "                     0.03828896, 0.04128029, 0.04337421, 0.04606641, 0.05563865,\n",
       "                     0.06341609, 0.06700568, 0.06850135, 0.07089441, 0.074484  ,\n",
       "                     0.08226144, 0.10020939, 0.1085851 , 0.11307209, 0.11606342,\n",
       "                     0.12952438, 0.13281484, 0.13790009, 0.15704457, 0.16153156,\n",
       "                     0.1702064 , 0.17409512, 0.18755609, 0.19264134, 0.1950344 ,\n",
       "                     0.1968292 , 0.20460664, 0.20759797, 0.22793898, 0.24169907,\n",
       "                     0.24528866, 0.25276698, 0.2548609 , 0.25785223, 0.27609931,\n",
       "                     0.2805863 , 0.30062818, 0.34160933, 0.34400239, 0.35686509,\n",
       "                     0.37541131, 0.40442716, 0.40771762, 0.41340114, 0.4148968 ,\n",
       "                     0.41818726, 0.42327251, 0.43763087, 0.46335627, 0.47053545,\n",
       "                     0.47621897, 0.48220162, 0.50673048, 0.50822614, 0.52976369,\n",
       "                     0.58241101, 0.5970685 , 0.61800778, 0.64552797, 0.64822016,\n",
       "                     0.65031409, 0.65210888, 0.66437332, 0.66676638, 0.68052647,\n",
       "                     0.68142387, 0.71791804, 0.7203111 , 0.72240503, 0.74035298,\n",
       "                     0.7433443 , 0.7544122 , 0.79060724, 0.7938977 , 0.79838468,\n",
       "                     0.80735866, 0.82381095, 0.82769967, 0.83457972, 0.84415196,\n",
       "                     0.84624589, 0.84863895, 0.86419384, 0.86628777, 0.87077475,\n",
       "                     0.87466348, 0.87735567, 0.88303919, 0.88573138, 0.90188453,\n",
       "                     0.90696979, 0.90756805, 0.90846545, 0.91893509, 0.92372121,\n",
       "                     0.92940473, 0.93568651, 0.93718217, 0.9641041 , 0.97367634,\n",
       "                     0.97457374, 0.97816333, 0.97906072, 0.98145378, 0.98235118,\n",
       "                     0.98294945, 0.99072689, 0.99252169, 0.99282082, 0.99401735,\n",
       "                     0.99461561, 0.99491475, 0.99551301, 0.99611128, 0.99670954,\n",
       "                     0.99790607, 0.99850434, 0.9991026 , 0.99940173, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -1.54150680e-01,\n",
       "                     -2.87682072e-01, -3.18453731e-01, -3.36472237e-01, -3.56674944e-01,\n",
       "                     -3.67724780e-01, -3.84411699e-01, -4.05465108e-01, -4.59532329e-01,\n",
       "                     -4.70003629e-01, -4.85507816e-01, -5.10825624e-01, -5.26093096e-01,\n",
       "                     -5.30628251e-01, -5.38996501e-01, -5.50046337e-01, -5.87786665e-01,\n",
       "                     -6.00056757e-01, -6.46627165e-01, -6.63294217e-01, -6.93147181e-01,\n",
       "                     -7.25937003e-01, -7.27048732e-01, -7.30887509e-01, -7.36632292e-01,\n",
       "                     -7.50305594e-01, -7.53771802e-01, -7.73189888e-01, -7.84954730e-01,\n",
       "                     -7.88457360e-01, -7.91127589e-01, -8.06087592e-01, -8.10930216e-01,\n",
       "                     -8.24175443e-01, -8.26678573e-01, -8.32909123e-01, -8.37886026e-01,\n",
       "                     -8.47297860e-01, -8.57902414e-01, -8.60762590e-01, -8.64997437e-01,\n",
       "                     -9.02238978e-01, -9.16290732e-01, -9.26547232e-01, -9.34309237e-01,\n",
       "                     -9.47381319e-01, -9.55511445e-01, -9.69400557e-01, -9.73449146e-01,\n",
       "                     -9.80829253e-01, -9.88070414e-01, -9.96333440e-01, -1.00680474e+00,\n",
       "                     -1.01160091e+00, -1.02700276e+00, -1.02961942e+00, -1.03653986e+00,\n",
       "                     -1.07173927e+00, -1.09178632e+00, -1.09861229e+00, -1.12011849e+00,\n",
       "                     -1.13497993e+00, -1.14513230e+00, -1.15267951e+00, -1.16162526e+00,\n",
       "                     -1.17865500e+00, -1.20179652e+00, -1.20397280e+00, -1.21457217e+00,\n",
       "                     -1.21639532e+00, -1.23214368e+00, -1.24319352e+00, -1.25276297e+00,\n",
       "                     -1.27188401e+00, -1.28642836e+00, -1.29098418e+00, -1.29928298e+00,\n",
       "                     -1.31730149e+00, -1.32054298e+00, -1.32687094e+00, -1.33041390e+00,\n",
       "                     -1.34644845e+00, -1.34992672e+00, -1.35454566e+00, -1.36687628e+00,\n",
       "                     -1.38629436e+00, -1.40282366e+00, -1.40534256e+00, -1.41369334e+00,\n",
       "                     -1.42500887e+00, -1.46633707e+00, -1.47484776e+00, -1.49752000e+00,\n",
       "                     -1.50407740e+00, -1.54044504e+00, -1.59214642e+00, -1.59685913e+00,\n",
       "                     -1.60943791e+00, -1.67397643e+00, -1.68639895e+00, -1.72870133e+00,\n",
       "                     -1.79175947e+00, -1.84582669e+00, -1.94591015e+00, -2.03688193e+00,\n",
       "                     -2.07944154e+00, -2.12026354e+00, -2.14006616e+00, -2.16685348e+00,\n",
       "                     -2.23359222e+00, -2.30258509e+00, -2.32727771e+00, -2.35137526e+00,\n",
       "                     -2.39789527e+00, -2.48490665e+00, -2.67414865e+00, -2.83321334e+00,\n",
       "                     -2.93119375e+00, -3.04452244e+00, -3.11351531e+00, -3.17805383e+00,\n",
       "                     -4.15888308e+00, -3.45387764e+01]), auc_score=0.5626887359989364, privacy_risk=0.5437422142453552, accuracy=0.5431676094075618, tpr_ind=0.6643733173795991, tnr_ind=0.4231111111111111, test_train_ratio=1.0095722405025427, dataset_size=[3343, 3375]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00808625, 0.01168014, 0.01287811, 0.01377658,\n",
       "                     0.01527403, 0.01856843, 0.02126385, 0.02276131, 0.02515723,\n",
       "                     0.02815214, 0.03743636, 0.04222821, 0.04702007, 0.05330937,\n",
       "                     0.05720276, 0.05780174, 0.06259359, 0.06409105, 0.07038035,\n",
       "                     0.07157832, 0.07696915, 0.07756813, 0.08745133, 0.10452231,\n",
       "                     0.10542078, 0.11350704, 0.13297394, 0.14974543, 0.15214136,\n",
       "                     0.16022761, 0.16142558, 0.16531896, 0.17430368, 0.17759808,\n",
       "                     0.18837975, 0.21114106, 0.2165319 , 0.2198263 , 0.23869422,\n",
       "                     0.24228811, 0.24947589, 0.31925726, 0.32345013, 0.34591195,\n",
       "                     0.35908955, 0.37945493, 0.39293202, 0.39442947, 0.39982031,\n",
       "                     0.40491165, 0.40551063, 0.40820605, 0.45342917, 0.45492662,\n",
       "                     0.45941899, 0.45971848, 0.46840371, 0.47678946, 0.47948488,\n",
       "                     0.48936807, 0.50014975, 0.50404313, 0.51063193, 0.5115304 ,\n",
       "                     0.53818509, 0.55495657, 0.55795148, 0.61485475, 0.62473795,\n",
       "                     0.63132674, 0.6460018 , 0.64899671, 0.6492962 , 0.65947889,\n",
       "                     0.66516921, 0.67804732, 0.68703205, 0.68972746, 0.70679844,\n",
       "                     0.70949386, 0.74932615, 0.77118898, 0.7738844 , 0.78496556,\n",
       "                     0.78766098, 0.79814316, 0.80053908, 0.80712788, 0.80892483,\n",
       "                     0.81461515, 0.81761006, 0.82090446, 0.82599581, 0.82988919,\n",
       "                     0.83528002, 0.85294999, 0.86163522, 0.86762504, 0.87151842,\n",
       "                     0.87511231, 0.88050314, 0.88080264, 0.88679245, 0.89218329,\n",
       "                     0.89757412, 0.90356394, 0.90536089, 0.90775681, 0.90895478,\n",
       "                     0.91614256, 0.92392932, 0.92482779, 0.92722372, 0.92722372,\n",
       "                     0.93321354, 0.93920335, 0.93980234, 0.94129979, 0.94369572,\n",
       "                     0.9442947 , 0.94699012, 0.95058401, 0.95178197, 0.95387841,\n",
       "                     0.95537586, 0.95597484, 0.95777179, 0.96106619, 0.96466008,\n",
       "                     0.9673555 , 1.        ]), tpr=array([0.        , 0.02219592, 0.02485943, 0.02722699, 0.02900266,\n",
       "                     0.03196212, 0.03432968, 0.0396567 , 0.04113643, 0.04646345,\n",
       "                     0.05297425, 0.06658775, 0.07132288, 0.07753773, 0.0864161 ,\n",
       "                     0.09144717, 0.09411068, 0.10062149, 0.1026931 , 0.11216336,\n",
       "                     0.11482687, 0.12370524, 0.12548091, 0.14530926, 0.16543356,\n",
       "                     0.16750518, 0.18023084, 0.19591595, 0.21426458, 0.21781592,\n",
       "                     0.22491861, 0.22639834, 0.23054158, 0.24030778, 0.24385913,\n",
       "                     0.25421722, 0.27463747, 0.28114827, 0.28381178, 0.30186446,\n",
       "                     0.30748742, 0.31518201, 0.39242379, 0.39686298, 0.42201835,\n",
       "                     0.43918319, 0.46285883, 0.47617638, 0.47943178, 0.48387097,\n",
       "                     0.48771826, 0.49067772, 0.4918615 , 0.55253033, 0.55401006,\n",
       "                     0.55904114, 0.56081681, 0.56851139, 0.5750222 , 0.57916543,\n",
       "                     0.59544244, 0.60668837, 0.61023972, 0.61734241, 0.61941403,\n",
       "                     0.64249778, 0.65492749, 0.657591  , 0.71500444, 0.72240308,\n",
       "                     0.73039361, 0.74134359, 0.74519088, 0.74607872, 0.76235573,\n",
       "                     0.76916247, 0.78248002, 0.78839893, 0.79106244, 0.81237052,\n",
       "                     0.81592187, 0.84965966, 0.86771234, 0.8706718 , 0.87777449,\n",
       "                     0.88102989, 0.8934596 , 0.89523528, 0.89937851, 0.90085824,\n",
       "                     0.90440959, 0.90973661, 0.91328796, 0.9168393 , 0.91891092,\n",
       "                     0.92305416, 0.93252442, 0.93844333, 0.94465818, 0.94732169,\n",
       "                     0.94968926, 0.95472033, 0.95531222, 0.9603433 , 0.96330275,\n",
       "                     0.96478248, 0.96981355, 0.97158923, 0.97247706, 0.97277301,\n",
       "                     0.97721219, 0.98165138, 0.98194732, 0.98342705, 0.98401894,\n",
       "                     0.98549867, 0.98757029, 0.98816218, 0.98875407, 0.98993785,\n",
       "                     0.99052974, 0.99200947, 0.99260136, 0.99289731, 0.99615271,\n",
       "                     0.99644865, 0.9967446 , 0.99704054, 0.99940811, 0.99970405,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.05360516e-01, -1.17783036e-01,\n",
       "                     -1.54150680e-01, -1.82321557e-01, -2.23143551e-01, -2.87682072e-01,\n",
       "                     -3.36472237e-01, -3.67724780e-01, -3.74693449e-01, -4.05465108e-01,\n",
       "                     -4.46287103e-01, -4.51985124e-01, -4.70003629e-01, -4.98991166e-01,\n",
       "                     -5.10825624e-01, -5.19875459e-01, -5.38996501e-01, -5.59615788e-01,\n",
       "                     -5.75364145e-01, -5.87786665e-01, -6.06135804e-01, -6.15588946e-01,\n",
       "                     -6.16774202e-01, -6.19039208e-01, -6.81451141e-01, -6.83668437e-01,\n",
       "                     -6.93147181e-01, -7.33969175e-01, -7.73189888e-01, -7.88457360e-01,\n",
       "                     -7.94929875e-01, -8.07557532e-01, -8.10930216e-01, -8.14099791e-01,\n",
       "                     -8.34797698e-01, -8.40783179e-01, -8.47297860e-01, -8.51970766e-01,\n",
       "                     -8.62223511e-01, -8.69037847e-01, -8.74829964e-01, -8.75468737e-01,\n",
       "                     -8.85224912e-01, -9.09370289e-01, -9.16290732e-01, -9.20725329e-01,\n",
       "                     -9.34309237e-01, -9.80829253e-01, -9.90398704e-01, -9.93251773e-01,\n",
       "                     -1.01160091e+00, -1.01734932e+00, -1.02961942e+00, -1.03798767e+00,\n",
       "                     -1.04145387e+00, -1.04596856e+00, -1.06784063e+00, -1.07451474e+00,\n",
       "                     -1.08026315e+00, -1.09861229e+00, -1.12601126e+00, -1.13943428e+00,\n",
       "                     -1.14513230e+00, -1.14862271e+00, -1.16017018e+00, -1.17007125e+00,\n",
       "                     -1.17468201e+00, -1.17557333e+00, -1.18149995e+00, -1.19310313e+00,\n",
       "                     -1.19625076e+00, -1.20397280e+00, -1.21841349e+00, -1.23395364e+00,\n",
       "                     -1.23676263e+00, -1.25276297e+00, -1.26851133e+00, -1.28785429e+00,\n",
       "                     -1.32175584e+00, -1.37082444e+00, -1.38629436e+00, -1.41098697e+00,\n",
       "                     -1.42711636e+00, -1.45225233e+00, -1.46082741e+00, -1.46633707e+00,\n",
       "                     -1.47181653e+00, -1.48160454e+00, -1.48538526e+00, -1.49165488e+00,\n",
       "                     -1.50407740e+00, -1.52242654e+00, -1.55059741e+00, -1.56563529e+00,\n",
       "                     -1.57121670e+00, -1.60943791e+00, -1.62830640e+00, -1.65292302e+00,\n",
       "                     -1.65822808e+00, -1.67764616e+00, -1.70474809e+00, -1.71008144e+00,\n",
       "                     -1.74046617e+00, -1.79175947e+00, -1.81117756e+00, -1.87180218e+00,\n",
       "                     -1.89711998e+00, -1.94591015e+00, -2.02814825e+00, -2.03688193e+00,\n",
       "                     -2.07944154e+00, -2.10413415e+00, -2.14006616e+00, -2.19722458e+00,\n",
       "                     -2.21297293e+00, -2.25129180e+00, -2.30258509e+00, -2.35137526e+00,\n",
       "                     -2.39789527e+00, -2.43361336e+00, -2.56494936e+00, -2.70805020e+00,\n",
       "                     -2.73200344e+00, -2.77258872e+00, -2.89037176e+00, -3.09104245e+00,\n",
       "                     -3.28653447e+00, -3.29583687e+00, -4.72738782e+00, -3.45387764e+01]), auc_score=0.5763426944835981, privacy_risk=0.5539418147480151, accuracy=0.5543316463233106, tpr_ind=0.6194140278188813, tnr_ind=0.48846960167714887, test_train_ratio=0.9881621781592187, dataset_size=[3379, 3339]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.01017964, 0.01167665, 0.01437126, 0.01796407,\n",
       "                     0.01856287, 0.01916168, 0.02155689, 0.02305389, 0.02365269,\n",
       "                     0.03353293, 0.03473054, 0.03862275, 0.04041916, 0.04491018,\n",
       "                     0.04700599, 0.05209581, 0.05269461, 0.05778443, 0.06197605,\n",
       "                     0.06287425, 0.06556886, 0.06916168, 0.09640719, 0.1008982 ,\n",
       "                     0.10508982, 0.12874251, 0.1508982 , 0.15748503, 0.17245509,\n",
       "                     0.17754491, 0.20868263, 0.21077844, 0.21736527, 0.23143713,\n",
       "                     0.24281437, 0.24520958, 0.25538922, 0.28053892, 0.28892216,\n",
       "                     0.29820359, 0.30688623, 0.31676647, 0.32185629, 0.3254491 ,\n",
       "                     0.33682635, 0.34700599, 0.35299401, 0.36077844, 0.37634731,\n",
       "                     0.41047904, 0.41706587, 0.41976048, 0.4260479 , 0.42934132,\n",
       "                     0.44311377, 0.44520958, 0.4760479 , 0.48353293, 0.52275449,\n",
       "                     0.53083832, 0.54131737, 0.54491018, 0.5488024 , 0.5502994 ,\n",
       "                     0.55419162, 0.55628743, 0.56946108, 0.58353293, 0.58562874,\n",
       "                     0.59131737, 0.59281437, 0.6008982 , 0.60628743, 0.6242515 ,\n",
       "                     0.64041916, 0.65209581, 0.67065868, 0.73263473, 0.73562874,\n",
       "                     0.75      , 0.75419162, 0.76047904, 0.76197605, 0.76526946,\n",
       "                     0.76886228, 0.7748503 , 0.78173653, 0.79820359, 0.80179641,\n",
       "                     0.80538922, 0.81317365, 0.83532934, 0.84191617, 0.85359281,\n",
       "                     0.85568862, 0.88173653, 0.89760479, 0.8991018 , 0.90239521,\n",
       "                     0.90389222, 0.90538922, 0.90838323, 0.91497006, 0.91526946,\n",
       "                     0.91796407, 0.92245509, 0.9245509 , 0.9248503 , 0.92934132,\n",
       "                     0.92964072, 0.93113772, 0.93413174, 0.93413174, 0.94191617,\n",
       "                     0.95      , 0.95179641, 0.95958084, 0.95958084, 0.96107784,\n",
       "                     0.96197605, 0.96347305, 0.96407186, 0.96467066, 0.96586826,\n",
       "                     0.96616766, 0.96796407, 0.96856287, 0.96946108, 1.        ]), tpr=array([0.        , 0.01865009, 0.02161042, 0.02516282, 0.02812315,\n",
       "                     0.02930728, 0.03374778, 0.03848431, 0.03996448, 0.04262877,\n",
       "                     0.05210184, 0.0553582 , 0.06009473, 0.06216696, 0.07104796,\n",
       "                     0.07371226, 0.08170515, 0.08377738, 0.09088218, 0.09591474,\n",
       "                     0.09739491, 0.10094731, 0.10657194, 0.13765542, 0.14268798,\n",
       "                     0.14535228, 0.17288336, 0.19567792, 0.20100651, 0.22024867,\n",
       "                     0.22616933, 0.25458851, 0.25577265, 0.26613381, 0.28271166,\n",
       "                     0.29721729, 0.30076969, 0.31320308, 0.3312611 , 0.3365897 ,\n",
       "                     0.34931912, 0.36056838, 0.37359384, 0.37625814, 0.38336294,\n",
       "                     0.39846063, 0.41030195, 0.41740675, 0.43191237, 0.44493783,\n",
       "                     0.47424512, 0.48105388, 0.48460628, 0.48875074, 0.49319124,\n",
       "                     0.5071048 , 0.50888099, 0.53226761, 0.53966844, 0.57785672,\n",
       "                     0.58703375, 0.59680284, 0.60301954, 0.6080521 , 0.61190053,\n",
       "                     0.6178212 , 0.62048549, 0.62995856, 0.64268798, 0.64446418,\n",
       "                     0.64772054, 0.65216104, 0.660746  , 0.6678508 , 0.68531676,\n",
       "                     0.70130255, 0.70840734, 0.73238603, 0.79899349, 0.80106572,\n",
       "                     0.81557134, 0.82060391, 0.82474837, 0.82711664, 0.82918887,\n",
       "                     0.83155713, 0.83984606, 0.84635879, 0.86204855, 0.86412078,\n",
       "                     0.86944938, 0.87537004, 0.89816459, 0.90408526, 0.91089402,\n",
       "                     0.91296625, 0.93428064, 0.94878626, 0.9499704 , 0.95233866,\n",
       "                     0.95441089, 0.95677916, 0.95973949, 0.96417999, 0.96477205,\n",
       "                     0.96743635, 0.97039668, 0.97217288, 0.97276495, 0.97661338,\n",
       "                     0.97809355, 0.97868561, 0.98046181, 0.98075784, 0.98431024,\n",
       "                     0.98845471, 0.98934281, 0.99259917, 0.99319124, 0.9937833 ,\n",
       "                     0.9946714 , 0.9955595 , 0.99615157, 0.9964476 , 0.9982238 ,\n",
       "                     0.99851983, 0.99940793, 0.99970397, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -9.53101798e-02, -1.54150680e-01,\n",
       "                     -1.82321557e-01, -2.23143551e-01, -2.87682072e-01, -3.18453731e-01,\n",
       "                     -3.36472237e-01, -3.67724780e-01, -4.05465108e-01, -4.35318071e-01,\n",
       "                     -4.46287103e-01, -4.51985124e-01, -4.70003629e-01, -5.10825624e-01,\n",
       "                     -5.32804530e-01, -5.38996501e-01, -5.59615788e-01, -5.67984038e-01,\n",
       "                     -5.87786665e-01, -6.06135804e-01, -6.66478933e-01, -6.93147181e-01,\n",
       "                     -7.22134717e-01, -7.47214402e-01, -7.55667538e-01, -7.68182367e-01,\n",
       "                     -7.73189888e-01, -7.74372620e-01, -7.88457360e-01, -7.96943974e-01,\n",
       "                     -8.10930216e-01, -8.14099791e-01, -8.34460714e-01, -8.44378150e-01,\n",
       "                     -8.47297860e-01, -8.67500568e-01, -8.79558723e-01, -8.93817876e-01,\n",
       "                     -9.02238978e-01, -9.16290732e-01, -9.34309237e-01, -9.38269639e-01,\n",
       "                     -9.49080555e-01, -9.50976290e-01, -9.55511445e-01, -9.65080896e-01,\n",
       "                     -9.67992106e-01, -9.77984301e-01, -9.88376459e-01, -9.91640169e-01,\n",
       "                     -1.01160091e+00, -1.02450432e+00, -1.02961942e+00, -1.04020153e+00,\n",
       "                     -1.04145387e+00, -1.05108715e+00, -1.07158362e+00, -1.08298697e+00,\n",
       "                     -1.09861229e+00, -1.10866262e+00, -1.11436065e+00, -1.11803037e+00,\n",
       "                     -1.12393010e+00, -1.13140211e+00, -1.13497993e+00, -1.13943428e+00,\n",
       "                     -1.15145477e+00, -1.15267951e+00, -1.15745279e+00, -1.16315081e+00,\n",
       "                     -1.17599895e+00, -1.17865500e+00, -1.17995793e+00, -1.19279950e+00,\n",
       "                     -1.20397280e+00, -1.21867895e+00, -1.21984615e+00, -1.23214368e+00,\n",
       "                     -1.23807842e+00, -1.24432410e+00, -1.25276297e+00, -1.28785429e+00,\n",
       "                     -1.31218639e+00, -1.35454566e+00, -1.35914337e+00, -1.38629436e+00,\n",
       "                     -1.39568410e+00, -1.42138568e+00, -1.42711636e+00, -1.44691898e+00,\n",
       "                     -1.45831295e+00, -1.45861502e+00, -1.46967597e+00, -1.51982575e+00,\n",
       "                     -1.54341681e+00, -1.55059741e+00, -1.60943791e+00, -1.65822808e+00,\n",
       "                     -1.66500776e+00, -1.68175857e+00, -1.68639895e+00, -1.69866905e+00,\n",
       "                     -1.70474809e+00, -1.73460106e+00, -1.74046617e+00, -1.79175947e+00,\n",
       "                     -1.87180218e+00, -1.88939794e+00, -1.97408103e+00, -2.07944154e+00,\n",
       "                     -2.14006616e+00, -2.19722458e+00, -2.23359222e+00, -2.25129180e+00,\n",
       "                     -2.26868354e+00, -2.30258509e+00, -2.48490665e+00, -2.52572864e+00,\n",
       "                     -2.61495978e+00, -2.63905733e+00, -2.70805020e+00, -2.83321334e+00,\n",
       "                     -2.86220088e+00, -2.94443898e+00, -2.96183072e+00, -3.13549422e+00,\n",
       "                     -3.25809654e+00, -3.45387764e+01]), auc_score=0.5523531090571965, privacy_risk=0.5355669655360682, accuracy=0.5349806490026794, tpr_ind=0.43191237418590883, tnr_ind=0.6392215568862275, test_train_ratio=0.9887507400828893, dataset_size=[3378, 3340]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.01044464, 0.01283199, 0.01283199, 0.01372725,\n",
       "                     0.01760668, 0.01850194, 0.01969561, 0.02655924, 0.02894658,\n",
       "                     0.0373023 , 0.0405849 , 0.04177857, 0.04804536, 0.05132796,\n",
       "                     0.05849   , 0.06386153, 0.07430618, 0.07818562, 0.0844524 ,\n",
       "                     0.10772904, 0.11429424, 0.11817368, 0.1217547 , 0.12414205,\n",
       "                     0.13697404, 0.13816771, 0.14324082, 0.15129812, 0.15279021,\n",
       "                     0.15666965, 0.16830797, 0.17308266, 0.27215756, 0.27902119,\n",
       "                     0.28528797, 0.28916741, 0.2954342 , 0.33452701, 0.34497165,\n",
       "                     0.35690839, 0.36974038, 0.37809609, 0.3977917 , 0.40704267,\n",
       "                     0.42017308, 0.42793196, 0.44046553, 0.44285288, 0.4497165 ,\n",
       "                     0.45926589, 0.46195166, 0.46404058, 0.48284094, 0.49179349,\n",
       "                     0.49895554, 0.51894957, 0.52461952, 0.55267084, 0.56460758,\n",
       "                     0.56789018, 0.57117278, 0.58102059, 0.59952253, 0.61265294,\n",
       "                     0.62757386, 0.63175172, 0.6460758 , 0.64697105, 0.65562519,\n",
       "                     0.66248881, 0.67382871, 0.68307968, 0.6965085 , 0.69889585,\n",
       "                     0.70516264, 0.71083259, 0.72217249, 0.72843927, 0.72933453,\n",
       "                     0.73291555, 0.73470606, 0.74604596, 0.7564906 , 0.79468815,\n",
       "                     0.8051328 , 0.81587586, 0.82273948, 0.84661295, 0.85347657,\n",
       "                     0.85675918, 0.85974336, 0.86869591, 0.87764846, 0.87884214,\n",
       "                     0.87914056, 0.88242316, 0.88749627, 0.91316025, 0.91674127,\n",
       "                     0.91853178, 0.92241122, 0.92599224, 0.92629066, 0.93136377,\n",
       "                     0.93584005, 0.93703372, 0.94658311, 0.9480752 , 0.94897046,\n",
       "                     0.94926887, 0.95792301, 0.96150403, 0.96150403, 0.96210087,\n",
       "                     0.96389138, 0.96896449, 0.96896449, 0.97224709, 0.97284393,\n",
       "                     0.97552969, 0.9773202 , 0.97970755, 0.98239332, 1.        ]), tpr=array([0.        , 0.02138402, 0.02435402, 0.02791803, 0.02999703,\n",
       "                     0.03445203, 0.03593704, 0.03861004, 0.04989605, 0.05375705,\n",
       "                     0.06474606, 0.06741907, 0.07157707, 0.08048708, 0.08434808,\n",
       "                     0.09028809, 0.09444609, 0.1039501 , 0.10959311, 0.11672112,\n",
       "                     0.14820315, 0.15354915, 0.15592516, 0.16038016, 0.16424116,\n",
       "                     0.17730918, 0.17909118, 0.18532819, 0.19275319, 0.1954262 ,\n",
       "                     0.2001782 , 0.21621622, 0.22364122, 0.32105732, 0.32848233,\n",
       "                     0.33382833, 0.33679834, 0.34214434, 0.38699139, 0.3970894 ,\n",
       "                     0.4048114 , 0.41639442, 0.42768043, 0.44579745, 0.45559846,\n",
       "                     0.47044847, 0.48203148, 0.49420849, 0.4974755 , 0.50519751,\n",
       "                     0.51559252, 0.51796852, 0.52064152, 0.54915355, 0.55568756,\n",
       "                     0.56370656, 0.58538759, 0.58954559, 0.62013662, 0.62934363,\n",
       "                     0.63231363, 0.63884764, 0.64894565, 0.66646867, 0.68102168,\n",
       "                     0.6952777 , 0.7015147 , 0.71369171, 0.71458271, 0.72527473,\n",
       "                     0.72765073, 0.73893674, 0.74695575, 0.76150876, 0.76447876,\n",
       "                     0.76982477, 0.77635878, 0.78318978, 0.79002079, 0.79150579,\n",
       "                     0.79358479, 0.7965548 , 0.8045738 , 0.81170181, 0.84763885,\n",
       "                     0.85595486, 0.86337986, 0.86664687, 0.88981289, 0.8990199 ,\n",
       "                     0.9034749 , 0.90555391, 0.91327591, 0.91980992, 0.92188892,\n",
       "                     0.92248292, 0.92723493, 0.93139293, 0.95604396, 0.95871696,\n",
       "                     0.96079596, 0.96317196, 0.96614197, 0.96673597, 0.96970597,\n",
       "                     0.97445797, 0.97623998, 0.97950698, 0.97980398, 0.98099198,\n",
       "                     0.98217998, 0.98693199, 0.98841699, 0.98871399, 0.98930799,\n",
       "                     0.98990199, 0.99168399, 0.99227799, 0.99465399, 0.995248  ,\n",
       "                     0.996139  , 0.99703   , 0.998218  , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.82321557e-01, -2.23143551e-01,\n",
       "                     -2.51314428e-01, -2.87682072e-01, -3.36472237e-01, -3.67724780e-01,\n",
       "                     -4.05465108e-01, -4.30782916e-01, -4.32133355e-01, -4.41832752e-01,\n",
       "                     -4.96436886e-01, -5.10825624e-01, -5.70544858e-01, -5.87786665e-01,\n",
       "                     -6.19039208e-01, -6.28608659e-01, -6.39079959e-01, -6.50587566e-01,\n",
       "                     -6.93147181e-01, -7.20546155e-01, -7.53771802e-01, -7.57685702e-01,\n",
       "                     -7.67255153e-01, -7.69687258e-01, -7.73189888e-01, -7.84118959e-01,\n",
       "                     -7.88457360e-01, -7.98507696e-01, -8.10930216e-01, -8.23200309e-01,\n",
       "                     -8.24175443e-01, -8.36349645e-01, -8.41567186e-01, -8.47297860e-01,\n",
       "                     -8.75468737e-01, -8.93817876e-01, -9.04298583e-01, -9.04456274e-01,\n",
       "                     -9.16290732e-01, -9.21405833e-01, -9.37124819e-01, -9.58030338e-01,\n",
       "                     -9.69400557e-01, -9.70778917e-01, -9.80829253e-01, -9.95958135e-01,\n",
       "                     -1.00330211e+00, -1.00458334e+00, -1.00900013e+00, -1.01160091e+00,\n",
       "                     -1.02165125e+00, -1.02663879e+00, -1.03609193e+00, -1.06087196e+00,\n",
       "                     -1.09861229e+00, -1.14513230e+00, -1.15523118e+00, -1.16113265e+00,\n",
       "                     -1.16315081e+00, -1.17163742e+00, -1.17411984e+00, -1.17473598e+00,\n",
       "                     -1.18335352e+00, -1.18504479e+00, -1.18958407e+00, -1.19908282e+00,\n",
       "                     -1.20397280e+00, -1.21227161e+00, -1.21639532e+00, -1.25276297e+00,\n",
       "                     -1.25804003e+00, -1.27866370e+00, -1.28093385e+00, -1.28401551e+00,\n",
       "                     -1.29098418e+00, -1.31885308e+00, -1.33041390e+00, -1.33500107e+00,\n",
       "                     -1.34992672e+00, -1.36097655e+00, -1.36760223e+00, -1.37582306e+00,\n",
       "                     -1.38629436e+00, -1.39518331e+00, -1.40609699e+00, -1.40876722e+00,\n",
       "                     -1.42711636e+00, -1.47866768e+00, -1.49664242e+00, -1.51982575e+00,\n",
       "                     -1.52102696e+00, -1.56291790e+00, -1.58045038e+00, -1.60943791e+00,\n",
       "                     -1.62186043e+00, -1.63760879e+00, -1.68595262e+00, -1.73460106e+00,\n",
       "                     -1.74296931e+00, -1.74919985e+00, -1.75785792e+00, -1.79175947e+00,\n",
       "                     -1.80828877e+00, -1.91875916e+00, -1.92181260e+00, -1.93283807e+00,\n",
       "                     -1.94591015e+00, -1.98100147e+00, -2.01490302e+00, -2.02320182e+00,\n",
       "                     -2.02814825e+00, -2.07944154e+00, -2.14006616e+00, -2.25129180e+00,\n",
       "                     -2.38262780e+00, -2.39789527e+00, -2.48490665e+00, -2.52572864e+00,\n",
       "                     -2.53897387e+00, -2.70805020e+00, -2.84781214e+00, -3.20545280e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5491317904030527, privacy_risk=0.5348814928045009, accuracy=0.535278356653766, tpr_ind=0.7015147015147015, tnr_ind=0.3682482840943002, test_train_ratio=0.9952479952479952, dataset_size=[3367, 3351]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.01061249, 0.01182535, 0.01364463, 0.01485749,\n",
       "                     0.0151607 , 0.01758642, 0.02001213, 0.02274106, 0.02456034,\n",
       "                     0.03244391, 0.03305033, 0.03486962, 0.03729533, 0.04244997,\n",
       "                     0.04972711, 0.05700424, 0.05791389, 0.06397817, 0.06519102,\n",
       "                     0.07186173, 0.07368102, 0.0970285 , 0.10400243, 0.12037599,\n",
       "                     0.13402062, 0.14554275, 0.14857489, 0.15039418, 0.1658581 ,\n",
       "                     0.16858702, 0.17283202, 0.21194663, 0.22559127, 0.23165555,\n",
       "                     0.23771983, 0.2413584 , 0.2565191 , 0.25894482, 0.2628866 ,\n",
       "                     0.26622195, 0.27228623, 0.29411765, 0.33292905, 0.33565797,\n",
       "                     0.35385082, 0.35839903, 0.36112796, 0.36961795, 0.41904184,\n",
       "                     0.45451789, 0.4569436 , 0.46604002, 0.47028502, 0.48574894,\n",
       "                     0.49090358, 0.50727714, 0.51030928, 0.53032141, 0.53608247,\n",
       "                     0.53972104, 0.54821104, 0.55003032, 0.57064888, 0.57822923,\n",
       "                     0.58126137, 0.59278351, 0.59642207, 0.60309278, 0.6055185 ,\n",
       "                     0.60612492, 0.61673742, 0.61946634, 0.62128563, 0.62886598,\n",
       "                     0.62886598, 0.63341419, 0.63432383, 0.63765919, 0.6443299 ,\n",
       "                     0.64887811, 0.67131595, 0.69739236, 0.71315949, 0.73286841,\n",
       "                     0.74257126, 0.74742268, 0.74893875, 0.75136446, 0.7628866 ,\n",
       "                     0.76713159, 0.77986659, 0.78138266, 0.79108551, 0.79442086,\n",
       "                     0.80109157, 0.80988478, 0.81322013, 0.82019406, 0.82261977,\n",
       "                     0.83201941, 0.84505761, 0.86931474, 0.87204366, 0.87204366,\n",
       "                     0.87325652, 0.88204973, 0.8944815 , 0.905094  , 0.91055185,\n",
       "                     0.91449363, 0.91570649, 0.91964827, 0.92571255, 0.93268648,\n",
       "                     0.93875076, 0.9417829 , 0.9439054 , 0.94420861, 0.94693754,\n",
       "                     0.94724075, 0.95239539, 0.95239539, 0.95664039, 0.95967253,\n",
       "                     0.96058217, 0.96361431, 0.96513038, 0.96573681, 0.96694967,\n",
       "                     0.96816252, 0.96967859, 0.96967859, 0.97119466, 0.97483323,\n",
       "                     0.97907823, 0.97998787, 1.        ]), tpr=array([0.        , 0.01959064, 0.02251462, 0.0251462 , 0.02690058,\n",
       "                     0.02982456, 0.03684211, 0.03976608, 0.04327485, 0.04532164,\n",
       "                     0.05292398, 0.05497076, 0.05643275, 0.05877193, 0.06608187,\n",
       "                     0.0748538 , 0.08421053, 0.08567251, 0.09093567, 0.09327485,\n",
       "                     0.10263158, 0.10643275, 0.13099415, 0.13918129, 0.16052632,\n",
       "                     0.17251462, 0.18157895, 0.18450292, 0.18684211, 0.20263158,\n",
       "                     0.20701754, 0.21169591, 0.25292398, 0.26900585, 0.27602339,\n",
       "                     0.28128655, 0.2871345 , 0.30116959, 0.30380117, 0.30701754,\n",
       "                     0.31140351, 0.31695906, 0.33859649, 0.37748538, 0.38157895,\n",
       "                     0.40087719, 0.40438596, 0.40730994, 0.41403509, 0.45818713,\n",
       "                     0.51023392, 0.5119883 , 0.52222222, 0.52807018, 0.54473684,\n",
       "                     0.55146199, 0.57923977, 0.58157895, 0.59590643, 0.60380117,\n",
       "                     0.60964912, 0.61959064, 0.62134503, 0.64181287, 0.65146199,\n",
       "                     0.65497076, 0.66666667, 0.67134503, 0.68070175, 0.68362573,\n",
       "                     0.68625731, 0.69649123, 0.7002924 , 0.70204678, 0.71169591,\n",
       "                     0.7128655 , 0.72046784, 0.72251462, 0.72426901, 0.73011696,\n",
       "                     0.7374269 , 0.75730994, 0.78421053, 0.79502924, 0.81666667,\n",
       "                     0.82368421, 0.82690058, 0.82836257, 0.82923977, 0.84093567,\n",
       "                     0.84298246, 0.85263158, 0.85409357, 0.86432749, 0.86666667,\n",
       "                     0.86988304, 0.87865497, 0.88040936, 0.88684211, 0.88830409,\n",
       "                     0.89619883, 0.90409357, 0.92397661, 0.92573099, 0.92777778,\n",
       "                     0.92865497, 0.93391813, 0.94327485, 0.95380117, 0.95701754,\n",
       "                     0.95964912, 0.96081871, 0.9628655 , 0.96549708, 0.97222222,\n",
       "                     0.97660819, 0.97865497, 0.98011696, 0.98128655, 0.98274854,\n",
       "                     0.98304094, 0.98538012, 0.9871345 , 0.98947368, 0.99122807,\n",
       "                     0.99210526, 0.99327485, 0.99415205, 0.99444444, 0.99532164,\n",
       "                     0.99590643, 0.99619883, 0.99678363, 0.99736842, 0.99912281,\n",
       "                     0.9997076 , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -9.53101798e-02, -1.05360516e-01,\n",
       "                     -1.54150680e-01, -1.82321557e-01, -2.87682072e-01, -3.36472237e-01,\n",
       "                     -3.48306694e-01, -3.56674944e-01, -4.05465108e-01, -4.51985124e-01,\n",
       "                     -4.70003629e-01, -4.85507816e-01, -4.94696242e-01, -5.10825624e-01,\n",
       "                     -5.59615788e-01, -5.87786665e-01, -6.06135804e-01, -6.28608659e-01,\n",
       "                     -6.45137961e-01, -6.53926467e-01, -6.56779536e-01, -6.75128675e-01,\n",
       "                     -6.93147181e-01, -7.05268541e-01, -7.09147522e-01, -7.41937345e-01,\n",
       "                     -7.53771802e-01, -7.81700578e-01, -7.88457360e-01, -8.10930216e-01,\n",
       "                     -8.31983625e-01, -8.36853901e-01, -8.47297860e-01, -8.70828358e-01,\n",
       "                     -8.75468737e-01, -8.90972924e-01, -8.93817876e-01, -8.97941593e-01,\n",
       "                     -9.02867712e-01, -9.05708623e-01, -9.16290732e-01, -9.32696767e-01,\n",
       "                     -9.44461609e-01, -9.46143695e-01, -9.49080555e-01, -9.55511445e-01,\n",
       "                     -9.58850346e-01, -9.66656444e-01, -9.70949144e-01, -9.80829253e-01,\n",
       "                     -9.87946721e-01, -9.93251773e-01, -1.00037385e+00, -1.00764051e+00,\n",
       "                     -1.01064352e+00, -1.01160091e+00, -1.01345448e+00, -1.02165125e+00,\n",
       "                     -1.02961942e+00, -1.03798767e+00, -1.04145387e+00, -1.04982212e+00,\n",
       "                     -1.06784063e+00, -1.07044141e+00, -1.09024404e+00, -1.09861229e+00,\n",
       "                     -1.12938395e+00, -1.13140211e+00, -1.13497993e+00, -1.14513230e+00,\n",
       "                     -1.14862271e+00, -1.15267951e+00, -1.15745279e+00, -1.17865500e+00,\n",
       "                     -1.18455472e+00, -1.18958407e+00, -1.20397280e+00, -1.20896035e+00,\n",
       "                     -1.21194097e+00, -1.21421430e+00, -1.21800434e+00, -1.24111235e+00,\n",
       "                     -1.24889449e+00, -1.25276297e+00, -1.26566637e+00, -1.28093385e+00,\n",
       "                     -1.29928298e+00, -1.30833282e+00, -1.31218639e+00, -1.32377400e+00,\n",
       "                     -1.33500107e+00, -1.38629436e+00, -1.41706602e+00, -1.45225233e+00,\n",
       "                     -1.45861502e+00, -1.46633707e+00, -1.47330574e+00, -1.48160454e+00,\n",
       "                     -1.49165488e+00, -1.49995368e+00, -1.58863478e+00, -1.60943791e+00,\n",
       "                     -1.63760879e+00, -1.67397643e+00, -1.68433922e+00, -1.69905007e+00,\n",
       "                     -1.69968479e+00, -1.71297859e+00, -1.71479843e+00, -1.74919985e+00,\n",
       "                     -1.79175947e+00, -1.81010861e+00, -1.85493837e+00, -1.92667879e+00,\n",
       "                     -1.94591015e+00, -2.02814825e+00, -2.04769284e+00, -2.05412373e+00,\n",
       "                     -2.07944154e+00, -2.09494573e+00, -2.12026354e+00, -2.18323834e+00,\n",
       "                     -2.19722458e+00, -2.23359222e+00, -2.30258509e+00, -2.33537492e+00,\n",
       "                     -2.39789527e+00, -2.48490665e+00, -2.52572864e+00, -2.63905733e+00,\n",
       "                     -2.67414865e+00, -2.91777073e+00, -3.09104245e+00, -3.79548919e+00,\n",
       "                     -3.89182030e+00, -3.45387764e+01]), auc_score=0.5526427056624784, privacy_risk=0.5442743963202934, accuracy=0.5477820779994046, tpr_ind=0.7374269005847953, tnr_ind=0.35112189205579136, test_train_ratio=0.9643274853801169, dataset_size=[3420, 3298]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.01008304, 0.01097272, 0.0118624 , 0.01453144,\n",
       "                     0.01690391, 0.02135231, 0.02402135, 0.02669039, 0.02995255,\n",
       "                     0.03351127, 0.03499407, 0.03736655, 0.03884935, 0.04033215,\n",
       "                     0.04270463, 0.04744958, 0.05308422, 0.05753262, 0.05901542,\n",
       "                     0.07087782, 0.08392645, 0.08718861, 0.09104389, 0.10705813,\n",
       "                     0.11209964, 0.1183274 , 0.13285884, 0.17052195, 0.17259786,\n",
       "                     0.18890866, 0.19395018, 0.20225386, 0.20462633, 0.20581257,\n",
       "                     0.21174377, 0.21648873, 0.22212337, 0.25948992, 0.26957295,\n",
       "                     0.28558719, 0.29507711, 0.31346382, 0.32740214, 0.35557533,\n",
       "                     0.36209964, 0.36328588, 0.37603796, 0.386121  , 0.44988138,\n",
       "                     0.45136418, 0.45521945, 0.46293001, 0.46826809, 0.46945433,\n",
       "                     0.48576512, 0.51008304, 0.5118624 , 0.52075919, 0.54092527,\n",
       "                     0.54448399, 0.54863582, 0.55516014, 0.56049822, 0.5688019 ,\n",
       "                     0.58451957, 0.59104389, 0.59964413, 0.60438909, 0.62544484,\n",
       "                     0.62900356, 0.63374852, 0.63641756, 0.65065243, 0.65628707,\n",
       "                     0.65895611, 0.66666667, 0.66844603, 0.68030842, 0.69098458,\n",
       "                     0.70996441, 0.71174377, 0.71708185, 0.72064057, 0.73487544,\n",
       "                     0.77105575, 0.77253855, 0.78262159, 0.79863582, 0.80575326,\n",
       "                     0.82502966, 0.82680902, 0.84223013, 0.84816133, 0.85616845,\n",
       "                     0.88256228, 0.88701068, 0.89234875, 0.89353499, 0.89768683,\n",
       "                     0.90124555, 0.90569395, 0.90717675, 0.93979834, 0.94276394,\n",
       "                     0.94810202, 0.95077106, 0.95136418, 0.95166074, 0.95225386,\n",
       "                     0.95403321, 0.95462633, 0.95492289, 0.95492289, 0.95610913,\n",
       "                     0.95818505, 0.96144721, 0.96233689, 0.96263345, 0.96441281,\n",
       "                     0.96678529, 0.96915777, 0.97034401, 0.97271649, 0.97330961,\n",
       "                     1.        ]), tpr=array([0.        , 0.02121937, 0.02331142, 0.0251046 , 0.02749552,\n",
       "                     0.02958757, 0.03407053, 0.0385535 , 0.0427376 , 0.04632397,\n",
       "                     0.04901375, 0.0511058 , 0.05260012, 0.05648536, 0.06096832,\n",
       "                     0.06485356, 0.0720263 , 0.07650926, 0.08009564, 0.08158996,\n",
       "                     0.09742977, 0.1105798 , 0.11356844, 0.11715481, 0.13628213,\n",
       "                     0.14285714, 0.15451285, 0.17603108, 0.21129707, 0.21338912,\n",
       "                     0.2286312 , 0.23341303, 0.2453676 , 0.25014943, 0.25194262,\n",
       "                     0.25732218, 0.26031082, 0.26658697, 0.3099223 , 0.32038255,\n",
       "                     0.339211  , 0.34817693, 0.36371787, 0.37597131, 0.39539749,\n",
       "                     0.40526001, 0.40675433, 0.42319187, 0.43574417, 0.50089659,\n",
       "                     0.50298864, 0.5083682 , 0.51285117, 0.51882845, 0.52032277,\n",
       "                     0.54004782, 0.56754334, 0.56963539, 0.57740586, 0.59593545,\n",
       "                     0.59892409, 0.60520024, 0.60908548, 0.61595935, 0.62522415,\n",
       "                     0.64076509, 0.64793784, 0.65570831, 0.66108787, 0.68350269,\n",
       "                     0.6867902 , 0.69187089, 0.69485953, 0.70531978, 0.71099821,\n",
       "                     0.71548117, 0.72653915, 0.72952779, 0.74148237, 0.75164375,\n",
       "                     0.76509265, 0.76688583, 0.77256426, 0.77615063, 0.78959952,\n",
       "                     0.81888822, 0.82277346, 0.83203825, 0.85355649, 0.8601315 ,\n",
       "                     0.87836222, 0.87985655, 0.89001793, 0.89629408, 0.90346683,\n",
       "                     0.92408846, 0.92677824, 0.93126121, 0.93365212, 0.93693963,\n",
       "                     0.93992827, 0.94231919, 0.94321578, 0.97429767, 0.97638972,\n",
       "                     0.97997609, 0.98296473, 0.98386133, 0.98535565, 0.98684997,\n",
       "                     0.98924088, 0.98983861, 0.99073521, 0.99103407, 0.99222953,\n",
       "                     0.99252839, 0.99402271, 0.99432158, 0.99551704, 0.99611476,\n",
       "                     0.99731022, 0.99820681, 0.99880454, 0.99940227, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -1.54150680e-01,\n",
       "                     -2.23143551e-01, -2.51314428e-01, -2.87682072e-01, -3.36472237e-01,\n",
       "                     -3.56674944e-01, -4.05465108e-01, -4.41832752e-01, -4.51985124e-01,\n",
       "                     -4.70003629e-01, -4.79573080e-01, -5.10825624e-01, -5.26093096e-01,\n",
       "                     -5.35518236e-01, -5.50046337e-01, -5.59615788e-01, -5.87786665e-01,\n",
       "                     -6.04419065e-01, -6.10259521e-01, -6.41853886e-01, -6.50587566e-01,\n",
       "                     -6.93147181e-01, -7.15620036e-01, -7.30887509e-01, -7.33969175e-01,\n",
       "                     -7.54768315e-01, -7.62140052e-01, -7.68654733e-01, -8.10930216e-01,\n",
       "                     -8.32909123e-01, -8.38329190e-01, -8.47297860e-01, -8.70828358e-01,\n",
       "                     -8.75468737e-01, -8.87303195e-01, -8.95384047e-01, -9.10560057e-01,\n",
       "                     -9.13111079e-01, -9.16290732e-01, -9.31558204e-01, -9.40388283e-01,\n",
       "                     -9.43606543e-01, -9.46143695e-01, -9.55511445e-01, -9.62480114e-01,\n",
       "                     -9.80829253e-01, -9.88824727e-01, -9.98528830e-01, -1.00144854e+00,\n",
       "                     -1.00552187e+00, -1.01160091e+00, -1.02961942e+00, -1.03070108e+00,\n",
       "                     -1.04273183e+00, -1.04982212e+00, -1.05939158e+00, -1.06025142e+00,\n",
       "                     -1.06471074e+00, -1.06635143e+00, -1.07263680e+00, -1.08401349e+00,\n",
       "                     -1.09861229e+00, -1.12393010e+00, -1.13943428e+00, -1.16074407e+00,\n",
       "                     -1.17007125e+00, -1.18377010e+00, -1.18562367e+00, -1.19213835e+00,\n",
       "                     -1.19392247e+00, -1.19824213e+00, -1.19869575e+00, -1.20397280e+00,\n",
       "                     -1.21739582e+00, -1.22377543e+00, -1.24559448e+00, -1.25276297e+00,\n",
       "                     -1.28093385e+00, -1.29928298e+00, -1.31824090e+00, -1.32175584e+00,\n",
       "                     -1.35239281e+00, -1.35783190e+00, -1.38629436e+00, -1.41019988e+00,\n",
       "                     -1.42377745e+00, -1.46283444e+00, -1.46885596e+00, -1.48160454e+00,\n",
       "                     -1.49091931e+00, -1.51982575e+00, -1.55814462e+00, -1.55890710e+00,\n",
       "                     -1.56397554e+00, -1.56861592e+00, -1.58412010e+00, -1.60943791e+00,\n",
       "                     -1.64865863e+00, -1.65822808e+00, -1.67397643e+00, -1.67457721e+00,\n",
       "                     -1.69167601e+00, -1.70474809e+00, -1.72276660e+00, -1.73460106e+00,\n",
       "                     -1.79175947e+00, -1.82454929e+00, -1.85238409e+00, -1.87180218e+00,\n",
       "                     -1.89711998e+00, -1.94591015e+00, -2.01490302e+00, -2.07944154e+00,\n",
       "                     -2.17475172e+00, -2.19722458e+00, -2.22462355e+00, -2.30258509e+00,\n",
       "                     -2.39789527e+00, -2.56494936e+00, -2.89037176e+00, -3.02042489e+00,\n",
       "                     -3.21887582e+00, -3.45387764e+01]), auc_score=0.5449788579199752, privacy_risk=0.5305869723520373, accuracy=0.5297707651086633, tpr_ind=0.7414823670053795, tnr_ind=0.31969157769869516, test_train_ratio=1.0077704722056187, dataset_size=[3346, 3372]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00702165, 0.01023991, 0.01111761, 0.01170275,\n",
       "                     0.01433587, 0.02135752, 0.02135752, 0.02486834, 0.02662376,\n",
       "                     0.0280866 , 0.02954944, 0.03393798, 0.03481568, 0.03832651,\n",
       "                     0.04125219, 0.04476302, 0.04505559, 0.04827384, 0.0561732 ,\n",
       "                     0.05851375, 0.06963136, 0.07314219, 0.07987127, 0.08484494,\n",
       "                     0.0983031 , 0.11761264, 0.1348742 , 0.13721475, 0.14657695,\n",
       "                     0.15067291, 0.15476887, 0.17495611, 0.17758923, 0.18578116,\n",
       "                     0.19163253, 0.19777648, 0.20157987, 0.20304272, 0.20567583,\n",
       "                     0.2144529 , 0.22440023, 0.23610298, 0.23844353, 0.24488005,\n",
       "                     0.25511995, 0.28145114, 0.28759508, 0.32621416, 0.33265067,\n",
       "                     0.34464599, 0.34727911, 0.35166764, 0.3651258 , 0.3689292 ,\n",
       "                     0.37302516, 0.38238736, 0.38414277, 0.38677589, 0.39028672,\n",
       "                     0.39847864, 0.45523698, 0.45699239, 0.45991808, 0.46401404,\n",
       "                     0.47483909, 0.47981276, 0.4859567 , 0.49619661, 0.50146284,\n",
       "                     0.51199532, 0.52691633, 0.53071972, 0.53978935, 0.54300761,\n",
       "                     0.54827384, 0.55968403, 0.56816852, 0.5702165 , 0.61176126,\n",
       "                     0.61205383, 0.63897016, 0.64628438, 0.65593915, 0.6957285 ,\n",
       "                     0.69982446, 0.70479813, 0.70772382, 0.71503803, 0.72176712,\n",
       "                     0.7246928 , 0.72820363, 0.73259216, 0.77911059, 0.77969573,\n",
       "                     0.79607958, 0.82445875, 0.82884728, 0.83294324, 0.83323581,\n",
       "                     0.8370392 , 0.8417203 , 0.84318315, 0.84903452, 0.85254535,\n",
       "                     0.86600351, 0.89087185, 0.89116442, 0.89613809, 0.90228204,\n",
       "                     0.90842598, 0.91369222, 0.91456992, 0.91925102, 0.92598011,\n",
       "                     0.9297835 , 0.93270919, 0.93300176, 0.93973084, 0.94324166,\n",
       "                     0.9485079 , 0.95582212, 0.96021065, 0.96225863, 0.96313634,\n",
       "                     0.9719134 , 1.        ]), tpr=array([0.        , 0.01727273, 0.02363636, 0.02515152, 0.02636364,\n",
       "                     0.03272727, 0.04363636, 0.04515152, 0.04727273, 0.05151515,\n",
       "                     0.05545455, 0.05818182, 0.06424242, 0.06666667, 0.07      ,\n",
       "                     0.07454545, 0.07878788, 0.08      , 0.08606061, 0.10151515,\n",
       "                     0.10515152, 0.11636364, 0.12090909, 0.12636364, 0.13090909,\n",
       "                     0.14787879, 0.16878788, 0.1830303 , 0.18636364, 0.19242424,\n",
       "                     0.1969697 , 0.20090909, 0.22545455, 0.22727273, 0.23757576,\n",
       "                     0.24666667, 0.25424242, 0.25909091, 0.26212121, 0.26575758,\n",
       "                     0.27333333, 0.28363636, 0.29060606, 0.29393939, 0.29969697,\n",
       "                     0.31242424, 0.33666667, 0.34212121, 0.38757576, 0.39393939,\n",
       "                     0.40333333, 0.40575758, 0.40909091, 0.42181818, 0.4269697 ,\n",
       "                     0.43333333, 0.4430303 , 0.44606061, 0.44818182, 0.45060606,\n",
       "                     0.45727273, 0.52363636, 0.52666667, 0.53      , 0.53363636,\n",
       "                     0.54060606, 0.54606061, 0.55151515, 0.5630303 , 0.56909091,\n",
       "                     0.57727273, 0.58969697, 0.59424242, 0.60242424, 0.6069697 ,\n",
       "                     0.61212121, 0.62212121, 0.62727273, 0.63060606, 0.67636364,\n",
       "                     0.67757576, 0.70636364, 0.71272727, 0.71787879, 0.75151515,\n",
       "                     0.75363636, 0.75878788, 0.76151515, 0.77272727, 0.77727273,\n",
       "                     0.77848485, 0.78060606, 0.78575758, 0.83606061, 0.83757576,\n",
       "                     0.85848485, 0.88454545, 0.88878788, 0.89727273, 0.89848485,\n",
       "                     0.90333333, 0.90545455, 0.90727273, 0.91272727, 0.91454545,\n",
       "                     0.92181818, 0.94272727, 0.94333333, 0.94606061, 0.95606061,\n",
       "                     0.96090909, 0.96606061, 0.96727273, 0.96969697, 0.97333333,\n",
       "                     0.97575758, 0.9769697 , 0.97757576, 0.97969697, 0.98242424,\n",
       "                     0.98393939, 0.98757576, 0.99      , 0.99090909, 0.99121212,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -1.82321557e-01,\n",
       "                     -2.23143551e-01, -2.51314428e-01, -2.87682072e-01, -3.36472237e-01,\n",
       "                     -3.56674944e-01, -4.05465108e-01, -4.30782916e-01, -4.41832752e-01,\n",
       "                     -4.70003629e-01, -4.85507816e-01, -4.92476485e-01, -5.10825624e-01,\n",
       "                     -5.38996501e-01, -5.59615788e-01, -5.87786665e-01, -6.00773860e-01,\n",
       "                     -6.06135804e-01, -6.08589793e-01, -6.24154309e-01, -6.35988767e-01,\n",
       "                     -6.59245629e-01, -6.75128675e-01, -6.93147181e-01, -7.14200590e-01,\n",
       "                     -7.37598943e-01, -7.41937345e-01, -7.57685702e-01, -7.67255153e-01,\n",
       "                     -7.70336819e-01, -7.73189888e-01, -7.77704569e-01, -7.88457360e-01,\n",
       "                     -8.06475866e-01, -8.10930216e-01, -8.32909123e-01, -8.47297860e-01,\n",
       "                     -8.75468737e-01, -8.80358723e-01, -8.89857475e-01, -8.97941593e-01,\n",
       "                     -9.05708623e-01, -9.16290732e-01, -9.31179344e-01, -9.38269639e-01,\n",
       "                     -9.42608040e-01, -9.44461609e-01, -9.48039430e-01, -9.65080896e-01,\n",
       "                     -9.69400557e-01, -9.71860583e-01, -9.73449146e-01, -9.80829253e-01,\n",
       "                     -9.88611393e-01, -9.93251773e-01, -9.98528830e-01, -1.01160091e+00,\n",
       "                     -1.01983141e+00, -1.02766055e+00, -1.02961942e+00, -1.03609193e+00,\n",
       "                     -1.04145387e+00, -1.05416053e+00, -1.06087196e+00, -1.07992016e+00,\n",
       "                     -1.08091271e+00, -1.09861229e+00, -1.11088238e+00, -1.13845820e+00,\n",
       "                     -1.14209740e+00, -1.14681439e+00, -1.16315081e+00, -1.17411984e+00,\n",
       "                     -1.20397280e+00, -1.20983792e+00, -1.21302264e+00, -1.21516818e+00,\n",
       "                     -1.25276297e+00, -1.25426560e+00, -1.25954266e+00, -1.26113122e+00,\n",
       "                     -1.26173164e+00, -1.27296568e+00, -1.29392104e+00, -1.29928298e+00,\n",
       "                     -1.31633577e+00, -1.31730149e+00, -1.32175584e+00, -1.34992672e+00,\n",
       "                     -1.37147928e+00, -1.37873575e+00, -1.38629436e+00, -1.39710528e+00,\n",
       "                     -1.42618569e+00, -1.45528723e+00, -1.46358604e+00, -1.50407740e+00,\n",
       "                     -1.51787072e+00, -1.51982575e+00, -1.54044504e+00, -1.56397554e+00,\n",
       "                     -1.57553636e+00, -1.60943791e+00, -1.68209556e+00, -1.70474809e+00,\n",
       "                     -1.71479843e+00, -1.73993440e+00, -1.74919985e+00, -1.78190717e+00,\n",
       "                     -1.79175947e+00, -1.85238409e+00, -1.89711998e+00, -1.90954250e+00,\n",
       "                     -1.94591015e+00, -2.01490302e+00, -2.07944154e+00, -2.12026354e+00,\n",
       "                     -2.24070969e+00, -2.26868354e+00, -2.30258509e+00, -2.39789527e+00,\n",
       "                     -2.48490665e+00, -2.88267941e+00, -3.45387764e+01]), auc_score=0.554026898593897, privacy_risk=0.535040959625512, accuracy=0.5351295028282227, tpr_ind=0.53, tnr_ind=0.540081919251024, test_train_ratio=1.0357575757575757, dataset_size=[3300, 3418])],\n",
       "             'subpopulation_0.0_label_0.0_mia_auc': [0.5350563740589531,\n",
       "              0.5293245867503502,\n",
       "              0.5394664353757487,\n",
       "              0.5242016960307475,\n",
       "              0.5208593064733057,\n",
       "              0.5239242828942444,\n",
       "              0.5160329468165155,\n",
       "              0.528434933042737,\n",
       "              0.5239683167383893,\n",
       "              0.5173268693421595,\n",
       "              0.5190967156730533,\n",
       "              0.5332635247718482,\n",
       "              0.51998989221847,\n",
       "              0.5300960824097286,\n",
       "              0.5310856109459053,\n",
       "              0.5249683937244153,\n",
       "              0.5251926319229212,\n",
       "              0.5250587475952649,\n",
       "              0.528356784671806,\n",
       "              0.5210349712087512],\n",
       "             'subpopulation_0.0_label_0.0_mia_privacy_risk': [0.5248469787305134,\n",
       "              0.5246325927272338,\n",
       "              0.5327431438674117,\n",
       "              0.5176917051765599,\n",
       "              0.5167262566098891,\n",
       "              0.5207229596800924,\n",
       "              0.5141701115044887,\n",
       "              0.5234614686869705,\n",
       "              0.5220046318154464,\n",
       "              0.5136248845283289,\n",
       "              0.5159896579579479,\n",
       "              0.5276866501922806,\n",
       "              0.5177990932234008,\n",
       "              0.5314223351539735,\n",
       "              0.5265895953757225,\n",
       "              0.5223123051788838,\n",
       "              0.5262766615745882,\n",
       "              0.518962157149034,\n",
       "              0.5258935922247052,\n",
       "              0.52024777315597],\n",
       "             'subpopulation_0.0_label_0.0_mia_ppv': [0.5420560747663552,\n",
       "              0.535759096612296,\n",
       "              0.5413726747915331,\n",
       "              0.5478142076502731,\n",
       "              0.5145257262863143,\n",
       "              0.534466477809254,\n",
       "              0.5151785714285714,\n",
       "              0.5193675889328063,\n",
       "              0.5257847533632287,\n",
       "              0.5238817285822592,\n",
       "              0.5091012514220705,\n",
       "              0.5278833967046895,\n",
       "              0.5222469410456062,\n",
       "              0.5339313572542902,\n",
       "              0.5300462249614792,\n",
       "              0.5397489539748954,\n",
       "              0.5175141242937853,\n",
       "              0.5233399079552926,\n",
       "              0.5268915223336372,\n",
       "              0.5550847457627119],\n",
       "             'subpopulation_0.0_label_0.0_mia_attacker_advantage': [0.04969395746102678,\n",
       "              0.049265185454467675,\n",
       "              0.06548628773482346,\n",
       "              0.03538341035311998,\n",
       "              0.03345251321977827,\n",
       "              0.04144591936018471,\n",
       "              0.028340223008977317,\n",
       "              0.04692293737394093,\n",
       "              0.04400926363089286,\n",
       "              0.02724976905665777,\n",
       "              0.03197931591589598,\n",
       "              0.05537330038456101,\n",
       "              0.03559818644680157,\n",
       "              0.06284467030794694,\n",
       "              0.05317919075144506,\n",
       "              0.04462461035776771,\n",
       "              0.05255332314917649,\n",
       "              0.037924314298068085,\n",
       "              0.05178718444941033,\n",
       "              0.04049554631193997],\n",
       "             'subpopulation_0.0_label_0.0_mia_result': [MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.11165468, 0.11309353, 0.1171223 , 0.11827338,\n",
       "                     0.12489209, 0.12517986, 0.12690647, 0.13064748, 0.14676259,\n",
       "                     0.15971223, 0.17122302, 0.17294964, 0.19338129, 0.19827338,\n",
       "                     0.21553957, 0.22964029, 0.2342446 , 0.2371223 , 0.26733813,\n",
       "                     0.27884892, 0.28230216, 0.2894964 , 0.29381295, 0.30906475,\n",
       "                     0.3171223 , 0.35913669, 0.36920863, 0.37208633, 0.38273381,\n",
       "                     0.3847482 , 0.41553957, 0.42446043, 0.43366906, 0.46359712,\n",
       "                     0.48143885, 0.49553957, 0.50791367, 0.52028777, 0.53122302,\n",
       "                     0.54043165, 0.56892086, 0.57266187, 0.58273381, 0.58647482,\n",
       "                     0.59827338, 0.61669065, 0.62992806, 0.63395683, 0.63539568,\n",
       "                     0.64086331, 0.64517986, 0.65352518, 0.67683453, 0.70100719,\n",
       "                     0.71683453, 0.73093525, 0.73496403, 0.73841727, 0.73956835,\n",
       "                     0.73985612, 0.76086331, 0.77266187, 0.78100719, 0.78733813,\n",
       "                     0.79107914, 0.79251799, 0.79453237, 0.80115108, 0.81064748,\n",
       "                     0.81122302, 0.81496403, 0.81755396, 0.81870504, 0.83769784,\n",
       "                     0.84230216, 0.85496403, 0.87165468, 0.87884892, 0.89266187,\n",
       "                     0.89669065, 0.90129496, 0.90877698, 0.91223022, 0.91251799,\n",
       "                     0.92143885, 0.93352518, 0.93928058, 0.94129496, 0.95280576,\n",
       "                     0.95338129, 0.95338129, 0.95741007, 0.96      , 0.96690647,\n",
       "                     0.9694964 , 0.97179856, 0.9752518 , 0.97669065, 0.98791367,\n",
       "                     0.98964029, 0.99165468, 0.99194245, 1.        ]), tpr=array([0.        , 0.12917271, 0.1317852 , 0.13846154, 0.14049347,\n",
       "                     0.14687954, 0.14746009, 0.15152395, 0.15471698, 0.17503628,\n",
       "                     0.18519594, 0.19970972, 0.20319303, 0.22119013, 0.23512337,\n",
       "                     0.25428157, 0.26444122, 0.2682148 , 0.27111756, 0.30043541,\n",
       "                     0.31436865, 0.31814224, 0.32656023, 0.3317852 , 0.34658926,\n",
       "                     0.35355588, 0.39912917, 0.41219158, 0.41683599, 0.42931785,\n",
       "                     0.43309144, 0.46008708, 0.47256894, 0.48243832, 0.51030479,\n",
       "                     0.52917271, 0.5425254 , 0.55297533, 0.56371553, 0.57503628,\n",
       "                     0.58374456, 0.60870827, 0.61625544, 0.62786647, 0.63134978,\n",
       "                     0.64238026, 0.66473149, 0.67576197, 0.68098694, 0.68417997,\n",
       "                     0.68795356, 0.69404935, 0.70072569, 0.72133527, 0.74775036,\n",
       "                     0.76023222, 0.77619739, 0.7820029 , 0.78722787, 0.7892598 ,\n",
       "                     0.78955007, 0.80609579, 0.81741655, 0.82612482, 0.83105951,\n",
       "                     0.83454282, 0.83599419, 0.8383164 , 0.84267054, 0.85195936,\n",
       "                     0.85370102, 0.85660377, 0.86124819, 0.86328012, 0.88301887,\n",
       "                     0.8862119 , 0.89375907, 0.90682148, 0.91291727, 0.92365747,\n",
       "                     0.92830189, 0.93381713, 0.93788099, 0.93991292, 0.94078374,\n",
       "                     0.94891147, 0.95587808, 0.9605225 , 0.96400581, 0.97329463,\n",
       "                     0.97358491, 0.97387518, 0.97503628, 0.97677794, 0.98171263,\n",
       "                     0.98461538, 0.98635704, 0.98896952, 0.98955007, 0.99622642,\n",
       "                     0.99796807, 0.99941945, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.08219945e-02, -4.25596144e-02,\n",
       "                     -4.44517626e-02, -4.80092192e-02, -6.06246218e-02, -6.89928715e-02,\n",
       "                     -8.70113770e-02, -1.05360516e-01, -1.11703990e-01, -1.13328685e-01,\n",
       "                     -1.17783036e-01, -1.33531393e-01, -1.36132174e-01, -1.54150680e-01,\n",
       "                     -1.56698452e-01, -1.74353387e-01, -1.82321557e-01, -1.88900528e-01,\n",
       "                     -1.89242000e-01, -2.23143551e-01, -2.43622083e-01, -2.45122458e-01,\n",
       "                     -2.46471804e-01, -2.55933374e-01, -2.65494157e-01, -2.70874954e-01,\n",
       "                     -2.80902385e-01, -2.81851152e-01, -2.82862786e-01, -2.87682072e-01,\n",
       "                     -2.99242895e-01, -3.02280872e-01, -3.03186259e-01, -3.08838272e-01,\n",
       "                     -3.22083499e-01, -3.28504067e-01, -3.29957556e-01, -3.34369186e-01,\n",
       "                     -3.36472237e-01, -3.49673748e-01, -3.52821375e-01, -3.56674944e-01,\n",
       "                     -3.62905494e-01, -3.68560551e-01, -3.69044477e-01, -3.69747026e-01,\n",
       "                     -3.70859579e-01, -3.71563556e-01, -3.83725121e-01, -3.84845821e-01,\n",
       "                     -3.90866309e-01, -4.00759217e-01, -4.05465108e-01, -4.08128226e-01,\n",
       "                     -4.11507423e-01, -4.13562318e-01, -4.24883194e-01, -4.38254931e-01,\n",
       "                     -4.41832752e-01, -4.45585102e-01, -4.46287103e-01, -4.48950220e-01,\n",
       "                     -4.55475529e-01, -4.59532329e-01, -4.70003629e-01, -4.85507816e-01,\n",
       "                     -4.90622916e-01, -5.02091944e-01, -5.10825624e-01, -5.23248144e-01,\n",
       "                     -5.28067430e-01, -5.30628251e-01, -5.45694449e-01, -5.59615788e-01,\n",
       "                     -5.70544858e-01, -5.75364145e-01, -5.76422906e-01, -5.92342481e-01,\n",
       "                     -5.94707108e-01, -6.06135804e-01, -6.13104473e-01, -6.19039208e-01,\n",
       "                     -6.41853886e-01, -6.75128675e-01, -6.93147181e-01, -7.53771802e-01,\n",
       "                     -7.59105148e-01, -7.63351439e-01, -7.73189888e-01, -7.88457360e-01,\n",
       "                     -8.10930216e-01, -8.47297860e-01, -8.55666110e-01, -8.75468737e-01,\n",
       "                     -9.16290732e-01, -9.80829253e-01, -1.02961942e+00, -1.09861229e+00,\n",
       "                     -1.20397280e+00, -1.38629436e+00, -1.70474809e+00, -3.45387764e+01]), auc_score=0.5350563740589531, privacy_risk=0.5248469787305134, accuracy=0.5248469787305134, tpr_ind=0.7895500725689405, tnr_ind=0.26014388489208634, test_train_ratio=1.0087082728592163, dataset_size=[3445, 3475]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.10656682, 0.11549539, 0.14832949, 0.1500576 ,\n",
       "                     0.15956221, 0.16042627, 0.16647465, 0.16733871, 0.17050691,\n",
       "                     0.19902074, 0.20190092, 0.20564516, 0.20996544, 0.2358871 ,\n",
       "                     0.23934332, 0.24510369, 0.24567972, 0.28398618, 0.29579493,\n",
       "                     0.29925115, 0.3015553 , 0.30587558, 0.32862903, 0.32949309,\n",
       "                     0.34130184, 0.34389401, 0.36463134, 0.37788018, 0.38479263,\n",
       "                     0.38968894, 0.40120968, 0.40841014, 0.41445853, 0.42569124,\n",
       "                     0.43951613, 0.44297235, 0.4703341 , 0.47955069, 0.55097926,\n",
       "                     0.56307604, 0.57776498, 0.58266129, 0.58726959, 0.58870968,\n",
       "                     0.60195853, 0.62384793, 0.63479263, 0.64861751, 0.66071429,\n",
       "                     0.66618664, 0.67252304, 0.69354839, 0.7016129 , 0.73070276,\n",
       "                     0.75201613, 0.75345622, 0.76468894, 0.77016129, 0.77102535,\n",
       "                     0.7750576 , 0.78110599, 0.79349078, 0.796947  , 0.80328341,\n",
       "                     0.81365207, 0.81998848, 0.82834101, 0.83208525, 0.83554147,\n",
       "                     0.84735023, 0.84821429, 0.86751152, 0.88392857, 0.88565668,\n",
       "                     0.90524194, 0.91388249, 0.92482719, 0.94815668, 0.95132488,\n",
       "                     0.953053  , 0.9562212 , 0.96054147, 0.96543779, 0.97004608,\n",
       "                     0.97177419, 0.97609447, 0.98041475, 0.9812788 , 0.98473502,\n",
       "                     0.98790323, 0.98819124, 0.99078341, 0.99193548, 1.        ]), tpr=array([0.        , 0.12383991, 0.13080046, 0.16241299, 0.16444316,\n",
       "                     0.17198376, 0.17546404, 0.18387471, 0.1861949 , 0.18967517,\n",
       "                     0.22534803, 0.22766821, 0.23172854, 0.23520882, 0.26769142,\n",
       "                     0.27117169, 0.27726218, 0.2787123 , 0.31409513, 0.32656613,\n",
       "                     0.32888631, 0.33178654, 0.33700696, 0.36484919, 0.36600928,\n",
       "                     0.38167053, 0.38689095, 0.40516241, 0.42314385, 0.42865429,\n",
       "                     0.43300464, 0.44315545, 0.44982599, 0.45562645, 0.46113689,\n",
       "                     0.47447796, 0.48288863, 0.51044084, 0.52030162, 0.59512761,\n",
       "                     0.60933875, 0.62703016, 0.63051044, 0.63428074, 0.63776102,\n",
       "                     0.6487819 , 0.66241299, 0.67401392, 0.68416473, 0.69837587,\n",
       "                     0.70562645, 0.71055684, 0.7299884 , 0.73781903, 0.76363109,\n",
       "                     0.78509281, 0.78654292, 0.79756381, 0.80278422, 0.80394432,\n",
       "                     0.8100348 , 0.81351508, 0.82337587, 0.82830626, 0.83555684,\n",
       "                     0.84483759, 0.85150812, 0.85788863, 0.86078886, 0.86455916,\n",
       "                     0.87616009, 0.87819026, 0.89327146, 0.90139211, 0.90429234,\n",
       "                     0.92662413, 0.93358469, 0.94112529, 0.96490719, 0.9675174 ,\n",
       "                     0.96983759, 0.97331787, 0.9762181 , 0.97969838, 0.98143852,\n",
       "                     0.98433875, 0.98694896, 0.99274942, 0.99361949, 0.99593968,\n",
       "                     0.99796984, 0.99854988, 0.99941995, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.08219945e-02, -4.48505662e-02,\n",
       "                     -4.87901642e-02, -5.40672213e-02, -6.45385211e-02, -6.66913745e-02,\n",
       "                     -6.89928715e-02, -9.30904231e-02, -1.00083459e-01, -1.17783036e-01,\n",
       "                     -1.33531393e-01, -1.39761942e-01, -1.49035579e-01, -1.54150680e-01,\n",
       "                     -1.74353387e-01, -1.82321557e-01, -1.84778560e-01, -1.90043603e-01,\n",
       "                     -1.92371893e-01, -2.11309094e-01, -2.23143551e-01, -2.31442354e-01,\n",
       "                     -2.33614851e-01, -2.34029359e-01, -2.45122458e-01, -2.51314428e-01,\n",
       "                     -2.54892250e-01, -2.74436846e-01, -2.80301965e-01, -2.87682072e-01,\n",
       "                     -2.98492989e-01, -3.00104592e-01, -3.07025035e-01, -3.14493330e-01,\n",
       "                     -3.16669609e-01, -3.21320432e-01, -3.23787077e-01, -3.27573401e-01,\n",
       "                     -3.27687407e-01, -3.28296792e-01, -3.36472237e-01, -3.42944751e-01,\n",
       "                     -3.48306694e-01, -3.52077235e-01, -3.54545018e-01, -3.55765440e-01,\n",
       "                     -3.56674944e-01, -3.74693449e-01, -3.75312070e-01, -3.85662481e-01,\n",
       "                     -4.00477567e-01, -4.05465108e-01, -4.31344556e-01, -4.32133355e-01,\n",
       "                     -4.35318071e-01, -4.39951284e-01, -4.41832752e-01, -4.46287103e-01,\n",
       "                     -4.51985124e-01, -4.59532329e-01, -4.70003629e-01, -4.83796951e-01,\n",
       "                     -4.94696242e-01, -5.04556011e-01, -5.10825624e-01, -5.19875459e-01,\n",
       "                     -5.26093096e-01, -5.28067430e-01, -5.30628251e-01, -5.38996501e-01,\n",
       "                     -5.59615788e-01, -5.79818495e-01, -5.87786665e-01, -5.97837001e-01,\n",
       "                     -6.06135804e-01, -6.73729095e-01, -6.93147181e-01, -7.47214402e-01,\n",
       "                     -7.53771802e-01, -7.73189888e-01, -8.32909123e-01, -8.47297860e-01,\n",
       "                     -8.69037847e-01, -9.16290732e-01, -9.38269639e-01, -9.40983344e-01,\n",
       "                     -9.80829253e-01, -1.01160091e+00, -1.09861229e+00, -1.25276297e+00,\n",
       "                     -1.38629436e+00, -1.60943791e+00, -3.45387764e+01]), auc_score=0.5293245867503502, privacy_risk=0.5246325927272338, accuracy=0.5246325927272338, tpr_ind=0.627030162412993, tnr_ind=0.42223502304147464, test_train_ratio=1.0069605568445477, dataset_size=[3448, 3472]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.10852713, 0.12431812, 0.12546655, 0.13321849,\n",
       "                     0.14412862, 0.14843526, 0.15015791, 0.17657192, 0.17829457,\n",
       "                     0.18001723, 0.18260121, 0.18489808, 0.20155039, 0.2052828 ,\n",
       "                     0.22107379, 0.24231984, 0.24892334, 0.26155613, 0.28423773,\n",
       "                     0.29600919, 0.30376113, 0.30921619, 0.31180017, 0.32357163,\n",
       "                     0.36836061, 0.38041918, 0.39534884, 0.40252656, 0.40884295,\n",
       "                     0.42233707, 0.43755383, 0.45190927, 0.45966121, 0.46080965,\n",
       "                     0.4656905 , 0.4754522 , 0.4886592 , 0.50071777, 0.51220212,\n",
       "                     0.51737008, 0.52052828, 0.52339937, 0.52627046, 0.53603216,\n",
       "                     0.55239736, 0.55900086, 0.56244617, 0.56617858, 0.57450474,\n",
       "                     0.58082113, 0.59890899, 0.65546942, 0.66408269, 0.68676428,\n",
       "                     0.68992248, 0.69681309, 0.70513925, 0.71174275, 0.72236578,\n",
       "                     0.74016652, 0.75279931, 0.76342234, 0.76830319, 0.77260982,\n",
       "                     0.77662934, 0.78696526, 0.83606087, 0.84008039, 0.84381281,\n",
       "                     0.8501292 , 0.8535745 , 0.85874246, 0.87166236, 0.88458226,\n",
       "                     0.89692794, 0.9055412 , 0.91501579, 0.92535171, 0.94573643,\n",
       "                     0.9511915 , 0.95406259, 0.95492392, 0.9672696 , 0.96956647,\n",
       "                     0.9738731 , 0.97961527, 0.9804766 , 0.98133793, 0.98650589,\n",
       "                     0.98794143, 0.99196095, 0.99253517, 1.        ]), tpr=array([0.        , 0.12219959, 0.13820192, 0.14140239, 0.15216759,\n",
       "                     0.16962467, 0.17398894, 0.1754437 , 0.20279313, 0.2059936 ,\n",
       "                     0.20890311, 0.21326738, 0.215595  , 0.24090777, 0.24556299,\n",
       "                     0.25632819, 0.28076811, 0.28745999, 0.29647949, 0.32237416,\n",
       "                     0.33488507, 0.34594123, 0.35903404, 0.36339831, 0.37707303,\n",
       "                     0.42595287, 0.43584521, 0.44893803, 0.46086704, 0.46755892,\n",
       "                     0.47948793, 0.49665406, 0.50771021, 0.51323829, 0.5155659 ,\n",
       "                     0.52167588, 0.53156823, 0.54349724, 0.56095432, 0.57317428,\n",
       "                     0.57957521, 0.58306663, 0.58888566, 0.58975851, 0.59994181,\n",
       "                     0.61245272, 0.62030841, 0.62467268, 0.63020076, 0.63572883,\n",
       "                     0.64503928, 0.66336922, 0.70817573, 0.71661333, 0.73581612,\n",
       "                     0.73901658, 0.74425371, 0.74919988, 0.75472796, 0.76171079,\n",
       "                     0.78091359, 0.7934245 , 0.80069828, 0.80448065, 0.80680826,\n",
       "                     0.81175444, 0.8251382 , 0.87023567, 0.87576375, 0.87838231,\n",
       "                     0.8868199 , 0.89060227, 0.89583939, 0.90864126, 0.92260692,\n",
       "                     0.93599069, 0.94210067, 0.94937445, 0.95606634, 0.970032  ,\n",
       "                     0.97497818, 0.97701484, 0.97876055, 0.98778004, 0.98894385,\n",
       "                     0.99156241, 0.99505383, 0.99563573, 0.99679953, 0.99854524,\n",
       "                     0.99912715, 0.99970905, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.80185055e-02, -5.12932944e-02,\n",
       "                     -5.26437335e-02, -6.45385211e-02, -7.41079722e-02, -8.00427077e-02,\n",
       "                     -8.16780310e-02, -8.70113770e-02, -9.53101798e-02, -1.05360516e-01,\n",
       "                     -1.17783036e-01, -1.29211731e-01, -1.33531393e-01, -1.50282203e-01,\n",
       "                     -1.54150680e-01, -1.60342650e-01, -1.76930708e-01, -1.82321557e-01,\n",
       "                     -1.90043603e-01, -1.91055237e-01, -2.00670695e-01, -2.17723484e-01,\n",
       "                     -2.23143551e-01, -2.32622295e-01, -2.34839591e-01, -2.36388778e-01,\n",
       "                     -2.37671652e-01, -2.65703166e-01, -2.75411980e-01, -2.87682072e-01,\n",
       "                     -2.94239473e-01, -3.13657559e-01, -3.18453731e-01, -3.22773392e-01,\n",
       "                     -3.23787077e-01, -3.29479201e-01, -3.36472237e-01, -3.39867826e-01,\n",
       "                     -3.42944751e-01, -3.48306694e-01, -3.50202429e-01, -3.52821375e-01,\n",
       "                     -3.56674944e-01, -3.65934269e-01, -3.67724780e-01, -3.82992252e-01,\n",
       "                     -3.86772975e-01, -3.87765531e-01, -3.94654192e-01, -4.05465108e-01,\n",
       "                     -4.09784769e-01, -4.16893804e-01, -4.32263301e-01, -4.35318071e-01,\n",
       "                     -4.41832752e-01, -4.51985124e-01, -4.56758402e-01, -4.59532329e-01,\n",
       "                     -4.64305608e-01, -4.72906389e-01, -4.78224462e-01, -4.79573080e-01,\n",
       "                     -4.85507816e-01, -4.98991166e-01, -5.00775288e-01, -5.02430353e-01,\n",
       "                     -5.03526321e-01, -5.10825624e-01, -5.24524468e-01, -5.26093096e-01,\n",
       "                     -5.43615447e-01, -5.59615788e-01, -5.87786665e-01, -5.91364486e-01,\n",
       "                     -5.93063722e-01, -6.24154309e-01, -6.48695418e-01, -6.93147181e-01,\n",
       "                     -7.48717032e-01, -7.50305594e-01, -7.73189888e-01, -7.85520501e-01,\n",
       "                     -8.10930216e-01, -8.47297860e-01, -9.16290732e-01, -1.09861229e+00,\n",
       "                     -1.17865500e+00, -1.25276297e+00, -1.38629436e+00, -1.60943791e+00,\n",
       "                     -2.48490665e+00, -3.45387764e+01]), auc_score=0.5394664353757487, privacy_risk=0.5327431438674117, accuracy=0.5327431438674117, tpr_ind=0.5888856560954321, tnr_ind=0.4766006316393913, test_train_ratio=1.0133837649112598, dataset_size=[3437, 3483]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.0956924 , 0.12373518, 0.13240821, 0.13761203,\n",
       "                     0.15755999, 0.15842729, 0.160451  , 0.17143683, 0.18213356,\n",
       "                     0.18618098, 0.1936976 , 0.19890142, 0.20179243, 0.20265973,\n",
       "                     0.20612894, 0.21653657, 0.21942758, 0.24689217, 0.24833767,\n",
       "                     0.25151778, 0.31627638, 0.32523851, 0.33217693, 0.35067939,\n",
       "                     0.35299219, 0.3547268 , 0.36947095, 0.37987858, 0.3856606 ,\n",
       "                     0.41688349, 0.4197745 , 0.44608268, 0.45706852, 0.51431049,\n",
       "                     0.52934374, 0.53396936, 0.53859497, 0.55218271, 0.57068517,\n",
       "                     0.57617809, 0.5796473 , 0.59034403, 0.60277537, 0.60422087,\n",
       "                     0.63197456, 0.64758601, 0.67360509, 0.6773634 , 0.70598439,\n",
       "                     0.72795606, 0.73460538, 0.73865279, 0.74501301, 0.74732582,\n",
       "                     0.76900838, 0.7730558 , 0.79358196, 0.81584273, 0.82191385,\n",
       "                     0.82682856, 0.83665799, 0.839549  , 0.84070541, 0.84330731,\n",
       "                     0.84851113, 0.86036427, 0.86527898, 0.89852559, 0.90083839,\n",
       "                     0.90517491, 0.90980052, 0.91587164, 0.92165366, 0.92454467,\n",
       "                     0.92974848, 0.93321769, 0.94796184, 0.95172015, 0.95576756,\n",
       "                     0.95779127, 0.96501879, 0.9673316 , 0.97022261, 0.97195721,\n",
       "                     0.97542642, 0.97687193, 0.98265395, 0.98352125, 0.98467765,\n",
       "                     0.98612316, 0.98641226, 0.98814686, 0.99045967, 1.        ]), tpr=array([0.        , 0.11586247, 0.14735626, 0.15833574, 0.16555909,\n",
       "                     0.18347298, 0.18462872, 0.18722912, 0.19791968, 0.20629876,\n",
       "                     0.20947703, 0.21756718, 0.22190118, 0.22536839, 0.22652413,\n",
       "                     0.23085813, 0.23923721, 0.24328229, 0.266397  , 0.27275354,\n",
       "                     0.27650968, 0.33834152, 0.34787634, 0.35567755, 0.36925744,\n",
       "                     0.37330251, 0.37561398, 0.39092748, 0.40364057, 0.40884138,\n",
       "                     0.44120196, 0.4440913 , 0.47298469, 0.48714244, 0.53250506,\n",
       "                     0.55157469, 0.55793123, 0.56313204, 0.57266686, 0.59462583,\n",
       "                     0.60213811, 0.60878359, 0.62438602, 0.63334296, 0.63507657,\n",
       "                     0.65934701, 0.67754984, 0.70557642, 0.7087547 , 0.73331407,\n",
       "                     0.76047385, 0.7676972 , 0.77376481, 0.77867668, 0.78012135,\n",
       "                     0.80439179, 0.80843687, 0.82375036, 0.8454204 , 0.85235481,\n",
       "                     0.85668882, 0.86651257, 0.87084658, 0.87286911, 0.87402485,\n",
       "                     0.87893672, 0.88500433, 0.89078301, 0.92343253, 0.92689974,\n",
       "                     0.93238948, 0.93498989, 0.94481364, 0.94885871, 0.95117018,\n",
       "                     0.95550419, 0.95810459, 0.97255129, 0.97659636, 0.98179717,\n",
       "                     0.98468651, 0.98844265, 0.98959838, 0.99162092, 0.99248772,\n",
       "                     0.99393239, 0.99508812, 0.99682173, 0.9973996 , 0.9982664 ,\n",
       "                     0.99884426, 0.99942213, 0.99971107, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.65293020e-02, -5.12932944e-02,\n",
       "                     -6.06246218e-02, -6.89928715e-02, -8.00427077e-02, -1.05360516e-01,\n",
       "                     -1.17783036e-01, -1.29211731e-01, -1.33531393e-01, -1.45182010e-01,\n",
       "                     -1.48420005e-01, -1.54150680e-01, -1.67054085e-01, -1.82321557e-01,\n",
       "                     -1.84192465e-01, -1.94156014e-01, -2.02940844e-01, -2.04794413e-01,\n",
       "                     -2.13574100e-01, -2.13753811e-01, -2.17064505e-01, -2.23143551e-01,\n",
       "                     -2.44196961e-01, -2.51314428e-01, -2.54892250e-01, -2.63814591e-01,\n",
       "                     -2.65281136e-01, -2.66628663e-01, -2.85447435e-01, -2.87682072e-01,\n",
       "                     -2.97766192e-01, -2.97834444e-01, -3.00340469e-01, -3.10154928e-01,\n",
       "                     -3.15852949e-01, -3.16669609e-01, -3.36472237e-01, -3.51397887e-01,\n",
       "                     -3.52821375e-01, -3.56674944e-01, -3.57837059e-01, -3.61013346e-01,\n",
       "                     -3.62905494e-01, -3.64973747e-01, -3.67724780e-01, -3.74406711e-01,\n",
       "                     -3.74693449e-01, -3.77630309e-01, -4.05465108e-01, -4.18710335e-01,\n",
       "                     -4.21213465e-01, -4.24883194e-01, -4.35318071e-01, -4.36717652e-01,\n",
       "                     -4.41832752e-01, -4.51985124e-01, -4.53196511e-01, -4.59532329e-01,\n",
       "                     -4.70003629e-01, -4.98991166e-01, -5.10825624e-01, -5.38996501e-01,\n",
       "                     -5.59615788e-01, -5.67984038e-01, -5.79818495e-01, -5.87786665e-01,\n",
       "                     -5.90732175e-01, -6.06135804e-01, -6.10909082e-01, -6.15185639e-01,\n",
       "                     -6.16774202e-01, -6.19039208e-01, -6.28608659e-01, -6.59245629e-01,\n",
       "                     -6.66478933e-01, -6.93147181e-01, -7.28238500e-01, -7.47214402e-01,\n",
       "                     -7.88457360e-01, -8.02346473e-01, -8.10930216e-01, -8.26678573e-01,\n",
       "                     -8.47297860e-01, -8.75468737e-01, -9.16290732e-01, -1.09861229e+00,\n",
       "                     -1.25276297e+00, -1.38629436e+00, -1.60943791e+00, -1.70474809e+00,\n",
       "                     -1.79175947e+00, -2.07944154e+00, -3.45387764e+01]), auc_score=0.5242016960307475, privacy_risk=0.5176917051765599, accuracy=0.5176917051765599, tpr_ind=0.8043917942791101, tnr_ind=0.23099161607400984, test_train_ratio=0.9994221323316961, dataset_size=[3461, 3459]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.10544413, 0.13667622, 0.14212034, 0.14670487,\n",
       "                     0.1512894 , 0.15530086, 0.17277937, 0.17335244, 0.17851003,\n",
       "                     0.18051576, 0.18739255, 0.19426934, 0.19627507, 0.2017192 ,\n",
       "                     0.20802292, 0.21690544, 0.2217765 , 0.22836676, 0.23094556,\n",
       "                     0.23323782, 0.23667622, 0.25386819, 0.25558739, 0.28108883,\n",
       "                     0.29140401, 0.29713467, 0.30028653, 0.30315186, 0.30974212,\n",
       "                     0.31432665, 0.34040115, 0.34269341, 0.35071633, 0.37249284,\n",
       "                     0.38911175, 0.3974212 , 0.41232092, 0.42578797, 0.5       ,\n",
       "                     0.50859599, 0.5747851 , 0.58223496, 0.60200573, 0.60487106,\n",
       "                     0.61919771, 0.62320917, 0.6243553 , 0.63409742, 0.64011461,\n",
       "                     0.65501433, 0.66103152, 0.67077364, 0.67679083, 0.68595989,\n",
       "                     0.68853868, 0.7008596 , 0.71260745, 0.71633238, 0.75186246,\n",
       "                     0.75931232, 0.76418338, 0.79570201, 0.79684814, 0.80744986,\n",
       "                     0.81146132, 0.81547278, 0.83209169, 0.83925501, 0.84097421,\n",
       "                     0.84928367, 0.85587393, 0.86217765, 0.8765043 , 0.88022923,\n",
       "                     0.88166189, 0.88653295, 0.89283668, 0.90315186, 0.90974212,\n",
       "                     0.91489971, 0.91776504, 0.92922636, 0.94126074, 0.94727794,\n",
       "                     0.94842407, 0.95558739, 0.96160458, 0.96504298, 0.97449857,\n",
       "                     0.9765043 , 0.97908309, 0.98080229, 0.98194842, 0.98481375,\n",
       "                     0.98653295, 0.98882521, 0.99140401, 1.        ]), tpr=array([0.        , 0.11020408, 0.13994169, 0.14693878, 0.15306122,\n",
       "                     0.15830904, 0.16268222, 0.17813411, 0.17842566, 0.18309038,\n",
       "                     0.18571429, 0.19475219, 0.20262391, 0.20495627, 0.21078717,\n",
       "                     0.21720117, 0.22478134, 0.22944606, 0.23673469, 0.24023324,\n",
       "                     0.24285714, 0.24927114, 0.27055394, 0.27259475, 0.29620991,\n",
       "                     0.31195335, 0.31661808, 0.31924198, 0.32157434, 0.32769679,\n",
       "                     0.33206997, 0.3638484 , 0.36588921, 0.3728863 , 0.39854227,\n",
       "                     0.41457726, 0.42857143, 0.44169096, 0.45772595, 0.52623907,\n",
       "                     0.53877551, 0.60787172, 0.61311953, 0.6303207 , 0.63527697,\n",
       "                     0.64781341, 0.65247813, 0.6548105 , 0.66530612, 0.67317784,\n",
       "                     0.68542274, 0.68862974, 0.70087464, 0.70758017, 0.71661808,\n",
       "                     0.71924198, 0.73236152, 0.7425656 , 0.7451895 , 0.7787172 ,\n",
       "                     0.78483965, 0.78921283, 0.82915452, 0.83002915, 0.83819242,\n",
       "                     0.84344023, 0.84635569, 0.85947522, 0.86705539, 0.86880466,\n",
       "                     0.87725948, 0.88367347, 0.88833819, 0.90116618, 0.90408163,\n",
       "                     0.90874636, 0.91311953, 0.92011662, 0.93119534, 0.93411079,\n",
       "                     0.93760933, 0.93965015, 0.94723032, 0.95918367, 0.96355685,\n",
       "                     0.96618076, 0.97405248, 0.97784257, 0.98017493, 0.98746356,\n",
       "                     0.98950437, 0.99125364, 0.99329446, 0.99475219, 0.996793  ,\n",
       "                     0.99795918, 0.99912536, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.89875369e-02, -4.08219945e-02,\n",
       "                     -4.65200156e-02, -5.40672213e-02, -6.45385211e-02, -7.27593543e-02,\n",
       "                     -8.70113770e-02, -1.03184236e-01, -1.05360516e-01, -1.09199292e-01,\n",
       "                     -1.16072171e-01, -1.17783036e-01, -1.22602322e-01, -1.29211731e-01,\n",
       "                     -1.35801541e-01, -1.43100844e-01, -1.48420005e-01, -1.54150680e-01,\n",
       "                     -1.60342650e-01, -1.78248231e-01, -1.82321557e-01, -2.00670695e-01,\n",
       "                     -2.10721031e-01, -2.15708573e-01, -2.18253566e-01, -2.23143551e-01,\n",
       "                     -2.39229689e-01, -2.43977638e-01, -2.49654677e-01, -2.50294540e-01,\n",
       "                     -2.51314428e-01, -2.56719847e-01, -2.57829109e-01, -2.68263987e-01,\n",
       "                     -2.76632236e-01, -2.87682072e-01, -3.02280872e-01, -3.18066809e-01,\n",
       "                     -3.22773392e-01, -3.24953467e-01, -3.32705754e-01, -3.36472237e-01,\n",
       "                     -3.44840486e-01, -3.56674944e-01, -3.62905494e-01, -3.71563556e-01,\n",
       "                     -3.90427231e-01, -3.93042588e-01, -4.05465108e-01, -4.15515444e-01,\n",
       "                     -4.16893804e-01, -4.19853846e-01, -4.21725629e-01, -4.21994410e-01,\n",
       "                     -4.22414666e-01, -4.30036369e-01, -4.41832752e-01, -4.48024723e-01,\n",
       "                     -4.51985124e-01, -4.70003629e-01, -4.78181776e-01, -4.79573080e-01,\n",
       "                     -4.80585739e-01, -5.10825624e-01, -5.30628251e-01, -5.37142932e-01,\n",
       "                     -5.44301553e-01, -5.59615788e-01, -5.64529803e-01, -5.72519193e-01,\n",
       "                     -5.75364145e-01, -5.85258219e-01, -5.87786665e-01, -5.94707108e-01,\n",
       "                     -5.97837001e-01, -6.06135804e-01, -6.21688217e-01, -6.41853886e-01,\n",
       "                     -6.50587566e-01, -6.53926467e-01, -6.64976304e-01, -6.93147181e-01,\n",
       "                     -7.04197017e-01, -7.47214402e-01, -7.82759339e-01, -8.07091440e-01,\n",
       "                     -8.10930216e-01, -8.47297860e-01, -8.87303195e-01, -9.04456274e-01,\n",
       "                     -9.44461609e-01, -9.55511445e-01, -9.80829253e-01, -1.09861229e+00,\n",
       "                     -1.38629436e+00, -1.60943791e+00, -3.45387764e+01]), auc_score=0.5208593064733057, privacy_risk=0.5167262566098891, accuracy=0.5167262566098891, tpr_ind=0.8291545189504373, tnr_ind=0.20429799426934098, test_train_ratio=1.0174927113702623, dataset_size=[3430, 3490]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.13312065, 0.13457077, 0.14182135, 0.14298144,\n",
       "                     0.15400232, 0.16850348, 0.17314385, 0.18242459, 0.18590487,\n",
       "                     0.18706497, 0.19054524, 0.20301624, 0.2137471 , 0.21490719,\n",
       "                     0.21896752, 0.22360789, 0.22360789, 0.3387471 , 0.33961717,\n",
       "                     0.3462877 , 0.3474478 , 0.35730858, 0.37993039, 0.39530162,\n",
       "                     0.40719258, 0.42111369, 0.42633411, 0.4399652 , 0.4475058 ,\n",
       "                     0.45214617, 0.5087007 , 0.51276102, 0.52030162, 0.52610209,\n",
       "                     0.54060325, 0.5487239 , 0.55336427, 0.56032483, 0.56351508,\n",
       "                     0.60266821, 0.60614849, 0.61136891, 0.61484919, 0.61919954,\n",
       "                     0.6287703 , 0.64704176, 0.66241299, 0.66618329, 0.69083527,\n",
       "                     0.70562645, 0.7099768 , 0.71606729, 0.72070766, 0.73056845,\n",
       "                     0.737529  , 0.74187935, 0.74651972, 0.75812065, 0.76450116,\n",
       "                     0.77726218, 0.79582367, 0.80075406, 0.80423434, 0.81148492,\n",
       "                     0.82540603, 0.82859629, 0.84106729, 0.84715777, 0.85701856,\n",
       "                     0.87993039, 0.8863109 , 0.88805104, 0.89559165, 0.90690255,\n",
       "                     0.90864269, 0.90922274, 0.91299304, 0.91937355, 0.93213457,\n",
       "                     0.93677494, 0.95591647, 0.95678654, 0.96171694, 0.96722738,\n",
       "                     0.96867749, 0.97534803, 0.97534803, 0.97911833, 0.98230858,\n",
       "                     0.98317865, 0.98578886, 0.98636891, 0.98839907, 0.98926914,\n",
       "                     1.        ]), tpr=array([0.        , 0.14832949, 0.15034562, 0.15898618, 0.16301843,\n",
       "                     0.17453917, 0.18692396, 0.18980415, 0.19498848, 0.19786866,\n",
       "                     0.19959677, 0.20276498, 0.21284562, 0.22638249, 0.22955069,\n",
       "                     0.23559908, 0.23934332, 0.24049539, 0.35743088, 0.36059908,\n",
       "                     0.36434332, 0.36549539, 0.38191244, 0.40754608, 0.42597926,\n",
       "                     0.43836406, 0.44988479, 0.45593318, 0.47292627, 0.48070276,\n",
       "                     0.48387097, 0.53254608, 0.53888249, 0.54781106, 0.55299539,\n",
       "                     0.56826037, 0.57546083, 0.58179724, 0.58726959, 0.5921659 ,\n",
       "                     0.62903226, 0.63248848, 0.63796083, 0.64199309, 0.64544931,\n",
       "                     0.65380184, 0.67511521, 0.69239631, 0.69470046, 0.7235023 ,\n",
       "                     0.74164747, 0.74769585, 0.75518433, 0.7609447 , 0.77044931,\n",
       "                     0.77822581, 0.7828341 , 0.78686636, 0.79579493, 0.80443548,\n",
       "                     0.81422811, 0.83726959, 0.84101382, 0.84447005, 0.85109447,\n",
       "                     0.86117512, 0.8640553 , 0.87211982, 0.87672811, 0.88767281,\n",
       "                     0.91445853, 0.91762673, 0.91935484, 0.92713134, 0.93692396,\n",
       "                     0.93721198, 0.93951613, 0.94354839, 0.94700461, 0.95910138,\n",
       "                     0.96169355, 0.97379032, 0.97638249, 0.98243088, 0.98559908,\n",
       "                     0.98732719, 0.99049539, 0.99193548, 0.99452765, 0.99625576,\n",
       "                     0.99625576, 0.99798387, 0.99827189, 0.99971198, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.40672213e-02, -6.45385211e-02,\n",
       "                     -6.89928715e-02, -7.23206616e-02, -8.89474860e-02, -9.53101798e-02,\n",
       "                     -9.84400728e-02, -1.11225635e-01, -1.17783036e-01, -1.33531393e-01,\n",
       "                     -1.41078598e-01, -1.54150680e-01, -1.62518929e-01, -1.74353387e-01,\n",
       "                     -1.82321557e-01, -1.94156014e-01, -2.22157844e-01, -2.23143551e-01,\n",
       "                     -2.28841572e-01, -2.41162057e-01, -2.42313467e-01, -2.47562079e-01,\n",
       "                     -2.47836164e-01, -2.51314428e-01, -2.62364264e-01, -2.64692554e-01,\n",
       "                     -2.66267978e-01, -2.87682072e-01, -3.05381650e-01, -3.08180594e-01,\n",
       "                     -3.10154928e-01, -3.18453731e-01, -3.32133835e-01, -3.34934957e-01,\n",
       "                     -3.36472237e-01, -3.42944751e-01, -3.43771539e-01, -3.44840486e-01,\n",
       "                     -3.46466767e-01, -3.48306694e-01, -3.51397887e-01, -3.56674944e-01,\n",
       "                     -3.67724780e-01, -3.70373788e-01, -3.81934611e-01, -3.83958903e-01,\n",
       "                     -3.87765531e-01, -3.98776120e-01, -4.05465108e-01, -4.16893804e-01,\n",
       "                     -4.30782916e-01, -4.38254931e-01, -4.40971797e-01, -4.41832752e-01,\n",
       "                     -4.46287103e-01, -4.51985124e-01, -4.65057205e-01, -4.78490243e-01,\n",
       "                     -4.80972661e-01, -4.85507816e-01, -4.90622916e-01, -5.10825624e-01,\n",
       "                     -5.18793793e-01, -5.22189382e-01, -5.30628251e-01, -5.46543706e-01,\n",
       "                     -5.59615788e-01, -5.61377903e-01, -5.67984038e-01, -5.95983432e-01,\n",
       "                     -6.06135804e-01, -6.12517446e-01, -6.14158769e-01, -6.19039208e-01,\n",
       "                     -6.28608659e-01, -6.31271777e-01, -6.50587566e-01, -6.66191371e-01,\n",
       "                     -6.69049629e-01, -6.93147181e-01, -7.30887509e-01, -7.50305594e-01,\n",
       "                     -8.60201265e-01, -9.16290732e-01, -9.34309237e-01, -9.55511445e-01,\n",
       "                     -1.01160091e+00, -1.09861229e+00, -1.18562367e+00, -1.25276297e+00,\n",
       "                     -1.38629436e+00, -1.52605630e+00, -1.79175947e+00, -3.45387764e+01]), auc_score=0.5239242828942444, privacy_risk=0.5207229596800924, accuracy=0.5207229596800924, tpr_ind=0.8372695852534562, tnr_ind=0.20417633410672853, test_train_ratio=0.9930875576036866, dataset_size=[3472, 3448]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.12053057, 0.12975779, 0.13523645, 0.1372549 ,\n",
       "                     0.14158016, 0.14388697, 0.14677047, 0.15657439, 0.1600346 ,\n",
       "                     0.16868512, 0.17502884, 0.2032872 , 0.20732411, 0.21655133,\n",
       "                     0.22693195, 0.23875433, 0.24307958, 0.24653979, 0.24855825,\n",
       "                     0.26701269, 0.27537486, 0.29988466, 0.30276817, 0.3194925 ,\n",
       "                     0.34803922, 0.3650519 , 0.37687428, 0.38177624, 0.40282584,\n",
       "                     0.40311419, 0.41839677, 0.42589389, 0.43627451, 0.44117647,\n",
       "                     0.45126874, 0.46597463, 0.47462514, 0.4795271 , 0.49019608,\n",
       "                     0.49307958, 0.5438293 , 0.55190311, 0.55565167, 0.55622837,\n",
       "                     0.56286044, 0.58333333, 0.5899654 , 0.59371396, 0.60034602,\n",
       "                     0.60668973, 0.6144752 , 0.63811995, 0.65311419, 0.67070358,\n",
       "                     0.70761246, 0.70963091, 0.71482122, 0.73702422, 0.74365629,\n",
       "                     0.74798155, 0.7494233 , 0.76845444, 0.77422145, 0.78604383,\n",
       "                     0.80132641, 0.80997693, 0.81286044, 0.82064591, 0.82987313,\n",
       "                     0.83391003, 0.84313725, 0.85467128, 0.85899654, 0.86476355,\n",
       "                     0.87168397, 0.87514418, 0.87975779, 0.89042676, 0.89417532,\n",
       "                     0.90801615, 0.91349481, 0.92243368, 0.94059977, 0.94896194,\n",
       "                     0.95588235, 0.96741638, 0.97058824, 0.97231834, 0.97318339,\n",
       "                     0.97577855, 0.97923875, 0.98096886, 0.98125721, 0.98673587,\n",
       "                     0.98760092, 0.98904268, 0.99163783, 1.        ]), tpr=array([0.        , 0.12630359, 0.13354577, 0.1373117 , 0.1396292 ,\n",
       "                     0.14571263, 0.1486095 , 0.15208575, 0.16714948, 0.17033604,\n",
       "                     0.17612978, 0.18221321, 0.20828505, 0.21292005, 0.22334878,\n",
       "                     0.23522596, 0.24362688, 0.25028969, 0.25405562, 0.25695249,\n",
       "                     0.27896871, 0.28794902, 0.31141367, 0.31286211, 0.32908459,\n",
       "                     0.35950174, 0.37514484, 0.38876014, 0.39571263, 0.41367323,\n",
       "                     0.41512167, 0.43105446, 0.43626883, 0.44930475, 0.45393975,\n",
       "                     0.46552723, 0.48522596, 0.49565469, 0.50144844, 0.51448436,\n",
       "                     0.51767092, 0.57097335, 0.58024334, 0.58371958, 0.58400927,\n",
       "                     0.58951333, 0.60747393, 0.61616454, 0.61877173, 0.62137891,\n",
       "                     0.62804171, 0.63818076, 0.66106605, 0.6778679 , 0.69640788,\n",
       "                     0.73232908, 0.73580533, 0.74044032, 0.7636153 , 0.76738123,\n",
       "                     0.77114716, 0.77317497, 0.7905562 , 0.79577057, 0.8108343 ,\n",
       "                     0.82676709, 0.83690614, 0.83806489, 0.84617613, 0.85544612,\n",
       "                     0.85950174, 0.86964079, 0.8783314 , 0.88035921, 0.88991889,\n",
       "                     0.89542294, 0.89774044, 0.90150637, 0.9099073 , 0.91541136,\n",
       "                     0.92902665, 0.93539977, 0.94495944, 0.9594438 , 0.96378911,\n",
       "                     0.97421784, 0.98290846, 0.98609502, 0.98899189, 0.98986095,\n",
       "                     0.99130939, 0.99391657, 0.99565469, 0.99565469, 0.99826188,\n",
       "                     0.99884125, 0.99942063, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.19789067e-02, -3.50913198e-02,\n",
       "                     -7.41079722e-02, -8.45573880e-02, -9.53101798e-02, -1.05360516e-01,\n",
       "                     -1.09199292e-01, -1.17783036e-01, -1.24052649e-01, -1.25163143e-01,\n",
       "                     -1.49745386e-01, -1.50282203e-01, -1.54150680e-01, -1.57628944e-01,\n",
       "                     -1.59064695e-01, -1.60342650e-01, -1.60930367e-01, -1.63629424e-01,\n",
       "                     -1.69076330e-01, -1.76930708e-01, -1.80261824e-01, -1.82321557e-01,\n",
       "                     -1.94156014e-01, -2.00670695e-01, -2.06049118e-01, -2.15596346e-01,\n",
       "                     -2.23143551e-01, -2.46133070e-01, -2.51314428e-01, -2.55346692e-01,\n",
       "                     -2.55933374e-01, -2.70874954e-01, -2.71933715e-01, -2.81412459e-01,\n",
       "                     -2.87682072e-01, -2.89952221e-01, -2.94799540e-01, -3.04211374e-01,\n",
       "                     -3.10154928e-01, -3.18022790e-01, -3.18453731e-01, -3.31357136e-01,\n",
       "                     -3.36472237e-01, -3.51397887e-01, -3.52077235e-01, -3.56674944e-01,\n",
       "                     -3.67724780e-01, -3.85662481e-01, -3.90866309e-01, -3.95895657e-01,\n",
       "                     -4.03312255e-01, -4.05465108e-01, -4.07895243e-01, -4.18150268e-01,\n",
       "                     -4.19853846e-01, -4.29856561e-01, -4.38254931e-01, -4.39366660e-01,\n",
       "                     -4.41832752e-01, -4.51985124e-01, -4.70003629e-01, -4.76924072e-01,\n",
       "                     -4.79573080e-01, -4.81303184e-01, -4.87703206e-01, -4.96436886e-01,\n",
       "                     -5.10825624e-01, -5.23248144e-01, -5.24524468e-01, -5.28067430e-01,\n",
       "                     -5.30185871e-01, -5.38996501e-01, -5.46543706e-01, -5.52068582e-01,\n",
       "                     -5.59615788e-01, -5.70544858e-01, -5.81029882e-01, -5.81921545e-01,\n",
       "                     -6.17435359e-01, -6.19039208e-01, -6.20240410e-01, -6.31271777e-01,\n",
       "                     -6.33723760e-01, -6.40304699e-01, -6.93147181e-01, -7.88457360e-01,\n",
       "                     -7.93230639e-01, -8.10930216e-01, -8.75468737e-01, -8.93817876e-01,\n",
       "                     -9.16290732e-01, -9.80829253e-01, -1.09861229e+00, -1.38629436e+00,\n",
       "                     -1.60943791e+00, -2.07944154e+00, -3.45387764e+01]), auc_score=0.5160329468165155, privacy_risk=0.5141701115044887, accuracy=0.5141701115044887, tpr_ind=0.5802433371958285, tnr_ind=0.44809688581314877, test_train_ratio=1.0046349942062573, dataset_size=[3452, 3468]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.1224837 , 0.14148001, 0.15310462, 0.17295152,\n",
       "                     0.18854551, 0.1916643 , 0.19393252, 0.19620074, 0.20073717,\n",
       "                     0.20669124, 0.20754182, 0.20867593, 0.21094415, 0.22001701,\n",
       "                     0.22228523, 0.26396371, 0.2869294 , 0.30223986, 0.30819393,\n",
       "                     0.31613269, 0.32719025, 0.3277573 , 0.33314432, 0.33909838,\n",
       "                     0.34476893, 0.37142047, 0.38616388, 0.39240147, 0.39835554,\n",
       "                     0.4031755 , 0.41026368, 0.41366601, 0.43748228, 0.45562801,\n",
       "                     0.46356677, 0.4817125 , 0.50127587, 0.53416501, 0.55542954,\n",
       "                     0.57017295, 0.5769776 , 0.58179756, 0.61497023, 0.63113127,\n",
       "                     0.63992061, 0.6481429 , 0.65494755, 0.664871  , 0.67621208,\n",
       "                     0.67734619, 0.69152254, 0.70059541, 0.70172952, 0.71051885,\n",
       "                     0.7235611 , 0.73490218, 0.73887156, 0.74936206, 0.75730082,\n",
       "                     0.77459597, 0.77941593, 0.78026652, 0.78281826, 0.79557698,\n",
       "                     0.79926283, 0.80181457, 0.87241282, 0.87779983, 0.88205274,\n",
       "                     0.89254324, 0.89396087, 0.89481145, 0.90501843, 0.9078537 ,\n",
       "                     0.91295719, 0.91635951, 0.92316416, 0.95123334, 0.95662036,\n",
       "                     0.95718741, 0.96172384, 0.9696626 , 0.97221435, 0.97419904,\n",
       "                     0.97618373, 0.9801531 , 0.98185427, 0.9832719 , 0.98610717,\n",
       "                     0.98809186, 0.99064361, 1.        ]), tpr=array([0.        , 0.12584733, 0.14146773, 0.15738285, 0.1821397 ,\n",
       "                     0.19864427, 0.20247569, 0.20483348, 0.20807545, 0.21632773,\n",
       "                     0.22163277, 0.22222222, 0.22575892, 0.22723254, 0.23843207,\n",
       "                     0.24108459, 0.29266136, 0.31653404, 0.32950192, 0.33863837,\n",
       "                     0.34836428, 0.3654583 , 0.36663719, 0.37341586, 0.37989979,\n",
       "                     0.3872679 , 0.41084586, 0.42440318, 0.43000295, 0.43501326,\n",
       "                     0.44061303, 0.44414972, 0.44886531, 0.47745358, 0.49307398,\n",
       "                     0.50132626, 0.52166225, 0.54052461, 0.56970233, 0.58885942,\n",
       "                     0.60506926, 0.61125847, 0.61774241, 0.65841438, 0.67108753,\n",
       "                     0.67992927, 0.68906572, 0.69525494, 0.69997053, 0.7152962 ,\n",
       "                     0.71706454, 0.73474801, 0.74506337, 0.74712644, 0.75744179,\n",
       "                     0.76864132, 0.77895668, 0.78219864, 0.7936929 , 0.79929266,\n",
       "                     0.8166814 , 0.82051282, 0.82522841, 0.82905983, 0.84114353,\n",
       "                     0.84350133, 0.84526967, 0.90509873, 0.90981432, 0.91158267,\n",
       "                     0.92248747, 0.9239611 , 0.92572944, 0.9360448 , 0.93869732,\n",
       "                     0.94164456, 0.94400236, 0.94871795, 0.9734748 , 0.97848512,\n",
       "                     0.97877984, 0.98231653, 0.98703212, 0.9879163 , 0.99056882,\n",
       "                     0.99292661, 0.99440024, 0.99557913, 0.99616858, 0.9976422 ,\n",
       "                     0.99852638, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.66188940e-02, -5.66953437e-02,\n",
       "                     -6.89928715e-02, -7.14589640e-02, -7.41079722e-02, -8.70113770e-02,\n",
       "                     -9.53101798e-02, -1.01782694e-01, -1.05360516e-01, -1.17783036e-01,\n",
       "                     -1.33531393e-01, -1.38150338e-01, -1.54150680e-01, -1.82321557e-01,\n",
       "                     -1.96506192e-01, -2.00670695e-01, -2.02940844e-01, -2.03598955e-01,\n",
       "                     -2.12332635e-01, -2.16223108e-01, -2.23143551e-01, -2.31801614e-01,\n",
       "                     -2.76253377e-01, -2.77631737e-01, -2.81412459e-01, -2.82232468e-01,\n",
       "                     -2.87682072e-01, -3.01105093e-01, -3.05381650e-01, -3.07484700e-01,\n",
       "                     -3.15081047e-01, -3.23128821e-01, -3.33773180e-01, -3.36472237e-01,\n",
       "                     -3.46148531e-01, -3.51976423e-01, -3.53640040e-01, -3.58212223e-01,\n",
       "                     -3.62114667e-01, -3.74693449e-01, -3.79489622e-01, -3.82003621e-01,\n",
       "                     -3.97682968e-01, -4.05465108e-01, -4.16160397e-01, -4.21213465e-01,\n",
       "                     -4.26742507e-01, -4.30782916e-01, -4.41832752e-01, -4.48950220e-01,\n",
       "                     -4.50585543e-01, -4.51985124e-01, -4.70003629e-01, -4.73287704e-01,\n",
       "                     -4.84245986e-01, -4.92476485e-01, -4.95321437e-01, -5.07247802e-01,\n",
       "                     -5.09648461e-01, -5.10825624e-01, -5.23248144e-01, -5.26093096e-01,\n",
       "                     -5.28067430e-01, -5.30628251e-01, -5.52068582e-01, -5.58932027e-01,\n",
       "                     -5.59615788e-01, -5.63094052e-01, -5.85818160e-01, -5.87786665e-01,\n",
       "                     -6.06135804e-01, -6.07380359e-01, -6.35988767e-01, -6.41853886e-01,\n",
       "                     -6.46627165e-01, -6.61398482e-01, -6.93147181e-01, -7.06219262e-01,\n",
       "                     -7.53771802e-01, -7.73189888e-01, -8.10930216e-01, -8.47297860e-01,\n",
       "                     -8.67500568e-01, -9.16290732e-01, -1.09861229e+00, -1.17865500e+00,\n",
       "                     -1.25276297e+00, -1.28093385e+00, -1.38629436e+00, -1.60943791e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.528434933042737, privacy_risk=0.5234614686869705, accuracy=0.5234614686869705, tpr_ind=0.7574417919245505, tnr_ind=0.2894811454493904, test_train_ratio=1.0394930739758326, dataset_size=[3393, 3527]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.12205629, 0.1412981 , 0.14417002, 0.15077542,\n",
       "                     0.15364733, 0.15680643, 0.15709362, 0.16829408, 0.17317634,\n",
       "                     0.1743251 , 0.17690982, 0.17978173, 0.18064331, 0.19500287,\n",
       "                     0.20275704, 0.20534176, 0.20763929, 0.21855256, 0.21970132,\n",
       "                     0.22601953, 0.22774268, 0.23205055, 0.23721999, 0.24066628,\n",
       "                     0.24296381, 0.24842045, 0.25588742, 0.26766226, 0.27828834,\n",
       "                     0.29063756, 0.36071223, 0.39172889, 0.41958644, 0.42044802,\n",
       "                     0.42245836, 0.49080988, 0.49224584, 0.50143596, 0.50689259,\n",
       "                     0.5132108 , 0.51924182, 0.5758185 , 0.57811603, 0.58931648,\n",
       "                     0.59936818, 0.6120046 , 0.62320505, 0.64244687, 0.64905227,\n",
       "                     0.66255026, 0.66599655, 0.67145319, 0.68351522, 0.69873636,\n",
       "                     0.70562895, 0.7139575 , 0.72085009, 0.76450316, 0.76995979,\n",
       "                     0.79896611, 0.80183802, 0.80413555, 0.81447444, 0.83113153,\n",
       "                     0.8322803 , 0.84750144, 0.85496841, 0.86530729, 0.87306146,\n",
       "                     0.88110281, 0.89115451, 0.89345204, 0.89546238, 0.90005744,\n",
       "                     0.9078116 , 0.91412981, 0.92245836, 0.95261344, 0.95605974,\n",
       "                     0.95950603, 0.96553705, 0.96553705, 0.966973  , 0.97616312,\n",
       "                     0.97673751, 0.97759908, 0.98535325, 0.98793797, 0.98793797,\n",
       "                     0.98908673, 1.        ]), tpr=array([0.        , 0.12885398, 0.14514252, 0.14892379, 0.16143106,\n",
       "                     0.16521233, 0.17015707, 0.1707388 , 0.18411867, 0.18964514,\n",
       "                     0.19226294, 0.19633508, 0.19924375, 0.20069808, 0.21524142,\n",
       "                     0.22134962, 0.22513089, 0.22920303, 0.2399651 , 0.2434555 ,\n",
       "                     0.2486911 , 0.25101803, 0.25683537, 0.26527051, 0.27021524,\n",
       "                     0.27283304, 0.27661431, 0.28301338, 0.29261198, 0.30337405,\n",
       "                     0.31820826, 0.38947062, 0.41913903, 0.44357184, 0.44444444,\n",
       "                     0.44589878, 0.51948807, 0.52297848, 0.53374055, 0.53955788,\n",
       "                     0.54537522, 0.55322862, 0.60616638, 0.60907504, 0.62594532,\n",
       "                     0.63728912, 0.65037813, 0.66143106, 0.68091914, 0.68906341,\n",
       "                     0.70389761, 0.71000582, 0.71320535, 0.72367656, 0.73269343,\n",
       "                     0.73880163, 0.7460733 , 0.75276323, 0.79493892, 0.79959279,\n",
       "                     0.82373473, 0.82780686, 0.83042467, 0.840605  , 0.85863874,\n",
       "                     0.85951134, 0.87463642, 0.87958115, 0.88888889, 0.89557882,\n",
       "                     0.90110529, 0.9107039 , 0.91390343, 0.9159395 , 0.92059337,\n",
       "                     0.93251891, 0.93804538, 0.94444444, 0.97440372, 0.97818499,\n",
       "                     0.98022106, 0.98487493, 0.98545666, 0.98894706, 0.9930192 ,\n",
       "                     0.9938918 , 0.99505526, 0.9982548 , 0.99883653, 0.99970913,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.50913198e-02, -3.77403280e-02,\n",
       "                     -4.54623741e-02, -4.87901642e-02, -5.71584138e-02, -6.06246218e-02,\n",
       "                     -8.00427077e-02, -1.00083459e-01, -1.05360516e-01, -1.21360857e-01,\n",
       "                     -1.25163143e-01, -1.27833372e-01, -1.31028262e-01, -1.33531393e-01,\n",
       "                     -1.43100844e-01, -1.45182010e-01, -1.50282203e-01, -1.54150680e-01,\n",
       "                     -1.67054085e-01, -1.71850257e-01, -1.82321557e-01, -1.88052232e-01,\n",
       "                     -1.93191229e-01, -2.00670695e-01, -2.03598955e-01, -2.04794413e-01,\n",
       "                     -2.23143551e-01, -2.28633044e-01, -2.34507310e-01, -2.41744977e-01,\n",
       "                     -2.57829109e-01, -2.60531083e-01, -2.62364264e-01, -2.71933715e-01,\n",
       "                     -2.86693442e-01, -2.87682072e-01, -2.98981628e-01, -3.00104592e-01,\n",
       "                     -3.18453731e-01, -3.36472237e-01, -3.37256858e-01, -3.56674944e-01,\n",
       "                     -3.58397597e-01, -3.61790045e-01, -3.67724780e-01, -3.69747026e-01,\n",
       "                     -3.80274859e-01, -3.81367557e-01, -3.85662481e-01, -3.99386062e-01,\n",
       "                     -4.05465108e-01, -4.14943852e-01, -4.16160397e-01, -4.38254931e-01,\n",
       "                     -4.70003629e-01, -4.75423697e-01, -4.78837948e-01, -4.85507816e-01,\n",
       "                     -4.86434171e-01, -4.96436886e-01, -4.99955952e-01, -5.05094949e-01,\n",
       "                     -5.10825624e-01, -5.30628251e-01, -5.31576568e-01, -5.59615788e-01,\n",
       "                     -5.77315365e-01, -5.78077851e-01, -5.81921545e-01, -5.89606502e-01,\n",
       "                     -5.97837001e-01, -6.19039208e-01, -6.28608659e-01, -6.41090819e-01,\n",
       "                     -6.63294217e-01, -6.70157662e-01, -6.93147181e-01, -7.43578034e-01,\n",
       "                     -7.62140052e-01, -8.10930216e-01, -8.47297860e-01, -8.82389180e-01,\n",
       "                     -9.16290732e-01, -9.80829253e-01, -1.06784063e+00, -1.09861229e+00,\n",
       "                     -1.38629436e+00, -1.46633707e+00, -1.79175947e+00, -3.45387764e+01]), auc_score=0.5239683167383893, privacy_risk=0.5220046318154464, accuracy=0.5220046318154464, tpr_ind=0.7100058173356603, tnr_ind=0.3340034462952326, test_train_ratio=1.0127981384525888, dataset_size=[3438, 3482]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.07703446, 0.11033884, 0.11497249, 0.13785114,\n",
       "                     0.14624964, 0.15783377, 0.16015059, 0.17665798, 0.17926441,\n",
       "                     0.18187084, 0.19808862, 0.20764553, 0.25687808, 0.26209094,\n",
       "                     0.26643498, 0.30495222, 0.30611063, 0.31566754, 0.32001158,\n",
       "                     0.34433826, 0.3483927 , 0.35592239, 0.3753258 , 0.38546192,\n",
       "                     0.39038517, 0.41702867, 0.4375905 , 0.44367217, 0.48363742,\n",
       "                     0.48421662, 0.49493194, 0.49898639, 0.53750362, 0.53866203,\n",
       "                     0.55980307, 0.56125109, 0.56704315, 0.57775847, 0.58210252,\n",
       "                     0.60787721, 0.61106284, 0.64755285, 0.65797857, 0.68027802,\n",
       "                     0.68867651, 0.6964958 , 0.71213438, 0.713872  , 0.71618882,\n",
       "                     0.7318274 , 0.73327541, 0.75065161, 0.78945844, 0.79351289,\n",
       "                     0.81175789, 0.81436432, 0.81668115, 0.82536924, 0.82652766,\n",
       "                     0.82942369, 0.83174052, 0.83666377, 0.8479583 , 0.85027512,\n",
       "                     0.85403997, 0.85461917, 0.8575152 , 0.85838401, 0.86359687,\n",
       "                     0.8664929 , 0.875181  , 0.88155227, 0.89081958, 0.89400521,\n",
       "                     0.90761657, 0.91601506, 0.92093831, 0.95192586, 0.95684912,\n",
       "                     0.95887634, 0.96379959, 0.96640602, 0.96843325, 0.97132928,\n",
       "                     0.97161888, 0.97451491, 0.98001738, 0.98262381, 0.98291341,\n",
       "                     0.98436142, 0.98551984, 0.99015349, 0.9907327 , 0.9913119 ,\n",
       "                     1.        ]), tpr=array([0.        , 0.07730026, 0.11825786, 0.12316123, 0.14710124,\n",
       "                     0.15488895, 0.16959908, 0.17190655, 0.19296222, 0.19469282,\n",
       "                     0.19930776, 0.21401788, 0.22382463, 0.27776175, 0.283242  ,\n",
       "                     0.2858379 , 0.31987309, 0.32102682, 0.33025671, 0.33429478,\n",
       "                     0.35938852, 0.36256129, 0.37236804, 0.39861552, 0.40899913,\n",
       "                     0.41332564, 0.43841938, 0.46034035, 0.46466686, 0.50591289,\n",
       "                     0.50648976, 0.51571964, 0.51946928, 0.56475339, 0.56561869,\n",
       "                     0.58263628, 0.58407845, 0.59100087, 0.60484569, 0.60917219,\n",
       "                     0.6348428 , 0.63743871, 0.67003173, 0.68358812, 0.70493222,\n",
       "                     0.71271993, 0.71935391, 0.73896741, 0.74012114, 0.74329391,\n",
       "                     0.75396596, 0.75454283, 0.77098356, 0.81222959, 0.8165561 ,\n",
       "                     0.83184309, 0.834439  , 0.8370349 , 0.84164984, 0.84309201,\n",
       "                     0.84713008, 0.84972599, 0.85607153, 0.86299394, 0.86501298,\n",
       "                     0.86818575, 0.86905105, 0.87107009, 0.87424286, 0.88116527,\n",
       "                     0.88606865, 0.89443323, 0.89962504, 0.90510528, 0.90943179,\n",
       "                     0.92327661, 0.92933372, 0.93366022, 0.96769541, 0.97202192,\n",
       "                     0.97432939, 0.97807903, 0.98096337, 0.98240554, 0.98528988,\n",
       "                     0.98615518, 0.98875108, 0.99336602, 0.99538506, 0.99596193,\n",
       "                     0.9974041 , 0.99798096, 0.9991347 , 0.99971157, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.29441557e-02, -5.71584138e-02,\n",
       "                     -7.24955020e-02, -8.16780310e-02, -1.11225635e-01, -1.17783036e-01,\n",
       "                     -1.25880246e-01, -1.27833372e-01, -1.33531393e-01, -1.40146632e-01,\n",
       "                     -1.54150680e-01, -1.57963113e-01, -1.67054085e-01, -2.00670695e-01,\n",
       "                     -2.02073712e-01, -2.07639365e-01, -2.09720531e-01, -2.23143551e-01,\n",
       "                     -2.34572247e-01, -2.36388778e-01, -2.38411023e-01, -2.51314428e-01,\n",
       "                     -2.66628663e-01, -2.75411980e-01, -2.83305698e-01, -2.87682072e-01,\n",
       "                     -2.99242895e-01, -3.05013529e-01, -3.10154928e-01, -3.14115330e-01,\n",
       "                     -3.15081047e-01, -3.19308310e-01, -3.22773392e-01, -3.29181803e-01,\n",
       "                     -3.36472237e-01, -3.48306694e-01, -3.54057141e-01, -3.72675285e-01,\n",
       "                     -3.77134601e-01, -3.82992252e-01, -4.02510896e-01, -4.05465108e-01,\n",
       "                     -4.12154096e-01, -4.17735201e-01, -4.19853846e-01, -4.24883194e-01,\n",
       "                     -4.27444015e-01, -4.28995606e-01, -4.34038481e-01, -4.41832752e-01,\n",
       "                     -4.57690369e-01, -4.62105387e-01, -4.70003629e-01, -4.74622575e-01,\n",
       "                     -4.79573080e-01, -4.81838087e-01, -4.85507816e-01, -4.94696242e-01,\n",
       "                     -4.96436886e-01, -5.10825624e-01, -5.19875459e-01, -5.21296924e-01,\n",
       "                     -5.26093096e-01, -5.29259325e-01, -5.30628251e-01, -5.38996501e-01,\n",
       "                     -5.41597282e-01, -5.59615788e-01, -5.67984038e-01, -5.74285978e-01,\n",
       "                     -5.81029882e-01, -5.81921545e-01, -5.87786665e-01, -5.91097926e-01,\n",
       "                     -6.00773860e-01, -6.06135804e-01, -6.12517446e-01, -6.15760517e-01,\n",
       "                     -6.28608659e-01, -6.58055861e-01, -6.93147181e-01, -7.88457360e-01,\n",
       "                     -8.10930216e-01, -8.47297860e-01, -8.75468737e-01, -9.16290732e-01,\n",
       "                     -9.44461609e-01, -1.09861229e+00, -1.22377543e+00, -1.25276297e+00,\n",
       "                     -1.60943791e+00, -2.07944154e+00, -2.48490665e+00, -3.45387764e+01]), auc_score=0.5173268693421595, privacy_risk=0.5136248845283289, accuracy=0.5136248845283289, tpr_ind=0.5647533890972022, tnr_ind=0.46249637995945553, test_train_ratio=0.9959619267378137, dataset_size=[3467, 3453]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.12137578, 0.12734508, 0.13786242, 0.14553724,\n",
       "                     0.14923252, 0.15378056, 0.16117112, 0.17168846, 0.17538374,\n",
       "                     0.17765776, 0.17907902, 0.18135304, 0.1941444 , 0.24530984,\n",
       "                     0.2586697 , 0.29306424, 0.29903354, 0.30699261, 0.30756111,\n",
       "                     0.31495168, 0.31836271, 0.32774304, 0.33371234, 0.34451393,\n",
       "                     0.35531552, 0.36299034, 0.39681637, 0.40449119, 0.42069358,\n",
       "                     0.43831723, 0.45082433, 0.46304719, 0.46674247, 0.47271177,\n",
       "                     0.4766913 , 0.48095509, 0.48607163, 0.51222285, 0.55486072,\n",
       "                     0.56253553, 0.5758954 , 0.59010802, 0.5943718 , 0.59664582,\n",
       "                     0.61028994, 0.64383172, 0.65946561, 0.67936327, 0.68959636,\n",
       "                     0.7055145 , 0.72057987, 0.72683343, 0.72967595, 0.73791927,\n",
       "                     0.74047754, 0.75724844, 0.7700398 , 0.78055713, 0.79050597,\n",
       "                     0.79533826, 0.8004548 , 0.81296191, 0.82660603, 0.83541785,\n",
       "                     0.87464468, 0.88345651, 0.89226833, 0.89511086, 0.89653212,\n",
       "                     0.89937464, 0.90505969, 0.91245026, 0.92978965, 0.9354747 ,\n",
       "                     0.9408755 , 0.9533826 , 0.95650938, 0.95764639, 0.95992041,\n",
       "                     0.96560546, 0.96674247, 0.97299602, 0.97356453, 0.98521887,\n",
       "                     0.98919841, 0.98919841, 0.98948266, 0.99175668, 1.        ]), tpr=array([0.        , 0.11963551, 0.12463257, 0.13903586, 0.14902998,\n",
       "                     0.15196943, 0.16108172, 0.16843034, 0.1787184 , 0.1845973 ,\n",
       "                     0.18694885, 0.18959436, 0.19194591, 0.20399765, 0.26308054,\n",
       "                     0.27425044, 0.30952381, 0.31657848, 0.32686655, 0.32951205,\n",
       "                     0.33568489, 0.33980012, 0.34685479, 0.35273369, 0.36478542,\n",
       "                     0.37742504, 0.38418577, 0.41857731, 0.42886537, 0.44385655,\n",
       "                     0.46737213, 0.48206937, 0.4914756 , 0.49617872, 0.5026455 ,\n",
       "                     0.50646678, 0.51175779, 0.51704879, 0.54320988, 0.57907113,\n",
       "                     0.58465608, 0.59847149, 0.61493239, 0.62198707, 0.62580835,\n",
       "                     0.64226925, 0.67166373, 0.6845973 , 0.70135215, 0.7122281 ,\n",
       "                     0.72721928, 0.74279835, 0.75073486, 0.75602587, 0.76337449,\n",
       "                     0.76866549, 0.78101117, 0.79453263, 0.80687831, 0.81804821,\n",
       "                     0.82363316, 0.82716049, 0.83656673, 0.84832451, 0.86037625,\n",
       "                     0.90005879, 0.91122869, 0.91798942, 0.92151675, 0.92416226,\n",
       "                     0.9271017 , 0.92974721, 0.93709583, 0.95620223, 0.95972957,\n",
       "                     0.96472663, 0.97707231, 0.97883598, 0.9803057 , 0.98148148,\n",
       "                     0.9861846 , 0.98677249, 0.99118166, 0.99206349, 0.99617872,\n",
       "                     0.99853028, 0.99882422, 0.99941211, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.15062052e-02, -3.77403280e-02,\n",
       "                     -4.25596144e-02, -6.06246218e-02, -7.79615415e-02, -9.01510970e-02,\n",
       "                     -9.30904231e-02, -9.53101798e-02, -1.00083459e-01, -1.05360516e-01,\n",
       "                     -1.17783036e-01, -1.63453072e-01, -1.64755233e-01, -1.68820870e-01,\n",
       "                     -1.82321557e-01, -1.89242000e-01, -1.98850859e-01, -2.00670695e-01,\n",
       "                     -2.11843996e-01, -2.23143551e-01, -2.35314087e-01, -2.36388778e-01,\n",
       "                     -2.37671652e-01, -2.38411023e-01, -2.51314428e-01, -2.55105902e-01,\n",
       "                     -2.85320796e-01, -2.87682072e-01, -2.92387963e-01, -2.92669614e-01,\n",
       "                     -2.95464213e-01, -3.00104592e-01, -3.10154928e-01, -3.25422400e-01,\n",
       "                     -3.26684230e-01, -3.46870944e-01, -3.47645537e-01, -3.49270550e-01,\n",
       "                     -3.51397887e-01, -3.56674944e-01, -3.69097464e-01, -3.77294231e-01,\n",
       "                     -3.79489622e-01, -3.81367557e-01, -3.89464767e-01, -3.90197636e-01,\n",
       "                     -3.92561703e-01, -3.95312737e-01, -4.05465108e-01, -4.08696129e-01,\n",
       "                     -4.15515444e-01, -4.17299566e-01, -4.32133355e-01, -4.41832752e-01,\n",
       "                     -4.50505834e-01, -4.50927482e-01, -4.70003629e-01, -4.77329669e-01,\n",
       "                     -4.89548225e-01, -5.10825624e-01, -5.22386446e-01, -5.30628251e-01,\n",
       "                     -5.36801110e-01, -5.40440544e-01, -5.45016989e-01, -5.50046337e-01,\n",
       "                     -5.59615788e-01, -5.75364145e-01, -5.87786665e-01, -5.93063722e-01,\n",
       "                     -6.31271777e-01, -6.43314807e-01, -6.50587566e-01, -6.93147181e-01,\n",
       "                     -7.13766468e-01, -7.73189888e-01, -7.88457360e-01, -8.10930216e-01,\n",
       "                     -8.47297860e-01, -9.16290732e-01, -9.55511445e-01, -9.80829253e-01,\n",
       "                     -1.09861229e+00, -1.38629436e+00, -1.60943791e+00, -1.70474809e+00,\n",
       "                     -1.79175947e+00, -3.45387764e+01]), auc_score=0.5190967156730533, privacy_risk=0.5159896579579479, accuracy=0.5159896579579479, tpr_ind=0.6422692533803644, tnr_ind=0.38971006253553153, test_train_ratio=1.0340975896531452, dataset_size=[3402, 3518]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.09634743, 0.1078516 , 0.11159045, 0.11302847,\n",
       "                     0.13114754, 0.15070463, 0.15645672, 0.16566005, 0.16968651,\n",
       "                     0.17457578, 0.17687662, 0.19700892, 0.20477423, 0.21052632,\n",
       "                     0.21340236, 0.21426517, 0.22116767, 0.2231809 , 0.22576934,\n",
       "                     0.23209664, 0.24532643, 0.24733966, 0.25625539, 0.25855623,\n",
       "                     0.32499281, 0.3307449 , 0.34656313, 0.35231521, 0.35547886,\n",
       "                     0.36266897, 0.37043428, 0.37359793, 0.37791199, 0.38251366,\n",
       "                     0.391717  , 0.39545585, 0.40235835, 0.40782284, 0.41702617,\n",
       "                     0.4259419 , 0.43370722, 0.44492378, 0.47742307, 0.50848433,\n",
       "                     0.51136037, 0.51912568, 0.52430256, 0.53062985, 0.53293069,\n",
       "                     0.53695715, 0.55996549, 0.56485476, 0.57233247, 0.58930112,\n",
       "                     0.594478  , 0.59735404, 0.608283  , 0.62007478, 0.62496405,\n",
       "                     0.63215416, 0.63761864, 0.65631291, 0.66062698, 0.67356917,\n",
       "                     0.68075928, 0.68794938, 0.69226345, 0.70002876, 0.70491803,\n",
       "                     0.72792637, 0.73051481, 0.73137762, 0.73454127, 0.75639919,\n",
       "                     0.75870003, 0.76589014, 0.77394305, 0.80069025, 0.81449525,\n",
       "                     0.82312338, 0.82801265, 0.83232672, 0.83433995, 0.85274662,\n",
       "                     0.85389704, 0.85849871, 0.8645384 , 0.87259131, 0.87604257,\n",
       "                     0.87748059, 0.88294507, 0.88380788, 0.88639632, 0.89991372,\n",
       "                     0.9056658 , 0.91113028, 0.93385102, 0.93874029, 0.94334196,\n",
       "                     0.94938165, 0.95427092, 0.95829738, 0.96261145, 0.96347426,\n",
       "                     0.96577509, 0.9660627 , 0.97354041, 0.97526603, 0.97814208,\n",
       "                     0.97900489, 0.98159333, 0.98188093, 0.98475697, 0.98993385,\n",
       "                     0.99079666, 0.99137187, 1.        ]), tpr=array([0.        , 0.10659309, 0.11472553, 0.1190822 , 0.12285797,\n",
       "                     0.14144641, 0.16642463, 0.17107174, 0.17891374, 0.18414174,\n",
       "                     0.1937264 , 0.19604996, 0.21899506, 0.22770839, 0.23671217,\n",
       "                     0.23874528, 0.24194017, 0.24832994, 0.24978217, 0.25355794,\n",
       "                     0.25907639, 0.27272727, 0.27446994, 0.28492594, 0.28870171,\n",
       "                     0.35957014, 0.3645077 , 0.38367703, 0.38716236, 0.38977636,\n",
       "                     0.39761836, 0.40604124, 0.40749347, 0.41243102, 0.41475457,\n",
       "                     0.42492013, 0.43014813, 0.43828057, 0.44379901, 0.45715945,\n",
       "                     0.46877723, 0.47749056, 0.490851  , 0.52860877, 0.55968632,\n",
       "                     0.56288121, 0.57449898, 0.5785652 , 0.58582631, 0.58756898,\n",
       "                     0.59018298, 0.60760964, 0.61196631, 0.61864653, 0.6354923 ,\n",
       "                     0.63984897, 0.64478652, 0.65698519, 0.66918385, 0.67557363,\n",
       "                     0.68022074, 0.68602963, 0.70461807, 0.70839384, 0.71943073,\n",
       "                     0.72814406, 0.73308161, 0.74005228, 0.75021783, 0.75544583,\n",
       "                     0.77926227, 0.78129538, 0.7827476 , 0.78652338, 0.80162649,\n",
       "                     0.80482138, 0.81324426, 0.81876271, 0.83996515, 0.85158292,\n",
       "                     0.85623003, 0.85913448, 0.86349114, 0.8658147 , 0.88643625,\n",
       "                     0.88817891, 0.8939878 , 0.89892536, 0.91083358, 0.91693291,\n",
       "                     0.91925646, 0.92448446, 0.92622713, 0.92855068, 0.93581179,\n",
       "                     0.94162068, 0.94684868, 0.96166134, 0.96601801, 0.96805112,\n",
       "                     0.9718269 , 0.97618356, 0.97937845, 0.981702  , 0.98228289,\n",
       "                     0.98605867, 0.98693   , 0.99041534, 0.99157711, 0.99390067,\n",
       "                     0.994772  , 0.99680511, 0.99680511, 0.99854778, 0.99941911,\n",
       "                     0.99970956, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.17486983e-02, -4.08219945e-02,\n",
       "                     -7.41079722e-02, -7.52234212e-02, -7.82521969e-02, -8.00427077e-02,\n",
       "                     -8.70113770e-02, -1.05360516e-01, -1.14410351e-01, -1.17783036e-01,\n",
       "                     -1.32873281e-01, -1.33531393e-01, -1.45711811e-01, -1.62518929e-01,\n",
       "                     -1.67054085e-01, -1.71850257e-01, -1.82321557e-01, -1.90043603e-01,\n",
       "                     -1.91055237e-01, -1.92903666e-01, -1.94156014e-01, -2.00670695e-01,\n",
       "                     -2.03598955e-01, -2.09942039e-01, -2.11309094e-01, -2.17064505e-01,\n",
       "                     -2.23143551e-01, -2.29574442e-01, -2.30523659e-01, -2.44453338e-01,\n",
       "                     -2.51314428e-01, -2.57045103e-01, -2.57829109e-01, -2.73597333e-01,\n",
       "                     -2.76986783e-01, -2.79171383e-01, -2.87682072e-01, -3.14493330e-01,\n",
       "                     -3.18453731e-01, -3.24239668e-01, -3.30241687e-01, -3.30962581e-01,\n",
       "                     -3.31117471e-01, -3.36472237e-01, -3.54821375e-01, -3.56674944e-01,\n",
       "                     -3.61013346e-01, -3.62905494e-01, -3.67724780e-01, -3.71563556e-01,\n",
       "                     -3.72675285e-01, -3.74693449e-01, -3.82606970e-01, -3.82992252e-01,\n",
       "                     -3.85662481e-01, -3.86233746e-01, -3.89464767e-01, -4.05465108e-01,\n",
       "                     -4.11979789e-01, -4.13763911e-01, -4.15827895e-01, -4.21994410e-01,\n",
       "                     -4.22856851e-01, -4.25667815e-01, -4.32133355e-01, -4.32864082e-01,\n",
       "                     -4.33635985e-01, -4.41832752e-01, -4.45311017e-01, -4.51985124e-01,\n",
       "                     -4.70003629e-01, -4.79573080e-01, -4.91407538e-01, -4.92476485e-01,\n",
       "                     -4.98991166e-01, -5.10825624e-01, -5.13561604e-01, -5.15813165e-01,\n",
       "                     -5.28844129e-01, -5.30628251e-01, -5.50046337e-01, -5.59615788e-01,\n",
       "                     -5.65633860e-01, -5.79818495e-01, -5.87786665e-01, -6.00773860e-01,\n",
       "                     -6.17161274e-01, -6.19039208e-01, -6.28608659e-01, -6.38087403e-01,\n",
       "                     -6.41853886e-01, -6.72093771e-01, -6.93147181e-01, -7.05569701e-01,\n",
       "                     -7.25937003e-01, -7.41003202e-01, -7.57685702e-01, -7.62140052e-01,\n",
       "                     -7.67255153e-01, -7.88457360e-01, -7.96331417e-01, -8.10930216e-01,\n",
       "                     -8.32909123e-01, -8.36248024e-01, -8.47297860e-01, -8.60201265e-01,\n",
       "                     -9.16290732e-01, -9.29535959e-01, -9.80829253e-01, -1.09861229e+00,\n",
       "                     -1.25276297e+00, -1.29928298e+00, -1.38629436e+00, -1.50407740e+00,\n",
       "                     -2.30258509e+00, -3.45387764e+01]), auc_score=0.5332635247718482, privacy_risk=0.5276866501922806, accuracy=0.5276866501922806, tpr_ind=0.5744989834446703, tnr_ind=0.4808743169398907, test_train_ratio=1.0098751089166424, dataset_size=[3443, 3477]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.07307132, 0.08238719, 0.10101892, 0.10684134,\n",
       "                     0.11237263, 0.13799127, 0.14992722, 0.15429403, 0.15720524,\n",
       "                     0.18282387, 0.19068413, 0.22037846, 0.2224163 , 0.22620087,\n",
       "                     0.22765648, 0.24366812, 0.24454148, 0.24570597, 0.25007278,\n",
       "                     0.27860262, 0.28558952, 0.29286754, 0.29665211, 0.30247453,\n",
       "                     0.31528384, 0.31761281, 0.37641921, 0.38486172, 0.39388646,\n",
       "                     0.41280932, 0.41834061, 0.41892285, 0.46113537, 0.48879185,\n",
       "                     0.49403202, 0.49839884, 0.54934498, 0.61193595, 0.61688501,\n",
       "                     0.62852984, 0.63114993, 0.64104803, 0.65298399, 0.6588064 ,\n",
       "                     0.66200873, 0.69199418, 0.69781659, 0.70276565, 0.71208151,\n",
       "                     0.71499272, 0.71732169, 0.71994178, 0.7231441 , 0.74556041,\n",
       "                     0.75633188, 0.76419214, 0.76943231, 0.77088792, 0.8055313 ,\n",
       "                     0.81863173, 0.84745269, 0.84861718, 0.85705968, 0.87103348,\n",
       "                     0.87481805, 0.88093159, 0.88558952, 0.90800582, 0.913246  ,\n",
       "                     0.91935953, 0.9202329 , 0.93333333, 0.93449782, 0.94090247,\n",
       "                     0.95080058, 0.96040757, 0.96069869, 0.96622999, 0.97292576,\n",
       "                     0.97321689, 0.97496361, 0.97671033, 0.9790393 , 0.98369723,\n",
       "                     0.98427948, 0.98544396, 0.98864629, 0.98951965, 0.9915575 ,\n",
       "                     1.        ]), tpr=array([0.        , 0.07173601, 0.08120516, 0.09583931, 0.10272597,\n",
       "                     0.11162123, 0.14146341, 0.15150646, 0.15781923, 0.16413199,\n",
       "                     0.18995696, 0.20114778, 0.23443329, 0.23672884, 0.24045911,\n",
       "                     0.24447633, 0.26083214, 0.26341463, 0.26456241, 0.26944046,\n",
       "                     0.2989957 , 0.30502152, 0.31305595, 0.31822095, 0.32137733,\n",
       "                     0.33572453, 0.33974175, 0.40172166, 0.40832138, 0.41865136,\n",
       "                     0.43730273, 0.44304161, 0.44418938, 0.48608321, 0.51563845,\n",
       "                     0.52223816, 0.52912482, 0.58163558, 0.63931133, 0.64505022,\n",
       "                     0.65480631, 0.65824964, 0.66829268, 0.68723099, 0.69440459,\n",
       "                     0.6964132 , 0.71994261, 0.72625538, 0.73170732, 0.74060258,\n",
       "                     0.74261119, 0.74519369, 0.74662841, 0.7517934 , 0.77274032,\n",
       "                     0.78134864, 0.79167862, 0.79913917, 0.80057389, 0.83414634,\n",
       "                     0.84476327, 0.87403156, 0.87546628, 0.88579627, 0.89698709,\n",
       "                     0.90071736, 0.90588235, 0.90961263, 0.92998565, 0.93342898,\n",
       "                     0.93830703, 0.94002869, 0.95265423, 0.95408895, 0.95753228,\n",
       "                     0.9661406 , 0.97474892, 0.97560976, 0.98077475, 0.98536585,\n",
       "                     0.98593974, 0.98766141, 0.98995696, 0.99311334, 0.99655667,\n",
       "                     0.9974175 , 0.99799139, 0.99942611, 0.99971306, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.76995771e-02, -1.94180859e-02,\n",
       "                     -4.08219945e-02, -5.21857532e-02, -5.40672213e-02, -7.14589640e-02,\n",
       "                     -7.41079722e-02, -8.70113770e-02, -1.24126067e-01, -1.33531393e-01,\n",
       "                     -1.36758937e-01, -1.43100844e-01, -1.46603474e-01, -1.54150680e-01,\n",
       "                     -1.76456437e-01, -1.78248231e-01, -1.82321557e-01, -1.89242000e-01,\n",
       "                     -2.09458098e-01, -2.13574100e-01, -2.16223108e-01, -2.23143551e-01,\n",
       "                     -2.41162057e-01, -2.46860078e-01, -2.51314428e-01, -2.52342706e-01,\n",
       "                     -2.65703166e-01, -2.66628663e-01, -2.68263987e-01, -2.75411980e-01,\n",
       "                     -2.87682072e-01, -3.06455187e-01, -3.06913434e-01, -3.08735482e-01,\n",
       "                     -3.11436158e-01, -3.23299708e-01, -3.31484695e-01, -3.36472237e-01,\n",
       "                     -3.44840486e-01, -3.52220594e-01, -3.56674944e-01, -3.64222150e-01,\n",
       "                     -3.70018359e-01, -3.74693449e-01, -3.82475590e-01, -3.85662481e-01,\n",
       "                     -3.87765531e-01, -4.05465108e-01, -4.21213465e-01, -4.30782916e-01,\n",
       "                     -4.35318071e-01, -4.41832752e-01, -4.45739007e-01, -4.48950220e-01,\n",
       "                     -4.49402811e-01, -4.51985124e-01, -4.70003629e-01, -4.74268028e-01,\n",
       "                     -4.80585739e-01, -4.91686284e-01, -5.10825624e-01, -5.12710638e-01,\n",
       "                     -5.24524468e-01, -5.26093096e-01, -5.43615447e-01, -5.59615788e-01,\n",
       "                     -5.60460739e-01, -5.65313809e-01, -6.00773860e-01, -6.06135804e-01,\n",
       "                     -6.19039208e-01, -6.53926467e-01, -6.69049629e-01, -6.75447603e-01,\n",
       "                     -6.93147181e-01, -7.53771802e-01, -7.98507696e-01, -8.10930216e-01,\n",
       "                     -8.26678573e-01, -8.47297860e-01, -9.16290732e-01, -9.75379648e-01,\n",
       "                     -1.09861229e+00, -1.20397280e+00, -1.25276297e+00, -1.38629436e+00,\n",
       "                     -1.60943791e+00, -2.07944154e+00, -3.45387764e+01]), auc_score=0.51998989221847, privacy_risk=0.5177990932234008, accuracy=0.5177990932234008, tpr_ind=0.6944045911047346, tnr_ind=0.34119359534206695, test_train_ratio=0.9856527977044476, dataset_size=[3485, 3435]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.10217264, 0.1274222 , 0.13270699, 0.14357017,\n",
       "                     0.14914856, 0.16147974, 0.16470934, 0.16823253, 0.16881973,\n",
       "                     0.17351732, 0.17968291, 0.18320611, 0.1887845 , 0.19260129,\n",
       "                     0.21168526, 0.21491486, 0.22460364, 0.23076923, 0.24163241,\n",
       "                     0.34057546, 0.34527305, 0.35085144, 0.36964181, 0.40927775,\n",
       "                     0.41015854, 0.42571932, 0.43335291, 0.44685849, 0.45184968,\n",
       "                     0.46212566, 0.46594245, 0.46917205, 0.51350558, 0.51761597,\n",
       "                     0.52378156, 0.53288315, 0.54110393, 0.55490311, 0.5622431 ,\n",
       "                     0.56723429, 0.58485026, 0.59130945, 0.60011744, 0.60804463,\n",
       "                     0.60951262, 0.6259542 , 0.63006459, 0.63300059, 0.63652378,\n",
       "                     0.66382854, 0.69495009, 0.71374046, 0.71550206, 0.76394598,\n",
       "                     0.77422196, 0.78508514, 0.79213153, 0.80299472, 0.8115091 ,\n",
       "                     0.81679389, 0.82090429, 0.82413388, 0.82648268, 0.83382267,\n",
       "                     0.86142102, 0.86934821, 0.8752202 , 0.87903699, 0.89019378,\n",
       "                     0.89136817, 0.89988256, 0.91573693, 0.92307692, 0.9374633 ,\n",
       "                     0.94069289, 0.94539049, 0.95860247, 0.96388726, 0.97034645,\n",
       "                     0.97181445, 0.97563124, 0.97680564, 0.97915443, 0.98150323,\n",
       "                     0.98326483, 0.98649442, 0.98796242, 0.99031122, 1.        ]), tpr=array([0.        , 0.09903244, 0.12379055, 0.1303358 , 0.13574274,\n",
       "                     0.14257257, 0.15480933, 0.15936255, 0.16562322, 0.1670461 ,\n",
       "                     0.17245304, 0.18298236, 0.18554354, 0.18924303, 0.19294252,\n",
       "                     0.21314741, 0.21741605, 0.23335231, 0.24473534, 0.25554923,\n",
       "                     0.37421742, 0.38047809, 0.38958452, 0.40751281, 0.44649972,\n",
       "                     0.44849175, 0.46528173, 0.47381901, 0.49089357, 0.4988617 ,\n",
       "                     0.51024474, 0.51394422, 0.51735913, 0.56061468, 0.56715993,\n",
       "                     0.57285145, 0.58110415, 0.59134889, 0.60500854, 0.61240751,\n",
       "                     0.62066022, 0.64769493, 0.65310188, 0.65793967, 0.66334661,\n",
       "                     0.66448492, 0.6812749 , 0.68639727, 0.69009676, 0.6943654 ,\n",
       "                     0.72140011, 0.74558907, 0.76010245, 0.76266363, 0.8044963 ,\n",
       "                     0.81445646, 0.82384747, 0.82925441, 0.84462151, 0.85600455,\n",
       "                     0.86112692, 0.86340353, 0.86767217, 0.87051793, 0.87905521,\n",
       "                     0.90210586, 0.90808196, 0.91149687, 0.91519636, 0.92430279,\n",
       "                     0.92572567, 0.93540125, 0.94422311, 0.94963005, 0.96357427,\n",
       "                     0.96755834, 0.97211155, 0.97837223, 0.98178714, 0.9846329 ,\n",
       "                     0.98662493, 0.99032442, 0.99117814, 0.99317018, 0.99630051,\n",
       "                     0.99743882, 0.99829254, 0.99914627, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.57483570e-02, -4.25596144e-02,\n",
       "                     -4.54623741e-02, -4.87901642e-02, -5.48082365e-02, -6.06246218e-02,\n",
       "                     -8.70113770e-02, -9.53101798e-02, -1.00083459e-01, -1.02654154e-01,\n",
       "                     -1.05360516e-01, -1.13328685e-01, -1.17783036e-01, -1.21645109e-01,\n",
       "                     -1.25163143e-01, -1.33531393e-01, -1.54150680e-01, -1.82321557e-01,\n",
       "                     -1.95424782e-01, -2.04794413e-01, -2.23143551e-01, -2.26313126e-01,\n",
       "                     -2.27513551e-01, -2.51314428e-01, -2.53195896e-01, -2.62364264e-01,\n",
       "                     -2.75103290e-01, -2.78713402e-01, -2.81412459e-01, -2.82232468e-01,\n",
       "                     -2.87682072e-01, -2.94239473e-01, -2.98492989e-01, -3.00104592e-01,\n",
       "                     -3.07025035e-01, -3.08301360e-01, -3.11779624e-01, -3.18453731e-01,\n",
       "                     -3.21583624e-01, -3.28925031e-01, -3.36472237e-01, -3.44840486e-01,\n",
       "                     -3.51397887e-01, -3.56674944e-01, -3.57609087e-01, -3.67724780e-01,\n",
       "                     -3.79489622e-01, -3.82992252e-01, -3.94882999e-01, -4.05465108e-01,\n",
       "                     -4.38008656e-01, -4.41832752e-01, -4.43289417e-01, -4.51985124e-01,\n",
       "                     -4.54736157e-01, -4.60815203e-01, -4.65683968e-01, -4.70003629e-01,\n",
       "                     -4.76924072e-01, -4.85507816e-01, -4.90622916e-01, -4.98991166e-01,\n",
       "                     -5.10825624e-01, -5.49634899e-01, -5.51735527e-01, -5.59615788e-01,\n",
       "                     -5.70544858e-01, -5.77315365e-01, -5.87786665e-01, -6.03916047e-01,\n",
       "                     -6.09064063e-01, -6.39079959e-01, -6.51474484e-01, -6.56779536e-01,\n",
       "                     -6.61398482e-01, -6.93147181e-01, -7.95801335e-01, -8.75468737e-01,\n",
       "                     -8.87303195e-01, -8.93817876e-01, -9.16290732e-01, -9.98528830e-01,\n",
       "                     -1.09861229e+00, -1.17865500e+00, -1.20397280e+00, -1.29928298e+00,\n",
       "                     -1.38629436e+00, -3.45387764e+01]), auc_score=0.5300960824097286, privacy_risk=0.5314223351539735, accuracy=0.5314223351539735, tpr_ind=0.6476949345475241, tnr_ind=0.4151497357604228, test_train_ratio=0.9692657939669892, dataset_size=[3514, 3406]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.09682081, 0.14768786, 0.14942197, 0.15086705,\n",
       "                     0.15375723, 0.17630058, 0.18294798, 0.19219653, 0.19219653,\n",
       "                     0.19739884, 0.20144509, 0.20202312, 0.23265896, 0.2583815 ,\n",
       "                     0.25953757, 0.26069364, 0.28092486, 0.28872832, 0.29624277,\n",
       "                     0.29884393, 0.30520231, 0.31763006, 0.34075145, 0.35115607,\n",
       "                     0.37080925, 0.37630058, 0.38352601, 0.38815029, 0.39046243,\n",
       "                     0.39653179, 0.4       , 0.40520231, 0.42196532, 0.4265896 ,\n",
       "                     0.46820809, 0.50433526, 0.52109827, 0.52456647, 0.53208092,\n",
       "                     0.54450867, 0.55549133, 0.56618497, 0.62601156, 0.67601156,\n",
       "                     0.68757225, 0.69104046, 0.70346821, 0.72283237, 0.73323699,\n",
       "                     0.73872832, 0.73988439, 0.74277457, 0.74393064, 0.74855491,\n",
       "                     0.76618497, 0.78092486, 0.80578035, 0.80722543, 0.8650289 ,\n",
       "                     0.87716763, 0.88208092, 0.88294798, 0.88988439, 0.89393064,\n",
       "                     0.8982659 , 0.90578035, 0.91936416, 0.94104046, 0.9433526 ,\n",
       "                     0.95086705, 0.95346821, 0.95606936, 0.95867052, 0.96473988,\n",
       "                     0.96878613, 0.97514451, 0.97976879, 0.98468208, 0.98612717,\n",
       "                     0.98699422, 0.98757225, 0.99017341, 1.        ]), tpr=array([0.        , 0.10086705, 0.16040462, 0.16647399, 0.1699422 ,\n",
       "                     0.17225434, 0.19884393, 0.20578035, 0.21098266, 0.21213873,\n",
       "                     0.21763006, 0.22283237, 0.22312139, 0.25202312, 0.28063584,\n",
       "                     0.28236994, 0.28554913, 0.31069364, 0.31589595, 0.3234104 ,\n",
       "                     0.32601156, 0.33092486, 0.34190751, 0.36676301, 0.37485549,\n",
       "                     0.39537572, 0.40231214, 0.40635838, 0.41213873, 0.41705202,\n",
       "                     0.42485549, 0.43063584, 0.43381503, 0.45578035, 0.46473988,\n",
       "                     0.50722543, 0.55317919, 0.56936416, 0.57601156, 0.5849711 ,\n",
       "                     0.59768786, 0.60809249, 0.61878613, 0.6734104 , 0.72196532,\n",
       "                     0.73179191, 0.7349711 , 0.74393064, 0.76156069, 0.77369942,\n",
       "                     0.7783237 , 0.78092486, 0.78468208, 0.78612717, 0.79104046,\n",
       "                     0.81069364, 0.82427746, 0.84913295, 0.85115607, 0.90549133,\n",
       "                     0.91589595, 0.9199422 , 0.92109827, 0.92947977, 0.93526012,\n",
       "                     0.94017341, 0.9482659 , 0.9566474 , 0.9716763 , 0.9734104 ,\n",
       "                     0.9765896 , 0.98063584, 0.98179191, 0.98323699, 0.98757225,\n",
       "                     0.98872832, 0.99306358, 0.99508671, 0.99739884, 0.99884393,\n",
       "                     0.99942197, 0.99971098, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.80998462e-02, -4.65200156e-02,\n",
       "                     -5.71584138e-02, -6.45385211e-02, -6.73036819e-02, -8.00427077e-02,\n",
       "                     -9.18075493e-02, -9.53101798e-02, -1.00083459e-01, -1.05360516e-01,\n",
       "                     -1.17783036e-01, -1.39761942e-01, -1.41078598e-01, -1.54150680e-01,\n",
       "                     -1.67054085e-01, -1.78482780e-01, -1.82321557e-01, -1.92903666e-01,\n",
       "                     -2.00670695e-01, -2.11309094e-01, -2.12561442e-01, -2.18481538e-01,\n",
       "                     -2.23143551e-01, -2.32931558e-01, -2.46133070e-01, -2.51314428e-01,\n",
       "                     -2.54892250e-01, -2.57829109e-01, -2.60726262e-01, -2.62364264e-01,\n",
       "                     -2.66628663e-01, -2.74436846e-01, -2.79584862e-01, -2.87682072e-01,\n",
       "                     -2.92892356e-01, -3.22773392e-01, -3.30241687e-01, -3.36472237e-01,\n",
       "                     -3.42944751e-01, -3.66462950e-01, -3.69097464e-01, -3.69495632e-01,\n",
       "                     -3.81367557e-01, -3.85662481e-01, -3.92042088e-01, -4.05465108e-01,\n",
       "                     -4.14767501e-01, -4.21213465e-01, -4.37213806e-01, -4.41832752e-01,\n",
       "                     -4.64305608e-01, -4.70003629e-01, -4.98991166e-01, -5.07880114e-01,\n",
       "                     -5.10825624e-01, -5.15466003e-01, -5.38996501e-01, -5.39453018e-01,\n",
       "                     -5.43615447e-01, -5.48565952e-01, -5.59615788e-01, -5.64529803e-01,\n",
       "                     -5.85258219e-01, -6.00773860e-01, -6.19039208e-01, -6.93147181e-01,\n",
       "                     -7.02716632e-01, -7.73189888e-01, -7.77230298e-01, -8.10930216e-01,\n",
       "                     -8.47297860e-01, -8.75468737e-01, -9.02867712e-01, -9.16290732e-01,\n",
       "                     -9.80829253e-01, -1.09861229e+00, -1.17865500e+00, -1.38629436e+00,\n",
       "                     -1.60943791e+00, -1.94591015e+00, -2.19722458e+00, -3.45387764e+01]), auc_score=0.5310856109459053, privacy_risk=0.5265895953757225, accuracy=0.5265895953757225, tpr_ind=0.5976878612716763, tnr_ind=0.4554913294797688, test_train_ratio=1.0, dataset_size=[3460, 3460]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.09382997, 0.09980097, 0.10662496, 0.11060563,\n",
       "                     0.13079329, 0.13278362, 0.13363662, 0.14046062, 0.15098095,\n",
       "                     0.15154962, 0.15410862, 0.15553028, 0.16633494, 0.16974694,\n",
       "                     0.18083594, 0.20983793, 0.21154393, 0.22206426, 0.22775092,\n",
       "                     0.22917259, 0.23230026, 0.23684959, 0.23940859, 0.25419392,\n",
       "                     0.26755758, 0.27779357, 0.28205857, 0.2874609 , 0.33124822,\n",
       "                     0.33352289, 0.34262155, 0.34802388, 0.37418254, 0.38185954,\n",
       "                     0.38413421, 0.3909582 , 0.42706852, 0.43702019, 0.43957919,\n",
       "                     0.44441285, 0.44611885, 0.45436452, 0.46374751, 0.47000284,\n",
       "                     0.53625249, 0.55245948, 0.5902758 , 0.61302246, 0.62979812,\n",
       "                     0.63662212, 0.64543645, 0.64771112, 0.65396645, 0.65538811,\n",
       "                     0.65794711, 0.66221211, 0.66590844, 0.67813477, 0.68126244,\n",
       "                     0.70969576, 0.7125391 , 0.73471709, 0.73756042, 0.74324709,\n",
       "                     0.74609042, 0.74978675, 0.76059141, 0.76485641, 0.77423941,\n",
       "                     0.78049474, 0.78191641, 0.79499574, 0.80722206, 0.82058573,\n",
       "                     0.82797839, 0.84816605, 0.84987205, 0.86266705, 0.86437305,\n",
       "                     0.87517771, 0.87773671, 0.90133637, 0.90474837, 0.92522036,\n",
       "                     0.93801535, 0.96076201, 0.96531134, 0.96758601, 0.97042934,\n",
       "                     0.97412568, 0.97640034, 0.97696901, 0.98094967, 0.98578334,\n",
       "                     0.98748934, 0.990617  , 0.99175434, 0.99374467, 0.99431334,\n",
       "                     0.99545067, 0.99601933, 1.        ]), tpr=array([0.        , 0.11372319, 0.1178372 , 0.12371437, 0.12900382,\n",
       "                     0.14839847, 0.14957391, 0.1510432 , 0.16044666, 0.16720541,\n",
       "                     0.16779312, 0.17102557, 0.17190714, 0.18160447, 0.18542463,\n",
       "                     0.19806053, 0.22744637, 0.22920952, 0.23773141, 0.24684102,\n",
       "                     0.24977961, 0.25359976, 0.25683221, 0.25859536, 0.27828387,\n",
       "                     0.29121364, 0.30149868, 0.30384954, 0.30855128, 0.35439318,\n",
       "                     0.35733177, 0.36761681, 0.37584484, 0.40552454, 0.412871  ,\n",
       "                     0.41610344, 0.42256832, 0.46987952, 0.47957684, 0.48163385,\n",
       "                     0.48780488, 0.49074346, 0.4954452 , 0.50749339, 0.51248898,\n",
       "                     0.56920364, 0.58154569, 0.61798413, 0.64178666, 0.65765501,\n",
       "                     0.66206289, 0.67058478, 0.67411108, 0.68645313, 0.68821628,\n",
       "                     0.69144872, 0.69732589, 0.69967676, 0.70878636, 0.71407582,\n",
       "                     0.74052307, 0.74757567, 0.7663826 , 0.76961505, 0.7734352 ,\n",
       "                     0.77637379, 0.78254481, 0.79429915, 0.79900088, 0.80811049,\n",
       "                     0.81545695, 0.81751396, 0.82838672, 0.83925948, 0.84866294,\n",
       "                     0.85395239, 0.87099618, 0.87217161, 0.88039965, 0.88186894,\n",
       "                     0.89421099, 0.89597414, 0.91830738, 0.92036438, 0.94651778,\n",
       "                     0.95944755, 0.97825448, 0.98119306, 0.9823685 , 0.98354393,\n",
       "                     0.98707023, 0.98795181, 0.98853952, 0.99118425, 0.99382897,\n",
       "                     0.99559212, 0.99764913, 0.99823685, 0.99911842, 0.99941228,\n",
       "                     0.99970614, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.92207132e-02, -5.31098253e-02,\n",
       "                     -5.40672213e-02, -5.88405000e-02, -6.06246218e-02, -6.89928715e-02,\n",
       "                     -7.41079722e-02, -7.59859070e-02, -8.33816089e-02, -8.70113770e-02,\n",
       "                     -9.53101798e-02, -1.05360516e-01, -1.09199292e-01, -1.11225635e-01,\n",
       "                     -1.13328685e-01, -1.17783036e-01, -1.25163143e-01, -1.49531734e-01,\n",
       "                     -1.82321557e-01, -1.92903666e-01, -1.94156014e-01, -2.00670695e-01,\n",
       "                     -2.02026628e-01, -2.04794413e-01, -2.05852054e-01, -2.09720531e-01,\n",
       "                     -2.23143551e-01, -2.38411023e-01, -2.46860078e-01, -2.61364764e-01,\n",
       "                     -2.64692554e-01, -2.64784108e-01, -2.68263987e-01, -2.74436846e-01,\n",
       "                     -2.76253377e-01, -2.84571650e-01, -2.87682072e-01, -3.13657559e-01,\n",
       "                     -3.22773392e-01, -3.36472237e-01, -3.39867826e-01, -3.42406972e-01,\n",
       "                     -3.44840486e-01, -3.50437917e-01, -3.56674944e-01, -3.61501985e-01,\n",
       "                     -3.67146244e-01, -3.67724780e-01, -3.68907512e-01, -3.74693449e-01,\n",
       "                     -3.77294231e-01, -3.80055393e-01, -3.87765531e-01, -3.93042588e-01,\n",
       "                     -3.95895657e-01, -3.97682968e-01, -4.00477567e-01, -4.05465108e-01,\n",
       "                     -4.13370288e-01, -4.19258430e-01, -4.30102412e-01, -4.35318071e-01,\n",
       "                     -4.41832752e-01, -4.44685821e-01, -4.51985124e-01, -4.71714494e-01,\n",
       "                     -4.79573080e-01, -4.85507816e-01, -4.88352768e-01, -4.96436886e-01,\n",
       "                     -4.98991166e-01, -5.10825624e-01, -5.20304368e-01, -5.26093096e-01,\n",
       "                     -5.44727175e-01, -5.59615788e-01, -5.69352963e-01, -5.87786665e-01,\n",
       "                     -5.99118231e-01, -6.06135804e-01, -6.18026550e-01, -6.19039208e-01,\n",
       "                     -6.23351419e-01, -6.34306681e-01, -6.93147181e-01, -7.20546155e-01,\n",
       "                     -8.10930216e-01, -8.36248024e-01, -8.47297860e-01, -8.75468737e-01,\n",
       "                     -9.16290732e-01, -9.80829253e-01, -1.02165125e+00, -1.04145387e+00,\n",
       "                     -1.09861229e+00, -1.25276297e+00, -1.29928298e+00, -1.38629436e+00,\n",
       "                     -1.79175947e+00, -2.39789527e+00, -3.45387764e+01]), auc_score=0.5249683937244153, privacy_risk=0.5223123051788838, accuracy=0.5223123051788838, tpr_ind=0.49074346165148397, tnr_ind=0.5538811487062838, test_train_ratio=1.03349985307082, dataset_size=[3403, 3517]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.10668973, 0.13004614, 0.13869666, 0.14042676,\n",
       "                     0.14763552, 0.16551326, 0.17012687, 0.17416378, 0.17848904,\n",
       "                     0.18137255, 0.18137255, 0.18973472, 0.20184544, 0.20588235,\n",
       "                     0.20876586, 0.21020761, 0.21193772, 0.21683968, 0.22981546,\n",
       "                     0.23298731, 0.23846597, 0.24625144, 0.25086505, 0.25259516,\n",
       "                     0.35351788, 0.36937716, 0.36937716, 0.38408304, 0.39129181,\n",
       "                     0.41637832, 0.43858131, 0.44780854, 0.46309112, 0.49077278,\n",
       "                     0.49567474, 0.50288351, 0.50490196, 0.51038062, 0.52797001,\n",
       "                     0.54209919, 0.5449827 , 0.55680507, 0.56084198, 0.5893887 ,\n",
       "                     0.6150519 , 0.62572088, 0.6349481 , 0.64561707, 0.65859285,\n",
       "                     0.67445213, 0.67704729, 0.69809689, 0.71222607, 0.71337947,\n",
       "                     0.72635525, 0.73817762, 0.74279123, 0.76528258, 0.77595156,\n",
       "                     0.78921569, 0.80363322, 0.81084198, 0.82785467, 0.83044983,\n",
       "                     0.83246828, 0.89532872, 0.89705882, 0.90369089, 0.90484429,\n",
       "                     0.9083045 , 0.91291811, 0.91493656, 0.91926182, 0.92387543,\n",
       "                     0.92647059, 0.95732411, 0.96136101, 0.96366782, 0.96828143,\n",
       "                     0.96943483, 0.97174164, 0.977797  , 0.98471742, 0.98615917,\n",
       "                     0.98817762, 0.98846597, 0.98990773, 0.99019608, 0.99336794,\n",
       "                     1.        ]), tpr=array([0.        , 0.10486674, 0.12688297, 0.13557358, 0.13818076,\n",
       "                     0.14831981, 0.16425261, 0.16714948, 0.17265353, 0.17757822,\n",
       "                     0.17989571, 0.18192352, 0.1914832 , 0.20451912, 0.21002317,\n",
       "                     0.21436848, 0.2161066 , 0.2207416 , 0.2297219 , 0.24449594,\n",
       "                     0.24739282, 0.25434531, 0.26535342, 0.26911935, 0.2702781 ,\n",
       "                     0.3760139 , 0.39281576, 0.39339513, 0.40874855, 0.41454229,\n",
       "                     0.44495944, 0.46958285, 0.47566628, 0.49623407, 0.51911935,\n",
       "                     0.52752028, 0.53331402, 0.53534183, 0.54026651, 0.5585168 ,\n",
       "                     0.5721321 , 0.57589803, 0.59038239, 0.59588644, 0.62050985,\n",
       "                     0.64803013, 0.66193511, 0.67670915, 0.69090382, 0.70509849,\n",
       "                     0.72479722, 0.72914253, 0.75      , 0.76477404, 0.76593279,\n",
       "                     0.77520278, 0.7882387 , 0.79374276, 0.81402086, 0.82155272,\n",
       "                     0.83719583, 0.84849363, 0.85486674, 0.87224797, 0.87688297,\n",
       "                     0.87804171, 0.92873696, 0.93105446, 0.9368482 , 0.93771727,\n",
       "                     0.94032445, 0.94351101, 0.94553882, 0.9504635 , 0.95307068,\n",
       "                     0.95509849, 0.97682503, 0.97798378, 0.9797219 , 0.98406721,\n",
       "                     0.98493627, 0.98725377, 0.99015064, 0.99478563, 0.99478563,\n",
       "                     0.99710313, 0.99797219, 0.99913094, 0.99942063, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.13852162e-02, -5.97192347e-02,\n",
       "                     -6.89928715e-02, -8.22380982e-02, -8.70113770e-02, -9.53101798e-02,\n",
       "                     -9.68498260e-02, -1.11225635e-01, -1.25163143e-01, -1.33531393e-01,\n",
       "                     -1.41078598e-01, -1.41830195e-01, -1.43100844e-01, -1.48420005e-01,\n",
       "                     -1.54150680e-01, -1.58224005e-01, -1.58748389e-01, -1.79048231e-01,\n",
       "                     -1.82321557e-01, -1.89242000e-01, -1.91055237e-01, -1.92371893e-01,\n",
       "                     -1.94156014e-01, -2.04895879e-01, -2.16223108e-01, -2.23143551e-01,\n",
       "                     -2.46524000e-01, -2.53448901e-01, -2.58694536e-01, -2.84736562e-01,\n",
       "                     -2.87682072e-01, -2.91197015e-01, -2.93991242e-01, -2.96265816e-01,\n",
       "                     -3.00104592e-01, -3.05381650e-01, -3.07025035e-01, -3.11212570e-01,\n",
       "                     -3.24239668e-01, -3.25422400e-01, -3.36472237e-01, -3.51397887e-01,\n",
       "                     -3.53139289e-01, -3.58777994e-01, -3.62905494e-01, -3.64897923e-01,\n",
       "                     -3.69471505e-01, -3.70859579e-01, -3.75612145e-01, -3.82992252e-01,\n",
       "                     -4.05465108e-01, -4.24883194e-01, -4.46287103e-01, -4.53474327e-01,\n",
       "                     -4.56017387e-01, -4.56758402e-01, -4.61034959e-01, -4.70003629e-01,\n",
       "                     -4.76924072e-01, -4.83936724e-01, -5.10825624e-01, -5.18901038e-01,\n",
       "                     -5.26093096e-01, -5.59615788e-01, -5.67906335e-01, -5.77315365e-01,\n",
       "                     -5.87786665e-01, -5.97837001e-01, -6.06135804e-01, -6.09765572e-01,\n",
       "                     -6.19039208e-01, -6.32522559e-01, -6.35988767e-01, -6.66478933e-01,\n",
       "                     -6.93147181e-01, -7.37598943e-01, -7.50305594e-01, -7.62140052e-01,\n",
       "                     -7.73189888e-01, -8.10930216e-01, -8.32909123e-01, -9.16290732e-01,\n",
       "                     -9.38269639e-01, -1.04731899e+00, -1.09861229e+00, -1.38629436e+00,\n",
       "                     -1.60943791e+00, -1.79175947e+00, -3.45387764e+01]), auc_score=0.5251926319229212, privacy_risk=0.5262766615745882, accuracy=0.5262766615745882, tpr_ind=0.7659327925840093, tnr_ind=0.28662053056516723, test_train_ratio=1.0046349942062573, dataset_size=[3452, 3468]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.08335704, 0.09672831, 0.11465149, 0.13598862,\n",
       "                     0.14423898, 0.15476529, 0.15647226, 0.1601707 , 0.16187767,\n",
       "                     0.16330014, 0.17211949, 0.17837838, 0.1829303 , 0.1883357 ,\n",
       "                     0.19231863, 0.19857752, 0.20312945, 0.20625889, 0.20654339,\n",
       "                     0.22958748, 0.2458037 , 0.24864865, 0.26230441, 0.30469417,\n",
       "                     0.32859175, 0.32916074, 0.33172119, 0.3544808 , 0.36358464,\n",
       "                     0.38463727, 0.39004267, 0.40056899, 0.4056899 , 0.41337127,\n",
       "                     0.44125178, 0.44182077, 0.47510669, 0.48136558, 0.48790896,\n",
       "                     0.55049787, 0.55846373, 0.55931721, 0.56130868, 0.56216216,\n",
       "                     0.5940256 , 0.59459459, 0.60967283, 0.63044097, 0.63669986,\n",
       "                     0.64324324, 0.64978663, 0.66401138, 0.66628734, 0.67226174,\n",
       "                     0.67795164, 0.69217639, 0.70128023, 0.70355619, 0.70583215,\n",
       "                     0.71209104, 0.71379801, 0.74566145, 0.78236131, 0.78549075,\n",
       "                     0.79032717, 0.80512091, 0.81877667, 0.83926031, 0.84495021,\n",
       "                     0.84665718, 0.856899  , 0.86799431, 0.87339972, 0.88193457,\n",
       "                     0.90469417, 0.91379801, 0.92802276, 0.9544808 , 0.96045519,\n",
       "                     0.96671408, 0.96870555, 0.96984353, 0.9715505 , 0.97382646,\n",
       "                     0.97467994, 0.98065434, 0.98122333, 0.98549075, 0.98719772,\n",
       "                     0.98890469, 0.98947368, 0.99118065, 1.        ]), tpr=array([0.        , 0.08928047, 0.10337739, 0.12892805, 0.14977974,\n",
       "                     0.15653451, 0.16446402, 0.16681351, 0.16975037, 0.17298091,\n",
       "                     0.17591777, 0.18414097, 0.19265786, 0.2       , 0.20881057,\n",
       "                     0.21350954, 0.22143906, 0.22936858, 0.23377386, 0.23406755,\n",
       "                     0.25991189, 0.27342144, 0.27723935, 0.29192364, 0.33920705,\n",
       "                     0.35741557, 0.35829662, 0.36035242, 0.38208517, 0.39060206,\n",
       "                     0.41791483, 0.42378855, 0.43436123, 0.44170338, 0.45080764,\n",
       "                     0.47753304, 0.47870778, 0.51042584, 0.51864905, 0.5215859 ,\n",
       "                     0.57562408, 0.5876652 , 0.58913363, 0.59030837, 0.59089574,\n",
       "                     0.61204112, 0.6123348 , 0.63436123, 0.65403818, 0.66167401,\n",
       "                     0.66842878, 0.67459618, 0.69104258, 0.6928047 , 0.69720999,\n",
       "                     0.7051395 , 0.71923642, 0.73127753, 0.7339207 , 0.73891336,\n",
       "                     0.74713656, 0.74860499, 0.77767988, 0.81409692, 0.81703377,\n",
       "                     0.8226138 , 0.83612335, 0.85403818, 0.8743025 , 0.8825257 ,\n",
       "                     0.8845815 , 0.89251101, 0.90073421, 0.90484581, 0.9154185 ,\n",
       "                     0.93538913, 0.94185022, 0.95066079, 0.97356828, 0.97709251,\n",
       "                     0.98120411, 0.98325991, 0.98472834, 0.98590308, 0.98737151,\n",
       "                     0.98913363, 0.9938326 , 0.99471366, 0.99735683, 0.99853157,\n",
       "                     0.99941263, 0.99970631, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.06192872e-02, -2.27282511e-02,\n",
       "                     -4.65200156e-02, -5.55698512e-02, -7.14589640e-02, -7.41079722e-02,\n",
       "                     -8.33816089e-02, -8.70113770e-02, -9.53101798e-02, -1.01782694e-01,\n",
       "                     -1.05360516e-01, -1.13328685e-01, -1.17783036e-01, -1.19545151e-01,\n",
       "                     -1.27833372e-01, -1.38150338e-01, -1.41078598e-01, -1.54150680e-01,\n",
       "                     -1.57392174e-01, -1.78691789e-01, -1.82321557e-01, -1.98850859e-01,\n",
       "                     -2.01799364e-01, -2.01941344e-01, -2.07639365e-01, -2.23143551e-01,\n",
       "                     -2.28412664e-01, -2.52495763e-01, -2.54892250e-01, -2.62364264e-01,\n",
       "                     -2.66628663e-01, -2.77631737e-01, -2.87682072e-01, -3.09422059e-01,\n",
       "                     -3.13657559e-01, -3.15081047e-01, -3.31357136e-01, -3.36472237e-01,\n",
       "                     -3.38023827e-01, -3.41170757e-01, -3.56674944e-01, -3.62905494e-01,\n",
       "                     -3.67724780e-01, -3.77294231e-01, -3.79489622e-01, -3.82992252e-01,\n",
       "                     -3.90427231e-01, -4.05465108e-01, -4.19853846e-01, -4.21213465e-01,\n",
       "                     -4.30782916e-01, -4.35318071e-01, -4.37213806e-01, -4.41832752e-01,\n",
       "                     -4.46287103e-01, -4.50927482e-01, -4.51985124e-01, -4.62623522e-01,\n",
       "                     -4.65757338e-01, -4.70003629e-01, -4.75978892e-01, -4.78604745e-01,\n",
       "                     -4.83426650e-01, -4.89548225e-01, -4.91407538e-01, -5.00035916e-01,\n",
       "                     -5.10825624e-01, -5.17943092e-01, -5.19875459e-01, -5.28067430e-01,\n",
       "                     -5.38996501e-01, -5.42324291e-01, -5.67520967e-01, -5.71257363e-01,\n",
       "                     -6.11801541e-01, -6.93147181e-01, -7.30887509e-01, -7.33969175e-01,\n",
       "                     -7.43578034e-01, -7.62140052e-01, -7.88457360e-01, -8.10930216e-01,\n",
       "                     -8.47297860e-01, -9.16290732e-01, -9.40983344e-01, -9.80829253e-01,\n",
       "                     -1.09861229e+00, -1.38629436e+00, -1.60943791e+00, -2.30258509e+00,\n",
       "                     -2.39789527e+00, -3.45387764e+01]), auc_score=0.5250587475952649, privacy_risk=0.518962157149034, accuracy=0.518962157149034, tpr_ind=0.8845814977973568, tnr_ind=0.15334281650071124, test_train_ratio=1.0323054331864905, dataset_size=[3405, 3515]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.13220046, 0.14084101, 0.14256912, 0.14458525,\n",
       "                     0.1468894 , 0.14948157, 0.15581797, 0.16589862, 0.16705069,\n",
       "                     0.16993088, 0.17223502, 0.17482719, 0.18461982, 0.18721198,\n",
       "                     0.18894009, 0.19095622, 0.20190092, 0.32978111, 0.33698157,\n",
       "                     0.34014977, 0.34677419, 0.36664747, 0.37067972, 0.42828341,\n",
       "                     0.44498848, 0.44786866, 0.46774194, 0.47523041, 0.48243088,\n",
       "                     0.49423963, 0.52073733, 0.52361751, 0.54637097, 0.55414747,\n",
       "                     0.56048387, 0.56509217, 0.57114055, 0.58784562, 0.59821429,\n",
       "                     0.61463134, 0.63248848, 0.64832949, 0.65293779, 0.65898618,\n",
       "                     0.66359447, 0.67482719, 0.67885945, 0.71342166, 0.71342166,\n",
       "                     0.71687788, 0.71918203, 0.72206221, 0.72724654, 0.77822581,\n",
       "                     0.78052995, 0.79406682, 0.79406682, 0.80616359, 0.8125    ,\n",
       "                     0.82690092, 0.83698157, 0.84331797, 0.859447  , 0.89285714,\n",
       "                     0.89948157, 0.90034562, 0.91129032, 0.91618664, 0.92108295,\n",
       "                     0.94124424, 0.95334101, 0.95650922, 0.96342166, 0.96486175,\n",
       "                     0.96745392, 0.97321429, 0.97407834, 0.9749424 , 0.97638249,\n",
       "                     0.9781106 , 0.97897465, 0.98358295, 0.98387097, 0.98473502,\n",
       "                     0.98617512, 1.        ]), tpr=array([0.        , 0.14472158, 0.15226218, 0.15661253, 0.15922274,\n",
       "                     0.16270302, 0.16763341, 0.17053364, 0.18010441, 0.18068445,\n",
       "                     0.18242459, 0.18590487, 0.18909513, 0.20156613, 0.20272622,\n",
       "                     0.20330626, 0.20736659, 0.22215777, 0.35295824, 0.36136891,\n",
       "                     0.36484919, 0.37006961, 0.39182135, 0.39530162, 0.45446636,\n",
       "                     0.47563805, 0.47969838, 0.50464037, 0.51421114, 0.52146172,\n",
       "                     0.53741299, 0.56612529, 0.56960557, 0.59512761, 0.60179814,\n",
       "                     0.61020882, 0.61687935, 0.62209977, 0.63283063, 0.64443155,\n",
       "                     0.66096288, 0.67575406, 0.6899652 , 0.69344548, 0.69547564,\n",
       "                     0.70098608, 0.71403712, 0.71780742, 0.75232019, 0.75261021,\n",
       "                     0.75609049, 0.75783063, 0.76073086, 0.76421114, 0.81583527,\n",
       "                     0.81844548, 0.83091647, 0.8312065 , 0.84599768, 0.85353828,\n",
       "                     0.862529  , 0.87180974, 0.87906032, 0.89414153, 0.92517401,\n",
       "                     0.93387471, 0.93474478, 0.94982599, 0.95301624, 0.95707657,\n",
       "                     0.97157773, 0.97737819, 0.9799884 , 0.98288863, 0.9837587 ,\n",
       "                     0.98549884, 0.99042923, 0.99303944, 0.99419954, 0.99651972,\n",
       "                     0.99767981, 0.99825986, 0.99883991, 0.99941995, 0.99970998,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.08219945e-02, -5.00104206e-02,\n",
       "                     -6.06246218e-02, -8.00427077e-02, -9.53101798e-02, -1.05360516e-01,\n",
       "                     -1.14410351e-01, -1.43100844e-01, -1.54150680e-01, -1.62518929e-01,\n",
       "                     -1.67054085e-01, -1.70625517e-01, -1.75890666e-01, -1.82321557e-01,\n",
       "                     -1.94156014e-01, -2.00670695e-01, -2.07500774e-01, -2.13574100e-01,\n",
       "                     -2.23143551e-01, -2.29574442e-01, -2.46860078e-01, -2.57829109e-01,\n",
       "                     -2.61609832e-01, -2.63417450e-01, -2.87682072e-01, -2.97352477e-01,\n",
       "                     -3.10154928e-01, -3.11436158e-01, -3.36472237e-01, -3.39354083e-01,\n",
       "                     -3.48306694e-01, -3.50976923e-01, -3.56674944e-01, -3.59141036e-01,\n",
       "                     -3.61013346e-01, -3.61790045e-01, -3.65459773e-01, -3.71563556e-01,\n",
       "                     -3.75789340e-01, -3.85662481e-01, -3.93042588e-01, -4.05465108e-01,\n",
       "                     -4.18710335e-01, -4.22856851e-01, -4.25211871e-01, -4.30782916e-01,\n",
       "                     -4.41232332e-01, -4.41832752e-01, -4.51985124e-01, -4.55475529e-01,\n",
       "                     -4.57833094e-01, -4.59532329e-01, -4.65236851e-01, -4.70003629e-01,\n",
       "                     -4.81176930e-01, -4.85507816e-01, -4.93020999e-01, -4.95077267e-01,\n",
       "                     -5.00775288e-01, -5.10825624e-01, -5.12951023e-01, -5.14664400e-01,\n",
       "                     -5.25010259e-01, -5.30628251e-01, -5.59615788e-01, -5.70544858e-01,\n",
       "                     -5.87786665e-01, -6.22942922e-01, -6.35103811e-01, -6.93147181e-01,\n",
       "                     -7.47214402e-01, -7.83531242e-01, -8.47297860e-01, -8.60201265e-01,\n",
       "                     -8.80358723e-01, -8.93817876e-01, -9.16290732e-01, -9.65080896e-01,\n",
       "                     -1.01160091e+00, -1.09861229e+00, -1.38629436e+00, -1.50407740e+00,\n",
       "                     -1.60943791e+00, -1.94591015e+00, -3.45387764e+01]), auc_score=0.528356784671806, privacy_risk=0.5258935922247052, accuracy=0.5258935922247052, tpr_ind=0.6168793503480279, tnr_ind=0.4349078341013825, test_train_ratio=1.0069605568445477, dataset_size=[3448, 3472]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.06133178, 0.15508178, 0.15537383, 0.15975467,\n",
       "                     0.16296729, 0.19246495, 0.19363318, 0.20093458, 0.20297897,\n",
       "                     0.20297897, 0.21261682, 0.22254673, 0.22867991, 0.23218458,\n",
       "                     0.24649533, 0.27219626, 0.28154206, 0.37733645, 0.39281542,\n",
       "                     0.40595794, 0.40800234, 0.41705607, 0.42231308, 0.48014019,\n",
       "                     0.48247664, 0.49474299, 0.50204439, 0.51139019, 0.5192757 ,\n",
       "                     0.52015187, 0.52570093, 0.53154206, 0.54497664, 0.60981308,\n",
       "                     0.61098131, 0.61828271, 0.62120327, 0.62938084, 0.63931075,\n",
       "                     0.65128505, 0.66296729, 0.66793224, 0.67260514, 0.68925234,\n",
       "                     0.70035047, 0.70181075, 0.74766355, 0.75204439, 0.75584112,\n",
       "                     0.76285047, 0.78008178, 0.78271028, 0.80198598, 0.8078271 ,\n",
       "                     0.81483645, 0.82184579, 0.85309579, 0.85543224, 0.86594626,\n",
       "                     0.87879673, 0.88434579, 0.88726636, 0.88989486, 0.89106308,\n",
       "                     0.89193925, 0.90303738, 0.91384346, 0.91851636, 0.92202103,\n",
       "                     0.92610981, 0.93165888, 0.94742991, 0.9541472 , 0.95706776,\n",
       "                     0.96174065, 0.96816589, 0.97283879, 0.97371495, 0.97575935,\n",
       "                     0.97838785, 0.98014019, 0.98276869, 0.98452103, 0.98598131,\n",
       "                     0.98627336, 0.99036215, 0.99153037, 0.9926986 , 1.        ]), tpr=array([0.        , 0.07494279, 0.16504577, 0.16561785, 0.17191076,\n",
       "                     0.17763158, 0.20737986, 0.20995423, 0.21653318, 0.21853547,\n",
       "                     0.21882151, 0.23197941, 0.24284897, 0.24856979, 0.25286041,\n",
       "                     0.26430206, 0.28604119, 0.29776888, 0.38415332, 0.40474828,\n",
       "                     0.42105263, 0.42334096, 0.43449657, 0.4416476 , 0.50171625,\n",
       "                     0.5048627 , 0.51916476, 0.53089245, 0.54262014, 0.54948513,\n",
       "                     0.55234554, 0.55749428, 0.56264302, 0.5778032 , 0.64588101,\n",
       "                     0.64874142, 0.65617849, 0.66046911, 0.66847826, 0.67791762,\n",
       "                     0.68735698, 0.69908467, 0.7076659 , 0.71310069, 0.72311213,\n",
       "                     0.73283753, 0.7354119 , 0.77602975, 0.78003432, 0.78346682,\n",
       "                     0.78832952, 0.80377574, 0.80663616, 0.826373  , 0.83152174,\n",
       "                     0.83524027, 0.84467963, 0.88215103, 0.88358124, 0.89359268,\n",
       "                     0.90389016, 0.91189931, 0.91447368, 0.91647597, 0.9173341 ,\n",
       "                     0.92048055, 0.92934783, 0.93764302, 0.94250572, 0.94450801,\n",
       "                     0.94765446, 0.95108696, 0.96510297, 0.97053776, 0.97425629,\n",
       "                     0.97911899, 0.98312357, 0.98655606, 0.98741419, 0.98827231,\n",
       "                     0.9902746 , 0.99170481, 0.99342105, 0.99542334, 0.99685355,\n",
       "                     0.99742563, 0.99914188, 0.99971396, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.76127528e-02, -8.70113770e-02,\n",
       "                     -9.53101798e-02, -1.05360516e-01, -1.09199292e-01, -1.12477983e-01,\n",
       "                     -1.27833372e-01, -1.33531393e-01, -1.54150680e-01, -1.60342650e-01,\n",
       "                     -1.62518929e-01, -1.70625517e-01, -1.82321557e-01, -1.84303718e-01,\n",
       "                     -1.91055237e-01, -1.98450939e-01, -2.05775045e-01, -2.23143551e-01,\n",
       "                     -2.47408173e-01, -2.51314428e-01, -2.63191052e-01, -2.65703166e-01,\n",
       "                     -2.84104251e-01, -2.87682072e-01, -2.92669614e-01, -3.11779624e-01,\n",
       "                     -3.12133168e-01, -3.18453731e-01, -3.20471895e-01, -3.28504067e-01,\n",
       "                     -3.33144447e-01, -3.33773180e-01, -3.35871816e-01, -3.36472237e-01,\n",
       "                     -3.52821375e-01, -3.54171814e-01, -3.56674944e-01, -3.74693449e-01,\n",
       "                     -3.82208246e-01, -3.86122145e-01, -4.05465108e-01, -4.14433778e-01,\n",
       "                     -4.14943852e-01, -4.24883194e-01, -4.35318071e-01, -4.42922671e-01,\n",
       "                     -4.47312218e-01, -4.59532329e-01, -4.62623522e-01, -4.65363250e-01,\n",
       "                     -4.70003629e-01, -4.75423697e-01, -4.76924072e-01, -4.79573080e-01,\n",
       "                     -4.92476485e-01, -4.93657820e-01, -4.96436886e-01, -5.01021624e-01,\n",
       "                     -5.10825624e-01, -5.17943092e-01, -5.23248144e-01, -5.38996501e-01,\n",
       "                     -5.59615788e-01, -5.87786665e-01, -5.91364486e-01, -6.06135804e-01,\n",
       "                     -6.15185639e-01, -6.19039208e-01, -6.46627165e-01, -6.50587566e-01,\n",
       "                     -6.72527893e-01, -6.93147181e-01, -7.11496319e-01, -7.85520501e-01,\n",
       "                     -7.94929875e-01, -8.10930216e-01, -8.47297860e-01, -9.16290732e-01,\n",
       "                     -9.44461609e-01, -9.55511445e-01, -9.80829253e-01, -1.04982212e+00,\n",
       "                     -1.09861229e+00, -1.20397280e+00, -1.38629436e+00, -1.50407740e+00,\n",
       "                     -2.07944154e+00, -3.45387764e+01]), auc_score=0.5210349712087512, privacy_risk=0.52024777315597, accuracy=0.52024777315597, tpr_ind=0.7131006864988558, tnr_ind=0.32739485981308414, test_train_ratio=0.9794050343249427, dataset_size=[3496, 3424])],\n",
       "             'subpopulation_0.0_label_1.0_mia_auc': [0.5667154859503177,\n",
       "              0.579339796577465,\n",
       "              0.5632329560176561,\n",
       "              0.5645808127817331,\n",
       "              0.5591794158553547,\n",
       "              0.5641310262548126,\n",
       "              0.5720063248798881,\n",
       "              0.5525369211258386,\n",
       "              0.5550257105135155,\n",
       "              0.5550678653269876,\n",
       "              0.5719639233808723,\n",
       "              0.5618250521974152,\n",
       "              0.5449542461017597,\n",
       "              0.5725011960896185,\n",
       "              0.5820019165655146,\n",
       "              0.5547147299061576,\n",
       "              0.5504723057106055,\n",
       "              0.5639508711294561,\n",
       "              0.5249811463046757,\n",
       "              0.5571288563498195],\n",
       "             'subpopulation_0.0_label_1.0_mia_privacy_risk': [0.5472255026759474,\n",
       "              0.5545231466718994,\n",
       "              0.5445613749969975,\n",
       "              0.5492949611458089,\n",
       "              0.5438108484005564,\n",
       "              0.5455533897244228,\n",
       "              0.552136307907582,\n",
       "              0.5395050932744232,\n",
       "              0.5399264041660025,\n",
       "              0.5359225111576065,\n",
       "              0.551782344612344,\n",
       "              0.5422144513187053,\n",
       "              0.5302475447102628,\n",
       "              0.5560117894779932,\n",
       "              0.559294703890628,\n",
       "              0.5376488562880524,\n",
       "              0.5422268907563025,\n",
       "              0.5498030972015633,\n",
       "              0.5214206591538012,\n",
       "              0.5394735497426716],\n",
       "             'subpopulation_0.0_label_1.0_mia_ppv': [0.6956521739130435,\n",
       "              0.7209302325581395,\n",
       "              0.7108433734939759,\n",
       "              0.7857142857142857,\n",
       "              0.7000000000000001,\n",
       "              0.7234042553191489,\n",
       "              0.6792452830188679,\n",
       "              0.7093023255813954,\n",
       "              0.6666666666666667,\n",
       "              0.8048780487804879,\n",
       "              0.7391304347826086,\n",
       "              0.7352941176470589,\n",
       "              0.75,\n",
       "              0.6781609195402298,\n",
       "              0.7272727272727273,\n",
       "              0.7297297297297297,\n",
       "              0.763157894736842,\n",
       "              0.6792452830188679,\n",
       "              0.6351351351351351,\n",
       "              0.7058823529411764],\n",
       "             'subpopulation_0.0_label_1.0_mia_attacker_advantage': [0.09445100535189488,\n",
       "              0.10904629334379884,\n",
       "              0.08912274999399505,\n",
       "              0.09858992229161778,\n",
       "              0.08762169680111265,\n",
       "              0.09110677944884571,\n",
       "              0.1042726158151639,\n",
       "              0.0790101865488464,\n",
       "              0.07985280833200481,\n",
       "              0.07184502231521289,\n",
       "              0.10356468922468792,\n",
       "              0.08442890263741049,\n",
       "              0.06049508942052556,\n",
       "              0.11202357895598641,\n",
       "              0.11858940778125593,\n",
       "              0.07529771257610479,\n",
       "              0.08445378151260496,\n",
       "              0.09960619440312668,\n",
       "              0.042841318307602405,\n",
       "              0.07894709948534306],\n",
       "             'subpopulation_0.0_label_1.0_mia_result': [MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.01593049, 0.02027516, 0.02172339, 0.02534395,\n",
       "                     0.04634323, 0.05068791, 0.05865315, 0.06299783, 0.07023896,\n",
       "                     0.08110065, 0.08544533, 0.09051412, 0.09051412, 0.09268646,\n",
       "                     0.11006517, 0.11947864, 0.12816799, 0.14192614, 0.16147719,\n",
       "                     0.16292542, 0.16944243, 0.17958001, 0.19188993, 0.19768284,\n",
       "                     0.21144098, 0.22447502, 0.24330196, 0.25778421, 0.26574946,\n",
       "                     0.28964518, 0.29181752, 0.29833454, 0.30340333, 0.30847212,\n",
       "                     0.32295438, 0.3294714 , 0.3352643 , 0.33743664, 0.34757422,\n",
       "                     0.35119479, 0.36495293, 0.38088342, 0.40260681, 0.40260681,\n",
       "                     0.40477915, 0.41636495, 0.42722665, 0.44315713, 0.45908762,\n",
       "                     0.48805214, 0.51339609, 0.51991311, 0.52425778, 0.52787835,\n",
       "                     0.52932657, 0.54018827, 0.55104996, 0.57132513, 0.5756698 ,\n",
       "                     0.57929037, 0.60101376, 0.61332368, 0.64011586, 0.64011586,\n",
       "                     0.65532223, 0.66980449, 0.67994207, 0.6871832 , 0.70166546,\n",
       "                     0.71469949, 0.72483707, 0.73931933, 0.75452571, 0.76104272,\n",
       "                     0.78059377, 0.79217958, 0.80666184, 0.82910934, 0.83562636,\n",
       "                     0.8493845 , 0.85445329, 0.86097031, 0.86241854, 0.87110789,\n",
       "                     0.89500362, 0.89717596, 0.89717596, 0.90079652, 0.90948588,\n",
       "                     0.91745112, 0.93482983, 0.9384504 , 0.94713975, 0.95872556,\n",
       "                     0.96451846, 0.9666908 , 0.96813903, 0.96813903, 0.97103548,\n",
       "                     0.97175959, 0.97248371, 1.        ]), tpr=array([0.        , 0.03387438, 0.04022583, 0.04657728, 0.0564573 ,\n",
       "                     0.08821454, 0.09033169, 0.10091743, 0.10726888, 0.11714891,\n",
       "                     0.13338038, 0.13902611, 0.14255469, 0.14396613, 0.14467184,\n",
       "                     0.16513761, 0.17431193, 0.18207481, 0.19760056, 0.2166549 ,\n",
       "                     0.21947777, 0.22371207, 0.2335921 , 0.24488356, 0.25405787,\n",
       "                     0.27593507, 0.28863797, 0.31333804, 0.32745236, 0.33592096,\n",
       "                     0.36697248, 0.37050106, 0.37826394, 0.38249824, 0.3853211 ,\n",
       "                     0.40296401, 0.4114326 , 0.41496119, 0.41707833, 0.42201835,\n",
       "                     0.4283698 , 0.44036697, 0.45730416, 0.47988709, 0.48129852,\n",
       "                     0.48341567, 0.48835568, 0.49541284, 0.5151729 , 0.52858151,\n",
       "                     0.56104446, 0.58574453, 0.59350741, 0.60268172, 0.6062103 ,\n",
       "                     0.60903317, 0.61750176, 0.62949894, 0.65631616, 0.66760762,\n",
       "                     0.6711362 , 0.6838391 , 0.69160198, 0.71700776, 0.72547636,\n",
       "                     0.7360621 , 0.74664785, 0.75652788, 0.7706422 , 0.78405081,\n",
       "                     0.80804517, 0.81651376, 0.82709951, 0.84897671, 0.85109386,\n",
       "                     0.86097389, 0.86520819, 0.87508821, 0.91107975, 0.91601976,\n",
       "                     0.92378264, 0.92801694, 0.93366267, 0.9350741 , 0.94213126,\n",
       "                     0.95695131, 0.95836274, 0.95977417, 0.96330275, 0.97106563,\n",
       "                     0.97600565, 0.98306281, 0.98447424, 0.98870854, 0.9915314 ,\n",
       "                     0.99717713, 0.99788285, 0.99858857, 0.99929428, 0.99929428,\n",
       "                     1.        , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.00670695e-01, -2.87682072e-01,\n",
       "                     -3.56674944e-01, -4.05465108e-01, -4.41832752e-01, -4.70003629e-01,\n",
       "                     -5.10825624e-01, -5.38996501e-01, -5.53385238e-01, -5.59615788e-01,\n",
       "                     -5.87786665e-01, -6.06135804e-01, -6.19039208e-01, -6.27549898e-01,\n",
       "                     -6.31271777e-01, -6.35988767e-01, -6.93147181e-01, -7.11496319e-01,\n",
       "                     -7.47214402e-01, -7.73189888e-01, -7.80158558e-01, -7.88457360e-01,\n",
       "                     -8.02346473e-01, -8.05264479e-01, -8.25318954e-01, -8.26678573e-01,\n",
       "                     -8.32909123e-01, -8.47297860e-01, -8.66166345e-01, -8.87303195e-01,\n",
       "                     -8.90972924e-01, -8.97941593e-01, -9.16290732e-01, -9.29535959e-01,\n",
       "                     -9.47381319e-01, -9.55511445e-01, -9.80829253e-01, -9.98528830e-01,\n",
       "                     -1.00552187e+00, -1.01693426e+00, -1.02165125e+00, -1.02290047e+00,\n",
       "                     -1.02961942e+00, -1.03609193e+00, -1.06087196e+00, -1.08261195e+00,\n",
       "                     -1.08663610e+00, -1.09330724e+00, -1.09861229e+00, -1.10809103e+00,\n",
       "                     -1.12846525e+00, -1.14117190e+00, -1.14356368e+00, -1.17007125e+00,\n",
       "                     -1.17163742e+00, -1.17411984e+00, -1.17569203e+00, -1.17677706e+00,\n",
       "                     -1.18958407e+00, -1.20397280e+00, -1.21302264e+00, -1.22050211e+00,\n",
       "                     -1.25276297e+00, -1.25804003e+00, -1.26923781e+00, -1.27296568e+00,\n",
       "                     -1.28966753e+00, -1.32538561e+00, -1.34117393e+00, -1.34373475e+00,\n",
       "                     -1.35239281e+00, -1.38629436e+00, -1.40089316e+00, -1.40399394e+00,\n",
       "                     -1.40691365e+00, -1.43848011e+00, -1.45597428e+00, -1.48807706e+00,\n",
       "                     -1.52121368e+00, -1.52605630e+00, -1.53147637e+00, -1.60943791e+00,\n",
       "                     -1.75785792e+00, -1.75949861e+00, -1.79175947e+00, -1.83258146e+00,\n",
       "                     -1.93075834e+00, -1.94591015e+00, -2.06142304e+00, -2.07944154e+00,\n",
       "                     -2.19722458e+00, -2.23359222e+00, -2.24723500e+00, -2.30258509e+00,\n",
       "                     -2.48490665e+00, -2.70805020e+00, -2.83321334e+00, -3.13549422e+00,\n",
       "                     -3.17805383e+00, -3.21887582e+00, -3.45387764e+01]), auc_score=0.5667154859503177, privacy_risk=0.5472255026759474, accuracy=0.5472255026759474, tpr_ind=0.8489767113620325, tnr_ind=0.24547429398986242, test_train_ratio=0.9745942131263232, dataset_size=[1417, 1381]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.00847458, 0.01200565, 0.01694915, 0.01765537,\n",
       "                     0.02330508, 0.02966102, 0.03248588, 0.04449153, 0.0529661 ,\n",
       "                     0.05932203, 0.06214689, 0.06920904, 0.07909605, 0.09039548,\n",
       "                     0.09039548, 0.0960452 , 0.14053672, 0.15960452, 0.17161017,\n",
       "                     0.21468927, 0.21822034, 0.23022599, 0.25776836, 0.25918079,\n",
       "                     0.27259887, 0.27612994, 0.28107345, 0.2930791 , 0.29731638,\n",
       "                     0.31355932, 0.3220339 , 0.32485876, 0.33827684, 0.34887006,\n",
       "                     0.35310734, 0.35805085, 0.36299435, 0.37358757, 0.37358757,\n",
       "                     0.41878531, 0.45127119, 0.46115819, 0.49293785, 0.49717514,\n",
       "                     0.50776836, 0.53107345, 0.53813559, 0.55579096, 0.57627119,\n",
       "                     0.58474576, 0.58474576, 0.58968927, 0.5960452 , 0.60663842,\n",
       "                     0.62076271, 0.67655367, 0.68573446, 0.72316384, 0.72881356,\n",
       "                     0.74646893, 0.75      , 0.75847458, 0.76553672, 0.77471751,\n",
       "                     0.78601695, 0.79661017, 0.81144068, 0.81779661, 0.8319209 ,\n",
       "                     0.83333333, 0.85240113, 0.86016949, 0.86087571, 0.86158192,\n",
       "                     0.8700565 , 0.89830508, 0.89830508, 0.9039548 , 0.90677966,\n",
       "                     0.92161017, 0.9230226 , 0.93079096, 0.93149718, 0.94562147,\n",
       "                     0.9470339 , 0.94774011, 0.95338983, 0.95621469, 0.96045198,\n",
       "                     0.96468927, 0.96468927, 1.        ]), tpr=array([0.        , 0.02243126, 0.02821997, 0.03400868, 0.03762663,\n",
       "                     0.04775687, 0.05788712, 0.06150507, 0.08465991, 0.09479016,\n",
       "                     0.10564399, 0.11287988, 0.12445731, 0.13386397, 0.14399421,\n",
       "                     0.15050651, 0.1577424 , 0.21562952, 0.23371925, 0.24819103,\n",
       "                     0.29377713, 0.29956585, 0.3154848 , 0.34370478, 0.34732272,\n",
       "                     0.36758321, 0.37554269, 0.38060781, 0.39146165, 0.40376266,\n",
       "                     0.41895803, 0.43053546, 0.43270622, 0.44500724, 0.45007236,\n",
       "                     0.45875543, 0.45947902, 0.46671491, 0.48191027, 0.48263386,\n",
       "                     0.51157742, 0.5463097 , 0.55716353, 0.58104197, 0.58683068,\n",
       "                     0.59985528, 0.61649783, 0.62735166, 0.64254703, 0.65701881,\n",
       "                     0.67149059, 0.67510854, 0.67872648, 0.68306802, 0.69681621,\n",
       "                     0.7105644 , 0.7829233 , 0.79232996, 0.81837916, 0.82489146,\n",
       "                     0.83719247, 0.84298119, 0.84804631, 0.85383502, 0.86251809,\n",
       "                     0.87120116, 0.88422576, 0.89725036, 0.90086831, 0.91316932,\n",
       "                     0.91389291, 0.93198263, 0.93487699, 0.93704776, 0.93777135,\n",
       "                     0.94428365, 0.96164978, 0.96237337, 0.96526773, 0.96671491,\n",
       "                     0.97973951, 0.98118669, 0.98263386, 0.98335745, 0.99204052,\n",
       "                     0.99276411, 0.9934877 , 0.99493488, 0.99493488, 0.99565847,\n",
       "                     0.99927641, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.23143551e-01, -2.87682072e-01,\n",
       "                     -3.36472237e-01, -4.05465108e-01, -4.51985124e-01, -4.70003629e-01,\n",
       "                     -4.94696242e-01, -4.96436886e-01, -5.10825624e-01, -5.43615447e-01,\n",
       "                     -5.59615788e-01, -5.70544858e-01, -6.19039208e-01, -6.35988767e-01,\n",
       "                     -6.41853886e-01, -6.93147181e-01, -7.12949808e-01, -7.88457360e-01,\n",
       "                     -7.98507696e-01, -8.10930216e-01, -8.20980552e-01, -8.47297860e-01,\n",
       "                     -8.75468737e-01, -8.87303195e-01, -8.90972924e-01, -8.93817876e-01,\n",
       "                     -9.02867712e-01, -9.16290732e-01, -9.25769476e-01, -9.40983344e-01,\n",
       "                     -9.58254931e-01, -9.80829253e-01, -9.98528830e-01, -1.01160091e+00,\n",
       "                     -1.02165125e+00, -1.02961942e+00, -1.03301501e+00, -1.04145387e+00,\n",
       "                     -1.04731899e+00, -1.04877991e+00, -1.09861229e+00, -1.10866262e+00,\n",
       "                     -1.13943428e+00, -1.16179119e+00, -1.16315081e+00, -1.20397280e+00,\n",
       "                     -1.20609820e+00, -1.20896035e+00, -1.21478372e+00, -1.22377543e+00,\n",
       "                     -1.23676263e+00, -1.25276297e+00, -1.27349887e+00, -1.27506873e+00,\n",
       "                     -1.27536280e+00, -1.28519824e+00, -1.29167838e+00, -1.30405626e+00,\n",
       "                     -1.30992138e+00, -1.33041390e+00, -1.34992672e+00, -1.35454566e+00,\n",
       "                     -1.38629436e+00, -1.42711636e+00, -1.49165488e+00, -1.50407740e+00,\n",
       "                     -1.52605630e+00, -1.56704235e+00, -1.56861592e+00, -1.57691472e+00,\n",
       "                     -1.60943791e+00, -1.65822808e+00, -1.74296931e+00, -1.75401914e+00,\n",
       "                     -1.77956420e+00, -1.79175947e+00, -1.83258146e+00, -1.94591015e+00,\n",
       "                     -1.97716269e+00, -2.03688193e+00, -2.07944154e+00, -2.19722458e+00,\n",
       "                     -2.35137526e+00, -2.42036813e+00, -2.70805020e+00, -2.74084002e+00,\n",
       "                     -2.77258872e+00, -2.94443898e+00, -3.12676054e+00, -3.21887582e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.579339796577465, privacy_risk=0.5545231466718994, accuracy=0.5545231466718994, tpr_ind=0.48263386396526775, tnr_ind=0.626412429378531, test_train_ratio=1.0246020260492041, dataset_size=[1382, 1416]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.0140746 , 0.01688951, 0.02181562, 0.02533427,\n",
       "                     0.03166784, 0.03518649, 0.03659395, 0.04855735, 0.05348346,\n",
       "                     0.05700211, 0.08163265, 0.0851513 , 0.09429979, 0.10485574,\n",
       "                     0.13370866, 0.14637579, 0.15552428, 0.16608023, 0.2033779 ,\n",
       "                     0.22800844, 0.24700915, 0.25686137, 0.25897255, 0.27304715,\n",
       "                     0.27726953, 0.28571429, 0.3617171 , 0.37156932, 0.38142153,\n",
       "                     0.38212526, 0.3877551 , 0.40675581, 0.4137931 , 0.43560873,\n",
       "                     0.45038705, 0.45320197, 0.45953554, 0.46516538, 0.46727657,\n",
       "                     0.50035186, 0.50668543, 0.57002111, 0.58902182, 0.59957776,\n",
       "                     0.6052076 , 0.60731879, 0.61646728, 0.62491203, 0.64039409,\n",
       "                     0.6572836 , 0.6572836 , 0.66150598, 0.66572836, 0.6713582 ,\n",
       "                     0.68402533, 0.70021112, 0.70795215, 0.72413793, 0.7304715 ,\n",
       "                     0.73187896, 0.73961999, 0.74876847, 0.77128783, 0.78536242,\n",
       "                     0.79310345, 0.80365939, 0.81069669, 0.82054891, 0.85784659,\n",
       "                     0.86840253, 0.86910626, 0.87614356, 0.87895848, 0.88669951,\n",
       "                     0.90288529, 0.91273751, 0.9148487 , 0.92962702, 0.93033075,\n",
       "                     0.93244194, 0.9408867 , 0.94229416, 0.94440535, 0.94510908,\n",
       "                     0.94722027, 0.95003519, 0.95073892, 0.95144265, 0.95707248,\n",
       "                     0.95847994, 0.95918367, 0.9598874 , 1.        ]), tpr=array([0.        , 0.03485839, 0.04284677, 0.0486565 , 0.0530138 ,\n",
       "                     0.06390704, 0.07044299, 0.07334786, 0.08641975, 0.09513435,\n",
       "                     0.09876543, 0.12563544, 0.13071895, 0.13870733, 0.15250545,\n",
       "                     0.1902687 , 0.20551924, 0.22294844, 0.23529412, 0.26143791,\n",
       "                     0.28612927, 0.31009441, 0.31953522, 0.32607117, 0.3405955 ,\n",
       "                     0.3449528 , 0.35221496, 0.42338417, 0.44081336, 0.44880174,\n",
       "                     0.45243282, 0.45824256, 0.47058824, 0.48946986, 0.5177923 ,\n",
       "                     0.52868555, 0.53667393, 0.54466231, 0.55192447, 0.55628177,\n",
       "                     0.58169935, 0.59259259, 0.64923747, 0.67175018, 0.68191721,\n",
       "                     0.68845316, 0.69644154, 0.70152505, 0.71023965, 0.72403776,\n",
       "                     0.73493101, 0.73783588, 0.74219317, 0.74582426, 0.7523602 ,\n",
       "                     0.76470588, 0.78213508, 0.79375454, 0.80319535, 0.80900508,\n",
       "                     0.81118373, 0.81626725, 0.82570806, 0.84095861, 0.85039942,\n",
       "                     0.85548293, 0.86347131, 0.87218591, 0.87872186, 0.91067538,\n",
       "                     0.91938998, 0.92156863, 0.92883079, 0.93464052, 0.94117647,\n",
       "                     0.95424837, 0.95860566, 0.96151053, 0.97167756, 0.97603486,\n",
       "                     0.97676107, 0.98547567, 0.98620189, 0.9869281 , 0.98765432,\n",
       "                     0.98838054, 0.99419027, 0.99419027, 0.99491649, 0.99782135,\n",
       "                     0.99927378, 0.99927378, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -8.70113770e-02, -2.23143551e-01,\n",
       "                     -2.87682072e-01, -3.36472237e-01, -3.67724780e-01, -4.05465108e-01,\n",
       "                     -5.10825624e-01, -5.59615788e-01, -5.87786665e-01, -6.08589793e-01,\n",
       "                     -6.19039208e-01, -6.39079959e-01, -6.40503447e-01, -6.93147181e-01,\n",
       "                     -7.39667196e-01, -7.67255153e-01, -8.04372816e-01, -8.06475866e-01,\n",
       "                     -8.10930216e-01, -8.47297860e-01, -8.69037847e-01, -8.93817876e-01,\n",
       "                     -8.96088025e-01, -9.16290732e-01, -9.27340568e-01, -9.29017286e-01,\n",
       "                     -9.31558204e-01, -9.34309237e-01, -9.55511445e-01, -9.65080896e-01,\n",
       "                     -9.67276287e-01, -9.76009967e-01, -9.90398704e-01, -9.98528830e-01,\n",
       "                     -1.00330211e+00, -1.01160091e+00, -1.02961942e+00, -1.04145387e+00,\n",
       "                     -1.04707864e+00, -1.07613943e+00, -1.09002854e+00, -1.09861229e+00,\n",
       "                     -1.12059120e+00, -1.13497993e+00, -1.13707857e+00, -1.14513230e+00,\n",
       "                     -1.17865500e+00, -1.18269541e+00, -1.20397280e+00, -1.21302264e+00,\n",
       "                     -1.21924028e+00, -1.22377543e+00, -1.23676263e+00, -1.24432410e+00,\n",
       "                     -1.25276297e+00, -1.27046255e+00, -1.28519824e+00, -1.28785429e+00,\n",
       "                     -1.29928298e+00, -1.31218639e+00, -1.36687628e+00, -1.38629436e+00,\n",
       "                     -1.42403469e+00, -1.45528723e+00, -1.55334845e+00, -1.55814462e+00,\n",
       "                     -1.56397554e+00, -1.57239664e+00, -1.60943791e+00, -1.63141682e+00,\n",
       "                     -1.70474809e+00, -1.74919985e+00, -1.75401914e+00, -1.79175947e+00,\n",
       "                     -1.81915844e+00, -1.90954250e+00, -1.94591015e+00, -1.96944065e+00,\n",
       "                     -2.07944154e+00, -2.11021320e+00, -2.19722458e+00, -2.30258509e+00,\n",
       "                     -2.39789527e+00, -2.48490665e+00, -2.54553127e+00, -2.56494936e+00,\n",
       "                     -2.63905733e+00, -2.77258872e+00, -2.97041447e+00, -2.99573227e+00,\n",
       "                     -4.02535169e+00, -3.45387764e+01]), auc_score=0.5632329560176561, privacy_risk=0.5445613749969975, accuracy=0.5445613749969975, tpr_ind=0.6964415395787945, tnr_ind=0.39268121041520054, test_train_ratio=1.0319535221496006, dataset_size=[1377, 1421]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.00630694, 0.00981079, 0.01611773, 0.02032235,\n",
       "                     0.02382621, 0.02662929, 0.03083392, 0.03293623, 0.03644008,\n",
       "                     0.03994394, 0.04344779, 0.04625088, 0.04975473, 0.06657323,\n",
       "                     0.07288017, 0.08339173, 0.08759636, 0.11002102, 0.11212334,\n",
       "                     0.1177295 , 0.12193413, 0.12683952, 0.14085494, 0.14716188,\n",
       "                     0.15557113, 0.1562719 , 0.21653819, 0.22915207, 0.2452698 ,\n",
       "                     0.25087596, 0.25157673, 0.25297828, 0.26489138, 0.28100911,\n",
       "                     0.28871759, 0.29782761, 0.33006307, 0.34968465, 0.36019622,\n",
       "                     0.39243167, 0.39313245, 0.41135249, 0.41976174, 0.43798178,\n",
       "                     0.47442186, 0.50525578, 0.50595655, 0.5311843 , 0.55360897,\n",
       "                     0.5914506 , 0.59285214, 0.60967064, 0.62438683, 0.62999299,\n",
       "                     0.63489839, 0.65522074, 0.67484233, 0.68605466, 0.68815697,\n",
       "                     0.70567624, 0.74211633, 0.75613174, 0.77855641, 0.77925718,\n",
       "                     0.8051857 , 0.81079187, 0.81990189, 0.83251577, 0.83251577,\n",
       "                     0.83812193, 0.85143658, 0.8605466 , 0.86895585, 0.90329362,\n",
       "                     0.90679748, 0.91030133, 0.92361598, 0.92571829, 0.92922214,\n",
       "                     0.93202523, 0.932726  , 0.93412754, 0.93412754, 0.93622985,\n",
       "                     0.93973371, 0.94183602, 0.94604064, 0.94674142, 0.9495445 ,\n",
       "                     0.95094604, 0.96075683, 1.        ]), tpr=array([0.        , 0.02407002, 0.02917578, 0.03282276, 0.03938731,\n",
       "                     0.04522247, 0.05178702, 0.05543399, 0.06564551, 0.07002188,\n",
       "                     0.07512764, 0.07950401, 0.08606856, 0.08971554, 0.10138585,\n",
       "                     0.11013858, 0.12472648, 0.1356674 , 0.17213713, 0.17724289,\n",
       "                     0.18745441, 0.19256018, 0.20131291, 0.22246535, 0.22757112,\n",
       "                     0.23924143, 0.24653538, 0.31291028, 0.3245806 , 0.33625091,\n",
       "                     0.34573304, 0.34792123, 0.3515682 , 0.35886214, 0.37490883,\n",
       "                     0.38147338, 0.3916849 , 0.42304887, 0.44347192, 0.45003647,\n",
       "                     0.48358862, 0.48577681, 0.49234136, 0.5003647 , 0.50984683,\n",
       "                     0.54412837, 0.57257476, 0.57622174, 0.6075857 , 0.62800875,\n",
       "                     0.65499635, 0.65718454, 0.66812546, 0.68271335, 0.6892779 ,\n",
       "                     0.69730124, 0.72064187, 0.730124  , 0.73522976, 0.73887673,\n",
       "                     0.7563822 , 0.79649891, 0.80889861, 0.83296864, 0.83588621,\n",
       "                     0.86287381, 0.86725018, 0.87746171, 0.88913202, 0.89059081,\n",
       "                     0.89350839, 0.90299052, 0.90809628, 0.91393144, 0.95113056,\n",
       "                     0.95331875, 0.95696572, 0.97009482, 0.97228301, 0.97738877,\n",
       "                     0.97957695, 0.98030635, 0.98176513, 0.98395332, 0.9861415 ,\n",
       "                     0.98760029, 0.99051787, 0.99343545, 0.99416484, 0.99635303,\n",
       "                     0.99708242, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -1.82321557e-01,\n",
       "                     -2.00670695e-01, -2.23143551e-01, -2.87682072e-01, -3.36472237e-01,\n",
       "                     -4.05465108e-01, -5.10825624e-01, -5.38996501e-01, -5.59615788e-01,\n",
       "                     -5.75364145e-01, -5.87786665e-01, -5.94707108e-01, -6.06135804e-01,\n",
       "                     -6.41853886e-01, -6.59245629e-01, -6.93147181e-01, -7.20546155e-01,\n",
       "                     -7.28238500e-01, -7.62140052e-01, -7.73189888e-01, -7.75838896e-01,\n",
       "                     -7.77704569e-01, -7.82759339e-01, -7.88457360e-01, -8.07260487e-01,\n",
       "                     -8.10930216e-01, -8.20980552e-01, -8.36248024e-01, -8.47297860e-01,\n",
       "                     -8.75468737e-01, -9.16290732e-01, -9.34309237e-01, -9.80829253e-01,\n",
       "                     -9.98528830e-01, -1.00948451e+00, -1.01160091e+00, -1.02961942e+00,\n",
       "                     -1.03889305e+00, -1.04145387e+00, -1.06087196e+00, -1.06784063e+00,\n",
       "                     -1.07263680e+00, -1.09861229e+00, -1.15671992e+00, -1.16315081e+00,\n",
       "                     -1.16378192e+00, -1.17865500e+00, -1.18487263e+00, -1.18958407e+00,\n",
       "                     -1.19392247e+00, -1.20126644e+00, -1.20397280e+00, -1.21302264e+00,\n",
       "                     -1.21639532e+00, -1.25276297e+00, -1.30405626e+00, -1.30625165e+00,\n",
       "                     -1.32175584e+00, -1.34925309e+00, -1.35644140e+00, -1.35663815e+00,\n",
       "                     -1.38629436e+00, -1.39302839e+00, -1.45225233e+00, -1.45667516e+00,\n",
       "                     -1.46151778e+00, -1.49165488e+00, -1.50407740e+00, -1.52939520e+00,\n",
       "                     -1.60943791e+00, -1.63413053e+00, -1.64790419e+00, -1.64865863e+00,\n",
       "                     -1.68639895e+00, -1.69459572e+00, -1.73460106e+00, -1.78245708e+00,\n",
       "                     -1.79175947e+00, -1.87180218e+00, -1.94591015e+00, -1.98100147e+00,\n",
       "                     -2.00148000e+00, -2.07944154e+00, -2.11021320e+00, -2.19722458e+00,\n",
       "                     -2.30258509e+00, -2.70805020e+00, -2.83321334e+00, -4.11087386e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5645808127817331, privacy_risk=0.5492949611458089, accuracy=0.5492949611458089, tpr_ind=0.3515681983953319, tnr_ind=0.747021723896286, test_train_ratio=1.0408460977388767, dataset_size=[1371, 1427]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.01102941, 0.01544118, 0.02058824, 0.03014706,\n",
       "                     0.03676471, 0.0375    , 0.04264706, 0.05735294, 0.06029412,\n",
       "                     0.075     , 0.08014706, 0.08970588, 0.10735294, 0.11029412,\n",
       "                     0.12279412, 0.14338235, 0.16029412, 0.16102941, 0.16985294,\n",
       "                     0.17941176, 0.20441176, 0.21323529, 0.21691176, 0.22352941,\n",
       "                     0.23382353, 0.25220588, 0.26029412, 0.26691176, 0.28014706,\n",
       "                     0.28455882, 0.30220588, 0.32205882, 0.32867647, 0.33970588,\n",
       "                     0.34485294, 0.34779412, 0.39632353, 0.40735294, 0.41323529,\n",
       "                     0.45147059, 0.45367647, 0.46838235, 0.48161765, 0.48529412,\n",
       "                     0.49558824, 0.5       , 0.51838235, 0.53088235, 0.53970588,\n",
       "                     0.55147059, 0.56764706, 0.56838235, 0.57205882, 0.59191176,\n",
       "                     0.59705882, 0.6125    , 0.61911765, 0.67720588, 0.69338235,\n",
       "                     0.75955882, 0.77941176, 0.79264706, 0.80514706, 0.82279412,\n",
       "                     0.83823529, 0.84117647, 0.84411765, 0.86691176, 0.86911765,\n",
       "                     0.87132353, 0.87352941, 0.875     , 0.87647059, 0.88308824,\n",
       "                     0.9       , 0.90147059, 0.91985294, 0.92132353, 0.92352941,\n",
       "                     0.92426471, 0.92794118, 0.93088235, 0.93161765, 0.93308824,\n",
       "                     0.93676471, 0.93823529, 0.93970588, 0.94338235, 0.94411765,\n",
       "                     0.94705882, 0.95073529, 0.95882353, 0.9625    , 0.96323529,\n",
       "                     0.96691176, 0.96911765, 1.        ]), tpr=array([0.        , 0.02433936, 0.03268428, 0.0403338 , 0.04589708,\n",
       "                     0.05493741, 0.0605007 , 0.06815021, 0.07927677, 0.08623088,\n",
       "                     0.11057024, 0.11752434, 0.12795549, 0.14812239, 0.15090403,\n",
       "                     0.16620306, 0.19471488, 0.21070932, 0.21418637, 0.22183588,\n",
       "                     0.22809458, 0.25034771, 0.26425591, 0.27399166, 0.28303199,\n",
       "                     0.28859527, 0.31293463, 0.31988873, 0.33171071, 0.34700974,\n",
       "                     0.35048679, 0.36161335, 0.38386648, 0.38873435, 0.39638387,\n",
       "                     0.41098748, 0.41376912, 0.47218359, 0.47844228, 0.4867872 ,\n",
       "                     0.53198887, 0.53546592, 0.55006954, 0.5674548 , 0.56815021,\n",
       "                     0.57927677, 0.5876217 , 0.60222531, 0.60709318, 0.62308762,\n",
       "                     0.63212796, 0.64394993, 0.64673157, 0.65159944, 0.66411683,\n",
       "                     0.6689847 , 0.68636996, 0.69262865, 0.75591099, 0.76564673,\n",
       "                     0.82684284, 0.84075104, 0.85326843, 0.86230876, 0.87552156,\n",
       "                     0.89082058, 0.89638387, 0.89777469, 0.91933241, 0.9255911 ,\n",
       "                     0.92976356, 0.93324061, 0.93463143, 0.93741307, 0.94645341,\n",
       "                     0.9596662 , 0.96105702, 0.97148818, 0.972879  , 0.97426982,\n",
       "                     0.97566064, 0.97844228, 0.97844228, 0.98122392, 0.98261474,\n",
       "                     0.98539638, 0.98609179, 0.98956885, 0.99026426, 0.99095967,\n",
       "                     0.99235049, 0.99513213, 0.99582754, 0.99652295, 0.99721836,\n",
       "                     0.99791377, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.23143551e-01, -2.87682072e-01,\n",
       "                     -4.05465108e-01, -4.70003629e-01, -4.85507816e-01, -4.92476485e-01,\n",
       "                     -5.18793793e-01, -5.30628251e-01, -5.59615788e-01, -5.87786665e-01,\n",
       "                     -5.90868331e-01, -6.10909082e-01, -6.41853886e-01, -6.82218110e-01,\n",
       "                     -6.93147181e-01, -7.22134717e-01, -7.33969175e-01, -7.37598943e-01,\n",
       "                     -7.47214402e-01, -7.70108222e-01, -7.88457360e-01, -7.98507696e-01,\n",
       "                     -8.02346473e-01, -8.10930216e-01, -8.14099791e-01, -8.26678573e-01,\n",
       "                     -8.30348302e-01, -8.40783179e-01, -8.47297860e-01, -8.68088630e-01,\n",
       "                     -8.78069519e-01, -8.87303195e-01, -9.16290732e-01, -9.63437510e-01,\n",
       "                     -9.65080896e-01, -9.67345903e-01, -9.80829253e-01, -1.01160091e+00,\n",
       "                     -1.01856958e+00, -1.02961942e+00, -1.05121005e+00, -1.06555143e+00,\n",
       "                     -1.06635143e+00, -1.06686359e+00, -1.07044141e+00, -1.07613943e+00,\n",
       "                     -1.07880966e+00, -1.09861229e+00, -1.12393010e+00, -1.12938395e+00,\n",
       "                     -1.17007125e+00, -1.18958407e+00, -1.20397280e+00, -1.23214368e+00,\n",
       "                     -1.25276297e+00, -1.26224171e+00, -1.28215410e+00, -1.28785429e+00,\n",
       "                     -1.30031551e+00, -1.34373475e+00, -1.38629436e+00, -1.42019591e+00,\n",
       "                     -1.44691898e+00, -1.48160454e+00, -1.48538526e+00, -1.50407740e+00,\n",
       "                     -1.50765522e+00, -1.50990832e+00, -1.53018854e+00, -1.54756251e+00,\n",
       "                     -1.60943791e+00, -1.62924054e+00, -1.63974326e+00, -1.66073121e+00,\n",
       "                     -1.70474809e+00, -1.79175947e+00, -1.81237876e+00, -1.90954250e+00,\n",
       "                     -1.94591015e+00, -1.98100147e+00, -2.01490302e+00, -2.06369318e+00,\n",
       "                     -2.11021320e+00, -2.15948425e+00, -2.19722458e+00, -2.21101790e+00,\n",
       "                     -2.26868354e+00, -2.30258509e+00, -2.32238772e+00, -2.65675691e+00,\n",
       "                     -2.77258872e+00, -2.94443898e+00, -3.09104245e+00, -3.21887582e+00,\n",
       "                     -3.55534806e+00, -3.45387764e+01]), auc_score=0.5591794158553547, privacy_risk=0.5438108484005564, accuracy=0.5438108484005564, tpr_ind=0.5876216968011126, tnr_ind=0.5, test_train_ratio=0.9457579972183588, dataset_size=[1438, 1360]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.00933238, 0.01076813, 0.017229  , 0.01794688,\n",
       "                     0.02727925, 0.028715  , 0.03374013, 0.04307251, 0.04522613,\n",
       "                     0.05312276, 0.06030151, 0.06604451, 0.07681263, 0.07968413,\n",
       "                     0.10265614, 0.10983489, 0.14142139, 0.14931802, 0.15577889,\n",
       "                     0.15936827, 0.16008615, 0.1787509 , 0.1959799 , 0.19813352,\n",
       "                     0.20890165, 0.25125628, 0.26704953, 0.27781766, 0.28930366,\n",
       "                     0.29361091, 0.31371141, 0.32304379, 0.33237617, 0.34386217,\n",
       "                     0.37544867, 0.39339555, 0.40272793, 0.4178033 , 0.4235463 ,\n",
       "                     0.43359655, 0.44580043, 0.45872218, 0.46446518, 0.47020818,\n",
       "                     0.47595118, 0.49102656, 0.51902369, 0.52261307, 0.54271357,\n",
       "                     0.55994257, 0.56927495, 0.57142857, 0.57430007, 0.58076095,\n",
       "                     0.58291457, 0.63173008, 0.6367552 , 0.64249821, 0.65470208,\n",
       "                     0.65900933, 0.67552046, 0.68341709, 0.69562096, 0.69992821,\n",
       "                     0.74300072, 0.74371859, 0.75376884, 0.76453697, 0.76453697,\n",
       "                     0.77027997, 0.78248385, 0.79396985, 0.8126346 , 0.8183776 ,\n",
       "                     0.81909548, 0.82627423, 0.8269921 , 0.90811199, 0.91098349,\n",
       "                     0.91241924, 0.91385499, 0.92749462, 0.93251974, 0.93251974,\n",
       "                     0.93395549, 0.93395549, 0.93682699, 0.93826274, 0.94544149,\n",
       "                     0.94687724, 0.94687724, 0.95692749, 0.95692749, 1.        ]), tpr=array([0.        , 0.02419929, 0.02775801, 0.0405694 , 0.04270463,\n",
       "                     0.05338078, 0.06120996, 0.07046263, 0.08042705, 0.086121  ,\n",
       "                     0.09822064, 0.10462633, 0.11530249, 0.13523132, 0.14092527,\n",
       "                     0.17081851, 0.17864769, 0.20498221, 0.21281139, 0.2227758 ,\n",
       "                     0.22775801, 0.23060498, 0.25266904, 0.26405694, 0.26761566,\n",
       "                     0.27402135, 0.31530249, 0.33096085, 0.33950178, 0.35231317,\n",
       "                     0.35729537, 0.37437722, 0.38576512, 0.39145907, 0.39715302,\n",
       "                     0.43274021, 0.44768683, 0.46120996, 0.48113879, 0.48683274,\n",
       "                     0.49323843, 0.50391459, 0.51886121, 0.52669039, 0.5366548 ,\n",
       "                     0.5430605 , 0.56512456, 0.6       , 0.60355872, 0.62491103,\n",
       "                     0.64839858, 0.65765125, 0.66049822, 0.66476868, 0.67046263,\n",
       "                     0.67402135, 0.71174377, 0.71672598, 0.72455516, 0.73096085,\n",
       "                     0.73807829, 0.75160142, 0.75587189, 0.76370107, 0.76939502,\n",
       "                     0.81281139, 0.81423488, 0.81921708, 0.83202847, 0.83629893,\n",
       "                     0.84483986, 0.85338078, 0.86619217, 0.88398577, 0.89395018,\n",
       "                     0.89466192, 0.89964413, 0.90177936, 0.97366548, 0.97508897,\n",
       "                     0.97793594, 0.97935943, 0.98576512, 0.98790036, 0.98932384,\n",
       "                     0.99003559, 0.99074733, 0.99145907, 0.99217082, 0.99501779,\n",
       "                     0.99715302, 0.99786477, 0.99928826, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.82321557e-01, -2.45122458e-01,\n",
       "                     -2.87682072e-01, -3.36472237e-01, -3.64643114e-01, -4.05465108e-01,\n",
       "                     -4.51985124e-01, -4.85507816e-01, -4.98991166e-01, -5.10825624e-01,\n",
       "                     -5.50046337e-01, -6.39079959e-01, -6.56779536e-01, -6.93147181e-01,\n",
       "                     -7.17839793e-01, -7.20849783e-01, -7.37598943e-01, -7.59105148e-01,\n",
       "                     -7.62140052e-01, -7.73189888e-01, -7.78914002e-01, -7.80852761e-01,\n",
       "                     -7.88457360e-01, -8.00777845e-01, -8.36248024e-01, -8.44953193e-01,\n",
       "                     -8.47297860e-01, -8.64997437e-01, -8.87303195e-01, -8.99483614e-01,\n",
       "                     -9.04456274e-01, -9.16290732e-01, -9.47381319e-01, -9.55511445e-01,\n",
       "                     -9.62810748e-01, -9.66843011e-01, -9.89128056e-01, -1.01160091e+00,\n",
       "                     -1.02165125e+00, -1.02961942e+00, -1.03117101e+00, -1.03609193e+00,\n",
       "                     -1.04982212e+00, -1.07613943e+00, -1.09861229e+00, -1.11212601e+00,\n",
       "                     -1.13497993e+00, -1.14306405e+00, -1.14740245e+00, -1.17272026e+00,\n",
       "                     -1.17865500e+00, -1.20397280e+00, -1.21639532e+00, -1.22377543e+00,\n",
       "                     -1.22820512e+00, -1.23214368e+00, -1.23474446e+00, -1.23676263e+00,\n",
       "                     -1.25276297e+00, -1.25661654e+00, -1.26369204e+00, -1.29928298e+00,\n",
       "                     -1.32175584e+00, -1.32720544e+00, -1.33500107e+00, -1.38629436e+00,\n",
       "                     -1.45343366e+00, -1.45861502e+00, -1.46633707e+00, -1.50407740e+00,\n",
       "                     -1.51634749e+00, -1.51732262e+00, -1.53623451e+00, -1.54044504e+00,\n",
       "                     -1.58696506e+00, -1.60943791e+00, -1.61339049e+00, -1.79175947e+00,\n",
       "                     -1.83258146e+00, -1.89711998e+00, -1.94591015e+00, -2.02814825e+00,\n",
       "                     -2.07944154e+00, -2.19722458e+00, -2.25129180e+00, -2.36712361e+00,\n",
       "                     -2.39789527e+00, -2.46385324e+00, -2.66258783e+00, -2.70805020e+00,\n",
       "                     -2.77258872e+00, -2.94443898e+00, -3.45387764e+01]), auc_score=0.5641310262548126, privacy_risk=0.5455533897244228, accuracy=0.5455533897244228, tpr_ind=0.6740213523131673, tnr_ind=0.41708542713567837, test_train_ratio=0.9914590747330961, dataset_size=[1405, 1393]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.01196341, 0.01688951, 0.02111189, 0.02181562,\n",
       "                     0.026038  , 0.026038  , 0.03870514, 0.04996481, 0.05489092,\n",
       "                     0.0591133 , 0.06474314, 0.07178044, 0.08233638, 0.09711471,\n",
       "                     0.10204082, 0.12596763, 0.14637579, 0.15693174, 0.1914145 ,\n",
       "                     0.19634061, 0.21393385, 0.21674877, 0.21885996, 0.23082336,\n",
       "                     0.24700915, 0.2505278 , 0.27023223, 0.28641802, 0.29275158,\n",
       "                     0.30823364, 0.32301196, 0.32723434, 0.33779029, 0.36242083,\n",
       "                     0.37860662, 0.38282899, 0.40394089, 0.40675581, 0.40957072,\n",
       "                     0.41520056, 0.44405348, 0.45601689, 0.45953554, 0.49331457,\n",
       "                     0.51724138, 0.53764954, 0.57283603, 0.58479944, 0.59535538,\n",
       "                     0.59746657, 0.60028149, 0.6122449 , 0.63054187, 0.63546798,\n",
       "                     0.63757917, 0.64250528, 0.65165376, 0.69247009, 0.69458128,\n",
       "                     0.70795215, 0.71358198, 0.71780436, 0.73680507, 0.74736101,\n",
       "                     0.74876847, 0.76284307, 0.76495426, 0.77973258, 0.77973258,\n",
       "                     0.80084448, 0.80647431, 0.81703026, 0.82828994, 0.85080929,\n",
       "                     0.86347643, 0.86347643, 0.88106967, 0.88669951, 0.89795918,\n",
       "                     0.89936664, 0.90147783, 0.9078114 , 0.91414497, 0.92399719,\n",
       "                     0.93807178, 0.94018297, 0.94581281, 0.94651654, 0.95073892,\n",
       "                     0.95355384, 0.96129486, 0.96199859, 0.96199859, 0.96199859,\n",
       "                     0.96270232, 0.96551724, 0.96622097, 1.        ]), tpr=array([0.        , 0.02614379, 0.03267974, 0.03848947, 0.04284677,\n",
       "                     0.05591866, 0.05664488, 0.06318083, 0.07262164, 0.07770516,\n",
       "                     0.07988381, 0.0885984 , 0.10094408, 0.12345679, 0.14814815,\n",
       "                     0.15613653, 0.18809005, 0.20769789, 0.22222222, 0.2519971 ,\n",
       "                     0.26289034, 0.28249818, 0.28976035, 0.29411765, 0.30428468,\n",
       "                     0.32171387, 0.32534495, 0.33986928, 0.35439361, 0.35947712,\n",
       "                     0.37545389, 0.389252  , 0.39215686, 0.40813362, 0.43282498,\n",
       "                     0.45315904, 0.46114742, 0.48729121, 0.49019608, 0.49455338,\n",
       "                     0.50036311, 0.53231663, 0.53957879, 0.54466231, 0.59404503,\n",
       "                     0.6194626 , 0.64052288, 0.66884532, 0.68119099, 0.68917938,\n",
       "                     0.69498911, 0.69789397, 0.70733479, 0.72258533, 0.72839506,\n",
       "                     0.72912128, 0.73275236, 0.74146696, 0.79448076, 0.79738562,\n",
       "                     0.80900508, 0.81481481, 0.82207698, 0.83732752, 0.84676834,\n",
       "                     0.85039942, 0.86056645, 0.86347131, 0.87509078, 0.87581699,\n",
       "                     0.88671024, 0.89106754, 0.89760349, 0.90777052, 0.92229484,\n",
       "                     0.93100944, 0.93173566, 0.94335512, 0.94771242, 0.95787945,\n",
       "                     0.95933188, 0.9600581 , 0.96296296, 0.96659405, 0.97167756,\n",
       "                     0.97603486, 0.97748729, 0.9869281 , 0.98910675, 0.98983297,\n",
       "                     0.9912854 , 0.9956427 , 0.99636892, 0.99709513, 0.99854757,\n",
       "                     0.99927378, 0.99927378, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -2.23143551e-01,\n",
       "                     -2.87682072e-01, -4.05465108e-01, -4.70003629e-01, -5.10825624e-01,\n",
       "                     -5.26093096e-01, -5.38996501e-01, -5.87786665e-01, -6.02175402e-01,\n",
       "                     -6.06135804e-01, -6.93147181e-01, -7.48938540e-01, -7.56326082e-01,\n",
       "                     -7.59105148e-01, -7.71790308e-01, -7.73189888e-01, -7.75064303e-01,\n",
       "                     -8.18310324e-01, -8.19440906e-01, -8.32909123e-01, -8.47297860e-01,\n",
       "                     -8.57450232e-01, -8.64997437e-01, -8.75468737e-01, -8.87935506e-01,\n",
       "                     -8.90972924e-01, -8.96088025e-01, -8.97941593e-01, -9.16290732e-01,\n",
       "                     -9.38269639e-01, -9.52008814e-01, -9.62275845e-01, -9.65080896e-01,\n",
       "                     -9.69400557e-01, -9.80829253e-01, -1.01160091e+00, -1.02961942e+00,\n",
       "                     -1.03407377e+00, -1.03609193e+00, -1.05154478e+00, -1.07044141e+00,\n",
       "                     -1.07371474e+00, -1.09376966e+00, -1.09861229e+00, -1.10293195e+00,\n",
       "                     -1.11803037e+00, -1.12846525e+00, -1.13943428e+00, -1.17865500e+00,\n",
       "                     -1.20397280e+00, -1.21478372e+00, -1.21639532e+00, -1.25276297e+00,\n",
       "                     -1.26566637e+00, -1.29928298e+00, -1.30043307e+00, -1.32175584e+00,\n",
       "                     -1.33828514e+00, -1.36524095e+00, -1.37951467e+00, -1.38629436e+00,\n",
       "                     -1.40534256e+00, -1.43508453e+00, -1.43848011e+00, -1.48807706e+00,\n",
       "                     -1.49009115e+00, -1.50407740e+00, -1.52242654e+00, -1.60943791e+00,\n",
       "                     -1.64020957e+00, -1.68089688e+00, -1.70474809e+00, -1.73460106e+00,\n",
       "                     -1.79175947e+00, -1.80212226e+00, -1.81915844e+00, -1.86075234e+00,\n",
       "                     -1.89085037e+00, -1.90616982e+00, -1.90954250e+00, -1.91692261e+00,\n",
       "                     -1.92529086e+00, -1.94591015e+00, -1.96944065e+00, -1.97275740e+00,\n",
       "                     -2.14006616e+00, -2.14843441e+00, -2.19722458e+00, -2.26868354e+00,\n",
       "                     -2.30258509e+00, -2.39789527e+00, -2.51230562e+00, -2.63905733e+00,\n",
       "                     -3.36729583e+00, -3.82864140e+00, -3.45387764e+01]), auc_score=0.5720063248798881, privacy_risk=0.552136307907582, accuracy=0.552136307907582, tpr_ind=0.8220769789397241, tnr_ind=0.2821956368754398, test_train_ratio=1.0319535221496006, dataset_size=[1377, 1421]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.01251841, 0.01840943, 0.02798233, 0.03166421,\n",
       "                     0.03387334, 0.03755523, 0.04418262, 0.04860088, 0.0544919 ,\n",
       "                     0.05596465, 0.06701031, 0.07142857, 0.07290133, 0.07879234,\n",
       "                     0.12739323, 0.13622975, 0.13991163, 0.14948454, 0.15611193,\n",
       "                     0.18556701, 0.19072165, 0.1921944 , 0.21354934, 0.22091311,\n",
       "                     0.22901325, 0.33799705, 0.34020619, 0.34536082, 0.35714286,\n",
       "                     0.35935199, 0.36745214, 0.37260677, 0.40132548, 0.40500736,\n",
       "                     0.4197349 , 0.42783505, 0.43740795, 0.45213549, 0.46097202,\n",
       "                     0.46318115, 0.4808542 , 0.51178203, 0.51251841, 0.52135493,\n",
       "                     0.52945508, 0.54050074, 0.54933726, 0.56259205, 0.57731959,\n",
       "                     0.61782032, 0.62592047, 0.63328424, 0.64359352, 0.66789396,\n",
       "                     0.69440353, 0.70618557, 0.73416789, 0.7437408 , 0.75478645,\n",
       "                     0.78129602, 0.78792342, 0.7916053 , 0.79749632, 0.80191458,\n",
       "                     0.80633284, 0.81516937, 0.82621502, 0.82916053, 0.83063328,\n",
       "                     0.83799705, 0.84020619, 0.84756996, 0.84977909, 0.85198822,\n",
       "                     0.85640648, 0.88365243, 0.91163476, 0.91237113, 0.91826215,\n",
       "                     0.91899853, 0.92194404, 0.92488954, 0.92709867, 0.93298969,\n",
       "                     0.93298969, 0.93446244, 0.93667158, 0.94035346, 0.95360825,\n",
       "                     0.95729013, 0.96170839, 1.        ]), tpr=array([0.        , 0.02847222, 0.04236111, 0.04861111, 0.05763889,\n",
       "                     0.06111111, 0.06736111, 0.07430556, 0.08263889, 0.09097222,\n",
       "                     0.09375   , 0.10763889, 0.11736111, 0.11736111, 0.12777778,\n",
       "                     0.18472222, 0.19513889, 0.2       , 0.20625   , 0.21180556,\n",
       "                     0.23263889, 0.23611111, 0.23888889, 0.26388889, 0.26805556,\n",
       "                     0.27638889, 0.37291667, 0.375     , 0.37916667, 0.39930556,\n",
       "                     0.40555556, 0.41319444, 0.41944444, 0.44861111, 0.45833333,\n",
       "                     0.47569444, 0.48055556, 0.49583333, 0.51180556, 0.52638889,\n",
       "                     0.52916667, 0.54305556, 0.56666667, 0.56805556, 0.5875    ,\n",
       "                     0.59305556, 0.60069444, 0.61180556, 0.62291667, 0.6375    ,\n",
       "                     0.67986111, 0.68611111, 0.69375   , 0.71041667, 0.72986111,\n",
       "                     0.75902778, 0.77777778, 0.79513889, 0.80277778, 0.81736111,\n",
       "                     0.84305556, 0.84652778, 0.84861111, 0.85416667, 0.85972222,\n",
       "                     0.86388889, 0.87430556, 0.89236111, 0.89791667, 0.90277778,\n",
       "                     0.90694444, 0.90763889, 0.91736111, 0.92152778, 0.92638889,\n",
       "                     0.93541667, 0.94791667, 0.97430556, 0.97569444, 0.98055556,\n",
       "                     0.98055556, 0.98263889, 0.98263889, 0.98402778, 0.98611111,\n",
       "                     0.98680556, 0.9875    , 0.98819444, 0.99027778, 0.99444444,\n",
       "                     0.99722222, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.23143551e-01, -2.87682072e-01,\n",
       "                     -3.25422400e-01, -3.36472237e-01, -3.67724780e-01, -4.05465108e-01,\n",
       "                     -5.10825624e-01, -5.44727175e-01, -5.59615788e-01, -5.87786665e-01,\n",
       "                     -6.19039208e-01, -6.35988767e-01, -6.80243776e-01, -6.93147181e-01,\n",
       "                     -7.25937003e-01, -7.41937345e-01, -7.47214402e-01, -7.53771802e-01,\n",
       "                     -7.86965936e-01, -7.88457360e-01, -8.10930216e-01, -8.13396309e-01,\n",
       "                     -8.42678915e-01, -8.47297860e-01, -8.48210269e-01, -8.57450232e-01,\n",
       "                     -8.87303195e-01, -8.90972924e-01, -8.93817876e-01, -8.97941593e-01,\n",
       "                     -9.16290732e-01, -9.18059079e-01, -9.21681581e-01, -9.40007258e-01,\n",
       "                     -9.44461609e-01, -9.57533690e-01, -9.75379648e-01, -9.80829253e-01,\n",
       "                     -1.01160091e+00, -1.01405490e+00, -1.01693426e+00, -1.02961942e+00,\n",
       "                     -1.04982212e+00, -1.05736933e+00, -1.06784063e+00, -1.07755888e+00,\n",
       "                     -1.09861229e+00, -1.11436065e+00, -1.14725410e+00, -1.15267951e+00,\n",
       "                     -1.16315081e+00, -1.19139402e+00, -1.20039498e+00, -1.21109027e+00,\n",
       "                     -1.21502264e+00, -1.22897411e+00, -1.25276297e+00, -1.25954266e+00,\n",
       "                     -1.28692189e+00, -1.30833282e+00, -1.32913595e+00, -1.33500107e+00,\n",
       "                     -1.34707365e+00, -1.38629436e+00, -1.40282366e+00, -1.40534256e+00,\n",
       "                     -1.41706602e+00, -1.42138568e+00, -1.57553636e+00, -1.60943791e+00,\n",
       "                     -1.63760879e+00, -1.65388968e+00, -1.69167601e+00, -1.69459572e+00,\n",
       "                     -1.70474809e+00, -1.72370601e+00, -1.79175947e+00, -1.94591015e+00,\n",
       "                     -2.04769284e+00, -2.07944154e+00, -2.19722458e+00, -2.30258509e+00,\n",
       "                     -2.33537492e+00, -2.39789527e+00, -2.48490665e+00, -2.63905733e+00,\n",
       "                     -2.67414865e+00, -2.70805020e+00, -2.89827694e+00, -2.89958841e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5525369211258386, privacy_risk=0.5395050932744232, accuracy=0.5395050932744232, tpr_ind=0.9354166666666667, tnr_ind=0.14359351988217967, test_train_ratio=0.9430555555555555, dataset_size=[1440, 1358]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.01506456, 0.01649928, 0.02008608, 0.02367288,\n",
       "                     0.03443329, 0.03802009, 0.04232425, 0.05738881, 0.06527977,\n",
       "                     0.06527977, 0.07675753, 0.08177905, 0.08751793, 0.15064562,\n",
       "                     0.16427547, 0.17288379, 0.19296987, 0.20229555, 0.20444763,\n",
       "                     0.20946915, 0.22596844, 0.23959828, 0.25322812, 0.27474892,\n",
       "                     0.28550933, 0.30774749, 0.30774749, 0.32639885, 0.34361549,\n",
       "                     0.34863702, 0.3543759 , 0.38593974, 0.39167862, 0.46628407,\n",
       "                     0.47058824, 0.48063128, 0.49067432, 0.50430416, 0.517934  ,\n",
       "                     0.52008608, 0.52439024, 0.54375897, 0.54591105, 0.57173601,\n",
       "                     0.58393113, 0.60114778, 0.61406026, 0.62840746, 0.63199426,\n",
       "                     0.68220947, 0.68507891, 0.68866571, 0.69440459, 0.70373027,\n",
       "                     0.70659971, 0.78981349, 0.79196557, 0.80774749, 0.84218077,\n",
       "                     0.88593974, 0.89096126, 0.89454806, 0.89956958, 0.90243902,\n",
       "                     0.90315638, 0.9045911 , 0.90746055, 0.91678623, 0.91893831,\n",
       "                     0.91965567, 0.92109039, 0.92395983, 0.92826399, 0.92898135,\n",
       "                     0.93328551, 0.93902439, 0.94763271, 0.94763271, 0.95337159,\n",
       "                     0.95480631, 0.95552367, 0.95839311, 0.95839311, 0.95982783,\n",
       "                     0.96843615, 0.96987088, 0.97274032, 1.        ]), tpr=array([0.        , 0.02920228, 0.03276353, 0.03988604, 0.04415954,\n",
       "                     0.05982906, 0.06623932, 0.06980057, 0.08475783, 0.0968661 ,\n",
       "                     0.0982906 , 0.11253561, 0.11823362, 0.12535613, 0.1951567 ,\n",
       "                     0.21011396, 0.22222222, 0.25071225, 0.26068376, 0.26495726,\n",
       "                     0.27136752, 0.28988604, 0.3005698 , 0.31339031, 0.33119658,\n",
       "                     0.34116809, 0.36182336, 0.36253561, 0.39031339, 0.40669516,\n",
       "                     0.41239316, 0.41880342, 0.45584046, 0.46296296, 0.52920228,\n",
       "                     0.53917379, 0.54985755, 0.55982906, 0.57122507, 0.58404558,\n",
       "                     0.58831909, 0.59330484, 0.61039886, 0.61965812, 0.64173789,\n",
       "                     0.65384615, 0.66809117, 0.68019943, 0.6980057 , 0.70156695,\n",
       "                     0.75356125, 0.76282051, 0.76851852, 0.77350427, 0.78133903,\n",
       "                     0.78347578, 0.84330484, 0.84401709, 0.86182336, 0.88319088,\n",
       "                     0.93091168, 0.94017094, 0.94586895, 0.95156695, 0.95512821,\n",
       "                     0.95726496, 0.95868946, 0.96082621, 0.96509972, 0.96794872,\n",
       "                     0.96866097, 0.97079772, 0.97364672, 0.97792023, 0.98005698,\n",
       "                     0.98148148, 0.98361823, 0.98860399, 0.99002849, 0.99002849,\n",
       "                     0.99074074, 0.99216524, 0.99430199, 0.99501425, 0.99643875,\n",
       "                     0.99786325, 0.9985755 , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.82321557e-01, -2.62364264e-01,\n",
       "                     -2.87682072e-01, -4.05465108e-01, -4.21213465e-01, -4.70003629e-01,\n",
       "                     -5.10825624e-01, -5.34082486e-01, -5.59615788e-01, -5.87786665e-01,\n",
       "                     -6.28608659e-01, -6.45137961e-01, -6.93147181e-01, -7.16677678e-01,\n",
       "                     -7.23918839e-01, -7.48062938e-01, -7.62140052e-01, -7.73189888e-01,\n",
       "                     -7.98507696e-01, -8.08660068e-01, -8.18310324e-01, -8.23200309e-01,\n",
       "                     -8.24175443e-01, -8.47297860e-01, -8.85950015e-01, -8.87303195e-01,\n",
       "                     -9.16290732e-01, -9.24948795e-01, -9.32820034e-01, -9.38269639e-01,\n",
       "                     -9.54031060e-01, -9.55511445e-01, -9.66276639e-01, -9.71860583e-01,\n",
       "                     -9.80829253e-01, -1.03609193e+00, -1.07755888e+00, -1.07992016e+00,\n",
       "                     -1.09861229e+00, -1.11088238e+00, -1.13943428e+00, -1.14862271e+00,\n",
       "                     -1.15098027e+00, -1.17411984e+00, -1.17865500e+00, -1.19213835e+00,\n",
       "                     -1.19996478e+00, -1.20397280e+00, -1.25080410e+00, -1.25276297e+00,\n",
       "                     -1.29928298e+00, -1.34992672e+00, -1.35314215e+00, -1.38629436e+00,\n",
       "                     -1.38926613e+00, -1.43508453e+00, -1.47247206e+00, -1.48160454e+00,\n",
       "                     -1.53831057e+00, -1.56523182e+00, -1.58777642e+00, -1.60943791e+00,\n",
       "                     -1.68639895e+00, -1.69167601e+00, -1.70474809e+00, -1.73911574e+00,\n",
       "                     -1.76358859e+00, -1.79175947e+00, -1.84582669e+00, -1.87180218e+00,\n",
       "                     -1.94591015e+00, -1.96944065e+00, -2.00148000e+00, -2.01490302e+00,\n",
       "                     -2.07944154e+00, -2.09714112e+00, -2.14006616e+00, -2.16905370e+00,\n",
       "                     -2.30258509e+00, -2.35137526e+00, -2.56494936e+00, -2.83321334e+00,\n",
       "                     -3.04452244e+00, -3.11351531e+00, -3.29583687e+00, -3.36729583e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5550257105135155, privacy_risk=0.5399264041660025, accuracy=0.5399264041660025, tpr_ind=0.7685185185185185, tnr_ind=0.3113342898134864, test_train_ratio=0.9928774928774928, dataset_size=[1404, 1394]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.00570207, 0.0085531 , 0.01140413, 0.01425517,\n",
       "                     0.01924448, 0.02209551, 0.02637206, 0.02708482, 0.03349964,\n",
       "                     0.04133999, 0.04846757, 0.04918033, 0.05702067, 0.06414825,\n",
       "                     0.06771205, 0.07483963, 0.08267997, 0.09622238, 0.15110478,\n",
       "                     0.16037063, 0.1746258 , 0.2002851 , 0.20741269, 0.21382751,\n",
       "                     0.22451889, 0.23877406, 0.24590164, 0.25659301, 0.25801853,\n",
       "                     0.26086957, 0.26229508, 0.26585887, 0.26728439, 0.27797577,\n",
       "                     0.29294369, 0.29864576, 0.30434783, 0.31076265, 0.31717748,\n",
       "                     0.32216679, 0.3235923 , 0.34996436, 0.3528154 , 0.41838917,\n",
       "                     0.4383464 , 0.44048468, 0.44761226, 0.45473984, 0.45687812,\n",
       "                     0.48039914, 0.48610121, 0.49607983, 0.52886671, 0.54169636,\n",
       "                     0.58802566, 0.58873842, 0.62295082, 0.62865289, 0.64076978,\n",
       "                     0.64433357, 0.6471846 , 0.67355666, 0.67498218, 0.70848182,\n",
       "                     0.70990734, 0.71703493, 0.71703493, 0.74625802, 0.74910905,\n",
       "                     0.77334284, 0.80042766, 0.80399145, 0.81824661, 0.84176764,\n",
       "                     0.84533143, 0.84604419, 0.86386315, 0.86885246, 0.87526728,\n",
       "                     0.87598004, 0.89807555, 0.89878831, 0.89950107, 0.9315752 ,\n",
       "                     0.9365645 , 0.94369209, 0.94725588, 0.94725588, 0.95153243,\n",
       "                     0.95438346, 0.96436208, 0.96507484, 0.96792587, 0.97006415,\n",
       "                     0.9743407 , 1.        ]), tpr=array([0.        , 0.02365591, 0.03154122, 0.04157706, 0.04731183,\n",
       "                     0.0516129 , 0.05519713, 0.06379928, 0.06666667, 0.07455197,\n",
       "                     0.08888889, 0.09749104, 0.10035842, 0.10896057, 0.11326165,\n",
       "                     0.12043011, 0.13046595, 0.13548387, 0.14336918, 0.21146953,\n",
       "                     0.22007168, 0.23010753, 0.25519713, 0.26379928, 0.27455197,\n",
       "                     0.28315412, 0.29677419, 0.30609319, 0.31899642, 0.32258065,\n",
       "                     0.32616487, 0.32759857, 0.33189964, 0.33620072, 0.34982079,\n",
       "                     0.36057348, 0.36487455, 0.37132616, 0.37419355, 0.38136201,\n",
       "                     0.38566308, 0.38853047, 0.41003584, 0.41577061, 0.47598566,\n",
       "                     0.49964158, 0.50035842, 0.51612903, 0.52043011, 0.52114695,\n",
       "                     0.54695341, 0.55555556, 0.56774194, 0.59283154, 0.60860215,\n",
       "                     0.64874552, 0.65232975, 0.68387097, 0.68888889, 0.70179211,\n",
       "                     0.70896057, 0.71039427, 0.72688172, 0.72759857, 0.76917563,\n",
       "                     0.77491039, 0.77992832, 0.78064516, 0.8172043 , 0.81935484,\n",
       "                     0.83799283, 0.85734767, 0.85878136, 0.86666667, 0.88530466,\n",
       "                     0.89032258, 0.89247312, 0.90896057, 0.91111111, 0.91684588,\n",
       "                     0.91684588, 0.9390681 , 0.94050179, 0.94336918, 0.96630824,\n",
       "                     0.96989247, 0.97706093, 0.97849462, 0.97992832, 0.98566308,\n",
       "                     0.98637993, 0.990681  , 0.9921147 , 0.99426523, 0.99498208,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -8.70113770e-02, -1.33531393e-01,\n",
       "                     -2.23143551e-01, -2.87682072e-01, -3.36472237e-01, -3.48306694e-01,\n",
       "                     -4.05465108e-01, -4.92476485e-01, -5.10825624e-01, -5.38996501e-01,\n",
       "                     -5.59615788e-01, -5.87786665e-01, -6.06135804e-01, -6.93147181e-01,\n",
       "                     -7.29514825e-01, -7.62140052e-01, -7.77028665e-01, -7.80852761e-01,\n",
       "                     -7.88457360e-01, -7.94929875e-01, -8.06806499e-01, -8.10930216e-01,\n",
       "                     -8.18310324e-01, -8.19440906e-01, -8.28066498e-01, -8.36248024e-01,\n",
       "                     -8.47297860e-01, -8.71838969e-01, -8.75468737e-01, -8.87303195e-01,\n",
       "                     -8.89262059e-01, -8.93817876e-01, -9.00786545e-01, -9.02867712e-01,\n",
       "                     -9.16290732e-01, -9.38269639e-01, -9.40983344e-01, -9.55511445e-01,\n",
       "                     -9.61411167e-01, -9.65080896e-01, -9.73178106e-01, -9.80829253e-01,\n",
       "                     -9.94133219e-01, -1.00169439e+00, -1.02961942e+00, -1.04380405e+00,\n",
       "                     -1.05314991e+00, -1.05605267e+00, -1.06087196e+00, -1.07044141e+00,\n",
       "                     -1.07451474e+00, -1.08536706e+00, -1.09861229e+00, -1.10454702e+00,\n",
       "                     -1.14513230e+00, -1.15780116e+00, -1.16760516e+00, -1.21010779e+00,\n",
       "                     -1.22377543e+00, -1.25276297e+00, -1.27122503e+00, -1.28785429e+00,\n",
       "                     -1.29700767e+00, -1.30833282e+00, -1.31094492e+00, -1.32175584e+00,\n",
       "                     -1.33603253e+00, -1.35239281e+00, -1.38629436e+00, -1.39953959e+00,\n",
       "                     -1.42403469e+00, -1.45225233e+00, -1.50407740e+00, -1.55059741e+00,\n",
       "                     -1.55814462e+00, -1.56498615e+00, -1.60943791e+00, -1.66500776e+00,\n",
       "                     -1.67397643e+00, -1.69845876e+00, -1.70474809e+00, -1.87180218e+00,\n",
       "                     -1.92333583e+00, -1.94591015e+00, -2.03432111e+00, -2.07944154e+00,\n",
       "                     -2.12026354e+00, -2.13470422e+00, -2.19722458e+00, -2.25129180e+00,\n",
       "                     -2.54553127e+00, -2.66025954e+00, -2.89037176e+00, -3.42936826e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5550678653269876, privacy_risk=0.5359225111576065, accuracy=0.5359225111576065, tpr_ind=0.34982078853046594, tnr_ind=0.722024233784747, test_train_ratio=1.0057347670250896, dataset_size=[1395, 1403]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.00850461, 0.01275691, 0.01559178, 0.0163005 ,\n",
       "                     0.0205528 , 0.02197023, 0.03614458, 0.04039688, 0.05173636,\n",
       "                     0.05386251, 0.0659107 , 0.06661942, 0.07087172, 0.07228916,\n",
       "                     0.09567682, 0.10347271, 0.1112686 , 0.15308292, 0.16583983,\n",
       "                     0.17150957, 0.18072289, 0.18497519, 0.19064493, 0.19489724,\n",
       "                     0.20694543, 0.2714387 , 0.28773919, 0.30403969, 0.31963147,\n",
       "                     0.32175762, 0.33238838, 0.35152374, 0.36286322, 0.37774628,\n",
       "                     0.39475549, 0.40184266, 0.41672573, 0.4280652 , 0.43515237,\n",
       "                     0.46137491, 0.48263643, 0.4939759 , 0.51381999, 0.53153792,\n",
       "                     0.56839121, 0.58540043, 0.59461375, 0.59886605, 0.62508859,\n",
       "                     0.6378455 , 0.64564139, 0.67753366, 0.70304748, 0.7080085 ,\n",
       "                     0.71296953, 0.72147413, 0.72927002, 0.73068746, 0.73635719,\n",
       "                     0.74698795, 0.76399717, 0.77958894, 0.78809355, 0.81785967,\n",
       "                     0.82565556, 0.8313253 , 0.84337349, 0.84620836, 0.85471297,\n",
       "                     0.86321758, 0.86463501, 0.86463501, 0.8724309 , 0.87526577,\n",
       "                     0.89440113, 0.90077959, 0.93479802, 0.94046775, 0.94117647,\n",
       "                     0.94755493, 0.94897236, 0.95038979, 0.95251595, 0.95322466,\n",
       "                     0.95535082, 0.95535082, 0.96102055, 0.96172927, 0.96527286,\n",
       "                     1.        ]), tpr=array([0.        , 0.02451334, 0.03172314, 0.03821197, 0.04109589,\n",
       "                     0.04974766, 0.05695746, 0.07714492, 0.08074982, 0.09805335,\n",
       "                     0.10021629, 0.11535689, 0.11896179, 0.12328767, 0.12833453,\n",
       "                     0.15645278, 0.16943043, 0.17736121, 0.22062004, 0.23648161,\n",
       "                     0.24224946, 0.2480173 , 0.25306417, 0.25955299, 0.26964672,\n",
       "                     0.28550829, 0.3518385 , 0.37274694, 0.39293439, 0.40951694,\n",
       "                     0.41528479, 0.42393655, 0.44340303, 0.46070656, 0.48017304,\n",
       "                     0.49819755, 0.50540735, 0.518385  , 0.52126893, 0.53280461,\n",
       "                     0.55227109, 0.5702956 , 0.58255227, 0.60057678, 0.61571738,\n",
       "                     0.64960346, 0.66834895, 0.67267484, 0.68060562, 0.69863014,\n",
       "                     0.71232877, 0.71809661, 0.75486662, 0.7815429 , 0.78803172,\n",
       "                     0.79235761, 0.79596251, 0.80173035, 0.80317231, 0.8111031 ,\n",
       "                     0.82335977, 0.84354722, 0.85652487, 0.86373468, 0.88824802,\n",
       "                     0.8925739 , 0.90194665, 0.90987743, 0.9149243 , 0.92069214,\n",
       "                     0.92357606, 0.92501802, 0.92645999, 0.93222783, 0.93583273,\n",
       "                     0.95313627, 0.95818313, 0.98413843, 0.98774333, 0.98846431,\n",
       "                     0.98918529, 0.98990627, 0.99134823, 0.99423216, 0.99567412,\n",
       "                     0.99783706, 0.99855804, 0.99927902, 1.        , 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.82321557e-01, -2.00670695e-01,\n",
       "                     -2.23143551e-01, -2.87682072e-01, -3.13657559e-01, -4.05465108e-01,\n",
       "                     -4.70003629e-01, -4.85507816e-01, -5.10825624e-01, -5.59615788e-01,\n",
       "                     -5.87786665e-01, -6.06135804e-01, -6.19039208e-01, -6.72944473e-01,\n",
       "                     -6.93147181e-01, -7.37598943e-01, -7.45593656e-01, -7.59105148e-01,\n",
       "                     -8.04372816e-01, -8.10930216e-01, -8.26678573e-01, -8.47297860e-01,\n",
       "                     -8.60201265e-01, -8.67100488e-01, -8.73450573e-01, -8.78550404e-01,\n",
       "                     -8.87303195e-01, -8.99196299e-01, -9.16290732e-01, -9.49080555e-01,\n",
       "                     -9.68737207e-01, -9.80829253e-01, -1.01345448e+00, -1.01419495e+00,\n",
       "                     -1.02961942e+00, -1.04731899e+00, -1.07535543e+00, -1.07880966e+00,\n",
       "                     -1.09218140e+00, -1.09861229e+00, -1.11923158e+00, -1.12492960e+00,\n",
       "                     -1.12986483e+00, -1.13140211e+00, -1.14862271e+00, -1.15267951e+00,\n",
       "                     -1.15745279e+00, -1.17557333e+00, -1.20397280e+00, -1.21639532e+00,\n",
       "                     -1.22146596e+00, -1.22536399e+00, -1.22722967e+00, -1.27766052e+00,\n",
       "                     -1.28093385e+00, -1.32175584e+00, -1.34992672e+00, -1.36330484e+00,\n",
       "                     -1.37147928e+00, -1.37230812e+00, -1.38629436e+00, -1.39341183e+00,\n",
       "                     -1.49091931e+00, -1.50407740e+00, -1.55059741e+00, -1.55334845e+00,\n",
       "                     -1.55814462e+00, -1.56218503e+00, -1.60943791e+00, -1.65595793e+00,\n",
       "                     -1.70474809e+00, -1.71297859e+00, -1.75785792e+00, -1.79175947e+00,\n",
       "                     -1.86214027e+00, -1.88454120e+00, -1.89184293e+00, -2.19722458e+00,\n",
       "                     -2.30258509e+00, -2.35137526e+00, -2.39789527e+00, -2.42036813e+00,\n",
       "                     -2.45100510e+00, -2.59026717e+00, -2.83321334e+00, -3.17805383e+00,\n",
       "                     -3.29583687e+00, -3.85014760e+00, -3.45387764e+01]), auc_score=0.5719639233808723, privacy_risk=0.551782344612344, accuracy=0.551782344612344, tpr_ind=0.505407354001442, tnr_ind=0.5981573352232459, test_train_ratio=1.0173035328046143, dataset_size=[1387, 1411]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.00679245, 0.01132075, 0.01433962, 0.01735849,\n",
       "                     0.02339623, 0.02641509, 0.0309434 , 0.03471698, 0.04377358,\n",
       "                     0.04528302, 0.05283019, 0.05584906, 0.06716981, 0.07471698,\n",
       "                     0.08075472, 0.09433962, 0.09735849, 0.10490566, 0.12679245,\n",
       "                     0.13886792, 0.15169811, 0.16679245, 0.17584906, 0.17886792,\n",
       "                     0.18641509, 0.19471698, 0.2       , 0.22113208, 0.23018868,\n",
       "                     0.24679245, 0.24830189, 0.27018868, 0.27471698, 0.28377358,\n",
       "                     0.28830189, 0.29509434, 0.30943396, 0.34490566, 0.36226415,\n",
       "                     0.36830189, 0.37509434, 0.38943396, 0.39622642, 0.39849057,\n",
       "                     0.40150943, 0.4445283 , 0.45358491, 0.46490566, 0.47018868,\n",
       "                     0.4845283 , 0.48830189, 0.50264151, 0.50943396, 0.5290566 ,\n",
       "                     0.54490566, 0.54641509, 0.55471698, 0.56830189, 0.58037736,\n",
       "                     0.59169811, 0.60150943, 0.61056604, 0.62037736, 0.62264151,\n",
       "                     0.63924528, 0.64226415, 0.64679245, 0.65358491, 0.66113208,\n",
       "                     0.66943396, 0.67245283, 0.69962264, 0.73584906, 0.74867925,\n",
       "                     0.75773585, 0.77132075, 0.78566038, 0.7909434 , 0.79622642,\n",
       "                     0.79924528, 0.80679245, 0.80754717, 0.81358491, 0.81358491,\n",
       "                     0.81811321, 0.82415094, 0.82716981, 0.82867925, 0.84      ,\n",
       "                     0.8490566 , 0.88830189, 0.88981132, 0.90339623, 0.90339623,\n",
       "                     0.91245283, 0.91396226, 0.91924528, 0.92      , 0.92377358,\n",
       "                     0.9245283 , 0.92603774, 0.92679245, 0.92981132, 0.93509434,\n",
       "                     0.93660377, 0.94490566, 0.94641509, 0.95018868, 0.95169811,\n",
       "                     0.9645283 , 0.96679245, 0.96981132, 0.97056604, 0.97056604,\n",
       "                     1.        ]), tpr=array([0.        , 0.01697217, 0.02308215, 0.02919212, 0.04005431,\n",
       "                     0.04955872, 0.05295316, 0.06042091, 0.06449423, 0.07399864,\n",
       "                     0.07671419, 0.08825526, 0.09097081, 0.09775967, 0.10319077,\n",
       "                     0.11541073, 0.12559403, 0.13102512, 0.14256619, 0.18058384,\n",
       "                     0.19687712, 0.21181263, 0.22878479, 0.23557366, 0.23828921,\n",
       "                     0.25186694, 0.25661914, 0.2688391 , 0.29260014, 0.30210455,\n",
       "                     0.31296673, 0.31636117, 0.35302105, 0.35709437, 0.36456212,\n",
       "                     0.36931432, 0.3754243 , 0.39375424, 0.42701969, 0.43516633,\n",
       "                     0.4467074 , 0.45145961, 0.47386286, 0.47929396, 0.48133062,\n",
       "                     0.48404616, 0.51527495, 0.52206382, 0.53496266, 0.54378819,\n",
       "                     0.55125594, 0.5634759 , 0.57705363, 0.58248473, 0.60488798,\n",
       "                     0.61099796, 0.61710794, 0.6245757 , 0.63815343, 0.65241005,\n",
       "                     0.65784114, 0.66259335, 0.68499661, 0.69110659, 0.69653768,\n",
       "                     0.71486762, 0.71758316, 0.71961982, 0.72708758, 0.7311609 ,\n",
       "                     0.7413442 , 0.74405974, 0.77257298, 0.8071962 , 0.81941616,\n",
       "                     0.82620502, 0.83638832, 0.8479294 , 0.85200272, 0.85947047,\n",
       "                     0.86354379, 0.87101154, 0.8730482 , 0.87712152, 0.87847929,\n",
       "                     0.8832315 , 0.88798371, 0.89137814, 0.89273591, 0.9035981 ,\n",
       "                     0.90631365, 0.94501018, 0.94704684, 0.95247794, 0.95315682,\n",
       "                     0.95994569, 0.96266124, 0.9646979 , 0.96537678, 0.96877122,\n",
       "                     0.97012899, 0.97080788, 0.97352342, 0.97691785, 0.98234895,\n",
       "                     0.98302783, 0.98574338, 0.98710115, 0.98845893, 0.98913781,\n",
       "                     0.99389002, 0.99728445, 0.99796334, 0.99864223, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.05360516e-01, -2.87682072e-01,\n",
       "                     -3.18453731e-01, -4.05465108e-01, -4.70003629e-01, -5.02091944e-01,\n",
       "                     -5.10825624e-01, -5.50046337e-01, -5.59615788e-01, -5.67984038e-01,\n",
       "                     -5.70544858e-01, -5.87786665e-01, -5.99621123e-01, -6.06135804e-01,\n",
       "                     -6.24154309e-01, -6.28608659e-01, -6.32522559e-01, -6.47477144e-01,\n",
       "                     -6.61398482e-01, -6.80877088e-01, -6.93147181e-01, -7.14653386e-01,\n",
       "                     -7.47214402e-01, -7.51416089e-01, -7.62140052e-01, -7.73189888e-01,\n",
       "                     -7.75385279e-01, -7.94929875e-01, -8.10930216e-01, -8.20980552e-01,\n",
       "                     -8.39329691e-01, -8.47297860e-01, -8.60201265e-01, -8.87303195e-01,\n",
       "                     -8.89857475e-01, -9.08855753e-01, -9.12200747e-01, -9.16290732e-01,\n",
       "                     -9.34309237e-01, -9.44461609e-01, -9.46143695e-01, -9.65080896e-01,\n",
       "                     -9.80829253e-01, -1.01160091e+00, -1.02338887e+00, -1.02961942e+00,\n",
       "                     -1.04454507e+00, -1.04596856e+00, -1.04731899e+00, -1.05939158e+00,\n",
       "                     -1.06471074e+00, -1.06635143e+00, -1.07820342e+00, -1.08221848e+00,\n",
       "                     -1.08570888e+00, -1.09861229e+00, -1.13140211e+00, -1.13822143e+00,\n",
       "                     -1.13943428e+00, -1.14513230e+00, -1.14595841e+00, -1.16315081e+00,\n",
       "                     -1.16760516e+00, -1.17007125e+00, -1.17865500e+00, -1.18958407e+00,\n",
       "                     -1.19392247e+00, -1.20397280e+00, -1.20831121e+00, -1.25276297e+00,\n",
       "                     -1.26627669e+00, -1.26667140e+00, -1.26851133e+00, -1.28401551e+00,\n",
       "                     -1.29928298e+00, -1.30992138e+00, -1.38629436e+00, -1.41226985e+00,\n",
       "                     -1.41908418e+00, -1.42977947e+00, -1.48160454e+00, -1.48427477e+00,\n",
       "                     -1.50407740e+00, -1.52846885e+00, -1.58045038e+00, -1.58412010e+00,\n",
       "                     -1.60943791e+00, -1.63413053e+00, -1.65822808e+00, -1.66405900e+00,\n",
       "                     -1.69167601e+00, -1.70474809e+00, -1.73460106e+00, -1.74046617e+00,\n",
       "                     -1.74919985e+00, -1.75401914e+00, -1.79175947e+00, -1.84582669e+00,\n",
       "                     -1.87180218e+00, -1.89711998e+00, -1.99809590e+00, -2.07944154e+00,\n",
       "                     -2.08406049e+00, -2.19722458e+00, -2.22462355e+00, -2.30258509e+00,\n",
       "                     -2.48490665e+00, -2.56494936e+00, -2.58668934e+00, -2.62466859e+00,\n",
       "                     -2.63905733e+00, -3.21887582e+00, -3.46573590e+00, -3.45387764e+01]), auc_score=0.5618250521974152, privacy_risk=0.5422144513187053, accuracy=0.5422144513187053, tpr_ind=0.47386286490156143, tnr_ind=0.610566037735849, test_train_ratio=0.8995247793618466, dataset_size=[1473, 1325]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.00709723, 0.01277502, 0.01348474, 0.01632363,\n",
       "                     0.01703336, 0.01774308, 0.02767921, 0.03477644, 0.03761533,\n",
       "                     0.04542229, 0.04613201, 0.05748758, 0.07168204, 0.07381121,\n",
       "                     0.09439319, 0.11639461, 0.13129879, 0.13484741, 0.16110717,\n",
       "                     0.16607523, 0.17459191, 0.17885025, 0.22001419, 0.22214336,\n",
       "                     0.22711143, 0.23349894, 0.26685593, 0.28672818, 0.2874379 ,\n",
       "                     0.33073101, 0.34279631, 0.38821859, 0.39105749, 0.40241306,\n",
       "                     0.42299503, 0.43009226, 0.45138396, 0.45919092, 0.46132009,\n",
       "                     0.46628815, 0.47054649, 0.4861604 , 0.49183818, 0.49964514,\n",
       "                     0.52803407, 0.53158268, 0.54222853, 0.5628105 , 0.57345635,\n",
       "                     0.5748758 , 0.58977999, 0.60113556, 0.6515259 , 0.69339957,\n",
       "                     0.69907736, 0.70475515, 0.74520937, 0.78424414, 0.78637331,\n",
       "                     0.79347055, 0.80482612, 0.81192335, 0.81405252, 0.84953868,\n",
       "                     0.85521647, 0.87224982, 0.87579844, 0.87721789, 0.88147622,\n",
       "                     0.88289567, 0.90702626, 0.90773598, 0.90773598, 0.90986515,\n",
       "                     0.92405962, 0.92405962, 0.92618879, 0.92760823, 0.94535131,\n",
       "                     0.95528744, 0.96238467, 0.96522356, 0.96522356, 0.96735273,\n",
       "                     0.9694819 , 0.97019163, 0.97444996, 0.97799858, 0.97799858,\n",
       "                     1.        ]), tpr=array([0.        , 0.02159827, 0.02663787, 0.02951764, 0.04031677,\n",
       "                     0.04391649, 0.04895608, 0.06479482, 0.07631389, 0.0849532 ,\n",
       "                     0.09071274, 0.09287257, 0.10727142, 0.12311015, 0.12526998,\n",
       "                     0.14686825, 0.16846652, 0.17854572, 0.18142549, 0.20590353,\n",
       "                     0.20950324, 0.21958243, 0.2275018 , 0.26061915, 0.26709863,\n",
       "                     0.27645788, 0.28293737, 0.30669546, 0.31965443, 0.32181425,\n",
       "                     0.37221022, 0.39020878, 0.44132469, 0.44348452, 0.45356371,\n",
       "                     0.47012239, 0.48236141, 0.51187905, 0.51907847, 0.51979842,\n",
       "                     0.52411807, 0.52915767, 0.54211663, 0.54859611, 0.55507559,\n",
       "                     0.58099352, 0.58387329, 0.59323254, 0.61411087, 0.62491001,\n",
       "                     0.62850972, 0.63858891, 0.64362851, 0.70050396, 0.74802016,\n",
       "                     0.75305976, 0.75953924, 0.78617711, 0.82433405, 0.825054  ,\n",
       "                     0.83009359, 0.84449244, 0.85241181, 0.8574514 , 0.90208783,\n",
       "                     0.9049676 , 0.9150468 , 0.91720662, 0.92080634, 0.92728582,\n",
       "                     0.93088553, 0.94816415, 0.95104392, 0.95176386, 0.9524838 ,\n",
       "                     0.96040317, 0.96256299, 0.96400288, 0.96400288, 0.9762419 ,\n",
       "                     0.97984161, 0.98776098, 0.98920086, 0.98992081, 0.99208063,\n",
       "                     0.99640029, 0.99784017, 0.99856012, 0.99928006, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -2.23143551e-01,\n",
       "                     -2.87682072e-01, -3.36472237e-01, -3.56674944e-01, -4.05465108e-01,\n",
       "                     -4.73287704e-01, -5.10825624e-01, -5.59615788e-01, -5.75364145e-01,\n",
       "                     -5.87786665e-01, -5.97837001e-01, -6.35988767e-01, -6.93147181e-01,\n",
       "                     -7.11165686e-01, -7.17839793e-01, -7.33969175e-01, -7.73189888e-01,\n",
       "                     -7.88457360e-01, -7.94929875e-01, -8.39750655e-01, -8.46172368e-01,\n",
       "                     -8.47297860e-01, -8.69037847e-01, -8.93817876e-01, -8.96088025e-01,\n",
       "                     -9.13469856e-01, -9.16290732e-01, -9.45704617e-01, -9.63437510e-01,\n",
       "                     -9.73762086e-01, -9.80829253e-01, -1.01160091e+00, -1.01613607e+00,\n",
       "                     -1.01693426e+00, -1.02262638e+00, -1.02961942e+00, -1.04145387e+00,\n",
       "                     -1.04982212e+00, -1.06784063e+00, -1.09861229e+00, -1.13497993e+00,\n",
       "                     -1.13943428e+00, -1.14624034e+00, -1.16315081e+00, -1.17351360e+00,\n",
       "                     -1.18658106e+00, -1.20397280e+00, -1.21444410e+00, -1.23214368e+00,\n",
       "                     -1.25276297e+00, -1.26534175e+00, -1.28647403e+00, -1.31824090e+00,\n",
       "                     -1.32566974e+00, -1.33072451e+00, -1.33200128e+00, -1.38629436e+00,\n",
       "                     -1.42403469e+00, -1.44691898e+00, -1.45225233e+00, -1.45528723e+00,\n",
       "                     -1.50048673e+00, -1.50407740e+00, -1.51982575e+00, -1.54044504e+00,\n",
       "                     -1.60943791e+00, -1.63760879e+00, -1.64865863e+00, -1.66613326e+00,\n",
       "                     -1.75785792e+00, -1.79175947e+00, -1.81237876e+00, -1.82161243e+00,\n",
       "                     -1.94591015e+00, -1.99243016e+00, -2.01490302e+00, -2.05713578e+00,\n",
       "                     -2.07944154e+00, -2.14787870e+00, -2.48490665e+00, -2.63905733e+00,\n",
       "                     -2.67414865e+00, -2.94443898e+00, -2.97892516e+00, -3.21887582e+00,\n",
       "                     -3.95124372e+00, -4.04305127e+00, -3.45387764e+01]), auc_score=0.5449542461017597, privacy_risk=0.5302475447102628, accuracy=0.5302475447102628, tpr_ind=0.5118790496760259, tnr_ind=0.5486160397444997, test_train_ratio=1.0143988480921526, dataset_size=[1389, 1409]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.01789401, 0.01927047, 0.02339986, 0.02546456,\n",
       "                     0.03097041, 0.04267034, 0.04679972, 0.04679972, 0.05437027,\n",
       "                     0.05712319, 0.06469374, 0.07364074, 0.09015829, 0.09841707,\n",
       "                     0.10736407, 0.13971094, 0.14590502, 0.16655196, 0.18444597,\n",
       "                     0.18995182, 0.20784584, 0.21335169, 0.220234  , 0.23055747,\n",
       "                     0.26565726, 0.27735719, 0.28286304, 0.28974535, 0.29387474,\n",
       "                     0.30213352, 0.32553338, 0.33723331, 0.34480385, 0.35650379,\n",
       "                     0.37095664, 0.41362698, 0.42050929, 0.44597385, 0.47075017,\n",
       "                     0.50240881, 0.51135582, 0.51479697, 0.52305575, 0.54370268,\n",
       "                     0.54370268, 0.55127323, 0.55540262, 0.59119064, 0.6056435 ,\n",
       "                     0.61252581, 0.62353751, 0.63799036, 0.6476256 , 0.65450791,\n",
       "                     0.66345492, 0.7047488 , 0.70887818, 0.71163111, 0.72057811,\n",
       "                     0.73227805, 0.75843083, 0.76806607, 0.78458362, 0.78733655,\n",
       "                     0.81004818, 0.82587749, 0.84170681, 0.84721266, 0.91465933,\n",
       "                     0.92016518, 0.92567103, 0.93599449, 0.93668273, 0.94150034,\n",
       "                     0.9449415 , 0.94907089, 0.95113558, 0.95320028, 0.95939436,\n",
       "                     0.96214728, 0.96214728, 0.96283551, 0.96352374, 0.96490021,\n",
       "                     0.96834136, 0.97247075, 1.        ]), tpr=array([0.        , 0.03717472, 0.04386617, 0.04981413, 0.05501859,\n",
       "                     0.06171004, 0.07657993, 0.08550186, 0.08921933, 0.10185874,\n",
       "                     0.10929368, 0.1197026 , 0.13085502, 0.14944238, 0.1605948 ,\n",
       "                     0.17026022, 0.20371747, 0.21635688, 0.23568773, 0.25501859,\n",
       "                     0.25799257, 0.27657993, 0.28401487, 0.29070632, 0.30185874,\n",
       "                     0.34275093, 0.35836431, 0.36208178, 0.37100372, 0.37472119,\n",
       "                     0.38289963, 0.40074349, 0.42379182, 0.43568773, 0.44981413,\n",
       "                     0.46468401, 0.52565056, 0.52936803, 0.55018587, 0.57918216,\n",
       "                     0.6133829 , 0.61858736, 0.62304833, 0.62899628, 0.64907063,\n",
       "                     0.65055762, 0.65650558, 0.6669145 , 0.69442379, 0.70260223,\n",
       "                     0.71003717, 0.71747212, 0.72713755, 0.73605948, 0.74126394,\n",
       "                     0.7472119 , 0.78587361, 0.78884758, 0.79256506, 0.80223048,\n",
       "                     0.80892193, 0.82304833, 0.82973978, 0.84237918, 0.84386617,\n",
       "                     0.86988848, 0.88178439, 0.88773234, 0.89144981, 0.95836431,\n",
       "                     0.96431227, 0.96951673, 0.97546468, 0.97695167, 0.98438662,\n",
       "                     0.98513011, 0.98736059, 0.98810409, 0.99107807, 0.99256506,\n",
       "                     0.99405204, 0.99479554, 0.99702602, 0.99702602, 0.99776952,\n",
       "                     0.99851301, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.87682072e-01, -3.18453731e-01,\n",
       "                     -3.56674944e-01, -3.67724780e-01, -4.05465108e-01, -4.59532329e-01,\n",
       "                     -5.10825624e-01, -5.26093096e-01, -5.30628251e-01, -5.38996501e-01,\n",
       "                     -6.00056757e-01, -6.93147181e-01, -7.25937003e-01, -7.30887509e-01,\n",
       "                     -7.36632292e-01, -7.50305594e-01, -7.84954730e-01, -7.91127589e-01,\n",
       "                     -8.10930216e-01, -8.24175443e-01, -8.32909123e-01, -8.47297860e-01,\n",
       "                     -8.57902414e-01, -8.60762590e-01, -9.16290732e-01, -9.34309237e-01,\n",
       "                     -9.47381319e-01, -9.55511445e-01, -9.69400557e-01, -9.80829253e-01,\n",
       "                     -9.88070414e-01, -9.96333440e-01, -1.00680474e+00, -1.01160091e+00,\n",
       "                     -1.02700276e+00, -1.02961942e+00, -1.03653986e+00, -1.09861229e+00,\n",
       "                     -1.12011849e+00, -1.14513230e+00, -1.15267951e+00, -1.17865500e+00,\n",
       "                     -1.20179652e+00, -1.20397280e+00, -1.21639532e+00, -1.25276297e+00,\n",
       "                     -1.27188401e+00, -1.29098418e+00, -1.29928298e+00, -1.31730149e+00,\n",
       "                     -1.32687094e+00, -1.33041390e+00, -1.34992672e+00, -1.35454566e+00,\n",
       "                     -1.36687628e+00, -1.38629436e+00, -1.40282366e+00, -1.40534256e+00,\n",
       "                     -1.41369334e+00, -1.42500887e+00, -1.46633707e+00, -1.49752000e+00,\n",
       "                     -1.50407740e+00, -1.59214642e+00, -1.59685913e+00, -1.60943791e+00,\n",
       "                     -1.68639895e+00, -1.72870133e+00, -1.79175947e+00, -1.94591015e+00,\n",
       "                     -2.07944154e+00, -2.14006616e+00, -2.16685348e+00, -2.19722458e+00,\n",
       "                     -2.23359222e+00, -2.30258509e+00, -2.32727771e+00, -2.35137526e+00,\n",
       "                     -2.48490665e+00, -2.83321334e+00, -2.93119375e+00, -3.04452244e+00,\n",
       "                     -3.11351531e+00, -3.17805383e+00, -4.15888308e+00, -3.45387764e+01]), auc_score=0.5725011960896185, privacy_risk=0.5560117894779932, accuracy=0.5560117894779932, tpr_ind=0.5256505576208178, tnr_ind=0.5863730213351687, test_train_ratio=1.0802973977695167, dataset_size=[1345, 1453]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.01054111, 0.01335207, 0.0154603 , 0.02319044,\n",
       "                     0.02810963, 0.03373155, 0.04005622, 0.05340829, 0.05481377,\n",
       "                     0.06605762, 0.06957133, 0.07097681, 0.07730148, 0.08362614,\n",
       "                     0.08573436, 0.13141251, 0.15460295, 0.17357695, 0.18271258,\n",
       "                     0.19465917, 0.2073085 , 0.21152495, 0.21503865, 0.23190443,\n",
       "                     0.31412509, 0.31763879, 0.34855938, 0.36331694, 0.39494027,\n",
       "                     0.39845397, 0.40056219, 0.40829234, 0.41180604, 0.41953619,\n",
       "                     0.43921293, 0.45326774, 0.45959241, 0.4645116 , 0.47786367,\n",
       "                     0.54040759, 0.5924104 , 0.60576247, 0.61560084, 0.62754743,\n",
       "                     0.64089951, 0.64722417, 0.65917077, 0.69992973, 0.74349965,\n",
       "                     0.74982431, 0.77582572, 0.77793394, 0.78355587, 0.79198876,\n",
       "                     0.7962052 , 0.79831342, 0.79901616, 0.80674631, 0.83204498,\n",
       "                     0.8376669 , 0.85172171, 0.86085734, 0.86437105, 0.86507379,\n",
       "                     0.86999297, 0.87842586, 0.89248067, 0.89388616, 0.89669712,\n",
       "                     0.9135629 , 0.93183415, 0.93886156, 0.93886156, 0.94026704,\n",
       "                     0.94869993, 0.95291637, 0.9550246 , 0.95572734, 0.95994378,\n",
       "                     0.96767393, 1.        ]), tpr=array([0.        , 0.02909091, 0.03490909, 0.03927273, 0.04509091,\n",
       "                     0.056     , 0.06909091, 0.07927273, 0.09745455, 0.10254545,\n",
       "                     0.11854545, 0.12363636, 0.12872727, 0.13963636, 0.15490909,\n",
       "                     0.16      , 0.19854545, 0.22109091, 0.23854545, 0.24872727,\n",
       "                     0.26109091, 0.27709091, 0.27927273, 0.28727273, 0.30618182,\n",
       "                     0.39781818, 0.40145455, 0.44363636, 0.46545455, 0.49818182,\n",
       "                     0.50618182, 0.50836364, 0.51490909, 0.51854545, 0.52581818,\n",
       "                     0.54181818, 0.568     , 0.57818182, 0.58181818, 0.59345455,\n",
       "                     0.65018182, 0.70618182, 0.71636364, 0.72509091, 0.73818182,\n",
       "                     0.74690909, 0.75345455, 0.76872727, 0.80509091, 0.84072727,\n",
       "                     0.848     , 0.86545455, 0.86981818, 0.87418182, 0.87854545,\n",
       "                     0.88218182, 0.88509091, 0.888     , 0.89381818, 0.90690909,\n",
       "                     0.91127273, 0.92654545, 0.93309091, 0.936     , 0.93745455,\n",
       "                     0.94181818, 0.94472727, 0.95709091, 0.95854545, 0.95927273,\n",
       "                     0.97018182, 0.98109091, 0.984     , 0.98472727, 0.98690909,\n",
       "                     0.98836364, 0.99272727, 0.99272727, 0.99345455, 0.99418182,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.17783036e-01, -1.54150680e-01,\n",
       "                     -2.23143551e-01, -2.87682072e-01, -3.67724780e-01, -4.05465108e-01,\n",
       "                     -4.70003629e-01, -5.10825624e-01, -5.19875459e-01, -5.38996501e-01,\n",
       "                     -5.59615788e-01, -5.87786665e-01, -6.15588946e-01, -6.19039208e-01,\n",
       "                     -6.83668437e-01, -6.93147181e-01, -7.73189888e-01, -7.94929875e-01,\n",
       "                     -8.14099791e-01, -8.40783179e-01, -8.47297860e-01, -8.62223511e-01,\n",
       "                     -8.69037847e-01, -8.74829964e-01, -8.75468737e-01, -9.09370289e-01,\n",
       "                     -9.16290732e-01, -9.20725329e-01, -9.34309237e-01, -9.80829253e-01,\n",
       "                     -9.90398704e-01, -1.02961942e+00, -1.03798767e+00, -1.06784063e+00,\n",
       "                     -1.08026315e+00, -1.09861229e+00, -1.12601126e+00, -1.13943428e+00,\n",
       "                     -1.14862271e+00, -1.17468201e+00, -1.17557333e+00, -1.18149995e+00,\n",
       "                     -1.23676263e+00, -1.25276297e+00, -1.26851133e+00, -1.28785429e+00,\n",
       "                     -1.37082444e+00, -1.38629436e+00, -1.41098697e+00, -1.42711636e+00,\n",
       "                     -1.45225233e+00, -1.46633707e+00, -1.47181653e+00, -1.48160454e+00,\n",
       "                     -1.49165488e+00, -1.50407740e+00, -1.52242654e+00, -1.57121670e+00,\n",
       "                     -1.60943791e+00, -1.62830640e+00, -1.65292302e+00, -1.65822808e+00,\n",
       "                     -1.70474809e+00, -1.74046617e+00, -1.79175947e+00, -1.81117756e+00,\n",
       "                     -1.87180218e+00, -1.94591015e+00, -2.02814825e+00, -2.03688193e+00,\n",
       "                     -2.35137526e+00, -2.39789527e+00, -2.43361336e+00, -2.56494936e+00,\n",
       "                     -2.73200344e+00, -2.77258872e+00, -2.89037176e+00, -3.09104245e+00,\n",
       "                     -3.28653447e+00, -3.45387764e+01]), auc_score=0.5820019165655146, privacy_risk=0.559294703890628, accuracy=0.559294703890628, tpr_ind=0.5781818181818181, tnr_ind=0.5404075895994378, test_train_ratio=1.034909090909091, dataset_size=[1375, 1423]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.00722022, 0.01083032, 0.01516245, 0.01516245,\n",
       "                     0.01949458, 0.02310469, 0.03465704, 0.03754513, 0.04693141,\n",
       "                     0.0534296 , 0.05631769, 0.05631769, 0.06425993, 0.06859206,\n",
       "                     0.07075812, 0.07364621, 0.10758123, 0.12851986, 0.18194946,\n",
       "                     0.18916968, 0.22527076, 0.23104693, 0.25848375, 0.26353791,\n",
       "                     0.28158845, 0.28231047, 0.30685921, 0.32202166, 0.33429603,\n",
       "                     0.34296029, 0.35451264, 0.35884477, 0.36462094, 0.37761733,\n",
       "                     0.38122744, 0.39927798, 0.40577617, 0.41083032, 0.41444043,\n",
       "                     0.41949458, 0.4534296 , 0.46137184, 0.50180505, 0.50613718,\n",
       "                     0.52202166, 0.52274368, 0.52779783, 0.52924188, 0.53068592,\n",
       "                     0.55162455, 0.55595668, 0.55884477, 0.56389892, 0.57689531,\n",
       "                     0.60216606, 0.64115523, 0.66281588, 0.70758123, 0.71480144,\n",
       "                     0.72418773, 0.73068592, 0.73646209, 0.7400722 , 0.74368231,\n",
       "                     0.75451264, 0.79422383, 0.80288809, 0.80361011, 0.80722022,\n",
       "                     0.82310469, 0.82815884, 0.84259928, 0.84548736, 0.87581227,\n",
       "                     0.87942238, 0.88086643, 0.88447653, 0.89169675, 0.90758123,\n",
       "                     0.90758123, 0.90830325, 0.91191336, 0.91480144, 0.91552347,\n",
       "                     0.92057762, 0.92057762, 0.93935018, 0.94512635, 0.94873646,\n",
       "                     0.95451264, 0.95451264, 0.9566787 , 0.95812274, 0.95884477,\n",
       "                     0.96028881, 0.96101083, 0.9631769 , 0.96389892, 1.        ]), tpr=array([0.        , 0.01910828, 0.02618542, 0.02972399, 0.03255485,\n",
       "                     0.03821656, 0.04175513, 0.05166313, 0.05944798, 0.07077141,\n",
       "                     0.08138712, 0.08351026, 0.08704883, 0.09837226, 0.10120311,\n",
       "                     0.10474168, 0.10969568, 0.1556971 , 0.18259023, 0.23708422,\n",
       "                     0.2413305 , 0.28733192, 0.29087049, 0.31210191, 0.31493277,\n",
       "                     0.33191791, 0.33404105, 0.36376504, 0.37296532, 0.38995046,\n",
       "                     0.4069356 , 0.42321302, 0.42533616, 0.43665959, 0.45081387,\n",
       "                     0.45506016, 0.47062987, 0.47912243, 0.482661  , 0.48973815,\n",
       "                     0.49398443, 0.517339  , 0.52583156, 0.55626327, 0.56192498,\n",
       "                     0.57395612, 0.57820241, 0.58527955, 0.58881812, 0.59094126,\n",
       "                     0.60721868, 0.61075725, 0.61854211, 0.62420382, 0.64118896,\n",
       "                     0.66666667, 0.70488323, 0.71762208, 0.77494692, 0.77990092,\n",
       "                     0.79193206, 0.79830149, 0.80113234, 0.80679406, 0.8089172 ,\n",
       "                     0.81740977, 0.85491861, 0.85987261, 0.86270347, 0.86765747,\n",
       "                     0.88888889, 0.89313517, 0.90162774, 0.90516631, 0.9348903 ,\n",
       "                     0.93772116, 0.93913659, 0.9447983 , 0.95187544, 0.96249115,\n",
       "                     0.96319887, 0.96532201, 0.96602972, 0.96744515, 0.97098372,\n",
       "                     0.97381458, 0.97452229, 0.98301486, 0.98726115, 0.98867657,\n",
       "                     0.99079972, 0.99150743, 0.99292286, 0.99433829, 0.99433829,\n",
       "                     0.99716914, 0.99787686, 0.99929229, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -9.53101798e-02, -1.82321557e-01,\n",
       "                     -2.87682072e-01, -3.18453731e-01, -3.36472237e-01, -4.05465108e-01,\n",
       "                     -4.35318071e-01, -4.46287103e-01, -4.70003629e-01, -5.10825624e-01,\n",
       "                     -5.38996501e-01, -5.59615788e-01, -5.67984038e-01, -5.87786665e-01,\n",
       "                     -6.66478933e-01, -6.93147181e-01, -7.55667538e-01, -7.68182367e-01,\n",
       "                     -7.73189888e-01, -7.74372620e-01, -7.88457360e-01, -7.96943974e-01,\n",
       "                     -8.10930216e-01, -8.34460714e-01, -8.47297860e-01, -8.67500568e-01,\n",
       "                     -8.93817876e-01, -9.02238978e-01, -9.16290732e-01, -9.34309237e-01,\n",
       "                     -9.38269639e-01, -9.50976290e-01, -9.55511445e-01, -9.65080896e-01,\n",
       "                     -9.77984301e-01, -1.01160091e+00, -1.02450432e+00, -1.02961942e+00,\n",
       "                     -1.04145387e+00, -1.05108715e+00, -1.07158362e+00, -1.08298697e+00,\n",
       "                     -1.09861229e+00, -1.10866262e+00, -1.11436065e+00, -1.11803037e+00,\n",
       "                     -1.12393010e+00, -1.13497993e+00, -1.15145477e+00, -1.15745279e+00,\n",
       "                     -1.16315081e+00, -1.17599895e+00, -1.17865500e+00, -1.17995793e+00,\n",
       "                     -1.19279950e+00, -1.20397280e+00, -1.21867895e+00, -1.23214368e+00,\n",
       "                     -1.23807842e+00, -1.24432410e+00, -1.25276297e+00, -1.28785429e+00,\n",
       "                     -1.31218639e+00, -1.38629436e+00, -1.39568410e+00, -1.42138568e+00,\n",
       "                     -1.42711636e+00, -1.44691898e+00, -1.45831295e+00, -1.45861502e+00,\n",
       "                     -1.46967597e+00, -1.51982575e+00, -1.55059741e+00, -1.60943791e+00,\n",
       "                     -1.66500776e+00, -1.68175857e+00, -1.68639895e+00, -1.69866905e+00,\n",
       "                     -1.70474809e+00, -1.73460106e+00, -1.74046617e+00, -1.79175947e+00,\n",
       "                     -1.97408103e+00, -2.14006616e+00, -2.19722458e+00, -2.23359222e+00,\n",
       "                     -2.25129180e+00, -2.26868354e+00, -2.30258509e+00, -2.48490665e+00,\n",
       "                     -2.61495978e+00, -2.63905733e+00, -2.70805020e+00, -2.86220088e+00,\n",
       "                     -2.94443898e+00, -2.96183072e+00, -3.25809654e+00, -3.45387764e+01]), auc_score=0.5547147299061576, privacy_risk=0.5376488562880524, accuracy=0.5376488562880524, tpr_ind=0.4897381457891012, tnr_ind=0.5855595667870036, test_train_ratio=0.9801840056617127, dataset_size=[1413, 1385]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.00630252, 0.01190476, 0.01190476, 0.017507  ,\n",
       "                     0.02310924, 0.03011204, 0.03081232, 0.04271709, 0.05042017,\n",
       "                     0.05952381, 0.06512605, 0.07983193, 0.08193277, 0.08753501,\n",
       "                     0.12605042, 0.1337535 , 0.14285714, 0.1512605 , 0.15406162,\n",
       "                     0.15966387, 0.17156863, 0.17226891, 0.18137255, 0.18347339,\n",
       "                     0.27591036, 0.27941176, 0.28991597, 0.31652661, 0.33543417,\n",
       "                     0.35364146, 0.37535014, 0.37955182, 0.40896359, 0.41456583,\n",
       "                     0.43067227, 0.44257703, 0.44257703, 0.45938375, 0.47619048,\n",
       "                     0.48319328, 0.51120448, 0.51890756, 0.53221289, 0.55182073,\n",
       "                     0.56162465, 0.5952381 , 0.61554622, 0.63165266, 0.6442577 ,\n",
       "                     0.64845938, 0.66316527, 0.68977591, 0.69537815, 0.69607843,\n",
       "                     0.70448179, 0.70868347, 0.73529412, 0.75980392, 0.76540616,\n",
       "                     0.78991597, 0.80602241, 0.81232493, 0.82492997, 0.83683473,\n",
       "                     0.89705882, 0.89845938, 0.89915966, 0.90826331, 0.90966387,\n",
       "                     0.91036415, 0.92226891, 0.92436975, 0.92507003, 0.92857143,\n",
       "                     0.93067227, 0.93137255, 0.94257703, 0.95098039, 0.95098039,\n",
       "                     0.95238095, 0.95658263, 0.95658263, 0.95658263, 0.96218487,\n",
       "                     0.96848739, 0.96848739, 0.97058824, 0.9754902 , 1.        ]), tpr=array([0.        , 0.02116788, 0.02846715, 0.03138686, 0.03941606,\n",
       "                     0.04379562, 0.05182482, 0.0540146 , 0.07153285, 0.0810219 ,\n",
       "                     0.08832117, 0.09124088, 0.10291971, 0.1080292 , 0.11094891,\n",
       "                     0.16642336, 0.17153285, 0.17737226, 0.18832117, 0.19270073,\n",
       "                     0.20145985, 0.20875912, 0.21021898, 0.22189781, 0.22481752,\n",
       "                     0.32773723, 0.32992701, 0.3379562 , 0.36861314, 0.37883212,\n",
       "                     0.39489051, 0.4189781 , 0.43065693, 0.46058394, 0.46861314,\n",
       "                     0.48759124, 0.50218978, 0.50510949, 0.52481752, 0.55182482,\n",
       "                     0.55693431, 0.57956204, 0.59562044, 0.61094891, 0.62846715,\n",
       "                     0.64379562, 0.67372263, 0.7       , 0.70583942, 0.72043796,\n",
       "                     0.72408759, 0.73722628, 0.7540146 , 0.75912409, 0.76131387,\n",
       "                     0.76642336, 0.77372263, 0.79343066, 0.81094891, 0.81605839,\n",
       "                     0.83649635, 0.85912409, 0.86423358, 0.87226277, 0.88248175,\n",
       "                     0.94306569, 0.94379562, 0.94525547, 0.95109489, 0.95474453,\n",
       "                     0.95620438, 0.96350365, 0.96788321, 0.96861314, 0.96934307,\n",
       "                     0.97153285, 0.97372263, 0.97956204, 0.98321168, 0.98394161,\n",
       "                     0.98394161, 0.98540146, 0.98759124, 0.98832117, 0.9919708 ,\n",
       "                     0.99416058, 0.99489051, 0.99708029, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.82321557e-01, -2.23143551e-01,\n",
       "                     -2.87682072e-01, -4.05465108e-01, -4.32133355e-01, -4.96436886e-01,\n",
       "                     -5.10825624e-01, -5.70544858e-01, -5.87786665e-01, -6.19039208e-01,\n",
       "                     -6.28608659e-01, -6.39079959e-01, -6.50587566e-01, -6.93147181e-01,\n",
       "                     -7.20546155e-01, -7.53771802e-01, -7.57685702e-01, -7.73189888e-01,\n",
       "                     -7.84118959e-01, -7.88457360e-01, -7.98507696e-01, -8.10930216e-01,\n",
       "                     -8.24175443e-01, -8.36349645e-01, -8.47297860e-01, -8.93817876e-01,\n",
       "                     -9.04298583e-01, -9.16290732e-01, -9.58030338e-01, -9.69400557e-01,\n",
       "                     -9.80829253e-01, -9.95958135e-01, -1.00330211e+00, -1.00458334e+00,\n",
       "                     -1.00900013e+00, -1.02165125e+00, -1.06087196e+00, -1.09861229e+00,\n",
       "                     -1.14513230e+00, -1.16113265e+00, -1.17163742e+00, -1.17473598e+00,\n",
       "                     -1.18504479e+00, -1.18958407e+00, -1.19908282e+00, -1.21227161e+00,\n",
       "                     -1.21639532e+00, -1.25276297e+00, -1.28093385e+00, -1.28401551e+00,\n",
       "                     -1.31885308e+00, -1.33041390e+00, -1.33500107e+00, -1.34992672e+00,\n",
       "                     -1.36097655e+00, -1.36760223e+00, -1.37582306e+00, -1.38629436e+00,\n",
       "                     -1.39518331e+00, -1.47866768e+00, -1.49664242e+00, -1.52102696e+00,\n",
       "                     -1.63760879e+00, -1.68595262e+00, -1.73460106e+00, -1.74296931e+00,\n",
       "                     -1.74919985e+00, -1.75785792e+00, -1.79175947e+00, -1.80828877e+00,\n",
       "                     -1.91875916e+00, -1.92181260e+00, -1.94591015e+00, -1.98100147e+00,\n",
       "                     -2.01490302e+00, -2.02320182e+00, -2.02814825e+00, -2.07944154e+00,\n",
       "                     -2.14006616e+00, -2.25129180e+00, -2.38262780e+00, -2.39789527e+00,\n",
       "                     -2.48490665e+00, -2.53897387e+00, -2.70805020e+00, -2.84781214e+00,\n",
       "                     -3.20545280e+00, -3.45387764e+01]), auc_score=0.5504723057106055, privacy_risk=0.5422268907563025, accuracy=0.5422268907563025, tpr_ind=0.7, tnr_ind=0.38445378151260506, test_train_ratio=1.0423357664233577, dataset_size=[1370, 1428]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.01369863, 0.01658255, 0.02090844, 0.02162942,\n",
       "                     0.02451334, 0.03460707, 0.03893295, 0.05118962, 0.05623648,\n",
       "                     0.0591204 , 0.06128335, 0.06560923, 0.06849315, 0.07642394,\n",
       "                     0.08074982, 0.13626532, 0.15501081, 0.1665465 , 0.20331651,\n",
       "                     0.222062  , 0.23359769, 0.24224946, 0.25594809, 0.25739005,\n",
       "                     0.27180966, 0.29920692, 0.3294881 , 0.34967556, 0.36049027,\n",
       "                     0.36625811, 0.42321557, 0.44917087, 0.45205479, 0.4592646 ,\n",
       "                     0.46431146, 0.47007931, 0.49315068, 0.50684932, 0.51333814,\n",
       "                     0.51910598, 0.52054795, 0.54145638, 0.54650324, 0.55371305,\n",
       "                     0.56092286, 0.57678443, 0.60201875, 0.60346071, 0.62148522,\n",
       "                     0.62148522, 0.6222062 , 0.62292718, 0.63878875, 0.68565249,\n",
       "                     0.69069935, 0.70223504, 0.7296323 , 0.73107426, 0.76135544,\n",
       "                     0.76928623, 0.77721702, 0.79307859, 0.80100937, 0.82335977,\n",
       "                     0.83129056, 0.84498919, 0.84787311, 0.84859409, 0.8630137 ,\n",
       "                     0.88824802, 0.90122567, 0.90627253, 0.92069214, 0.93511175,\n",
       "                     0.93655371, 0.93727469, 0.93727469, 0.9408796 , 0.94232156,\n",
       "                     0.9444845 , 0.95025234, 0.95385725, 0.95529921, 0.95602019,\n",
       "                     0.95746215, 0.95962509, 0.95962509, 0.96178803, 0.9668349 ,\n",
       "                     0.97692862, 0.97909156, 1.        ]), tpr=array([0.        , 0.02267895, 0.02976612, 0.03614458, 0.04252303,\n",
       "                     0.05102764, 0.06307583, 0.06661942, 0.08433735, 0.09213324,\n",
       "                     0.09638554, 0.09992913, 0.10418143, 0.10985117, 0.12048193,\n",
       "                     0.12969525, 0.1892275 , 0.21048901, 0.22608079, 0.26151665,\n",
       "                     0.2799433 , 0.28844791, 0.30262225, 0.31325301, 0.31537916,\n",
       "                     0.32884479, 0.36144578, 0.39404678, 0.41743444, 0.42593905,\n",
       "                     0.43160879, 0.48334515, 0.52374203, 0.52586818, 0.53579022,\n",
       "                     0.54287739, 0.5471297 , 0.55705174, 0.5761871 , 0.58681786,\n",
       "                     0.5924876 , 0.59532247, 0.62083629, 0.62863218, 0.63713678,\n",
       "                     0.64635011, 0.66902906, 0.69383416, 0.69525159, 0.71863926,\n",
       "                     0.71934798, 0.72147413, 0.72218285, 0.73281361, 0.78525868,\n",
       "                     0.78809355, 0.79588944, 0.82423813, 0.82494685, 0.84833451,\n",
       "                     0.85471297, 0.86038271, 0.8681786 , 0.8724309 , 0.89156627,\n",
       "                     0.89794472, 0.90786676, 0.9092842 , 0.90999291, 0.92062367,\n",
       "                     0.94613749, 0.95393338, 0.95605953, 0.96243799, 0.97306875,\n",
       "                     0.97377746, 0.97661233, 0.9794472 , 0.98228207, 0.9836995 ,\n",
       "                     0.98582566, 0.98795181, 0.99007796, 0.99078668, 0.99149539,\n",
       "                     0.99291283, 0.99362155, 0.99503898, 0.99503898, 0.99787385,\n",
       "                     0.99929128, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -9.53101798e-02, -1.05360516e-01,\n",
       "                     -2.23143551e-01, -2.87682072e-01, -4.05465108e-01, -4.70003629e-01,\n",
       "                     -4.94696242e-01, -5.10825624e-01, -5.59615788e-01, -5.87786665e-01,\n",
       "                     -6.06135804e-01, -6.28608659e-01, -6.45137961e-01, -6.53926467e-01,\n",
       "                     -6.56779536e-01, -6.93147181e-01, -7.81700578e-01, -8.31983625e-01,\n",
       "                     -8.36853901e-01, -8.70828358e-01, -8.75468737e-01, -8.90972924e-01,\n",
       "                     -9.02867712e-01, -9.05708623e-01, -9.16290732e-01, -9.32696767e-01,\n",
       "                     -9.46143695e-01, -9.49080555e-01, -9.58850346e-01, -9.66656444e-01,\n",
       "                     -9.70949144e-01, -9.80829253e-01, -9.87946721e-01, -9.93251773e-01,\n",
       "                     -1.01160091e+00, -1.01345448e+00, -1.02165125e+00, -1.02961942e+00,\n",
       "                     -1.03798767e+00, -1.04145387e+00, -1.04982212e+00, -1.06784063e+00,\n",
       "                     -1.07044141e+00, -1.09861229e+00, -1.12938395e+00, -1.14513230e+00,\n",
       "                     -1.15267951e+00, -1.15745279e+00, -1.17865500e+00, -1.18958407e+00,\n",
       "                     -1.20397280e+00, -1.24111235e+00, -1.24889449e+00, -1.25276297e+00,\n",
       "                     -1.26566637e+00, -1.30833282e+00, -1.31218639e+00, -1.32377400e+00,\n",
       "                     -1.38629436e+00, -1.41706602e+00, -1.45225233e+00, -1.46633707e+00,\n",
       "                     -1.49165488e+00, -1.49995368e+00, -1.58863478e+00, -1.60943791e+00,\n",
       "                     -1.67397643e+00, -1.69905007e+00, -1.69968479e+00, -1.71297859e+00,\n",
       "                     -1.79175947e+00, -1.81010861e+00, -1.92667879e+00, -2.02814825e+00,\n",
       "                     -2.04769284e+00, -2.12026354e+00, -2.18323834e+00, -2.19722458e+00,\n",
       "                     -2.23359222e+00, -2.30258509e+00, -2.33537492e+00, -2.39789527e+00,\n",
       "                     -2.48490665e+00, -2.52572864e+00, -2.63905733e+00, -2.67414865e+00,\n",
       "                     -2.91777073e+00, -3.09104245e+00, -3.79548919e+00, -3.89182030e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5639508711294561, privacy_risk=0.5498030972015633, accuracy=0.5498030972015633, tpr_ind=0.7852586817859674, tnr_ind=0.3143475126171593, test_train_ratio=0.9829907866761163, dataset_size=[1411, 1387]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.01578192, 0.017934  , 0.01936872, 0.0251076 ,\n",
       "                     0.03299857, 0.03802009, 0.04160689, 0.04519369, 0.04662841,\n",
       "                     0.05236729, 0.06384505, 0.06886657, 0.07030129, 0.08249641,\n",
       "                     0.09038737, 0.1097561 , 0.15423242, 0.16857963, 0.17503587,\n",
       "                     0.19512195, 0.19583931, 0.20946915, 0.25609756, 0.2804878 ,\n",
       "                     0.29411765, 0.31205165, 0.32855093, 0.33931133, 0.37733142,\n",
       "                     0.37804878, 0.39239598, 0.39670014, 0.47058824, 0.47417504,\n",
       "                     0.47704448, 0.47919656, 0.48421808, 0.4856528 , 0.5251076 ,\n",
       "                     0.52941176, 0.54375897, 0.55236729, 0.55738881, 0.55882353,\n",
       "                     0.57819225, 0.59397418, 0.61477762, 0.62625538, 0.63773314,\n",
       "                     0.64131994, 0.64777618, 0.66068867, 0.66427547, 0.68292683,\n",
       "                     0.68507891, 0.71377331, 0.73457676, 0.73816356, 0.74677188,\n",
       "                     0.77259684, 0.77259684, 0.78981349, 0.83644189, 0.83859397,\n",
       "                     0.85294118, 0.85581062, 0.85724534, 0.86441894, 0.94332855,\n",
       "                     0.95624103, 0.95767575, 0.95767575, 0.96197991, 0.96341463,\n",
       "                     0.96413199, 0.96413199, 0.96484935, 0.96556671, 0.96700143,\n",
       "                     0.96987088, 0.97274032, 0.97274032, 0.97345768, 0.9748924 ,\n",
       "                     1.        ]), tpr=array([0.        , 0.02635328, 0.03062678, 0.03347578, 0.03846154,\n",
       "                     0.04344729, 0.0462963 , 0.05128205, 0.06054131, 0.06339031,\n",
       "                     0.07264957, 0.08974359, 0.0954416 , 0.0982906 , 0.11111111,\n",
       "                     0.11823362, 0.13247863, 0.17022792, 0.17877493, 0.18518519,\n",
       "                     0.21367521, 0.21509972, 0.23005698, 0.28490028, 0.30982906,\n",
       "                     0.32336182, 0.33903134, 0.3525641 , 0.36253561, 0.38390313,\n",
       "                     0.38461538, 0.4017094 , 0.40669516, 0.48504274, 0.49002849,\n",
       "                     0.49358974, 0.49643875, 0.5014245 , 0.50213675, 0.5491453 ,\n",
       "                     0.55413105, 0.57193732, 0.57905983, 0.58119658, 0.58475783,\n",
       "                     0.60612536, 0.62321937, 0.64173789, 0.6545584 , 0.66809117,\n",
       "                     0.67450142, 0.68162393, 0.69159544, 0.6980057 , 0.72435897,\n",
       "                     0.72792023, 0.75641026, 0.77207977, 0.77777778, 0.78632479,\n",
       "                     0.80911681, 0.81267806, 0.82834758, 0.87179487, 0.87250712,\n",
       "                     0.88746439, 0.89031339, 0.89245014, 0.89672365, 0.97079772,\n",
       "                     0.97934473, 0.98148148, 0.98290598, 0.98860399, 0.99002849,\n",
       "                     0.99145299, 0.99216524, 0.99287749, 0.9957265 , 0.99643875,\n",
       "                     0.99786325, 0.9985755 , 0.99928775, 1.        , 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.54150680e-01, -2.23143551e-01,\n",
       "                     -2.51314428e-01, -2.87682072e-01, -4.05465108e-01, -4.51985124e-01,\n",
       "                     -4.79573080e-01, -5.10825624e-01, -5.26093096e-01, -5.35518236e-01,\n",
       "                     -5.50046337e-01, -5.59615788e-01, -6.10259521e-01, -6.41853886e-01,\n",
       "                     -6.93147181e-01, -7.54768315e-01, -7.68654733e-01, -8.10930216e-01,\n",
       "                     -8.32909123e-01, -8.47297860e-01, -8.87303195e-01, -8.95384047e-01,\n",
       "                     -9.10560057e-01, -9.13111079e-01, -9.16290732e-01, -9.31558204e-01,\n",
       "                     -9.40388283e-01, -9.43606543e-01, -9.55511445e-01, -9.62480114e-01,\n",
       "                     -9.80829253e-01, -9.88824727e-01, -9.98528830e-01, -1.00144854e+00,\n",
       "                     -1.00552187e+00, -1.01160091e+00, -1.02961942e+00, -1.03070108e+00,\n",
       "                     -1.04982212e+00, -1.06025142e+00, -1.06471074e+00, -1.07263680e+00,\n",
       "                     -1.09861229e+00, -1.12393010e+00, -1.13943428e+00, -1.16074407e+00,\n",
       "                     -1.17007125e+00, -1.18377010e+00, -1.19213835e+00, -1.19392247e+00,\n",
       "                     -1.19824213e+00, -1.20397280e+00, -1.21739582e+00, -1.22377543e+00,\n",
       "                     -1.24559448e+00, -1.25276297e+00, -1.31824090e+00, -1.32175584e+00,\n",
       "                     -1.35783190e+00, -1.38629436e+00, -1.46283444e+00, -1.46885596e+00,\n",
       "                     -1.48160454e+00, -1.51982575e+00, -1.58412010e+00, -1.60943791e+00,\n",
       "                     -1.64865863e+00, -1.67457721e+00, -1.70474809e+00, -1.73460106e+00,\n",
       "                     -1.82454929e+00, -1.85238409e+00, -1.87180218e+00, -1.89711998e+00,\n",
       "                     -1.94591015e+00, -2.01490302e+00, -2.22462355e+00, -2.30258509e+00,\n",
       "                     -2.39789527e+00, -2.56494936e+00, -2.83321334e+00, -3.02042489e+00,\n",
       "                     -3.21887582e+00, -3.45387764e+01]), auc_score=0.5249811463046757, privacy_risk=0.5214206591538012, accuracy=0.5214206591538012, tpr_ind=0.7279202279202279, tnr_ind=0.3149210903873745, test_train_ratio=0.9928774928774928, dataset_size=[1404, 1394]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.01062323, 0.01345609, 0.01487252, 0.02124646,\n",
       "                     0.02549575, 0.02832861, 0.03186969, 0.03753541, 0.03966006,\n",
       "                     0.04815864, 0.04957507, 0.05028329, 0.05524079, 0.06232295,\n",
       "                     0.07648725, 0.08569405, 0.09844193, 0.14022663, 0.14589235,\n",
       "                     0.1572238 , 0.16359773, 0.17067989, 0.18271955, 0.19759207,\n",
       "                     0.20113314, 0.20184136, 0.20679887, 0.21033994, 0.22592068,\n",
       "                     0.24150142, 0.26558074, 0.2684136 , 0.31515581, 0.33073654,\n",
       "                     0.33711048, 0.34773371, 0.38031161, 0.38243626, 0.40509915,\n",
       "                     0.40934844, 0.41572238, 0.4213881 , 0.47096317, 0.47521246,\n",
       "                     0.48725212, 0.50212465, 0.51133144, 0.51912181, 0.53895184,\n",
       "                     0.54957507, 0.55736544, 0.56373938, 0.57082153, 0.57577904,\n",
       "                     0.57648725, 0.64164306, 0.65934844, 0.67280453, 0.68271955,\n",
       "                     0.68484419, 0.69192635, 0.69546742, 0.71175637, 0.7223796 ,\n",
       "                     0.72308782, 0.76274788, 0.77124646, 0.77549575, 0.77620397,\n",
       "                     0.78541076, 0.81373938, 0.87393768, 0.88597734, 0.90084986,\n",
       "                     0.90651558, 0.90651558, 0.91572238, 0.92847025, 0.93767705,\n",
       "                     0.94121813, 0.94263456, 0.94334278, 0.96104816, 0.96175637,\n",
       "                     0.96388102, 0.9766289 , 1.        ]), tpr=array([0.        , 0.02597403, 0.03102453, 0.03607504, 0.04978355,\n",
       "                     0.05194805, 0.05988456, 0.06926407, 0.07792208, 0.08369408,\n",
       "                     0.09163059, 0.09451659, 0.0974026 , 0.10822511, 0.12049062,\n",
       "                     0.13492063, 0.14213564, 0.15728716, 0.19119769, 0.1991342 ,\n",
       "                     0.20634921, 0.21067821, 0.22150072, 0.23809524, 0.25613276,\n",
       "                     0.26118326, 0.26334776, 0.26695527, 0.27272727, 0.28643579,\n",
       "                     0.3037518 , 0.32034632, 0.32251082, 0.37734488, 0.39249639,\n",
       "                     0.3982684 , 0.40620491, 0.43650794, 0.44083694, 0.46392496,\n",
       "                     0.47113997, 0.47619048, 0.48124098, 0.53679654, 0.54256854,\n",
       "                     0.55555556, 0.56854257, 0.57431457, 0.58441558, 0.6002886 ,\n",
       "                     0.61327561, 0.62409812, 0.63419913, 0.63852814, 0.64646465,\n",
       "                     0.64935065, 0.71789322, 0.73304473, 0.73809524, 0.74314574,\n",
       "                     0.74531025, 0.75180375, 0.76262626, 0.77344877, 0.78571429,\n",
       "                     0.78787879, 0.83766234, 0.84271284, 0.85281385, 0.85281385,\n",
       "                     0.86435786, 0.87734488, 0.92712843, 0.93362193, 0.94516595,\n",
       "                     0.95310245, 0.95526696, 0.96031746, 0.96320346, 0.96897547,\n",
       "                     0.96969697, 0.97402597, 0.97402597, 0.98268398, 0.98556999,\n",
       "                     0.98701299, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -2.51314428e-01,\n",
       "                     -2.87682072e-01, -3.56674944e-01, -4.05465108e-01, -4.30782916e-01,\n",
       "                     -4.70003629e-01, -4.85507816e-01, -4.92476485e-01, -5.10825624e-01,\n",
       "                     -5.59615788e-01, -5.87786665e-01, -6.00773860e-01, -6.08589793e-01,\n",
       "                     -6.75128675e-01, -6.93147181e-01, -7.14200590e-01, -7.37598943e-01,\n",
       "                     -7.41937345e-01, -7.73189888e-01, -7.77704569e-01, -7.88457360e-01,\n",
       "                     -8.06475866e-01, -8.10930216e-01, -8.47297860e-01, -8.75468737e-01,\n",
       "                     -8.97941593e-01, -9.05708623e-01, -9.16290732e-01, -9.31179344e-01,\n",
       "                     -9.38269639e-01, -9.42608040e-01, -9.44461609e-01, -9.65080896e-01,\n",
       "                     -9.69400557e-01, -9.71860583e-01, -9.80829253e-01, -9.88611393e-01,\n",
       "                     -9.93251773e-01, -9.98528830e-01, -1.01983141e+00, -1.02766055e+00,\n",
       "                     -1.04145387e+00, -1.06087196e+00, -1.07992016e+00, -1.08091271e+00,\n",
       "                     -1.09861229e+00, -1.13845820e+00, -1.14681439e+00, -1.16315081e+00,\n",
       "                     -1.20397280e+00, -1.20983792e+00, -1.21302264e+00, -1.25276297e+00,\n",
       "                     -1.25426560e+00, -1.25954266e+00, -1.26113122e+00, -1.27296568e+00,\n",
       "                     -1.29392104e+00, -1.29928298e+00, -1.31633577e+00, -1.31730149e+00,\n",
       "                     -1.37147928e+00, -1.38629436e+00, -1.39710528e+00, -1.45528723e+00,\n",
       "                     -1.46358604e+00, -1.50407740e+00, -1.51787072e+00, -1.60943791e+00,\n",
       "                     -1.68209556e+00, -1.71479843e+00, -1.74919985e+00, -1.78190717e+00,\n",
       "                     -1.79175947e+00, -1.85238409e+00, -1.89711998e+00, -1.90954250e+00,\n",
       "                     -2.07944154e+00, -2.12026354e+00, -2.24070969e+00, -2.26868354e+00,\n",
       "                     -2.30258509e+00, -2.39789527e+00, -2.88267941e+00, -3.45387764e+01]), auc_score=0.5571288563498195, privacy_risk=0.5394735497426716, accuracy=0.5394735497426716, tpr_ind=0.8643578643578643, tnr_ind=0.21458923512747877, test_train_ratio=1.0187590187590188, dataset_size=[1386, 1412])],\n",
       "             'subpopulation_1.0_label_0.0_mia_auc': [0.529154747083068,\n",
       "              0.5211786175094573,\n",
       "              0.5063777054506157,\n",
       "              0.5219496463638167,\n",
       "              0.5331736996697383,\n",
       "              0.5311100689602445,\n",
       "              0.525532548925937,\n",
       "              0.5284966018195054,\n",
       "              0.5101452883326875,\n",
       "              0.5101794072009981,\n",
       "              0.5226645183690847,\n",
       "              0.5206378014822091,\n",
       "              0.5194735150996235,\n",
       "              0.5280198337140402,\n",
       "              0.5310837073663598,\n",
       "              0.5283004795532478,\n",
       "              0.5170434865984538,\n",
       "              0.5243350428841427,\n",
       "              0.5239296068239979,\n",
       "              0.5265756393756393],\n",
       "             'subpopulation_1.0_label_0.0_mia_privacy_risk': [0.5250590039188106,\n",
       "              0.5171079418766225,\n",
       "              0.5145901489856113,\n",
       "              0.5206485769335312,\n",
       "              0.5238933859096783,\n",
       "              0.5251466739051682,\n",
       "              0.518470738736096,\n",
       "              0.5252511811694265,\n",
       "              0.5095328935488538,\n",
       "              0.5129000404863686,\n",
       "              0.5194478799183596,\n",
       "              0.5193903216734466,\n",
       "              0.5171389828575321,\n",
       "              0.5195147335105389,\n",
       "              0.5223101935510033,\n",
       "              0.5224891569853093,\n",
       "              0.5134420955882353,\n",
       "              0.5199113320113953,\n",
       "              0.5223481844266616,\n",
       "              0.5243348051348051],\n",
       "             'subpopulation_1.0_label_0.0_mia_ppv': [0.5285234899328859,\n",
       "              0.5500603136308806,\n",
       "              0.5119919574895878,\n",
       "              0.5266881028938907,\n",
       "              0.5526315789473685,\n",
       "              0.533115671641791,\n",
       "              0.5433070866141733,\n",
       "              0.5271668822768434,\n",
       "              0.5226480836236934,\n",
       "              0.5269461077844311,\n",
       "              0.5346181299072091,\n",
       "              0.510948905109489,\n",
       "              0.5328753680078508,\n",
       "              0.5601783060921248,\n",
       "              0.5512195121951221,\n",
       "              0.5390693590869183,\n",
       "              0.5357142857142857,\n",
       "              0.5453629032258065,\n",
       "              0.5390492359932089,\n",
       "              0.5324118207816968],\n",
       "             'subpopulation_1.0_label_0.0_mia_attacker_advantage': [0.050118007837621215,\n",
       "              0.034215883753245024,\n",
       "              0.02918029797122257,\n",
       "              0.041297153867062175,\n",
       "              0.04778677181935648,\n",
       "              0.050293347810336564,\n",
       "              0.0369414774721919,\n",
       "              0.05050236233885297,\n",
       "              0.019065787097707565,\n",
       "              0.025800080972737227,\n",
       "              0.038895759836719224,\n",
       "              0.03878064334689324,\n",
       "              0.03427796571506425,\n",
       "              0.03902946702107779,\n",
       "              0.0446203871020065,\n",
       "              0.04497831397061858,\n",
       "              0.026884191176470562,\n",
       "              0.039822664022790444,\n",
       "              0.04469636885332329,\n",
       "              0.04866961026961025],\n",
       "             'subpopulation_1.0_label_0.0_mia_result': [MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.08290993, 0.08568129, 0.08960739, 0.09676674,\n",
       "                     0.09930716, 0.10230947, 0.10323326, 0.1182448 , 0.11847575,\n",
       "                     0.12448037, 0.13672055, 0.14387991, 0.16235566, 0.1743649 ,\n",
       "                     0.17759815, 0.17967667, 0.18314088, 0.19030023, 0.19676674,\n",
       "                     0.22309469, 0.22863741, 0.23764434, 0.2595843 , 0.2630485 ,\n",
       "                     0.30161663, 0.30669746, 0.31062356, 0.31755196, 0.32448037,\n",
       "                     0.36836028, 0.38337182, 0.39515012, 0.41685912, 0.42401848,\n",
       "                     0.4369515 , 0.44942263, 0.47297921, 0.4812933 , 0.49214781,\n",
       "                     0.49930716, 0.51986143, 0.52378753, 0.53949192, 0.57136259,\n",
       "                     0.57690531, 0.57852194, 0.58683603, 0.59237875, 0.62817552,\n",
       "                     0.63625866, 0.65265589, 0.66120092, 0.66443418, 0.66812933,\n",
       "                     0.67690531, 0.70923788, 0.72655889, 0.72817552, 0.73418014,\n",
       "                     0.74711316, 0.75727483, 0.75796767, 0.76212471, 0.76327945,\n",
       "                     0.79491917, 0.79976905, 0.80415704, 0.81362587, 0.81385681,\n",
       "                     0.81755196, 0.8187067 , 0.81939954, 0.83071594, 0.83256351,\n",
       "                     0.84849885, 0.85242494, 0.85796767, 0.86558891, 0.87090069,\n",
       "                     0.88013857, 0.88891455, 0.89237875, 0.89445727, 0.9       ,\n",
       "                     0.90092379, 0.91732102, 0.92378753, 0.93094688, 0.93187067,\n",
       "                     0.93464203, 0.94249423, 0.94595843, 0.95542725, 0.95704388,\n",
       "                     0.96558891, 0.96812933, 0.97090069, 0.97274827, 0.97505774,\n",
       "                     0.97990762, 0.98083141, 0.98198614, 0.98337182, 0.9852194 ,\n",
       "                     0.98545035, 0.98729792, 0.98822171, 0.98960739, 1.        ]), tpr=array([0.        , 0.08824874, 0.0916781 , 0.09510745, 0.10402378,\n",
       "                     0.10722451, 0.11202561, 0.11248285, 0.12962963, 0.13054412,\n",
       "                     0.13397348, 0.15020576, 0.15843621, 0.17604024, 0.18815729,\n",
       "                     0.19318701, 0.195016  , 0.19958848, 0.20484682, 0.21010517,\n",
       "                     0.24142661, 0.25057156, 0.26291724, 0.28806584, 0.29126658,\n",
       "                     0.32830361, 0.33790581, 0.3427069 , 0.35162323, 0.35916781,\n",
       "                     0.40146319, 0.41746685, 0.42798354, 0.4478738 , 0.45450389,\n",
       "                     0.46684957, 0.48353909, 0.50663009, 0.51326017, 0.52583448,\n",
       "                     0.53132144, 0.55578418, 0.56035665, 0.57270233, 0.60836763,\n",
       "                     0.61545496, 0.61751257, 0.62871513, 0.6351166 , 0.66803841,\n",
       "                     0.67832647, 0.69707362, 0.70827618, 0.71307727, 0.71673525,\n",
       "                     0.72702332, 0.75697302, 0.76680384, 0.76977595, 0.77572016,\n",
       "                     0.78715135, 0.8001829 , 0.80178326, 0.80384088, 0.804984  ,\n",
       "                     0.8349337 , 0.83927755, 0.8427069 , 0.85116598, 0.85253772,\n",
       "                     0.85756744, 0.85916781, 0.85985368, 0.87151349, 0.87311385,\n",
       "                     0.88591678, 0.88934614, 0.89414723, 0.90169182, 0.91037952,\n",
       "                     0.91860997, 0.92615455, 0.93004115, 0.93278464, 0.93644262,\n",
       "                     0.93804298, 0.9517604 , 0.95587563, 0.9613626 , 0.96387746,\n",
       "                     0.96593507, 0.96959305, 0.97187929, 0.97713763, 0.97828075,\n",
       "                     0.98491084, 0.98696845, 0.98879744, 0.99039781, 0.99154092,\n",
       "                     0.99565615, 0.99634202, 0.99702789, 0.99771376, 0.99862826,\n",
       "                     0.99908551, 0.99954275, 0.99977138, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.08219945e-02, -4.44517626e-02,\n",
       "                     -4.80092192e-02, -6.06246218e-02, -9.09717782e-02, -1.05360516e-01,\n",
       "                     -1.11703990e-01, -1.17783036e-01, -1.25163143e-01, -1.33531393e-01,\n",
       "                     -1.54150680e-01, -1.56698452e-01, -1.56842471e-01, -1.67054085e-01,\n",
       "                     -1.74353387e-01, -1.82321557e-01, -2.23143551e-01, -2.31801614e-01,\n",
       "                     -2.33310669e-01, -2.42946179e-01, -2.45122458e-01, -2.46471804e-01,\n",
       "                     -2.51314428e-01, -2.65494157e-01, -2.69663567e-01, -2.80902385e-01,\n",
       "                     -2.82862786e-01, -2.87682072e-01, -2.93072921e-01, -2.94799540e-01,\n",
       "                     -2.98492989e-01, -3.08838272e-01, -3.21583624e-01, -3.22083499e-01,\n",
       "                     -3.29957556e-01, -3.33639374e-01, -3.34369186e-01, -3.36472237e-01,\n",
       "                     -3.48306694e-01, -3.56674944e-01, -3.62905494e-01, -3.68560551e-01,\n",
       "                     -3.69044477e-01, -3.70859579e-01, -3.71563556e-01, -3.83725121e-01,\n",
       "                     -3.84845821e-01, -3.91478866e-01, -4.05465108e-01, -4.08128226e-01,\n",
       "                     -4.12244795e-01, -4.13562318e-01, -4.24883194e-01, -4.27444015e-01,\n",
       "                     -4.28107585e-01, -4.28454626e-01, -4.38254931e-01, -4.41832752e-01,\n",
       "                     -4.44685821e-01, -4.46287103e-01, -4.51985124e-01, -4.55475529e-01,\n",
       "                     -4.70003629e-01, -4.81388951e-01, -4.89548225e-01, -4.90622916e-01,\n",
       "                     -5.02091944e-01, -5.10825624e-01, -5.23248144e-01, -5.28067430e-01,\n",
       "                     -5.30628251e-01, -5.34082486e-01, -5.38996501e-01, -5.45694449e-01,\n",
       "                     -5.50046337e-01, -5.59615788e-01, -5.63935449e-01, -5.76422906e-01,\n",
       "                     -5.92342481e-01, -5.97837001e-01, -6.06135804e-01, -6.13104473e-01,\n",
       "                     -6.28608659e-01, -6.41853886e-01, -6.93147181e-01, -7.20546155e-01,\n",
       "                     -7.33969175e-01, -7.37598943e-01, -7.47214402e-01, -7.53771802e-01,\n",
       "                     -7.59105148e-01, -7.63351439e-01, -7.73189888e-01, -7.75838896e-01,\n",
       "                     -7.88457360e-01, -8.10930216e-01, -8.26678573e-01, -8.75468737e-01,\n",
       "                     -9.16290732e-01, -9.80829253e-01, -1.02961942e+00, -1.09861229e+00,\n",
       "                     -1.17865500e+00, -1.25276297e+00, -1.38629436e+00, -1.60943791e+00,\n",
       "                     -2.48490665e+00, -3.45387764e+01]), auc_score=0.529154747083068, privacy_risk=0.5250590039188106, accuracy=0.5250590039188106, tpr_ind=0.7270233196159122, tnr_ind=0.323094688221709, test_train_ratio=0.9899405578417924, dataset_size=[4374, 4330]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.07758221, 0.08221399, 0.08522464, 0.08638258,\n",
       "                     0.09194071, 0.09865679, 0.10398333, 0.10467809, 0.11185734,\n",
       "                     0.11949977, 0.12204724, 0.12459472, 0.12806855, 0.12945808,\n",
       "                     0.13385827, 0.14103752, 0.14173228, 0.15145901, 0.15585919,\n",
       "                     0.18689208, 0.20032422, 0.20449282, 0.21120889, 0.21815655,\n",
       "                     0.22163038, 0.22417786, 0.2274201 , 0.25057897, 0.25335804,\n",
       "                     0.25961093, 0.27003242, 0.29851783, 0.30199166, 0.30963409,\n",
       "                     0.31241315, 0.32468736, 0.35062529, 0.35803613, 0.36313108,\n",
       "                     0.39393238, 0.4201019 , 0.43330245, 0.43909217, 0.44210283,\n",
       "                     0.4569245 , 0.49397869, 0.49652617, 0.51042149, 0.51273738,\n",
       "                     0.52200093, 0.53983326, 0.61463641, 0.61718388, 0.62945808,\n",
       "                     0.63131079, 0.64659565, 0.66767022, 0.71329319, 0.71676702,\n",
       "                     0.71861973, 0.7213988 , 0.72371468, 0.72626216, 0.72834646,\n",
       "                     0.75104215, 0.7540528 , 0.76146364, 0.77119037, 0.81009727,\n",
       "                     0.823761  , 0.82723483, 0.83464567, 0.84089856, 0.84159333,\n",
       "                     0.85896248, 0.89207967, 0.89485873, 0.90690134, 0.91500695,\n",
       "                     0.91824919, 0.92056508, 0.9221862 , 0.92450208, 0.93121816,\n",
       "                     0.93584993, 0.94279759, 0.95437703, 0.95622974, 0.95785086,\n",
       "                     0.96039833, 0.96340899, 0.96757758, 0.97660954, 0.98008337,\n",
       "                     0.9835572 , 0.98494673, 0.98633627, 0.98888374, 0.98934692,\n",
       "                     0.99027327, 0.99119963, 0.99421028, 0.99444187, 1.        ]), tpr=array([0.        , 0.09165527, 0.09872321, 0.10168719, 0.10396717,\n",
       "                     0.10761514, 0.11468308, 0.11878705, 0.12015504, 0.12767898,\n",
       "                     0.13429093, 0.13657091, 0.13839489, 0.14158687, 0.14341085,\n",
       "                     0.14933881, 0.15367077, 0.15503876, 0.1625627 , 0.16712266,\n",
       "                     0.20109439, 0.21454628, 0.21887825, 0.2245782 , 0.23073415,\n",
       "                     0.23620611, 0.23848609, 0.24190606, 0.2754218 , 0.27792978,\n",
       "                     0.28454172, 0.29434565, 0.32079343, 0.3251254 , 0.33219334,\n",
       "                     0.33538532, 0.34564523, 0.37072503, 0.37938896, 0.38440492,\n",
       "                     0.41450068, 0.44254446, 0.45554036, 0.4628363 , 0.46488828,\n",
       "                     0.48107615, 0.51504788, 0.52097583, 0.5369357 , 0.54012768,\n",
       "                     0.55129959, 0.56543548, 0.64386685, 0.64523484, 0.6625627 ,\n",
       "                     0.66552668, 0.68080255, 0.69881441, 0.73962608, 0.74099407,\n",
       "                     0.74304606, 0.74578203, 0.74897401, 0.75330597, 0.75604195,\n",
       "                     0.78020976, 0.78431373, 0.79069767, 0.7995896 , 0.83470132,\n",
       "                     0.84724122, 0.8495212 , 0.85864113, 0.86479708, 0.86639307,\n",
       "                     0.88258094, 0.9122207 , 0.91495668, 0.92635659, 0.93251254,\n",
       "                     0.93616051, 0.94117647, 0.94391245, 0.94573643, 0.95508436,\n",
       "                     0.95804834, 0.96420429, 0.97309622, 0.9753762 , 0.97697218,\n",
       "                     0.97902417, 0.98267214, 0.98426813, 0.9874601 , 0.98928409,\n",
       "                     0.99202006, 0.99384405, 0.99521204, 0.99635203, 0.99749202,\n",
       "                     0.99840401, 0.99886001, 0.999772  , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.17486983e-02, -4.87901642e-02,\n",
       "                     -5.40672213e-02, -6.06246218e-02, -6.25203570e-02, -6.45385211e-02,\n",
       "                     -6.89928715e-02, -8.70113770e-02, -9.30904231e-02, -1.00083459e-01,\n",
       "                     -1.17783036e-01, -1.33531393e-01, -1.39761942e-01, -1.43100844e-01,\n",
       "                     -1.46603474e-01, -1.54150680e-01, -1.67054085e-01, -1.82321557e-01,\n",
       "                     -1.84778560e-01, -1.85142433e-01, -1.91055237e-01, -1.92371893e-01,\n",
       "                     -2.00670695e-01, -2.11309094e-01, -2.23143551e-01, -2.33614851e-01,\n",
       "                     -2.34029359e-01, -2.41162057e-01, -2.43622083e-01, -2.46133070e-01,\n",
       "                     -2.76847730e-01, -2.80301965e-01, -2.87682072e-01, -3.05381650e-01,\n",
       "                     -3.07025035e-01, -3.10154928e-01, -3.13657559e-01, -3.16669609e-01,\n",
       "                     -3.28296792e-01, -3.36472237e-01, -3.38975367e-01, -3.40926587e-01,\n",
       "                     -3.42944751e-01, -3.52077235e-01, -3.52639969e-01, -3.52821375e-01,\n",
       "                     -3.55765440e-01, -3.56674944e-01, -3.70859579e-01, -3.72675285e-01,\n",
       "                     -3.73966441e-01, -3.74693449e-01, -3.75312070e-01, -3.79489622e-01,\n",
       "                     -3.90427231e-01, -4.05465108e-01, -4.25742301e-01, -4.35318071e-01,\n",
       "                     -4.41832752e-01, -4.46287103e-01, -4.51985124e-01, -4.56758402e-01,\n",
       "                     -4.59532329e-01, -4.70003629e-01, -4.76924072e-01, -4.83796951e-01,\n",
       "                     -4.95321437e-01, -5.10825624e-01, -5.26093096e-01, -5.28067430e-01,\n",
       "                     -5.30628251e-01, -5.32804530e-01, -5.38996501e-01, -5.49504478e-01,\n",
       "                     -5.57415567e-01, -5.59615788e-01, -5.65313809e-01, -5.75364145e-01,\n",
       "                     -5.94707108e-01, -5.97837001e-01, -6.06135804e-01, -6.28608659e-01,\n",
       "                     -6.43136760e-01, -6.53926467e-01, -6.55406853e-01, -6.93147181e-01,\n",
       "                     -7.41937345e-01, -7.62140052e-01, -7.98507696e-01, -8.10930216e-01,\n",
       "                     -8.69037847e-01, -8.87303195e-01, -9.16290732e-01, -9.40983344e-01,\n",
       "                     -9.65080896e-01, -9.80829253e-01, -1.09861229e+00, -1.16315081e+00,\n",
       "                     -1.17865500e+00, -1.25276297e+00, -1.38629436e+00, -2.07944154e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5211786175094573, privacy_risk=0.5171079418766225, accuracy=0.5171079418766225, tpr_ind=0.6655266757865937, tnr_ind=0.3686892079666512, test_train_ratio=0.9844961240310077, dataset_size=[4386, 4318]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.10321685, 0.10715112, 0.11015969, 0.11455682,\n",
       "                     0.11617681, 0.12011109, 0.12034251, 0.12381393, 0.12497107,\n",
       "                     0.1335339 , 0.13955103, 0.1409396 , 0.15875955, 0.1666281 ,\n",
       "                     0.17171951, 0.18745661, 0.19301088, 0.19532516, 0.2048137 ,\n",
       "                     0.21245082, 0.21823652, 0.22078223, 0.23906503, 0.23952789,\n",
       "                     0.24137931, 0.25734784, 0.32029623, 0.34737329, 0.35061328,\n",
       "                     0.35454756, 0.36750752, 0.37491321, 0.38810461, 0.40800741,\n",
       "                     0.41772738, 0.41934737, 0.42004166, 0.4211988 , 0.42860449,\n",
       "                     0.50821569, 0.52117565, 0.52418422, 0.5290442 , 0.54362416,\n",
       "                     0.54431844, 0.59916686, 0.61536681, 0.61791252, 0.62184679,\n",
       "                     0.62763249, 0.63526961, 0.63943532, 0.64822958, 0.66512381,\n",
       "                     0.67368665, 0.68919232, 0.69682944, 0.71950937, 0.72807221,\n",
       "                     0.73293219, 0.73640361, 0.75005786, 0.75352928, 0.76718352,\n",
       "                     0.77134922, 0.78639204, 0.79541773, 0.83013191, 0.83938903,\n",
       "                     0.8449433 , 0.85003471, 0.85443184, 0.86230039, 0.86507753,\n",
       "                     0.87410322, 0.87526036, 0.88984031, 0.900486  , 0.90418885,\n",
       "                     0.90488313, 0.91576024, 0.91900023, 0.92733164, 0.93427447,\n",
       "                     0.94237445, 0.94839158, 0.94954872, 0.95417727, 0.9585744 ,\n",
       "                     0.96574867, 0.9685258 , 0.96945152, 0.97107151, 0.97269151,\n",
       "                     0.97477436, 0.97500579, 0.9817172 , 0.98380005, 0.98472576,\n",
       "                     0.98565147, 0.98750289, 0.98773432, 0.98981717, 1.        ]), tpr=array([0.        , 0.09582478, 0.10084417, 0.1026694 , 0.10677618,\n",
       "                     0.10928588, 0.11362081, 0.11430527, 0.11795574, 0.12137805,\n",
       "                     0.12571298, 0.13324207, 0.13597992, 0.15446042, 0.1619895 ,\n",
       "                     0.16678074, 0.18297969, 0.18959617, 0.19370294, 0.20374173,\n",
       "                     0.21149897, 0.21651837, 0.21948437, 0.23636778, 0.23887748,\n",
       "                     0.24047456, 0.24982888, 0.30937714, 0.33835273, 0.34063427,\n",
       "                     0.34588182, 0.35614876, 0.36732831, 0.38124572, 0.40543007,\n",
       "                     0.41592517, 0.41911932, 0.42162902, 0.42527949, 0.43189596,\n",
       "                     0.51060917, 0.5204198 , 0.5229295 , 0.52817705, 0.54688569,\n",
       "                     0.54848277, 0.60939995, 0.62422998, 0.62833676, 0.63289984,\n",
       "                     0.63883185, 0.64909879, 0.65297741, 0.65982204, 0.68149669,\n",
       "                     0.69153548, 0.70727812, 0.7118412 , 0.73191878, 0.74287018,\n",
       "                     0.74948665, 0.75290897, 0.77138946, 0.77572439, 0.78827287,\n",
       "                     0.79397673, 0.81336984, 0.82112708, 0.85671914, 0.86493269,\n",
       "                     0.87109286, 0.87611225, 0.88044718, 0.88843258, 0.89071412,\n",
       "                     0.9002966 , 0.90303445, 0.91832078, 0.92904403, 0.9326945 ,\n",
       "                     0.93406343, 0.94204883, 0.94592745, 0.95368469, 0.95687885,\n",
       "                     0.96486425, 0.96897102, 0.97125257, 0.97490303, 0.97969427,\n",
       "                     0.98425736, 0.98699521, 0.98836413, 0.99087383, 0.9920146 ,\n",
       "                     0.99361168, 0.99406799, 0.99612138, 0.99726215, 0.99817477,\n",
       "                     0.99885923, 0.99954369, 0.99977185, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.44517626e-02, -5.12932944e-02,\n",
       "                     -5.40672213e-02, -7.41079722e-02, -8.00427077e-02, -1.05360516e-01,\n",
       "                     -1.17783036e-01, -1.25163143e-01, -1.33531393e-01, -1.41078598e-01,\n",
       "                     -1.54150680e-01, -1.59427737e-01, -1.67054085e-01, -1.74353387e-01,\n",
       "                     -1.82321557e-01, -1.88052232e-01, -2.00670695e-01, -2.04794413e-01,\n",
       "                     -2.11309094e-01, -2.17723484e-01, -2.23143551e-01, -2.28534400e-01,\n",
       "                     -2.41162057e-01, -2.51314428e-01, -2.56719847e-01, -2.58525488e-01,\n",
       "                     -2.61758387e-01, -2.62364264e-01, -2.65703166e-01, -2.70874954e-01,\n",
       "                     -2.82566972e-01, -2.87682072e-01, -2.92387963e-01, -2.98492989e-01,\n",
       "                     -3.05381650e-01, -3.10154928e-01, -3.18453731e-01, -3.21583624e-01,\n",
       "                     -3.46770989e-01, -3.49673748e-01, -3.50202429e-01, -3.52821375e-01,\n",
       "                     -3.55454688e-01, -3.56674944e-01, -3.58171950e-01, -3.58212223e-01,\n",
       "                     -3.67724780e-01, -3.71563556e-01, -3.79489622e-01, -3.82992252e-01,\n",
       "                     -3.86772975e-01, -3.94654192e-01, -4.05465108e-01, -4.20502985e-01,\n",
       "                     -4.32263301e-01, -4.38254931e-01, -4.51985124e-01, -4.59532329e-01,\n",
       "                     -4.61345567e-01, -4.70003629e-01, -4.78224462e-01, -4.89548225e-01,\n",
       "                     -4.92476485e-01, -4.94696242e-01, -4.98991166e-01, -5.00775288e-01,\n",
       "                     -5.02430353e-01, -5.03526321e-01, -5.10825624e-01, -5.19875459e-01,\n",
       "                     -5.21296924e-01, -5.22189382e-01, -5.30628251e-01, -5.38996501e-01,\n",
       "                     -5.59615788e-01, -5.87786665e-01, -5.91364486e-01, -5.94707108e-01,\n",
       "                     -6.06135804e-01, -6.24154309e-01, -6.32522559e-01, -6.48026745e-01,\n",
       "                     -6.56779536e-01, -6.93147181e-01, -7.48717032e-01, -7.50305594e-01,\n",
       "                     -7.53771802e-01, -7.62140052e-01, -7.88457360e-01, -8.10930216e-01,\n",
       "                     -8.47297860e-01, -8.60201265e-01, -8.75468737e-01, -8.87303195e-01,\n",
       "                     -9.16290732e-01, -1.09861229e+00, -1.16315081e+00, -1.17865500e+00,\n",
       "                     -1.46633707e+00, -1.60943791e+00, -1.79175947e+00, -2.19722458e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5063777054506157, privacy_risk=0.5145901489856113, accuracy=0.5145901489856113, tpr_ind=0.9340634268765685, tnr_ind=0.09511687109465401, test_train_ratio=0.9858544375998175, dataset_size=[4383, 4321]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.06356518, 0.07715339, 0.08705666, 0.08935974,\n",
       "                     0.0935053 , 0.10202672, 0.11192999, 0.11308153, 0.11630585,\n",
       "                     0.1176877 , 0.12183326, 0.12897282, 0.13127591, 0.13473054,\n",
       "                     0.15108245, 0.16098572, 0.16121603, 0.16282819, 0.17342239,\n",
       "                     0.17964072, 0.18033164, 0.18378627, 0.1950714 , 0.20935053,\n",
       "                     0.21165362, 0.23307232, 0.26416398, 0.27498848, 0.29617688,\n",
       "                     0.31920774, 0.32427453, 0.3288807 , 0.33302626, 0.33555965,\n",
       "                     0.33901428, 0.35997236, 0.38737909, 0.39958544, 0.41593736,\n",
       "                     0.42215569, 0.43666513, 0.4412713 , 0.44633809, 0.45578075,\n",
       "                     0.46130815, 0.47950253, 0.48756333, 0.49309074, 0.49677568,\n",
       "                     0.51727315, 0.56310456, 0.59949332, 0.62206357, 0.62782128,\n",
       "                     0.63196684, 0.63657301, 0.65845233, 0.67134961, 0.67250115,\n",
       "                     0.67549516, 0.68516813, 0.69345924, 0.69553201, 0.71349608,\n",
       "                     0.72915707, 0.74712114, 0.76324275, 0.7835099 , 0.83302626,\n",
       "                     0.83809304, 0.8450023 , 0.84707508, 0.85076002, 0.85536619,\n",
       "                     0.86273607, 0.87678489, 0.8797789 , 0.88645785, 0.90050668,\n",
       "                     0.90718563, 0.91133118, 0.9145555 , 0.91962229, 0.92353754,\n",
       "                     0.93159834, 0.93689544, 0.93988945, 0.94725933, 0.9518655 ,\n",
       "                     0.95578075, 0.96775679, 0.97098111, 0.97351451, 0.9760479 ,\n",
       "                     0.97766006, 0.98249655, 0.9866421 , 0.99055735, 0.99216951,\n",
       "                     0.99378167, 0.9947029 , 1.        ]), tpr=array([0.        , 0.05983494, 0.07611188, 0.08895002, 0.09307657,\n",
       "                     0.09834938, 0.10660248, 0.11852361, 0.12035763, 0.12287941,\n",
       "                     0.12517194, 0.12815222, 0.13640532, 0.13869785, 0.14282439,\n",
       "                     0.16024759, 0.17079321, 0.17239798, 0.17469051, 0.18844567,\n",
       "                     0.19578175, 0.19784503, 0.20082531, 0.2086199 , 0.22489684,\n",
       "                     0.22879413, 0.25401192, 0.2909216 , 0.30169647, 0.32393398,\n",
       "                     0.34846401, 0.35373682, 0.36176066, 0.36588721, 0.37024301,\n",
       "                     0.37551582, 0.39385603, 0.42182485, 0.43833104, 0.45002293,\n",
       "                     0.45712976, 0.46813388, 0.47569922, 0.47936726, 0.49174691,\n",
       "                     0.49793673, 0.51834021, 0.5256763 , 0.5343879 , 0.53668042,\n",
       "                     0.55708391, 0.59903714, 0.62677671, 0.64878496, 0.65497478,\n",
       "                     0.65864282, 0.66299862, 0.68271435, 0.6916552 , 0.69624026,\n",
       "                     0.70128381, 0.7129757 , 0.71847776, 0.72122879, 0.74094452,\n",
       "                     0.75355342, 0.76547455, 0.78289775, 0.79825768, 0.85259055,\n",
       "                     0.85878038, 0.86634571, 0.86955525, 0.87345254, 0.87643283,\n",
       "                     0.88560293, 0.89912884, 0.90073361, 0.90761119, 0.92228336,\n",
       "                     0.92801467, 0.93099496, 0.93351674, 0.93741403, 0.94154058,\n",
       "                     0.95048143, 0.95414947, 0.956442  , 0.96400734, 0.96813388,\n",
       "                     0.97134342, 0.9825768 , 0.98647409, 0.9873911 , 0.98876662,\n",
       "                     0.98991288, 0.99243466, 0.99449794, 0.99656121, 0.99816598,\n",
       "                     0.99931224, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.65293020e-02, -5.21857532e-02,\n",
       "                     -5.40672213e-02, -6.06246218e-02, -6.89928715e-02, -7.41079722e-02,\n",
       "                     -8.00427077e-02, -1.17783036e-01, -1.33531393e-01, -1.43100844e-01,\n",
       "                     -1.45182010e-01, -1.48420005e-01, -1.54150680e-01, -1.57903029e-01,\n",
       "                     -1.60342650e-01, -1.67054085e-01, -1.82321557e-01, -1.84192465e-01,\n",
       "                     -1.97825743e-01, -2.00670695e-01, -2.07639365e-01, -2.11309094e-01,\n",
       "                     -2.13574100e-01, -2.23143551e-01, -2.26773319e-01, -2.26863332e-01,\n",
       "                     -2.27389842e-01, -2.29310066e-01, -2.32445944e-01, -2.54892250e-01,\n",
       "                     -2.65281136e-01, -2.66628663e-01, -2.74436846e-01, -2.87682072e-01,\n",
       "                     -2.90802200e-01, -2.97766192e-01, -2.98044859e-01, -3.02280872e-01,\n",
       "                     -3.03682414e-01, -3.15852949e-01, -3.16669609e-01, -3.18453731e-01,\n",
       "                     -3.28504067e-01, -3.36472237e-01, -3.56674944e-01, -3.57837059e-01,\n",
       "                     -3.61013346e-01, -3.62905494e-01, -3.71176035e-01, -3.74010156e-01,\n",
       "                     -3.74406711e-01, -3.84411699e-01, -3.93042588e-01, -4.05465108e-01,\n",
       "                     -4.22856851e-01, -4.28454626e-01, -4.35318071e-01, -4.38254931e-01,\n",
       "                     -4.41832752e-01, -4.50201002e-01, -4.51985124e-01, -4.59532329e-01,\n",
       "                     -4.65633630e-01, -4.70003629e-01, -4.79573080e-01, -4.89548225e-01,\n",
       "                     -4.95787746e-01, -5.08290768e-01, -5.10825624e-01, -5.28844129e-01,\n",
       "                     -5.38996501e-01, -5.67984038e-01, -5.70544858e-01, -5.73800423e-01,\n",
       "                     -5.76422906e-01, -5.79818495e-01, -5.87786665e-01, -5.94707108e-01,\n",
       "                     -6.09765572e-01, -6.13104473e-01, -6.15185639e-01, -6.32522559e-01,\n",
       "                     -6.35988767e-01, -6.40503447e-01, -6.61398482e-01, -6.66478933e-01,\n",
       "                     -6.93147181e-01, -7.47214402e-01, -7.62140052e-01, -7.90310929e-01,\n",
       "                     -8.04372816e-01, -8.10930216e-01, -8.47297860e-01, -8.75468737e-01,\n",
       "                     -1.00330211e+00, -1.02165125e+00, -1.09861229e+00, -1.23214368e+00,\n",
       "                     -1.38629436e+00, -1.54044504e+00, -3.45387764e+01]), auc_score=0.5219496463638167, privacy_risk=0.5206485769335312, accuracy=0.5206485769335312, tpr_ind=0.5343878954607978, tnr_ind=0.5069092584062644, test_train_ratio=0.9954149472718936, dataset_size=[4362, 4342]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.08690667, 0.09149278, 0.09745471, 0.10318734,\n",
       "                     0.10387526, 0.10823206, 0.11373538, 0.11992662, 0.12474203,\n",
       "                     0.13185049, 0.13414355, 0.14193992, 0.15569823, 0.15638615,\n",
       "                     0.15890851, 0.16395322, 0.17083238, 0.17771153, 0.18573722,\n",
       "                     0.19261637, 0.19789039, 0.20018344, 0.20958496, 0.21554689,\n",
       "                     0.22861729, 0.23733089, 0.25177712, 0.25521669, 0.27562486,\n",
       "                     0.28273332, 0.30520523, 0.31368952, 0.3217152 , 0.32813575,\n",
       "                     0.3304288 , 0.36321945, 0.36918138, 0.38064664, 0.39279982,\n",
       "                     0.39692731, 0.41618895, 0.42857143, 0.4315524 , 0.44026599,\n",
       "                     0.50791103, 0.51662463, 0.52006421, 0.55789956, 0.56088053,\n",
       "                     0.56592525, 0.59344187, 0.59734006, 0.60605366, 0.61316212,\n",
       "                     0.62004127, 0.64939234, 0.65168539, 0.66246274, 0.67140564,\n",
       "                     0.6785141 , 0.68608117, 0.69387755, 0.70121532, 0.70694795,\n",
       "                     0.7358404 , 0.7401972 , 0.74294886, 0.74959872, 0.7532676 ,\n",
       "                     0.75739509, 0.76243981, 0.76702591, 0.76977757, 0.77275854,\n",
       "                     0.77596881, 0.78009631, 0.78674616, 0.80050447, 0.80394405,\n",
       "                     0.81472139, 0.84086219, 0.84498968, 0.8500344 , 0.87709241,\n",
       "                     0.8855767 , 0.89130933, 0.90116946, 0.90369181, 0.90621417,\n",
       "                     0.91378124, 0.92570511, 0.93052052, 0.93992204, 0.94221509,\n",
       "                     0.94794772, 0.94955285, 0.95482687, 0.95964228, 0.96124742,\n",
       "                     0.96376978, 0.96858519, 0.97294199, 0.97546434, 0.97959184,\n",
       "                     0.98303141, 0.98349003, 0.98578308, 0.98830543, 0.98853474,\n",
       "                     0.9912864 , 0.99312084, 0.99449668, 0.99472598, 1.        ]), tpr=array([0.        , 0.10223348, 0.1072991 , 0.11213447, 0.11996316,\n",
       "                     0.12226571, 0.12917338, 0.13999539, 0.14874511, 0.15473175,\n",
       "                     0.15979738, 0.16140916, 0.16808658, 0.18535574, 0.18673728,\n",
       "                     0.18996086, 0.19433571, 0.20170389, 0.2104536 , 0.21920332,\n",
       "                     0.22611098, 0.23186737, 0.23255814, 0.24222887, 0.24890629,\n",
       "                     0.26157034, 0.27354363, 0.28966152, 0.29357587, 0.31637117,\n",
       "                     0.32396961, 0.35021874, 0.36011973, 0.36840893, 0.37508635,\n",
       "                     0.37807967, 0.41100622, 0.41676261, 0.42551232, 0.43403178,\n",
       "                     0.43863689, 0.45636657, 0.46281372, 0.46741883, 0.47801059,\n",
       "                     0.5463965 , 0.55353442, 0.55813953, 0.59912503, 0.6018881 ,\n",
       "                     0.60787474, 0.63826848, 0.64172231, 0.64886023, 0.65553765,\n",
       "                     0.66336634, 0.69306931, 0.69813493, 0.70849643, 0.71862768,\n",
       "                     0.72553534, 0.73267327, 0.7402717 , 0.74763988, 0.75293576,\n",
       "                     0.77457978, 0.78033617, 0.78263873, 0.78701359, 0.79138844,\n",
       "                     0.79530279, 0.7999079 , 0.80336173, 0.80566429, 0.80957863,\n",
       "                     0.81280221, 0.81694681, 0.82178218, 0.83536726, 0.83859084,\n",
       "                     0.84526825, 0.86967534, 0.87266866, 0.87727377, 0.9051347 ,\n",
       "                     0.91480543, 0.91895003, 0.93023256, 0.93161409, 0.93391665,\n",
       "                     0.93852176, 0.94773198, 0.95463965, 0.96292885, 0.96454064,\n",
       "                     0.96937601, 0.97052729, 0.97421137, 0.97789546, 0.97950725,\n",
       "                     0.9813493 , 0.98434262, 0.98664518, 0.98917799, 0.99148054,\n",
       "                     0.99332259, 0.99447387, 0.9958554 , 0.99677642, 0.99746719,\n",
       "                     0.99838821, 0.99930923, 0.99976974, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.44517626e-02, -4.65200156e-02,\n",
       "                     -8.45573880e-02, -8.70113770e-02, -1.03184236e-01, -1.09199292e-01,\n",
       "                     -1.16072171e-01, -1.22602322e-01, -1.27833372e-01, -1.29211731e-01,\n",
       "                     -1.35801541e-01, -1.43100844e-01, -1.54150680e-01, -1.60342650e-01,\n",
       "                     -1.78248231e-01, -1.82321557e-01, -1.91055237e-01, -2.00670695e-01,\n",
       "                     -2.09720531e-01, -2.18253566e-01, -2.23143551e-01, -2.32622295e-01,\n",
       "                     -2.39229689e-01, -2.43977638e-01, -2.49654677e-01, -2.51314428e-01,\n",
       "                     -2.56719847e-01, -2.57829109e-01, -2.64692554e-01, -2.68263987e-01,\n",
       "                     -2.76632236e-01, -2.87682072e-01, -2.96265816e-01, -3.02280872e-01,\n",
       "                     -3.05013529e-01, -3.07484700e-01, -3.13657559e-01, -3.20907720e-01,\n",
       "                     -3.22773392e-01, -3.29023413e-01, -3.31357136e-01, -3.32705754e-01,\n",
       "                     -3.36472237e-01, -3.36953121e-01, -3.50202429e-01, -3.56674944e-01,\n",
       "                     -3.67292535e-01, -3.71563556e-01, -3.79489622e-01, -3.79888266e-01,\n",
       "                     -3.82992252e-01, -3.90427231e-01, -3.93904286e-01, -4.05465108e-01,\n",
       "                     -4.13187154e-01, -4.15515444e-01, -4.16893804e-01, -4.20502985e-01,\n",
       "                     -4.21725629e-01, -4.21994410e-01, -4.22414666e-01, -4.30036369e-01,\n",
       "                     -4.48024723e-01, -4.67340512e-01, -4.70003629e-01, -4.79573080e-01,\n",
       "                     -4.80585739e-01, -4.89548225e-01, -4.98991166e-01, -5.00775288e-01,\n",
       "                     -5.10825624e-01, -5.30628251e-01, -5.34082486e-01, -5.38996501e-01,\n",
       "                     -5.43615447e-01, -5.44301553e-01, -5.47435369e-01, -5.59615788e-01,\n",
       "                     -5.64529803e-01, -5.67669523e-01, -5.70544858e-01, -5.75364145e-01,\n",
       "                     -5.88704517e-01, -5.93063722e-01, -5.97837001e-01, -6.21688217e-01,\n",
       "                     -6.53926467e-01, -6.64976304e-01, -6.67829373e-01, -6.93147181e-01,\n",
       "                     -7.04197017e-01, -7.47214402e-01, -7.62140052e-01, -7.82759339e-01,\n",
       "                     -7.88457360e-01, -8.07091440e-01, -8.10930216e-01, -8.26678573e-01,\n",
       "                     -8.47297860e-01, -8.69037847e-01, -8.75468737e-01, -9.04456274e-01,\n",
       "                     -9.16290732e-01, -9.80829253e-01, -1.02961942e+00, -1.09861229e+00,\n",
       "                     -1.17865500e+00, -1.20397280e+00, -1.25276297e+00, -1.32175584e+00,\n",
       "                     -1.38629436e+00, -2.07944154e+00, -3.45387764e+01]), auc_score=0.5331736996697383, privacy_risk=0.5238933859096783, accuracy=0.5238933859096783, tpr_ind=0.41100621690075984, tnr_ind=0.6367805549185966, test_train_ratio=1.0041446005065622, dataset_size=[4343, 4361]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.07957924, 0.08026526, 0.08415276, 0.08712554,\n",
       "                     0.0942145 , 0.10839241, 0.11022182, 0.11616739, 0.11936885,\n",
       "                     0.12645781, 0.14200777, 0.14795335, 0.15229819, 0.16030185,\n",
       "                     0.18065401, 0.18431283, 0.188429  , 0.188429  , 0.19208781,\n",
       "                     0.2016922 , 0.21243997, 0.21655614, 0.22890464, 0.29224788,\n",
       "                     0.29361994, 0.3073405 , 0.30848388, 0.31054196, 0.31831694,\n",
       "                     0.36496684, 0.37685799, 0.37845872, 0.39400869, 0.39629545,\n",
       "                     0.46512692, 0.46787103, 0.47473131, 0.47839012, 0.48845186,\n",
       "                     0.49119598, 0.49645552, 0.49874228, 0.50674594, 0.52504002,\n",
       "                     0.52892751, 0.53533044, 0.61376629, 0.61628173, 0.62154128,\n",
       "                     0.63457581, 0.6450949 , 0.65492797, 0.66018751, 0.6622456 ,\n",
       "                     0.66841985, 0.67619483, 0.67962497, 0.69883375, 0.70706609,\n",
       "                     0.71369769, 0.73382118, 0.73565058, 0.74091013, 0.74342557,\n",
       "                     0.74891379, 0.74937114, 0.77406815, 0.78298651, 0.78618797,\n",
       "                     0.79510633, 0.79785045, 0.81751658, 0.82163275, 0.82460553,\n",
       "                     0.83466728, 0.86050766, 0.8630231 , 0.87011205, 0.87422822,\n",
       "                     0.87582895, 0.88497599, 0.89640979, 0.89892522, 0.90372742,\n",
       "                     0.90464212, 0.90784359, 0.91447519, 0.91607592, 0.9286531 ,\n",
       "                     0.93093986, 0.9515207 , 0.95563686, 0.95838097, 0.96021038,\n",
       "                     0.96089641, 0.96272582, 0.96844272, 0.96890007, 0.97781843,\n",
       "                     0.97941916, 0.97964784, 0.98239195, 0.98399268, 0.98467871,\n",
       "                     0.98559341, 0.98719415, 0.9876515 , 0.98902355, 1.        ]), tpr=array([0.        , 0.08704687, 0.0895867 , 0.09212653, 0.09466636,\n",
       "                     0.10113138, 0.12375895, 0.1253752 , 0.13114754, 0.13530363,\n",
       "                     0.13922882, 0.154006  , 0.16531979, 0.17063034, 0.1791734 ,\n",
       "                     0.2008774 , 0.20595705, 0.21080582, 0.21103671, 0.21611637,\n",
       "                     0.22812284, 0.24428538, 0.24844147, 0.26391134, 0.32786885,\n",
       "                     0.32925421, 0.34703302, 0.34934195, 0.35211268, 0.35696144,\n",
       "                     0.401293  , 0.41168321, 0.41237589, 0.42784576, 0.43177095,\n",
       "                     0.50288617, 0.50704225, 0.51235281, 0.51581621, 0.52505195,\n",
       "                     0.52736089, 0.53197876, 0.53590395, 0.54259986, 0.56314939,\n",
       "                     0.56684369, 0.57261602, 0.65389056, 0.65527592, 0.66335719,\n",
       "                     0.67536366, 0.6880628 , 0.69591318, 0.69983837, 0.7023782 ,\n",
       "                     0.70630339, 0.71761718, 0.71946433, 0.73978296, 0.75132764,\n",
       "                     0.7561764 , 0.78411452, 0.78526899, 0.7885015 , 0.79242669,\n",
       "                     0.79773724, 0.7991226 , 0.82105749, 0.82729162, 0.83260217,\n",
       "                     0.83975987, 0.84137613, 0.85869314, 0.86238744, 0.86423459,\n",
       "                     0.87416301, 0.89194181, 0.89401986, 0.89748326, 0.90117756,\n",
       "                     0.90371739, 0.9138767 , 0.92426691, 0.92726853, 0.92980836,\n",
       "                     0.9318864 , 0.93673517, 0.9425075 , 0.94550912, 0.95751559,\n",
       "                     0.96028631, 0.97367813, 0.97760332, 0.98060494, 0.9819903 ,\n",
       "                     0.98291388, 0.98360656, 0.98683907, 0.98799353, 0.99307319,\n",
       "                     0.99376587, 0.99399677, 0.9965366 , 0.99792196, 0.99861464,\n",
       "                     0.99907643, 0.99930732, 0.99976911, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.40672213e-02, -8.70113770e-02,\n",
       "                     -9.84400728e-02, -1.01782694e-01, -1.06380404e-01, -1.11225635e-01,\n",
       "                     -1.13328685e-01, -1.17783036e-01, -1.33531393e-01, -1.41078598e-01,\n",
       "                     -1.54150680e-01, -1.62518929e-01, -1.82321557e-01, -1.94156014e-01,\n",
       "                     -2.04794413e-01, -2.13574100e-01, -2.23143551e-01, -2.28841572e-01,\n",
       "                     -2.38411023e-01, -2.40141128e-01, -2.41162057e-01, -2.42313467e-01,\n",
       "                     -2.50913225e-01, -2.51314428e-01, -2.61364764e-01, -2.62364264e-01,\n",
       "                     -2.64692554e-01, -2.87682072e-01, -2.95464213e-01, -3.04211374e-01,\n",
       "                     -3.05381650e-01, -3.17095958e-01, -3.18453731e-01, -3.19633672e-01,\n",
       "                     -3.28504067e-01, -3.30241687e-01, -3.32133835e-01, -3.34934957e-01,\n",
       "                     -3.36472237e-01, -3.43771539e-01, -3.44840486e-01, -3.46276237e-01,\n",
       "                     -3.55550717e-01, -3.62905494e-01, -3.64643114e-01, -3.66850272e-01,\n",
       "                     -3.67724780e-01, -3.76477571e-01, -3.79489622e-01, -3.81934611e-01,\n",
       "                     -3.83958903e-01, -3.85662481e-01, -3.87765531e-01, -4.05465108e-01,\n",
       "                     -4.12244795e-01, -4.16893804e-01, -4.20502985e-01, -4.40971797e-01,\n",
       "                     -4.51985124e-01, -4.65057205e-01, -4.70003629e-01, -4.78490243e-01,\n",
       "                     -4.90622916e-01, -5.02091944e-01, -5.10825624e-01, -5.15027311e-01,\n",
       "                     -5.18793793e-01, -5.28067430e-01, -5.36304709e-01, -5.38996501e-01,\n",
       "                     -5.42324291e-01, -5.46543706e-01, -5.59615788e-01, -5.61377903e-01,\n",
       "                     -5.67984038e-01, -5.75364145e-01, -5.87786665e-01, -5.95983432e-01,\n",
       "                     -5.97837001e-01, -6.12517446e-01, -6.14158769e-01, -6.19039208e-01,\n",
       "                     -6.31271777e-01, -6.35988767e-01, -6.44357016e-01, -6.52325186e-01,\n",
       "                     -6.53926467e-01, -6.66191371e-01, -6.69049629e-01, -6.93147181e-01,\n",
       "                     -7.30887509e-01, -7.50305594e-01, -7.73189888e-01, -8.10930216e-01,\n",
       "                     -8.47297860e-01, -8.57450232e-01, -8.75468737e-01, -9.16290732e-01,\n",
       "                     -1.01160091e+00, -1.09861229e+00, -1.18562367e+00, -1.20397280e+00,\n",
       "                     -1.29928298e+00, -1.38629436e+00, -1.60943791e+00, -2.07944154e+00,\n",
       "                     -2.63905733e+00, -3.45387764e+01]), auc_score=0.5311100689602445, privacy_risk=0.5251466739051682, accuracy=0.5251466739051682, tpr_ind=0.7841145232048026, tnr_ind=0.26617882460553394, test_train_ratio=1.0096975294389288, dataset_size=[4331, 4373]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.08159044, 0.08434843, 0.08756608, 0.09216272,\n",
       "                     0.09721903, 0.09836819, 0.10434383, 0.10641232, 0.10664215,\n",
       "                     0.11652494, 0.11859343, 0.12158125, 0.16157205, 0.1654792 ,\n",
       "                     0.17283383, 0.18294645, 0.18961158, 0.19145024, 0.19420823,\n",
       "                     0.20524017, 0.23787635, 0.2546541 , 0.26085957, 0.27855665,\n",
       "                     0.27924615, 0.28545162, 0.28935877, 0.2960239 , 0.29993105,\n",
       "                     0.31326132, 0.32199494, 0.32957941, 0.343829  , 0.34681682,\n",
       "                     0.34957481, 0.35623994, 0.40611354, 0.40772236, 0.41139968,\n",
       "                     0.45851528, 0.47230522, 0.47897035, 0.48471616, 0.49827626,\n",
       "                     0.51896116, 0.51896116, 0.52953344, 0.53114227, 0.552057  ,\n",
       "                     0.5584923 , 0.56975408, 0.58239485, 0.59687428, 0.61893818,\n",
       "                     0.63525626, 0.6412319 , 0.67179959, 0.67294875, 0.70029878,\n",
       "                     0.70627442, 0.70926224, 0.71408872, 0.7168467 , 0.71960469,\n",
       "                     0.72902781, 0.73247529, 0.73454378, 0.75545852, 0.75637784,\n",
       "                     0.76649046, 0.77039761, 0.77200644, 0.78234889, 0.80280395,\n",
       "                     0.80694093, 0.80854976, 0.81291657, 0.81498506, 0.82486785,\n",
       "                     0.84670191, 0.84968973, 0.85750402, 0.85796369, 0.86393932,\n",
       "                     0.87267295, 0.87841875, 0.88623305, 0.89059986, 0.89197886,\n",
       "                     0.89864399, 0.90875661, 0.91978855, 0.94116295, 0.95748104,\n",
       "                     0.96023903, 0.96161802, 0.96460584, 0.97058148, 0.97310963,\n",
       "                     0.97540795, 0.97655711, 0.97816594, 0.98368191, 0.98666973,\n",
       "                     0.98735923, 0.98804872, 0.98850839, 0.98919789, 0.99080671,\n",
       "                     1.        ]), tpr=array([0.        , 0.09510682, 0.09970136, 0.10314725, 0.10728233,\n",
       "                     0.11279577, 0.11578222, 0.12221456, 0.12566046, 0.1268091 ,\n",
       "                     0.13439008, 0.13645762, 0.13967379, 0.17872731, 0.18355157,\n",
       "                     0.19320009, 0.20468642, 0.21272686, 0.21525385, 0.21869975,\n",
       "                     0.2294969 , 0.26119917, 0.27590168, 0.28279348, 0.30254997,\n",
       "                     0.30346887, 0.30898231, 0.31265794, 0.31954974, 0.321847  ,\n",
       "                     0.33448197, 0.3425224 , 0.35240064, 0.36940041, 0.37284631,\n",
       "                     0.37537331, 0.38341374, 0.43808867, 0.43992649, 0.44475075,\n",
       "                     0.49069607, 0.50723639, 0.51274983, 0.51987135, 0.5306685 ,\n",
       "                     0.55111417, 0.55226281, 0.5616816 , 0.56374914, 0.58465426,\n",
       "                     0.59039743, 0.60372157, 0.61635654, 0.63381576, 0.65173444,\n",
       "                     0.66850448, 0.67562601, 0.70112566, 0.70365265, 0.73121985,\n",
       "                     0.73994946, 0.74293591, 0.74661153, 0.74776017, 0.75120606,\n",
       "                     0.7601654 , 0.7626924 , 0.76498966, 0.78244889, 0.78290834,\n",
       "                     0.79025959, 0.79370549, 0.79669194, 0.80450264, 0.82816448,\n",
       "                     0.83459683, 0.83712382, 0.84056972, 0.84424535, 0.85733977,\n",
       "                     0.8766368 , 0.88077188, 0.88927177, 0.8904204 , 0.89501493,\n",
       "                     0.90627154, 0.91086607, 0.91798759, 0.92051459, 0.92258213,\n",
       "                     0.92993338, 0.94073053, 0.9499196 , 0.96577073, 0.97656788,\n",
       "                     0.97886515, 0.98070296, 0.98391914, 0.98805422, 0.99012176,\n",
       "                     0.99127039, 0.99264875, 0.99425683, 0.99678383, 0.99770273,\n",
       "                     0.99839191, 0.99931082, 0.99954055, 1.        , 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.19789067e-02, -3.50913198e-02,\n",
       "                     -7.41079722e-02, -8.00427077e-02, -8.45573880e-02, -1.01782694e-01,\n",
       "                     -1.05360516e-01, -1.17783036e-01, -1.24052649e-01, -1.25163143e-01,\n",
       "                     -1.33531393e-01, -1.49745386e-01, -1.50282203e-01, -1.54150680e-01,\n",
       "                     -1.60930367e-01, -1.63629424e-01, -1.67054085e-01, -1.82321557e-01,\n",
       "                     -1.92903666e-01, -2.00670695e-01, -2.06049118e-01, -2.09720531e-01,\n",
       "                     -2.15596346e-01, -2.23143551e-01, -2.46133070e-01, -2.51314428e-01,\n",
       "                     -2.55933374e-01, -2.62364264e-01, -2.69332934e-01, -2.73293335e-01,\n",
       "                     -2.87682072e-01, -2.89952221e-01, -2.94799540e-01, -3.10154928e-01,\n",
       "                     -3.15852949e-01, -3.18022790e-01, -3.18453731e-01, -3.22773392e-01,\n",
       "                     -3.29303747e-01, -3.31357136e-01, -3.36472237e-01, -3.50202429e-01,\n",
       "                     -3.52077235e-01, -3.55550717e-01, -3.56674944e-01, -3.63965377e-01,\n",
       "                     -3.67724780e-01, -3.79489622e-01, -3.85662481e-01, -3.93904286e-01,\n",
       "                     -3.99386062e-01, -4.03312255e-01, -4.05465108e-01, -4.07895243e-01,\n",
       "                     -4.16160397e-01, -4.18150268e-01, -4.19853846e-01, -4.21994410e-01,\n",
       "                     -4.29856561e-01, -4.30782916e-01, -4.39366660e-01, -4.41832752e-01,\n",
       "                     -4.70003629e-01, -4.79573080e-01, -4.92476485e-01, -4.96436886e-01,\n",
       "                     -4.97580397e-01, -5.10825624e-01, -5.23248144e-01, -5.24524468e-01,\n",
       "                     -5.26093096e-01, -5.28067430e-01, -5.30185871e-01, -5.38996501e-01,\n",
       "                     -5.46543706e-01, -5.50046337e-01, -5.59615788e-01, -5.62118918e-01,\n",
       "                     -5.66395475e-01, -5.75364145e-01, -5.81029882e-01, -5.87786665e-01,\n",
       "                     -6.15185639e-01, -6.17435359e-01, -6.19039208e-01, -6.20240410e-01,\n",
       "                     -6.33723760e-01, -6.35988767e-01, -6.40304699e-01, -6.60711905e-01,\n",
       "                     -6.93147181e-01, -7.00367429e-01, -7.24563377e-01, -7.41937345e-01,\n",
       "                     -7.53771802e-01, -7.88457360e-01, -8.10930216e-01, -8.47297860e-01,\n",
       "                     -8.75468737e-01, -9.80829253e-01, -9.98528830e-01, -1.09861229e+00,\n",
       "                     -1.17865500e+00, -1.20397280e+00, -1.25276297e+00, -1.38629436e+00,\n",
       "                     -1.60943791e+00, -2.07944154e+00, -3.45387764e+01]), auc_score=0.525532548925937, privacy_risk=0.518470738736096, accuracy=0.518470738736096, tpr_ind=0.6338157592464967, tnr_ind=0.40312571822569526, test_train_ratio=0.9995405467493682, dataset_size=[4353, 4351]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.07534714, 0.08650125, 0.09947644, 0.10493968,\n",
       "                     0.11199636, 0.11336217, 0.11518325, 0.12087412, 0.12223993,\n",
       "                     0.12406101, 0.12656499, 0.13089005, 0.13293877, 0.13908491,\n",
       "                     0.15069429, 0.16640109, 0.20145686, 0.20441612, 0.21989529,\n",
       "                     0.22763487, 0.22922832, 0.24015479, 0.24470749, 0.25381288,\n",
       "                     0.3205099 , 0.32324152, 0.33166401, 0.34759845, 0.35920783,\n",
       "                     0.36284999, 0.36603688, 0.36763032, 0.37058957, 0.39107671,\n",
       "                     0.39471887, 0.39676758, 0.39813339, 0.41475074, 0.44092875,\n",
       "                     0.46187116, 0.46505805, 0.52242204, 0.5515593 , 0.55816071,\n",
       "                     0.56089233, 0.57933075, 0.59276121, 0.60346005, 0.60755748,\n",
       "                     0.61848395, 0.62667881, 0.62941043, 0.64284088, 0.68609151,\n",
       "                     0.69997724, 0.70157068, 0.70931027, 0.71386296, 0.72069201,\n",
       "                     0.73070794, 0.74618712, 0.75483724, 0.78010471, 0.78078762,\n",
       "                     0.79012065, 0.79353517, 0.80855907, 0.81220123, 0.8675165 ,\n",
       "                     0.87411791, 0.8811746 , 0.89847485, 0.89893012, 0.90803551,\n",
       "                     0.91782381, 0.92010016, 0.92123833, 0.92510813, 0.93876622,\n",
       "                     0.94536763, 0.94855452, 0.9503756 , 0.95287958, 0.9549283 ,\n",
       "                     0.9562941 , 0.96175734, 0.96448896, 0.96813112, 0.97200091,\n",
       "                     0.97928523, 0.98269975, 0.98361029, 0.98429319, 0.98861826,\n",
       "                     0.9895288 , 0.99066697, 1.        ]), tpr=array([0.        , 0.08002784, 0.09162607, 0.10693575, 0.11435862,\n",
       "                     0.12015774, 0.12294131, 0.12363721, 0.12804454, 0.13013222,\n",
       "                     0.13337973, 0.13709116, 0.14219439, 0.14590582, 0.15216887,\n",
       "                     0.16562283, 0.18905126, 0.22523776, 0.22825331, 0.24217119,\n",
       "                     0.2526096 , 0.25446532, 0.26699142, 0.27116678, 0.28114127,\n",
       "                     0.35003479, 0.35374623, 0.36325678, 0.3769427 , 0.39016469,\n",
       "                     0.39480399, 0.40013918, 0.40315472, 0.40570633, 0.42704709,\n",
       "                     0.4295987 , 0.43331014, 0.43609371, 0.45720251, 0.4855022 ,\n",
       "                     0.50846671, 0.51125029, 0.56854558, 0.59498956, 0.60287636,\n",
       "                     0.60681976, 0.62816052, 0.64161447, 0.65228485, 0.65506843,\n",
       "                     0.66898631, 0.67594526, 0.67756901, 0.69125493, 0.72280213,\n",
       "                     0.7348643 , 0.73602412, 0.74019949, 0.74623057, 0.75226166,\n",
       "                     0.76107632, 0.77313848, 0.78172118, 0.80746926, 0.80862909,\n",
       "                     0.8151241 , 0.81790768, 0.83646486, 0.8394804 , 0.88935282,\n",
       "                     0.89584783, 0.9039666 , 0.92159592, 0.92298771, 0.93180237,\n",
       "                     0.94061703, 0.94224078, 0.94432846, 0.94757597, 0.96288564,\n",
       "                     0.9677569 , 0.97077244, 0.97286013, 0.97448388, 0.9756437 ,\n",
       "                     0.97749942, 0.98167479, 0.98445836, 0.98840176, 0.99118534,\n",
       "                     0.99466481, 0.9960566 , 0.99675249, 0.99721642, 0.99930411,\n",
       "                     0.99953607, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.66188940e-02, -5.66953437e-02,\n",
       "                     -6.06246218e-02, -7.14589640e-02, -8.00427077e-02, -8.70113770e-02,\n",
       "                     -9.53101798e-02, -1.05360516e-01, -1.17783036e-01, -1.33531393e-01,\n",
       "                     -1.38150338e-01, -1.54150680e-01, -1.69899037e-01, -1.73663494e-01,\n",
       "                     -1.82321557e-01, -2.02940844e-01, -2.07639365e-01, -2.12332635e-01,\n",
       "                     -2.18689201e-01, -2.23143551e-01, -2.30523659e-01, -2.45122458e-01,\n",
       "                     -2.46133070e-01, -2.62105231e-01, -2.71933715e-01, -2.87682072e-01,\n",
       "                     -2.91910409e-01, -3.00754154e-01, -3.01105093e-01, -3.05381650e-01,\n",
       "                     -3.07484700e-01, -3.10154928e-01, -3.14493330e-01, -3.15081047e-01,\n",
       "                     -3.18453731e-01, -3.36472237e-01, -3.41170757e-01, -3.46148531e-01,\n",
       "                     -3.46522572e-01, -3.48306694e-01, -3.48544818e-01, -3.57551752e-01,\n",
       "                     -3.74693449e-01, -3.79489622e-01, -3.82003621e-01, -4.05465108e-01,\n",
       "                     -4.26742507e-01, -4.41832752e-01, -4.48950220e-01, -4.50585543e-01,\n",
       "                     -4.51985124e-01, -4.55062049e-01, -4.62623522e-01, -4.67596889e-01,\n",
       "                     -4.70003629e-01, -4.76924072e-01, -4.79573080e-01, -4.84245986e-01,\n",
       "                     -4.89548225e-01, -5.03103578e-01, -5.07247802e-01, -5.09648461e-01,\n",
       "                     -5.10825624e-01, -5.28067430e-01, -5.30628251e-01, -5.37954291e-01,\n",
       "                     -5.52068582e-01, -5.58932027e-01, -5.59615788e-01, -5.63094052e-01,\n",
       "                     -5.85818160e-01, -6.06135804e-01, -6.07380359e-01, -6.10909082e-01,\n",
       "                     -6.19039208e-01, -6.35988767e-01, -6.46627165e-01, -6.93147181e-01,\n",
       "                     -7.06219262e-01, -7.30887509e-01, -7.47214402e-01, -7.53771802e-01,\n",
       "                     -7.88457360e-01, -8.10930216e-01, -8.47297860e-01, -8.67500568e-01,\n",
       "                     -9.04456274e-01, -9.80829253e-01, -1.09861229e+00, -1.15267951e+00,\n",
       "                     -1.20397280e+00, -1.25276297e+00, -1.29928298e+00, -1.94591015e+00,\n",
       "                     -2.01490302e+00, -3.45387764e+01]), auc_score=0.5284966018195054, privacy_risk=0.5252511811694265, accuracy=0.5252511811694265, tpr_ind=0.6689863140802598, tnr_ind=0.3815160482585932, test_train_ratio=1.0190211087914638, dataset_size=[4311, 4393]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.10452238, 0.10659898, 0.10982926, 0.11121366,\n",
       "                     0.11536687, 0.11790494, 0.12275035, 0.12690355, 0.12851869,\n",
       "                     0.13313336, 0.13913244, 0.14120904, 0.14397785, 0.1511306 ,\n",
       "                     0.15297647, 0.15712967, 0.16105215, 0.16451315, 0.16797416,\n",
       "                     0.17558837, 0.17674204, 0.18781726, 0.19127826, 0.19381634,\n",
       "                     0.19958468, 0.22127365, 0.23973235, 0.26280572, 0.29856945,\n",
       "                     0.30226119, 0.30802953, 0.31679742, 0.32994924, 0.34010152,\n",
       "                     0.35186894, 0.37655745, 0.39432395, 0.39570835, 0.4063221 ,\n",
       "                     0.41624365, 0.41832026, 0.43562529, 0.44600831, 0.46769728,\n",
       "                     0.4794647 , 0.4829257 , 0.50715275, 0.51661283, 0.61444393,\n",
       "                     0.6162898 , 0.62944162, 0.63567144, 0.64051684, 0.64374712,\n",
       "                     0.65228426, 0.65782187, 0.66359022, 0.67351177, 0.68366405,\n",
       "                     0.6928934 , 0.69520074, 0.70304569, 0.70766036, 0.73857868,\n",
       "                     0.73904015, 0.77734195, 0.78264882, 0.79649285, 0.80526073,\n",
       "                     0.81079834, 0.83133364, 0.8461006 , 0.85025381, 0.86271343,\n",
       "                     0.88140286, 0.88740194, 0.89178588, 0.89478542, 0.90170743,\n",
       "                     0.91624365, 0.91878173, 0.92524227, 0.92662667, 0.92801108,\n",
       "                     0.93424089, 0.93954776, 0.94716198, 0.96562067, 0.96838948,\n",
       "                     0.97069682, 0.97185048, 0.97623443, 0.97692663, 0.9787725 ,\n",
       "                     0.97900323, 0.98038763, 0.98177204, 0.98315644, 0.98477157,\n",
       "                     0.98869405, 0.98961698, 0.99053992, 0.99053992, 0.99146285,\n",
       "                     0.99261652, 0.99353946, 1.        ]), tpr=array([0.        , 0.10480549, 0.10778032, 0.11258581, 0.11418764,\n",
       "                     0.12196796, 0.12517162, 0.13203661, 0.13524027, 0.13729977,\n",
       "                     0.14118993, 0.14645309, 0.14759725, 0.15148741, 0.16132723,\n",
       "                     0.16292906, 0.16704805, 0.17116705, 0.17459954, 0.17643021,\n",
       "                     0.18466819, 0.18695652, 0.19702517, 0.20114416, 0.20617849,\n",
       "                     0.21418764, 0.2402746 , 0.25675057, 0.2771167 , 0.30778032,\n",
       "                     0.31167048, 0.31762014, 0.32379863, 0.3395881 , 0.35171625,\n",
       "                     0.36430206, 0.38695652, 0.40869565, 0.41189931, 0.42196796,\n",
       "                     0.42837529, 0.43135011, 0.45469108, 0.46453089, 0.48146453,\n",
       "                     0.49633867, 0.49908467, 0.5187643 , 0.53066362, 0.62540046,\n",
       "                     0.62791762, 0.63775744, 0.64393593, 0.64691076, 0.65080092,\n",
       "                     0.65858124, 0.66430206, 0.67208238, 0.68352403, 0.69199085,\n",
       "                     0.70091533, 0.70297483, 0.71304348, 0.71624714, 0.74576659,\n",
       "                     0.74691076, 0.78787185, 0.79267735, 0.80778032, 0.81418764,\n",
       "                     0.82059497, 0.84210526, 0.85491991, 0.85652174, 0.87299771,\n",
       "                     0.89313501, 0.89885584, 0.90228833, 0.90572082, 0.91258581,\n",
       "                     0.92562929, 0.92974828, 0.93615561, 0.93775744, 0.93981693,\n",
       "                     0.94622426, 0.94965675, 0.95926773, 0.97963387, 0.98329519,\n",
       "                     0.98466819, 0.98581236, 0.98855835, 0.98878719, 0.99038902,\n",
       "                     0.99084668, 0.99153318, 0.99244851, 0.99359268, 0.99519451,\n",
       "                     0.99679634, 0.99748284, 0.998627  , 0.99908467, 0.9993135 ,\n",
       "                     0.99977117, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.77403280e-02, -4.65200156e-02,\n",
       "                     -4.87901642e-02, -5.71584138e-02, -6.06246218e-02, -6.45385211e-02,\n",
       "                     -8.00427077e-02, -1.05360516e-01, -1.21360857e-01, -1.22602322e-01,\n",
       "                     -1.25163143e-01, -1.27833372e-01, -1.30620182e-01, -1.33531393e-01,\n",
       "                     -1.45182010e-01, -1.54150680e-01, -1.67054085e-01, -1.71850257e-01,\n",
       "                     -1.77681177e-01, -1.82321557e-01, -1.93191229e-01, -2.03598955e-01,\n",
       "                     -2.04794413e-01, -2.23143551e-01, -2.26646182e-01, -2.28633044e-01,\n",
       "                     -2.34507310e-01, -2.61215499e-01, -2.62364264e-01, -2.68263987e-01,\n",
       "                     -2.71933715e-01, -2.76753002e-01, -2.78203328e-01, -2.83126256e-01,\n",
       "                     -2.87682072e-01, -2.98981628e-01, -3.05381650e-01, -3.10154928e-01,\n",
       "                     -3.18453731e-01, -3.25422400e-01, -3.30854244e-01, -3.36472237e-01,\n",
       "                     -3.40325806e-01, -3.47401307e-01, -3.48306694e-01, -3.49673748e-01,\n",
       "                     -3.52821375e-01, -3.55950044e-01, -3.56674944e-01, -3.65934269e-01,\n",
       "                     -3.67724780e-01, -3.79489622e-01, -3.85662481e-01, -3.99386062e-01,\n",
       "                     -4.05465108e-01, -4.14943852e-01, -4.18710335e-01, -4.32133355e-01,\n",
       "                     -4.38254931e-01, -4.41832752e-01, -4.49916871e-01, -4.51985124e-01,\n",
       "                     -4.53393575e-01, -4.70003629e-01, -4.78837948e-01, -4.81838087e-01,\n",
       "                     -4.83174092e-01, -4.96436886e-01, -4.99955952e-01, -5.10825624e-01,\n",
       "                     -5.28525201e-01, -5.30628251e-01, -5.31576568e-01, -5.39943022e-01,\n",
       "                     -5.42324291e-01, -5.50046337e-01, -5.59615788e-01, -5.69094532e-01,\n",
       "                     -5.72069249e-01, -5.75364145e-01, -5.89606502e-01, -6.19039208e-01,\n",
       "                     -6.35988767e-01, -6.41090819e-01, -6.63294217e-01, -6.81170990e-01,\n",
       "                     -6.93147181e-01, -7.43578034e-01, -7.73189888e-01, -7.88457360e-01,\n",
       "                     -8.10930216e-01, -8.47297860e-01, -8.87303195e-01, -9.16290732e-01,\n",
       "                     -9.80829253e-01, -1.01160091e+00, -1.02961942e+00, -1.06784063e+00,\n",
       "                     -1.09861229e+00, -1.29928298e+00, -1.38629436e+00, -1.60943791e+00,\n",
       "                     -1.79175947e+00, -2.01490302e+00, -2.19722458e+00, -3.45387764e+01]), auc_score=0.5101452883326875, privacy_risk=0.5095328935488538, accuracy=0.5095328935488538, tpr_ind=0.45469107551487414, tnr_ind=0.5643747115828334, test_train_ratio=0.9917620137299771, dataset_size=[4370, 4334]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.0542831 , 0.07100321, 0.0758131 , 0.09230417,\n",
       "                     0.09780119, 0.09825928, 0.09986257, 0.10100779, 0.11016949,\n",
       "                     0.13307375, 0.13788365, 0.14383875, 0.15277142, 0.15277142,\n",
       "                     0.15666514, 0.16032982, 0.16491067, 0.19331196, 0.19560238,\n",
       "                     0.20705451, 0.2134677 , 0.22950069, 0.24644984, 0.24759505,\n",
       "                     0.25240495, 0.25332112, 0.26706367, 0.27805772, 0.284929  ,\n",
       "                     0.31905634, 0.32340815, 0.33027943, 0.33623454, 0.38776913,\n",
       "                     0.39051764, 0.40082455, 0.40723775, 0.419377  , 0.46083372,\n",
       "                     0.46358223, 0.47984425, 0.5032066 , 0.52061383, 0.54283097,\n",
       "                     0.56046725, 0.56367384, 0.57466789, 0.59115896, 0.59253321,\n",
       "                     0.6268896 , 0.66491067, 0.67682089, 0.68964727, 0.70316079,\n",
       "                     0.71049015, 0.71232249, 0.71461292, 0.73110399, 0.73453962,\n",
       "                     0.74324324, 0.76339899, 0.76683463, 0.78309666, 0.79111315,\n",
       "                     0.79431974, 0.80668804, 0.80874943, 0.80989464, 0.81859826,\n",
       "                     0.82157581, 0.8327989 , 0.83577645, 0.83737975, 0.8435639 ,\n",
       "                     0.85432891, 0.86898763, 0.87173614, 0.87333944, 0.88845625,\n",
       "                     0.90059551, 0.90196977, 0.93953275, 0.95029776, 0.95098488,\n",
       "                     0.95464956, 0.9580852 , 0.96174989, 0.96678882, 0.96885021,\n",
       "                     0.97182776, 0.97617957, 0.98350893, 0.98648649, 0.98671553,\n",
       "                     0.98694457, 0.98992213, 0.99060925, 0.99175447, 0.99198351,\n",
       "                     0.99381585, 0.99404489, 1.        ]), tpr=array([0.        , 0.06085754, 0.07630244, 0.0802213 , 0.09174735,\n",
       "                     0.09635777, 0.09866298, 0.10073767, 0.10258183, 0.11134163,\n",
       "                     0.13231904, 0.13600738, 0.14361457, 0.15790687, 0.15836791,\n",
       "                     0.15905947, 0.16390041, 0.1692024 , 0.20170586, 0.20378054,\n",
       "                     0.21715076, 0.22498847, 0.23835869, 0.25656985, 0.25749193,\n",
       "                     0.26164131, 0.26417704, 0.27731674, 0.28538497, 0.29137852,\n",
       "                     0.32411249, 0.32941448, 0.33540802, 0.34186261, 0.38473951,\n",
       "                     0.38934993, 0.40133702, 0.41078838, 0.42438912, 0.46173352,\n",
       "                     0.4658829 , 0.48455509, 0.50922084, 0.53342554, 0.55048409,\n",
       "                     0.57307515, 0.57722453, 0.58805901, 0.6088059 , 0.61018903,\n",
       "                     0.64015675, 0.67657907, 0.69017981, 0.70746888, 0.71991701,\n",
       "                     0.73144306, 0.73397879, 0.73789765, 0.7505763 , 0.75426464,\n",
       "                     0.76279391, 0.78261872, 0.78607653, 0.80497925, 0.81189488,\n",
       "                     0.81466113, 0.82710927, 0.83171969, 0.83241125, 0.84439834,\n",
       "                     0.84578147, 0.85315814, 0.8593822 , 0.86099585, 0.86583679,\n",
       "                     0.8725219 , 0.88220378, 0.8856616 , 0.8879668 , 0.90779161,\n",
       "                     0.91862609, 0.91931766, 0.95758414, 0.96496081, 0.96657446,\n",
       "                     0.96841863, 0.972568  , 0.97625634, 0.98294145, 0.98432457,\n",
       "                     0.98639926, 0.9900876 , 0.99239281, 0.9944675 , 0.99515906,\n",
       "                     0.99608114, 0.99769479, 0.99861687, 0.99930844, 0.99953896,\n",
       "                     0.99976948, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.29441557e-02, -5.71584138e-02,\n",
       "                     -7.24955020e-02, -8.16780310e-02, -9.53101798e-02, -1.05360516e-01,\n",
       "                     -1.17783036e-01, -1.23613956e-01, -1.25880246e-01, -1.27833372e-01,\n",
       "                     -1.33531393e-01, -1.40146632e-01, -1.54150680e-01, -1.67054085e-01,\n",
       "                     -1.74353387e-01, -1.96710294e-01, -2.02073712e-01, -2.07639365e-01,\n",
       "                     -2.09720531e-01, -2.23143551e-01, -2.30016431e-01, -2.35722334e-01,\n",
       "                     -2.36388778e-01, -2.38411023e-01, -2.41162057e-01, -2.47408173e-01,\n",
       "                     -2.51314428e-01, -2.75411980e-01, -2.83305698e-01, -2.87682072e-01,\n",
       "                     -2.97251523e-01, -2.99242895e-01, -3.07642815e-01, -3.10154928e-01,\n",
       "                     -3.14115330e-01, -3.15081047e-01, -3.16911711e-01, -3.19308310e-01,\n",
       "                     -3.22773392e-01, -3.50482974e-01, -3.51051686e-01, -3.54057141e-01,\n",
       "                     -3.59374001e-01, -3.63792412e-01, -3.67724780e-01, -3.72675285e-01,\n",
       "                     -3.77134601e-01, -3.82992252e-01, -3.89960922e-01, -4.01236772e-01,\n",
       "                     -4.05465108e-01, -4.12154096e-01, -4.17735201e-01, -4.18710335e-01,\n",
       "                     -4.27444015e-01, -4.28995606e-01, -4.34038481e-01, -4.41832752e-01,\n",
       "                     -4.49525098e-01, -4.57690369e-01, -4.70003629e-01, -4.74622575e-01,\n",
       "                     -4.79573080e-01, -4.81838087e-01, -4.88352768e-01, -4.94696242e-01,\n",
       "                     -5.10825624e-01, -5.21296924e-01, -5.26093096e-01, -5.29259325e-01,\n",
       "                     -5.30628251e-01, -5.38996501e-01, -5.41597282e-01, -5.74285978e-01,\n",
       "                     -5.79818495e-01, -5.81029882e-01, -5.87786665e-01, -5.91097926e-01,\n",
       "                     -6.00773860e-01, -6.06135804e-01, -6.12517446e-01, -6.15760517e-01,\n",
       "                     -6.19039208e-01, -6.28608659e-01, -6.35988767e-01, -6.58055861e-01,\n",
       "                     -6.93147181e-01, -8.10930216e-01, -8.47297860e-01, -8.75468737e-01,\n",
       "                     -9.16290732e-01, -9.38269639e-01, -9.80829253e-01, -1.01160091e+00,\n",
       "                     -1.09861229e+00, -1.17865500e+00, -1.29928298e+00, -1.38629436e+00,\n",
       "                     -1.60943791e+00, -2.19722458e+00, -3.45387764e+01]), auc_score=0.5101794072009981, privacy_risk=0.5129000404863686, accuracy=0.5129000404863686, tpr_ind=0.8443983402489627, tnr_ind=0.18140174072377463, test_train_ratio=1.0064545873674504, dataset_size=[4338, 4366]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.07195572, 0.0777214 , 0.08556273, 0.08717712,\n",
       "                     0.08856089, 0.09178967, 0.10262915, 0.11047048, 0.11531365,\n",
       "                     0.11854244, 0.12730627, 0.13053506, 0.14183579, 0.150369  ,\n",
       "                     0.15821033, 0.16305351, 0.16951107, 0.17965867, 0.18427122,\n",
       "                     0.19672509, 0.21171587, 0.2170203 , 0.22324723, 0.22762915,\n",
       "                     0.22901292, 0.23454797, 0.25207565, 0.30258303, 0.31849631,\n",
       "                     0.35862546, 0.37476937, 0.37892066, 0.38122694, 0.38676199,\n",
       "                     0.39990775, 0.40313653, 0.41166974, 0.56388376, 0.56941882,\n",
       "                     0.58879151, 0.59363469, 0.60539668, 0.61070111, 0.61623616,\n",
       "                     0.62661439, 0.63745387, 0.64368081, 0.64921587, 0.65659594,\n",
       "                     0.6595941 , 0.66097786, 0.68796125, 0.70433579, 0.71425277,\n",
       "                     0.71886531, 0.72947417, 0.73662362, 0.75276753, 0.75322878,\n",
       "                     0.7576107 , 0.79128229, 0.80073801, 0.81088561, 0.82103321,\n",
       "                     0.82702952, 0.8800738 , 0.89160517, 0.8952952 , 0.90821033,\n",
       "                     0.91051661, 0.91305351, 0.91512915, 0.92873616, 0.94972325,\n",
       "                     0.96609779, 0.97001845, 0.97117159, 0.9720941 , 0.97393911,\n",
       "                     0.98016605, 0.98362546, 0.98570111, 0.98662362, 0.98939114,\n",
       "                     0.99100554, 0.99285055, 0.99354244, 0.99400369, 0.99423432,\n",
       "                     1.        ]), tpr=array([0.        , 0.08081502, 0.08745421, 0.09409341, 0.09684066,\n",
       "                     0.09821429, 0.10164835, 0.11149267, 0.11790293, 0.128663  ,\n",
       "                     0.13118132, 0.14377289, 0.14514652, 0.16025641, 0.17147436,\n",
       "                     0.17880037, 0.18360806, 0.18956044, 0.19986264, 0.20512821,\n",
       "                     0.22000916, 0.23557692, 0.2415293 , 0.24725275, 0.25297619,\n",
       "                     0.25503663, 0.26098901, 0.28021978, 0.32532051, 0.34157509,\n",
       "                     0.37797619, 0.39285714, 0.39880952, 0.39972527, 0.40567766,\n",
       "                     0.41895604, 0.42422161, 0.43429487, 0.59065934, 0.59661172,\n",
       "                     0.61698718, 0.62225275, 0.63301282, 0.63965201, 0.64445971,\n",
       "                     0.65590659, 0.66483516, 0.6735348 , 0.67788462, 0.68910256,\n",
       "                     0.69368132, 0.69574176, 0.71863553, 0.73717949, 0.746337  ,\n",
       "                     0.75137363, 0.76350733, 0.7742674 , 0.79029304, 0.79212454,\n",
       "                     0.79601648, 0.82119963, 0.82944139, 0.84180403, 0.8489011 ,\n",
       "                     0.85691392, 0.90521978, 0.91231685, 0.91391941, 0.92490842,\n",
       "                     0.92765568, 0.93063187, 0.93269231, 0.95077839, 0.96840659,\n",
       "                     0.98076923, 0.98466117, 0.98580586, 0.98672161, 0.98832418,\n",
       "                     0.99221612, 0.99404762, 0.99496337, 0.99542125, 0.99771062,\n",
       "                     0.99839744, 0.99931319, 0.99954212, 0.99977106, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.15062052e-02, -3.77403280e-02,\n",
       "                     -4.25596144e-02, -6.06246218e-02, -6.45385211e-02, -7.79615415e-02,\n",
       "                     -9.01510970e-02, -9.30904231e-02, -1.00083459e-01, -1.19801200e-01,\n",
       "                     -1.54150680e-01, -1.63453072e-01, -1.68820870e-01, -1.71850257e-01,\n",
       "                     -1.74353387e-01, -1.75890666e-01, -1.82321557e-01, -1.96710294e-01,\n",
       "                     -1.98850859e-01, -2.11843996e-01, -2.23143551e-01, -2.35314087e-01,\n",
       "                     -2.36388778e-01, -2.38411023e-01, -2.51314428e-01, -2.69663567e-01,\n",
       "                     -2.77477902e-01, -2.85320796e-01, -2.87682072e-01, -2.91520849e-01,\n",
       "                     -2.92387963e-01, -3.00104592e-01, -3.26684230e-01, -3.46276237e-01,\n",
       "                     -3.46870944e-01, -3.56674944e-01, -3.65131037e-01, -3.79489622e-01,\n",
       "                     -3.89464767e-01, -3.90866309e-01, -3.92561703e-01, -3.95312737e-01,\n",
       "                     -4.05465108e-01, -4.08696129e-01, -4.15515444e-01, -4.17299566e-01,\n",
       "                     -4.22856851e-01, -4.32133355e-01, -4.38254931e-01, -4.41832752e-01,\n",
       "                     -4.44685821e-01, -4.50505834e-01, -4.50927482e-01, -4.64305608e-01,\n",
       "                     -4.70003629e-01, -4.77329669e-01, -4.78892577e-01, -4.85507816e-01,\n",
       "                     -4.98991166e-01, -5.03526321e-01, -5.10825624e-01, -5.22386446e-01,\n",
       "                     -5.36304709e-01, -5.36801110e-01, -5.40440544e-01, -5.45016989e-01,\n",
       "                     -5.50046337e-01, -5.83146285e-01, -5.93063722e-01, -6.13104473e-01,\n",
       "                     -6.35988767e-01, -6.43314807e-01, -6.93147181e-01, -7.13766468e-01,\n",
       "                     -7.22134717e-01, -7.88457360e-01, -8.10930216e-01, -8.26678573e-01,\n",
       "                     -8.47297860e-01, -1.01160091e+00, -1.09861229e+00, -1.25276297e+00,\n",
       "                     -1.30833282e+00, -1.31218639e+00, -1.32175584e+00, -1.38629436e+00,\n",
       "                     -1.60943791e+00, -1.94591015e+00, -3.45387764e+01]), auc_score=0.5226645183690847, privacy_risk=0.5194478799183596, accuracy=0.5194478799183596, tpr_ind=0.7921245421245421, tnr_ind=0.2467712177121771, test_train_ratio=0.9926739926739927, dataset_size=[4368, 4336]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.08655367, 0.09288136, 0.0940113 , 0.09627119,\n",
       "                     0.09853107, 0.10553672, 0.1340113 , 0.13446328, 0.1459887 ,\n",
       "                     0.14960452, 0.15254237, 0.15389831, 0.16903955, 0.17220339,\n",
       "                     0.17875706, 0.17966102, 0.18327684, 0.19299435, 0.20474576,\n",
       "                     0.2560452 , 0.28610169, 0.2919774 , 0.29446328, 0.29627119,\n",
       "                     0.30372881, 0.3159322 , 0.31683616, 0.32519774, 0.32858757,\n",
       "                     0.34734463, 0.35367232, 0.35954802, 0.37649718, 0.38757062,\n",
       "                     0.40090395, 0.40632768, 0.42372881, 0.4239548 , 0.44677966,\n",
       "                     0.46214689, 0.47367232, 0.47819209, 0.48112994, 0.48316384,\n",
       "                     0.4899435 , 0.49152542, 0.50508475, 0.51141243, 0.51548023,\n",
       "                     0.5299435 , 0.54508475, 0.58011299, 0.58847458, 0.63435028,\n",
       "                     0.64180791, 0.65423729, 0.66146893, 0.66644068, 0.66937853,\n",
       "                     0.67254237, 0.67841808, 0.68045198, 0.68158192, 0.68632768,\n",
       "                     0.70508475, 0.71073446, 0.72384181, 0.72610169, 0.7299435 ,\n",
       "                     0.73966102, 0.79751412, 0.80067797, 0.80384181, 0.84926554,\n",
       "                     0.85288136, 0.85717514, 0.87638418, 0.87841808, 0.87954802,\n",
       "                     0.89491525, 0.89672316, 0.90033898, 0.90576271, 0.90689266,\n",
       "                     0.91661017, 0.92949153, 0.93107345, 0.9340113 , 0.9459887 ,\n",
       "                     0.94870056, 0.95163842, 0.95344633, 0.95412429, 0.95774011,\n",
       "                     0.95864407, 0.96      , 0.96338983, 0.96836158, 0.97220339,\n",
       "                     0.97378531, 0.97694915, 0.97988701, 0.98101695, 0.98463277,\n",
       "                     0.98621469, 0.98779661, 0.98983051, 0.99073446, 0.99118644,\n",
       "                     1.        ]), tpr=array([0.        , 0.07291423, 0.08086001, 0.08296331, 0.0864688 ,\n",
       "                     0.0883384 , 0.09745268, 0.12339332, 0.12456181, 0.13741528,\n",
       "                     0.14208927, 0.14793176, 0.15026875, 0.16756251, 0.1722365 ,\n",
       "                     0.17924749, 0.18111708, 0.18532367, 0.19443795, 0.20962842,\n",
       "                     0.26571629, 0.29913531, 0.3042767 , 0.30778219, 0.31035289,\n",
       "                     0.31876607, 0.33535873, 0.33746202, 0.3470437 , 0.349147  ,\n",
       "                     0.37438654, 0.38116382, 0.38840851, 0.40570227, 0.41621874,\n",
       "                     0.43117551, 0.43725169, 0.45711615, 0.45805095, 0.48188829,\n",
       "                     0.49754616, 0.51016593, 0.51530731, 0.51857911, 0.520215  ,\n",
       "                     0.52512269, 0.52745969, 0.54007946, 0.54942744, 0.55316663,\n",
       "                     0.5657864 , 0.57980837, 0.61462959, 0.62117317, 0.66417387,\n",
       "                     0.67235335, 0.68637532, 0.69268521, 0.6971255 , 0.70179949,\n",
       "                     0.70600608, 0.71184856, 0.71465296, 0.71582145, 0.72236504,\n",
       "                     0.74386539, 0.74807198, 0.76092545, 0.76209395, 0.76536574,\n",
       "                     0.77424632, 0.83243749, 0.83547558, 0.83944847, 0.88057957,\n",
       "                     0.88408507, 0.88782426, 0.90348212, 0.90558542, 0.90745501,\n",
       "                     0.91773779, 0.91890629, 0.92404767, 0.92965646, 0.93129236,\n",
       "                     0.93760224, 0.94648282, 0.94741762, 0.95115681, 0.96260809,\n",
       "                     0.96728208, 0.97008647, 0.97148867, 0.97265716, 0.97546156,\n",
       "                     0.97733115, 0.97920075, 0.98153774, 0.98480953, 0.98738023,\n",
       "                     0.98924982, 0.99088572, 0.99392381, 0.99462491, 0.99626081,\n",
       "                     0.99766301, 0.9985978 , 0.9992989 , 0.9995326 , 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.17486983e-02, -4.08219945e-02,\n",
       "                     -6.45385211e-02, -8.00427077e-02, -8.70113770e-02, -1.32873281e-01,\n",
       "                     -1.33531393e-01, -1.35801541e-01, -1.45711811e-01, -1.48420005e-01,\n",
       "                     -1.62518929e-01, -1.71850257e-01, -1.82321557e-01, -1.90043603e-01,\n",
       "                     -1.94156014e-01, -2.03598955e-01, -2.07639365e-01, -2.20061885e-01,\n",
       "                     -2.23143551e-01, -2.24541176e-01, -2.29574442e-01, -2.36388778e-01,\n",
       "                     -2.41162057e-01, -2.44453338e-01, -2.48179629e-01, -2.51314428e-01,\n",
       "                     -2.57045103e-01, -2.57829109e-01, -2.73597333e-01, -2.76986783e-01,\n",
       "                     -2.79171383e-01, -2.87682072e-01, -3.20471895e-01, -3.24239668e-01,\n",
       "                     -3.25422400e-01, -3.28033368e-01, -3.36472237e-01, -3.37871817e-01,\n",
       "                     -3.38602163e-01, -3.41749294e-01, -3.42944751e-01, -3.54821375e-01,\n",
       "                     -3.56674944e-01, -3.61013346e-01, -3.62905494e-01, -3.67724780e-01,\n",
       "                     -3.71563556e-01, -3.72675285e-01, -3.74693449e-01, -3.82606970e-01,\n",
       "                     -3.85125424e-01, -3.86233746e-01, -4.05465108e-01, -4.11979789e-01,\n",
       "                     -4.13763911e-01, -4.21994410e-01, -4.25667815e-01, -4.32133355e-01,\n",
       "                     -4.41832752e-01, -4.44685821e-01, -4.59532329e-01, -4.70003629e-01,\n",
       "                     -4.74457980e-01, -4.75423697e-01, -4.76924072e-01, -4.92476485e-01,\n",
       "                     -4.98991166e-01, -5.10825624e-01, -5.21296924e-01, -5.25179937e-01,\n",
       "                     -5.26093096e-01, -5.28844129e-01, -5.29959578e-01, -5.50046337e-01,\n",
       "                     -5.59615788e-01, -5.65992005e-01, -5.75364145e-01, -5.79818495e-01,\n",
       "                     -5.85258219e-01, -5.87786665e-01, -5.97837001e-01, -6.06135804e-01,\n",
       "                     -6.19039208e-01, -6.35988767e-01, -6.38087403e-01, -6.41853886e-01,\n",
       "                     -6.72093771e-01, -6.93147181e-01, -7.05569701e-01, -7.25937003e-01,\n",
       "                     -7.73189888e-01, -7.88457360e-01, -7.96331417e-01, -8.10930216e-01,\n",
       "                     -8.32909123e-01, -8.60201265e-01, -8.87303195e-01, -8.97941593e-01,\n",
       "                     -9.16290732e-01, -9.29535959e-01, -9.61411167e-01, -9.80829253e-01,\n",
       "                     -1.09861229e+00, -1.20397280e+00, -1.25276297e+00, -1.38629436e+00,\n",
       "                     -1.50407740e+00, -1.79175947e+00, -3.45387764e+01]), auc_score=0.5206378014822091, privacy_risk=0.5193903216734466, accuracy=0.5193903216734466, tpr_ind=0.7438653891096051, tnr_ind=0.29491525423728815, test_train_ratio=1.0341201215237206, dataset_size=[4279, 4425]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.06312369, 0.06753307, 0.07217452, 0.08424228,\n",
       "                     0.0891158 , 0.08981202, 0.10211186, 0.10605709, 0.10814574,\n",
       "                     0.11046647, 0.13947552, 0.14342075, 0.1496867 , 0.15525644,\n",
       "                     0.16268276, 0.16639592, 0.17823161, 0.19865398, 0.20051056,\n",
       "                     0.2035275 , 0.20793688, 0.20909724, 0.22418194, 0.2346252 ,\n",
       "                     0.23810629, 0.24367603, 0.25852866, 0.27639824, 0.30239035,\n",
       "                     0.30935252, 0.31004874, 0.34787654, 0.39034579, 0.43745649,\n",
       "                     0.44209793, 0.44441866, 0.45323741, 0.46716175, 0.53283825,\n",
       "                     0.5391042 , 0.54258529, 0.55186818, 0.57971687, 0.58714319,\n",
       "                     0.60245997, 0.61174286, 0.62032954, 0.62241819, 0.64562544,\n",
       "                     0.6484103 , 0.66976097, 0.67904386, 0.68182873, 0.69203992,\n",
       "                     0.69273613, 0.70016245, 0.70155489, 0.72429798, 0.73288466,\n",
       "                     0.73706196, 0.76491065, 0.76815967, 0.77813878, 0.77906707,\n",
       "                     0.80761197, 0.80830819, 0.82385704, 0.8368531 , 0.86354142,\n",
       "                     0.86632629, 0.86748666, 0.8721281 , 0.87375261, 0.8948712 ,\n",
       "                     0.91134834, 0.91598979, 0.9176143 , 0.91831051, 0.92318403,\n",
       "                     0.92736134, 0.92944999, 0.9352518 , 0.94128568, 0.95451381,\n",
       "                     0.95590624, 0.96077976, 0.9621722 , 0.96565328, 0.97006266,\n",
       "                     0.9730796 , 0.97493618, 0.97841727, 0.98630773, 0.98746809,\n",
       "                     0.98839638, 0.98932467, 0.99141332, 0.99257368, 1.        ]), tpr=array([0.        , 0.06825939, 0.07349261, 0.07918089, 0.0923777 ,\n",
       "                     0.0967008 , 0.09761092, 0.11194539, 0.11763367, 0.11990899,\n",
       "                     0.12354949, 0.15472127, 0.15858931, 0.16313993, 0.16723549,\n",
       "                     0.17292378, 0.17929465, 0.19135381, 0.20864619, 0.21228669,\n",
       "                     0.21956769, 0.22434585, 0.22593857, 0.24095563, 0.24778157,\n",
       "                     0.25187713, 0.2589306 , 0.27508532, 0.29419795, 0.32150171,\n",
       "                     0.32627986, 0.32741752, 0.36268487, 0.40705347, 0.45187713,\n",
       "                     0.45733788, 0.45984073, 0.4662116 , 0.48259386, 0.56018203,\n",
       "                     0.56723549, 0.57178612, 0.5847554 , 0.60819113, 0.61569966,\n",
       "                     0.63526735, 0.64505119, 0.65460751, 0.65551763, 0.67690557,\n",
       "                     0.67963595, 0.6967008 , 0.7069397 , 0.71012514, 0.72036405,\n",
       "                     0.72127418, 0.72764505, 0.72969283, 0.75358362, 0.75881684,\n",
       "                     0.76268487, 0.7883959 , 0.79180887, 0.80477816, 0.80659841,\n",
       "                     0.83139932, 0.83435722, 0.85028441, 0.86120592, 0.88555176,\n",
       "                     0.88850967, 0.89078498, 0.89624573, 0.89874858, 0.92104664,\n",
       "                     0.93765643, 0.94061433, 0.94266212, 0.94379977, 0.94653015,\n",
       "                     0.94994312, 0.95176337, 0.95858931, 0.96473265, 0.97565415,\n",
       "                     0.97679181, 0.97952218, 0.98020478, 0.98384528, 0.98657565,\n",
       "                     0.98930603, 0.99067122, 0.99294653, 0.99749716, 0.99817975,\n",
       "                     0.99863481, 0.99886234, 0.99954494, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.76995771e-02, -5.21857532e-02,\n",
       "                     -5.40672213e-02, -7.14589640e-02, -7.41079722e-02, -7.63729788e-02,\n",
       "                     -7.69610411e-02, -9.53101798e-02, -1.17783036e-01, -1.24126067e-01,\n",
       "                     -1.33531393e-01, -1.39761942e-01, -1.43100844e-01, -1.46603474e-01,\n",
       "                     -1.54150680e-01, -1.56842471e-01, -1.57903029e-01, -1.71850257e-01,\n",
       "                     -1.78248231e-01, -1.82321557e-01, -1.89242000e-01, -1.92371893e-01,\n",
       "                     -2.16223108e-01, -2.23143551e-01, -2.29574442e-01, -2.48179629e-01,\n",
       "                     -2.51314428e-01, -2.62364264e-01, -2.75411980e-01, -2.87682072e-01,\n",
       "                     -2.94112963e-01, -2.95344945e-01, -3.06455187e-01, -3.08735482e-01,\n",
       "                     -3.10154928e-01, -3.11436158e-01, -3.18453731e-01, -3.23299708e-01,\n",
       "                     -3.27212911e-01, -3.36472237e-01, -3.38975367e-01, -3.42004754e-01,\n",
       "                     -3.52220594e-01, -3.57837059e-01, -3.65934269e-01, -3.70018359e-01,\n",
       "                     -3.74693449e-01, -3.82475590e-01, -3.85662481e-01, -4.05465108e-01,\n",
       "                     -4.12845215e-01, -4.21213465e-01, -4.27444015e-01, -4.30782916e-01,\n",
       "                     -4.35318071e-01, -4.41832752e-01, -4.49402811e-01, -4.51985124e-01,\n",
       "                     -4.62623522e-01, -4.65569032e-01, -4.70003629e-01, -4.80585739e-01,\n",
       "                     -4.85507816e-01, -4.91686284e-01, -5.10825624e-01, -5.12710638e-01,\n",
       "                     -5.24524468e-01, -5.25668197e-01, -5.26093096e-01, -5.30628251e-01,\n",
       "                     -5.35518236e-01, -5.59615788e-01, -5.60460739e-01, -5.61570823e-01,\n",
       "                     -5.65313809e-01, -5.75364145e-01, -5.87786665e-01, -6.19039208e-01,\n",
       "                     -6.24154309e-01, -6.53926467e-01, -6.69049629e-01, -6.75447603e-01,\n",
       "                     -6.93147181e-01, -7.53771802e-01, -8.26678573e-01, -8.47297860e-01,\n",
       "                     -8.64997437e-01, -9.16290732e-01, -9.75379648e-01, -9.80829253e-01,\n",
       "                     -1.02961942e+00, -1.09861229e+00, -1.29928298e+00, -1.38629436e+00,\n",
       "                     -1.60943791e+00, -1.79175947e+00, -1.94591015e+00, -3.45387764e+01]), auc_score=0.5194735150996235, privacy_risk=0.5171389828575321, accuracy=0.5171389828575321, tpr_ind=0.6546075085324232, tnr_ind=0.379670457182641, test_train_ratio=0.9804323094425483, dataset_size=[4395, 4309]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.06742597, 0.07790433, 0.08246014, 0.08656036,\n",
       "                     0.09316629, 0.09544419, 0.10068337, 0.1022779 , 0.10432802,\n",
       "                     0.10592255, 0.13234624, 0.13712984, 0.13917995, 0.14943052,\n",
       "                     0.15375854, 0.18268793, 0.19635535, 0.20546697, 0.20774487,\n",
       "                     0.25102506, 0.26013667, 0.26173121, 0.28063781, 0.28906606,\n",
       "                     0.32277904, 0.33075171, 0.33211845, 0.40728929, 0.40865604,\n",
       "                     0.4428246 , 0.51548975, 0.51617312, 0.52779043, 0.54829157,\n",
       "                     0.55421412, 0.57835991, 0.59066059, 0.61548975, 0.68177677,\n",
       "                     0.69817768, 0.7022779 , 0.72346241, 0.73599089, 0.74305239,\n",
       "                     0.74829157, 0.7498861 , 0.78610478, 0.79863326, 0.81252847,\n",
       "                     0.81548975, 0.84350797, 0.861959  , 0.86332574, 0.88929385,\n",
       "                     0.89202733, 0.8952164 , 0.90820046, 0.91867882, 0.92164009,\n",
       "                     0.92232346, 0.92437358, 0.93257403, 0.94077449, 0.94555809,\n",
       "                     0.94965831, 0.95649203, 0.95808656, 0.95990888, 0.96287016,\n",
       "                     0.97585421, 0.97722096, 0.97881549, 0.9808656 , 0.98359909,\n",
       "                     0.98382688, 0.98838269, 0.98861048, 0.99066059, 0.99202733,\n",
       "                     0.99225513, 0.99316629, 1.        ]), tpr=array([0.        , 0.08738989, 0.09643023, 0.10199351, 0.10570236,\n",
       "                     0.11219286, 0.11566991, 0.1219286 , 0.12308762, 0.12586926,\n",
       "                     0.1284191 , 0.15855355, 0.16365322, 0.16828929, 0.175707  ,\n",
       "                     0.17941586, 0.20769587, 0.22878999, 0.23898934, 0.24153917,\n",
       "                     0.2837274 , 0.29137691, 0.29346314, 0.31455726, 0.32267038,\n",
       "                     0.35767269, 0.36555401, 0.36879926, 0.44228095, 0.44367177,\n",
       "                     0.47797867, 0.54496987, 0.54566528, 0.55679184, 0.57765415,\n",
       "                     0.58205841, 0.60407974, 0.61682893, 0.63931386, 0.71766342,\n",
       "                     0.7362077 , 0.74130737, 0.76240148, 0.77167362, 0.77816412,\n",
       "                     0.78164117, 0.78326379, 0.8175707 , 0.83217432, 0.84677793,\n",
       "                     0.84932777, 0.87389893, 0.89012517, 0.8919796 , 0.91052388,\n",
       "                     0.91261011, 0.91492814, 0.92814094, 0.9392675 , 0.94204914,\n",
       "                     0.94367177, 0.945758  , 0.9529439 , 0.96267965, 0.9663885 ,\n",
       "                     0.96870654, 0.97450162, 0.97635605, 0.97890589, 0.98122392,\n",
       "                     0.98933704, 0.99049606, 0.99165508, 0.99281409, 0.9935095 ,\n",
       "                     0.99397311, 0.99745016, 0.99837738, 0.99907279, 0.99953639,\n",
       "                     0.9997682 , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.57483570e-02, -4.54623741e-02,\n",
       "                     -4.87901642e-02, -5.48082365e-02, -6.45385211e-02, -7.14589640e-02,\n",
       "                     -9.53101798e-02, -1.13328685e-01, -1.17783036e-01, -1.21645109e-01,\n",
       "                     -1.27833372e-01, -1.39761942e-01, -1.54150680e-01, -1.71850257e-01,\n",
       "                     -1.82321557e-01, -2.07639365e-01, -2.23143551e-01, -2.41162057e-01,\n",
       "                     -2.59825118e-01, -2.82232468e-01, -2.87682072e-01, -3.01324849e-01,\n",
       "                     -3.07025035e-01, -3.10596332e-01, -3.11779624e-01, -3.18453731e-01,\n",
       "                     -3.23317136e-01, -3.36472237e-01, -3.40325806e-01, -3.52166526e-01,\n",
       "                     -3.56674944e-01, -3.57609087e-01, -3.75387653e-01, -3.87765531e-01,\n",
       "                     -3.94882999e-01, -4.05465108e-01, -4.08895643e-01, -4.19177370e-01,\n",
       "                     -4.38008656e-01, -4.60815203e-01, -4.65683968e-01, -4.70003629e-01,\n",
       "                     -4.74457980e-01, -4.90622916e-01, -4.98991166e-01, -5.04045937e-01,\n",
       "                     -5.10825624e-01, -5.20304368e-01, -5.46543706e-01, -5.49634899e-01,\n",
       "                     -5.51735527e-01, -5.59615788e-01, -5.66733256e-01, -5.75364145e-01,\n",
       "                     -5.87786665e-01, -5.91677720e-01, -6.03916047e-01, -6.06135804e-01,\n",
       "                     -6.19039208e-01, -6.35988767e-01, -6.60357358e-01, -6.93147181e-01,\n",
       "                     -7.23918839e-01, -7.41937345e-01, -7.95801335e-01, -8.10930216e-01,\n",
       "                     -8.60201265e-01, -8.75468737e-01, -8.87303195e-01, -8.93817876e-01,\n",
       "                     -9.16290732e-01, -9.55511445e-01, -9.80829253e-01, -1.09861229e+00,\n",
       "                     -1.14209740e+00, -1.25276297e+00, -1.29928298e+00, -1.38629436e+00,\n",
       "                     -1.94591015e+00, -2.07944154e+00, -3.45387764e+01]), auc_score=0.5280198337140402, privacy_risk=0.5195147335105389, accuracy=0.5195147335105389, tpr_ind=0.741307371349096, tnr_ind=0.29772209567198177, test_train_ratio=1.0176170607324988, dataset_size=[4314, 4390]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.063129  , 0.08668801, 0.09240622, 0.09309241,\n",
       "                     0.0946935 , 0.10887466, 0.11139067, 0.1189387 , 0.12076853,\n",
       "                     0.12511436, 0.12831656, 0.13929552, 0.14638609, 0.14775846,\n",
       "                     0.15805124, 0.15988106, 0.16193962, 0.16742909, 0.16788655,\n",
       "                     0.17223239, 0.18549863, 0.19670631, 0.20059469, 0.21294602,\n",
       "                     0.22118024, 0.23238792, 0.23970723, 0.24496798, 0.25274474,\n",
       "                     0.26486734, 0.27310156, 0.27698994, 0.30718207, 0.31358646,\n",
       "                     0.32136322, 0.36710887, 0.37602928, 0.40187557, 0.40576395,\n",
       "                     0.41948765, 0.43412626, 0.46660567, 0.46752059, 0.47369625,\n",
       "                     0.49290942, 0.49954254, 0.50709058, 0.56541629, 0.56999085,\n",
       "                     0.58668801, 0.58851784, 0.5905764 , 0.59377859, 0.605215  ,\n",
       "                     0.61710887, 0.62442818, 0.63677951, 0.63929552, 0.64226898,\n",
       "                     0.72804209, 0.72987191, 0.73559012, 0.73650503, 0.74405306,\n",
       "                     0.76189387, 0.79437328, 0.79574565, 0.84194876, 0.84537969,\n",
       "                     0.86276304, 0.86527905, 0.88700823, 0.8915828 , 0.89455627,\n",
       "                     0.90553522, 0.90599268, 0.90988106, 0.91971638, 0.93046661,\n",
       "                     0.94556267, 0.95814273, 0.9595151 , 0.96431839, 0.96614822,\n",
       "                     0.97072278, 0.97140897, 0.97209515, 0.97301006, 0.97689844,\n",
       "                     0.9805581 , 0.98764867, 0.99085087, 0.99153705, 0.99313815,\n",
       "                     0.99359561, 0.99496798, 1.        ]), tpr=array([0.        , 0.07825485, 0.10410896, 0.1101108 , 0.111265  ,\n",
       "                     0.11288089, 0.12811634, 0.13134811, 0.13919668, 0.14289012,\n",
       "                     0.14727608, 0.15120037, 0.16435826, 0.17336103, 0.17682364,\n",
       "                     0.18513389, 0.18674977, 0.19067405, 0.19575254, 0.19736842,\n",
       "                     0.20221607, 0.21999077, 0.23707295, 0.24099723, 0.25300092,\n",
       "                     0.26477378, 0.27700831, 0.28301016, 0.28739612, 0.29385965,\n",
       "                     0.30355494, 0.31301939, 0.3176362 , 0.34972299, 0.355494  ,\n",
       "                     0.36380425, 0.40443213, 0.41204986, 0.44275162, 0.44713758,\n",
       "                     0.46237304, 0.47530009, 0.50554017, 0.50715605, 0.51408126,\n",
       "                     0.53370268, 0.53947368, 0.54385965, 0.60041551, 0.60503232,\n",
       "                     0.62626962, 0.62973223, 0.63365651, 0.63688827, 0.64727608,\n",
       "                     0.65789474, 0.66412742, 0.67520776, 0.677747  , 0.6812096 ,\n",
       "                     0.76477378, 0.76638966, 0.77031394, 0.77239151, 0.77700831,\n",
       "                     0.79385965, 0.82179132, 0.82502308, 0.86588181, 0.86865189,\n",
       "                     0.88758079, 0.88942752, 0.91020314, 0.91574331, 0.91920591,\n",
       "                     0.92867036, 0.9300554 , 0.93305633, 0.94067405, 0.95036934,\n",
       "                     0.96375808, 0.97437673, 0.97553093, 0.97783934, 0.97945522,\n",
       "                     0.98407202, 0.9845337 , 0.98707295, 0.98776547, 0.99053555,\n",
       "                     0.99261311, 0.99630656, 0.99861496, 0.99907664, 0.99930748,\n",
       "                     0.99976916, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -8.88894742e-03, -3.77403280e-02,\n",
       "                     -5.71584138e-02, -6.45385211e-02, -6.73036819e-02, -6.89928715e-02,\n",
       "                     -9.18075493e-02, -9.53101798e-02, -1.00083459e-01, -1.11225635e-01,\n",
       "                     -1.15831816e-01, -1.17783036e-01, -1.25163143e-01, -1.30053128e-01,\n",
       "                     -1.33531393e-01, -1.62518929e-01, -1.67054085e-01, -1.82321557e-01,\n",
       "                     -1.92903666e-01, -1.99489360e-01, -2.06794413e-01, -2.11309094e-01,\n",
       "                     -2.23143551e-01, -2.32931558e-01, -2.34400706e-01, -2.38411023e-01,\n",
       "                     -2.46133070e-01, -2.51314428e-01, -2.54892250e-01, -2.56719847e-01,\n",
       "                     -2.60726262e-01, -2.64023098e-01, -2.66628663e-01, -2.87682072e-01,\n",
       "                     -2.92892356e-01, -3.10154928e-01, -3.22773392e-01, -3.36472237e-01,\n",
       "                     -3.42944751e-01, -3.44096162e-01, -3.50549351e-01, -3.56674944e-01,\n",
       "                     -3.60002734e-01, -3.61369788e-01, -3.66462950e-01, -3.69097464e-01,\n",
       "                     -3.69495632e-01, -3.71563556e-01, -3.76051223e-01, -3.82992252e-01,\n",
       "                     -3.85662481e-01, -3.92042088e-01, -4.05465108e-01, -4.14767501e-01,\n",
       "                     -4.17735201e-01, -4.32864082e-01, -4.35318071e-01, -4.37213806e-01,\n",
       "                     -4.48715092e-01, -4.51985124e-01, -4.62623522e-01, -4.64305608e-01,\n",
       "                     -4.70003629e-01, -5.10825624e-01, -5.32085623e-01, -5.38996501e-01,\n",
       "                     -5.39453018e-01, -5.48565952e-01, -5.56125383e-01, -5.59615788e-01,\n",
       "                     -5.69094532e-01, -5.85258219e-01, -5.87786665e-01, -5.90493026e-01,\n",
       "                     -6.06135804e-01, -6.53926467e-01, -6.93147181e-01, -7.04981638e-01,\n",
       "                     -7.75838896e-01, -7.77230298e-01, -7.88457360e-01, -8.10930216e-01,\n",
       "                     -8.26678573e-01, -8.47297860e-01, -9.16290732e-01, -9.34309237e-01,\n",
       "                     -9.80829253e-01, -1.01160091e+00, -1.02165125e+00, -1.09861229e+00,\n",
       "                     -1.16315081e+00, -1.25276297e+00, -1.38629436e+00, -1.79175947e+00,\n",
       "                     -2.30258509e+00, -3.45387764e+01]), auc_score=0.5310837073663598, privacy_risk=0.5223101935510033, accuracy=0.5223101935510033, tpr_ind=0.2770083102493075, tnr_ind=0.7676120768526989, test_train_ratio=1.0092336103416435, dataset_size=[4332, 4372]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.07348169, 0.07579972, 0.07742235, 0.08344924,\n",
       "                     0.09179416, 0.09388039, 0.09828465, 0.10060269, 0.10477515,\n",
       "                     0.10848401, 0.11080204, 0.12100139, 0.1216968 , 0.13815484,\n",
       "                     0.13861845, 0.14232731, 0.148586  , 0.16156699, 0.16388503,\n",
       "                     0.16805749, 0.17431618, 0.18103848, 0.18173389, 0.18590635,\n",
       "                     0.19146963, 0.19726472, 0.25428836, 0.2566064 , 0.26425591,\n",
       "                     0.2702828 , 0.30621233, 0.31803431, 0.32892907, 0.33495596,\n",
       "                     0.35071859, 0.35558646, 0.3583681 , 0.36346778, 0.3713491 ,\n",
       "                     0.38942976, 0.5064905 , 0.50904033, 0.52178952, 0.53314789,\n",
       "                     0.5340751 , 0.53778396, 0.53824757, 0.5472879 , 0.55980529,\n",
       "                     0.56281873, 0.57533611, 0.57881317, 0.58275382, 0.59411219,\n",
       "                     0.60013908, 0.61126565, 0.64904961, 0.65577191, 0.67385257,\n",
       "                     0.69448308, 0.69819193, 0.70190079, 0.71210014, 0.74802967,\n",
       "                     0.75753361, 0.77329624, 0.77862772, 0.78789986, 0.80273528,\n",
       "                     0.81548447, 0.81687529, 0.8245248 , 0.82869726, 0.83912842,\n",
       "                     0.84075104, 0.86045433, 0.86230876, 0.87505795, 0.88363468,\n",
       "                     0.8984701 , 0.9188688 , 0.92211405, 0.92744553, 0.94367177,\n",
       "                     0.94506259, 0.94738062, 0.95804358, 0.96012981, 0.96267965,\n",
       "                     0.96499768, 0.96685211, 0.96754752, 0.97148818, 0.97218359,\n",
       "                     0.97589244, 0.97844228, 0.98099212, 0.98284655, 0.98539638,\n",
       "                     0.98748261, 0.98933704, 0.98956885, 0.99072786, 1.        ]), tpr=array([0.        , 0.07949886, 0.08200456, 0.08701595, 0.09498861,\n",
       "                     0.10250569, 0.10523918, 0.11047836, 0.11207289, 0.11548975,\n",
       "                     0.12027335, 0.12186788, 0.13690205, 0.13986333, 0.1571754 ,\n",
       "                     0.15763098, 0.16127563, 0.16446469, 0.18109339, 0.18359909,\n",
       "                     0.1881549 , 0.19589977, 0.20296128, 0.20364465, 0.20865604,\n",
       "                     0.21640091, 0.22232346, 0.28268793, 0.28610478, 0.29567198,\n",
       "                     0.30432802, 0.33917995, 0.34829157, 0.35876993, 0.36628702,\n",
       "                     0.38473804, 0.38997722, 0.39271071, 0.39840547, 0.40432802,\n",
       "                     0.42232346, 0.54464692, 0.54783599, 0.55968109, 0.57107062,\n",
       "                     0.57198178, 0.57471526, 0.57767654, 0.58929385, 0.6047836 ,\n",
       "                     0.60774487, 0.61731207, 0.62095672, 0.62437358, 0.63234624,\n",
       "                     0.6405467 , 0.65056948, 0.68747153, 0.6929385 , 0.7118451 ,\n",
       "                     0.73143508, 0.73462415, 0.738041  , 0.74692483, 0.78496583,\n",
       "                     0.79248292, 0.81070615, 0.81594533, 0.82346241, 0.83621868,\n",
       "                     0.84487472, 0.84646925, 0.85353075, 0.85808656, 0.86514806,\n",
       "                     0.86697039, 0.88656036, 0.88929385, 0.90410023, 0.9143508 ,\n",
       "                     0.92437358, 0.94145786, 0.94555809, 0.94874715, 0.96264237,\n",
       "                     0.96492027, 0.9690205 , 0.97835991, 0.98018223, 0.98246014,\n",
       "                     0.98451025, 0.98587699, 0.98633257, 0.99066059, 0.99157175,\n",
       "                     0.99362187, 0.99453303, 0.99658314, 0.99749431, 0.99817768,\n",
       "                     0.99908884, 0.99931663, 0.99954442, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.92207132e-02, -4.44517626e-02,\n",
       "                     -5.31098253e-02, -5.88405000e-02, -6.06246218e-02, -6.89928715e-02,\n",
       "                     -7.41079722e-02, -7.59859070e-02, -8.33816089e-02, -9.53101798e-02,\n",
       "                     -1.05360516e-01, -1.09199292e-01, -1.11225635e-01, -1.17783036e-01,\n",
       "                     -1.25163143e-01, -1.33531393e-01, -1.63887855e-01, -1.67054085e-01,\n",
       "                     -1.82321557e-01, -1.92903666e-01, -1.94156014e-01, -2.00670695e-01,\n",
       "                     -2.09720531e-01, -2.11309094e-01, -2.38411023e-01, -2.40353104e-01,\n",
       "                     -2.46860078e-01, -2.61364764e-01, -2.64692554e-01, -2.64784108e-01,\n",
       "                     -2.68263987e-01, -2.74436846e-01, -2.87682072e-01, -2.96898728e-01,\n",
       "                     -2.98492989e-01, -3.13657559e-01, -3.36472237e-01, -3.39867826e-01,\n",
       "                     -3.42406972e-01, -3.49948461e-01, -3.56674944e-01, -3.67146244e-01,\n",
       "                     -3.68907512e-01, -3.74693449e-01, -3.77294231e-01, -3.79489622e-01,\n",
       "                     -3.80055393e-01, -3.85662481e-01, -3.87765531e-01, -3.89464767e-01,\n",
       "                     -3.93042588e-01, -3.95895657e-01, -3.97682968e-01, -4.00477567e-01,\n",
       "                     -4.05465108e-01, -4.13370288e-01, -4.19258430e-01, -4.30102412e-01,\n",
       "                     -4.36001832e-01, -4.41832752e-01, -4.44685821e-01, -4.63572739e-01,\n",
       "                     -4.65502496e-01, -4.71714494e-01, -4.77785770e-01, -4.79573080e-01,\n",
       "                     -4.85507816e-01, -4.88352768e-01, -4.89548225e-01, -4.96436886e-01,\n",
       "                     -4.98991166e-01, -5.10825624e-01, -5.20304368e-01, -5.26093096e-01,\n",
       "                     -5.36085291e-01, -5.59615788e-01, -5.61811178e-01, -5.69352963e-01,\n",
       "                     -5.85258219e-01, -5.99118231e-01, -6.06135804e-01, -6.19039208e-01,\n",
       "                     -6.34306681e-01, -6.41853886e-01, -6.64976304e-01, -6.93147181e-01,\n",
       "                     -7.20546155e-01, -7.88457360e-01, -8.36248024e-01, -8.47297860e-01,\n",
       "                     -8.75468737e-01, -8.84202417e-01, -9.16290732e-01, -9.80829253e-01,\n",
       "                     -1.01160091e+00, -1.09861229e+00, -1.17865500e+00, -1.29928298e+00,\n",
       "                     -1.38629436e+00, -1.60943791e+00, -1.79175947e+00, -1.94591015e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5283004795532478, privacy_risk=0.5224891569853093, accuracy=0.5224891569853093, tpr_ind=0.6047835990888383, tnr_ind=0.44019471488178025, test_train_ratio=0.9826879271070615, dataset_size=[4390, 4314]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.06112132, 0.07169118, 0.08111213, 0.0870864 ,\n",
       "                     0.09030331, 0.09719669, 0.09880515, 0.10799632, 0.11098346,\n",
       "                     0.12270221, 0.12408088, 0.12568934, 0.13901654, 0.14338235,\n",
       "                     0.15647978, 0.16176471, 0.16590074, 0.17715993, 0.19232537,\n",
       "                     0.1941636 , 0.20036765, 0.21852022, 0.22633272, 0.22931985,\n",
       "                     0.23414522, 0.2902114 , 0.296875  , 0.3136489 , 0.40050551,\n",
       "                     0.40326287, 0.41222426, 0.42830882, 0.4308364 , 0.45749081,\n",
       "                     0.47334559, 0.48368566, 0.48621324, 0.49793199, 0.52320772,\n",
       "                     0.54595588, 0.56341912, 0.56801471, 0.61649816, 0.61925551,\n",
       "                     0.63763787, 0.64636949, 0.68520221, 0.68956801, 0.69462316,\n",
       "                     0.70335478, 0.71392463, 0.73184743, 0.74448529, 0.7578125 ,\n",
       "                     0.77136949, 0.77757353, 0.79365809, 0.82743566, 0.82835478,\n",
       "                     0.83065257, 0.8347886 , 0.83984375, 0.89751838, 0.90349265,\n",
       "                     0.9207261 , 0.921875  , 0.92417279, 0.9285386 , 0.9386489 ,\n",
       "                     0.94347426, 0.94508272, 0.95266544, 0.95703125, 0.95886949,\n",
       "                     0.96346507, 0.96668199, 0.96806066, 0.96875   , 0.97127757,\n",
       "                     0.97334559, 0.97633272, 0.98046875, 0.98575368, 0.98759191,\n",
       "                     0.98805147, 0.98943015, 0.98943015, 0.99034926, 1.        ]), tpr=array([0.        , 0.06755515, 0.08272059, 0.09076287, 0.09834559,\n",
       "                     0.10363051, 0.11121324, 0.11351103, 0.12270221, 0.12431066,\n",
       "                     0.13809743, 0.13970588, 0.14200368, 0.15693934, 0.16130515,\n",
       "                     0.17555147, 0.18106618, 0.18566176, 0.19439338, 0.20932904,\n",
       "                     0.21070772, 0.21691176, 0.23598346, 0.24517463, 0.25091912,\n",
       "                     0.25827206, 0.31502757, 0.32284007, 0.34053309, 0.41911765,\n",
       "                     0.4207261 , 0.43152574, 0.44485294, 0.44784007, 0.47702206,\n",
       "                     0.49264706, 0.50298713, 0.50459559, 0.51792279, 0.54342831,\n",
       "                     0.5625    , 0.57996324, 0.58501838, 0.63648897, 0.63993566,\n",
       "                     0.65693934, 0.66613051, 0.70565257, 0.70840993, 0.71162684,\n",
       "                     0.71829044, 0.72725184, 0.74609375, 0.75965074, 0.77320772,\n",
       "                     0.78676471, 0.79067096, 0.80215993, 0.83938419, 0.84168199,\n",
       "                     0.8448989 , 0.84949449, 0.85707721, 0.91544118, 0.92095588,\n",
       "                     0.93681066, 0.9386489 , 0.94347426, 0.94669118, 0.95840993,\n",
       "                     0.96185662, 0.96461397, 0.97173713, 0.97587316, 0.97840074,\n",
       "                     0.98138787, 0.98345588, 0.98529412, 0.98621324, 0.98828125,\n",
       "                     0.98943015, 0.9921875 , 0.99379596, 0.99747243, 0.99839154,\n",
       "                     0.9988511 , 0.99908088, 0.99954044, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.13852162e-02, -5.97192347e-02,\n",
       "                     -6.89928715e-02, -8.33816089e-02, -8.70113770e-02, -9.53101798e-02,\n",
       "                     -9.68498260e-02, -1.25163143e-01, -1.41830195e-01, -1.43100844e-01,\n",
       "                     -1.48420005e-01, -1.56346070e-01, -1.58224005e-01, -1.58748389e-01,\n",
       "                     -1.89242000e-01, -1.92371893e-01, -1.94156014e-01, -2.20061885e-01,\n",
       "                     -2.23143551e-01, -2.30523659e-01, -2.35119742e-01, -2.46524000e-01,\n",
       "                     -2.46860078e-01, -2.53448901e-01, -2.74436846e-01, -2.80301965e-01,\n",
       "                     -2.81167391e-01, -2.87682072e-01, -3.05381650e-01, -3.07025035e-01,\n",
       "                     -3.21583624e-01, -3.25422400e-01, -3.26296909e-01, -3.34369186e-01,\n",
       "                     -3.36472237e-01, -3.56674944e-01, -3.64897923e-01, -3.65643614e-01,\n",
       "                     -3.69471505e-01, -3.69747026e-01, -3.74693449e-01, -3.78314119e-01,\n",
       "                     -3.82992252e-01, -4.05465108e-01, -4.38254931e-01, -4.43492504e-01,\n",
       "                     -4.46287103e-01, -4.51985124e-01, -4.53474327e-01, -4.70003629e-01,\n",
       "                     -4.76082675e-01, -4.83936724e-01, -4.97173535e-01, -5.07430035e-01,\n",
       "                     -5.10825624e-01, -5.18793793e-01, -5.18901038e-01, -5.26093096e-01,\n",
       "                     -5.38996501e-01, -5.59615788e-01, -5.63935449e-01, -5.67906335e-01,\n",
       "                     -5.77315365e-01, -5.78077851e-01, -5.97837001e-01, -6.06135804e-01,\n",
       "                     -6.09765572e-01, -6.22051259e-01, -6.24154309e-01, -6.66478933e-01,\n",
       "                     -6.93147181e-01, -7.37598943e-01, -7.50305594e-01, -7.62140052e-01,\n",
       "                     -7.73189888e-01, -8.10930216e-01, -9.16290732e-01, -9.38269639e-01,\n",
       "                     -1.02961942e+00, -1.04731899e+00, -1.04982212e+00, -1.09861229e+00,\n",
       "                     -1.17865500e+00, -1.25276297e+00, -1.38629436e+00, -1.50407740e+00,\n",
       "                     -1.60943791e+00, -3.45387764e+01]), auc_score=0.5170434865984538, privacy_risk=0.5134420955882353, accuracy=0.5134420955882353, tpr_ind=0.3405330882352941, tnr_ind=0.6863511029411765, test_train_ratio=1.0, dataset_size=[4352, 4352]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.06929784, 0.08031207, 0.0826067 , 0.08375402,\n",
       "                     0.08581918, 0.08926113, 0.08972006, 0.09362093, 0.10027536,\n",
       "                     0.10348784, 0.11817347, 0.12000918, 0.12712253, 0.13033502,\n",
       "                     0.13767783, 0.17163837, 0.17439192, 0.17622763, 0.18425883,\n",
       "                     0.20536944, 0.22441487, 0.2267095 , 0.23129876, 0.23336393,\n",
       "                     0.2751262 , 0.28705828, 0.29095916, 0.30908674, 0.32996788,\n",
       "                     0.3435062 , 0.34511244, 0.34947223, 0.35061955, 0.35360257,\n",
       "                     0.37241854, 0.42244149, 0.46558054, 0.47820101, 0.48829738,\n",
       "                     0.49082148, 0.49426342, 0.50504819, 0.50688389, 0.51078476,\n",
       "                     0.51904543, 0.52134006, 0.52822396, 0.52960073, 0.546581  ,\n",
       "                     0.55621845, 0.57618173, 0.5764112 , 0.5913263 , 0.59201469,\n",
       "                     0.60417623, 0.60647086, 0.64387334, 0.65603488, 0.67760441,\n",
       "                     0.68081689, 0.68999541, 0.69206058, 0.7459844 , 0.76984855,\n",
       "                     0.77627352, 0.77994493, 0.79394218, 0.79738412, 0.82446076,\n",
       "                     0.83432767, 0.83822855, 0.84304727, 0.84694814, 0.85796237,\n",
       "                     0.85910968, 0.8708123 , 0.87884351, 0.90270766, 0.90798531,\n",
       "                     0.91326296, 0.92106471, 0.92221202, 0.92381827, 0.93253786,\n",
       "                     0.93988068, 0.95273061, 0.95800826, 0.96305645, 0.96695732,\n",
       "                     0.9745296 , 0.98187242, 0.9832492 , 0.98393759, 0.98737953,\n",
       "                     0.98875631, 0.98921524, 0.9912804 , 0.99173933, 0.99173933,\n",
       "                     0.99196879, 1.        ]), tpr=array([0.        , 0.07938334, 0.09203866, 0.09479982, 0.0959503 ,\n",
       "                     0.09894156, 0.10400368, 0.10561436, 0.1097561 , 0.12057064,\n",
       "                     0.12448228, 0.13759779, 0.13920847, 0.14703175, 0.15117349,\n",
       "                     0.16060746, 0.18913944, 0.19420156, 0.1985734 , 0.20800736,\n",
       "                     0.22664519, 0.24482283, 0.24712379, 0.25379659, 0.25770824,\n",
       "                     0.3016567 , 0.31661298, 0.32052462, 0.33755177, 0.36033134,\n",
       "                     0.37735849, 0.38057984, 0.38403129, 0.38587207, 0.38886332,\n",
       "                     0.41187299, 0.46226415, 0.49930971, 0.51288541, 0.52369995,\n",
       "                     0.52577082, 0.52853198, 0.54210769, 0.54371836, 0.54647952,\n",
       "                     0.55292223, 0.55729406, 0.56212609, 0.56350667, 0.58168431,\n",
       "                     0.59134837, 0.60837552, 0.609526  , 0.62034054, 0.62241141,\n",
       "                     0.63276576, 0.63391624, 0.67211229, 0.68131615, 0.70386562,\n",
       "                     0.70777727, 0.71491026, 0.71606075, 0.7604694 , 0.78854119,\n",
       "                     0.7947538 , 0.79843534, 0.81178095, 0.81684307, 0.84997699,\n",
       "                     0.85964105, 0.8630925 , 0.86677405, 0.8697653 , 0.87942936,\n",
       "                     0.88196042, 0.88932352, 0.89760699, 0.92406811, 0.92867004,\n",
       "                     0.93281178, 0.94247584, 0.94454671, 0.94707777, 0.95444087,\n",
       "                     0.96410492, 0.97399908, 0.98021169, 0.98366314, 0.9859641 ,\n",
       "                     0.99033594, 0.99355729, 0.99470778, 0.99562816, 0.99654855,\n",
       "                     0.99723884, 0.99838932, 0.99930971, 0.99930971, 0.9997699 ,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.65200156e-02, -5.55698512e-02,\n",
       "                     -7.41079722e-02, -8.33816089e-02, -8.70113770e-02, -1.05360516e-01,\n",
       "                     -1.17783036e-01, -1.19545151e-01, -1.27833372e-01, -1.31336002e-01,\n",
       "                     -1.33531393e-01, -1.37201122e-01, -1.41078598e-01, -1.54150680e-01,\n",
       "                     -1.70151021e-01, -1.82321557e-01, -1.91055237e-01, -1.98450939e-01,\n",
       "                     -2.01941344e-01, -2.05263126e-01, -2.07639365e-01, -2.16223108e-01,\n",
       "                     -2.23143551e-01, -2.28412664e-01, -2.52495763e-01, -2.57829109e-01,\n",
       "                     -2.60283098e-01, -2.64692554e-01, -2.87682072e-01, -3.05381650e-01,\n",
       "                     -3.13657559e-01, -3.18453731e-01, -3.25422400e-01, -3.41170757e-01,\n",
       "                     -3.50721182e-01, -3.52317639e-01, -3.53279355e-01, -3.54545018e-01,\n",
       "                     -3.56674944e-01, -3.62905494e-01, -3.65113813e-01, -3.67724780e-01,\n",
       "                     -3.79489622e-01, -3.81367557e-01, -3.87765531e-01, -3.89464767e-01,\n",
       "                     -4.05465108e-01, -4.09675641e-01, -4.21213465e-01, -4.30782916e-01,\n",
       "                     -4.35318071e-01, -4.37213806e-01, -4.41832752e-01, -4.50927482e-01,\n",
       "                     -4.51985124e-01, -4.52532619e-01, -4.54255272e-01, -4.58457638e-01,\n",
       "                     -4.62623522e-01, -4.65757338e-01, -4.70003629e-01, -4.75978892e-01,\n",
       "                     -4.78604745e-01, -4.83426650e-01, -4.85507816e-01, -4.91407538e-01,\n",
       "                     -4.92476485e-01, -5.00035916e-01, -5.10825624e-01, -5.19875459e-01,\n",
       "                     -5.23248144e-01, -5.26093096e-01, -5.28067430e-01, -5.42324291e-01,\n",
       "                     -5.59615788e-01, -5.67520967e-01, -5.71257363e-01, -5.87786665e-01,\n",
       "                     -6.06135804e-01, -6.11801541e-01, -6.35988767e-01, -6.46627165e-01,\n",
       "                     -6.77398824e-01, -6.81170990e-01, -6.93147181e-01, -7.11496319e-01,\n",
       "                     -7.43578034e-01, -7.88457360e-01, -8.47297860e-01, -9.16290732e-01,\n",
       "                     -9.55511445e-01, -1.01160091e+00, -1.09861229e+00, -1.20397280e+00,\n",
       "                     -1.22377543e+00, -1.25276297e+00, -1.60943791e+00, -1.79175947e+00,\n",
       "                     -1.94591015e+00, -3.45387764e+01]), auc_score=0.5243350428841427, privacy_risk=0.5199113320113953, accuracy=0.5199113320113953, tpr_ind=0.46226415094339623, tnr_ind=0.5775585130793942, test_train_ratio=1.0027611596870685, dataset_size=[4346, 4358]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.0892073 , 0.09406055, 0.09729605, 0.10053155,\n",
       "                     0.1023804 , 0.10862029, 0.11254911, 0.11462907, 0.11578461,\n",
       "                     0.1222556 , 0.12318003, 0.1254911 , 0.12664664, 0.13126878,\n",
       "                     0.13565981, 0.14790848, 0.1486018 , 0.15461058, 0.1583083 ,\n",
       "                     0.16570372, 0.16917033, 0.17471689, 0.17633464, 0.19112549,\n",
       "                     0.19736538, 0.25814652, 0.27917726, 0.30228796, 0.30459903,\n",
       "                     0.35105154, 0.37185117, 0.37716663, 0.41090825, 0.43725445,\n",
       "                     0.44534319, 0.44788537, 0.47423157, 0.4818581 , 0.48486249,\n",
       "                     0.4885602 , 0.49757338, 0.50727987, 0.51259533, 0.51999076,\n",
       "                     0.5544257 , 0.56390109, 0.57822972, 0.58770511, 0.59486942,\n",
       "                     0.60758031, 0.62953547, 0.6403975 , 0.68869887, 0.68892997,\n",
       "                     0.69678761, 0.70372082, 0.70695632, 0.75017333, 0.76473307,\n",
       "                     0.77651953, 0.77675064, 0.78969263, 0.79893691, 0.80656344,\n",
       "                     0.8183499 , 0.8218165 , 0.83452739, 0.85786919, 0.86179801,\n",
       "                     0.86711347, 0.86780679, 0.87266004, 0.87289115, 0.88305986,\n",
       "                     0.8844465 , 0.89946845, 0.91980587, 0.93020569, 0.9371389 ,\n",
       "                     0.94869425, 0.95470303, 0.96117402, 0.97411602, 0.97550266,\n",
       "                     0.97735151, 0.97920037, 0.98081812, 0.98197365, 0.98243587,\n",
       "                     0.98382251, 0.98844465, 0.99075572, 0.99191125, 0.99214236,\n",
       "                     1.        ]), tpr=array([0.        , 0.09869774, 0.10372401, 0.10920722, 0.11309116,\n",
       "                     0.11469043, 0.12017363, 0.12542838, 0.12725611, 0.12908385,\n",
       "                     0.13799406, 0.13959333, 0.14507654, 0.14621887, 0.15124515,\n",
       "                     0.15649989, 0.16700937, 0.16769477, 0.17477724, 0.17774732,\n",
       "                     0.18551519, 0.18848526, 0.19579621, 0.19876628, 0.2117889 ,\n",
       "                     0.21955677, 0.27872972, 0.29929175, 0.32602239, 0.32716472,\n",
       "                     0.37902673, 0.40095956, 0.40667124, 0.45167923, 0.48115147,\n",
       "                     0.48732008, 0.49097555, 0.51770619, 0.5245602 , 0.5273018 ,\n",
       "                     0.53004341, 0.54009596, 0.55197624, 0.55677405, 0.56248572,\n",
       "                     0.59287183, 0.60635138, 0.61777473, 0.62805575, 0.63216815,\n",
       "                     0.64130683, 0.65775645, 0.66895134, 0.70756226, 0.70938999,\n",
       "                     0.71464473, 0.71921407, 0.72401188, 0.76742061, 0.78135709,\n",
       "                     0.79186658, 0.79346584, 0.80534613, 0.81699794, 0.82567969,\n",
       "                     0.83687457, 0.83984464, 0.85560886, 0.87914096, 0.8823395 ,\n",
       "                     0.88805118, 0.88919351, 0.89399132, 0.89604752, 0.90632854,\n",
       "                     0.90815627, 0.92711903, 0.94493946, 0.95453507, 0.95978981,\n",
       "                     0.96984236, 0.97235549, 0.9785241 , 0.98857665, 0.98949052,\n",
       "                     0.99086132, 0.99200366, 0.99337446, 0.99405986, 0.99520219,\n",
       "                     0.99611606, 0.99885767, 0.99954307, 0.99977153, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.08219945e-02, -5.00104206e-02,\n",
       "                     -5.71584138e-02, -6.06246218e-02, -8.00427077e-02, -9.53101798e-02,\n",
       "                     -1.05360516e-01, -1.17783036e-01, -1.20627988e-01, -1.33531393e-01,\n",
       "                     -1.43100844e-01, -1.62518929e-01, -1.75890666e-01, -1.82321557e-01,\n",
       "                     -1.96710294e-01, -2.00670695e-01, -2.03598955e-01, -2.07639365e-01,\n",
       "                     -2.11309094e-01, -2.13574100e-01, -2.23143551e-01, -2.29574442e-01,\n",
       "                     -2.33614851e-01, -2.34839591e-01, -2.36185547e-01, -2.36388778e-01,\n",
       "                     -2.55105902e-01, -2.57829109e-01, -2.75493556e-01, -2.79838895e-01,\n",
       "                     -2.87682072e-01, -2.97352477e-01, -2.99242895e-01, -3.11436158e-01,\n",
       "                     -3.18453731e-01, -3.25422400e-01, -3.36472237e-01, -3.48306694e-01,\n",
       "                     -3.56674944e-01, -3.58945092e-01, -3.59141036e-01, -3.61790045e-01,\n",
       "                     -3.64643114e-01, -3.65459773e-01, -3.93042588e-01, -4.05465108e-01,\n",
       "                     -4.12845215e-01, -4.18710335e-01, -4.21994410e-01, -4.25211871e-01,\n",
       "                     -4.25667815e-01, -4.34621692e-01, -4.41832752e-01, -4.51985124e-01,\n",
       "                     -4.55475529e-01, -4.57833094e-01, -4.65236851e-01, -4.70003629e-01,\n",
       "                     -4.81176930e-01, -4.85507816e-01, -4.91407538e-01, -4.93020999e-01,\n",
       "                     -4.95077267e-01, -5.00775288e-01, -5.10825624e-01, -5.12951023e-01,\n",
       "                     -5.25010259e-01, -5.38996501e-01, -5.42324291e-01, -5.59615788e-01,\n",
       "                     -5.66395475e-01, -5.87786665e-01, -6.22942922e-01, -6.28608659e-01,\n",
       "                     -6.35103811e-01, -6.53926467e-01, -6.56779536e-01, -6.71168274e-01,\n",
       "                     -6.93147181e-01, -7.37598943e-01, -7.83531242e-01, -7.90521345e-01,\n",
       "                     -8.10930216e-01, -8.47297860e-01, -8.60201265e-01, -9.16290732e-01,\n",
       "                     -9.80829253e-01, -1.02961942e+00, -1.09861229e+00, -1.25276297e+00,\n",
       "                     -1.38629436e+00, -1.60943791e+00, -2.07944154e+00, -3.45387764e+01]), auc_score=0.5239296068239979, privacy_risk=0.5223481844266616, accuracy=0.5223481844266616, tpr_ind=0.5519762394334019, tnr_ind=0.49272012941992144, test_train_ratio=0.9885766506739776, dataset_size=[4377, 4327]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.06468006, 0.10787711, 0.10995611, 0.11226611,\n",
       "                     0.12335412, 0.12681913, 0.13167013, 0.14252714, 0.14529915,\n",
       "                     0.15038115, 0.15500116, 0.15731116, 0.15892816, 0.16793717,\n",
       "                     0.2021252 , 0.2028182 , 0.20766921, 0.20997921, 0.22060522,\n",
       "                     0.22337722, 0.22661123, 0.23053823, 0.24670825, 0.25155925,\n",
       "                     0.30630631, 0.30746131, 0.41672442, 0.42157542, 0.42388542,\n",
       "                     0.43774544, 0.44513745, 0.50981751, 0.51443751, 0.58974359,\n",
       "                     0.59413259, 0.6033726 , 0.60984061, 0.61607762, 0.62531763,\n",
       "                     0.63963964, 0.65049665, 0.65234465, 0.66181566, 0.66966967,\n",
       "                     0.67267267, 0.67544468, 0.68098868, 0.75028875, 0.75814276,\n",
       "                     0.76206976, 0.76437976, 0.76738277, 0.78078078, 0.80757681,\n",
       "                     0.81265881, 0.83321783, 0.83945484, 0.84199584, 0.84892585,\n",
       "                     0.86186186, 0.86994687, 0.87179487, 0.87502888, 0.87687688,\n",
       "                     0.87918688, 0.88449988, 0.90713791, 0.91198891, 0.91545392,\n",
       "                     0.92030492, 0.93624394, 0.94871795, 0.95241395, 0.95657196,\n",
       "                     0.95911296, 0.96350196, 0.96465696, 0.97389697, 0.97458997,\n",
       "                     0.97897898, 0.98105798, 0.98359898, 0.98613999, 0.98683299,\n",
       "                     0.98706399, 0.98729499, 0.99075999, 0.99145299, 0.99191499,\n",
       "                     0.99306999, 0.99538   , 1.        ]), tpr=array([0.        , 0.06674286, 0.10651429, 0.10857143, 0.1104    ,\n",
       "                     0.12228571, 0.12982857, 0.13965714, 0.14925714, 0.15222857,\n",
       "                     0.15748571, 0.16434286, 0.1696    , 0.17074286, 0.1808    ,\n",
       "                     0.21622857, 0.21828571, 0.22377143, 0.22902857, 0.24457143,\n",
       "                     0.2496    , 0.25531429, 0.25668571, 0.26902857, 0.27382857,\n",
       "                     0.336     , 0.33691429, 0.4496    , 0.45417143, 0.45668571,\n",
       "                     0.4704    , 0.4784    , 0.54262857, 0.54834286, 0.63017143,\n",
       "                     0.63588571, 0.64708571, 0.65577143, 0.66148571, 0.6688    ,\n",
       "                     0.67931429, 0.69188571, 0.69417143, 0.70674286, 0.71657143,\n",
       "                     0.71954286, 0.72411429, 0.72822857, 0.7856    , 0.79131429,\n",
       "                     0.79451429, 0.80022857, 0.80662857, 0.81782857, 0.8416    ,\n",
       "                     0.84685714, 0.86697143, 0.87314286, 0.87474286, 0.88228571,\n",
       "                     0.89325714, 0.89965714, 0.90262857, 0.9056    , 0.90765714,\n",
       "                     0.90925714, 0.91451429, 0.936     , 0.93942857, 0.94331429,\n",
       "                     0.94582857, 0.95725714, 0.96662857, 0.96982857, 0.97348571,\n",
       "                     0.97645714, 0.97965714, 0.98194286, 0.98834286, 0.98925714,\n",
       "                     0.99154286, 0.99314286, 0.99451429, 0.99565714, 0.99611429,\n",
       "                     0.99634286, 0.9968    , 0.99817143, 0.99908571, 0.99931429,\n",
       "                     0.99954286, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.76127528e-02, -8.70113770e-02,\n",
       "                     -9.53101798e-02, -1.05360516e-01, -1.12477983e-01, -1.27833372e-01,\n",
       "                     -1.33531393e-01, -1.43100844e-01, -1.54150680e-01, -1.62518929e-01,\n",
       "                     -1.70625517e-01, -1.82321557e-01, -1.84303718e-01, -1.93016846e-01,\n",
       "                     -2.00670695e-01, -2.23143551e-01, -2.31801614e-01, -2.34839591e-01,\n",
       "                     -2.41162057e-01, -2.46860078e-01, -2.51314428e-01, -2.63191052e-01,\n",
       "                     -2.65703166e-01, -2.74730920e-01, -2.87682072e-01, -2.90214360e-01,\n",
       "                     -3.00104592e-01, -3.10154928e-01, -3.12133168e-01, -3.20471895e-01,\n",
       "                     -3.32907170e-01, -3.33144447e-01, -3.51915030e-01, -3.54171814e-01,\n",
       "                     -3.56674944e-01, -3.69747026e-01, -3.82208246e-01, -3.84411699e-01,\n",
       "                     -3.86122145e-01, -3.99386062e-01, -4.05465108e-01, -4.14433778e-01,\n",
       "                     -4.28454626e-01, -4.35318071e-01, -4.38254931e-01, -4.41832752e-01,\n",
       "                     -4.42922671e-01, -4.47312218e-01, -4.51985124e-01, -4.70003629e-01,\n",
       "                     -4.74457980e-01, -4.90206337e-01, -4.93657820e-01, -4.96436886e-01,\n",
       "                     -5.01021624e-01, -5.10825624e-01, -5.23248144e-01, -5.28844129e-01,\n",
       "                     -5.35518236e-01, -5.38996501e-01, -5.59615788e-01, -5.70544858e-01,\n",
       "                     -5.87786665e-01, -6.06135804e-01, -6.15185639e-01, -6.21491192e-01,\n",
       "                     -6.24154309e-01, -6.32522559e-01, -6.46627165e-01, -6.93147181e-01,\n",
       "                     -7.11496319e-01, -7.28238500e-01, -7.53771802e-01, -7.67255153e-01,\n",
       "                     -7.85520501e-01, -7.88457360e-01, -7.94929875e-01, -8.10930216e-01,\n",
       "                     -8.75468737e-01, -9.16290732e-01, -9.80829253e-01, -1.02961942e+00,\n",
       "                     -1.09861229e+00, -1.20397280e+00, -1.25276297e+00, -1.38629436e+00,\n",
       "                     -1.50407740e+00, -1.60943791e+00, -1.79175947e+00, -2.07944154e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5265756393756393, privacy_risk=0.5243348051348051, accuracy=0.5243348051348051, tpr_ind=0.7241142857142857, tnr_ind=0.32455532455532454, test_train_ratio=0.9894857142857143, dataset_size=[4375, 4329])],\n",
       "             'subpopulation_1.0_label_1.0_mia_auc': [0.546727198172339,\n",
       "              0.560962495851311,\n",
       "              0.5716157425774534,\n",
       "              0.5619831354451643,\n",
       "              0.5596288004997918,\n",
       "              0.5567953485938508,\n",
       "              0.570926736095652,\n",
       "              0.5652313680787446,\n",
       "              0.5749905182711678,\n",
       "              0.5573106087525143,\n",
       "              0.5516101351400635,\n",
       "              0.5568772283867314,\n",
       "              0.5727700172683494,\n",
       "              0.5505040680639015,\n",
       "              0.5706569637343268,\n",
       "              0.5507518400655981,\n",
       "              0.5473019721990682,\n",
       "              0.5438807678372494,\n",
       "              0.5590171078568684,\n",
       "              0.5513141870105461],\n",
       "             'subpopulation_1.0_label_1.0_mia_privacy_risk': [0.5363839910439406,\n",
       "              0.5424415766970578,\n",
       "              0.5596513670522548,\n",
       "              0.5438856682002576,\n",
       "              0.5413265306122449,\n",
       "              0.536120190827186,\n",
       "              0.5537836401607078,\n",
       "              0.5455863799613824,\n",
       "              0.55447210913997,\n",
       "              0.5431363805450973,\n",
       "              0.536346831361998,\n",
       "              0.5394507755618867,\n",
       "              0.5534094307906028,\n",
       "              0.5347985863074313,\n",
       "              0.5507174586109618,\n",
       "              0.5344878077351086,\n",
       "              0.5333142719799929,\n",
       "              0.5402100802797667,\n",
       "              0.5406750256945869,\n",
       "              0.5364674003069163],\n",
       "             'subpopulation_1.0_label_1.0_mia_ppv': [0.7391304347826088,\n",
       "              0.8095238095238095,\n",
       "              0.7164179104477612,\n",
       "              0.6949152542372882,\n",
       "              0.7027027027027026,\n",
       "              0.7076923076923077,\n",
       "              0.6527777777777778,\n",
       "              0.6478873239436619,\n",
       "              0.7894736842105263,\n",
       "              0.7551020408163265,\n",
       "              0.6796116504854368,\n",
       "              0.6885245901639344,\n",
       "              0.6585365853658536,\n",
       "              0.7083333333333334,\n",
       "              0.7446808510638299,\n",
       "              0.643939393939394,\n",
       "              0.6666666666666667,\n",
       "              0.7083333333333333,\n",
       "              0.7391304347826086,\n",
       "              0.7],\n",
       "             'subpopulation_1.0_label_1.0_mia_attacker_advantage': [0.07276798208788138,\n",
       "              0.08488315339411567,\n",
       "              0.11930273410450964,\n",
       "              0.08777133640051527,\n",
       "              0.08265306122448979,\n",
       "              0.07224038165437185,\n",
       "              0.1075672803214156,\n",
       "              0.09117275992276486,\n",
       "              0.10894421827994016,\n",
       "              0.08627276109019466,\n",
       "              0.07269366272399602,\n",
       "              0.0789015511237734,\n",
       "              0.10681886158120557,\n",
       "              0.06959717261486253,\n",
       "              0.10143491722192355,\n",
       "              0.0689756154702173,\n",
       "              0.06662854395998574,\n",
       "              0.08042016055953338,\n",
       "              0.08135005138917384,\n",
       "              0.0729348006138325],\n",
       "             'subpopulation_1.0_label_1.0_mia_result': [MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00604534, 0.01108312, 0.01209068, 0.02216625,\n",
       "                     0.02267003, 0.02619647, 0.03123426, 0.03274559, 0.03476071,\n",
       "                     0.04282116, 0.04584383, 0.05138539, 0.05390428, 0.05743073,\n",
       "                     0.07304786, 0.07506297, 0.0861461 , 0.09672544, 0.10881612,\n",
       "                     0.11284635, 0.11889169, 0.12997481, 0.14156171, 0.15869018,\n",
       "                     0.16020151, 0.16826196, 0.17178841, 0.18438287, 0.19798489,\n",
       "                     0.21360202, 0.22518892, 0.23627204, 0.24433249, 0.25692695,\n",
       "                     0.27254408, 0.27506297, 0.29118388, 0.29118388, 0.29370277,\n",
       "                     0.29974811, 0.30377834, 0.32292191, 0.32695214, 0.33400504,\n",
       "                     0.36070529, 0.36372796, 0.36926952, 0.37078086, 0.39093199,\n",
       "                     0.40654912, 0.41460957, 0.41914358, 0.42821159, 0.45793451,\n",
       "                     0.4720403 , 0.47707809, 0.48110831, 0.48916877, 0.502267  ,\n",
       "                     0.51486146, 0.54760705, 0.55717884, 0.56775819, 0.56826196,\n",
       "                     0.57279597, 0.60403023, 0.61612091, 0.62115869, 0.64634761,\n",
       "                     0.65138539, 0.66246851, 0.67103275, 0.69370277, 0.71586902,\n",
       "                     0.72745592, 0.73602015, 0.75869018, 0.76523929, 0.77581864,\n",
       "                     0.80503778, 0.80957179, 0.82267003, 0.82821159, 0.83425693,\n",
       "                     0.85994962, 0.86246851, 0.88564232, 0.89521411, 0.90075567,\n",
       "                     0.91889169, 0.92292191, 0.93047859, 0.93198992, 0.93198992,\n",
       "                     0.93299748, 0.94206549, 0.94911839, 0.95264484, 0.95768262,\n",
       "                     0.9581864 , 0.96775819, 0.97279597, 0.97380353, 0.9768262 ,\n",
       "                     0.9768262 , 1.        ]), tpr=array([0.        , 0.01757106, 0.02325581, 0.025323  , 0.03152455,\n",
       "                     0.03410853, 0.03875969, 0.04237726, 0.04547804, 0.04806202,\n",
       "                     0.0620155 , 0.06563307, 0.07028424, 0.0754522 , 0.08062016,\n",
       "                     0.09819121, 0.10129199, 0.11886305, 0.1250646 , 0.1379845 ,\n",
       "                     0.14315245, 0.14935401, 0.1627907 , 0.17260982, 0.20465116,\n",
       "                     0.20723514, 0.21447028, 0.21860465, 0.22583979, 0.23979328,\n",
       "                     0.25426357, 0.26873385, 0.28165375, 0.2878553 , 0.29354005,\n",
       "                     0.31731266, 0.31989664, 0.33850129, 0.33953488, 0.34211886,\n",
       "                     0.3503876 , 0.35245478, 0.3627907 , 0.36640827, 0.37260982,\n",
       "                     0.41447028, 0.41602067, 0.41912145, 0.42118863, 0.43669251,\n",
       "                     0.45116279, 0.45788114, 0.4620155 , 0.47390181, 0.51007752,\n",
       "                     0.52248062, 0.52816537, 0.53385013, 0.54677003, 0.56950904,\n",
       "                     0.58087855, 0.61653747, 0.62170543, 0.63410853, 0.63669251,\n",
       "                     0.64186047, 0.67596899, 0.68888889, 0.69354005, 0.71679587,\n",
       "                     0.72196382, 0.73333333, 0.73953488, 0.76020672, 0.774677  ,\n",
       "                     0.78397933, 0.78966408, 0.80826873, 0.81653747, 0.82894057,\n",
       "                     0.86149871, 0.86718346, 0.8744186 , 0.87751938, 0.88423773,\n",
       "                     0.90801034, 0.91007752, 0.92764858, 0.93488372, 0.94056848,\n",
       "                     0.95917313, 0.9622739 , 0.96589147, 0.96795866, 0.96899225,\n",
       "                     0.97105943, 0.97571059, 0.98294574, 0.98604651, 0.99069767,\n",
       "                     0.99173127, 0.99638243, 0.99741602, 0.99741602, 0.99896641,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -8.70113770e-02, -2.23143551e-01,\n",
       "                     -2.87682072e-01, -3.36472237e-01, -3.67724780e-01, -4.05465108e-01,\n",
       "                     -4.41832752e-01, -4.70003629e-01, -5.10825624e-01, -5.38996501e-01,\n",
       "                     -5.75364145e-01, -5.87786665e-01, -6.06135804e-01, -6.16774202e-01,\n",
       "                     -6.19039208e-01, -6.27549898e-01, -6.31271777e-01, -6.35988767e-01,\n",
       "                     -6.41853886e-01, -6.50587566e-01, -6.53926467e-01, -6.66478933e-01,\n",
       "                     -6.93147181e-01, -7.47214402e-01, -7.62140052e-01, -7.80158558e-01,\n",
       "                     -7.88457360e-01, -7.98507696e-01, -8.05264479e-01, -8.25318954e-01,\n",
       "                     -8.41567186e-01, -8.47297860e-01, -8.60201265e-01, -8.66166345e-01,\n",
       "                     -8.75468737e-01, -8.82389180e-01, -8.87303195e-01, -8.90972924e-01,\n",
       "                     -8.97941593e-01, -9.16290732e-01, -9.29535959e-01, -9.47381319e-01,\n",
       "                     -9.49080555e-01, -9.62137120e-01, -9.80829253e-01, -1.00552187e+00,\n",
       "                     -1.01160091e+00, -1.02165125e+00, -1.02450432e+00, -1.02961942e+00,\n",
       "                     -1.03609193e+00, -1.05416053e+00, -1.05480967e+00, -1.05605267e+00,\n",
       "                     -1.06087196e+00, -1.08261195e+00, -1.08518927e+00, -1.09330724e+00,\n",
       "                     -1.09861229e+00, -1.12718566e+00, -1.14117190e+00, -1.14356368e+00,\n",
       "                     -1.17007125e+00, -1.17163742e+00, -1.17569203e+00, -1.17677706e+00,\n",
       "                     -1.18958407e+00, -1.20397280e+00, -1.22377543e+00, -1.25276297e+00,\n",
       "                     -1.25804003e+00, -1.25988044e+00, -1.26923781e+00, -1.28966753e+00,\n",
       "                     -1.29098418e+00, -1.32538561e+00, -1.35454566e+00, -1.36524095e+00,\n",
       "                     -1.37029402e+00, -1.38629436e+00, -1.40089316e+00, -1.40691365e+00,\n",
       "                     -1.44238383e+00, -1.45597428e+00, -1.50407740e+00, -1.52121368e+00,\n",
       "                     -1.52605630e+00, -1.53393036e+00, -1.56977266e+00, -1.57553636e+00,\n",
       "                     -1.60943791e+00, -1.79175947e+00, -1.83258146e+00, -1.87180218e+00,\n",
       "                     -1.92990981e+00, -1.93075834e+00, -1.94591015e+00, -2.07944154e+00,\n",
       "                     -2.14006616e+00, -2.24723500e+00, -2.44234704e+00, -2.83321334e+00,\n",
       "                     -3.06027079e+00, -3.21887582e+00, -3.45387764e+01]), auc_score=0.546727198172339, privacy_risk=0.5363839910439406, accuracy=0.5363839910439406, tpr_ind=0.6888888888888889, tnr_ind=0.38387909319899244, test_train_ratio=1.0258397932816536, dataset_size=[1935, 1985]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00407125, 0.00559796, 0.01424936, 0.01475827,\n",
       "                     0.01679389, 0.02188295, 0.02900763, 0.03256997, 0.03867684,\n",
       "                     0.04529262, 0.05547074, 0.05750636, 0.06361323, 0.06870229,\n",
       "                     0.0697201 , 0.07430025, 0.09211196, 0.10330789, 0.10788804,\n",
       "                     0.12417303, 0.12773537, 0.13638677, 0.14402036, 0.1475827 ,\n",
       "                     0.15470738, 0.1740458 , 0.17811705, 0.22340967, 0.24122137,\n",
       "                     0.243257  , 0.25394402, 0.26564885, 0.27022901, 0.29007634,\n",
       "                     0.33994911, 0.35470738, 0.36386768, 0.36844784, 0.39796438,\n",
       "                     0.40407125, 0.41017812, 0.41577608, 0.41984733, 0.42544529,\n",
       "                     0.4264631 , 0.47175573, 0.4870229 , 0.50737913, 0.51145038,\n",
       "                     0.53384224, 0.53435115, 0.60356234, 0.61119593, 0.61933842,\n",
       "                     0.62290076, 0.643257  , 0.64987277, 0.6783715 , 0.68804071,\n",
       "                     0.68956743, 0.69465649, 0.70890585, 0.74045802, 0.7653944 ,\n",
       "                     0.77048346, 0.78117048, 0.79796438, 0.80712468, 0.81017812,\n",
       "                     0.81628499, 0.81933842, 0.84071247, 0.84885496, 0.85343511,\n",
       "                     0.85699746, 0.88956743, 0.89160305, 0.89262087, 0.89720102,\n",
       "                     0.90279898, 0.90636132, 0.91195929, 0.91704835, 0.93333333,\n",
       "                     0.9389313 , 0.94402036, 0.94452926, 0.94452926, 0.95012723,\n",
       "                     0.95063613, 0.95216285, 0.95267176, 0.95470738, 0.95979644,\n",
       "                     0.96234097, 0.96284987, 0.96793893, 0.97251908, 0.9735369 ,\n",
       "                     0.9735369 , 0.97455471, 0.97709924, 1.        ]), tpr=array([0.        , 0.0173913 , 0.02097187, 0.02762148, 0.03017903,\n",
       "                     0.03478261, 0.04040921, 0.05063939, 0.057289  , 0.06649616,\n",
       "                     0.07263427, 0.08286445, 0.08695652, 0.0971867 , 0.1028133 ,\n",
       "                     0.10690537, 0.11253197, 0.13350384, 0.14629156, 0.15242967,\n",
       "                     0.1713555 , 0.17493606, 0.18005115, 0.18925831, 0.19590793,\n",
       "                     0.20664962, 0.22608696, 0.23069054, 0.28030691, 0.30690537,\n",
       "                     0.30946292, 0.31918159, 0.33350384, 0.33606138, 0.35549872,\n",
       "                     0.40716113, 0.41994885, 0.43273657, 0.43836317, 0.47263427,\n",
       "                     0.47621483, 0.48184143, 0.4859335 , 0.49002558, 0.49258312,\n",
       "                     0.49514066, 0.54373402, 0.56317136, 0.57953964, 0.5826087 ,\n",
       "                     0.59693095, 0.59795396, 0.67774936, 0.69207161, 0.70332481,\n",
       "                     0.70639386, 0.71969309, 0.72531969, 0.75754476, 0.77084399,\n",
       "                     0.77289003, 0.77953964, 0.79130435, 0.81585678, 0.84450128,\n",
       "                     0.84961637, 0.85677749, 0.87723785, 0.88491049, 0.88746803,\n",
       "                     0.89258312, 0.89514066, 0.9140665 , 0.9202046 , 0.92429668,\n",
       "                     0.9258312 , 0.94424552, 0.94629156, 0.94782609, 0.95038363,\n",
       "                     0.95345269, 0.95652174, 0.95856777, 0.96470588, 0.98056266,\n",
       "                     0.9826087 , 0.98567775, 0.98618926, 0.98772379, 0.98976982,\n",
       "                     0.99028133, 0.99130435, 0.99181586, 0.99283887, 0.9943734 ,\n",
       "                     0.99590793, 0.99590793, 0.99693095, 0.99795396, 0.99846547,\n",
       "                     0.99897698, 0.99948849, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -2.87682072e-01,\n",
       "                     -3.36472237e-01, -3.67724780e-01, -3.74693449e-01, -4.70003629e-01,\n",
       "                     -4.79573080e-01, -4.94696242e-01, -5.10825624e-01, -5.30628251e-01,\n",
       "                     -5.43615447e-01, -5.87786665e-01, -5.97837001e-01, -6.28608659e-01,\n",
       "                     -6.46627165e-01, -6.93147181e-01, -7.32367894e-01, -7.33969175e-01,\n",
       "                     -7.45790914e-01, -7.62140052e-01, -7.88457360e-01, -7.98507696e-01,\n",
       "                     -8.02346473e-01, -8.26678573e-01, -8.39750655e-01, -8.47297860e-01,\n",
       "                     -8.50239039e-01, -8.60940637e-01, -8.75468737e-01, -8.84202417e-01,\n",
       "                     -8.87303195e-01, -8.90972924e-01, -8.93817876e-01, -9.16290732e-01,\n",
       "                     -9.40007258e-01, -9.58254931e-01, -9.69400557e-01, -9.80829253e-01,\n",
       "                     -9.98528830e-01, -1.00330211e+00, -1.01160091e+00, -1.02165125e+00,\n",
       "                     -1.02961942e+00, -1.04145387e+00, -1.05925121e+00, -1.09861229e+00,\n",
       "                     -1.12938395e+00, -1.15267951e+00, -1.16179119e+00, -1.16315081e+00,\n",
       "                     -1.16475209e+00, -1.16760516e+00, -1.17163742e+00, -1.20397280e+00,\n",
       "                     -1.20609820e+00, -1.21302264e+00, -1.21345155e+00, -1.21478372e+00,\n",
       "                     -1.23676263e+00, -1.24171313e+00, -1.24653242e+00, -1.25276297e+00,\n",
       "                     -1.27349887e+00, -1.30405626e+00, -1.31218639e+00, -1.32175584e+00,\n",
       "                     -1.33041390e+00, -1.33500107e+00, -1.38629436e+00, -1.40876722e+00,\n",
       "                     -1.41952001e+00, -1.52242654e+00, -1.53147637e+00, -1.54044504e+00,\n",
       "                     -1.56704235e+00, -1.56861592e+00, -1.60943791e+00, -1.65822808e+00,\n",
       "                     -1.70474809e+00, -1.74296931e+00, -1.74919985e+00, -1.77777323e+00,\n",
       "                     -1.77956420e+00, -1.79175947e+00, -1.87180218e+00, -1.94591015e+00,\n",
       "                     -1.99243016e+00, -2.01490302e+00, -2.03688193e+00, -2.07944154e+00,\n",
       "                     -2.19722458e+00, -2.35137526e+00, -2.42036813e+00, -2.48490665e+00,\n",
       "                     -2.70805020e+00, -2.77258872e+00, -2.80336038e+00, -2.83321334e+00,\n",
       "                     -2.94443898e+00, -3.04452244e+00, -3.46573590e+00, -3.45387764e+01]), auc_score=0.560962495851311, privacy_risk=0.5424415766970578, accuracy=0.5424415766970578, tpr_ind=0.779539641943734, tnr_ind=0.3053435114503817, test_train_ratio=1.0051150895140666, dataset_size=[1955, 1965]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00873587, 0.00976362, 0.01233299, 0.01541624,\n",
       "                     0.02106886, 0.02312436, 0.02774923, 0.03186023, 0.03340185,\n",
       "                     0.03905447, 0.04213772, 0.04522097, 0.04676259, 0.05292909,\n",
       "                     0.0626927 , 0.07399794, 0.07759507, 0.07965057, 0.08838643,\n",
       "                     0.10174717, 0.10380267, 0.12332991, 0.1294964 , 0.14594039,\n",
       "                     0.14850976, 0.15416238, 0.17574512, 0.20554985, 0.20811922,\n",
       "                     0.21736896, 0.21942446, 0.22661871, 0.23432682, 0.23586845,\n",
       "                     0.24717369, 0.25796506, 0.31243577, 0.32117163, 0.34326824,\n",
       "                     0.35046249, 0.36742035, 0.37512847, 0.3967112 , 0.3987667 ,\n",
       "                     0.40596095, 0.42189106, 0.44141829, 0.44758479, 0.46248715,\n",
       "                     0.47327852, 0.49948613, 0.51233299, 0.51490236, 0.52261048,\n",
       "                     0.52569373, 0.52672148, 0.5323741 , 0.54265159, 0.60071942,\n",
       "                     0.60380267, 0.61973279, 0.62178828, 0.62435766, 0.63257965,\n",
       "                     0.68602261, 0.69270298, 0.69527235, 0.6963001 , 0.69886948,\n",
       "                     0.71223022, 0.7348407 , 0.75025694, 0.76567318, 0.77749229,\n",
       "                     0.78160329, 0.78571429, 0.81140802, 0.85817061, 0.86536485,\n",
       "                     0.87101747, 0.87512847, 0.88643371, 0.88694758, 0.88951696,\n",
       "                     0.89414183, 0.90133607, 0.90596095, 0.90904419, 0.92600206,\n",
       "                     0.92959918, 0.93216855, 0.93884892, 0.94244604, 0.94450154,\n",
       "                     0.94758479, 0.95118191, 0.95786228, 0.95786228, 0.96043165,\n",
       "                     0.96197328, 0.96300103, 0.9655704 , 1.        ]), tpr=array([0.        , 0.02026342, 0.02431611, 0.02684904, 0.03292806,\n",
       "                     0.03799392, 0.04255319, 0.04812563, 0.05724417, 0.05876393,\n",
       "                     0.06382979, 0.06737589, 0.07497467, 0.07902736, 0.08662614,\n",
       "                     0.09878419, 0.11094225, 0.12006079, 0.12411348, 0.13424519,\n",
       "                     0.14994934, 0.15653495, 0.17223911, 0.17983789, 0.19402229,\n",
       "                     0.19655522, 0.20314083, 0.22289767, 0.25227964, 0.25683891,\n",
       "                     0.27203647, 0.27558257, 0.28774063, 0.29432624, 0.30192503,\n",
       "                     0.31104357, 0.32421479, 0.37740628, 0.39159068, 0.41945289,\n",
       "                     0.42755826, 0.44528875, 0.45136778, 0.47568389, 0.48024316,\n",
       "                     0.48885512, 0.50253293, 0.52735562, 0.53292806, 0.55217832,\n",
       "                     0.56382979, 0.5881459 , 0.59625127, 0.59929078, 0.60992908,\n",
       "                     0.61600811, 0.62056738, 0.62462006, 0.63880446, 0.6970618 ,\n",
       "                     0.69858156, 0.71631206, 0.71985816, 0.72340426, 0.7325228 ,\n",
       "                     0.80496454, 0.81053698, 0.81357649, 0.81560284, 0.81813576,\n",
       "                     0.82624113, 0.84447822, 0.85410334, 0.86220871, 0.86930091,\n",
       "                     0.87284701, 0.87436677, 0.89361702, 0.93262411, 0.93870314,\n",
       "                     0.93971631, 0.94123607, 0.9508612 , 0.95238095, 0.95542047,\n",
       "                     0.95947315, 0.96453901, 0.96656535, 0.96960486, 0.97669706,\n",
       "                     0.9787234 , 0.98176292, 0.98885512, 0.98986829, 0.99240122,\n",
       "                     0.99442756, 0.99544073, 0.9964539 , 0.99696049, 0.99797366,\n",
       "                     0.99848024, 0.99949341, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.17783036e-01, -1.82321557e-01,\n",
       "                     -2.23143551e-01, -2.62364264e-01, -3.67724780e-01, -3.74693449e-01,\n",
       "                     -4.05465108e-01, -5.10825624e-01, -5.30628251e-01, -5.38996501e-01,\n",
       "                     -5.50046337e-01, -5.59615788e-01, -5.87786665e-01, -6.06135804e-01,\n",
       "                     -6.28608659e-01, -6.35988767e-01, -6.39079959e-01, -6.40503447e-01,\n",
       "                     -6.93147181e-01, -7.30887509e-01, -7.40400065e-01, -7.57685702e-01,\n",
       "                     -7.67255153e-01, -7.88457360e-01, -8.02346473e-01, -8.06475866e-01,\n",
       "                     -8.10930216e-01, -8.47297860e-01, -8.75468737e-01, -8.87303195e-01,\n",
       "                     -8.99483614e-01, -9.00786545e-01, -9.02867712e-01, -9.16290732e-01,\n",
       "                     -9.27340568e-01, -9.29017286e-01, -9.31558204e-01, -9.34309237e-01,\n",
       "                     -9.40983344e-01, -9.44461609e-01, -9.49080555e-01, -9.67276287e-01,\n",
       "                     -9.80829253e-01, -9.95428052e-01, -9.98528830e-01, -1.01160091e+00,\n",
       "                     -1.03609193e+00, -1.04707864e+00, -1.06919840e+00, -1.09861229e+00,\n",
       "                     -1.12059120e+00, -1.13707857e+00, -1.14513230e+00, -1.15267951e+00,\n",
       "                     -1.17007125e+00, -1.17865500e+00, -1.20039498e+00, -1.20048848e+00,\n",
       "                     -1.20397280e+00, -1.20682587e+00, -1.21302264e+00, -1.21924028e+00,\n",
       "                     -1.22050211e+00, -1.22747078e+00, -1.29098418e+00, -1.29928298e+00,\n",
       "                     -1.32175584e+00, -1.33500107e+00, -1.35454566e+00, -1.37230812e+00,\n",
       "                     -1.38629436e+00, -1.40179855e+00, -1.43848011e+00, -1.45528723e+00,\n",
       "                     -1.46633707e+00, -1.46835931e+00, -1.47924047e+00, -1.48538526e+00,\n",
       "                     -1.50407740e+00, -1.54044504e+00, -1.58816051e+00, -1.60943791e+00,\n",
       "                     -1.63141682e+00, -1.65822808e+00, -1.68639895e+00, -1.70474809e+00,\n",
       "                     -1.76358859e+00, -1.79175947e+00, -1.83258146e+00, -1.87180218e+00,\n",
       "                     -1.91481956e+00, -1.94591015e+00, -2.02814825e+00, -2.07944154e+00,\n",
       "                     -2.14006616e+00, -2.19722458e+00, -2.30258509e+00, -2.56494936e+00,\n",
       "                     -2.63905733e+00, -2.99573227e+00, -3.13549422e+00, -3.45387764e+01]), auc_score=0.5716157425774534, privacy_risk=0.5596513670522548, accuracy=0.5596513670522548, tpr_ind=0.8156028368794326, tnr_ind=0.30369989722507706, test_train_ratio=0.9858156028368794, dataset_size=[1974, 1946]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00926402, 0.01441071, 0.01595471, 0.01904272,\n",
       "                     0.02264539, 0.02676274, 0.03396809, 0.03911477, 0.04065878,\n",
       "                     0.04477612, 0.05352548, 0.07205353, 0.08080288, 0.08903757,\n",
       "                     0.0998456 , 0.10550695, 0.10962429, 0.13587236, 0.14307771,\n",
       "                     0.15234174, 0.15440041, 0.16057643, 0.17035512, 0.19454452,\n",
       "                     0.20483788, 0.20638188, 0.22748327, 0.2382913 , 0.24240865,\n",
       "                     0.24704066, 0.25270201, 0.25887802, 0.27174472, 0.35409161,\n",
       "                     0.376737  , 0.39269171, 0.41019043, 0.42254246, 0.44981987,\n",
       "                     0.45136387, 0.45753989, 0.46886258, 0.47195059, 0.47709727,\n",
       "                     0.4863613 , 0.51312403, 0.5234174 , 0.52907874, 0.53371076,\n",
       "                     0.54966547, 0.57282553, 0.62789501, 0.64487905, 0.64848173,\n",
       "                     0.65568708, 0.66495111, 0.68244982, 0.69119918, 0.69788986,\n",
       "                     0.69840453, 0.70612455, 0.7117859 , 0.71950592, 0.73185795,\n",
       "                     0.74420998, 0.77200206, 0.79001544, 0.79670612, 0.79722079,\n",
       "                     0.80082347, 0.80442615, 0.80597015, 0.82192486, 0.83530623,\n",
       "                     0.84354092, 0.87905301, 0.89912506, 0.9016984 , 0.91250643,\n",
       "                     0.91662378, 0.91765311, 0.91868245, 0.92074112, 0.92897581,\n",
       "                     0.93103448, 0.93154915, 0.93669583, 0.94235718, 0.94544519,\n",
       "                     0.94595986, 0.94904786, 0.95470921, 0.95522388, 0.95676788,\n",
       "                     0.95728255, 0.96345857, 0.96551724, 0.96603191, 0.96757591,\n",
       "                     0.97220793, 0.9742666 , 1.        ]), tpr=array([0.        , 0.02073849, 0.02630248, 0.03388973, 0.04248862,\n",
       "                     0.05058169, 0.05867476, 0.06828528, 0.071826  , 0.0748609 ,\n",
       "                     0.07738998, 0.08801214, 0.11785534, 0.12594841, 0.13606474,\n",
       "                     0.1527567 , 0.15832069, 0.16590794, 0.18361153, 0.1917046 ,\n",
       "                     0.19929186, 0.20435003, 0.20991401, 0.22053617, 0.24683864,\n",
       "                     0.25897825, 0.26201315, 0.28528073, 0.30096105, 0.30601922,\n",
       "                     0.31259484, 0.31765301, 0.3292868 , 0.3383915 , 0.41780475,\n",
       "                     0.43955488, 0.46383409, 0.48002023, 0.49671219, 0.52250885,\n",
       "                     0.52604957, 0.53414264, 0.54881133, 0.55437532, 0.5599393 ,\n",
       "                     0.57056146, 0.59382903, 0.5988872 , 0.60293374, 0.60950936,\n",
       "                     0.63227112, 0.66059686, 0.70257967, 0.72281234, 0.72483561,\n",
       "                     0.73242286, 0.74102175, 0.76074861, 0.76631259, 0.77693475,\n",
       "                     0.77996965, 0.78603945, 0.79666161, 0.80222559, 0.8113303 ,\n",
       "                     0.82397572, 0.84623166, 0.85988872, 0.86342944, 0.86646434,\n",
       "                     0.86899342, 0.87405159, 0.87759231, 0.89175518, 0.90440061,\n",
       "                     0.91047041, 0.9312089 , 0.94537178, 0.94739504, 0.95599393,\n",
       "                     0.96004047, 0.96155792, 0.96256955, 0.96611027, 0.97167425,\n",
       "                     0.97268589, 0.9731917 , 0.97723824, 0.98381386, 0.98533131,\n",
       "                     0.98583713, 0.98937785, 0.99038948, 0.9908953 , 0.99190693,\n",
       "                     0.99241275, 0.99443601, 0.99645928, 0.99747092, 0.99797673,\n",
       "                     0.99949418, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.41162057e-01, -2.87682072e-01,\n",
       "                     -3.44840486e-01, -4.05465108e-01, -4.46287103e-01, -4.56758402e-01,\n",
       "                     -5.38996501e-01, -5.59615788e-01, -5.87786665e-01, -5.93063722e-01,\n",
       "                     -6.04593783e-01, -6.28608659e-01, -6.41853886e-01, -6.93147181e-01,\n",
       "                     -7.20546155e-01, -7.25937003e-01, -7.48717032e-01, -7.53771802e-01,\n",
       "                     -7.57685702e-01, -7.77704569e-01, -7.80158558e-01, -7.84118959e-01,\n",
       "                     -8.02346473e-01, -8.10930216e-01, -8.20980552e-01, -8.25318954e-01,\n",
       "                     -8.28692673e-01, -8.32909123e-01, -8.36248024e-01, -8.75468737e-01,\n",
       "                     -8.89857475e-01, -9.16290732e-01, -9.20105104e-01, -9.39280250e-01,\n",
       "                     -9.49080555e-01, -9.65080896e-01, -9.80829253e-01, -9.88155293e-01,\n",
       "                     -9.98528830e-01, -1.01160091e+00, -1.01473080e+00, -1.02961942e+00,\n",
       "                     -1.03609193e+00, -1.04145387e+00, -1.05416053e+00, -1.06471074e+00,\n",
       "                     -1.09861229e+00, -1.12393010e+00, -1.14209740e+00, -1.16378192e+00,\n",
       "                     -1.16465570e+00, -1.17093295e+00, -1.18958407e+00, -1.19392247e+00,\n",
       "                     -1.20126644e+00, -1.20397280e+00, -1.25276297e+00, -1.27296568e+00,\n",
       "                     -1.29928298e+00, -1.30405626e+00, -1.30625165e+00, -1.33977435e+00,\n",
       "                     -1.34373475e+00, -1.35583515e+00, -1.35663815e+00, -1.37699197e+00,\n",
       "                     -1.38629436e+00, -1.42711636e+00, -1.45225233e+00, -1.45667516e+00,\n",
       "                     -1.49165488e+00, -1.57307027e+00, -1.58514522e+00, -1.59263079e+00,\n",
       "                     -1.59469563e+00, -1.59504917e+00, -1.60943791e+00, -1.64865863e+00,\n",
       "                     -1.65822808e+00, -1.67397643e+00, -1.70474809e+00, -1.71765150e+00,\n",
       "                     -1.78245708e+00, -1.79175947e+00, -1.87180218e+00, -1.90954250e+00,\n",
       "                     -1.92368701e+00, -1.94591015e+00, -1.98100147e+00, -2.00148000e+00,\n",
       "                     -2.01490302e+00, -2.07944154e+00, -2.19722458e+00, -2.56494936e+00,\n",
       "                     -2.63905733e+00, -2.70805020e+00, -2.83321334e+00, -2.94443898e+00,\n",
       "                     -2.97892516e+00, -4.11087386e+00, -3.45387764e+01]), auc_score=0.5619831354451643, privacy_risk=0.5438856682002576, accuracy=0.5438856682002576, tpr_ind=0.6605968639352554, tnr_ind=0.4271744724652599, test_train_ratio=0.9828022255943348, dataset_size=[1977, 1943]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00663265, 0.00867347, 0.00969388, 0.0127551 ,\n",
       "                     0.01479592, 0.01530612, 0.01683673, 0.02193878, 0.02806122,\n",
       "                     0.03163265, 0.04132653, 0.05      , 0.05612245, 0.06122449,\n",
       "                     0.06836735, 0.06938776, 0.07857143, 0.08316327, 0.08520408,\n",
       "                     0.09693878, 0.09897959, 0.11632653, 0.12704082, 0.14642857,\n",
       "                     0.15663265, 0.15867347, 0.15969388, 0.17857143, 0.18367347,\n",
       "                     0.19591837, 0.23826531, 0.24081633, 0.24642857, 0.28520408,\n",
       "                     0.2994898 , 0.30306122, 0.32193878, 0.32857143, 0.33418367,\n",
       "                     0.34132653, 0.34693878, 0.34897959, 0.35714286, 0.36938776,\n",
       "                     0.37346939, 0.37653061, 0.38418367, 0.38979592, 0.39540816,\n",
       "                     0.43010204, 0.43877551, 0.44591837, 0.45663265, 0.46530612,\n",
       "                     0.47040816, 0.48163265, 0.49081633, 0.49489796, 0.53163265,\n",
       "                     0.53979592, 0.5505102 , 0.55816327, 0.56122449, 0.59795918,\n",
       "                     0.60459184, 0.60510204, 0.64489796, 0.64897959, 0.65408163,\n",
       "                     0.71530612, 0.72142857, 0.72295918, 0.72704082, 0.74234694,\n",
       "                     0.74489796, 0.75357143, 0.76071429, 0.76683673, 0.79183673,\n",
       "                     0.79234694, 0.79897959, 0.80255102, 0.81071429, 0.83010204,\n",
       "                     0.83622449, 0.85255102, 0.85612245, 0.86938776, 0.8755102 ,\n",
       "                     0.88061224, 0.88571429, 0.89132653, 0.89285714, 0.89489796,\n",
       "                     0.89795918, 0.90867347, 0.91122449, 0.91734694, 0.91989796,\n",
       "                     0.92091837, 0.92142857, 0.93112245, 0.93316327, 0.93367347,\n",
       "                     0.93877551, 0.94183673, 0.94489796, 0.95255102, 0.95816327,\n",
       "                     0.9622449 , 0.96377551, 0.96377551, 0.96632653, 1.        ]), tpr=array([0.        , 0.01377551, 0.01734694, 0.02091837, 0.02653061,\n",
       "                     0.03163265, 0.03520408, 0.03979592, 0.04591837, 0.0505102 ,\n",
       "                     0.05663265, 0.06428571, 0.06887755, 0.07602041, 0.08520408,\n",
       "                     0.08979592, 0.09438776, 0.10459184, 0.11530612, 0.11836735,\n",
       "                     0.13265306, 0.13673469, 0.16020408, 0.17244898, 0.19285714,\n",
       "                     0.20255102, 0.20816327, 0.21173469, 0.23367347, 0.24030612,\n",
       "                     0.25765306, 0.30714286, 0.31632653, 0.32142857, 0.3627551 ,\n",
       "                     0.37397959, 0.37908163, 0.40102041, 0.41020408, 0.41683673,\n",
       "                     0.42193878, 0.42806122, 0.43163265, 0.4372449 , 0.44387755,\n",
       "                     0.4494898 , 0.45561224, 0.45969388, 0.46173469, 0.46938776,\n",
       "                     0.49795918, 0.50459184, 0.5122449 , 0.52040816, 0.53061224,\n",
       "                     0.53877551, 0.5505102 , 0.5627551 , 0.56785714, 0.60153061,\n",
       "                     0.60918367, 0.61632653, 0.62397959, 0.62755102, 0.65867347,\n",
       "                     0.66479592, 0.66734694, 0.70765306, 0.7122449 , 0.71887755,\n",
       "                     0.77959184, 0.78826531, 0.79132653, 0.79693878, 0.8122449 ,\n",
       "                     0.81734694, 0.8244898 , 0.83163265, 0.83622449, 0.8622449 ,\n",
       "                     0.86428571, 0.86938776, 0.87397959, 0.88214286, 0.89897959,\n",
       "                     0.90408163, 0.92091837, 0.92295918, 0.93316327, 0.93826531,\n",
       "                     0.94591837, 0.94846939, 0.95408163, 0.95459184, 0.95765306,\n",
       "                     0.96122449, 0.96530612, 0.96938776, 0.97244898, 0.9755102 ,\n",
       "                     0.97653061, 0.97704082, 0.98418367, 0.98622449, 0.9872449 ,\n",
       "                     0.98877551, 0.98979592, 0.99132653, 0.99540816, 0.99693878,\n",
       "                     0.99744898, 0.99897959, 0.9994898 , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -2.87682072e-01,\n",
       "                     -3.10154928e-01, -3.36472237e-01, -3.56674944e-01, -3.67724780e-01,\n",
       "                     -4.05465108e-01, -4.41832752e-01, -4.70003629e-01, -5.10825624e-01,\n",
       "                     -5.18793793e-01, -5.38996501e-01, -5.43615447e-01, -5.59615788e-01,\n",
       "                     -5.75364145e-01, -5.87786665e-01, -5.90868331e-01, -6.06135804e-01,\n",
       "                     -6.10909082e-01, -6.28608659e-01, -6.41853886e-01, -6.82218110e-01,\n",
       "                     -6.93147181e-01, -7.19122667e-01, -7.22134717e-01, -7.33969175e-01,\n",
       "                     -7.70108222e-01, -7.98507696e-01, -8.04372816e-01, -8.09784084e-01,\n",
       "                     -8.26678573e-01, -8.32909123e-01, -8.36659462e-01, -8.40783179e-01,\n",
       "                     -8.47297860e-01, -8.63772698e-01, -8.68088630e-01, -8.69037847e-01,\n",
       "                     -8.75468737e-01, -8.82389180e-01, -8.87303195e-01, -9.16290732e-01,\n",
       "                     -9.31558204e-01, -9.34309237e-01, -9.49080555e-01, -9.63437510e-01,\n",
       "                     -9.65080896e-01, -9.80829253e-01, -9.85283603e-01, -1.01856958e+00,\n",
       "                     -1.05121005e+00, -1.06555143e+00, -1.06635143e+00, -1.06686359e+00,\n",
       "                     -1.06919840e+00, -1.07613943e+00, -1.07880966e+00, -1.08334482e+00,\n",
       "                     -1.09861229e+00, -1.12214279e+00, -1.12938395e+00, -1.14513230e+00,\n",
       "                     -1.15181632e+00, -1.15267951e+00, -1.17007125e+00, -1.17962823e+00,\n",
       "                     -1.20397280e+00, -1.21924028e+00, -1.25156177e+00, -1.25276297e+00,\n",
       "                     -1.26224171e+00, -1.26566637e+00, -1.27163145e+00, -1.28785429e+00,\n",
       "                     -1.29276830e+00, -1.31218639e+00, -1.32913595e+00, -1.33603253e+00,\n",
       "                     -1.34373475e+00, -1.36097655e+00, -1.38629436e+00, -1.42019591e+00,\n",
       "                     -1.44691898e+00, -1.45861502e+00, -1.48160454e+00, -1.48538526e+00,\n",
       "                     -1.50407740e+00, -1.50990832e+00, -1.53018854e+00, -1.54756251e+00,\n",
       "                     -1.57239664e+00, -1.60943791e+00, -1.62924054e+00, -1.66500776e+00,\n",
       "                     -1.70474809e+00, -1.74919985e+00, -1.79175947e+00, -1.81237876e+00,\n",
       "                     -1.90954250e+00, -1.94591015e+00, -2.01490302e+00, -2.06369318e+00,\n",
       "                     -2.11021320e+00, -2.12026354e+00, -2.15948425e+00, -2.21101790e+00,\n",
       "                     -2.26868354e+00, -2.32238772e+00, -2.48490665e+00, -2.51230562e+00,\n",
       "                     -3.09104245e+00, -3.13549422e+00, -3.45387764e+01]), auc_score=0.5596288004997918, privacy_risk=0.5413265306122449, accuracy=0.5413265306122449, tpr_ind=0.41683673469387755, tnr_ind=0.6658163265306123, test_train_ratio=1.0, dataset_size=[1960, 1960]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00970874, 0.01379663, 0.01532959, 0.01788452,\n",
       "                     0.0183955 , 0.02095043, 0.02248339, 0.03168114, 0.03168114,\n",
       "                     0.03474706, 0.04956566, 0.05160961, 0.05723045, 0.0592744 ,\n",
       "                     0.06131834, 0.0628513 , 0.06745018, 0.0776699 , 0.1037302 ,\n",
       "                     0.10884006, 0.13234543, 0.13438937, 0.14307614, 0.14767501,\n",
       "                     0.14920797, 0.15380685, 0.15636178, 0.1742463 , 0.19417476,\n",
       "                     0.19519673, 0.19826265, 0.20950434, 0.21410322, 0.24578436,\n",
       "                     0.26877874, 0.27491058, 0.27950945, 0.30556975, 0.30761369,\n",
       "                     0.32089934, 0.32754216, 0.33980583, 0.36535514, 0.36791007,\n",
       "                     0.37506387, 0.38170669, 0.38579458, 0.38988247, 0.43076137,\n",
       "                     0.43536025, 0.45017885, 0.47061829, 0.47470618, 0.48492591,\n",
       "                     0.48748084, 0.49003577, 0.49361267, 0.50332141, 0.51558508,\n",
       "                     0.52682678, 0.53193664, 0.53244762, 0.60960654, 0.61573838,\n",
       "                     0.61982626, 0.6443536 , 0.65150741, 0.65610629, 0.65866122,\n",
       "                     0.65866122, 0.66479305, 0.66785897, 0.67296883, 0.68063362,\n",
       "                     0.74961676, 0.75319366, 0.76341339, 0.76392437, 0.777721  ,\n",
       "                     0.80429228, 0.80684722, 0.81042412, 0.81042412, 0.82422075,\n",
       "                     0.82422075, 0.86561063, 0.87991824, 0.87991824, 0.89064895,\n",
       "                     0.90955544, 0.9146653 , 0.91517629, 0.92079714, 0.92437404,\n",
       "                     0.93357179, 0.93663771, 0.9371487 , 0.94225856, 0.94787941,\n",
       "                     0.94890138, 0.95094532, 0.9555442 , 0.9555442 , 0.96525294,\n",
       "                     0.97189576, 0.97189576, 0.97649463, 1.        ]), tpr=array([0.        , 0.02343352, 0.03005604, 0.03362201, 0.03667855,\n",
       "                     0.03871625, 0.0417728 , 0.04584819, 0.06011207, 0.0606215 ,\n",
       "                     0.06418747, 0.08099847, 0.08456444, 0.0942435 , 0.0962812 ,\n",
       "                     0.09882832, 0.10239429, 0.10748854, 0.11767702, 0.14722364,\n",
       "                     0.15180846, 0.17829852, 0.18441161, 0.19612837, 0.20580744,\n",
       "                     0.20988283, 0.21395823, 0.21803362, 0.2363729 , 0.25878757,\n",
       "                     0.26337239, 0.26999491, 0.276108  , 0.27967397, 0.31635252,\n",
       "                     0.33622007, 0.33927662, 0.34640856, 0.37391747, 0.3764646 ,\n",
       "                     0.38767193, 0.39582272, 0.40499236, 0.43759552, 0.43963321,\n",
       "                     0.44727458, 0.45287825, 0.45695364, 0.45848192, 0.49006623,\n",
       "                     0.49617932, 0.50891493, 0.53234845, 0.53540499, 0.5481406 ,\n",
       "                     0.55272542, 0.55476312, 0.55883851, 0.56597045, 0.57972491,\n",
       "                     0.5919511 , 0.60010188, 0.60213958, 0.68160978, 0.68721345,\n",
       "                     0.69077942, 0.71013754, 0.71625064, 0.71981661, 0.72236373,\n",
       "                     0.72440143, 0.73357106, 0.73713704, 0.74172185, 0.74528782,\n",
       "                     0.80438105, 0.80794702, 0.82068263, 0.8222109 , 0.83036169,\n",
       "                     0.8639837 , 0.86856852, 0.87060621, 0.87213449, 0.88385125,\n",
       "                     0.8848701 , 0.92511462, 0.93530311, 0.93785023, 0.94752929,\n",
       "                     0.95466123, 0.95568008, 0.95568008, 0.9582272 , 0.96077433,\n",
       "                     0.97147224, 0.97554763, 0.97758533, 0.9811513 , 0.98726439,\n",
       "                     0.98828324, 0.98930209, 0.99083036, 0.99133979, 0.99694345,\n",
       "                     0.99847173, 0.99949058, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -7.41079722e-02, -1.33531393e-01,\n",
       "                     -1.54150680e-01, -2.23143551e-01, -2.87682072e-01, -3.18453731e-01,\n",
       "                     -3.64643114e-01, -4.05465108e-01, -4.51985124e-01, -5.10825624e-01,\n",
       "                     -5.38996501e-01, -5.52068582e-01, -5.59615788e-01, -5.87786665e-01,\n",
       "                     -6.19039208e-01, -6.39079959e-01, -6.56779536e-01, -6.93147181e-01,\n",
       "                     -7.17839793e-01, -7.20849783e-01, -7.33969175e-01, -7.35706795e-01,\n",
       "                     -7.44440475e-01, -7.53771802e-01, -7.59105148e-01, -7.73189888e-01,\n",
       "                     -7.78914002e-01, -7.80852761e-01, -7.98507696e-01, -8.00777845e-01,\n",
       "                     -8.10930216e-01, -8.26678573e-01, -8.36248024e-01, -8.44953193e-01,\n",
       "                     -8.47297860e-01, -8.64997437e-01, -8.70828358e-01, -8.75468737e-01,\n",
       "                     -8.79249460e-01, -8.90972924e-01, -9.04456274e-01, -9.10021119e-01,\n",
       "                     -9.16290732e-01, -9.29535959e-01, -9.47381319e-01, -9.66843011e-01,\n",
       "                     -9.80829253e-01, -9.89128056e-01, -1.01160091e+00, -1.03117101e+00,\n",
       "                     -1.06919840e+00, -1.07613943e+00, -1.08518927e+00, -1.09861229e+00,\n",
       "                     -1.13497993e+00, -1.13943428e+00, -1.14306405e+00, -1.14740245e+00,\n",
       "                     -1.15267951e+00, -1.15923691e+00, -1.17865500e+00, -1.18062544e+00,\n",
       "                     -1.18562367e+00, -1.18958407e+00, -1.20660093e+00, -1.22866542e+00,\n",
       "                     -1.23214368e+00, -1.23474446e+00, -1.25276297e+00, -1.25661654e+00,\n",
       "                     -1.26369204e+00, -1.26851133e+00, -1.27296568e+00, -1.29614326e+00,\n",
       "                     -1.29928298e+00, -1.30291275e+00, -1.33500107e+00, -1.33828514e+00,\n",
       "                     -1.36330484e+00, -1.38629436e+00, -1.45861502e+00, -1.46633707e+00,\n",
       "                     -1.46967597e+00, -1.50407740e+00, -1.50548288e+00, -1.53623451e+00,\n",
       "                     -1.54044504e+00, -1.54419739e+00, -1.55059741e+00, -1.58696506e+00,\n",
       "                     -1.60943791e+00, -1.64865863e+00, -1.68639895e+00, -1.73460106e+00,\n",
       "                     -1.79175947e+00, -1.89711998e+00, -1.94591015e+00, -2.02814825e+00,\n",
       "                     -2.07944154e+00, -2.19722458e+00, -2.23359222e+00, -2.25129180e+00,\n",
       "                     -2.29345261e+00, -2.33537492e+00, -2.36712361e+00, -2.48490665e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5567953485938508, privacy_risk=0.536120190827186, accuracy=0.536120190827186, tpr_ind=0.43759551706571576, tnr_ind=0.6346448645886561, test_train_ratio=0.9969434538970963, dataset_size=[1963, 1957]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.01191093, 0.01294666, 0.01760746, 0.01864319,\n",
       "                     0.02433972, 0.02641119, 0.03107198, 0.03935785, 0.04350078,\n",
       "                     0.04557224, 0.04867944, 0.05126877, 0.05592957, 0.06110823,\n",
       "                     0.06835836, 0.07042983, 0.07353703, 0.08700155, 0.11134127,\n",
       "                     0.12532367, 0.14966339, 0.16261005, 0.16519938, 0.17296737,\n",
       "                     0.18436044, 0.1895391 , 0.20870016, 0.21595028, 0.21853962,\n",
       "                     0.23045054, 0.2418436 , 0.26670119, 0.29104091, 0.29414811,\n",
       "                     0.29932677, 0.30088037, 0.3081305 , 0.33454169, 0.34334542,\n",
       "                     0.34697048, 0.35370274, 0.36561367, 0.36561367, 0.39098912,\n",
       "                     0.39254272, 0.39461419, 0.40756085, 0.40859658, 0.41170378,\n",
       "                     0.41532885, 0.41740031, 0.42672191, 0.45572242, 0.45675816,\n",
       "                     0.48368721, 0.48886587, 0.50491973, 0.52097359, 0.54375971,\n",
       "                     0.55256344, 0.57897462, 0.58156396, 0.60383221, 0.60745728,\n",
       "                     0.61367167, 0.61367167, 0.62765407, 0.63956499, 0.64474366,\n",
       "                     0.64992232, 0.66079751, 0.71776282, 0.72242361, 0.72242361,\n",
       "                     0.77162092, 0.77628172, 0.77783532, 0.78146038, 0.79596064,\n",
       "                     0.8089073 , 0.81719316, 0.83013982, 0.83221129, 0.83635422,\n",
       "                     0.83997929, 0.84360435, 0.84567582, 0.86639047, 0.87001554,\n",
       "                     0.87881926, 0.90833765, 0.91610564, 0.91817711, 0.91869498,\n",
       "                     0.91921284, 0.92490937, 0.9290523 , 0.9321595 , 0.95183843,\n",
       "                     0.95390989, 0.95442776, 0.96323149, 0.96633868, 0.96892802,\n",
       "                     0.97151735, 0.97462455, 0.97566028, 0.97773175, 0.97876748,\n",
       "                     1.        ]), tpr=array([0.        , 0.02111614, 0.02362996, 0.02765209, 0.02916038,\n",
       "                     0.03418803, 0.03770739, 0.04223228, 0.05329311, 0.05932629,\n",
       "                     0.06385118, 0.06737054, 0.07340372, 0.0794369 , 0.08496732,\n",
       "                     0.09150327, 0.09602815, 0.10155857, 0.12669683, 0.1618904 ,\n",
       "                     0.18149824, 0.20361991, 0.21719457, 0.22121669, 0.22724987,\n",
       "                     0.2413273 , 0.24937154, 0.26998492, 0.27853193, 0.28054299,\n",
       "                     0.29311212, 0.30015083, 0.3323278 , 0.35394671, 0.35997989,\n",
       "                     0.36551031, 0.36953243, 0.37958773, 0.41628959, 0.43036702,\n",
       "                     0.43489191, 0.44142785, 0.45248869, 0.45299145, 0.47762695,\n",
       "                     0.48014077, 0.48366013, 0.49773756, 0.50226244, 0.5042735 ,\n",
       "                     0.50829563, 0.51181498, 0.52136752, 0.55304173, 0.55555556,\n",
       "                     0.58270488, 0.59074912, 0.60784314, 0.62745098, 0.64655606,\n",
       "                     0.66013072, 0.67420814, 0.67823027, 0.69934641, 0.70135747,\n",
       "                     0.71040724, 0.71141277, 0.73051785, 0.74308698, 0.74962293,\n",
       "                     0.75414781, 0.76822524, 0.80744093, 0.81146305, 0.81297134,\n",
       "                     0.85570639, 0.86224233, 0.86425339, 0.86626445, 0.87983912,\n",
       "                     0.88788336, 0.89341378, 0.90196078, 0.90346908, 0.90849673,\n",
       "                     0.91101056, 0.91553544, 0.91603821, 0.92760181, 0.93112117,\n",
       "                     0.93765711, 0.95475113, 0.95977878, 0.96128708, 0.96229261,\n",
       "                     0.9653092 , 0.97033685, 0.97385621, 0.97586727, 0.99044746,\n",
       "                     0.99145299, 0.99195576, 0.99497235, 0.99597788, 0.99748617,\n",
       "                     0.99798894, 0.99899447, 0.99949723, 1.        , 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -2.23143551e-01,\n",
       "                     -2.87682072e-01, -3.36472237e-01, -3.56674944e-01, -3.67724780e-01,\n",
       "                     -4.05465108e-01, -4.59532329e-01, -4.70003629e-01, -5.38996501e-01,\n",
       "                     -5.59615788e-01, -5.87786665e-01, -6.02175402e-01, -6.06135804e-01,\n",
       "                     -6.35988767e-01, -6.46627165e-01, -6.62687973e-01, -6.85978691e-01,\n",
       "                     -6.93147181e-01, -7.26669873e-01, -7.48938540e-01, -7.53771802e-01,\n",
       "                     -7.56326082e-01, -7.71790308e-01, -7.73189888e-01, -7.75064303e-01,\n",
       "                     -7.77704569e-01, -8.10930216e-01, -8.19440906e-01, -8.26678573e-01,\n",
       "                     -8.38329190e-01, -8.43970070e-01, -8.47297860e-01, -8.60201265e-01,\n",
       "                     -8.64997437e-01, -8.75468737e-01, -8.87935506e-01, -8.90972924e-01,\n",
       "                     -8.93817876e-01, -8.96088025e-01, -8.97941593e-01, -9.16290732e-01,\n",
       "                     -9.36493439e-01, -9.38269639e-01, -9.44461609e-01, -9.65080896e-01,\n",
       "                     -9.80829253e-01, -1.02961942e+00, -1.03407377e+00, -1.04982212e+00,\n",
       "                     -1.05154478e+00, -1.06635143e+00, -1.07044141e+00, -1.07371474e+00,\n",
       "                     -1.07755888e+00, -1.09376966e+00, -1.09861229e+00, -1.10293195e+00,\n",
       "                     -1.11088238e+00, -1.12214279e+00, -1.13943428e+00, -1.15267951e+00,\n",
       "                     -1.17865500e+00, -1.18716569e+00, -1.20397280e+00, -1.20660093e+00,\n",
       "                     -1.21478372e+00, -1.21924028e+00, -1.25276297e+00, -1.26566637e+00,\n",
       "                     -1.27091229e+00, -1.28785429e+00, -1.29928298e+00, -1.30043307e+00,\n",
       "                     -1.30625165e+00, -1.32175584e+00, -1.36524095e+00, -1.37951467e+00,\n",
       "                     -1.38629436e+00, -1.43074612e+00, -1.44345277e+00, -1.46633707e+00,\n",
       "                     -1.48807706e+00, -1.50407740e+00, -1.52242654e+00, -1.60943791e+00,\n",
       "                     -1.64020957e+00, -1.66500776e+00, -1.68089688e+00, -1.70474809e+00,\n",
       "                     -1.74046617e+00, -1.79175947e+00, -1.87180218e+00, -1.89085037e+00,\n",
       "                     -1.90616982e+00, -1.94591015e+00, -1.96944065e+00, -1.97275740e+00,\n",
       "                     -2.07944154e+00, -2.14006616e+00, -2.14843441e+00, -2.30258509e+00,\n",
       "                     -2.33537492e+00, -2.51230562e+00, -2.56494936e+00, -2.63905733e+00,\n",
       "                     -3.36729583e+00, -3.82864140e+00, -3.45387764e+01]), auc_score=0.570926736095652, privacy_risk=0.5537836401607078, accuracy=0.5537836401607078, tpr_ind=0.6601307189542484, tnr_ind=0.44743656136716725, test_train_ratio=0.9708396178984414, dataset_size=[1989, 1931]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.01267829, 0.01690438, 0.01901743, 0.02588484,\n",
       "                     0.0264131 , 0.03116746, 0.03539356, 0.05176968, 0.05493925,\n",
       "                     0.06127839, 0.06444797, 0.07659799, 0.07871104, 0.08240887,\n",
       "                     0.08610671, 0.09138933, 0.0945589 , 0.10618067, 0.13100898,\n",
       "                     0.1362916 , 0.13734812, 0.13893291, 0.14632858, 0.1669308 ,\n",
       "                     0.16904385, 0.19756999, 0.20655045, 0.21500264, 0.28631801,\n",
       "                     0.29107237, 0.31378764, 0.31801373, 0.32382462, 0.32593767,\n",
       "                     0.36767036, 0.37876387, 0.40042261, 0.4131009 , 0.42102483,\n",
       "                     0.43211833, 0.43792921, 0.43898574, 0.45747491, 0.48652932,\n",
       "                     0.50554675, 0.51082937, 0.52086635, 0.53354464, 0.53460116,\n",
       "                     0.54675119, 0.55837295, 0.57950343, 0.58214474, 0.58637084,\n",
       "                     0.60591653, 0.66719493, 0.6703645 , 0.68251453, 0.71473851,\n",
       "                     0.73534073, 0.7385103 , 0.73956683, 0.74537771, 0.76069731,\n",
       "                     0.7649234 , 0.76809297, 0.77231907, 0.7760169 , 0.78499736,\n",
       "                     0.79926043, 0.80401479, 0.80507132, 0.85736926, 0.86529319,\n",
       "                     0.86634971, 0.879028  , 0.88061278, 0.88959324, 0.89381933,\n",
       "                     0.89804543, 0.91442155, 0.93079768, 0.94030639, 0.94981511,\n",
       "                     0.95034337, 0.95087163, 0.95192816, 0.95509773, 0.95668251,\n",
       "                     0.95879556, 0.95985209, 0.96038035, 0.96354992, 0.96513471,\n",
       "                     0.97411516, 0.97517169, 1.        ]), tpr=array([0.        , 0.02170696, 0.02812037, 0.03108041, 0.04292057,\n",
       "                     0.04538727, 0.04884065, 0.05525407, 0.07005427, 0.07992107,\n",
       "                     0.09225456, 0.10064134, 0.1124815 , 0.1174149 , 0.12037494,\n",
       "                     0.124815  , 0.1297484 , 0.13665516, 0.14849531, 0.18204243,\n",
       "                     0.18845585, 0.19240257, 0.1953626 , 0.21114948, 0.22644302,\n",
       "                     0.22890972, 0.25555007, 0.26788357, 0.27824371, 0.36408485,\n",
       "                     0.36951159, 0.39763197, 0.40157869, 0.41095215, 0.41243217,\n",
       "                     0.4474593 , 0.45880612, 0.47557967, 0.48741983, 0.49531327,\n",
       "                     0.50320671, 0.50863345, 0.51011347, 0.52540701, 0.5648742 ,\n",
       "                     0.58164776, 0.58362111, 0.59200789, 0.60878145, 0.61272817,\n",
       "                     0.62506167, 0.63887519, 0.66156882, 0.66600888, 0.67291564,\n",
       "                     0.69708929, 0.74790331, 0.75037   , 0.77059694, 0.7972373 ,\n",
       "                     0.81549087, 0.81795757, 0.82091761, 0.82338431, 0.84015787,\n",
       "                     0.84213123, 0.84509127, 0.84854465, 0.85101135, 0.86087815,\n",
       "                     0.87074494, 0.8776517 , 0.8801184 , 0.92402565, 0.92994573,\n",
       "                     0.93241243, 0.93931919, 0.94030587, 0.94573261, 0.95362605,\n",
       "                     0.95510607, 0.97089295, 0.98075974, 0.98618648, 0.98865318,\n",
       "                     0.98963986, 0.99161322, 0.99210656, 0.99309324, 0.99358658,\n",
       "                     0.99457326, 0.99457326, 0.9950666 , 0.99654662, 0.9975333 ,\n",
       "                     0.99901332, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.43100844e-01, -1.54150680e-01,\n",
       "                     -3.18453731e-01, -3.36472237e-01, -3.56674944e-01, -3.79489622e-01,\n",
       "                     -4.05465108e-01, -4.70003629e-01, -5.18793793e-01, -5.44727175e-01,\n",
       "                     -5.59615788e-01, -5.87786665e-01, -6.06135804e-01, -6.35988767e-01,\n",
       "                     -6.41853886e-01, -6.56779536e-01, -6.80243776e-01, -6.93147181e-01,\n",
       "                     -7.41937345e-01, -7.53771802e-01, -7.73189888e-01, -7.82759339e-01,\n",
       "                     -7.86965936e-01, -7.88457360e-01, -8.13396309e-01, -8.42678915e-01,\n",
       "                     -8.47297860e-01, -8.48210269e-01, -8.57450232e-01, -8.76929658e-01,\n",
       "                     -8.87303195e-01, -8.90972924e-01, -9.16290732e-01, -9.18059079e-01,\n",
       "                     -9.21681581e-01, -9.27986772e-01, -9.49080555e-01, -9.57533690e-01,\n",
       "                     -9.65080896e-01, -9.69400557e-01, -9.80829253e-01, -9.84853403e-01,\n",
       "                     -9.93251773e-01, -1.00623897e+00, -1.01160091e+00, -1.01405490e+00,\n",
       "                     -1.01693426e+00, -1.02961942e+00, -1.05736933e+00, -1.09861229e+00,\n",
       "                     -1.14725410e+00, -1.15267951e+00, -1.16315081e+00, -1.20192990e+00,\n",
       "                     -1.22320417e+00, -1.22377543e+00, -1.22807036e+00, -1.22897411e+00,\n",
       "                     -1.24111235e+00, -1.25276297e+00, -1.29928298e+00, -1.30833282e+00,\n",
       "                     -1.30992138e+00, -1.32175584e+00, -1.32913595e+00, -1.33500107e+00,\n",
       "                     -1.34707365e+00, -1.34807315e+00, -1.37371558e+00, -1.38629436e+00,\n",
       "                     -1.43508453e+00, -1.46720100e+00, -1.52242654e+00, -1.52605630e+00,\n",
       "                     -1.58045038e+00, -1.60943791e+00, -1.62745642e+00, -1.65388968e+00,\n",
       "                     -1.67397643e+00, -1.69459572e+00, -1.79175947e+00, -1.83621123e+00,\n",
       "                     -1.85629799e+00, -1.94591015e+00, -2.04769284e+00, -2.07944154e+00,\n",
       "                     -2.19722458e+00, -2.30258509e+00, -2.39789527e+00, -2.48490665e+00,\n",
       "                     -2.56494936e+00, -2.67414865e+00, -2.83321334e+00, -2.89827694e+00,\n",
       "                     -2.89958841e+00, -3.45387764e+01]), auc_score=0.5652313680787446, privacy_risk=0.5455863799613824, accuracy=0.5455863799613824, tpr_ind=0.697089294523927, tnr_ind=0.3940834653988378, test_train_ratio=0.9338924518993587, dataset_size=[2027, 1893]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00509944, 0.00611933, 0.01019888, 0.01223865,\n",
       "                     0.01376849, 0.01886792, 0.02192759, 0.02600714, 0.03008669,\n",
       "                     0.03059663, 0.03263641, 0.03671596, 0.03773585, 0.04487506,\n",
       "                     0.04691484, 0.05150433, 0.05354411, 0.05711372, 0.06476288,\n",
       "                     0.10351861, 0.11830699, 0.12697603, 0.13768485, 0.14023457,\n",
       "                     0.14278429, 0.15553289, 0.16012239, 0.18204997, 0.19224885,\n",
       "                     0.20040796, 0.20244773, 0.209077  , 0.22794493, 0.25038246,\n",
       "                     0.25140235, 0.27078021, 0.29882713, 0.30698623, 0.31616522,\n",
       "                     0.34472208, 0.34931158, 0.40642529, 0.40948496, 0.44518103,\n",
       "                     0.44773075, 0.46251912, 0.46251912, 0.47220806, 0.4854666 ,\n",
       "                     0.49566548, 0.50076492, 0.50841407, 0.51657318, 0.51861295,\n",
       "                     0.52524222, 0.53187149, 0.5400306 , 0.54258032, 0.63539011,\n",
       "                     0.64609893, 0.66292708, 0.66802652, 0.67771545, 0.6863845 ,\n",
       "                     0.69148394, 0.70474248, 0.70780214, 0.71086181, 0.7200408 ,\n",
       "                     0.7236104 , 0.7445181 , 0.75879653, 0.77409485, 0.78480367,\n",
       "                     0.80112188, 0.8072412 , 0.81132075, 0.81489036, 0.84956655,\n",
       "                     0.8618052 , 0.87302397, 0.89291178, 0.90617032, 0.90973993,\n",
       "                     0.91126976, 0.91840898, 0.91891892, 0.92044875, 0.92248853,\n",
       "                     0.92605813, 0.92860785, 0.92860785, 0.93013768, 0.93574707,\n",
       "                     0.93676696, 0.93676696, 0.94288628, 0.94798572, 0.94849567,\n",
       "                     0.94849567, 0.9500255 , 0.95104539, 0.95308516, 0.95410505,\n",
       "                     0.95614482, 1.        ]), tpr=array([0.        , 0.01888719, 0.0229709 , 0.02960694, 0.03215926,\n",
       "                     0.03624298, 0.04389995, 0.04798367, 0.05513017, 0.06125574,\n",
       "                     0.06584992, 0.06942318, 0.0719755 , 0.07350689, 0.07861154,\n",
       "                     0.07963247, 0.08728943, 0.09035222, 0.09392547, 0.10515569,\n",
       "                     0.15313936, 0.1740684 , 0.18172537, 0.19295559, 0.19703931,\n",
       "                     0.20010209, 0.21184278, 0.21898928, 0.24144972, 0.2531904 ,\n",
       "                     0.25829505, 0.26391016, 0.27309852, 0.30525778, 0.33486473,\n",
       "                     0.33792751, 0.35783563, 0.39101582, 0.39918326, 0.40837162,\n",
       "                     0.42930066, 0.4359367 , 0.49004594, 0.49157734, 0.52935171,\n",
       "                     0.53343543, 0.54619704, 0.54874936, 0.55844819, 0.56865748,\n",
       "                     0.58192956, 0.59111792, 0.59724349, 0.60745278, 0.6115365 ,\n",
       "                     0.61459929, 0.62072486, 0.63042369, 0.63246554, 0.72281776,\n",
       "                     0.73404798, 0.75242471, 0.75497703, 0.76875957, 0.78407351,\n",
       "                     0.79173047, 0.81214906, 0.81470138, 0.81980602, 0.82797346,\n",
       "                     0.83052578, 0.84839204, 0.86574783, 0.87493619, 0.88361409,\n",
       "                     0.89484431, 0.89943849, 0.90352221, 0.90658499, 0.92700357,\n",
       "                     0.93925472, 0.94946401, 0.96426748, 0.96886166, 0.97141399,\n",
       "                     0.97345584, 0.97856049, 0.97958142, 0.98315467, 0.9841756 ,\n",
       "                     0.98570699, 0.98621746, 0.98723839, 0.98774885, 0.99081164,\n",
       "                     0.99183257, 0.99234303, 0.99387443, 0.99591628, 0.99642675,\n",
       "                     0.99744768, 0.99846861, 0.99846861, 0.99948954, 1.        ,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.17783036e-01, -1.43100844e-01,\n",
       "                     -1.82321557e-01, -2.23143551e-01, -2.87682072e-01, -3.18453731e-01,\n",
       "                     -4.05465108e-01, -4.21213465e-01, -4.41832752e-01, -4.51985124e-01,\n",
       "                     -4.70003629e-01, -5.10825624e-01, -5.30628251e-01, -5.59615788e-01,\n",
       "                     -5.87786665e-01, -6.06135804e-01, -6.19039208e-01, -6.45137961e-01,\n",
       "                     -6.93147181e-01, -7.05268541e-01, -7.23918839e-01, -7.48062938e-01,\n",
       "                     -7.53771802e-01, -7.73189888e-01, -8.08660068e-01, -8.26678573e-01,\n",
       "                     -8.30930883e-01, -8.34797698e-01, -8.47297860e-01, -8.60201265e-01,\n",
       "                     -8.70828358e-01, -8.74145110e-01, -8.85950015e-01, -8.87303195e-01,\n",
       "                     -8.90315245e-01, -9.16290732e-01, -9.32820034e-01, -9.38269639e-01,\n",
       "                     -9.59256768e-01, -9.61411167e-01, -9.66276639e-01, -9.80829253e-01,\n",
       "                     -1.00914089e+00, -1.01160091e+00, -1.01523068e+00, -1.02961942e+00,\n",
       "                     -1.03609193e+00, -1.04731899e+00, -1.07263680e+00, -1.07992016e+00,\n",
       "                     -1.09861229e+00, -1.11088238e+00, -1.13943428e+00, -1.15267951e+00,\n",
       "                     -1.17865500e+00, -1.18269541e+00, -1.20397280e+00, -1.20566628e+00,\n",
       "                     -1.21302264e+00, -1.22050211e+00, -1.22377543e+00, -1.22595171e+00,\n",
       "                     -1.24319352e+00, -1.25276297e+00, -1.26694760e+00, -1.28093385e+00,\n",
       "                     -1.29928298e+00, -1.32175584e+00, -1.33500107e+00, -1.35314215e+00,\n",
       "                     -1.38629436e+00, -1.40008768e+00, -1.41528190e+00, -1.41981705e+00,\n",
       "                     -1.43508453e+00, -1.44691898e+00, -1.46633707e+00, -1.47017585e+00,\n",
       "                     -1.56523182e+00, -1.58777642e+00, -1.59554880e+00, -1.60943791e+00,\n",
       "                     -1.68639895e+00, -1.69167601e+00, -1.73911574e+00, -1.79175947e+00,\n",
       "                     -1.81528997e+00, -1.84582669e+00, -1.87180218e+00, -1.94591015e+00,\n",
       "                     -2.00148000e+00, -2.07944154e+00, -2.10006083e+00, -2.12026354e+00,\n",
       "                     -2.14006616e+00, -2.15948425e+00, -2.16905370e+00, -2.30258509e+00,\n",
       "                     -2.56494936e+00, -2.77258872e+00, -2.83321334e+00, -2.89037176e+00,\n",
       "                     -3.09104245e+00, -3.29583687e+00, -3.45387764e+01]), auc_score=0.5749905182711678, privacy_risk=0.55447210913997, accuracy=0.55447210913997, tpr_ind=0.819806023481368, tnr_ind=0.28913819479857217, test_train_ratio=1.0010209290454313, dataset_size=[1959, 1961]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00513084, 0.006157  , 0.00769625, 0.01180092,\n",
       "                     0.01436634, 0.02052335, 0.02565418, 0.02719343, 0.02873268,\n",
       "                     0.03232427, 0.04104669, 0.04925603, 0.05438687, 0.05746537,\n",
       "                     0.06618779, 0.07080554, 0.08055413, 0.08414572, 0.08619805,\n",
       "                     0.09902514, 0.15854284, 0.15956901, 0.17906619, 0.21498204,\n",
       "                     0.22319138, 0.23242689, 0.24781939, 0.26423807, 0.26936891,\n",
       "                     0.27347358, 0.27603899, 0.28630067, 0.28783992, 0.30374551,\n",
       "                     0.30425859, 0.30682401, 0.31862494, 0.32119035, 0.33093894,\n",
       "                     0.35402771, 0.36018471, 0.38429964, 0.38943048, 0.3950744 ,\n",
       "                     0.40584915, 0.40944074, 0.41354541, 0.4263725 , 0.43919959,\n",
       "                     0.45920985, 0.47306311, 0.52231914, 0.5454079 , 0.54694715,\n",
       "                     0.57773217, 0.58542842, 0.58799384, 0.61364802, 0.62801437,\n",
       "                     0.64391996, 0.66803489, 0.67829656, 0.67983581, 0.72190867,\n",
       "                     0.7367881 , 0.7429451 , 0.75012827, 0.75885069, 0.79374038,\n",
       "                     0.80400205, 0.80656747, 0.81118522, 0.85017958, 0.85633658,\n",
       "                     0.86095434, 0.87275526, 0.87737301, 0.8778861 , 0.8778861 ,\n",
       "                     0.8902001 , 0.89892252, 0.9061057 , 0.92047204, 0.92252437,\n",
       "                     0.93689071, 0.93945613, 0.94304772, 0.94407388, 0.94407388,\n",
       "                     0.95125705, 0.95433556, 0.95638789, 0.96254489, 0.96511031,\n",
       "                     0.9656234 , 0.96664956, 0.97024115, 0.97075423, 0.97280657,\n",
       "                     0.97691124, 0.97742432, 1.        ]), tpr=array([0.        , 0.01471334, 0.0187722 , 0.02080162, 0.02232369,\n",
       "                     0.02638255, 0.03094876, 0.03805175, 0.04160325, 0.04414003,\n",
       "                     0.05124302, 0.0608828 , 0.072552  , 0.07864028, 0.08269914,\n",
       "                     0.09741248, 0.10400812, 0.11212582, 0.11567732, 0.11872146,\n",
       "                     0.1334348 , 0.20700152, 0.20852359, 0.22983257, 0.26686961,\n",
       "                     0.27092846, 0.27803146, 0.29477423, 0.3079655 , 0.31709792,\n",
       "                     0.3196347 , 0.32927448, 0.34145104, 0.34297311, 0.35971588,\n",
       "                     0.36073059, 0.36681887, 0.384069  , 0.3876205 , 0.39776763,\n",
       "                     0.42415018, 0.42922374, 0.45459158, 0.46524607, 0.46981228,\n",
       "                     0.48401826, 0.48858447, 0.49213597, 0.50532725, 0.51801116,\n",
       "                     0.53881279, 0.55454084, 0.59411466, 0.62557078, 0.62658549,\n",
       "                     0.64586504, 0.65651953, 0.66057839, 0.68239472, 0.69863014,\n",
       "                     0.7224759 , 0.74530695, 0.76255708, 0.76610857, 0.79756469,\n",
       "                     0.80872653, 0.81481481, 0.82699137, 0.83054287, 0.86453577,\n",
       "                     0.87062405, 0.87519026, 0.87874176, 0.90309488, 0.9086758 ,\n",
       "                     0.91374937, 0.92186707, 0.92338914, 0.92694064, 0.927448  ,\n",
       "                     0.93810249, 0.94571284, 0.95027905, 0.95687468, 0.95839675,\n",
       "                     0.97209538, 0.97463217, 0.97666159, 0.97666159, 0.97716895,\n",
       "                     0.98072045, 0.98325723, 0.98376459, 0.99086758, 0.99340436,\n",
       "                     0.99391172, 0.99441908, 0.99492643, 0.99594115, 0.99949264,\n",
       "                     1.        , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.17783036e-01, -2.23143551e-01,\n",
       "                     -2.87682072e-01, -3.18453731e-01, -3.67724780e-01, -4.05465108e-01,\n",
       "                     -4.51985124e-01, -4.70003629e-01, -4.96436886e-01, -5.10825624e-01,\n",
       "                     -5.38996501e-01, -5.59615788e-01, -5.87786665e-01, -6.93147181e-01,\n",
       "                     -7.29514825e-01, -7.53771802e-01, -7.62140052e-01, -7.73189888e-01,\n",
       "                     -7.77028665e-01, -7.80852761e-01, -7.88457360e-01, -7.94929875e-01,\n",
       "                     -8.06806499e-01, -8.10930216e-01, -8.19440906e-01, -8.20980552e-01,\n",
       "                     -8.28066498e-01, -8.71838969e-01, -8.75468737e-01, -8.87303195e-01,\n",
       "                     -8.89262059e-01, -8.93817876e-01, -9.00786545e-01, -9.16290732e-01,\n",
       "                     -9.40983344e-01, -9.50976290e-01, -9.61411167e-01, -9.65080896e-01,\n",
       "                     -9.73178106e-01, -9.80829253e-01, -1.00169439e+00, -1.01592057e+00,\n",
       "                     -1.02961942e+00, -1.04380405e+00, -1.05314991e+00, -1.05605267e+00,\n",
       "                     -1.07263680e+00, -1.07451474e+00, -1.08536706e+00, -1.09861229e+00,\n",
       "                     -1.10712298e+00, -1.13036099e+00, -1.14513230e+00, -1.15780116e+00,\n",
       "                     -1.16760516e+00, -1.17865500e+00, -1.18755977e+00, -1.19770319e+00,\n",
       "                     -1.21010779e+00, -1.21721803e+00, -1.21857160e+00, -1.28785429e+00,\n",
       "                     -1.29700767e+00, -1.30340670e+00, -1.30833282e+00, -1.31094492e+00,\n",
       "                     -1.32175584e+00, -1.32869687e+00, -1.35239281e+00, -1.35812348e+00,\n",
       "                     -1.38629436e+00, -1.39953959e+00, -1.42403469e+00, -1.50407740e+00,\n",
       "                     -1.51787072e+00, -1.54044504e+00, -1.55059741e+00, -1.55814462e+00,\n",
       "                     -1.56064775e+00, -1.58240924e+00, -1.60943791e+00, -1.66500776e+00,\n",
       "                     -1.67397643e+00, -1.69845876e+00, -1.72276660e+00, -1.83258146e+00,\n",
       "                     -1.87180218e+00, -1.94591015e+00, -2.03432111e+00, -2.07944154e+00,\n",
       "                     -2.12026354e+00, -2.13470422e+00, -2.15176220e+00, -2.19722458e+00,\n",
       "                     -2.30258509e+00, -2.39789527e+00, -2.54553127e+00, -2.66025954e+00,\n",
       "                     -2.89037176e+00, -3.42936826e+00, -3.45387764e+01]), auc_score=0.5573106087525143, privacy_risk=0.5431363805450973, accuracy=0.5431363805450973, tpr_ind=0.7661085743277524, tnr_ind=0.3201641867624423, test_train_ratio=0.9888381532217149, dataset_size=[1971, 1949]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.01049318, 0.01259182, 0.01364113, 0.01469045,\n",
       "                     0.01573977, 0.01731375, 0.02675761, 0.02990556, 0.03672613,\n",
       "                     0.04144806, 0.0524659 , 0.05456453, 0.05561385, 0.05718783,\n",
       "                     0.06243442, 0.08814271, 0.11962225, 0.15110178, 0.15267576,\n",
       "                     0.15582371, 0.15687303, 0.17366212, 0.17576076, 0.18520462,\n",
       "                     0.2775446 , 0.29328437, 0.30272823, 0.31794334, 0.32686254,\n",
       "                     0.35624344, 0.36358867, 0.36621196, 0.38142707, 0.39401889,\n",
       "                     0.40346275, 0.41238195, 0.42392445, 0.44648478, 0.46956978,\n",
       "                     0.47219307, 0.47586569, 0.49317943, 0.5       , 0.50944386,\n",
       "                     0.51783841, 0.53095488, 0.53934942, 0.54459601, 0.5613851 ,\n",
       "                     0.56610703, 0.58394544, 0.59391396, 0.73347324, 0.7429171 ,\n",
       "                     0.74658972, 0.75550892, 0.76547744, 0.76810073, 0.77229801,\n",
       "                     0.78436516, 0.81374607, 0.83053515, 0.86778594, 0.88405037,\n",
       "                     0.88982162, 0.89034627, 0.89296957, 0.8976915 , 0.89979014,\n",
       "                     0.90870934, 0.91972718, 0.92235047, 0.93231899, 0.94018888,\n",
       "                     0.94491081, 0.94805876, 0.95278069, 0.95697796, 0.95802728,\n",
       "                     0.96274921, 0.96327387, 0.96327387, 0.96537251, 0.97114376,\n",
       "                     0.97114376, 0.97166842, 0.97324239, 0.97534103, 1.        ]), tpr=array([0.        , 0.0183714 , 0.02135055, 0.02333664, 0.02482622,\n",
       "                     0.03028798, 0.0347567 , 0.04816286, 0.05064548, 0.05461768,\n",
       "                     0.06156902, 0.07298908, 0.0774578 , 0.07994042, 0.08291956,\n",
       "                     0.091857  , 0.12214499, 0.15988083, 0.19463754, 0.19860973,\n",
       "                     0.2040715 , 0.20854022, 0.22740814, 0.23138034, 0.24528302,\n",
       "                     0.32274081, 0.33515392, 0.34607746, 0.36395233, 0.37586892,\n",
       "                     0.41161867, 0.41708044, 0.41956306, 0.4409136 , 0.45332671,\n",
       "                     0.46971202, 0.47616683, 0.48709037, 0.50943396, 0.53723932,\n",
       "                     0.53972195, 0.54518371, 0.55610725, 0.56107249, 0.5734856 ,\n",
       "                     0.58242304, 0.59483615, 0.60029791, 0.60774578, 0.62015889,\n",
       "                     0.62562066, 0.6469712 , 0.65292949, 0.80238332, 0.8123138 ,\n",
       "                     0.816286  , 0.82820258, 0.83366435, 0.83614697, 0.84011917,\n",
       "                     0.8510427 , 0.87686197, 0.88927507, 0.92055611, 0.93346574,\n",
       "                     0.93743793, 0.93793446, 0.94041708, 0.9428997 , 0.94587885,\n",
       "                     0.95531281, 0.96226415, 0.96474677, 0.96921549, 0.97169811,\n",
       "                     0.97368421, 0.97666336, 0.98113208, 0.98808342, 0.98857994,\n",
       "                     0.99205561, 0.99255214, 0.99453823, 0.99602781, 0.99751738,\n",
       "                     0.9980139 , 0.99851043, 0.99950348, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.54150680e-01, -2.23143551e-01,\n",
       "                     -2.87682072e-01, -3.10154928e-01, -3.13657559e-01, -3.15081047e-01,\n",
       "                     -3.36472237e-01, -4.05465108e-01, -4.51985124e-01, -5.59615788e-01,\n",
       "                     -5.75364145e-01, -5.87786665e-01, -6.06135804e-01, -6.64976304e-01,\n",
       "                     -6.72944473e-01, -6.93147181e-01, -7.45593656e-01, -7.53771802e-01,\n",
       "                     -7.80158558e-01, -8.04372816e-01, -8.16761137e-01, -8.60201265e-01,\n",
       "                     -8.67100488e-01, -8.73450573e-01, -8.78550404e-01, -8.79249460e-01,\n",
       "                     -8.99196299e-01, -9.16290732e-01, -9.27340568e-01, -9.34309237e-01,\n",
       "                     -9.55511445e-01, -9.66187703e-01, -9.68737207e-01, -9.80829253e-01,\n",
       "                     -9.90398704e-01, -1.01345448e+00, -1.01419495e+00, -1.02450432e+00,\n",
       "                     -1.02961942e+00, -1.03609193e+00, -1.04731899e+00, -1.06471074e+00,\n",
       "                     -1.07535543e+00, -1.07880966e+00, -1.09218140e+00, -1.09861229e+00,\n",
       "                     -1.11923158e+00, -1.12492960e+00, -1.12846525e+00, -1.13140211e+00,\n",
       "                     -1.15267951e+00, -1.18451563e+00, -1.20397280e+00, -1.22722967e+00,\n",
       "                     -1.22866542e+00, -1.27766052e+00, -1.34992672e+00, -1.37230812e+00,\n",
       "                     -1.37486567e+00, -1.38629436e+00, -1.39341183e+00, -1.41754690e+00,\n",
       "                     -1.44238383e+00, -1.50407740e+00, -1.55059741e+00, -1.55814462e+00,\n",
       "                     -1.56218503e+00, -1.60943791e+00, -1.65595793e+00, -1.71297859e+00,\n",
       "                     -1.72276660e+00, -1.79175947e+00, -1.82454929e+00, -1.83258146e+00,\n",
       "                     -1.84582669e+00, -1.86214027e+00, -1.89184293e+00, -1.94591015e+00,\n",
       "                     -2.18122424e+00, -2.35137526e+00, -2.42036813e+00, -2.45100510e+00,\n",
       "                     -2.59026717e+00, -2.77258872e+00, -3.17805383e+00, -3.29583687e+00,\n",
       "                     -3.85014760e+00, -3.45387764e+01]), auc_score=0.5516101351400635, privacy_risk=0.536346831361998, accuracy=0.536346831361998, tpr_ind=0.8282025819265144, tnr_ind=0.24449108079748164, test_train_ratio=0.9463753723932473, dataset_size=[2014, 1906]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00977366, 0.0154321 , 0.01697531, 0.02006173,\n",
       "                     0.02211934, 0.0313786 , 0.03497942, 0.03600823, 0.04063786,\n",
       "                     0.04475309, 0.05092593, 0.05504115, 0.0622428 , 0.06790123,\n",
       "                     0.06944444, 0.07458848, 0.08333333, 0.08487654, 0.08641975,\n",
       "                     0.09156379, 0.09876543, 0.11831276, 0.12397119, 0.12654321,\n",
       "                     0.14300412, 0.15534979, 0.15895062, 0.16666667, 0.1718107 ,\n",
       "                     0.17541152, 0.19238683, 0.19753086, 0.20113169, 0.22685185,\n",
       "                     0.23302469, 0.23816872, 0.29063786, 0.2973251 , 0.30092593,\n",
       "                     0.3904321 , 0.39917695, 0.40277778, 0.40534979, 0.41820988,\n",
       "                     0.42283951, 0.46296296, 0.47016461, 0.47273663, 0.47427984,\n",
       "                     0.47839506, 0.48199588, 0.4845679 , 0.48765432, 0.49434156,\n",
       "                     0.51388889, 0.52109053, 0.56121399, 0.56532922, 0.60493827,\n",
       "                     0.61728395, 0.63014403, 0.63014403, 0.64197531, 0.6558642 ,\n",
       "                     0.66203704, 0.66820988, 0.66923868, 0.67335391, 0.67746914,\n",
       "                     0.68569959, 0.69650206, 0.72273663, 0.72325103, 0.73559671,\n",
       "                     0.74125514, 0.75977366, 0.76646091, 0.78497942, 0.78703704,\n",
       "                     0.79063786, 0.81018519, 0.81069959, 0.81841564, 0.81893004,\n",
       "                     0.83024691, 0.83693416, 0.83796296, 0.84156379, 0.8436214 ,\n",
       "                     0.86625514, 0.91409465, 0.92592593, 0.92952675, 0.93158436,\n",
       "                     0.93261317, 0.9377572 , 0.94135802, 0.94701646, 0.94804527,\n",
       "                     0.9531893 , 0.95421811, 0.96244856, 0.96450617, 0.97582305,\n",
       "                     0.98148148, 0.98148148, 0.98199588, 0.98353909, 0.9840535 ,\n",
       "                     1.        ]), tpr=array([0.        , 0.02125506, 0.02631579, 0.0298583 , 0.03441296,\n",
       "                     0.03947368, 0.0465587 , 0.05364372, 0.05617409, 0.06680162,\n",
       "                     0.07287449, 0.07894737, 0.08704453, 0.09716599, 0.10526316,\n",
       "                     0.10981781, 0.11487854, 0.125     , 0.12803644, 0.13157895,\n",
       "                     0.13562753, 0.14524291, 0.17004049, 0.17661943, 0.1791498 ,\n",
       "                     0.19433198, 0.20647773, 0.20951417, 0.21963563, 0.22874494,\n",
       "                     0.23076923, 0.24848178, 0.25151822, 0.25506073, 0.28087045,\n",
       "                     0.28694332, 0.29251012, 0.35475709, 0.36184211, 0.36639676,\n",
       "                     0.4534413 , 0.46659919, 0.47165992, 0.47419028, 0.49190283,\n",
       "                     0.49746964, 0.52580972, 0.53441296, 0.53593117, 0.53947368,\n",
       "                     0.5465587 , 0.55161943, 0.55617409, 0.56022267, 0.56680162,\n",
       "                     0.58299595, 0.59159919, 0.63815789, 0.64423077, 0.67965587,\n",
       "                     0.69078947, 0.70394737, 0.70698381, 0.71609312, 0.72823887,\n",
       "                     0.73026316, 0.73481781, 0.73633603, 0.74038462, 0.74493927,\n",
       "                     0.75607287, 0.76973684, 0.79048583, 0.79149798, 0.80819838,\n",
       "                     0.81325911, 0.826417  , 0.83502024, 0.84767206, 0.85172065,\n",
       "                     0.8562753 , 0.87348178, 0.87449393, 0.88006073, 0.88107287,\n",
       "                     0.89119433, 0.89676113, 0.89827935, 0.90030364, 0.90182186,\n",
       "                     0.92004049, 0.95091093, 0.9590081 , 0.96356275, 0.96558704,\n",
       "                     0.96659919, 0.96963563, 0.97165992, 0.97823887, 0.97925101,\n",
       "                     0.9812753 , 0.9832996 , 0.98734818, 0.98734818, 0.99696356,\n",
       "                     0.99898785, 0.99949393, 1.        , 1.        , 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.82321557e-01, -2.51314428e-01,\n",
       "                     -2.87682072e-01, -3.36472237e-01, -3.56674944e-01, -4.05465108e-01,\n",
       "                     -4.70003629e-01, -4.81838087e-01, -5.02091944e-01, -5.10825624e-01,\n",
       "                     -5.23248144e-01, -5.30628251e-01, -5.50046337e-01, -5.70544858e-01,\n",
       "                     -5.87786665e-01, -5.99621123e-01, -6.06135804e-01, -6.19039208e-01,\n",
       "                     -6.61398482e-01, -6.80877088e-01, -6.93147181e-01, -7.14653386e-01,\n",
       "                     -7.47214402e-01, -7.51416089e-01, -7.53771802e-01, -7.73189888e-01,\n",
       "                     -7.88457360e-01, -7.98507696e-01, -8.10930216e-01, -8.14099791e-01,\n",
       "                     -8.20980552e-01, -8.26678573e-01, -8.38858992e-01, -8.47297860e-01,\n",
       "                     -8.60201265e-01, -8.88259218e-01, -8.89857475e-01, -8.93817876e-01,\n",
       "                     -8.95138357e-01, -9.00786545e-01, -9.16290732e-01, -9.34309237e-01,\n",
       "                     -9.44461609e-01, -9.69400557e-01, -9.71860583e-01, -9.73449146e-01,\n",
       "                     -9.80829253e-01, -9.98528830e-01, -1.02450432e+00, -1.02961942e+00,\n",
       "                     -1.04731899e+00, -1.05939158e+00, -1.06635143e+00, -1.08221848e+00,\n",
       "                     -1.08570888e+00, -1.09861229e+00, -1.13822143e+00, -1.14057649e+00,\n",
       "                     -1.14595841e+00, -1.16315081e+00, -1.16760516e+00, -1.17007125e+00,\n",
       "                     -1.17865500e+00, -1.18958407e+00, -1.19392247e+00, -1.20397280e+00,\n",
       "                     -1.20831121e+00, -1.23676263e+00, -1.23969089e+00, -1.24745792e+00,\n",
       "                     -1.24927256e+00, -1.25276297e+00, -1.27417706e+00, -1.28093385e+00,\n",
       "                     -1.28401551e+00, -1.29392104e+00, -1.38629436e+00, -1.41226985e+00,\n",
       "                     -1.41908418e+00, -1.42977947e+00, -1.48160454e+00, -1.48427477e+00,\n",
       "                     -1.50407740e+00, -1.51512723e+00, -1.52846885e+00, -1.54044504e+00,\n",
       "                     -1.55814462e+00, -1.58412010e+00, -1.60386687e+00, -1.60943791e+00,\n",
       "                     -1.62186043e+00, -1.67397643e+00, -1.69167601e+00, -1.73460106e+00,\n",
       "                     -1.75401914e+00, -1.79175947e+00, -1.84582669e+00, -1.89711998e+00,\n",
       "                     -1.98100147e+00, -1.99809590e+00, -2.06369318e+00, -2.07944154e+00,\n",
       "                     -2.08406049e+00, -2.48490665e+00, -2.56494936e+00, -2.77258872e+00,\n",
       "                     -3.21887582e+00, -3.46573590e+00, -3.45387764e+01]), auc_score=0.5568772283867314, privacy_risk=0.5394507755618867, accuracy=0.5394507755618867, tpr_ind=0.6442307692307693, tnr_ind=0.4346707818930041, test_train_ratio=0.9838056680161943, dataset_size=[1976, 1944]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00693756, 0.01139742, 0.01437066, 0.01536174,\n",
       "                     0.01783944, 0.01883053, 0.03567889, 0.04063429, 0.04410307,\n",
       "                     0.04955401, 0.05252725, 0.06095144, 0.06194252, 0.06838454,\n",
       "                     0.06937562, 0.08325074, 0.09464817, 0.10802775, 0.10901883,\n",
       "                     0.11298315, 0.11942517, 0.12388503, 0.12685828, 0.12983152,\n",
       "                     0.14866204, 0.18533201, 0.18979187, 0.19375619, 0.19524281,\n",
       "                     0.20218038, 0.22745292, 0.25173439, 0.27205154, 0.27601586,\n",
       "                     0.30921705, 0.31318137, 0.33250743, 0.33696729, 0.3691774 ,\n",
       "                     0.37215064, 0.38354807, 0.42120912, 0.42517344, 0.432111  ,\n",
       "                     0.43409316, 0.44549058, 0.44945491, 0.46432111, 0.48711596,\n",
       "                     0.48810704, 0.5099108 , 0.5123885 , 0.52279485, 0.52775025,\n",
       "                     0.55946482, 0.56937562, 0.59514371, 0.60455897, 0.61149653,\n",
       "                     0.61694747, 0.68780971, 0.70564916, 0.71704658, 0.71952428,\n",
       "                     0.72547076, 0.76560951, 0.79484638, 0.82408325, 0.82755203,\n",
       "                     0.83349851, 0.85530228, 0.86620416, 0.87859267, 0.88404361,\n",
       "                     0.88949455, 0.89444995, 0.90386521, 0.90386521, 0.90832507,\n",
       "                     0.91129832, 0.91674926, 0.92666006, 0.93508424, 0.9395441 ,\n",
       "                     0.94301288, 0.94350842, 0.94648167, 0.94895937, 0.96580773,\n",
       "                     0.96927651, 0.96927651, 0.97125867, 0.97670961, 0.97720515,\n",
       "                     0.97720515, 0.97968285, 0.98017839, 0.98116947, 1.        ]), tpr=array([0.        , 0.01419558, 0.02050473, 0.02839117, 0.03049422,\n",
       "                     0.03364879, 0.03785489, 0.05993691, 0.06940063, 0.07465825,\n",
       "                     0.08622503, 0.09568875, 0.10725552, 0.10935857, 0.11724501,\n",
       "                     0.12039958, 0.14563617, 0.15878023, 0.17245005, 0.17665615,\n",
       "                     0.18349106, 0.19085174, 0.19295478, 0.19663512, 0.20084122,\n",
       "                     0.22975815, 0.2723449 , 0.27707676, 0.28601472, 0.28969506,\n",
       "                     0.29442692, 0.33333333, 0.34752892, 0.37539432, 0.38012618,\n",
       "                     0.41377497, 0.41640379, 0.43375394, 0.4384858 , 0.47371188,\n",
       "                     0.47896951, 0.48633018, 0.51629863, 0.51892744, 0.5278654 ,\n",
       "                     0.52839117, 0.54100946, 0.54311251, 0.55520505, 0.57360673,\n",
       "                     0.57728707, 0.60147213, 0.6019979 , 0.61093586, 0.62092534,\n",
       "                     0.64037855, 0.64773922, 0.66982124, 0.68191377, 0.68664564,\n",
       "                     0.69295478, 0.76340694, 0.77760252, 0.78391167, 0.78601472,\n",
       "                     0.79022082, 0.82702419, 0.86225026, 0.89011567, 0.89116719,\n",
       "                     0.89432177, 0.91324921, 0.92586751, 0.93638275, 0.94058885,\n",
       "                     0.9426919 , 0.94532072, 0.95268139, 0.95320715, 0.9553102 ,\n",
       "                     0.95899054, 0.96056782, 0.96740273, 0.9721346 , 0.97423764,\n",
       "                     0.97634069, 0.97844374, 0.98002103, 0.98159832, 0.9915878 ,\n",
       "                     0.99263933, 0.99316509, 0.99421661, 0.99684543, 0.99737119,\n",
       "                     0.99789695, 0.99947424, 1.        , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.54150680e-01, -1.82321557e-01,\n",
       "                     -2.23143551e-01, -2.87682072e-01, -3.18453731e-01, -4.05465108e-01,\n",
       "                     -4.41832752e-01, -4.70003629e-01, -4.73287704e-01, -5.10825624e-01,\n",
       "                     -5.46543706e-01, -5.59615788e-01, -5.75364145e-01, -6.35988767e-01,\n",
       "                     -6.93147181e-01, -7.11165686e-01, -7.17839793e-01, -7.33969175e-01,\n",
       "                     -7.67255153e-01, -7.73189888e-01, -8.10930216e-01, -8.26678573e-01,\n",
       "                     -8.39750655e-01, -8.44697079e-01, -8.46172368e-01, -8.47297860e-01,\n",
       "                     -8.80358723e-01, -8.87303195e-01, -8.93817876e-01, -8.94431938e-01,\n",
       "                     -8.96088025e-01, -9.13469856e-01, -9.16290732e-01, -9.45704617e-01,\n",
       "                     -9.55511445e-01, -9.63437510e-01, -9.80829253e-01, -9.88264231e-01,\n",
       "                     -9.93251773e-01, -1.01160091e+00, -1.01613607e+00, -1.02961942e+00,\n",
       "                     -1.04145387e+00, -1.04982212e+00, -1.05605267e+00, -1.06784063e+00,\n",
       "                     -1.08401349e+00, -1.09861229e+00, -1.13943428e+00, -1.14624034e+00,\n",
       "                     -1.16315081e+00, -1.17351360e+00, -1.18269541e+00, -1.20126644e+00,\n",
       "                     -1.21444410e+00, -1.23906412e+00, -1.24653242e+00, -1.25276297e+00,\n",
       "                     -1.27629347e+00, -1.28647403e+00, -1.29928298e+00, -1.31824090e+00,\n",
       "                     -1.32175584e+00, -1.32566974e+00, -1.33200128e+00, -1.36365188e+00,\n",
       "                     -1.36724617e+00, -1.38629436e+00, -1.42403469e+00, -1.46633707e+00,\n",
       "                     -1.50407740e+00, -1.51512723e+00, -1.58412010e+00, -1.60943791e+00,\n",
       "                     -1.63760879e+00, -1.74296931e+00, -1.75785792e+00, -1.79175947e+00,\n",
       "                     -1.81237876e+00, -1.84582669e+00, -1.92368701e+00, -1.92990981e+00,\n",
       "                     -1.94591015e+00, -1.99243016e+00, -2.01490302e+00, -2.03688193e+00,\n",
       "                     -2.07944154e+00, -2.14787870e+00, -2.19722458e+00, -2.39789527e+00,\n",
       "                     -2.60268969e+00, -2.61006979e+00, -2.63905733e+00, -2.67414865e+00,\n",
       "                     -2.94443898e+00, -2.97892516e+00, -4.04305127e+00, -3.45387764e+01]), auc_score=0.5727700172683494, privacy_risk=0.5534094307906028, accuracy=0.5534094307906028, tpr_ind=0.47896950578338593, tnr_ind=0.6278493557978196, test_train_ratio=1.060988433228181, dataset_size=[1902, 2018]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00728408, 0.00884495, 0.01092612, 0.01404787,\n",
       "                     0.01873049, 0.02237253, 0.0359001 , 0.0364204 , 0.03902185,\n",
       "                     0.04526535, 0.04942768, 0.05359001, 0.07544225, 0.07908429,\n",
       "                     0.08272633, 0.08844953, 0.09729448, 0.09833507, 0.10197711,\n",
       "                     0.11706556, 0.12851197, 0.1326743 , 0.13631634, 0.14255983,\n",
       "                     0.16181061, 0.18366285, 0.1930281 , 0.19406868, 0.22060354,\n",
       "                     0.22112383, 0.24817898, 0.28616025, 0.28772112, 0.30801249,\n",
       "                     0.33662851, 0.36888658, 0.37252862, 0.37773153, 0.38085328,\n",
       "                     0.39698231, 0.42924037, 0.43548387, 0.4640999 , 0.55046826,\n",
       "                     0.57700312, 0.59105099, 0.60353798, 0.60561915, 0.62382934,\n",
       "                     0.63371488, 0.63371488, 0.69979188, 0.73569199, 0.73725286,\n",
       "                     0.79552549, 0.79656608, 0.80176899, 0.83194589, 0.83922997,\n",
       "                     0.855359  , 0.85587929, 0.86472425, 0.89958377, 0.90062435,\n",
       "                     0.90530697, 0.92039542, 0.93808533, 0.9396462 , 0.94693028,\n",
       "                     0.95317378, 0.95577523, 0.96774194, 0.9698231 , 0.97138398,\n",
       "                     0.97138398, 0.97398543, 0.97398543, 0.97450572, 0.97502601,\n",
       "                     0.9760666 , 0.97710718, 1.        ]), tpr=array([0.        , 0.01701702, 0.02052052, 0.02352352, 0.02652653,\n",
       "                     0.03053053, 0.03553554, 0.05155155, 0.05455455, 0.05705706,\n",
       "                     0.06106106, 0.06456456, 0.06906907, 0.09409409, 0.1011011 ,\n",
       "                     0.10860861, 0.11361361, 0.12862863, 0.13413413, 0.14264264,\n",
       "                     0.16216216, 0.17667668, 0.18068068, 0.18368368, 0.18868869,\n",
       "                     0.20970971, 0.23273273, 0.23673674, 0.24024024, 0.27077077,\n",
       "                     0.27377377, 0.2997998 , 0.34084084, 0.34484484, 0.36636637,\n",
       "                     0.38688689, 0.43543544, 0.43843844, 0.44194194, 0.45045045,\n",
       "                     0.46246246, 0.48998999, 0.49399399, 0.51601602, 0.6041041 ,\n",
       "                     0.62862863, 0.64414414, 0.66716717, 0.67167167, 0.69219219,\n",
       "                     0.7017017 , 0.7022022 , 0.76326326, 0.79329329, 0.79479479,\n",
       "                     0.85535536, 0.85785786, 0.86786787, 0.8953954 , 0.9009009 ,\n",
       "                     0.91691692, 0.91841842, 0.92342342, 0.95045045, 0.95195195,\n",
       "                     0.95745746, 0.96796797, 0.97997998, 0.98148148, 0.98398398,\n",
       "                     0.98548549, 0.98698699, 0.99499499, 0.995996  , 0.995996  ,\n",
       "                     0.9964965 , 0.9974975 , 0.997998  , 0.9984985 , 0.9994995 ,\n",
       "                     1.        , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -1.54150680e-01,\n",
       "                     -2.87682072e-01, -3.18453731e-01, -3.36472237e-01, -3.84411699e-01,\n",
       "                     -4.05465108e-01, -4.70003629e-01, -4.85507816e-01, -5.10825624e-01,\n",
       "                     -5.26093096e-01, -5.30628251e-01, -5.38996501e-01, -5.50046337e-01,\n",
       "                     -5.87786665e-01, -6.00056757e-01, -6.46627165e-01, -6.63294217e-01,\n",
       "                     -6.93147181e-01, -7.27048732e-01, -7.53771802e-01, -7.73189888e-01,\n",
       "                     -7.88457360e-01, -7.91127589e-01, -8.06087592e-01, -8.10930216e-01,\n",
       "                     -8.26678573e-01, -8.37886026e-01, -8.47297860e-01, -8.57902414e-01,\n",
       "                     -8.60762590e-01, -8.64997437e-01, -9.02238978e-01, -9.16290732e-01,\n",
       "                     -9.26547232e-01, -9.34309237e-01, -9.47381319e-01, -9.73449146e-01,\n",
       "                     -9.80829253e-01, -9.88070414e-01, -9.96333440e-01, -1.03653986e+00,\n",
       "                     -1.07173927e+00, -1.09178632e+00, -1.09861229e+00, -1.12011849e+00,\n",
       "                     -1.13497993e+00, -1.16162526e+00, -1.20179652e+00, -1.20397280e+00,\n",
       "                     -1.21457217e+00, -1.24319352e+00, -1.25276297e+00, -1.28642836e+00,\n",
       "                     -1.29928298e+00, -1.31730149e+00, -1.32054298e+00, -1.33041390e+00,\n",
       "                     -1.34644845e+00, -1.38629436e+00, -1.40282366e+00, -1.47484776e+00,\n",
       "                     -1.54044504e+00, -1.60943791e+00, -1.67397643e+00, -1.79175947e+00,\n",
       "                     -1.84582669e+00, -1.94591015e+00, -2.03688193e+00, -2.12026354e+00,\n",
       "                     -2.16685348e+00, -2.19722458e+00, -2.23359222e+00, -2.39789527e+00,\n",
       "                     -2.67414865e+00, -2.77258872e+00, -2.93119375e+00, -3.04452244e+00,\n",
       "                     -3.11351531e+00, -4.15888308e+00, -3.45387764e+01]), auc_score=0.5505040680639015, privacy_risk=0.5347985863074313, accuracy=0.5347985863074313, tpr_ind=0.45045045045045046, tnr_ind=0.619146722164412, test_train_ratio=0.9619619619619619, dataset_size=[1998, 1922]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00626305, 0.0125261 , 0.0151357 , 0.01617954,\n",
       "                     0.01878914, 0.02400835, 0.03549061, 0.04384134, 0.05219207,\n",
       "                     0.05323591, 0.06002088, 0.06002088, 0.06993737, 0.07202505,\n",
       "                     0.07672234, 0.07776618, 0.09029228, 0.12004175, 0.13413361,\n",
       "                     0.14613779, 0.15031315, 0.15240084, 0.16805846, 0.17379958,\n",
       "                     0.18371608, 0.22338205, 0.22599165, 0.25887265, 0.2625261 ,\n",
       "                     0.32306889, 0.32776618, 0.36691023, 0.3914405 , 0.39926931,\n",
       "                     0.40240084, 0.40344468, 0.40814196, 0.48695198, 0.48903967,\n",
       "                     0.48956159, 0.50469729, 0.50939457, 0.51617954, 0.5302714 ,\n",
       "                     0.53340292, 0.53496868, 0.53653445, 0.565762  , 0.57098121,\n",
       "                     0.63152401, 0.6388309 , 0.64300626, 0.66858038, 0.67379958,\n",
       "                     0.6743215 , 0.69206681, 0.7019833 , 0.71555324, 0.72129436,\n",
       "                     0.74217119, 0.74686848, 0.78601253, 0.79175365, 0.79488518,\n",
       "                     0.8131524 , 0.81837161, 0.8282881 , 0.83194154, 0.83716075,\n",
       "                     0.84029228, 0.84707724, 0.85647182, 0.86847599, 0.87943633,\n",
       "                     0.88308977, 0.89248434, 0.90292276, 0.90866388, 0.91179541,\n",
       "                     0.91388309, 0.91805846, 0.91962422, 0.92379958, 0.92379958,\n",
       "                     0.934238  , 0.94467641, 0.94572025, 0.94728601, 0.94832985,\n",
       "                     0.9519833 , 0.95407098, 0.9545929 , 0.95563674, 0.95615866,\n",
       "                     0.96242171, 0.967119  , 1.        ]), tpr=array([0.        , 0.01746507, 0.02195609, 0.02694611, 0.02844311,\n",
       "                     0.03093812, 0.04191617, 0.05788423, 0.06586826, 0.07634731,\n",
       "                     0.07884232, 0.08732535, 0.08832335, 0.1007984 , 0.10528942,\n",
       "                     0.11277445, 0.11576846, 0.13872255, 0.17265469, 0.19411178,\n",
       "                     0.20958084, 0.21556886, 0.21806387, 0.23453094, 0.24051896,\n",
       "                     0.249501  , 0.28393214, 0.28692615, 0.31736527, 0.32135729,\n",
       "                     0.38872255, 0.39371257, 0.43612774, 0.46107784, 0.46706587,\n",
       "                     0.46906188, 0.4740519 , 0.4760479 , 0.57834331, 0.58183633,\n",
       "                     0.58483034, 0.59780439, 0.60479042, 0.61427146, 0.6262475 ,\n",
       "                     0.62974052, 0.63373253, 0.63722555, 0.65818363, 0.66267465,\n",
       "                     0.72105788, 0.72654691, 0.73403194, 0.75249501, 0.75898204,\n",
       "                     0.76047904, 0.78792415, 0.7994012 , 0.81287425, 0.81686627,\n",
       "                     0.84231537, 0.84830339, 0.88023952, 0.88622754, 0.88872255,\n",
       "                     0.90968064, 0.91367265, 0.91966068, 0.92664671, 0.93063872,\n",
       "                     0.93263473, 0.93612774, 0.94311377, 0.9500998 , 0.95708583,\n",
       "                     0.95908184, 0.96756487, 0.9760479 , 0.97804391, 0.97854291,\n",
       "                     0.98053892, 0.98203593, 0.98253493, 0.98502994, 0.98602794,\n",
       "                     0.98852295, 0.99201597, 0.99301397, 0.99401198, 0.99451098,\n",
       "                     0.99550898, 0.99600798, 0.99850299, 0.999002  , 0.999002  ,\n",
       "                     0.999501  , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.05360516e-01, -1.82321557e-01,\n",
       "                     -2.87682072e-01, -3.36472237e-01, -3.74693449e-01, -4.05465108e-01,\n",
       "                     -4.46287103e-01, -4.51985124e-01, -4.70003629e-01, -4.98991166e-01,\n",
       "                     -5.10825624e-01, -5.59615788e-01, -5.75364145e-01, -5.87786665e-01,\n",
       "                     -6.06135804e-01, -6.15588946e-01, -6.16774202e-01, -6.81451141e-01,\n",
       "                     -6.93147181e-01, -7.33969175e-01, -7.88457360e-01, -8.07557532e-01,\n",
       "                     -8.10930216e-01, -8.14099791e-01, -8.34797698e-01, -8.47297860e-01,\n",
       "                     -8.51970766e-01, -8.62223511e-01, -8.74829964e-01, -8.75468737e-01,\n",
       "                     -8.85224912e-01, -9.16290732e-01, -9.80829253e-01, -9.90398704e-01,\n",
       "                     -9.93251773e-01, -1.01160091e+00, -1.01734932e+00, -1.03798767e+00,\n",
       "                     -1.04145387e+00, -1.04596856e+00, -1.07451474e+00, -1.08026315e+00,\n",
       "                     -1.09861229e+00, -1.12601126e+00, -1.13943428e+00, -1.14513230e+00,\n",
       "                     -1.16017018e+00, -1.17007125e+00, -1.17468201e+00, -1.17557333e+00,\n",
       "                     -1.18149995e+00, -1.19310313e+00, -1.19625076e+00, -1.20397280e+00,\n",
       "                     -1.21841349e+00, -1.23395364e+00, -1.23676263e+00, -1.25276297e+00,\n",
       "                     -1.28785429e+00, -1.32175584e+00, -1.37082444e+00, -1.38629436e+00,\n",
       "                     -1.45225233e+00, -1.46082741e+00, -1.47181653e+00, -1.48538526e+00,\n",
       "                     -1.49165488e+00, -1.50407740e+00, -1.52242654e+00, -1.55059741e+00,\n",
       "                     -1.56563529e+00, -1.57121670e+00, -1.60943791e+00, -1.65822808e+00,\n",
       "                     -1.67764616e+00, -1.71008144e+00, -1.74046617e+00, -1.79175947e+00,\n",
       "                     -1.87180218e+00, -1.89711998e+00, -2.07944154e+00, -2.10413415e+00,\n",
       "                     -2.14006616e+00, -2.19722458e+00, -2.21297293e+00, -2.25129180e+00,\n",
       "                     -2.35137526e+00, -2.39789527e+00, -2.43361336e+00, -2.70805020e+00,\n",
       "                     -2.73200344e+00, -2.77258872e+00, -2.89037176e+00, -3.29583687e+00,\n",
       "                     -4.72738782e+00, -3.45387764e+01]), auc_score=0.5706569637343268, privacy_risk=0.5507174586109618, accuracy=0.5507174586109618, tpr_ind=0.8483033932135728, tnr_ind=0.2531315240083507, test_train_ratio=0.9560878243512974, dataset_size=[2004, 1916]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.01227621, 0.0168798 , 0.01994885, 0.02097187,\n",
       "                     0.02199488, 0.0230179 , 0.02404092, 0.03273657, 0.03580563,\n",
       "                     0.03887468, 0.04040921, 0.04910486, 0.05012788, 0.05319693,\n",
       "                     0.057289  , 0.06189258, 0.06598465, 0.08849105, 0.09616368,\n",
       "                     0.10332481, 0.12890026, 0.13503836, 0.13964194, 0.17340153,\n",
       "                     0.18465473, 0.19590793, 0.21534527, 0.21892583, 0.26189258,\n",
       "                     0.26547315, 0.27263427, 0.28132992, 0.29002558, 0.29565217,\n",
       "                     0.30179028, 0.31713555, 0.32531969, 0.33299233, 0.34629156,\n",
       "                     0.3601023 , 0.41841432, 0.42966752, 0.43682864, 0.4398977 ,\n",
       "                     0.46342711, 0.49207161, 0.49923274, 0.53759591, 0.5483376 ,\n",
       "                     0.55498721, 0.56061381, 0.56368286, 0.56521739, 0.57186701,\n",
       "                     0.57442455, 0.59693095, 0.60613811, 0.60971867, 0.61636829,\n",
       "                     0.6168798 , 0.62710997, 0.6398977 , 0.64450128, 0.75038363,\n",
       "                     0.76828645, 0.77084399, 0.77749361, 0.78056266, 0.78670077,\n",
       "                     0.79693095, 0.80102302, 0.80664962, 0.8173913 , 0.84398977,\n",
       "                     0.8516624 , 0.86138107, 0.8629156 , 0.90741688, 0.91304348,\n",
       "                     0.91867008, 0.9202046 , 0.92071611, 0.92480818, 0.92992327,\n",
       "                     0.9314578 , 0.93196931, 0.93964194, 0.94219949, 0.94373402,\n",
       "                     0.95345269, 0.95396419, 0.96317136, 0.96317136, 0.9657289 ,\n",
       "                     0.9657289 , 0.96726343, 0.96777494, 0.96879795, 0.96982097,\n",
       "                     0.9713555 , 0.97237852, 0.97340153, 1.        ]), tpr=array([0.        , 0.01832061, 0.02442748, 0.02697201, 0.02900763,\n",
       "                     0.0346056 , 0.03867684, 0.043257  , 0.0524173 , 0.05597964,\n",
       "                     0.06361323, 0.06666667, 0.08040712, 0.08142494, 0.08549618,\n",
       "                     0.09211196, 0.09821883, 0.1043257 , 0.12468193, 0.13333333,\n",
       "                     0.13791349, 0.16590331, 0.17201018, 0.17964377, 0.21323155,\n",
       "                     0.23104326, 0.24732824, 0.27226463, 0.27684478, 0.30788804,\n",
       "                     0.31043257, 0.32010178, 0.32722646, 0.33791349, 0.34096692,\n",
       "                     0.35318066, 0.37099237, 0.38117048, 0.39033079, 0.41526718,\n",
       "                     0.4264631 , 0.47684478, 0.48854962, 0.49312977, 0.4956743 ,\n",
       "                     0.51959288, 0.54300254, 0.54961832, 0.59338422, 0.60508906,\n",
       "                     0.61323155, 0.62086514, 0.62442748, 0.62849873, 0.63867684,\n",
       "                     0.64173028, 0.65801527, 0.66819338, 0.67124682, 0.67430025,\n",
       "                     0.67633588, 0.6870229 , 0.69872774, 0.70178117, 0.81628499,\n",
       "                     0.83256997, 0.83664122, 0.84173028, 0.8437659 , 0.84783715,\n",
       "                     0.86208651, 0.86717557, 0.87430025, 0.88091603, 0.90483461,\n",
       "                     0.91195929, 0.91755725, 0.91857506, 0.95521628, 0.95877863,\n",
       "                     0.96284987, 0.9653944 , 0.96590331, 0.96895674, 0.9735369 ,\n",
       "                     0.97557252, 0.97659033, 0.98320611, 0.98422392, 0.98524173,\n",
       "                     0.98931298, 0.98982188, 0.99389313, 0.99440204, 0.99541985,\n",
       "                     0.99592875, 0.99643766, 0.99745547, 0.99796438, 0.99898219,\n",
       "                     0.99949109, 1.        , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.54150680e-01, -1.82321557e-01,\n",
       "                     -2.23143551e-01, -2.87682072e-01, -3.18453731e-01, -3.67724780e-01,\n",
       "                     -4.05465108e-01, -4.51985124e-01, -4.70003629e-01, -5.10825624e-01,\n",
       "                     -5.32804530e-01, -5.38996501e-01, -5.59615788e-01, -5.67984038e-01,\n",
       "                     -6.06135804e-01, -6.66478933e-01, -6.93147181e-01, -7.22134717e-01,\n",
       "                     -7.47214402e-01, -7.55667538e-01, -7.73189888e-01, -7.88457360e-01,\n",
       "                     -7.96943974e-01, -8.14099791e-01, -8.34460714e-01, -8.44378150e-01,\n",
       "                     -8.47297860e-01, -8.79558723e-01, -8.93817876e-01, -9.02238978e-01,\n",
       "                     -9.16290732e-01, -9.34309237e-01, -9.38269639e-01, -9.49080555e-01,\n",
       "                     -9.50976290e-01, -9.55511445e-01, -9.65080896e-01, -9.67992106e-01,\n",
       "                     -9.77984301e-01, -9.88376459e-01, -9.91640169e-01, -1.02450432e+00,\n",
       "                     -1.02961942e+00, -1.04020153e+00, -1.05108715e+00, -1.07158362e+00,\n",
       "                     -1.08298697e+00, -1.09861229e+00, -1.10866262e+00, -1.11436065e+00,\n",
       "                     -1.11803037e+00, -1.12393010e+00, -1.13140211e+00, -1.13497993e+00,\n",
       "                     -1.13943428e+00, -1.15145477e+00, -1.15267951e+00, -1.15745279e+00,\n",
       "                     -1.16315081e+00, -1.17599895e+00, -1.17995793e+00, -1.20397280e+00,\n",
       "                     -1.21984615e+00, -1.23807842e+00, -1.24432410e+00, -1.25276297e+00,\n",
       "                     -1.31218639e+00, -1.35454566e+00, -1.35914337e+00, -1.38629436e+00,\n",
       "                     -1.42711636e+00, -1.44691898e+00, -1.45831295e+00, -1.45861502e+00,\n",
       "                     -1.46967597e+00, -1.51982575e+00, -1.54341681e+00, -1.55059741e+00,\n",
       "                     -1.65822808e+00, -1.66500776e+00, -1.70474809e+00, -1.73460106e+00,\n",
       "                     -1.74046617e+00, -1.79175947e+00, -1.87180218e+00, -1.88939794e+00,\n",
       "                     -2.07944154e+00, -2.14006616e+00, -2.25129180e+00, -2.26868354e+00,\n",
       "                     -2.30258509e+00, -2.39789527e+00, -2.52572864e+00, -2.61495978e+00,\n",
       "                     -2.63905733e+00, -2.70805020e+00, -2.83321334e+00, -2.86220088e+00,\n",
       "                     -2.96183072e+00, -3.13549422e+00, -3.25809654e+00, -3.45387764e+01]), auc_score=0.5507518400655981, privacy_risk=0.5344878077351086, accuracy=0.5344878077351086, tpr_ind=0.4152671755725191, tnr_ind=0.6537084398976982, test_train_ratio=0.9949109414758269, dataset_size=[1965, 1955]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.01352054, 0.01352054, 0.0150806 , 0.01768071,\n",
       "                     0.01924077, 0.02132085, 0.02912116, 0.03328133, 0.04264171,\n",
       "                     0.04836193, 0.049922  , 0.05200208, 0.05772231, 0.06292252,\n",
       "                     0.07020281, 0.07540302, 0.08216329, 0.09412376, 0.09984399,\n",
       "                     0.10400416, 0.12636505, 0.13104524, 0.13624545, 0.13832553,\n",
       "                     0.15860634, 0.16536661, 0.26937077, 0.28133125, 0.28965159,\n",
       "                     0.29641186, 0.29953198, 0.34789392, 0.36609464, 0.37285491,\n",
       "                     0.39521581, 0.40977639, 0.43057722, 0.45345814, 0.46385855,\n",
       "                     0.47165887, 0.47633905, 0.4799792 , 0.51274051, 0.52834113,\n",
       "                     0.55070203, 0.55538222, 0.60426417, 0.6099844 , 0.62714509,\n",
       "                     0.64950598, 0.6723869 , 0.68382735, 0.68538742, 0.69578783,\n",
       "                     0.71190848, 0.73530941, 0.73634945, 0.74622985, 0.75299012,\n",
       "                     0.75403016, 0.81643266, 0.83515341, 0.84711388, 0.88871555,\n",
       "                     0.88975559, 0.8949558 , 0.90119605, 0.91679667, 0.91887676,\n",
       "                     0.91939678, 0.925117  , 0.93031721, 0.93291732, 0.93811752,\n",
       "                     0.94435777, 0.94591784, 0.9625585 , 0.9625585 , 0.96931877,\n",
       "                     0.96931877, 0.97815913, 0.97815913, 0.97971919, 0.98075923,\n",
       "                     0.98387936, 0.98647946, 0.9875195 , 1.        ]), tpr=array([0.        , 0.0215323 , 0.02553831, 0.02904357, 0.03104657,\n",
       "                     0.03355033, 0.03805709, 0.05408112, 0.06059089, 0.07361042,\n",
       "                     0.07811718, 0.08362544, 0.08662994, 0.09163746, 0.09664497,\n",
       "                     0.10465699, 0.110666  , 0.12068102, 0.13570356, 0.14121182,\n",
       "                     0.14772158, 0.16975463, 0.17426139, 0.18177266, 0.18527792,\n",
       "                     0.21231848, 0.22283425, 0.31647471, 0.32899349, 0.33650476,\n",
       "                     0.34151227, 0.34501753, 0.3995994 , 0.41662494, 0.42263395,\n",
       "                     0.44216324, 0.46119179, 0.48072108, 0.50575864, 0.51727591,\n",
       "                     0.52478718, 0.52879319, 0.53129695, 0.57936905, 0.59038558,\n",
       "                     0.60841262, 0.61191788, 0.66349524, 0.66850275, 0.68552829,\n",
       "                     0.70455684, 0.72909364, 0.74111167, 0.74261392, 0.75162744,\n",
       "                     0.76514772, 0.78968453, 0.79218828, 0.80320481, 0.81121683,\n",
       "                     0.81221833, 0.86930396, 0.88182273, 0.887331  , 0.92638958,\n",
       "                     0.93039559, 0.93390085, 0.94141212, 0.95242864, 0.9559339 ,\n",
       "                     0.9569354 , 0.96494742, 0.96895343, 0.97145719, 0.97396094,\n",
       "                     0.97896845, 0.98147221, 0.98698047, 0.98798197, 0.99198798,\n",
       "                     0.99298948, 0.99449174, 0.99499249, 0.99649474, 0.99749624,\n",
       "                     0.99849775, 0.9989985 , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.23143551e-01, -2.51314428e-01,\n",
       "                     -2.87682072e-01, -3.36472237e-01, -3.67724780e-01, -4.05465108e-01,\n",
       "                     -4.30782916e-01, -4.32133355e-01, -4.41832752e-01, -4.96436886e-01,\n",
       "                     -5.10825624e-01, -5.87786665e-01, -6.19039208e-01, -6.28608659e-01,\n",
       "                     -6.39079959e-01, -6.50587566e-01, -6.93147181e-01, -7.20546155e-01,\n",
       "                     -7.67255153e-01, -7.69687258e-01, -7.84118959e-01, -7.88457360e-01,\n",
       "                     -7.98507696e-01, -8.23200309e-01, -8.24175443e-01, -8.36349645e-01,\n",
       "                     -8.41567186e-01, -8.47297860e-01, -8.75468737e-01, -8.93817876e-01,\n",
       "                     -9.04298583e-01, -9.04456274e-01, -9.16290732e-01, -9.21405833e-01,\n",
       "                     -9.37124819e-01, -9.58030338e-01, -9.70778917e-01, -9.80829253e-01,\n",
       "                     -1.00900013e+00, -1.01160091e+00, -1.02165125e+00, -1.02663879e+00,\n",
       "                     -1.03609193e+00, -1.09861229e+00, -1.14513230e+00, -1.15523118e+00,\n",
       "                     -1.16315081e+00, -1.17411984e+00, -1.17473598e+00, -1.18335352e+00,\n",
       "                     -1.18504479e+00, -1.20397280e+00, -1.25276297e+00, -1.25804003e+00,\n",
       "                     -1.27866370e+00, -1.28093385e+00, -1.29098418e+00, -1.33041390e+00,\n",
       "                     -1.33500107e+00, -1.38629436e+00, -1.40609699e+00, -1.40876722e+00,\n",
       "                     -1.42711636e+00, -1.49664242e+00, -1.51982575e+00, -1.52102696e+00,\n",
       "                     -1.56291790e+00, -1.58045038e+00, -1.60943791e+00, -1.62186043e+00,\n",
       "                     -1.73460106e+00, -1.74296931e+00, -1.75785792e+00, -1.91875916e+00,\n",
       "                     -1.92181260e+00, -1.93283807e+00, -2.01490302e+00, -2.02320182e+00,\n",
       "                     -2.14006616e+00, -2.38262780e+00, -2.39789527e+00, -2.48490665e+00,\n",
       "                     -2.52572864e+00, -2.70805020e+00, -2.84781214e+00, -3.20545280e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5473019721990682, privacy_risk=0.5333142719799929, accuracy=0.5333142719799929, tpr_ind=0.5793690535803706, tnr_ind=0.4872594903796152, test_train_ratio=0.9629444166249375, dataset_size=[1997, 1923]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00837258, 0.01046572, 0.01098901, 0.01255887,\n",
       "                     0.01674516, 0.02145474, 0.02459445, 0.03087389, 0.03192046,\n",
       "                     0.03610675, 0.04500262, 0.05546834, 0.06279435, 0.0685505 ,\n",
       "                     0.08058608, 0.0952381 , 0.11878598, 0.13867085, 0.14390372,\n",
       "                     0.14704343, 0.16535845, 0.17006803, 0.17739403, 0.21821036,\n",
       "                     0.2281528 , 0.23861852, 0.24071167, 0.25693354, 0.26111983,\n",
       "                     0.26792255, 0.27263213, 0.29042386, 0.33542648, 0.34013605,\n",
       "                     0.35688121, 0.36159079, 0.37205651, 0.41601256, 0.45839874,\n",
       "                     0.46049189, 0.47095761, 0.47462062, 0.50130822, 0.51020408,\n",
       "                     0.53846154, 0.53950811, 0.55729984, 0.5588697 , 0.56933543,\n",
       "                     0.57142857, 0.59183673, 0.60125589, 0.62114076, 0.62218734,\n",
       "                     0.62637363, 0.6274202 , 0.63212977, 0.63422292, 0.63422292,\n",
       "                     0.64207221, 0.64311879, 0.64835165, 0.65986395, 0.66771324,\n",
       "                     0.70643642, 0.75143904, 0.76713762, 0.78021978, 0.78283621,\n",
       "                     0.7870225 , 0.79330194, 0.79591837, 0.80690738, 0.82208268,\n",
       "                     0.83411826, 0.83830455, 0.85504971, 0.88697017, 0.8895866 ,\n",
       "                     0.8895866 , 0.89115646, 0.90633176, 0.91732077, 0.9241235 ,\n",
       "                     0.92621664, 0.92935636, 0.94139194, 0.9466248 , 0.94924123,\n",
       "                     0.95395081, 0.9544741 , 0.96336996, 0.96336996, 0.96807954,\n",
       "                     0.97226583, 0.9733124 , 0.97488226, 0.97697541, 0.97802198,\n",
       "                     0.98063841, 1.        ]), tpr=array([0.        , 0.0174216 , 0.02040816, 0.02538576, 0.02687904,\n",
       "                     0.03185665, 0.03782977, 0.04131409, 0.04579393, 0.04927825,\n",
       "                     0.05326033, 0.06271777, 0.07565953, 0.08163265, 0.09009457,\n",
       "                     0.10403186, 0.12543554, 0.1458437 , 0.16127427, 0.16625187,\n",
       "                     0.17023395, 0.18616227, 0.19362867, 0.20159283, 0.246889  ,\n",
       "                     0.26132404, 0.27327028, 0.27625684, 0.29268293, 0.29716277,\n",
       "                     0.30263813, 0.30861125, 0.32254853, 0.36585366, 0.3728223 ,\n",
       "                     0.38924838, 0.39422598, 0.40169238, 0.44051767, 0.50074664,\n",
       "                     0.50223992, 0.51269288, 0.51767048, 0.54604281, 0.55749129,\n",
       "                     0.6047785 , 0.60577402, 0.62319562, 0.62568442, 0.63862618,\n",
       "                     0.6396217 , 0.65654555, 0.66749627, 0.68740667, 0.68889995,\n",
       "                     0.69387755, 0.69835739, 0.70482827, 0.70681931, 0.70831259,\n",
       "                     0.72125436, 0.7232454 , 0.7257342 , 0.7356894 , 0.7481334 ,\n",
       "                     0.78198109, 0.82777501, 0.83872573, 0.84868094, 0.85116974,\n",
       "                     0.85266302, 0.85564958, 0.85813838, 0.87108014, 0.88601294,\n",
       "                     0.89696366, 0.89945246, 0.90841215, 0.93529119, 0.93728223,\n",
       "                     0.94076655, 0.94176207, 0.95072175, 0.95918367, 0.96366351,\n",
       "                     0.96565455, 0.96764559, 0.97909408, 0.9825784 , 0.98456944,\n",
       "                     0.98705824, 0.987556  , 0.99153808, 0.9925336 , 0.99452464,\n",
       "                     0.99651568, 0.99701344, 0.99800896, 0.99800896, 0.99900448,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.54150680e-01, -1.82321557e-01,\n",
       "                     -2.23143551e-01, -3.36472237e-01, -3.48306694e-01, -3.56674944e-01,\n",
       "                     -4.05465108e-01, -4.51985124e-01, -4.85507816e-01, -5.10825624e-01,\n",
       "                     -5.59615788e-01, -6.06135804e-01, -6.45137961e-01, -6.75128675e-01,\n",
       "                     -6.93147181e-01, -7.05268541e-01, -7.09147522e-01, -7.41937345e-01,\n",
       "                     -7.53771802e-01, -7.81700578e-01, -7.88457360e-01, -8.10930216e-01,\n",
       "                     -8.31983625e-01, -8.36853901e-01, -8.47297860e-01, -8.70828358e-01,\n",
       "                     -8.90972924e-01, -8.93817876e-01, -8.97941593e-01, -9.02867712e-01,\n",
       "                     -9.16290732e-01, -9.32696767e-01, -9.44461609e-01, -9.46143695e-01,\n",
       "                     -9.55511445e-01, -9.58850346e-01, -9.66656444e-01, -9.70949144e-01,\n",
       "                     -9.80829253e-01, -9.87946721e-01, -9.93251773e-01, -1.00037385e+00,\n",
       "                     -1.00764051e+00, -1.01064352e+00, -1.01160091e+00, -1.01345448e+00,\n",
       "                     -1.02961942e+00, -1.03798767e+00, -1.04145387e+00, -1.04982212e+00,\n",
       "                     -1.06784063e+00, -1.09024404e+00, -1.09861229e+00, -1.13140211e+00,\n",
       "                     -1.13497993e+00, -1.14862271e+00, -1.15267951e+00, -1.17865500e+00,\n",
       "                     -1.18455472e+00, -1.18958407e+00, -1.20397280e+00, -1.20896035e+00,\n",
       "                     -1.21194097e+00, -1.21421430e+00, -1.21800434e+00, -1.24111235e+00,\n",
       "                     -1.25276297e+00, -1.28093385e+00, -1.29928298e+00, -1.31218639e+00,\n",
       "                     -1.33500107e+00, -1.38629436e+00, -1.45861502e+00, -1.47330574e+00,\n",
       "                     -1.48160454e+00, -1.49995368e+00, -1.58863478e+00, -1.60943791e+00,\n",
       "                     -1.63760879e+00, -1.67397643e+00, -1.68433922e+00, -1.69905007e+00,\n",
       "                     -1.71479843e+00, -1.74919985e+00, -1.79175947e+00, -1.85493837e+00,\n",
       "                     -1.94591015e+00, -2.02814825e+00, -2.05412373e+00, -2.07944154e+00,\n",
       "                     -2.09494573e+00, -2.12026354e+00, -2.18323834e+00, -2.19722458e+00,\n",
       "                     -2.30258509e+00, -2.48490665e+00, -2.63905733e+00, -2.91777073e+00,\n",
       "                     -3.09104245e+00, -3.45387764e+01]), auc_score=0.5438807678372494, privacy_risk=0.5402100802797667, accuracy=0.5402100802797667, tpr_ind=0.748133399701344, tnr_ind=0.3322867608581894, test_train_ratio=0.9512195121951219, dataset_size=[2009, 1911]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00606673, 0.00758342, 0.01112235, 0.01314459,\n",
       "                     0.01769464, 0.02224469, 0.02426694, 0.03033367, 0.03437816,\n",
       "                     0.03589484, 0.04196158, 0.04853387, 0.05106168, 0.07128413,\n",
       "                     0.08493428, 0.09150657, 0.10515672, 0.11375126, 0.12436805,\n",
       "                     0.14914055, 0.18200202, 0.18554095, 0.20323559, 0.20728008,\n",
       "                     0.21132457, 0.21284125, 0.22295248, 0.23104146, 0.26188069,\n",
       "                     0.27957533, 0.28311426, 0.30283114, 0.3190091 , 0.34024267,\n",
       "                     0.35136502, 0.3528817 , 0.36450961, 0.37866532, 0.43528817,\n",
       "                     0.43983822, 0.45146613, 0.4570273 , 0.45803842, 0.49949444,\n",
       "                     0.51466127, 0.53892821, 0.54600607, 0.55358948, 0.56268959,\n",
       "                     0.57583418, 0.58897877, 0.61678463, 0.62285137, 0.62841254,\n",
       "                     0.64357937, 0.65318504, 0.65520728, 0.65672396, 0.66026289,\n",
       "                     0.69261881, 0.69565217, 0.70222447, 0.72649141, 0.76996967,\n",
       "                     0.77249747, 0.78968655, 0.81698686, 0.81850354, 0.84479272,\n",
       "                     0.85844287, 0.90343782, 0.91102123, 0.92012133, 0.92012133,\n",
       "                     0.92618807, 0.92719919, 0.93478261, 0.93731041, 0.94236603,\n",
       "                     0.94691608, 0.94742164, 0.94843276, 0.94843276, 0.94994944,\n",
       "                     0.95348837, 0.95904954, 0.96056623, 0.96258847, 0.96663296,\n",
       "                     0.96764408, 0.96865521, 0.97219414, 0.97219414, 1.        ]), tpr=array([0.        , 0.01750772, 0.02111226, 0.02317199, 0.02729145,\n",
       "                     0.03501545, 0.04222451, 0.04634398, 0.05097837, 0.05355304,\n",
       "                     0.0592173 , 0.06282183, 0.0669413 , 0.06951596, 0.09680742,\n",
       "                     0.11019567, 0.11637487, 0.13903193, 0.15036045, 0.17044284,\n",
       "                     0.20751802, 0.24098867, 0.2445932 , 0.26467559, 0.26828012,\n",
       "                     0.27651905, 0.27857878, 0.28784758, 0.29299691, 0.32801236,\n",
       "                     0.35066941, 0.35478888, 0.37178167, 0.38568486, 0.40370752,\n",
       "                     0.42070031, 0.42276004, 0.43872297, 0.45674562, 0.51235839,\n",
       "                     0.51905252, 0.52471679, 0.53141092, 0.53347065, 0.58084449,\n",
       "                     0.59423275, 0.61328527, 0.62409887, 0.6292482 , 0.64109166,\n",
       "                     0.65447992, 0.66580844, 0.6946447 , 0.70030896, 0.70442842,\n",
       "                     0.71524202, 0.72502575, 0.72811535, 0.73069001, 0.73686921,\n",
       "                     0.76004119, 0.76313079, 0.76879506, 0.79196704, 0.82595263,\n",
       "                     0.83007209, 0.84603502, 0.8831102 , 0.88516993, 0.90267765,\n",
       "                     0.91503605, 0.95056643, 0.95520082, 0.96292482, 0.96498455,\n",
       "                     0.96910402, 0.97116375, 0.97528321, 0.97682801, 0.98043254,\n",
       "                     0.98558187, 0.98764161, 0.98970134, 0.99021627, 0.99176107,\n",
       "                     0.992276  , 0.99485067, 0.9953656 , 0.99588054, 0.99794027,\n",
       "                     0.99794027, 0.9984552 , 0.99897013, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -2.23143551e-01,\n",
       "                     -2.87682072e-01, -3.36472237e-01, -3.56674944e-01, -4.05465108e-01,\n",
       "                     -4.41832752e-01, -4.70003629e-01, -5.10825624e-01, -5.50046337e-01,\n",
       "                     -5.59615788e-01, -5.87786665e-01, -6.04419065e-01, -6.10259521e-01,\n",
       "                     -6.50587566e-01, -6.93147181e-01, -7.15620036e-01, -7.30887509e-01,\n",
       "                     -7.33969175e-01, -7.54768315e-01, -7.62140052e-01, -7.68654733e-01,\n",
       "                     -8.10930216e-01, -8.38329190e-01, -8.47297860e-01, -8.70828358e-01,\n",
       "                     -8.75468737e-01, -8.95384047e-01, -9.13111079e-01, -9.16290732e-01,\n",
       "                     -9.31558204e-01, -9.40388283e-01, -9.43606543e-01, -9.46143695e-01,\n",
       "                     -9.55511445e-01, -9.62480114e-01, -9.80829253e-01, -9.88824727e-01,\n",
       "                     -1.00144854e+00, -1.00552187e+00, -1.01160091e+00, -1.02961942e+00,\n",
       "                     -1.04273183e+00, -1.05939158e+00, -1.06025142e+00, -1.06635143e+00,\n",
       "                     -1.07263680e+00, -1.08401349e+00, -1.09861229e+00, -1.12393010e+00,\n",
       "                     -1.18377010e+00, -1.18562367e+00, -1.19213835e+00, -1.19824213e+00,\n",
       "                     -1.19869575e+00, -1.20397280e+00, -1.22377543e+00, -1.25276297e+00,\n",
       "                     -1.28093385e+00, -1.29928298e+00, -1.31824090e+00, -1.35239281e+00,\n",
       "                     -1.35783190e+00, -1.38629436e+00, -1.41019988e+00, -1.42377745e+00,\n",
       "                     -1.48160454e+00, -1.49091931e+00, -1.55814462e+00, -1.55890710e+00,\n",
       "                     -1.56397554e+00, -1.56861592e+00, -1.58412010e+00, -1.60943791e+00,\n",
       "                     -1.64865863e+00, -1.65822808e+00, -1.67397643e+00, -1.69167601e+00,\n",
       "                     -1.72276660e+00, -1.79175947e+00, -1.82454929e+00, -1.89711998e+00,\n",
       "                     -2.01490302e+00, -2.07944154e+00, -2.17475172e+00, -2.19722458e+00,\n",
       "                     -2.30258509e+00, -2.56494936e+00, -2.83321334e+00, -2.89037176e+00,\n",
       "                     -3.02042489e+00, -3.21887582e+00, -3.45387764e+01]), auc_score=0.5590171078568684, privacy_risk=0.5406750256945869, accuracy=0.5406750256945869, tpr_ind=0.5808444902162719, tnr_ind=0.5005055611729019, test_train_ratio=1.0185375901132854, dataset_size=[1942, 1978]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00448654, 0.00797607, 0.00947159, 0.01046859,\n",
       "                     0.01395813, 0.02143569, 0.02143569, 0.02442672, 0.02542373,\n",
       "                     0.02791625, 0.03140578, 0.03539382, 0.04137587, 0.04336989,\n",
       "                     0.05184447, 0.0558325 , 0.06480558, 0.07078764, 0.08225324,\n",
       "                     0.09072782, 0.10717846, 0.13110668, 0.13908275, 0.14606181,\n",
       "                     0.15304088, 0.18743769, 0.19641077, 0.19790628, 0.20189432,\n",
       "                     0.20438684, 0.20837488, 0.21984048, 0.23678963, 0.25672981,\n",
       "                     0.25822532, 0.26470588, 0.29262213, 0.30109671, 0.33399801,\n",
       "                     0.35443669, 0.36091725, 0.3664008 , 0.37238285, 0.38235294,\n",
       "                     0.4441675 , 0.44715852, 0.45214357, 0.45613161, 0.47457627,\n",
       "                     0.48554337, 0.4890329 , 0.50697906, 0.51844467, 0.52492522,\n",
       "                     0.5329013 , 0.54187438, 0.55682951, 0.5663011 , 0.63708873,\n",
       "                     0.6440678 , 0.71186441, 0.71884347, 0.72881356, 0.7337986 ,\n",
       "                     0.73978066, 0.81904287, 0.81954138, 0.86789631, 0.86939182,\n",
       "                     0.87337986, 0.87337986, 0.88135593, 0.88384845, 0.89381854,\n",
       "                     0.8998006 , 0.90279163, 0.90329013, 0.91375872, 0.91874377,\n",
       "                     0.9217348 , 0.92422732, 0.92921236, 0.92971087, 0.93868395,\n",
       "                     0.94366899, 0.95214357, 0.95912263, 0.96111665, 0.96261216,\n",
       "                     0.96859422, 1.        ]), tpr=array([0.        , 0.01097179, 0.01828631, 0.02089864, 0.02298851,\n",
       "                     0.03030303, 0.03918495, 0.04179728, 0.04388715, 0.04545455,\n",
       "                     0.05015674, 0.05433647, 0.06008359, 0.06739812, 0.07001045,\n",
       "                     0.08777429, 0.09404389, 0.10292581, 0.1107628 , 0.12016719,\n",
       "                     0.12800418, 0.15203762, 0.17711599, 0.18234065, 0.19017764,\n",
       "                     0.1969697 , 0.23928945, 0.2492163 , 0.25287356, 0.25757576,\n",
       "                     0.26280042, 0.26750261, 0.27795193, 0.29571578, 0.3077325 ,\n",
       "                     0.3092999 , 0.31870428, 0.34848485, 0.35632184, 0.39498433,\n",
       "                     0.41118077, 0.4200627 , 0.42789969, 0.43207941, 0.43991641,\n",
       "                     0.51410658, 0.51933124, 0.52507837, 0.52716823, 0.53918495,\n",
       "                     0.55485893, 0.55799373, 0.57210031, 0.58202717, 0.58986416,\n",
       "                     0.59456635, 0.60344828, 0.61337513, 0.61912226, 0.69801463,\n",
       "                     0.70323929, 0.76123302, 0.76854754, 0.7800418 , 0.78213166,\n",
       "                     0.78578892, 0.87251829, 0.87356322, 0.9184953 , 0.92215256,\n",
       "                     0.92946708, 0.93155695, 0.93521421, 0.93834901, 0.9477534 ,\n",
       "                     0.95088819, 0.95402299, 0.95506792, 0.9723093 , 0.9754441 ,\n",
       "                     0.97648903, 0.98066876, 0.98275862, 0.98380355, 0.98693835,\n",
       "                     0.98850575, 0.99111808, 0.99320794, 0.99373041, 0.99425287,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -1.82321557e-01,\n",
       "                     -2.23143551e-01, -2.51314428e-01, -2.87682072e-01, -3.36472237e-01,\n",
       "                     -3.56674944e-01, -4.05465108e-01, -4.41832752e-01, -4.70003629e-01,\n",
       "                     -5.10825624e-01, -5.38996501e-01, -5.87786665e-01, -6.00773860e-01,\n",
       "                     -6.06135804e-01, -6.08589793e-01, -6.24154309e-01, -6.35988767e-01,\n",
       "                     -6.59245629e-01, -6.75128675e-01, -6.93147181e-01, -7.41937345e-01,\n",
       "                     -7.57685702e-01, -7.67255153e-01, -7.70336819e-01, -7.77704569e-01,\n",
       "                     -7.88457360e-01, -8.10930216e-01, -8.32909123e-01, -8.47297860e-01,\n",
       "                     -8.75468737e-01, -8.80358723e-01, -8.89857475e-01, -8.97941593e-01,\n",
       "                     -9.16290732e-01, -9.31179344e-01, -9.38269639e-01, -9.42608040e-01,\n",
       "                     -9.48039430e-01, -9.73449146e-01, -9.80829253e-01, -1.01160091e+00,\n",
       "                     -1.01983141e+00, -1.02766055e+00, -1.02961942e+00, -1.03609193e+00,\n",
       "                     -1.04145387e+00, -1.05416053e+00, -1.08091271e+00, -1.09861229e+00,\n",
       "                     -1.11088238e+00, -1.13845820e+00, -1.14209740e+00, -1.14681439e+00,\n",
       "                     -1.17411984e+00, -1.20397280e+00, -1.20983792e+00, -1.21516818e+00,\n",
       "                     -1.26113122e+00, -1.26173164e+00, -1.29392104e+00, -1.31633577e+00,\n",
       "                     -1.32175584e+00, -1.34992672e+00, -1.37873575e+00, -1.38629436e+00,\n",
       "                     -1.42618569e+00, -1.45528723e+00, -1.46358604e+00, -1.50407740e+00,\n",
       "                     -1.51982575e+00, -1.54044504e+00, -1.56397554e+00, -1.57553636e+00,\n",
       "                     -1.60943791e+00, -1.70474809e+00, -1.73993440e+00, -1.78190717e+00,\n",
       "                     -1.85238409e+00, -1.89711998e+00, -1.94591015e+00, -2.01490302e+00,\n",
       "                     -2.07944154e+00, -2.12026354e+00, -2.24070969e+00, -2.30258509e+00,\n",
       "                     -2.39789527e+00, -2.48490665e+00, -2.88267941e+00, -3.45387764e+01]), auc_score=0.5513141870105461, privacy_risk=0.5364674003069163, accuracy=0.5364674003069163, tpr_ind=0.5250783699059561, tnr_ind=0.5478564307078764, test_train_ratio=1.0480668756530827, dataset_size=[1914, 2006])]})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_mia_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "07df1431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['entire_dataset_mia_privacy_risk',\n",
       "       'entire_dataset_label_0.0_mia_privacy_risk',\n",
       "       'entire_dataset_label_1.0_mia_privacy_risk',\n",
       "       'subpopulation_0.0_label_0.0_mia_privacy_risk',\n",
       "       'subpopulation_0.0_label_1.0_mia_privacy_risk',\n",
       "       'subpopulation_1.0_label_0.0_mia_privacy_risk',\n",
       "       'subpopulation_1.0_label_1.0_mia_privacy_risk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7e2f4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = df[['subpopulation_0.0_label_0.0_mia_privacy_risk',\n",
    "       'subpopulation_0.0_label_1.0_mia_privacy_risk',\n",
    "       'subpopulation_1.0_label_0.0_mia_privacy_risk',\n",
    "       'subpopulation_1.0_label_1.0_mia_privacy_risk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "24d711e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subpopulation_0.0_label_0.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_0.0_label_1.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_1.0_label_0.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_1.0_label_1.0_mia_privacy_risk</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier MIA Attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>orig</th>\n",
       "      <td>0.522190</td>\n",
       "      <td>0.544129</td>\n",
       "      <td>0.519646</td>\n",
       "      <td>0.542833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syn</th>\n",
       "      <td>0.518921</td>\n",
       "      <td>0.537485</td>\n",
       "      <td>0.516918</td>\n",
       "      <td>0.537816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dir</th>\n",
       "      <td>0.533153</td>\n",
       "      <td>0.553178</td>\n",
       "      <td>0.533770</td>\n",
       "      <td>0.554011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rew</th>\n",
       "      <td>0.521112</td>\n",
       "      <td>0.544846</td>\n",
       "      <td>0.520046</td>\n",
       "      <td>0.543980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eg</th>\n",
       "      <td>0.510543</td>\n",
       "      <td>0.521680</td>\n",
       "      <td>0.511596</td>\n",
       "      <td>0.520414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        subpopulation_0.0_label_0.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                                 \n",
       "orig                                                        0.522190   \n",
       "syn                                                         0.518921   \n",
       "dir                                                         0.533153   \n",
       "rew                                                         0.521112   \n",
       "eg                                                          0.510543   \n",
       "\n",
       "                        subpopulation_0.0_label_1.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                                 \n",
       "orig                                                        0.544129   \n",
       "syn                                                         0.537485   \n",
       "dir                                                         0.553178   \n",
       "rew                                                         0.544846   \n",
       "eg                                                          0.521680   \n",
       "\n",
       "                        subpopulation_1.0_label_0.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                                 \n",
       "orig                                                        0.519646   \n",
       "syn                                                         0.516918   \n",
       "dir                                                         0.533770   \n",
       "rew                                                         0.520046   \n",
       "eg                                                          0.511596   \n",
       "\n",
       "                        subpopulation_1.0_label_1.0_mia_privacy_risk  \n",
       "Classifier MIA Attacks                                                \n",
       "orig                                                        0.542833  \n",
       "syn                                                         0.537816  \n",
       "dir                                                         0.554011  \n",
       "rew                                                         0.543980  \n",
       "eg                                                          0.520414  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "75f230c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Classifier MIA Attacks'>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_groups.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9225fcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  orig       syn       dir       rew        eg\n",
      "--------------------------------------------  --------  --------  --------  --------  --------\n",
      "subpopulation_0.0_label_0.0_mia_privacy_risk  0.52219   0.518921  0.533153  0.521112  0.510543\n",
      "subpopulation_0.0_label_1.0_mia_privacy_risk  0.544129  0.537485  0.553178  0.544846  0.52168\n",
      "subpopulation_1.0_label_0.0_mia_privacy_risk  0.519646  0.516918  0.53377   0.520046  0.511596\n",
      "subpopulation_1.0_label_1.0_mia_privacy_risk  0.542833  0.537816  0.554011  0.54398   0.520414\n"
     ]
    }
   ],
   "source": [
    "# Tabular Format\n",
    "# importing the modules\n",
    "from tabulate import tabulate\n",
    "\n",
    " \n",
    "# displaying the DataFrame\n",
    "print(tabulate(df_groups.T, headers = 'keys', tablefmt = 'simple'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a2e6d",
   "metadata": {},
   "source": [
    "### Visualizing using novel technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6faed82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_error_metrics = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "eg_mia_error_metrics = {k: v for (k,v) in eg_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "#orig_mia_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7f5e92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_error_metrics.keys():\n",
    "    for val in orig_mia_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in eg_mia_error_metrics.keys():\n",
    "    for val in eg_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"eg\", key.replace(\"_mia_attacker_advantage\", \"\"), val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5b110698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fairness</th>\n",
       "      <th>MIA</th>\n",
       "      <th>Privacy Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.517117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.517982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.517550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.521300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.524954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.504434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.505321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.502599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.503012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.501923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Fairness                                           MIA  Privacy Risk\n",
       "0       orig               entire_dataset_mia_privacy_risk      0.517117\n",
       "1       orig               entire_dataset_mia_privacy_risk      0.517982\n",
       "2       orig               entire_dataset_mia_privacy_risk      0.517550\n",
       "3       orig               entire_dataset_mia_privacy_risk      0.521300\n",
       "4       orig               entire_dataset_mia_privacy_risk      0.524954\n",
       "..       ...                                           ...           ...\n",
       "695       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.504434\n",
       "696       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.505321\n",
       "697       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.502599\n",
       "698       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.503012\n",
       "699       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.501923\n",
       "\n",
       "[700 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"Privacy Risk\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6e8a5e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fairness</th>\n",
       "      <th>MIA</th>\n",
       "      <th>Privacy Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.517117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.517982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.517550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.521300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.524954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.504434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.505321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.502599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.503012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.501923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Fairness                                           MIA  Privacy Risk\n",
       "0       orig               entire_dataset_mia_privacy_risk      0.517117\n",
       "1       orig               entire_dataset_mia_privacy_risk      0.517982\n",
       "2       orig               entire_dataset_mia_privacy_risk      0.517550\n",
       "3       orig               entire_dataset_mia_privacy_risk      0.521300\n",
       "4       orig               entire_dataset_mia_privacy_risk      0.524954\n",
       "..       ...                                           ...           ...\n",
       "695       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.504434\n",
       "696       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.505321\n",
       "697       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.502599\n",
       "698       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.503012\n",
       "699       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.501923\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only subgroups\n",
    "df_subgroups = df[~((df[\"MIA\"] == \"entire_dataset_label_0.0_mia_privacy_risk\") | (df[\"MIA\"] == \"entire_dataset_label_1.0_mia_privacy_risk\")) ]\n",
    "df_subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0df3d1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1f504a7cb90>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 908.5x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.figure(figsize=(15,8))\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df_subgroups, x=\"MIA\", y=\"Privacy Risk\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Privacy Risk\" )\n",
    "g.set(ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359dc0bf",
   "metadata": {},
   "source": [
    "### ROC curves and AUC scores with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5b7b52ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7fb5d538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['entire_dataset_mia_auc', 'entire_dataset_mia_privacy_risk', 'entire_dataset_mia_ppv', 'entire_dataset_mia_attacker_advantage', 'entire_dataset_mia_result', 'entire_dataset_label_0.0_mia_auc', 'entire_dataset_label_0.0_mia_privacy_risk', 'entire_dataset_label_0.0_mia_ppv', 'entire_dataset_label_0.0_mia_attacker_advantage', 'entire_dataset_label_0.0_mia_result', 'entire_dataset_label_1.0_mia_auc', 'entire_dataset_label_1.0_mia_privacy_risk', 'entire_dataset_label_1.0_mia_ppv', 'entire_dataset_label_1.0_mia_attacker_advantage', 'entire_dataset_label_1.0_mia_result', 'subpopulation_0.0_label_0.0_mia_auc', 'subpopulation_0.0_label_0.0_mia_privacy_risk', 'subpopulation_0.0_label_0.0_mia_ppv', 'subpopulation_0.0_label_0.0_mia_attacker_advantage', 'subpopulation_0.0_label_0.0_mia_result', 'subpopulation_0.0_label_1.0_mia_auc', 'subpopulation_0.0_label_1.0_mia_privacy_risk', 'subpopulation_0.0_label_1.0_mia_ppv', 'subpopulation_0.0_label_1.0_mia_attacker_advantage', 'subpopulation_0.0_label_1.0_mia_result', 'subpopulation_1.0_label_0.0_mia_auc', 'subpopulation_1.0_label_0.0_mia_privacy_risk', 'subpopulation_1.0_label_0.0_mia_ppv', 'subpopulation_1.0_label_0.0_mia_attacker_advantage', 'subpopulation_1.0_label_0.0_mia_result', 'subpopulation_1.0_label_1.0_mia_auc', 'subpopulation_1.0_label_1.0_mia_privacy_risk', 'subpopulation_1.0_label_1.0_mia_ppv', 'subpopulation_1.0_label_1.0_mia_attacker_advantage', 'subpopulation_1.0_label_1.0_mia_result'])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_mia_metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for orig dataset with different subpopulations\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for key in [\"entire_dataset_mia_result\", \n",
    "            \"subpopulation_0.0_label_0.0_mia_result\",\n",
    "            \"subpopulation_0.0_label_1.0_mia_result\", \n",
    "            \"subpopulation_1.0_label_0.0_mia_result\",\n",
    "            \"subpopulation_1.0_label_1.0_mia_result\"]:\n",
    "     # fprs = [mia_res.fpr for mia_res in orig_mia_metrics[key]]\n",
    "    # tprs = [mia_res.tpr for mia_res in orig_mia_metrics[key]]\n",
    "    tprs = []\n",
    "    \n",
    "    # aucs = [mia_res.get_auc() for mia_res in orig_mia_metrics[key]]\n",
    "    aucs = []\n",
    "\n",
    "    # mean_fpr = np.mean(fprs, axis=0)\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "    for mia_res in orig_mia_metrics[key]:\n",
    "        interp_tpr = np.interp(mean_fpr, mia_res.fpr, mia_res.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(mia_res.get_auc())\n",
    "    \n",
    "    #print(mean_fpr)\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    \n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    \n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        #color=\"b\",\n",
    "        label=r\"Mean ROC for %s $\\pm$ 1 std. dev. (AUC = %0.2f $\\pm$ %0.2f)\" % ( key ,mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        #label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve with variability\",\n",
    ")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ff10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entire dataset with different subpopulations\n",
    "# fig, ax = plt.subplots(figsize=(12, 10))\n",
    "fig, ax = plt.subplots(figsize=(24, 18))\n",
    "\n",
    "for mia_metrics, name in zip([orig_mia_metrics, transf_mia_metrics], [\"orig\", \"syn\"]): \n",
    "#                               dir_mia_metrics, reweigh_mia_metrics], [\"orig\", \"syn\", \"dir\", \"reweigh\"] ):\n",
    "    for key in [\"entire_dataset_mia_result\", \n",
    "                \"subpopulation_0.0_label_0.0_mia_result\",\n",
    "                \"subpopulation_0.0_label_1.0_mia_result\", \n",
    "                \"subpopulation_1.0_label_0.0_mia_result\",\n",
    "                \"subpopulation_1.0_label_1.0_mia_result\"]:\n",
    "   \n",
    "        # fprs = [mia_res.fpr for mia_res in orig_mia_metrics[key]]\n",
    "        # tprs = [mia_res.tpr for mia_res in orig_mia_metrics[key]]\n",
    "        tprs = []\n",
    "        # aucs = [mia_res.get_auc() for mia_res in orig_mia_metrics[key]]\n",
    "        aucs = []\n",
    "\n",
    "        # mean_fpr = np.mean(fprs, axis=0)\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "        for mia_res in mia_metrics[key]:\n",
    "            print(mia_res)\n",
    "            interp_tpr = np.interp(mean_fpr, mia_res.fpr, mia_res.tpr)\n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "            aucs.append(mia_res.get_auc())\n",
    "\n",
    "        #print(mean_fpr)\n",
    "        print(tprs)\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std(aucs)\n",
    "\n",
    "        ax.plot(\n",
    "            mean_fpr,\n",
    "            mean_tpr,\n",
    "            #color=\"b\",\n",
    "            label=r\"%s Mean ROC for %s $\\pm$ 1 std. dev. (AUC = %0.2f $\\pm$ %0.2f)\" % (name, key ,mean_auc, std_auc),\n",
    "            lw=2,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        std_tpr = np.std(tprs, axis=0)\n",
    "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        ax.fill_between(\n",
    "            mean_fpr,\n",
    "            tprs_lower,\n",
    "            tprs_upper,\n",
    "            color=\"grey\",\n",
    "            alpha=0.2,\n",
    "            #label=r\"$\\pm$ 1 std. dev.\",\n",
    "        )\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve for MIA attacks against Fairness Approaches\",\n",
    ")\n",
    "ax.legend(loc=\"lower right\")\n",
    "# ax.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entire dataset\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "for mia_res in orig_mia_metrics[\"entire_dataset_mia_result\"]:\n",
    "    plt.plot(mia_res.fpr,mia_res.tpr,label=f\"{mia_res.get_name()} auc={mia_res.get_auc()}\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e701aad9",
   "metadata": {},
   "source": [
    "## MIA Attacks AUC vs Fairness Bar Chart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f18425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "egr_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in eg_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "eg_mia_metrics_mean = {k:sum(v)/N for (k,v) in eg_mia_metrics.items() if k.endswith(\"mia_auc\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a025ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b078a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuazlization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "        transf_mia_metrics_mean,\n",
    "        dir_mia_metrics_mean,\n",
    "        reweigh_mia_metrics_mean,\n",
    "        eg_mia_metrics_mean\n",
    "        ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "        transf_mia_error_metrics,\n",
    "        dir_mia_error_metrics,\n",
    "        reweigh_mia_error_metrics,\n",
    "          egr_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn']+ ['dir']+ ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2233661a",
   "metadata": {},
   "source": [
    "###  MIA Attackers Advantage Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f09191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data structures to plot point categorical plot from seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ef741",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "egr_mia_error_metrics = {k: v for (k,v) in eg_mia_metrics.items() if k.endswith(\"attacker_advantage\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87375802",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_metrics_att_ad.keys():\n",
    "    for val in orig_mia_metrics_att_ad[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in egr_mia_error_metrics.keys():\n",
    "    for val in egr_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"egr\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "advantage_metrics_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105df8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"attacker_advantage\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac8578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting without scaling y limis to 1\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"attacker_advantage\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's Advantage\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf746e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15,8))\n",
    "\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"attacker_advantage\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's Advantage\" )\n",
    "g.set(ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b0356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(orig_mia_metrics_att_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "egr_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in eg_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "eg_mia_metrics_mean = {k:sum(v)/N for (k,v) in eg_mia_metrics.items() if k.endswith(\"attacker_advantage\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e9be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuazlization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "        transf_mia_metrics_mean,\n",
    "        dir_mia_metrics_mean,\n",
    "        reweigh_mia_metrics_mean,\n",
    "           eg_mia_metrics_mean\n",
    "        ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "        transf_mia_error_metrics,\n",
    "        dir_mia_error_metrics,\n",
    "        reweigh_mia_error_metrics,\n",
    "          egr_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn']+ ['dir']+ ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1309a4",
   "metadata": {},
   "source": [
    "## PPV Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "egr_mia_error_metrics = {k: v for (k,v) in eg_mia_metrics.items() if k.endswith(\"mia_ppv\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14018577",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_metrics_att_ad.keys():\n",
    "    for val in orig_mia_metrics_att_ad[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in egr_mia_error_metrics.keys():\n",
    "    for val in egr_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"egr\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "advantage_metrics_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95980069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"PPV\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff9b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting without scaling y limis to 1\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"PPV\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's PPV\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38297706",
   "metadata": {},
   "source": [
    "# Dataset Exploration for comparison with Shokri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c85d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame([dataset_orig.features, dataset_orig.labels]).drop_duplicates()\n",
    "\n",
    "df = pd.DataFrame(dataset_orig.features, columns=dataset_orig.feature_names)\n",
    "\n",
    "df[\"labels\"] = dataset_orig.labels\n",
    "df\n",
    "#df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d14528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"age\", \"labels\"]].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f7423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352b318b",
   "metadata": {},
   "source": [
    "## DT Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd7c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_orig_model_metrics(dataset_orig_train, dataset_orig_test, unprivileged_groups, f_label, uf_label, BASELINE, SCALER, ATTACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feceb031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_egr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ad93b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
