{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8c9f6b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "151964f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f57d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from data_utils import DatasetBuilder\n",
    "from metrics_utils import compute_metrics, describe_metrics, get_test_metrics, test\n",
    "from plot_utils import plot\n",
    "from mitigators import NullMitigator, SyntheticMitigator, DIRMitigator, ReweighMitigator, EGMitigator, PRMitigator, CPPMitigator, ROMitigator \n",
    "from test_algorithms import TestAlgorithms\n",
    "from plot_utils import plot_algo_lr, plot_algo\n",
    "\n",
    "# Metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "\n",
    "# Bias insertion\n",
    "from oversample import label_bias, selection_bias \n",
    "from metrics_utils import get_orig_model_metrics\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Privacy Meter\n",
    "from privacy_meter.dataset import Dataset\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "696bb6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180b2a8",
   "metadata": {},
   "source": [
    "## Arguments & Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "564c7837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-a', '--attack'], dest='attack', nargs=None, const=None, default='mia1', type=None, choices=['mia1', 'mia2'], required=False, help='attacks: our implementation, their implementation', metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct argument parser\n",
    "import argparse\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--data\", choices=['adult', 'compas', 'german', 'bank', 'meps19', 'grade', 'law_sex'], default='compas', help=\"dataset: adult, compas, german, bank, meps19, grade\")\n",
    "ap.add_argument(\"-c\", \"--classifier\", choices=['lr', 'rf', 'svm', 'nn', 'nb'], default='lr', help=\"baseline model: lr, rf, svm, nn, nb, dt\")\n",
    "ap.add_argument(\"-m\", \"--mitigator\", choices=['dir', 'rew', 'egr', 'pr', 'cpp', 'ro'], required=False, help=\"mitigators: dir, rew, egr, pr, cpp, ro\")\n",
    "ap.add_argument(\"-b\", \"--bias\", default=0., help=\"amount of bias: o-1\")\n",
    "ap.add_argument(\"-t\", \"--biastype\", choices=['label', 'selection', 'none'], default='none', help=\"amount of bias: o-1\")\n",
    "ap.add_argument(\"-o\", \"--os\", default=2, help=\"oversample mode: 1: privi unfav 2: unpriv fav\")\n",
    "ap.add_argument(\"-a\", \"--attack\", choices=['mia1', 'mia2'], default='mia1', help=\"attacks: our implementation, their implementation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4f8856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['']\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b063bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 'compas',\n",
       " 'classifier': 'lr',\n",
       " 'mitigator': None,\n",
       " 'bias': 0.0,\n",
       " 'biastype': 'none',\n",
       " 'os': 2,\n",
       " 'attack': 'mia1'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0dd1c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"law_race_aif\"#args[\"data\"]\n",
    "BASELINE = \"dt\" #args[\"classifier\"]\n",
    "MITIGATOR = args[\"mitigator\"]\n",
    "BIAS = float(args[\"bias\"])\n",
    "BIAS_TYPE = args[\"biastype\"]\n",
    "OS_MODE = int(args[\"os\"])\n",
    "ATTACK = \"mia1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b16266c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# global constants\n",
    "if BASELINE == 'svm' or BASELINE == 'nn':\n",
    "    SCALER = False \n",
    "else:\n",
    "    SCALER = False \n",
    "DISPLAY = False \n",
    "THRESH_ARR = 0.5\n",
    "\n",
    "# loop ten times \n",
    "N = 20\n",
    "\n",
    "# percentage of favor and unfavor\n",
    "priv_metric_orig = defaultdict(float)\n",
    "favor_metric_orig = defaultdict(float)\n",
    "favor_metric_transf = defaultdict(float)\n",
    "\n",
    "# for each pre-processing approach, we create a mia_metric_results\n",
    "orig_metrics = defaultdict(list)\n",
    "orig_mia_metrics = defaultdict(list)\n",
    "\n",
    "transf_metrics = defaultdict(list) \n",
    "transf_mia_metrics = defaultdict(list) \n",
    "\n",
    "reweigh_metrics = defaultdict(list) \n",
    "reweigh_mia_metrics = defaultdict(list) \n",
    "\n",
    "dir_metrics = defaultdict(list) \n",
    "dir_mia_metrics = defaultdict(list) \n",
    "\n",
    "eg_metrics = defaultdict(list) \n",
    "eg_mia_metrics = defaultdict(list) \n",
    "\n",
    "\n",
    "pr_orig_metrics = defaultdict(list) \n",
    "cpp_metrics = defaultdict(list) \n",
    "ro_metrics = defaultdict(list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42c45e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mia1'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATTACK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a48a7",
   "metadata": {},
   "source": [
    "## Loading & Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da867c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and set the groups\n",
    "dataset_builder =  DatasetBuilder(DATASET)\n",
    "dataset_orig = dataset_builder.load_data()\n",
    "sens_attr = dataset_orig.protected_attribute_names[0]\n",
    "unprivileged_groups = dataset_builder.unprivileged_groups\n",
    "privileged_groups = dataset_builder.privileged_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9aabd2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22342, 4)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb84777c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'race': 1}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "privileged_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a78a2150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'race'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5fedd14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# favorable and unfavorable labels and feature_names\n",
    "f_label = dataset_orig.favorable_label\n",
    "uf_label = dataset_orig.unfavorable_label\n",
    "feature_names = dataset_orig.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1fb1ad08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.5        0.75      ]\n",
      " [1.         1.         0.81081081 0.8       ]\n",
      " [1.         1.         0.35135135 0.65      ]\n",
      " ...\n",
      " [1.         0.         0.58108108 0.625     ]\n",
      " [1.         0.         0.60810811 0.85      ]\n",
      " [0.         0.         0.54054054 0.7       ]]\n",
      "no bias type specified\n"
     ]
    }
   ],
   "source": [
    "if ATTACK == \"mia1\":\n",
    "    # training data split ratio\n",
    "    p = 0.5\n",
    "    # split dataset into train, validation, and test\n",
    "    dataset_orig_train, dataset_orig_test = dataset_orig.split([p], shuffle=True)\n",
    "    dataset_orig_val = dataset_orig_test\n",
    "    print(dataset_orig_train.features)\n",
    "\n",
    "    # introduce label or selection biases, assuming the original data is fair\n",
    "    if BIAS_TYPE == 'label':\n",
    "        dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    elif BIAS_TYPE == 'selection':\n",
    "        dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    else:\n",
    "        print('no bias type specified')\n",
    "        \n",
    "    dataset_orig_train\n",
    "    dataset_orig_train?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cfd5f8",
   "metadata": {},
   "source": [
    "## Run Mitigating Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3ae7f8",
   "metadata": {},
   "source": [
    "### Setup for MIA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ad51a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "14350dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ATTACK == \"mia2\":\n",
    "    # prepare data format\n",
    "    X = dataset_orig.features\n",
    "    y_true = dataset_orig.labels.ravel()\n",
    "    sens_attr = dataset_orig.protected_attribute_names[0]\n",
    "    sens_attr_index = dataset_orig.feature_names.index(sens_attr)\n",
    "    sensitive_features = dataset_orig.features[:, sens_attr_index]\n",
    "\n",
    "    X_other_features = np.delete(X, sens_attr_index, axis=1)\n",
    "    X_other_features_normalized = preprocessing.normalize(X_other_features, norm='l2')\n",
    "\n",
    "    # Reconstruct X by combining the sensitive attribute and the normalized features\n",
    "    # Insert the sensitive attribute back into its original position\n",
    "    X_normalized = np.insert(X_other_features_normalized, sens_attr_index, sensitive_features, axis=1)\n",
    "    X = X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89c1ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_indices_reference():\n",
    "    # Determine split sizes proportionally (to sum up to the full dataset size)\n",
    "    num_train_points = int(X.shape[0] * 0.12)\n",
    "    num_test_points = int(X.shape[0] * 0.12)\n",
    "    num_population_points = int(X.shape[0] * 0.3)  # Reduced from 30000\n",
    "\n",
    "    # Start with all indices\n",
    "    all_indices = np.arange(X.shape[0])\n",
    "\n",
    "    # Select train indices without replacement\n",
    "    train_index = np.random.choice(all_indices, num_train_points, replace=False)\n",
    "    # Remove train indices from available indices\n",
    "    remaining_indices = np.setdiff1d(all_indices, train_index)\n",
    "\n",
    "    # Select test indices from the remaining indices without replacement\n",
    "    test_index = np.random.choice(remaining_indices, num_test_points, replace=False)\n",
    "    # Remove test indices from available indices\n",
    "    remaining_indices = np.setdiff1d(remaining_indices, test_index)\n",
    "\n",
    "    # Select population indices from the remaining indices (can also choose all remaining points)\n",
    "    population_index = np.random.choice(remaining_indices, min(num_population_points, len(remaining_indices)), replace=False)\n",
    "\n",
    "    # Summary of counts\n",
    "    print(\"==============================================================\")\n",
    "    print(\"GET UNIQUE INDICES REFERENCE\")\n",
    "    print(f\"Number of train points: {len(train_index)}\")\n",
    "    print(f\"Number of test points: {len(test_index)}\")\n",
    "    print(f\"Number of population points: {len(population_index)}\")\n",
    "    print(\"==============================================================\")\n",
    "    \n",
    "    return train_index, test_index, population_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "414d335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(train_index, test_index, population_index, g_train, g_test, g_pop_train):\n",
    "    # create the target model's dataset\n",
    "    train_ds = {'x': X[train_index], 'y': y_true[train_index],'g':g_train}\n",
    "    test_ds = {'x': X[test_index], 'y': y_true[test_index], 'g':g_test}\n",
    "    target_dataset = Dataset(\n",
    "        data_dict={'train': train_ds, 'test': test_ds},\n",
    "        default_input='x', default_output='y', default_group='g'\n",
    "    )\n",
    "\n",
    "    # create the reference dataset\n",
    "    population_ds = {'x': X[population_index], 'y': y_true[population_index], 'g': g_pop_train}\n",
    "    reference_dataset = Dataset(\n",
    "        data_dict={'train': population_ds},\n",
    "        default_input='x', default_output='y', default_group='g'\n",
    "    )\n",
    "    \n",
    "    return target_dataset, reference_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e23be8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features, labels, and protected attributes into a DataFrame\n",
    "def create_binary_label_dataset(dataset_orig, X, y, sensitive_features, sens_attr_name, privileged_value, unprivileged_value):\n",
    "    print(\"=====================================================\")\n",
    "    print(\"CREATE BINARY LABEL DATASET\")\n",
    "    # Extract the feature names from the original dataset\n",
    "    feature_names = dataset_orig.feature_names\n",
    "\n",
    "    # Create a DataFrame with features, labels, and sensitive attribute\n",
    "    df = pd.DataFrame(X, columns=feature_names)\n",
    "    df[dataset_orig.label_names[0]] = y\n",
    "#     df[sens_attr_name] = sensitive_features\n",
    "\n",
    "    print(df.head())\n",
    "    # print(dataset_orig.feature_names)\n",
    "    # print(dataset_orig.features.shape)\n",
    "    \n",
    "    # df_orig, _ = dataset_orig.convert_to_dataframe()\n",
    "\n",
    "    # # Display the first few rows\n",
    "    # print(\"Original df's head:\", df_orig.head())\n",
    "    \n",
    "    # Get the unique labels and their counts\n",
    "    # unique_labels, counts = np.unique(dataset_orig.labels, return_counts=True)\n",
    "\n",
    "    # # Print the value counts\n",
    "    # for label, count in zip(unique_labels, counts):\n",
    "    #     print(f\"Label {label}: {count} instances\")\n",
    "\n",
    "    # Create the BinaryLabelDataset\n",
    "    dataset = BinaryLabelDataset(\n",
    "        favorable_label=1.0,  # Adjust as per your dataset\n",
    "        unfavorable_label=0.0,  # Adjust as per your dataset\n",
    "        df=df,  # DataFrame containing features, labels, and protected attribute\n",
    "        label_names=dataset_orig.label_names,  # Column name of labels in DataFrame\n",
    "        protected_attribute_names=[sens_attr_name],  # Protected attribute column\n",
    "        privileged_protected_attributes=[privileged_value],  # Privileged group values\n",
    "        unprivileged_protected_attributes=[unprivileged_value]  # Unprivileged group values\n",
    "    )\n",
    "    \n",
    "    # print(dataset.feature_names)\n",
    "    # print(dataset.features.shape)\n",
    "    # # Get the unique labels and their counts\n",
    "    # unique_labels, counts = np.unique(dataset.labels, return_counts=True)\n",
    "\n",
    "    # Print the value counts\n",
    "    # for label, count in zip(unique_labels, counts):\n",
    "    #     print(f\"Label {label}: {count} instances\")\n",
    "    \n",
    "    print(\"=====================================================\")\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "22a3f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_logs():\n",
    "    # Search for directories ending with _group or _pop\n",
    "    for pattern in [\"*_group\", \"*_pop\"]:\n",
    "        # Find matching directories\n",
    "        for log_dir in glob.glob(pattern):\n",
    "            if os.path.exists(log_dir) and os.path.isdir(log_dir):  # Ensure it's a directory\n",
    "                shutil.rmtree(log_dir)\n",
    "                print(f\"{log_dir} deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31097df4",
   "metadata": {},
   "source": [
    "### Calling Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b3d0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = None\n",
    "reference_dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eea401f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Train dataset's features are as below:\n",
      "[[1.         0.         0.86486486 0.825     ]\n",
      " [1.         0.         0.64864865 0.9       ]\n",
      " [1.         0.         0.81081081 0.75      ]\n",
      " ...\n",
      " [1.         0.         0.86486486 0.9       ]\n",
      " [1.         0.         0.78378378 0.75      ]\n",
      " [1.         1.         0.59459459 0.85      ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10290.0 881.0\n",
      "base_pos unpriv:  0.06923950056753689\n",
      "base_pos priv:  0.31982507288629736\n",
      "number of favorable labels:  3352\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.250586\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 820\n",
      "Number of test samples (ntest): 771\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 6999\n",
      "Number of test samples (ntest): 7034\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3291\n",
      "Number of test samples (ntest): 3317\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.95      0.83      7819\n",
      "         1.0       0.62      0.18      0.27      3352\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.57      0.55     11171\n",
      "weighted avg       0.70      0.72      0.66     11171\n",
      "\n",
      "Train accuracy:  0.7204368454032763\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.55\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4274440148269396\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7819, Test = 7805\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4274440148269396\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3352, Test = 3366\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.176777061517446\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 820, Test = 771\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.11778303565638351\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.91\n",
      "  Privacy Risk: 0.86\n",
      "  Accuracy: 0.86\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.72\n",
      "  Positive predictive value: 0.95\n",
      "  Optimal thershold: -2.3025850929940455\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6999, Test = 7034\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4274440148269396\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3291, Test = 3317\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.176777061517446\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11495\n",
      "after transf priv:  0.31982507288629736\n",
      "after transf unpriv:  0.31950207468879666\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000323\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 820\n",
      "Number of test samples (ntest): 771\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 6999\n",
      "Number of test samples (ntest): 7034\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3291\n",
      "Number of test samples (ntest): 3317\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7819\n",
      "         1.0       0.70      0.19      0.30      3676\n",
      "\n",
      "    accuracy                           0.72     11495\n",
      "   macro avg       0.71      0.58      0.56     11495\n",
      "weighted avg       0.71      0.72      0.66     11495\n",
      "\n",
      "Train accuracy:  0.7153545019573728\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7819, Test = 7805\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.38946476676172315\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3352, Test = 3366\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.39\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.9707789171582248\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 820, Test = 771\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.08701137698962981\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.82\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.76\n",
      "  Attacker advantage: 0.51\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -1.5040773967762742\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6999, Test = 7034\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.38776553100876343\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3291, Test = 3317\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.39\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -0.9707789171582248\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 820\n",
      "Number of test samples (ntest): 771\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 6999\n",
      "Number of test samples (ntest): 7034\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3291\n",
      "Number of test samples (ntest): 3317\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7819\n",
      "         1.0       0.63      0.14      0.23      3352\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7173932503804494\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.34\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.42\n",
      "  Test Accuracy (TNR): 0.70\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.3610133455373305\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7819, Test = 7805\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.3610133455373305\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3352, Test = 3366\n",
      "  AUC: 0.49\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.05\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -2.0794415416798357\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 820, Test = 771\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.87\n",
      "  Privacy Risk: 0.85\n",
      "  Accuracy: 0.85\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.70\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -3.044522437723423\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6999, Test = 7034\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.3610133455373305\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3291, Test = 3317\n",
      "  AUC: 0.48\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.04\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -2.0794415416798357\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 820\n",
      "Number of test samples (ntest): 771\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 6999\n",
      "Number of test samples (ntest): 7034\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3291\n",
      "Number of test samples (ntest): 3317\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7819\n",
      "         1.0       0.60      0.15      0.24      3352\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.66      0.55      0.53     11171\n",
      "weighted avg       0.69      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7147972428609793\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.24000000000000002\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.45\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.3431237324739157\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7819, Test = 7805\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3431237324739157\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3352, Test = 3366\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.2416090561325235\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 820, Test = 771\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.21\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.2762546634424632\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.96\n",
      "  Privacy Risk: 0.91\n",
      "  Accuracy: 0.91\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.84\n",
      "  Attacker advantage: 0.82\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -1.497502283964529\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6999, Test = 7034\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.3431237324739157\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3291, Test = 3317\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.2416090561325235\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 820\n",
      "Number of test samples (ntest): 771\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 6999\n",
      "Number of test samples (ntest): 7034\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3291\n",
      "Number of test samples (ntest): 3317\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7819\n",
      "         1.0       0.57      0.14      0.23      3352\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.55      0.52     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7104108853280816\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.41000000000000003\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7819, Test = 7805\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3352, Test = 3366\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.18\n",
      "  Test Accuracy (TNR): 0.86\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -1.4387235726583005\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 820, Test = 771\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.50\n",
      "  Train Accuracy (TPR): 0.00\n",
      "  Test Accuracy (TNR): 1.00\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: 0.999999999999999\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.64\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.76\n",
      "  Attacker advantage: 0.28\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -1.4387235726583005\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6999, Test = 7034\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3291, Test = 3317\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.17\n",
      "  Test Accuracy (TNR): 0.86\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -1.4387235726583005\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.81081081 0.875     ]\n",
      " [1.         1.         0.89189189 0.85      ]\n",
      " [1.         0.         0.94594595 0.8       ]\n",
      " ...\n",
      " [1.         0.         0.91891892 0.9       ]\n",
      " [1.         1.         0.75675676 0.725     ]\n",
      " [1.         1.         0.89189189 0.575     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10301.0 870.0\n",
      "base_pos unpriv:  0.067816091954023\n",
      "base_pos priv:  0.3135617901174643\n",
      "number of favorable labels:  3289\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.245746\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 811\n",
      "Number of test samples (ntest): 780\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 59\n",
      "Number of test samples (ntest): 51\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7071\n",
      "Number of test samples (ntest): 6962\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3230\n",
      "Number of test samples (ntest): 3378\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.97      0.83      7882\n",
      "         1.0       0.63      0.13      0.22      3289\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.52     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7214215379106615\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.31\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.41494385206270806\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7882, Test = 7742\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.41494385206270806\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3289, Test = 3429\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.45\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.0116009116784799\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 811, Test = 780\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.04\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 59, Test = 51\n",
      "  AUC: 0.82\n",
      "  Privacy Risk: 0.78\n",
      "  Accuracy: 0.78\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.55\n",
      "  Positive predictive value: 0.85\n",
      "  Optimal thershold: -3.4011973816621555\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7071, Test = 6962\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.41494385206270806\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3230, Test = 3378\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.45\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.0116009116784799\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11482\n",
      "after transf priv:  0.3135617901174643\n",
      "after transf unpriv:  0.31329381879762913\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000268\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 811\n",
      "Number of test samples (ntest): 780\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 59\n",
      "Number of test samples (ntest): 51\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7071\n",
      "Number of test samples (ntest): 6962\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3230\n",
      "Number of test samples (ntest): 3378\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.82      7882\n",
      "         1.0       0.71      0.17      0.27      3600\n",
      "\n",
      "    accuracy                           0.72     11482\n",
      "   macro avg       0.71      0.57      0.55     11482\n",
      "weighted avg       0.72      0.72      0.65     11482\n",
      "\n",
      "Train accuracy:  0.7174708238982755\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.33\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.8018803806964109\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7882, Test = 7742\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.55\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.339007092224401\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3289, Test = 3429\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.22\n",
      "  Test Accuracy (TNR): 0.84\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -0.8472978603872037\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 811, Test = 780\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.7731898882334817\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 59, Test = 51\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.70\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.40\n",
      "  Positive predictive value: 0.81\n",
      "  Optimal thershold: -1.6183532760920527\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7071, Test = 6962\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.339007092224401\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3230, Test = 3378\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.21\n",
      "  Test Accuracy (TNR): 0.84\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -0.8472978603872037\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 811\n",
      "Number of test samples (ntest): 780\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 59\n",
      "Number of test samples (ntest): 51\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7071\n",
      "Number of test samples (ntest): 6962\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3230\n",
      "Number of test samples (ntest): 3378\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.98      0.83      7882\n",
      "         1.0       0.67      0.11      0.19      3289\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.70      0.54      0.51     11171\n",
      "weighted avg       0.71      0.72      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7221376779160326\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5436154465889816\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7882, Test = 7742\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5436154465889816\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3289, Test = 3429\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -1.2878542883066382\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 811, Test = 780\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.1823215567939546\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 59, Test = 51\n",
      "  AUC: 0.79\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.76\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.80\n",
      "  Optimal thershold: -2.1972245773362196\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7071, Test = 6962\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5436154465889816\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3230, Test = 3378\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -1.2878542883066382\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 811\n",
      "Number of test samples (ntest): 780\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 59\n",
      "Number of test samples (ntest): 51\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7071\n",
      "Number of test samples (ntest): 6962\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3230\n",
      "Number of test samples (ntest): 3378\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83      7882\n",
      "         1.0       0.59      0.12      0.21      3289\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.66      0.54      0.52     11171\n",
      "weighted avg       0.68      0.72      0.64     11171\n",
      "\n",
      "Train accuracy:  0.716587592874407\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.9292373254321386\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7882, Test = 7742\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3168923267751782\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3289, Test = 3429\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.1474743139953727\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 811, Test = 780\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.1728617617903918\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 59, Test = 51\n",
      "  AUC: 0.85\n",
      "  Privacy Risk: 0.83\n",
      "  Accuracy: 0.83\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.66\n",
      "  Positive predictive value: 0.84\n",
      "  Optimal thershold: -1.1474743139953727\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7071, Test = 6962\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.3168923267751782\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3230, Test = 3378\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.144573086737242\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 811\n",
      "Number of test samples (ntest): 780\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 59\n",
      "Number of test samples (ntest): 51\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7071\n",
      "Number of test samples (ntest): 6962\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3230\n",
      "Number of test samples (ntest): 3378\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.83      7882\n",
      "         1.0       0.57      0.13      0.21      3289\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.65      0.54      0.52     11171\n",
      "weighted avg       0.68      0.72      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7150657953629934\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.02\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.665197616094677\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7882, Test = 7742\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.05\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.016710003828231165\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3289, Test = 3429\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.13\n",
      "  Test Accuracy (TNR): 0.91\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.665197616094677\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 811, Test = 780\n",
      "  AUC: 0.49\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.06\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.016710003828231165\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 59, Test = 51\n",
      "  AUC: 0.48\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.19\n",
      "  Test Accuracy (TNR): 0.94\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.79\n",
      "  Optimal thershold: -0.665197616094677\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7071, Test = 6962\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.06\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3230, Test = 3378\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.14\n",
      "  Test Accuracy (TNR): 0.90\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -4.100091074875006\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         0.         0.78378378 0.85      ]\n",
      " [1.         1.         0.78378378 0.75      ]\n",
      " [1.         1.         0.63513514 0.7       ]\n",
      " ...\n",
      " [1.         1.         0.2972973  0.8       ]\n",
      " [1.         0.         0.59459459 0.9       ]\n",
      " [1.         0.         0.91891892 0.925     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10311.0 860.0\n",
      "base_pos unpriv:  0.05813953488372093\n",
      "base_pos priv:  0.318397827562797\n",
      "number of favorable labels:  3333\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.260258\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 810\n",
      "Number of test samples (ntest): 781\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7028\n",
      "Number of test samples (ntest): 7005\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3283\n",
      "Number of test samples (ntest): 3325\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83      7838\n",
      "         1.0       0.63      0.14      0.23      3333\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7194521528958912\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.34\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.0799201556559572\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7838, Test = 7786\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3184537311185346\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3333, Test = 3385\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -1.1430640512389436\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 810, Test = 781\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.10536051565782628\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.92\n",
      "  Privacy Risk: 0.86\n",
      "  Accuracy: 0.86\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.85\n",
      "  Attacker advantage: 0.73\n",
      "  Positive predictive value: 0.92\n",
      "  Optimal thershold: -2.5649493574615367\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7028, Test = 7005\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.41\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3184537311185346\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3283, Test = 3325\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -1.1430640512389436\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11499\n",
      "after transf priv:  0.318397827562797\n",
      "after transf unpriv:  0.3181818181818182\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000216\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 810\n",
      "Number of test samples (ntest): 781\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7028\n",
      "Number of test samples (ntest): 7005\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3283\n",
      "Number of test samples (ntest): 3325\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.97      0.82      7838\n",
      "         1.0       0.74      0.17      0.27      3661\n",
      "\n",
      "    accuracy                           0.72     11499\n",
      "   macro avg       0.73      0.57      0.55     11499\n",
      "weighted avg       0.72      0.72      0.65     11499\n",
      "\n",
      "Train accuracy:  0.715888338116358\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.1430640512389436\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7838, Test = 7786\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.34\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.28141245943818544\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3333, Test = 3385\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -1.1430640512389436\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 810, Test = 781\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.19237189264745613\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.88\n",
      "  Privacy Risk: 0.84\n",
      "  Accuracy: 0.84\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.83\n",
      "  Attacker advantage: 0.67\n",
      "  Positive predictive value: 0.91\n",
      "  Optimal thershold: -1.6094379124341003\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7028, Test = 7005\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.5147091237923882\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3283, Test = 3325\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -1.1430640512389436\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 810\n",
      "Number of test samples (ntest): 781\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7028\n",
      "Number of test samples (ntest): 7005\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3283\n",
      "Number of test samples (ntest): 3325\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7838\n",
      "         1.0       0.63      0.14      0.22      3333\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7181093903858204\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.32\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.38\n",
      "  Test Accuracy (TNR): 0.68\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.34032580593720285\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7838, Test = 7786\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.34032580593720285\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3333, Test = 3385\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.6020029339465822\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 810, Test = 781\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.05715841383994864\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.92\n",
      "  Privacy Risk: 0.92\n",
      "  Accuracy: 0.92\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.85\n",
      "  Positive predictive value: 0.87\n",
      "  Optimal thershold: -2.341805806147327\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7028, Test = 7005\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.34032580593720285\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3283, Test = 3325\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.3523928094442093\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 810\n",
      "Number of test samples (ntest): 781\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7028\n",
      "Number of test samples (ntest): 7005\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3283\n",
      "Number of test samples (ntest): 3325\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7838\n",
      "         1.0       0.61      0.11      0.19      3333\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.66      0.54      0.51     11171\n",
      "weighted avg       0.69      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7138125503535941\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.26\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.16\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.2080178614432036\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7838, Test = 7786\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.47795880496427207\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3333, Test = 3385\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -1.2080178614432036\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 810, Test = 781\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.6851743158244724\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.97\n",
      "  Privacy Risk: 0.94\n",
      "  Accuracy: 0.94\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.92\n",
      "  Attacker advantage: 0.88\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -0.7011841230932843\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7028, Test = 7005\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.47795880496427207\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3283, Test = 3325\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.61\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -1.2080178614432036\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 810\n",
      "Number of test samples (ntest): 781\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7028\n",
      "Number of test samples (ntest): 7005\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3283\n",
      "Number of test samples (ntest): 3325\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7838\n",
      "         1.0       0.57      0.13      0.21      3333\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.54      0.52     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7114850953361382\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.38\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -2.9948900859254017\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7838, Test = 7786\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3333, Test = 3385\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.15\n",
      "  Test Accuracy (TNR): 0.89\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -2.9948900859254017\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 810, Test = 781\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.69\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.82\n",
      "  Attacker advantage: 0.38\n",
      "  Positive predictive value: 0.88\n",
      "  Optimal thershold: -2.9948900859254017\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7028, Test = 7005\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.06\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3283, Test = 3325\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.15\n",
      "  Test Accuracy (TNR): 0.89\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -2.9948900859254017\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         0.         0.97297297 0.85      ]\n",
      " [1.         0.         0.67567568 0.875     ]\n",
      " [1.         0.         0.91891892 0.875     ]\n",
      " ...\n",
      " [1.         0.         0.64864865 1.        ]\n",
      " [1.         0.         0.72972973 0.925     ]\n",
      " [1.         1.         0.83783784 0.875     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10311.0 860.0\n",
      "base_pos unpriv:  0.06279069767441861\n",
      "base_pos priv:  0.32392590437396956\n",
      "number of favorable labels:  3394\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.261135\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 806\n",
      "Number of test samples (ntest): 785\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 6971\n",
      "Number of test samples (ntest): 7062\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3340\n",
      "Number of test samples (ntest): 3268\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.98      0.83      7777\n",
      "         1.0       0.66      0.10      0.18      3394\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.69      0.54      0.50     11171\n",
      "weighted avg       0.70      0.71      0.63     11171\n",
      "\n",
      "Train accuracy:  0.7113955778354668\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.1557707025080584\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7777, Test = 7847\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.46292216313295165\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3394, Test = 3324\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -1.1557707025080584\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 806, Test = 785\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.03509131981127006\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.91\n",
      "  Privacy Risk: 0.83\n",
      "  Accuracy: 0.83\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.79\n",
      "  Attacker advantage: 0.66\n",
      "  Positive predictive value: 0.93\n",
      "  Optimal thershold: -2.384823191231018\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6971, Test = 7062\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.46292216313295165\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3340, Test = 3268\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.1557707025080584\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11503\n",
      "after transf priv:  0.32392590437396956\n",
      "after transf unpriv:  0.3238255033557047\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000100\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 806\n",
      "Number of test samples (ntest): 785\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 6971\n",
      "Number of test samples (ntest): 7062\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3340\n",
      "Number of test samples (ntest): 3268\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.98      0.82      7777\n",
      "         1.0       0.77      0.15      0.25      3726\n",
      "\n",
      "    accuracy                           0.71     11503\n",
      "   macro avg       0.74      0.56      0.54     11503\n",
      "weighted avg       0.73      0.71      0.64     11503\n",
      "\n",
      "Train accuracy:  0.7100756324437103\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.1451323043030026\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7777, Test = 7847\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.42819335918572043\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3394, Test = 3324\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.1451323043030026\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 806, Test = 785\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.10536051565782628\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.83\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.75\n",
      "  Attacker advantage: 0.55\n",
      "  Positive predictive value: 0.83\n",
      "  Optimal thershold: -1.540445040947149\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6971, Test = 7062\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.42819335918572043\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3340, Test = 3268\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.1451323043030026\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 806\n",
      "Number of test samples (ntest): 785\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 6971\n",
      "Number of test samples (ntest): 7062\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3340\n",
      "Number of test samples (ntest): 3268\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.82      7777\n",
      "         1.0       0.63      0.12      0.20      3394\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.67      0.54      0.51     11171\n",
      "weighted avg       0.69      0.71      0.63     11171\n",
      "\n",
      "Train accuracy:  0.7110375078327813\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -1.2840155119994723\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7777, Test = 7847\n",
      "  AUC: 0.47\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.04\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.8023464725249373\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3394, Test = 3324\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -1.2840155119994723\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 806, Test = 785\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.03\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.6406569979385488\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.87\n",
      "  Privacy Risk: 0.82\n",
      "  Accuracy: 0.82\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.75\n",
      "  Attacker advantage: 0.64\n",
      "  Positive predictive value: 0.94\n",
      "  Optimal thershold: -2.3513752571634776\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6971, Test = 7062\n",
      "  AUC: 0.47\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.05\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.8023464725249373\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3340, Test = 3268\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.17\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -1.2840155119994723\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 806\n",
      "Number of test samples (ntest): 785\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 6971\n",
      "Number of test samples (ntest): 7062\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3340\n",
      "Number of test samples (ntest): 3268\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.97      0.82      7777\n",
      "         1.0       0.60      0.10      0.17      3394\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.54      0.50     11171\n",
      "weighted avg       0.68      0.71      0.62     11171\n",
      "\n",
      "Train accuracy:  0.7061140452958553\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.3595368998435862\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7777, Test = 7847\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4571930542718354\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3394, Test = 3324\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.3050553251429036\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 806, Test = 785\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.10340893344735054\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.89\n",
      "  Privacy Risk: 0.87\n",
      "  Accuracy: 0.87\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.75\n",
      "  Attacker advantage: 0.73\n",
      "  Positive predictive value: 0.86\n",
      "  Optimal thershold: -1.7507733015032847\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6971, Test = 7062\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4571930542718354\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3340, Test = 3268\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.3050553251429036\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 806\n",
      "Number of test samples (ntest): 785\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 6971\n",
      "Number of test samples (ntest): 7062\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3340\n",
      "Number of test samples (ntest): 3268\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.96      0.82      7777\n",
      "         1.0       0.59      0.12      0.20      3394\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.54      0.51     11171\n",
      "weighted avg       0.68      0.71      0.63     11171\n",
      "\n",
      "Train accuracy:  0.7070092203025692\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.09999999999999999\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -2.41998364375292\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7777, Test = 7847\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.09312794170361269\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3394, Test = 3324\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.14\n",
      "  Test Accuracy (TNR): 0.89\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -2.41998364375292\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 806, Test = 785\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.09312794170361269\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -2.41998364375292\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6971, Test = 7062\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.05\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.09312794170361269\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3340, Test = 3268\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.12\n",
      "  Test Accuracy (TNR): 0.89\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -2.41998364375292\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.67567568 0.775     ]\n",
      " [1.         1.         0.48648649 0.9       ]\n",
      " [1.         1.         0.97297297 0.925     ]\n",
      " ...\n",
      " [1.         0.         0.91891892 0.9       ]\n",
      " [0.         0.         0.54054054 0.75      ]\n",
      " [1.         0.         0.72972973 0.75      ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10332.0 839.0\n",
      "base_pos unpriv:  0.05959475566150179\n",
      "base_pos priv:  0.320267131242741\n",
      "number of favorable labels:  3359\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.260672\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 789\n",
      "Number of test samples (ntest): 802\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7023\n",
      "Number of test samples (ntest): 7010\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3309\n",
      "Number of test samples (ntest): 3299\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.83      7812\n",
      "         1.0       0.63      0.14      0.23      3359\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7176618028824635\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.5090057870490047\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7812, Test = 7812\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4769240720903093\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3359, Test = 3359\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.0736109864626924\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 789, Test = 802\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.84\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.55\n",
      "  Positive predictive value: 0.86\n",
      "  Optimal thershold: -3.1986731175506815\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7023, Test = 7010\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.4769240720903093\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3309, Test = 3299\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.0736109864626924\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11492\n",
      "after transf priv:  0.320267131242741\n",
      "after transf unpriv:  0.31982758620689655\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000440\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 789\n",
      "Number of test samples (ntest): 802\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7023\n",
      "Number of test samples (ntest): 7010\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3309\n",
      "Number of test samples (ntest): 3299\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.82      7812\n",
      "         1.0       0.74      0.19      0.30      3680\n",
      "\n",
      "    accuracy                           0.72     11492\n",
      "   macro avg       0.73      0.58      0.56     11492\n",
      "weighted avg       0.72      0.72      0.66     11492\n",
      "\n",
      "Train accuracy:  0.7188478941872607\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.5596157879354228\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7812, Test = 7812\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.5596157879354228\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3359, Test = 3359\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.0840134892469568\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 789, Test = 802\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.0953101798043249\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.82\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.58\n",
      "  Positive predictive value: 0.78\n",
      "  Optimal thershold: -3.2188758248682006\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7023, Test = 7010\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.5596157879354228\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3309, Test = 3299\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.0840134892469568\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 789\n",
      "Number of test samples (ntest): 802\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7023\n",
      "Number of test samples (ntest): 7010\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3309\n",
      "Number of test samples (ntest): 3299\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.83      7812\n",
      "         1.0       0.62      0.15      0.24      3359\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.56      0.53     11171\n",
      "weighted avg       0.69      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7173932503804494\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.35000000000000003\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.5440040224633094\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7812, Test = 7812\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.16\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.45198512374305727\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3359, Test = 3359\n",
      "  AUC: 0.49\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -1.6376087894007967\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 789, Test = 802\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.04\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.83\n",
      "  Privacy Risk: 0.80\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.78\n",
      "  Attacker advantage: 0.60\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -2.3025850929940455\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7023, Test = 7010\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.45198512374305727\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3309, Test = 3299\n",
      "  AUC: 0.49\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -1.6376087894007967\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 789\n",
      "Number of test samples (ntest): 802\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7023\n",
      "Number of test samples (ntest): 7010\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3309\n",
      "Number of test samples (ntest): 3299\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7812\n",
      "         1.0       0.62      0.13      0.22      3359\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.67      0.55      0.52     11171\n",
      "weighted avg       0.69      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7149762778623221\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.5829985873345802\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7812, Test = 7812\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.41011565667590677\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3359, Test = 3359\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.1998605581667836\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 789, Test = 802\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.2798914274519186\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.88\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.85\n",
      "  Attacker advantage: 0.59\n",
      "  Positive predictive value: 0.88\n",
      "  Optimal thershold: -1.0766242505170354\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7023, Test = 7010\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.41011565667590677\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3309, Test = 3299\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.1998605581667836\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 789\n",
      "Number of test samples (ntest): 802\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7023\n",
      "Number of test samples (ntest): 7010\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3309\n",
      "Number of test samples (ntest): 3299\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7812\n",
      "         1.0       0.60      0.13      0.21      3359\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.66      0.55      0.52     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7120222003401665\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.0242276289105821\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7812, Test = 7812\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.0242276289105821\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3359, Test = 3359\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.14\n",
      "  Test Accuracy (TNR): 0.90\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -1.3874008497884862\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 789, Test = 802\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.0242276289105821\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.40\n",
      "  Test Accuracy (TNR): 0.83\n",
      "  Attacker advantage: 0.23\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -1.3874008497884862\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7023, Test = 7010\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.06\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3309, Test = 3299\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.14\n",
      "  Test Accuracy (TNR): 0.90\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -3.7323509636907186\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.83783784 0.9       ]\n",
      " [1.         1.         0.64864865 0.775     ]\n",
      " [1.         0.         0.62162162 0.775     ]\n",
      " ...\n",
      " [1.         0.         0.78378378 0.875     ]\n",
      " [1.         1.         0.91891892 0.85      ]\n",
      " [0.         0.         0.56756757 0.55      ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10334.0 837.0\n",
      "base_pos unpriv:  0.06571087216248507\n",
      "base_pos priv:  0.32059221985678343\n",
      "number of favorable labels:  3368\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.254881\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 782\n",
      "Number of test samples (ntest): 809\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 55\n",
      "Number of test samples (ntest): 55\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7021\n",
      "Number of test samples (ntest): 7012\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3313\n",
      "Number of test samples (ntest): 3295\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.95      0.82      7803\n",
      "         1.0       0.61      0.19      0.28      3368\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.57      0.55     11171\n",
      "weighted avg       0.69      0.72      0.66     11171\n",
      "\n",
      "Train accuracy:  0.7183779428878345\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.9985288301111273\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7803, Test = 7821\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4595323293784402\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3368, Test = 3350\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.9985288301111273\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 782, Test = 809\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.36\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 55, Test = 55\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.81\n",
      "  Optimal thershold: -2.833213344056216\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7021, Test = 7012\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.4595323293784402\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3313, Test = 3295\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.9985288301111273\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11485\n",
      "after transf priv:  0.32059221985678343\n",
      "after transf unpriv:  0.3205907906168549\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000001\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 782\n",
      "Number of test samples (ntest): 809\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 55\n",
      "Number of test samples (ntest): 55\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7021\n",
      "Number of test samples (ntest): 7012\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3313\n",
      "Number of test samples (ntest): 3295\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7803\n",
      "         1.0       0.68      0.19      0.30      3682\n",
      "\n",
      "    accuracy                           0.71     11485\n",
      "   macro avg       0.70      0.57      0.56     11485\n",
      "weighted avg       0.70      0.71      0.65     11485\n",
      "\n",
      "Train accuracy:  0.7118850674793209\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.32\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.8967461358011849\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7803, Test = 7821\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.46780823868229987\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3368, Test = 3350\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.49\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.0330150061822965\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 782, Test = 809\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.36870421213309457\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 55, Test = 55\n",
      "  AUC: 0.71\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.35\n",
      "  Positive predictive value: 0.83\n",
      "  Optimal thershold: -1.791759469228055\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7021, Test = 7012\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.46780823868229987\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3313, Test = 3295\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.49\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.0330150061822965\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 782\n",
      "Number of test samples (ntest): 809\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 55\n",
      "Number of test samples (ntest): 55\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7021\n",
      "Number of test samples (ntest): 7012\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3313\n",
      "Number of test samples (ntest): 3295\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.95      0.82      7803\n",
      "         1.0       0.60      0.17      0.27      3368\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.66      0.56      0.54     11171\n",
      "weighted avg       0.69      0.72      0.66     11171\n",
      "\n",
      "Train accuracy:  0.7157819353683645\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.8522118751896327\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7803, Test = 7821\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.44531101665536404\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3368, Test = 3350\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.46\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.9808292530117262\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 782, Test = 809\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.06\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.2876820724517809\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 55, Test = 55\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -2.8081336596591924\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7021, Test = 7012\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.44531101665536404\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3313, Test = 3295\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.46\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -0.9808292530117262\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 782\n",
      "Number of test samples (ntest): 809\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 55\n",
      "Number of test samples (ntest): 55\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7021\n",
      "Number of test samples (ntest): 7012\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3313\n",
      "Number of test samples (ntest): 3295\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7803\n",
      "         1.0       0.61      0.14      0.23      3368\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.67      0.55      0.53     11171\n",
      "weighted avg       0.69      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7145286903589652\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.26\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.0945015010775678\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7803, Test = 7821\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4276090889414179\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3368, Test = 3350\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.0945015010775678\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 782, Test = 809\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.343064085253927\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 55, Test = 55\n",
      "  AUC: 0.84\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.80\n",
      "  Attacker advantage: 0.55\n",
      "  Positive predictive value: 0.87\n",
      "  Optimal thershold: -1.0072634081123366\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7021, Test = 7012\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.4276090889414179\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3313, Test = 3295\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.53\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.0945015010775678\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 782\n",
      "Number of test samples (ntest): 809\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 55\n",
      "Number of test samples (ntest): 55\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7021\n",
      "Number of test samples (ntest): 7012\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3313\n",
      "Number of test samples (ntest): 3295\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7803\n",
      "         1.0       0.58      0.17      0.26      3368\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.56      0.54     11171\n",
      "weighted avg       0.68      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7118431653388237\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.3467820542173172\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7803, Test = 7821\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3368, Test = 3350\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.21\n",
      "  Test Accuracy (TNR): 0.85\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -2.992383207205955\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 782, Test = 809\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 55, Test = 55\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.61\n",
      "  Accuracy: 0.61\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.22\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -2.992383207205955\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7021, Test = 7012\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.0514698721205146\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3313, Test = 3295\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.20\n",
      "  Test Accuracy (TNR): 0.86\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -2.992383207205955\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.56756757 0.8       ]\n",
      " [1.         1.         0.83783784 0.875     ]\n",
      " [1.         0.         0.81081081 0.85      ]\n",
      " ...\n",
      " [1.         0.         0.64864865 0.725     ]\n",
      " [0.         0.         0.64864865 0.775     ]\n",
      " [1.         0.         0.78378378 0.8       ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10303.0 868.0\n",
      "base_pos unpriv:  0.06797235023041474\n",
      "base_pos priv:  0.320295059691352\n",
      "number of favorable labels:  3359\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.252323\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 809\n",
      "Number of test samples (ntest): 782\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 59\n",
      "Number of test samples (ntest): 51\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7003\n",
      "Number of test samples (ntest): 7030\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3300\n",
      "Number of test samples (ntest): 3308\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.83      7812\n",
      "         1.0       0.63      0.14      0.23      3359\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7171246978784352\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.4769240720903093\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7812, Test = 7812\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.41616039722491244\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3359, Test = 3359\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -1.2039728043259361\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 809, Test = 782\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.06\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 59, Test = 51\n",
      "  AUC: 0.87\n",
      "  Privacy Risk: 0.85\n",
      "  Accuracy: 0.85\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.76\n",
      "  Attacker advantage: 0.70\n",
      "  Positive predictive value: 0.87\n",
      "  Optimal thershold: -2.772588722239781\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7003, Test = 7030\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.41616039722491244\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3300, Test = 3308\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -1.2039728043259361\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11493\n",
      "after transf priv:  0.320295059691352\n",
      "after transf unpriv:  0.32016806722689073\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000127\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 809\n",
      "Number of test samples (ntest): 782\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 59\n",
      "Number of test samples (ntest): 51\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7003\n",
      "Number of test samples (ntest): 7030\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3300\n",
      "Number of test samples (ntest): 3308\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.96      0.82      7812\n",
      "         1.0       0.69      0.18      0.28      3681\n",
      "\n",
      "    accuracy                           0.71     11493\n",
      "   macro avg       0.70      0.57      0.55     11493\n",
      "weighted avg       0.71      0.71      0.65     11493\n",
      "\n",
      "Train accuracy:  0.7113025319759854\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.34\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.55\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.4595323293784402\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7812, Test = 7812\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.44183275227903934\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3359, Test = 3359\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -1.2321436812926323\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 809, Test = 782\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.35667494393873245\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 59, Test = 51\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.86\n",
      "  Optimal thershold: -1.635190408536515\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7003, Test = 7030\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.43531807125784566\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3300, Test = 3308\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.43\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -0.9829821063728272\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 809\n",
      "Number of test samples (ntest): 782\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 59\n",
      "Number of test samples (ntest): 51\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7003\n",
      "Number of test samples (ntest): 7030\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3300\n",
      "Number of test samples (ntest): 3308\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7812\n",
      "         1.0       0.63      0.13      0.22      3359\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.55      0.52     11171\n",
      "weighted avg       0.69      0.72      0.64     11171\n",
      "\n",
      "Train accuracy:  0.715423865365679\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.33\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.41\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3722394604798439\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7812, Test = 7812\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3722394604798439\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3359, Test = 3359\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -1.349926716949016\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 809, Test = 782\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4228568508200336\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 59, Test = 51\n",
      "  AUC: 0.84\n",
      "  Privacy Risk: 0.81\n",
      "  Accuracy: 0.81\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.61\n",
      "  Positive predictive value: 0.82\n",
      "  Optimal thershold: -2.772588722239781\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7003, Test = 7030\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.6359887667199967\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3300, Test = 3308\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -1.349926716949016\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 809\n",
      "Number of test samples (ntest): 782\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 59\n",
      "Number of test samples (ntest): 51\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7003\n",
      "Number of test samples (ntest): 7030\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3300\n",
      "Number of test samples (ntest): 3308\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.83      7812\n",
      "         1.0       0.63      0.14      0.23      3359\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.53     11171\n",
      "weighted avg       0.69      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7167666278757497\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.3758538768621277\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7812, Test = 7812\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3758538768621277\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3359, Test = 3359\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.198336967787543\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 809, Test = 782\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.9875020323424728\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 59, Test = 51\n",
      "  AUC: 0.93\n",
      "  Privacy Risk: 0.88\n",
      "  Accuracy: 0.88\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.82\n",
      "  Attacker advantage: 0.76\n",
      "  Positive predictive value: 0.96\n",
      "  Optimal thershold: -1.2967113454548145\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7003, Test = 7030\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -0.3758538768621277\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3300, Test = 3308\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.26\n",
      "  Test Accuracy (TNR): 0.80\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -0.872058189935777\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 809\n",
      "Number of test samples (ntest): 782\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 59\n",
      "Number of test samples (ntest): 51\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7003\n",
      "Number of test samples (ntest): 7030\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3300\n",
      "Number of test samples (ntest): 3308\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7812\n",
      "         1.0       0.58      0.14      0.23      3359\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.55      0.53     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7113955778354668\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.26\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7812, Test = 7812\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3359, Test = 3359\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.18\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -1.4781535314011085\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 809, Test = 782\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.50\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.00\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -3.576697055473268\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 59, Test = 51\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.26\n",
      "  Positive predictive value: 0.79\n",
      "  Optimal thershold: -3.576697055473267\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7003, Test = 7030\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3300, Test = 3308\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.17\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -1.4781535314011085\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.97297297 0.9       ]\n",
      " [1.         0.         0.83783784 0.975     ]\n",
      " [1.         1.         0.64864865 0.825     ]\n",
      " ...\n",
      " [1.         0.         0.62162162 0.925     ]\n",
      " [1.         1.         0.59459459 0.875     ]\n",
      " [1.         1.         0.86486486 0.8       ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10349.0 822.0\n",
      "base_pos unpriv:  0.07420924574209246\n",
      "base_pos priv:  0.3230263793603247\n",
      "number of favorable labels:  3404\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.248817\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 761\n",
      "Number of test samples (ntest): 830\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7006\n",
      "Number of test samples (ntest): 7027\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3343\n",
      "Number of test samples (ntest): 3265\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7767\n",
      "         1.0       0.64      0.16      0.26      3404\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.56      0.54     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7166771103750783\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.16\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.0906441190189327\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7767, Test = 7857\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5007752879124893\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3404, Test = 3314\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -1.1952391243571814\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 761, Test = 830\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.056089466651043585\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.87\n",
      "  Privacy Risk: 0.83\n",
      "  Accuracy: 0.83\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.65\n",
      "  Positive predictive value: 0.86\n",
      "  Optimal thershold: -2.4277482359480516\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7006, Test = 7027\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.5007752879124893\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3343, Test = 3265\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -1.1952391243571814\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11473\n",
      "after transf priv:  0.3230263793603247\n",
      "after transf unpriv:  0.32295373665480426\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000073\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 761\n",
      "Number of test samples (ntest): 830\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7006\n",
      "Number of test samples (ntest): 7027\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3343\n",
      "Number of test samples (ntest): 3265\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.97      0.82      7767\n",
      "         1.0       0.72      0.17      0.28      3706\n",
      "\n",
      "    accuracy                           0.71     11473\n",
      "   macro avg       0.71      0.57      0.55     11473\n",
      "weighted avg       0.71      0.71      0.64     11473\n",
      "\n",
      "Train accuracy:  0.7107121066852611\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -1.0840134892469568\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7767, Test = 7857\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5134537461722601\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3404, Test = 3314\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.0840134892469568\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 761, Test = 830\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.27388875031944515\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.70\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.41\n",
      "  Positive predictive value: 0.80\n",
      "  Optimal thershold: -2.639057329615259\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7006, Test = 7027\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.5022785631875323\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3343, Test = 3265\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.62\n",
      "  Optimal thershold: -1.0840134892469568\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 761\n",
      "Number of test samples (ntest): 830\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7006\n",
      "Number of test samples (ntest): 7027\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3343\n",
      "Number of test samples (ntest): 3265\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7767\n",
      "         1.0       0.65      0.14      0.22      3404\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.68      0.55      0.52     11171\n",
      "weighted avg       0.70      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7144391728582938\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.45198512374305727\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7767, Test = 7857\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4541302800894454\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3404, Test = 3314\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.7047480922384253\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 761, Test = 830\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.49\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.84\n",
      "  Privacy Risk: 0.78\n",
      "  Accuracy: 0.78\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.55\n",
      "  Positive predictive value: 0.88\n",
      "  Optimal thershold: -2.6996819514316934\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7006, Test = 7027\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.45198512374305727\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3343, Test = 3265\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.7047480922384253\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 761\n",
      "Number of test samples (ntest): 830\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7006\n",
      "Number of test samples (ntest): 7027\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3343\n",
      "Number of test samples (ntest): 3265\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7767\n",
      "         1.0       0.62      0.17      0.26      3404\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.67      0.56      0.54     11171\n",
      "weighted avg       0.69      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7141706203562797\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.16\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.1410879602878008\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7767, Test = 7857\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4681346404171389\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3404, Test = 3314\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.1410879602878008\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 761, Test = 830\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.49\n",
      "  Optimal thershold: -0.9408471576185524\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.88\n",
      "  Privacy Risk: 0.80\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.61\n",
      "  Positive predictive value: 0.91\n",
      "  Optimal thershold: -1.4395992278354335\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7006, Test = 7027\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.47767439676261614\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3343, Test = 3265\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -1.1410879602878008\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 761\n",
      "Number of test samples (ntest): 830\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7006\n",
      "Number of test samples (ntest): 7027\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3343\n",
      "Number of test samples (ntest): 3265\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7767\n",
      "         1.0       0.60      0.15      0.24      3404\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.66      0.55      0.53     11171\n",
      "weighted avg       0.68      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.71094799033211\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.19\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7767, Test = 7857\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3404, Test = 3314\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.19\n",
      "  Test Accuracy (TNR): 0.86\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -2.5426108269381524\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 761, Test = 830\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.68\n",
      "  Accuracy: 0.68\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.36\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -2.5426108269381524\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7006, Test = 7027\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.08192697376979499\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3343, Test = 3265\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.18\n",
      "  Test Accuracy (TNR): 0.86\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -2.2032873384716387\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.83783784 0.875     ]\n",
      " [1.         1.         0.75675676 0.725     ]\n",
      " [1.         0.         0.72972973 0.9       ]\n",
      " ...\n",
      " [1.         1.         0.7027027  0.725     ]\n",
      " [1.         0.         0.56756757 0.8       ]\n",
      " [1.         0.         0.54054054 0.9       ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10342.0 829.0\n",
      "base_pos unpriv:  0.061519903498190594\n",
      "base_pos priv:  0.3181202862115645\n",
      "number of favorable labels:  3341\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.256600\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 778\n",
      "Number of test samples (ntest): 813\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 51\n",
      "Number of test samples (ntest): 59\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7052\n",
      "Number of test samples (ntest): 6981\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3290\n",
      "Number of test samples (ntest): 3318\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7830\n",
      "         1.0       0.63      0.14      0.22      3341\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.55      0.53     11171\n",
      "weighted avg       0.69      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.717303732879778\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.34\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.36\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7830, Test = 7794\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.50\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3341, Test = 3377\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.2426873165066266\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 778, Test = 813\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 51, Test = 59\n",
      "  AUC: 0.89\n",
      "  Privacy Risk: 0.84\n",
      "  Accuracy: 0.84\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.68\n",
      "  Attacker advantage: 0.68\n",
      "  Positive predictive value: 0.86\n",
      "  Optimal thershold: -2.8622008809294686\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7052, Test = 6981\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.44\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3290, Test = 3318\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.2426873165066266\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11482\n",
      "after transf priv:  0.3181202862115645\n",
      "after transf unpriv:  0.3175438596491228\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000576\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 778\n",
      "Number of test samples (ntest): 813\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 51\n",
      "Number of test samples (ntest): 59\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7052\n",
      "Number of test samples (ntest): 6981\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3290\n",
      "Number of test samples (ntest): 3318\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.82      7830\n",
      "         1.0       0.74      0.18      0.29      3652\n",
      "\n",
      "    accuracy                           0.72     11482\n",
      "   macro avg       0.73      0.57      0.56     11482\n",
      "weighted avg       0.72      0.72      0.65     11482\n",
      "\n",
      "Train accuracy:  0.7183417523079603\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.35000000000000003\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.1557707025080584\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7830, Test = 7794\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.46\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3184537311185346\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3341, Test = 3377\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -1.1557707025080584\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 778, Test = 813\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.05129329438755058\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 51, Test = 59\n",
      "  AUC: 0.88\n",
      "  Privacy Risk: 0.84\n",
      "  Accuracy: 0.84\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.69\n",
      "  Positive predictive value: 0.86\n",
      "  Optimal thershold: -2.339399066116762\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7052, Test = 6981\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.42\n",
      "  Test Accuracy (TNR): 0.62\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.3184537311185346\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3290, Test = 3318\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -1.1557707025080584\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 778\n",
      "Number of test samples (ntest): 813\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 51\n",
      "Number of test samples (ntest): 59\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7052\n",
      "Number of test samples (ntest): 6981\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3290\n",
      "Number of test samples (ntest): 3318\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.83      7830\n",
      "         1.0       0.60      0.14      0.23      3341\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.66      0.55      0.53     11171\n",
      "weighted avg       0.69      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7155133828663504\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -1.3470736479666092\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7830, Test = 7794\n",
      "  AUC: 0.48\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.6603573577369546\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3341, Test = 3377\n",
      "  AUC: 0.60\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -1.3470736479666092\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 778, Test = 813\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.03922071315328127\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 51, Test = 59\n",
      "  AUC: 0.87\n",
      "  Privacy Risk: 0.81\n",
      "  Accuracy: 0.81\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.75\n",
      "  Attacker advantage: 0.63\n",
      "  Positive predictive value: 0.89\n",
      "  Optimal thershold: -2.70805020110221\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7052, Test = 6981\n",
      "  AUC: 0.48\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.6603573577369546\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3290, Test = 3318\n",
      "  AUC: 0.59\n",
      "  Privacy Risk: 0.59\n",
      "  Accuracy: 0.59\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.18\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.3470736479666092\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 778\n",
      "Number of test samples (ntest): 813\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 51\n",
      "Number of test samples (ntest): 59\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7052\n",
      "Number of test samples (ntest): 6981\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3290\n",
      "Number of test samples (ntest): 3318\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7830\n",
      "         1.0       0.62      0.10      0.18      3341\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.67      0.54      0.50     11171\n",
      "weighted avg       0.69      0.71      0.63     11171\n",
      "\n",
      "Train accuracy:  0.7130964103482231\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.2177860934612093\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7830, Test = 7794\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.48\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3117695760058432\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3341, Test = 3377\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.4402638860772747\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 778, Test = 813\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.24888051275096312\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 51, Test = 59\n",
      "  AUC: 0.90\n",
      "  Privacy Risk: 0.86\n",
      "  Accuracy: 0.86\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.71\n",
      "  Positive predictive value: 0.87\n",
      "  Optimal thershold: -1.5126430571989655\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7052, Test = 6981\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.44\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.3117695760058432\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3290, Test = 3318\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -1.2177860934612093\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 778\n",
      "Number of test samples (ntest): 813\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 51\n",
      "Number of test samples (ntest): 59\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7052\n",
      "Number of test samples (ntest): 6981\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3290\n",
      "Number of test samples (ntest): 3318\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7830\n",
      "         1.0       0.58      0.13      0.21      3341\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.54      0.52     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.71094799033211\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.39\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -4.201685964123047\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7830, Test = 7794\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3341, Test = 3377\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.18\n",
      "  Test Accuracy (TNR): 0.86\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -4.201685964123047\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 778, Test = 813\n",
      "  AUC: 0.49\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.50\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.49\n",
      "  Optimal thershold: -0.015083502341545351\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 51, Test = 59\n",
      "  AUC: 0.48\n",
      "  Privacy Risk: 0.62\n",
      "  Accuracy: 0.62\n",
      "  Train Accuracy (TPR): 0.33\n",
      "  Test Accuracy (TNR): 0.92\n",
      "  Attacker advantage: 0.25\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -0.9634833321279579\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7052, Test = 6981\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3290, Test = 3318\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.18\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -4.201685964123047\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.83783784 0.675     ]\n",
      " [1.         1.         0.62162162 0.925     ]\n",
      " [1.         1.         0.75675676 0.825     ]\n",
      " ...\n",
      " [0.         0.         0.32432432 0.8       ]\n",
      " [1.         1.         0.94594595 0.85      ]\n",
      " [1.         0.         0.83783784 0.95      ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10342.0 829.0\n",
      "base_pos unpriv:  0.06272617611580217\n",
      "base_pos priv:  0.31850705859601625\n",
      "number of favorable labels:  3346\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.255781\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 777\n",
      "Number of test samples (ntest): 814\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 52\n",
      "Number of test samples (ntest): 58\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7048\n",
      "Number of test samples (ntest): 6985\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3294\n",
      "Number of test samples (ntest): 3314\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83      7825\n",
      "         1.0       0.63      0.18      0.28      3346\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.57      0.55     11171\n",
      "weighted avg       0.70      0.72      0.66     11171\n",
      "\n",
      "Train accuracy:  0.7226747829200608\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7825, Test = 7799\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.378436435720245\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3346, Test = 3372\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.2299482907291965\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 777, Test = 814\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.61\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.025533302005164762\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 52, Test = 58\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.42\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -2.6149597780361984\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7048, Test = 6985\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.378436435720245\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3294, Test = 3314\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.2299482907291965\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11482\n",
      "after transf priv:  0.31850705859601625\n",
      "after transf unpriv:  0.31842105263157894\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000086\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 777\n",
      "Number of test samples (ntest): 814\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 52\n",
      "Number of test samples (ntest): 58\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7048\n",
      "Number of test samples (ntest): 6985\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3294\n",
      "Number of test samples (ntest): 3314\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7825\n",
      "         1.0       0.68      0.20      0.31      3657\n",
      "\n",
      "    accuracy                           0.72     11482\n",
      "   macro avg       0.70      0.58      0.57     11482\n",
      "weighted avg       0.71      0.72      0.66     11482\n",
      "\n",
      "Train accuracy:  0.7156418742379377\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4825218476031389\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7825, Test = 7799\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4825218476031389\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3346, Test = 3372\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.2039728043259361\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 777, Test = 814\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.49899116611898775\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 52, Test = 58\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.68\n",
      "  Accuracy: 0.68\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.36\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -2.5257286443082556\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7048, Test = 6985\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.24\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.4825218476031389\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3294, Test = 3314\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.2039728043259361\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 777\n",
      "Number of test samples (ntest): 814\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 52\n",
      "Number of test samples (ntest): 58\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7048\n",
      "Number of test samples (ntest): 6985\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3294\n",
      "Number of test samples (ntest): 3314\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83      7825\n",
      "         1.0       0.63      0.16      0.26      3346\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.56      0.54     11171\n",
      "weighted avg       0.70      0.72      0.66     11171\n",
      "\n",
      "Train accuracy:  0.7202578104019336\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.8914226652961416\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7825, Test = 7799\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.48\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.31282625425280625\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3346, Test = 3372\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.43\n",
      "  Test Accuracy (TNR): 0.69\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.9555114450274363\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 777, Test = 814\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.08004270767353637\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 52, Test = 58\n",
      "  AUC: 0.84\n",
      "  Privacy Risk: 0.81\n",
      "  Accuracy: 0.81\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.61\n",
      "  Positive predictive value: 0.79\n",
      "  Optimal thershold: -2.2512917986064953\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7048, Test = 6985\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.43\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.31282625425280625\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3294, Test = 3314\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.43\n",
      "  Test Accuracy (TNR): 0.68\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.9555114450274363\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 777\n",
      "Number of test samples (ntest): 814\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 52\n",
      "Number of test samples (ntest): 58\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7048\n",
      "Number of test samples (ntest): 6985\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3294\n",
      "Number of test samples (ntest): 3314\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83      7825\n",
      "         1.0       0.62      0.15      0.25      3346\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.56      0.54     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7190045653925342\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.31\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.49\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.36269393738336747\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7825, Test = 7799\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.61\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.35126509919061016\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3346, Test = 3372\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.2936816435356167\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 777, Test = 814\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.16\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.4997323607560487\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 52, Test = 58\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.41\n",
      "  Positive predictive value: 0.79\n",
      "  Optimal thershold: -2.122973502750531\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7048, Test = 6985\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.35126509919061016\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3294, Test = 3314\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.2936816435356167\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 777\n",
      "Number of test samples (ntest): 814\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 52\n",
      "Number of test samples (ntest): 58\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7048\n",
      "Number of test samples (ntest): 6985\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3294\n",
      "Number of test samples (ntest): 3314\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7825\n",
      "         1.0       0.59      0.15      0.24      3346\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.66      0.55      0.53     11171\n",
      "weighted avg       0.68      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7139020678542655\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.2\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7825, Test = 7799\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3346, Test = 3372\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.18\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -1.6139712223015248\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 777, Test = 814\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.049885065205447277\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 52, Test = 58\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.65\n",
      "  Accuracy: 0.65\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.69\n",
      "  Attacker advantage: 0.31\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -1.6139712223015248\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7048, Test = 6985\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3294, Test = 3314\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.17\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -1.6139712223015248\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         0.         0.72972973 0.875     ]\n",
      " [1.         0.         0.78378378 0.8       ]\n",
      " [1.         1.         0.64864865 0.775     ]\n",
      " ...\n",
      " [1.         1.         0.7027027  0.875     ]\n",
      " [1.         1.         0.59459459 0.725     ]\n",
      " [1.         0.         0.91891892 0.825     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10323.0 848.0\n",
      "base_pos unpriv:  0.06367924528301887\n",
      "base_pos priv:  0.32112757919209534\n",
      "number of favorable labels:  3369\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.257448\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 794\n",
      "Number of test samples (ntest): 797\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7008\n",
      "Number of test samples (ntest): 7025\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3315\n",
      "Number of test samples (ntest): 3293\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.98      0.83      7802\n",
      "         1.0       0.67      0.11      0.19      3369\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.69      0.54      0.51     11171\n",
      "weighted avg       0.70      0.72      0.63     11171\n",
      "\n",
      "Train accuracy:  0.7150657953629934\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.31\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.252762968495368\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7802, Test = 7822\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.46134556650262093\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3369, Test = 3349\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.252762968495368\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 794, Test = 797\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.13976194237515874\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.82\n",
      "  Attacker advantage: 0.34\n",
      "  Positive predictive value: 0.85\n",
      "  Optimal thershold: -2.03688192726104\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7008, Test = 7025\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.46134556650262093\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3315, Test = 3293\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.252762968495368\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11492\n",
      "after transf priv:  0.32112757919209534\n",
      "after transf unpriv:  0.32078699743370404\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000341\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 794\n",
      "Number of test samples (ntest): 797\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7008\n",
      "Number of test samples (ntest): 7025\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3315\n",
      "Number of test samples (ntest): 3293\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.98      0.82      7802\n",
      "         1.0       0.74      0.14      0.24      3690\n",
      "\n",
      "    accuracy                           0.71     11492\n",
      "   macro avg       0.72      0.56      0.53     11492\n",
      "weighted avg       0.72      0.71      0.63     11492\n",
      "\n",
      "Train accuracy:  0.7082318134354334\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4700036292457356\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7802, Test = 7822\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4700036292457356\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3369, Test = 3349\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.213022639845854\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 794, Test = 797\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.36452784645620423\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.65\n",
      "  Privacy Risk: 0.63\n",
      "  Accuracy: 0.63\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.78\n",
      "  Optimal thershold: -1.1858856858347921\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7008, Test = 7025\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4700036292457356\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3315, Test = 3293\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -1.213022639845854\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 794\n",
      "Number of test samples (ntest): 797\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7008\n",
      "Number of test samples (ntest): 7025\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3315\n",
      "Number of test samples (ntest): 3293\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7802\n",
      "         1.0       0.65      0.11      0.18      3369\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.68      0.54      0.51     11171\n",
      "weighted avg       0.70      0.71      0.63     11171\n",
      "\n",
      "Train accuracy:  0.7132754453495659\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.32\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -1.262241712449912\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7802, Test = 7822\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.16\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.5280674302004967\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3369, Test = 3349\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.262241712449912\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 794, Test = 797\n",
      "  AUC: 0.47\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.06\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.70\n",
      "  Accuracy: 0.70\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.39\n",
      "  Positive predictive value: 0.83\n",
      "  Optimal thershold: -2.876871070677262\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7008, Test = 7025\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.5280674302004967\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3315, Test = 3293\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.262241712449912\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 794\n",
      "Number of test samples (ntest): 797\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7008\n",
      "Number of test samples (ntest): 7025\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3315\n",
      "Number of test samples (ntest): 3293\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.98      0.83      7802\n",
      "         1.0       0.65      0.10      0.18      3369\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.68      0.54      0.50     11171\n",
      "weighted avg       0.70      0.71      0.63     11171\n",
      "\n",
      "Train accuracy:  0.7126488228448662\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.43678758968602127\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7802, Test = 7822\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.61\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3337170970320665\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3369, Test = 3349\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.2191248311849132\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 794, Test = 797\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.24130016198666818\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.83\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.48\n",
      "  Positive predictive value: 0.94\n",
      "  Optimal thershold: -2.3908199332617266\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7008, Test = 7025\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3337170970320665\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3315, Test = 3293\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -1.2191248311849132\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 794\n",
      "Number of test samples (ntest): 797\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 54\n",
      "Number of test samples (ntest): 56\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7008\n",
      "Number of test samples (ntest): 7025\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3315\n",
      "Number of test samples (ntest): 3293\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7802\n",
      "         1.0       0.58      0.14      0.23      3369\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.55      0.52     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.710500402828753\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.04\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.13117542226550472\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7802, Test = 7822\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.08813713449073596\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3369, Test = 3349\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.19\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -3.2552442467484735\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 794, Test = 797\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.50\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.08813713449073596\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 54, Test = 56\n",
      "  AUC: 0.75\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.75\n",
      "  Attacker advantage: 0.55\n",
      "  Positive predictive value: 0.75\n",
      "  Optimal thershold: -3.2552442467484735\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7008, Test = 7025\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.06\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.08813713449073596\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3315, Test = 3293\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.18\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -3.2552442467484735\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         0.         0.81081081 0.95      ]\n",
      " [1.         0.         0.67567568 0.775     ]\n",
      " [1.         0.         0.91891892 0.9       ]\n",
      " ...\n",
      " [1.         1.         0.86486486 0.8       ]\n",
      " [1.         1.         0.67567568 0.65      ]\n",
      " [1.         0.         0.64864865 0.825     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10332.0 839.0\n",
      "base_pos unpriv:  0.060786650774731825\n",
      "base_pos priv:  0.3151374370886566\n",
      "number of favorable labels:  3307\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.254351\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 788\n",
      "Number of test samples (ntest): 803\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 51\n",
      "Number of test samples (ntest): 59\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7076\n",
      "Number of test samples (ntest): 6957\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3256\n",
      "Number of test samples (ntest): 3352\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83      7864\n",
      "         1.0       0.63      0.16      0.25      3307\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.56      0.54     11171\n",
      "weighted avg       0.70      0.72      0.66     11171\n",
      "\n",
      "Train accuracy:  0.7239280279294602\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.7308875085427923\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7864, Test = 7760\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3307, Test = 3411\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.2039728043259361\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 788, Test = 803\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.08004270767353637\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 51, Test = 59\n",
      "  AUC: 0.91\n",
      "  Privacy Risk: 0.85\n",
      "  Accuracy: 0.85\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.69\n",
      "  Attacker advantage: 0.69\n",
      "  Positive predictive value: 0.88\n",
      "  Optimal thershold: -3.1060803307228566\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7076, Test = 6957\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3256, Test = 3352\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.2039728043259361\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11482\n",
      "after transf priv:  0.3151374370886566\n",
      "after transf unpriv:  0.31478260869565217\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000355\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 788\n",
      "Number of test samples (ntest): 803\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 51\n",
      "Number of test samples (ntest): 59\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7076\n",
      "Number of test samples (ntest): 6957\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3256\n",
      "Number of test samples (ntest): 3352\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.83      7864\n",
      "         1.0       0.73      0.20      0.32      3618\n",
      "\n",
      "    accuracy                           0.72     11482\n",
      "   macro avg       0.73      0.58      0.57     11482\n",
      "weighted avg       0.73      0.72      0.67     11482\n",
      "\n",
      "Train accuracy:  0.7249608082215642\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.7308875085427923\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7864, Test = 7760\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.49247648509779407\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3307, Test = 3411\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.1716374236829996\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 788, Test = 803\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.1661845193909819\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 51, Test = 59\n",
      "  AUC: 0.84\n",
      "  Privacy Risk: 0.79\n",
      "  Accuracy: 0.79\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.68\n",
      "  Attacker advantage: 0.58\n",
      "  Positive predictive value: 0.82\n",
      "  Optimal thershold: -1.9095425048844386\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7076, Test = 6957\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.48835276791393206\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3256, Test = 3352\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.1716374236829996\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 788\n",
      "Number of test samples (ntest): 803\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 51\n",
      "Number of test samples (ntest): 59\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7076\n",
      "Number of test samples (ntest): 6957\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3256\n",
      "Number of test samples (ntest): 3352\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83      7864\n",
      "         1.0       0.62      0.15      0.24      3307\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.56      0.54     11171\n",
      "weighted avg       0.70      0.72      0.66     11171\n",
      "\n",
      "Train accuracy:  0.721779607913347\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.46\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.3923070235306532\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7864, Test = 7760\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.3923070235306532\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3307, Test = 3411\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.43\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.9808292530117262\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 788, Test = 803\n",
      "  AUC: 0.49\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.03\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 51, Test = 59\n",
      "  AUC: 0.89\n",
      "  Privacy Risk: 0.84\n",
      "  Accuracy: 0.84\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.68\n",
      "  Attacker advantage: 0.68\n",
      "  Positive predictive value: 0.88\n",
      "  Optimal thershold: -3.349904087274605\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7076, Test = 6957\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.14\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -0.3923070235306532\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3256, Test = 3352\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.43\n",
      "  Test Accuracy (TNR): 0.64\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.9808292530117262\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 788\n",
      "Number of test samples (ntest): 803\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 51\n",
      "Number of test samples (ntest): 59\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7076\n",
      "Number of test samples (ntest): 6957\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3256\n",
      "Number of test samples (ntest): 3352\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83      7864\n",
      "         1.0       0.62      0.15      0.24      3307\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.56      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7207053979052905\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.2134082937229096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7864, Test = 7760\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4545171286669397\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3307, Test = 3411\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.2134082937229096\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 788, Test = 803\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.04\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -1.4466256025348478\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 51, Test = 59\n",
      "  AUC: 0.91\n",
      "  Privacy Risk: 0.88\n",
      "  Accuracy: 0.88\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.76\n",
      "  Attacker advantage: 0.76\n",
      "  Positive predictive value: 0.85\n",
      "  Optimal thershold: -1.6453207953946745\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7076, Test = 6957\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.4545171286669397\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3256, Test = 3352\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.2134082937229096\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 788\n",
      "Number of test samples (ntest): 803\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 51\n",
      "Number of test samples (ntest): 59\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7076\n",
      "Number of test samples (ntest): 6957\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3256\n",
      "Number of test samples (ntest): 3352\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83      7864\n",
      "         1.0       0.58      0.14      0.23      3307\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.65      0.55      0.53     11171\n",
      "weighted avg       0.68      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.715423865365679\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.24000000000000002\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -1.4332385497220914\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7864, Test = 7760\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3307, Test = 3411\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.16\n",
      "  Test Accuracy (TNR): 0.89\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -2.2458961573426643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 788, Test = 803\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 51, Test = 59\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.75\n",
      "  Attacker advantage: 0.49\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -2.2458961573426643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7076, Test = 6957\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.06\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.11186233469592465\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3256, Test = 3352\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.15\n",
      "  Test Accuracy (TNR): 0.89\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -2.2458961573426643\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         0.         0.66216216 0.7       ]\n",
      " [0.         1.         0.56756757 0.65      ]\n",
      " [1.         0.         0.75675676 0.725     ]\n",
      " ...\n",
      " [0.         0.         0.45135135 0.575     ]\n",
      " [1.         0.         0.72972973 0.95      ]\n",
      " [1.         0.         0.71621622 0.775     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10327.0 844.0\n",
      "base_pos unpriv:  0.06279620853080568\n",
      "base_pos priv:  0.3249733707756367\n",
      "number of favorable labels:  3409\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.262177\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 791\n",
      "Number of test samples (ntest): 800\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 53\n",
      "Number of test samples (ntest): 57\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 6971\n",
      "Number of test samples (ntest): 7062\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3356\n",
      "Number of test samples (ntest): 3252\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7762\n",
      "         1.0       0.64      0.15      0.24      3409\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.68      0.56      0.53     11171\n",
      "weighted avg       0.70      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7147077253603079\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5232481437645479\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7762, Test = 7862\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3409, Test = 3309\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -1.0445450673978338\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 791, Test = 800\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.49\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.013423020332140661\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 53, Test = 57\n",
      "  AUC: 0.83\n",
      "  Privacy Risk: 0.74\n",
      "  Accuracy: 0.74\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.88\n",
      "  Attacker advantage: 0.48\n",
      "  Positive predictive value: 0.87\n",
      "  Optimal thershold: -2.120263536200091\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6971, Test = 7062\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3356, Test = 3252\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.0445450673978338\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11498\n",
      "after transf priv:  0.3249733707756367\n",
      "after transf unpriv:  0.32450896669513235\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000464\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 791\n",
      "Number of test samples (ntest): 800\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 53\n",
      "Number of test samples (ntest): 57\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 6971\n",
      "Number of test samples (ntest): 7062\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3356\n",
      "Number of test samples (ntest): 3252\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.97      0.82      7762\n",
      "         1.0       0.75      0.16      0.26      3736\n",
      "\n",
      "    accuracy                           0.71     11498\n",
      "   macro avg       0.73      0.57      0.54     11498\n",
      "weighted avg       0.72      0.71      0.64     11498\n",
      "\n",
      "Train accuracy:  0.7089058966776831\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.32\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.48\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4382549309311553\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7762, Test = 7862\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4382549309311553\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3409, Test = 3309\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.2396908869280152\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 791, Test = 800\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.2876820724517809\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 53, Test = 57\n",
      "  AUC: 0.74\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.37\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -1.6094379124341003\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6971, Test = 7062\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4382549309311553\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3356, Test = 3252\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.041453874828161\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 791\n",
      "Number of test samples (ntest): 800\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 53\n",
      "Number of test samples (ntest): 57\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 6971\n",
      "Number of test samples (ntest): 7062\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3356\n",
      "Number of test samples (ntest): 3252\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.97      0.82      7762\n",
      "         1.0       0.66      0.11      0.19      3409\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.69      0.54      0.51     11171\n",
      "weighted avg       0.70      0.71      0.63     11171\n",
      "\n",
      "Train accuracy:  0.7114850953361382\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.488077055429833\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7762, Test = 7862\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5659920050746986\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3409, Test = 3309\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.488077055429833\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 791, Test = 800\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 53, Test = 57\n",
      "  AUC: 0.85\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.52\n",
      "  Positive predictive value: 0.87\n",
      "  Optimal thershold: -3.784189633918261\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6971, Test = 7062\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.13\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.5659920050746986\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3356, Test = 3252\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.488077055429833\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 791\n",
      "Number of test samples (ntest): 800\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 53\n",
      "Number of test samples (ntest): 57\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 6971\n",
      "Number of test samples (ntest): 7062\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3356\n",
      "Number of test samples (ntest): 3252\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7762\n",
      "         1.0       0.61      0.13      0.22      3409\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.66      0.55      0.52     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7097842628233819\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.26\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.1584227194915564\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7762, Test = 7862\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4751058043140043\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3409, Test = 3309\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.61\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.123933196685719\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 791, Test = 800\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.03\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -2.0221721982409777\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 53, Test = 57\n",
      "  AUC: 0.86\n",
      "  Privacy Risk: 0.80\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.70\n",
      "  Attacker advantage: 0.61\n",
      "  Positive predictive value: 0.88\n",
      "  Optimal thershold: -1.0405390532026344\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6971, Test = 7062\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4751058043140043\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3356, Test = 3252\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -1.123933196685719\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 791\n",
      "Number of test samples (ntest): 800\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 53\n",
      "Number of test samples (ntest): 57\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 6971\n",
      "Number of test samples (ntest): 7062\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3356\n",
      "Number of test samples (ntest): 3252\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7762\n",
      "         1.0       0.59      0.15      0.24      3409\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.55      0.53     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7085310178139826\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.4\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.5074066397367204\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7762, Test = 7862\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3409, Test = 3309\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.16\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -2.3482851516245256\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 791, Test = 800\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.50\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 53, Test = 57\n",
      "  AUC: 0.66\n",
      "  Privacy Risk: 0.64\n",
      "  Accuracy: 0.64\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.27\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -2.3482851516245256\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6971, Test = 7062\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3356, Test = 3252\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.15\n",
      "  Test Accuracy (TNR): 0.88\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.5074066397367204\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.91891892 0.875     ]\n",
      " [1.         1.         0.78378378 0.85      ]\n",
      " [1.         1.         0.77567568 0.7       ]\n",
      " ...\n",
      " [1.         0.         0.64864865 0.8       ]\n",
      " [1.         0.         0.64864865 0.725     ]\n",
      " [1.         1.         0.72972973 0.825     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10362.0 809.0\n",
      "base_pos unpriv:  0.06551297898640297\n",
      "base_pos priv:  0.31509361127195523\n",
      "number of favorable labels:  3318\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.249581\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 756\n",
      "Number of test samples (ntest): 835\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 53\n",
      "Number of test samples (ntest): 57\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7097\n",
      "Number of test samples (ntest): 6936\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3265\n",
      "Number of test samples (ntest): 3343\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83      7853\n",
      "         1.0       0.61      0.16      0.25      3318\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.56      0.54     11171\n",
      "weighted avg       0.69      0.72      0.66     11171\n",
      "\n",
      "Train accuracy:  0.7203473279026049\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.26\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.0233888674305223\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7853, Test = 7771\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3169117107667193\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3318, Test = 3400\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.1842677332466036\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 756, Test = 835\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.07210329390134394\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 53, Test = 57\n",
      "  AUC: 0.89\n",
      "  Privacy Risk: 0.80\n",
      "  Accuracy: 0.80\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.81\n",
      "  Attacker advantage: 0.60\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -2.4849066497880004\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7097, Test = 6936\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.46\n",
      "  Test Accuracy (TNR): 0.58\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.3169117107667193\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3265, Test = 3343\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.1842677332466036\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11465\n",
      "after transf priv:  0.31509361127195523\n",
      "after transf unpriv:  0.314596554850408\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000497\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 756\n",
      "Number of test samples (ntest): 835\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 53\n",
      "Number of test samples (ntest): 57\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7097\n",
      "Number of test samples (ntest): 6936\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3265\n",
      "Number of test samples (ntest): 3343\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7853\n",
      "         1.0       0.70      0.18      0.29      3612\n",
      "\n",
      "    accuracy                           0.72     11465\n",
      "   macro avg       0.71      0.57      0.56     11465\n",
      "weighted avg       0.71      0.72      0.66     11465\n",
      "\n",
      "Train accuracy:  0.7178368948975141\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.33\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.19\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -1.0424177303244677\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7853, Test = 7771\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.46\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.325422400434628\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3318, Test = 3400\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.1727202608218315\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 756, Test = 835\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.43\n",
      "  Test Accuracy (TNR): 0.63\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.040821994520255166\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 53, Test = 57\n",
      "  AUC: 0.78\n",
      "  Privacy Risk: 0.72\n",
      "  Accuracy: 0.72\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.44\n",
      "  Positive predictive value: 0.88\n",
      "  Optimal thershold: -2.639057329615259\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7097, Test = 6936\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.43\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.325422400434628\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3265, Test = 3343\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.1727202608218315\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 756\n",
      "Number of test samples (ntest): 835\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 53\n",
      "Number of test samples (ntest): 57\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7097\n",
      "Number of test samples (ntest): 6936\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3265\n",
      "Number of test samples (ntest): 3343\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7853\n",
      "         1.0       0.66      0.11      0.20      3318\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.69      0.54      0.51     11171\n",
      "weighted avg       0.70      0.72      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7193626353952197\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.31\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.50\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3856624808119848\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7853, Test = 7771\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.3856624808119848\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3318, Test = 3400\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -1.6650077635889111\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 756, Test = 835\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.58\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 53, Test = 57\n",
      "  AUC: 0.86\n",
      "  Privacy Risk: 0.78\n",
      "  Accuracy: 0.78\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.82\n",
      "  Attacker advantage: 0.56\n",
      "  Positive predictive value: 0.89\n",
      "  Optimal thershold: -1.6094379124341003\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7097, Test = 6936\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.3856624808119848\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3265, Test = 3343\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -1.6650077635889111\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 756\n",
      "Number of test samples (ntest): 835\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 53\n",
      "Number of test samples (ntest): 57\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7097\n",
      "Number of test samples (ntest): 6936\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3265\n",
      "Number of test samples (ntest): 3343\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7853\n",
      "         1.0       0.63      0.13      0.21      3318\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.52     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7189150478918629\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.236213295626002\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7853, Test = 7771\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.48\n",
      "  Test Accuracy (TNR): 0.55\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3053913266639353\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3318, Test = 3400\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.236213295626002\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 756, Test = 835\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 53, Test = 57\n",
      "  AUC: 0.90\n",
      "  Privacy Risk: 0.87\n",
      "  Accuracy: 0.87\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.81\n",
      "  Attacker advantage: 0.73\n",
      "  Positive predictive value: 0.88\n",
      "  Optimal thershold: -1.2960438200300402\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7097, Test = 6936\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.44\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.3053913266639353\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3265, Test = 3343\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.65\n",
      "  Optimal thershold: -1.236213295626002\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 756\n",
      "Number of test samples (ntest): 835\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 53\n",
      "Number of test samples (ntest): 57\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7097\n",
      "Number of test samples (ntest): 6936\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3265\n",
      "Number of test samples (ntest): 3343\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7853\n",
      "         1.0       0.58      0.13      0.22      3318\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.55      0.52     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7137230328529227\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.17\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7853, Test = 7771\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3318, Test = 3400\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.17\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -1.933426040231844\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 756, Test = 835\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.50\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.48\n",
      "  Optimal thershold: -0.15624660150497058\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 53, Test = 57\n",
      "  AUC: 0.73\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.77\n",
      "  Attacker advantage: 0.41\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -1.933426040231844\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7097, Test = 6936\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3265, Test = 3343\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.17\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -3.8423236784771055\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.51351351 0.775     ]\n",
      " [0.         0.         0.40540541 0.7       ]\n",
      " [1.         1.         0.56756757 0.825     ]\n",
      " ...\n",
      " [1.         1.         0.75675676 0.825     ]\n",
      " [1.         1.         0.63513514 0.725     ]\n",
      " [1.         0.         0.67567568 0.925     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10307.0 864.0\n",
      "base_pos unpriv:  0.06712962962962964\n",
      "base_pos priv:  0.3177452216939944\n",
      "number of favorable labels:  3333\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.250616\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 806\n",
      "Number of test samples (ntest): 785\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7032\n",
      "Number of test samples (ntest): 7001\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3275\n",
      "Number of test samples (ntest): 3333\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.97      0.83      7838\n",
      "         1.0       0.68      0.13      0.22      3333\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.70      0.55      0.53     11171\n",
      "weighted avg       0.71      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7228538179214037\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.26\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.43\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.3629054936893685\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7838, Test = 7786\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.46\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3629054936893685\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3333, Test = 3385\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.088249501632563\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 806, Test = 785\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.325422400434628\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.85\n",
      "  Privacy Risk: 0.82\n",
      "  Accuracy: 0.82\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.69\n",
      "  Attacker advantage: 0.64\n",
      "  Positive predictive value: 0.83\n",
      "  Optimal thershold: -2.5649493574615367\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7032, Test = 7001\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.55\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.3629054936893685\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3275, Test = 3333\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.088249501632563\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11488\n",
      "after transf priv:  0.3177452216939944\n",
      "after transf unpriv:  0.31752751905165116\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000218\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 806\n",
      "Number of test samples (ntest): 785\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7032\n",
      "Number of test samples (ntest): 7001\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3275\n",
      "Number of test samples (ntest): 3333\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.98      0.82      7838\n",
      "         1.0       0.75      0.16      0.27      3650\n",
      "\n",
      "    accuracy                           0.72     11488\n",
      "   macro avg       0.73      0.57      0.55     11488\n",
      "weighted avg       0.73      0.72      0.65     11488\n",
      "\n",
      "Train accuracy:  0.7172701949860725\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.43\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.37729423114146804\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7838, Test = 7786\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.37729423114146804\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3333, Test = 3385\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.1786549963416462\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 806, Test = 785\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.39204208777602373\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.76\n",
      "  Privacy Risk: 0.69\n",
      "  Accuracy: 0.69\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.38\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -2.538973871058276\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7032, Test = 7001\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.37729423114146804\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3275, Test = 3333\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.1786549963416462\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 806\n",
      "Number of test samples (ntest): 785\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7032\n",
      "Number of test samples (ntest): 7001\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3275\n",
      "Number of test samples (ntest): 3333\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7838\n",
      "         1.0       0.64      0.13      0.22      3333\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.52     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7188255303911915\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.34\n",
      "  Test Accuracy (TNR): 0.72\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.322773392263051\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7838, Test = 7786\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.46\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.322773392263051\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3333, Test = 3385\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.41\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -0.9694005571881036\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 806, Test = 785\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.90\n",
      "  Privacy Risk: 0.87\n",
      "  Accuracy: 0.87\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.77\n",
      "  Attacker advantage: 0.73\n",
      "  Positive predictive value: 0.92\n",
      "  Optimal thershold: -2.833213344056216\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7032, Test = 7001\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.45\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.4001600558784712\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3275, Test = 3333\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.41\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.63\n",
      "  Optimal thershold: -0.9694005571881036\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 806\n",
      "Number of test samples (ntest): 785\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7032\n",
      "Number of test samples (ntest): 7001\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3275\n",
      "Number of test samples (ntest): 3333\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.83      7838\n",
      "         1.0       0.59      0.13      0.21      3333\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.66      0.55      0.52     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7137230328529227\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.36392718406449415\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7838, Test = 7786\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.54\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3308464590859833\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3333, Test = 3385\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -1.187252686933896\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 806, Test = 785\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.22866962761786053\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.88\n",
      "  Privacy Risk: 0.86\n",
      "  Accuracy: 0.86\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.71\n",
      "  Positive predictive value: 0.87\n",
      "  Optimal thershold: -1.3103820336266365\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7032, Test = 7001\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.36392718406449415\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3275, Test = 3333\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.187252686933896\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 806\n",
      "Number of test samples (ntest): 785\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7032\n",
      "Number of test samples (ntest): 7001\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3275\n",
      "Number of test samples (ntest): 3333\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.83      7838\n",
      "         1.0       0.60      0.14      0.23      3333\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.66      0.55      0.53     11171\n",
      "weighted avg       0.69      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7149762778623221\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.22\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -1.6351387582861652\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7838, Test = 7786\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.06\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.02196118292184134\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3333, Test = 3385\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.15\n",
      "  Test Accuracy (TNR): 0.90\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -1.6351387582861652\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 806, Test = 785\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.50\n",
      "  Accuracy: 0.50\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.21682023806371023\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.69\n",
      "  Privacy Risk: 0.68\n",
      "  Accuracy: 0.68\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.90\n",
      "  Attacker advantage: 0.37\n",
      "  Positive predictive value: 0.84\n",
      "  Optimal thershold: -1.6351387582861652\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7032, Test = 7001\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3275, Test = 3333\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.16\n",
      "  Test Accuracy (TNR): 0.89\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -3.829439292653655\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.94594595 0.75      ]\n",
      " [0.         0.         0.64864865 0.625     ]\n",
      " [1.         1.         0.54054054 0.85      ]\n",
      " ...\n",
      " [1.         0.         0.37837838 0.9       ]\n",
      " [1.         1.         0.56756757 0.725     ]\n",
      " [0.         1.         0.51351351 0.8       ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10304.0 867.0\n",
      "base_pos unpriv:  0.05767012687427912\n",
      "base_pos priv:  0.31667313664596275\n",
      "number of favorable labels:  3313\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.259003\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 817\n",
      "Number of test samples (ntest): 774\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7041\n",
      "Number of test samples (ntest): 6992\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3263\n",
      "Number of test samples (ntest): 3345\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83      7858\n",
      "         1.0       0.62      0.15      0.25      3313\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.56      0.54     11171\n",
      "weighted avg       0.70      0.72      0.66     11171\n",
      "\n",
      "Train accuracy:  0.7207949154059619\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.5753641449035618\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7858, Test = 7766\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.39176626375000245\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3313, Test = 3405\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.2219913098286144\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 817, Test = 774\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.04\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.6931471805599453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.89\n",
      "  Privacy Risk: 0.83\n",
      "  Accuracy: 0.83\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.78\n",
      "  Attacker advantage: 0.66\n",
      "  Positive predictive value: 0.89\n",
      "  Optimal thershold: -2.7850112422383386\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7041, Test = 6992\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.39176626375000245\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3263, Test = 3345\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.2219913098286144\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11499\n",
      "after transf priv:  0.31667313664596275\n",
      "after transf unpriv:  0.3163179916317992\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000355\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 817\n",
      "Number of test samples (ntest): 774\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7041\n",
      "Number of test samples (ntest): 6992\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3263\n",
      "Number of test samples (ntest): 3345\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.83      7858\n",
      "         1.0       0.71      0.20      0.31      3641\n",
      "\n",
      "    accuracy                           0.72     11499\n",
      "   macro avg       0.72      0.58      0.57     11499\n",
      "weighted avg       0.72      0.72      0.66     11499\n",
      "\n",
      "Train accuracy:  0.7211061831463605\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.32\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.7884573603642702\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7858, Test = 7766\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.55\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3313, Test = 3405\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.2396908869280152\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 817, Test = 774\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.2231435513142097\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.83\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.78\n",
      "  Attacker advantage: 0.54\n",
      "  Positive predictive value: 0.81\n",
      "  Optimal thershold: -1.7635885922613588\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7041, Test = 6992\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.50\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3263, Test = 3345\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.2396908869280152\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 817\n",
      "Number of test samples (ntest): 774\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7041\n",
      "Number of test samples (ntest): 6992\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3263\n",
      "Number of test samples (ntest): 3345\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83      7858\n",
      "         1.0       0.61      0.15      0.25      3313\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.56      0.54     11171\n",
      "weighted avg       0.69      0.72      0.66     11171\n",
      "\n",
      "Train accuracy:  0.7202578104019336\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.35000000000000003\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.45198512374305727\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7858, Test = 7766\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.45198512374305727\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3313, Test = 3405\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.2776605201170952\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 817, Test = 774\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.08004270767353637\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.93\n",
      "  Privacy Risk: 0.88\n",
      "  Accuracy: 0.88\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.77\n",
      "  Positive predictive value: 0.91\n",
      "  Optimal thershold: -2.772588722239781\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7041, Test = 6992\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.55\n",
      "  Optimal thershold: -0.45198512374305727\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3263, Test = 3345\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.70\n",
      "  Optimal thershold: -1.2776605201170952\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 817\n",
      "Number of test samples (ntest): 774\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7041\n",
      "Number of test samples (ntest): 6992\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3263\n",
      "Number of test samples (ntest): 3345\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7858\n",
      "         1.0       0.60      0.11      0.18      3313\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.66      0.54      0.51     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7139915853549369\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.5874599005900581\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7858, Test = 7766\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.27\n",
      "  Test Accuracy (TNR): 0.76\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.20493063306432624\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3313, Test = 3405\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.76\n",
      "  Optimal thershold: -1.321216621595022\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 817, Test = 774\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.8661827335935217\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.90\n",
      "  Privacy Risk: 0.85\n",
      "  Accuracy: 0.85\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.77\n",
      "  Attacker advantage: 0.71\n",
      "  Positive predictive value: 0.87\n",
      "  Optimal thershold: -1.4125190366941855\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7041, Test = 6992\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.5078071117910966\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3263, Test = 3345\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.321216621595022\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 817\n",
      "Number of test samples (ntest): 774\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 50\n",
      "Number of test samples (ntest): 60\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7041\n",
      "Number of test samples (ntest): 6992\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3263\n",
      "Number of test samples (ntest): 3345\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.95      0.82      7858\n",
      "         1.0       0.57      0.15      0.24      3313\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.55      0.53     11171\n",
      "weighted avg       0.68      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7144391728582938\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.03\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.021781030272010605\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7858, Test = 7766\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.0077841050986532\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3313, Test = 3405\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.16\n",
      "  Test Accuracy (TNR): 0.90\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -4.283692008582551\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 817, Test = 774\n",
      "  AUC: 0.49\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.0077841050986532\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 50, Test = 60\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.60\n",
      "  Attacker advantage: 0.50\n",
      "  Positive predictive value: 0.88\n",
      "  Optimal thershold: -4.283692008582551\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7041, Test = 6992\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3263, Test = 3345\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.15\n",
      "  Test Accuracy (TNR): 0.90\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.60\n",
      "  Optimal thershold: -0.021781030272010605\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         0.         0.91891892 0.8       ]\n",
      " [1.         0.         0.81081081 0.75      ]\n",
      " [1.         1.         0.89189189 0.85      ]\n",
      " ...\n",
      " [1.         0.         0.89189189 0.825     ]\n",
      " [1.         1.         0.89189189 0.675     ]\n",
      " [1.         1.         0.78378378 0.925     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10311.0 860.0\n",
      "base_pos unpriv:  0.07209302325581396\n",
      "base_pos priv:  0.3211133740665309\n",
      "number of favorable labels:  3373\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.249020\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 798\n",
      "Number of test samples (ntest): 793\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 62\n",
      "Number of test samples (ntest): 48\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7000\n",
      "Number of test samples (ntest): 7033\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3311\n",
      "Number of test samples (ntest): 3297\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7798\n",
      "         1.0       0.64      0.13      0.22      3373\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.55      0.52     11171\n",
      "weighted avg       0.70      0.72      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7158714528690359\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.32\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.38\n",
      "  Test Accuracy (TNR): 0.66\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.33550651950125393\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7798, Test = 7826\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3373, Test = 3345\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.2992829841302609\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 798, Test = 793\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.54\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 62, Test = 48\n",
      "  AUC: 0.89\n",
      "  Privacy Risk: 0.82\n",
      "  Accuracy: 0.82\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.63\n",
      "  Positive predictive value: 0.92\n",
      "  Optimal thershold: -2.622436448379218\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7000, Test = 7033\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.3364722366212129\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3311, Test = 3297\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.68\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.1913940221190757\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11486\n",
      "after transf priv:  0.3211133740665309\n",
      "after transf unpriv:  0.32085106382978723\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000262\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 798\n",
      "Number of test samples (ntest): 793\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 62\n",
      "Number of test samples (ntest): 48\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7000\n",
      "Number of test samples (ntest): 7033\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3311\n",
      "Number of test samples (ntest): 3297\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7798\n",
      "         1.0       0.72      0.19      0.30      3688\n",
      "\n",
      "    accuracy                           0.72     11486\n",
      "   macro avg       0.72      0.58      0.56     11486\n",
      "weighted avg       0.72      0.72      0.65     11486\n",
      "\n",
      "Train accuracy:  0.7162632770329096\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.31\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.50\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.4131871542020747\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7798, Test = 7826\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.34\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4131871542020747\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3373, Test = 3345\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.1786549963416462\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 798, Test = 793\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.46\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 62, Test = 48\n",
      "  AUC: 0.83\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.71\n",
      "  Attacker advantage: 0.55\n",
      "  Positive predictive value: 0.93\n",
      "  Optimal thershold: -1.6422277352570913\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7000, Test = 7033\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.4131871542020747\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3311, Test = 3297\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.1786549963416462\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 798\n",
      "Number of test samples (ntest): 793\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 62\n",
      "Number of test samples (ntest): 48\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7000\n",
      "Number of test samples (ntest): 7033\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3311\n",
      "Number of test samples (ntest): 3297\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7798\n",
      "         1.0       0.65      0.12      0.21      3373\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.69      0.55      0.52     11171\n",
      "weighted avg       0.70      0.72      0.64     11171\n",
      "\n",
      "Train accuracy:  0.715423865365679\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.32\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.78\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.8979415932059585\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7798, Test = 7826\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.69\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.4286680051878283\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3373, Test = 3345\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.96\n",
      "  Test Accuracy (TNR): 0.12\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -1.7346010553881064\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 798, Test = 793\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.72\n",
      "  Test Accuracy (TNR): 0.36\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 62, Test = 48\n",
      "  AUC: 0.88\n",
      "  Privacy Risk: 0.84\n",
      "  Accuracy: 0.84\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.69\n",
      "  Attacker advantage: 0.67\n",
      "  Positive predictive value: 0.92\n",
      "  Optimal thershold: -2.772588722239781\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7000, Test = 7033\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4286680051878283\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3311, Test = 3297\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -1.7346010553881064\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 798\n",
      "Number of test samples (ntest): 793\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 62\n",
      "Number of test samples (ntest): 48\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7000\n",
      "Number of test samples (ntest): 7033\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3311\n",
      "Number of test samples (ntest): 3297\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.82      7798\n",
      "         1.0       0.61      0.12      0.19      3373\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.67      0.54      0.51     11171\n",
      "weighted avg       0.69      0.71      0.63     11171\n",
      "\n",
      "Train accuracy:  0.71094799033211\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.38706359677851604\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7798, Test = 7826\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.38706359677851604\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3373, Test = 3345\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.32\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.3010242553316531\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 798, Test = 793\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.79\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.2732234966139742\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 62, Test = 48\n",
      "  AUC: 0.87\n",
      "  Privacy Risk: 0.81\n",
      "  Accuracy: 0.81\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.79\n",
      "  Attacker advantage: 0.61\n",
      "  Positive predictive value: 0.87\n",
      "  Optimal thershold: -1.3308124074444292\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7000, Test = 7033\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.64\n",
      "  Test Accuracy (TNR): 0.40\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.38706359677851604\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3311, Test = 3297\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.31\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.64\n",
      "  Optimal thershold: -1.3010242553316531\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 798\n",
      "Number of test samples (ntest): 793\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 62\n",
      "Number of test samples (ntest): 48\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7000\n",
      "Number of test samples (ntest): 7033\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3311\n",
      "Number of test samples (ntest): 3297\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7798\n",
      "         1.0       0.57      0.14      0.23      3373\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.64      0.55      0.52     11171\n",
      "weighted avg       0.67      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7081729478112971\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.14\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7798, Test = 7826\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3373, Test = 3345\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.20\n",
      "  Test Accuracy (TNR): 0.84\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -1.976336413500477\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 798, Test = 793\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 62, Test = 48\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.73\n",
      "  Accuracy: 0.73\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.75\n",
      "  Attacker advantage: 0.46\n",
      "  Positive predictive value: 0.79\n",
      "  Optimal thershold: -1.976336413500477\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7000, Test = 7033\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3311, Test = 3297\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.14\n",
      "  Test Accuracy (TNR): 0.89\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.7058812513525288\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.75675676 0.825     ]\n",
      " [0.         1.         0.2972973  0.725     ]\n",
      " [1.         1.         0.64864865 0.95      ]\n",
      " ...\n",
      " [1.         0.         0.59459459 0.875     ]\n",
      " [1.         0.         0.64864865 0.95      ]\n",
      " [1.         0.         0.51351351 0.775     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10309.0 862.0\n",
      "base_pos unpriv:  0.06728538283062645\n",
      "base_pos priv:  0.32369773983897565\n",
      "number of favorable labels:  3395\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.256412\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 804\n",
      "Number of test samples (ntest): 787\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 6972\n",
      "Number of test samples (ntest): 7061\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3337\n",
      "Number of test samples (ntest): 3271\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7776\n",
      "         1.0       0.63      0.15      0.25      3395\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.56      0.54     11171\n",
      "weighted avg       0.69      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7151553128636648\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.44\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3677247801253174\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7776, Test = 7848\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.61\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3677247801253174\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3395, Test = 3323\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.43\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.78\n",
      "  Optimal thershold: -1.1526795099383855\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 804, Test = 787\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.77\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.05264373348542203\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.89\n",
      "  Privacy Risk: 0.82\n",
      "  Accuracy: 0.82\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.75\n",
      "  Attacker advantage: 0.65\n",
      "  Positive predictive value: 0.90\n",
      "  Optimal thershold: -2.793208009442517\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6972, Test = 7061\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.3677247801253174\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3337, Test = 3271\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.67\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.74\n",
      "  Optimal thershold: -1.1526795099383855\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11497\n",
      "after transf priv:  0.32369773983897565\n",
      "after transf unpriv:  0.32323232323232326\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000465\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 804\n",
      "Number of test samples (ntest): 787\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 6972\n",
      "Number of test samples (ntest): 7061\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3337\n",
      "Number of test samples (ntest): 3271\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7776\n",
      "         1.0       0.71      0.20      0.32      3721\n",
      "\n",
      "    accuracy                           0.72     11497\n",
      "   macro avg       0.72      0.58      0.57     11497\n",
      "weighted avg       0.72      0.72      0.66     11497\n",
      "\n",
      "Train accuracy:  0.7160128729233713\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.85\n",
      "  Test Accuracy (TNR): 0.18\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.0715836162801904\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7776, Test = 7848\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.38\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3964152725882465\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3395, Test = 3323\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.80\n",
      "  Optimal thershold: -1.0715836162801904\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 804, Test = 787\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.80\n",
      "  Test Accuracy (TNR): 0.25\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.13005312824819779\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.89\n",
      "  Privacy Risk: 0.83\n",
      "  Accuracy: 0.83\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.79\n",
      "  Attacker advantage: 0.65\n",
      "  Positive predictive value: 0.93\n",
      "  Optimal thershold: -2.0794415416798357\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6972, Test = 7061\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -0.3964152725882465\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3337, Test = 3271\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.78\n",
      "  Optimal thershold: -1.0715836162801904\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 804\n",
      "Number of test samples (ntest): 787\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 6972\n",
      "Number of test samples (ntest): 7061\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3337\n",
      "Number of test samples (ntest): 3271\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7776\n",
      "         1.0       0.62      0.14      0.22      3395\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.67      0.55      0.52     11171\n",
      "weighted avg       0.69      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7118431653388237\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.62\n",
      "  Test Accuracy (TNR): 0.44\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.5571915443239164\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7776, Test = 7848\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.23\n",
      "  Attacker advantage: 0.10\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.5571915443239164\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3395, Test = 3323\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -1.7147984280919266\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 804, Test = 787\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.35\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.89\n",
      "  Privacy Risk: 0.85\n",
      "  Accuracy: 0.85\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.70\n",
      "  Positive predictive value: 0.88\n",
      "  Optimal thershold: -2.8213788864092133\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6972, Test = 7061\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.11\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.5571915443239164\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3337, Test = 3271\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.91\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -1.4445632692438664\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 804\n",
      "Number of test samples (ntest): 787\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 6972\n",
      "Number of test samples (ntest): 7061\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3337\n",
      "Number of test samples (ntest): 3271\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7776\n",
      "         1.0       0.62      0.15      0.24      3395\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.67      0.55      0.53     11171\n",
      "weighted avg       0.69      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7134544803509086\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.0130627522417135\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7776, Test = 7848\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.65\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.35557697772601515\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3395, Test = 3323\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.40\n",
      "  Test Accuracy (TNR): 0.69\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -1.0130627522417135\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 804, Test = 787\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.5633357501503982\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.90\n",
      "  Privacy Risk: 0.83\n",
      "  Accuracy: 0.83\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.77\n",
      "  Attacker advantage: 0.67\n",
      "  Positive predictive value: 0.91\n",
      "  Optimal thershold: -0.975426492761452\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6972, Test = 7061\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.41\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.35557697772601515\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3337, Test = 3271\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.39\n",
      "  Test Accuracy (TNR): 0.69\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.0130627522417135\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 804\n",
      "Number of test samples (ntest): 787\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 58\n",
      "Number of test samples (ntest): 52\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 6972\n",
      "Number of test samples (ntest): 7061\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3337\n",
      "Number of test samples (ntest): 3271\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7776\n",
      "         1.0       0.57      0.15      0.24      3395\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.64      0.55      0.53     11171\n",
      "weighted avg       0.67      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7071882553039119\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.71\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.01\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.31102265723807326\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7776, Test = 7848\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.020937702040313776\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3395, Test = 3323\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.19\n",
      "  Test Accuracy (TNR): 0.85\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -1.400057864969719\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 804, Test = 787\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.020937702040313776\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 58, Test = 52\n",
      "  AUC: 0.61\n",
      "  Privacy Risk: 0.67\n",
      "  Accuracy: 0.67\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.73\n",
      "  Attacker advantage: 0.33\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.400057864969719\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 6972, Test = 7061\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3337, Test = 3271\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.19\n",
      "  Test Accuracy (TNR): 0.86\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -3.8766544047033884\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         1.         0.56756757 0.775     ]\n",
      " [1.         0.         0.56756757 1.        ]\n",
      " [1.         1.         0.72972973 0.875     ]\n",
      " ...\n",
      " [1.         1.         0.45945946 0.6       ]\n",
      " [1.         0.         0.91891892 0.925     ]\n",
      " [1.         0.         0.63513514 0.875     ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10347.0 824.0\n",
      "base_pos unpriv:  0.06674757281553398\n",
      "base_pos priv:  0.31931960954866145\n",
      "number of favorable labels:  3359\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.252572\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 769\n",
      "Number of test samples (ntest): 822\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 55\n",
      "Number of test samples (ntest): 55\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7043\n",
      "Number of test samples (ntest): 6990\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3304\n",
      "Number of test samples (ntest): 3304\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83      7812\n",
      "         1.0       0.65      0.14      0.23      3359\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.69      0.55      0.53     11171\n",
      "weighted avg       0.70      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7186464953898487\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.88\n",
      "  Test Accuracy (TNR): 0.16\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.0861897686695525\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7812, Test = 7812\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.51\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.322773392263051\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3359, Test = 3359\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.49\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -1.0861897686695525\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 769, Test = 822\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.1823215567939546\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 55, Test = 55\n",
      "  AUC: 0.91\n",
      "  Privacy Risk: 0.83\n",
      "  Accuracy: 0.83\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.78\n",
      "  Attacker advantage: 0.65\n",
      "  Positive predictive value: 0.94\n",
      "  Optimal thershold: -2.639057329615259\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7043, Test = 6990\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.47\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.322773392263051\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3304, Test = 3304\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.61\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.73\n",
      "  Optimal thershold: -1.0861897686695525\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11476\n",
      "after transf priv:  0.31931960954866145\n",
      "after transf unpriv:  0.31886625332152346\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000453\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 769\n",
      "Number of test samples (ntest): 822\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 55\n",
      "Number of test samples (ntest): 55\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7043\n",
      "Number of test samples (ntest): 6990\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3304\n",
      "Number of test samples (ntest): 3304\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.96      0.82      7812\n",
      "         1.0       0.68      0.18      0.29      3664\n",
      "\n",
      "    accuracy                           0.71     11476\n",
      "   macro avg       0.70      0.57      0.55     11476\n",
      "weighted avg       0.70      0.71      0.65     11476\n",
      "\n",
      "Train accuracy:  0.7118333914255838\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.27\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.55\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.45198512374305727\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7812, Test = 7812\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.28\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.45198512374305727\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3359, Test = 3359\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.71\n",
      "  Optimal thershold: -1.0861897686695525\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 769, Test = 822\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.5340824859302579\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 55, Test = 55\n",
      "  AUC: 0.83\n",
      "  Privacy Risk: 0.76\n",
      "  Accuracy: 0.76\n",
      "  Train Accuracy (TPR): 0.84\n",
      "  Test Accuracy (TNR): 0.69\n",
      "  Attacker advantage: 0.53\n",
      "  Positive predictive value: 0.91\n",
      "  Optimal thershold: -1.5841201044498106\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7043, Test = 6990\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.66\n",
      "  Test Accuracy (TNR): 0.37\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3304, Test = 3304\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.50\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.0861897686695525\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 769\n",
      "Number of test samples (ntest): 822\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 55\n",
      "Number of test samples (ntest): 55\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7043\n",
      "Number of test samples (ntest): 6990\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3304\n",
      "Number of test samples (ntest): 3304\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.83      7812\n",
      "         1.0       0.62      0.15      0.24      3359\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.56      0.53     11171\n",
      "weighted avg       0.69      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.716587592874407\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.31\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -1.3609765531356008\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7812, Test = 7812\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3359, Test = 3359\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.3609765531356008\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 769, Test = 822\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.99\n",
      "  Test Accuracy (TNR): 0.06\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.4054651081081643\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 55, Test = 55\n",
      "  AUC: 0.87\n",
      "  Privacy Risk: 0.84\n",
      "  Accuracy: 0.84\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.67\n",
      "  Attacker advantage: 0.67\n",
      "  Positive predictive value: 0.86\n",
      "  Optimal thershold: -3.295836866004329\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7043, Test = 6990\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.55\n",
      "  Accuracy: 0.55\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.5108256237659907\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3304, Test = 3304\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.56\n",
      "  Accuracy: 0.56\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.12\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -1.3609765531356008\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 769\n",
      "Number of test samples (ntest): 822\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 55\n",
      "Number of test samples (ntest): 55\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7043\n",
      "Number of test samples (ntest): 6990\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3304\n",
      "Number of test samples (ntest): 3304\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.83      7812\n",
      "         1.0       0.62      0.15      0.24      3359\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.56      0.53     11171\n",
      "weighted avg       0.69      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7170351803777638\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.29000000000000004\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.38\n",
      "  Test Accuracy (TNR): 0.65\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.3101831868124642\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7812, Test = 7812\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3056448843153268\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3359, Test = 3359\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -1.3950469206480403\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 769, Test = 822\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.10\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.4360175590426274\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 55, Test = 55\n",
      "  AUC: 0.92\n",
      "  Privacy Risk: 0.83\n",
      "  Accuracy: 0.83\n",
      "  Train Accuracy (TPR): 0.75\n",
      "  Test Accuracy (TNR): 0.91\n",
      "  Attacker advantage: 0.65\n",
      "  Positive predictive value: 0.97\n",
      "  Optimal thershold: -0.4588030862930537\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7043, Test = 6990\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.48\n",
      "  Test Accuracy (TNR): 0.56\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.3056448843153268\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3304, Test = 3304\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.26\n",
      "  Attacker advantage: 0.08\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.3950469206480403\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 769\n",
      "Number of test samples (ntest): 822\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 55\n",
      "Number of test samples (ntest): 55\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7043\n",
      "Number of test samples (ntest): 6990\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3304\n",
      "Number of test samples (ntest): 3304\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7812\n",
      "         1.0       0.59      0.12      0.21      3359\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.54      0.51     11171\n",
      "weighted avg       0.68      0.71      0.64     11171\n",
      "\n",
      "Train accuracy:  0.7104108853280816\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.17\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.63\n",
      "  Test Accuracy (TNR): 0.39\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.012859103226184389\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7812, Test = 7812\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3359, Test = 3359\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.18\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.59\n",
      "  Optimal thershold: -4.360125957949272\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 769, Test = 822\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.87\n",
      "  Test Accuracy (TNR): 0.16\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.49\n",
      "  Optimal thershold: -0.012859103226184615\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 55, Test = 55\n",
      "  AUC: 0.70\n",
      "  Privacy Risk: 0.71\n",
      "  Accuracy: 0.71\n",
      "  Train Accuracy (TPR): 0.55\n",
      "  Test Accuracy (TNR): 0.87\n",
      "  Attacker advantage: 0.42\n",
      "  Positive predictive value: 0.81\n",
      "  Optimal thershold: -1.796559658024453\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7043, Test = 6990\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.95\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3304, Test = 3304\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.16\n",
      "  Test Accuracy (TNR): 0.88\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -4.360125957949272\n",
      ")\n",
      "#### Train dataset's features are as below:\n",
      "[[1.         0.         0.78378378 0.85      ]\n",
      " [1.         0.         0.67567568 0.65      ]\n",
      " [0.         0.         0.39189189 0.725     ]\n",
      " ...\n",
      " [1.         1.         0.7027027  0.55      ]\n",
      " [1.         1.         0.97297297 0.9       ]\n",
      " [1.         1.         0.64864865 0.75      ]]\n",
      "no bias type specified\n",
      "#### Training Dataset shape\n",
      "(11171, 4)\n",
      "#### Favorable and unfavorable labels\n",
      "1.0 0.0\n",
      "#### Protected attribute names\n",
      "['race']\n",
      "#### Privileged and unprivileged protected groups\n",
      "[{'race': 1}] [{'race': 0}]\n",
      "#### Privileged and unprivileged protected attribute values\n",
      "[array([1.])] [array([0.])]\n",
      "#### Dataset feature names\n",
      "['race', 'gender', 'lsat', 'ugpa']\n",
      "privileged vs. unprivileged:  10334.0 837.0\n",
      "base_pos unpriv:  0.07287933094384708\n",
      "base_pos priv:  0.32175343526224115\n",
      "number of favorable labels:  3386\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.248874\n",
      "#### Train shape, validation shape, test shape\n",
      "(11171, 4) (11171, 4) (11171, 4)\n",
      "#######################################################################\n",
      "                    dt\n",
      "#######################################################################\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Original Results......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 776\n",
      "Number of test samples (ntest): 815\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7009\n",
      "Number of test samples (ntest): 7024\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3325\n",
      "Number of test samples (ntest): 3283\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83      7785\n",
      "         1.0       0.64      0.17      0.27      3386\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.68      0.56      0.55     11171\n",
      "weighted avg       0.70      0.72      0.66     11171\n",
      "\n",
      "Train accuracy:  0.7193626353952197\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.3\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.86\n",
      "  Test Accuracy (TNR): 0.17\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -1.072263458971358\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7785, Test = 7839\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.76\n",
      "  Test Accuracy (TNR): 0.27\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.4462871026284195\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3386, Test = 3332\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.56\n",
      "  Test Accuracy (TNR): 0.53\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.69\n",
      "  Optimal thershold: -1.072263458971358\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 776, Test = 815\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.07\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.2876820724517809\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.77\n",
      "  Privacy Risk: 0.78\n",
      "  Accuracy: 0.78\n",
      "  Train Accuracy (TPR): 0.98\n",
      "  Test Accuracy (TNR): 0.57\n",
      "  Attacker advantage: 0.56\n",
      "  Positive predictive value: 0.77\n",
      "  Optimal thershold: -2.9267394020670396\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7009, Test = 7024\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.74\n",
      "  Test Accuracy (TNR): 0.29\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.4462871026284195\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3325, Test = 3283\n",
      "  AUC: 0.56\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.54\n",
      "  Train Accuracy (TPR): 0.57\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.09\n",
      "  Positive predictive value: 0.68\n",
      "  Optimal thershold: -1.072263458971358\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] Random Oversampling ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "origin, transf:  11171 11478\n",
      "after transf priv:  0.32175343526224115\n",
      "after transf unpriv:  0.32167832167832167\n",
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000075\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 776\n",
      "Number of test samples (ntest): 815\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7009\n",
      "Number of test samples (ntest): 7024\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3325\n",
      "Number of test samples (ntest): 3283\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7785\n",
      "         1.0       0.69      0.20      0.31      3693\n",
      "\n",
      "    accuracy                           0.71     11478\n",
      "   macro avg       0.71      0.58      0.56     11478\n",
      "weighted avg       0.71      0.71      0.66     11478\n",
      "\n",
      "Train accuracy:  0.714148806412267\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.34\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.30\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.7124403834946242\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7785, Test = 7839\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.55\n",
      "  Test Accuracy (TNR): 0.48\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.56\n",
      "  Optimal thershold: -0.3690974639372896\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3386, Test = 3332\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.54\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.37\n",
      "  Test Accuracy (TNR): 0.70\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -0.9285608244659693\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 776, Test = 815\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.3754842758962285\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.72\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 0.82\n",
      "  Test Accuracy (TNR): 0.51\n",
      "  Attacker advantage: 0.33\n",
      "  Positive predictive value: 0.93\n",
      "  Optimal thershold: -1.6863989535702288\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7009, Test = 7024\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.52\n",
      "  Test Accuracy (TNR): 0.52\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.61\n",
      "  Optimal thershold: -0.3690974639372896\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3325, Test = 3283\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.37\n",
      "  Test Accuracy (TNR): 0.70\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.66\n",
      "  Optimal thershold: -0.9285608244659693\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--disparat impact remover ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "=====================================================\n",
      "RUN DIRMITIGATOR\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 776\n",
      "Number of test samples (ntest): 815\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7009\n",
      "Number of test samples (ntest): 7024\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3325\n",
      "Number of test samples (ntest): 3283\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7785\n",
      "         1.0       0.63      0.16      0.25      3386\n",
      "\n",
      "    accuracy                           0.72     11171\n",
      "   macro avg       0.67      0.56      0.54     11171\n",
      "weighted avg       0.69      0.72      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7163190403723928\n",
      "Validating Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.25\n",
      "Testing Original ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.50\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.15\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -1.2060982036382495\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7785, Test = 7839\n",
      "  AUC: 0.49\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.6264558060612729\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3386, Test = 3332\n",
      "  AUC: 0.58\n",
      "  Privacy Risk: 0.58\n",
      "  Accuracy: 0.58\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -1.2060982036382495\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 776, Test = 815\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.97\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.3677247801253174\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.81\n",
      "  Privacy Risk: 0.75\n",
      "  Accuracy: 0.75\n",
      "  Train Accuracy (TPR): 0.90\n",
      "  Test Accuracy (TNR): 0.59\n",
      "  Attacker advantage: 0.49\n",
      "  Positive predictive value: 0.85\n",
      "  Optimal thershold: -2.639057329615259\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7009, Test = 7024\n",
      "  AUC: 0.49\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.92\n",
      "  Test Accuracy (TNR): 0.14\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.52\n",
      "  Optimal thershold: -0.6264558060612729\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3325, Test = 3283\n",
      "  AUC: 0.57\n",
      "  Privacy Risk: 0.57\n",
      "  Accuracy: 0.57\n",
      "  Train Accuracy (TPR): 0.73\n",
      "  Test Accuracy (TNR): 0.42\n",
      "  Attacker advantage: 0.15\n",
      "  Positive predictive value: 0.57\n",
      "  Optimal thershold: -1.2060982036382495\n",
      ")\n",
      "=====================================================\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO] preprocessing--reweighting ......\n",
      "\n",
      "------------------------------\n",
      "\n",
      "[INFO]: training decision tree\n",
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 776\n",
      "Number of test samples (ntest): 815\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples (ntrain): 7009\n",
      "Number of test samples (ntest): 7024\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3325\n",
      "Number of test samples (ntest): 3283\n",
      "Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82      7785\n",
      "         1.0       0.61      0.15      0.24      3386\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.67      0.55      0.53     11171\n",
      "weighted avg       0.69      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7137230328529227\n",
      "Validating Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "Best thresh:  0.28\n",
      "Testing Syn OR Rew ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.54\n",
      "  Optimal thershold: -0.6465380174750454\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7785, Test = 7839\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.08\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.53\n",
      "  Optimal thershold: -0.6430559587095052\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3386, Test = 3332\n",
      "  AUC: 0.55\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.60\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.07\n",
      "  Positive predictive value: 0.72\n",
      "  Optimal thershold: -1.1778894936193876\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 776, Test = 815\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.94\n",
      "  Test Accuracy (TNR): 0.11\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.7819094406093784\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.85\n",
      "  Privacy Risk: 0.77\n",
      "  Accuracy: 0.77\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.61\n",
      "  Attacker advantage: 0.55\n",
      "  Positive predictive value: 0.91\n",
      "  Optimal thershold: -1.3113039361256882\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7009, Test = 7024\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.83\n",
      "  Test Accuracy (TNR): 0.20\n",
      "  Attacker advantage: 0.03\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -0.45000125371343125\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3325, Test = 3283\n",
      "  AUC: 0.54\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.53\n",
      "  Train Accuracy (TPR): 0.59\n",
      "  Test Accuracy (TNR): 0.47\n",
      "  Attacker advantage: 0.06\n",
      "  Positive predictive value: 0.67\n",
      "  Optimal thershold: -1.1778894936193876\n",
      ")\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "[INFO:] in-processing Exponentiation Gradient Reduction ...... \n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected_attr_val, label, 0.0 0.0\n",
      "Number of training samples (ntrain): 776\n",
      "Number of test samples (ntest): 815\n",
      "Protected_attr_val, label, 0.0 1.0\n",
      "Number of training samples (ntrain): 61\n",
      "Number of test samples (ntest): 49\n",
      "Protected_attr_val, label, 1.0 0.0\n",
      "Number of training samples (ntrain): 7009\n",
      "Number of test samples (ntest): 7024\n",
      "Protected_attr_val, label, 1.0 1.0\n",
      "Number of training samples (ntrain): 3325\n",
      "Number of test samples (ntest): 3283\n",
      "####Train metrics:\n",
      "Classification report for train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82      7785\n",
      "         1.0       0.57      0.16      0.25      3386\n",
      "\n",
      "    accuracy                           0.71     11171\n",
      "   macro avg       0.65      0.55      0.53     11171\n",
      "weighted avg       0.68      0.71      0.65     11171\n",
      "\n",
      "Train accuracy:  0.7088890878166682\n",
      "Validating EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Best thresh:  0.19\n",
      "Testing EG ...\n",
      "=======================================================================\n",
      "TEST\n",
      "POS IND 1\n",
      "NEG IND 0\n",
      "=======================================================================\n",
      "MIA_Result(\n",
      "  Name: entire_dataset\n",
      "  Size of the Dataset: Train = 11171, Test = 11171\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.70\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -0.20790817798070682\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_0.0\n",
      "  Size of the Dataset: Train = 7785, Test = 7839\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.89\n",
      "  Test Accuracy (TNR): 0.13\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: entire_dataset_label_1.0\n",
      "  Size of the Dataset: Train = 3386, Test = 3332\n",
      "  AUC: 0.53\n",
      "  Privacy Risk: 0.53\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.22\n",
      "  Test Accuracy (TNR): 0.84\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -3.6590802931185538\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_0.0\n",
      "  Size of the Dataset: Train = 776, Test = 815\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.81\n",
      "  Test Accuracy (TNR): 0.22\n",
      "  Attacker advantage: 0.04\n",
      "  Positive predictive value: 0.50\n",
      "  Optimal thershold: -0.17669206184717842\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_0.0_label_1.0\n",
      "  Size of the Dataset: Train = 61, Test = 49\n",
      "  AUC: 0.68\n",
      "  Privacy Risk: 0.66\n",
      "  Accuracy: 0.66\n",
      "  Train Accuracy (TPR): 1.00\n",
      "  Test Accuracy (TNR): 0.33\n",
      "  Attacker advantage: 0.33\n",
      "  Positive predictive value: 1.00\n",
      "  Optimal thershold: -3.6590802931185538\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_0.0\n",
      "  Size of the Dataset: Train = 7009, Test = 7024\n",
      "  AUC: 0.51\n",
      "  Privacy Risk: 0.51\n",
      "  Accuracy: 0.51\n",
      "  Train Accuracy (TPR): 0.93\n",
      "  Test Accuracy (TNR): 0.09\n",
      "  Attacker advantage: 0.02\n",
      "  Positive predictive value: 0.51\n",
      "  Optimal thershold: -9.992007221626415e-16\n",
      ")\n",
      "MIA_Result(\n",
      "  Name: subpopulation_1.0_label_1.0\n",
      "  Size of the Dataset: Train = 3325, Test = 3283\n",
      "  AUC: 0.52\n",
      "  Privacy Risk: 0.52\n",
      "  Accuracy: 0.52\n",
      "  Train Accuracy (TPR): 0.20\n",
      "  Test Accuracy (TNR): 0.84\n",
      "  Attacker advantage: 0.05\n",
      "  Positive predictive value: 0.58\n",
      "  Optimal thershold: -3.6590802931185538\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# favorable and unfavorable labels and feature_names\n",
    "f_label = dataset_orig.favorable_label\n",
    "uf_label = dataset_orig.unfavorable_label\n",
    "feature_names = dataset_orig.feature_names\n",
    "\n",
    "# run mitigating algorithms\n",
    "for i in range(N):\n",
    "    if ATTACK == \"mia1\":\n",
    "        # split dataset into train, validation, and test\n",
    "        dataset_orig_train, dataset_orig_test = dataset_orig.split([p], shuffle=True)\n",
    "        dataset_orig_val = dataset_orig_test\n",
    "\n",
    "        print(\"#### Train dataset's features are as below:\")\n",
    "        print(dataset_orig_train.features)\n",
    "    elif ATTACK == \"mia2\":\n",
    "        train_index, test_index, population_index = get_unique_indices_reference()\n",
    "        \n",
    "        g_train = y_true[train_index] + (sensitive_features[train_index] + 1) * 2 # 2, 4, 3, 5\n",
    "        g_test = y_true[test_index] + (sensitive_features[test_index] + 1) * 2\n",
    "        g_pop_train = y_true[population_index] + (sensitive_features[population_index] + 1) * 2\n",
    "        \n",
    "        # for Audit\n",
    "        target_dataset, reference_dataset = create_datasets(train_index, test_index, population_index, g_train, g_test, g_pop_train)\n",
    "        \n",
    "        # for mitigators\n",
    "        privileged_value = [1]\n",
    "        unprivileged_value = [0]\n",
    "        # Convert train dataset\n",
    "        dataset_orig_train = create_binary_label_dataset(\n",
    "            dataset_orig=dataset_orig,\n",
    "            X=X[train_index],\n",
    "            y=y_true[train_index],\n",
    "            sensitive_features=sensitive_features[train_index],\n",
    "            sens_attr_name=sens_attr,\n",
    "            privileged_value=privileged_value,\n",
    "            unprivileged_value=unprivileged_value\n",
    "        )\n",
    "        \n",
    "        # Convert test dataset\n",
    "        dataset_orig_val = create_binary_label_dataset(\n",
    "            dataset_orig=dataset_orig,\n",
    "            X=X[test_index],\n",
    "            y=y_true[test_index],\n",
    "            sensitive_features=sensitive_features[test_index],\n",
    "            sens_attr_name=sens_attr,\n",
    "            privileged_value=privileged_value,\n",
    "            unprivileged_value=unprivileged_value\n",
    "        )\n",
    "        \n",
    "        # Since validation and testing datasets are the same\n",
    "        dataset_orig_test = dataset_orig_val\n",
    "        \n",
    "        # orig_metrics, orig_mia_metrics, priv_metric_orig, favor_metric_orig = run_MIA2(dataset_orig, target_dataset, reference_dataset, privileged_groups, unprivileged_groups, BASELINE, orig_metrics, orig_mia_metrics, f_label, uf_label, THRESH_ARR, DISPLAY, SCALER)\n",
    "        \n",
    "    # favorable and unfavorable labels and feature_names\n",
    "    f_label = dataset_orig.favorable_label\n",
    "    uf_label = dataset_orig.unfavorable_label\n",
    "    feature_names = dataset_orig.feature_names\n",
    "\n",
    "    # introduce label or selection biases, assuming the original data is fair\n",
    "    if BIAS_TYPE == 'label':\n",
    "        dataset_orig_train = label_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    elif BIAS_TYPE == 'selection':\n",
    "        dataset_orig_train = selection_bias(dataset_orig_train, unprivileged_groups, BIAS)\n",
    "    else:\n",
    "        print('no bias type specified')\n",
    "\n",
    "    # show data info\n",
    "    print(\"#### Training Dataset shape\")\n",
    "    print(dataset_orig_train.features.shape)\n",
    "    print(\"#### Favorable and unfavorable labels\")\n",
    "    print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "    print(\"#### Protected attribute names\")\n",
    "    print(dataset_orig_train.protected_attribute_names)\n",
    "    print(\"#### Privileged and unprivileged protected groups\")\n",
    "    print(privileged_groups, unprivileged_groups)\n",
    "    print(\"#### Privileged and unprivileged protected attribute values\")\n",
    "    print(dataset_orig_train.privileged_protected_attributes, dataset_orig_train.unprivileged_protected_attributes)\n",
    "    print(\"#### Dataset feature names\")\n",
    "    print(dataset_orig_train.feature_names)\n",
    "\n",
    "    # check fairness on the original data\n",
    "    metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    print(\"privileged vs. unprivileged: \", metric_orig_train.num_positives(privileged=True) + metric_orig_train.num_negatives(privileged=True), metric_orig_train.num_positives(privileged=False) + metric_orig_train.num_negatives(privileged=False)) \n",
    "    base_rate_unprivileged = metric_orig_train.base_rate(privileged=False)\n",
    "    base_rate_privileged = metric_orig_train.base_rate(privileged=True)\n",
    "    print('base_pos unpriv: ', base_rate_unprivileged)\n",
    "    print('base_pos priv: ', base_rate_privileged)\n",
    "    print('number of favorable labels: ', np.count_nonzero(dataset_orig_train.labels==f_label))\n",
    "    print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "    # statistics of favored/positive class BEFORE transf \n",
    "    priv_metric_orig['total_priv'] += metric_orig_train.num_instances(privileged = True) \n",
    "    priv_metric_orig['total_unpriv'] += metric_orig_train.num_instances(privileged = False) \n",
    "    favor_metric_orig['total_favor'] += metric_orig_train.base_rate()\n",
    "    favor_metric_orig['total_unfavor'] += 1 - metric_orig_train.base_rate()\n",
    "    favor_metric_orig['priv_favor'] += metric_orig_train.base_rate(privileged = True)\n",
    "    favor_metric_orig['priv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = True)\n",
    "    favor_metric_orig['unpriv_favor'] += metric_orig_train.base_rate(privileged = False)\n",
    "    favor_metric_orig['unpriv_unfavor'] += 1 - metric_orig_train.base_rate(privileged = False)\n",
    "\n",
    "    print(\"#### Train shape, validation shape, test shape\")\n",
    "    print(dataset_orig_train.features.shape, dataset_orig_val.features.shape, dataset_orig_test.features.shape)\n",
    "\n",
    "    # testing mitigation methods \n",
    "    test_cases = TestAlgorithms(BASELINE)\n",
    "\n",
    "    # null mitigator\n",
    "    orig_metrics, orig_mia_metrics = test_cases.run_original(dataset_orig_train, dataset_orig_val, dataset_orig_test, BASELINE, orig_metrics, orig_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset) \n",
    "\n",
    "    # synthetic data mitigator\n",
    "    metric_transf_train, transf_metrics, transf_mia_metrics = test_cases.run_oversample(dataset_orig_train, dataset_orig_val, dataset_orig_test, privileged_groups, unprivileged_groups, base_rate_privileged, base_rate_unprivileged, BASELINE, transf_metrics, transf_mia_metrics, f_label, uf_label, ATTACK, THRESH_ARR, DISPLAY, OS_MODE, SCALER, target_dataset, reference_dataset)\n",
    "    \n",
    "    # statistics of favored/positive class AFTER transf\n",
    "    favor_metric_transf['total_favor'] += metric_transf_train.base_rate()\n",
    "    favor_metric_transf['total_unfavor'] += 1 - metric_transf_train.base_rate()\n",
    "    favor_metric_transf['priv_favor'] += metric_transf_train.base_rate(privileged = True)\n",
    "    favor_metric_transf['priv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = True)\n",
    "    favor_metric_transf['unpriv_favor'] += metric_transf_train.base_rate(privileged = False)\n",
    "    favor_metric_transf['unpriv_unfavor'] += 1 - metric_transf_train.base_rate(privileged = False)\n",
    "\n",
    "    # dir mitigator\n",
    "    dir_metrics, dir_mia_metrics = test_cases.run_dir(dataset_orig_train, dataset_orig_val, dataset_orig_test,  sens_attr, BASELINE, dir_metrics, dir_mia_metrics, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset) \n",
    "    \n",
    "    # reweigh mitigator\n",
    "    reweigh_metrics, reweigh_mia_metrics = test_cases.run_rew(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, reweigh_metrics, reweigh_mia_metrics, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "\n",
    "    # eg mitigator, in-processing\n",
    "    eg_metrics, eg_mia_metrics = test_cases.run_eg(dataset_orig_train, dataset_orig_val, dataset_orig_test, eg_metrics, eg_mia_metrics, BASELINE, f_label, uf_label, unprivileged_groups, privileged_groups, ATTACK, THRESH_ARR, DISPLAY, SCALER, target_dataset, reference_dataset)\n",
    "#     # egr gave error so I replaced it with reweigh\n",
    "# #     eg_metrics, eg_mia_metrics = test_cases.run_rew(dataset_orig_train, dataset_orig_val, dataset_orig_test, f_label, uf_label,  unprivileged_groups, privileged_groups, BASELINE, eg_metrics, eg_mia_metrics, THRESH_ARR, DISPLAY, SCALER)\n",
    "\n",
    "#     # cpp mitigator\n",
    "#     cpp_metrics = test_cases.run_cpp(dataset_orig_train, dataset_orig_val, dataset_orig_test, cpp_metrics, BASELINE, unprivileged_groups, privileged_groups, THRESH_ARR, SCALER)\n",
    "\n",
    "#     # ro mitigator\n",
    "#     # ro_metrics = test_cases.run_ro(dataset_orig_train, dataset_orig_val, dataset_orig_test, ro_metrics, BASELINE, unprivileged_groups, privileged_groups, THRESH_ARR, SCALER)\n",
    "\n",
    "#     if (BASELINE == 'lr'):\n",
    "#         pr_orig_metrics = test_cases.run_pr(dataset_orig_train, dataset_orig_val, dataset_orig_test, pr_orig_metrics, sens_attr, f_label, uf_label, unprivileged_groups, privileged_groups, THRESH_ARR, DISPLAY, SCALER) \n",
    "\n",
    "    delete_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e9f7847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_bank, _ = dataset_orig.convert_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2811a790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race\n",
       "1.0    20641\n",
       "0.0     1701\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2bee0ec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the occurrences of privileged and unprivileged values\n",
    "gender_counts = df_bank['gender'].value_counts()\n",
    "\n",
    "# Plot the bar graph\n",
    "plt.figure(figsize=(6, 4))\n",
    "gender_counts.plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('Count of Privileged and Unprivileged Values in Gender')\n",
    "plt.xlabel('Gender Category (1=Privileged, 0=Unprivileged)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f013a728",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'y'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_counts \u001b[38;5;241m=\u001b[39m \u001b[43mdf_bank\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'y'"
     ]
    }
   ],
   "source": [
    "y_counts = df_bank['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3752774e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'y'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Count the occurrences of privileged and unprivileged values\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m label_counts \u001b[38;5;241m=\u001b[39m \u001b[43mdf_bank\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Plot the bar graph\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'y'"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of privileged and unprivileged values\n",
    "label_counts = df_bank['y'].value_counts()\n",
    "\n",
    "# Plot the bar graph\n",
    "plt.figure(figsize=(6, 4))\n",
    "age_counts.plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('Count of Favorable and Unfavorable Values in Dataset')\n",
    "plt.xlabel('Label Category (1=Favorable, 0=Unfavorable)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "900da4ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20798, 14)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90de2a9",
   "metadata": {},
   "source": [
    "## Display Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "72632350",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig_copy = priv_metric_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8530a47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float, {'total_priv': 206471.0, 'total_unpriv': 16949.0})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priv_metric_orig_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8b736dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float, {'total_priv': 206471.0, 'total_unpriv': 16949.0})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priv_metric_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c736a792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('total_priv', 206471.0), ('total_unpriv', 16949.0)])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priv_metric_orig.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c73a4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_metric_orig = priv_metric_orig_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0ea4ee29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('bal_acc', [0.582757750470755, 0.5958752029112696, 0.5816697090296905, 0.5877580968268434, 0.5910598796334279, 0.5887616005129702, 0.5863254057429071, 0.5875541485403427, 0.5864694062819407, 0.5799709394868735, 0.5892721748055172, 0.5839196716505424, 0.5911376272431077, 0.5839549758907552, 0.5791586876570112, 0.5824675729855997, 0.5878829221669977, 0.5824660231120142, 0.5848456135071776, 0.5875654509794732]), ('avg_odds_diff', [-0.5982734672517263, -0.4383311571326717, -0.4084203544748988, -0.5968020580541604, -0.4577174710691193, -0.5142423495503621, -0.5433352599055188, -0.5165418378018298, -0.4200839123442782, -0.52792722051381, -0.45578349264168927, -0.5591547385582392, -0.5786438501117561, -0.6369029870083596, -0.5511241124288089, -0.6058831620592893, -0.4608877212782817, -0.6044843256193013, -0.4956111021320936, -0.4113892905257839]), ('disp_imp', [0.9158585736376663, 0.9067032521367643, 0.9048461985062788, 0.9036701802131752, 0.8707447502559684, 0.9430325875486382, 0.8697308784080764, 0.8852470298478139, 0.8886014336706097, 0.8676362704192007, 0.9283979243192713, 0.9218084553661972, 0.9235265713467469, 0.9276941001257019, 0.8639608118560644, 0.928788870929262, 0.8758583503166747, 0.923511426646629, 0.869883779223133, 0.8585532871890497]), ('stat_par_diff', [-0.5707857848069351, -0.4444073580105533, -0.3957497700727365, -0.5688835606898625, -0.4610918218689817, -0.5173092315901814, -0.5369986648170586, -0.5090256434744814, -0.4024978821316044, -0.5562678214950948, -0.4712172833553037, -0.5470583111776501, -0.563661020615452, -0.618492817215822, -0.5614825636177015, -0.5942739278636102, -0.44462741423626745, -0.6044119499597856, -0.4726306564207289, -0.4566400621296566]), ('eq_opp_diff', [-0.6658463204395415, -0.47945181625047884, -0.46295739348370923, -0.6676648015387305, -0.4968576336263515, -0.5509725479376465, -0.5894267017568817, -0.5644216645310498, -0.4828363012229136, -0.5288119368197615, -0.47961585180686306, -0.6106043444844463, -0.6361591247491423, -0.6931057827038432, -0.5731265434235732, -0.6550074738415546, -0.5214589020321504, -0.638789596218517, -0.561352630420427, -0.40085287846481876]), ('theil_ind', [0.15528196063213395, 0.19278751624892412, 0.21378969900169756, 0.149753681830477, 0.18012140122347625, 0.17610279204220175, 0.15473652497005935, 0.1665855775836197, 0.20645634786118378, 0.15118211934029158, 0.18778138284582116, 0.16660332990949134, 0.15419843009517598, 0.1435999188678661, 0.148520611862108, 0.1519438837333612, 0.18745621203237017, 0.14457582919725398, 0.1791338908094774, 0.1798216901299366]), ('unpriv_fpr', [0.05317769130998703, 0.041025641025641026, 0.03969270166453265, 0.061146496815286625, 0.06359102244389027, 0.027194066749072928, 0.07800511508951406, 0.06385542168674699, 0.04920049200492005, 0.0773955773955774, 0.030112923462986198, 0.0448318804483188, 0.045, 0.04790419161676647, 0.0840764331210191, 0.04392764857881137, 0.0617906683480454, 0.04701397712833545, 0.0705596107055961, 0.06625766871165645]), ('unpriv_fnr', [0.9591836734693877, 0.8823529411764706, 0.9333333333333333, 0.9464285714285714, 0.8666666666666667, 0.9090909090909091, 0.8823529411764706, 0.8979591836734694, 0.9322033898305084, 0.8103448275862069, 0.875, 0.9322033898305084, 0.9298245614035088, 0.9473684210526315, 0.8461538461538461, 0.9333333333333333, 0.9166666666666666, 0.9038461538461539, 0.9272727272727272, 0.7755102040816326]), ('priv_fpr', [0.5838783053738982, 0.4382361390405056, 0.39357601713062096, 0.5870858113848768, 0.48216833095577744, 0.5047062179121506, 0.57524893314367, 0.5325174327593568, 0.40653201547056295, 0.6044380816034359, 0.46206405693950175, 0.5525370130803507, 0.5661285754743699, 0.6286043829296425, 0.6131981145550636, 0.6006864988558352, 0.46210720887245843, 0.6171930321484209, 0.5004291845493563, 0.48818337129840544]), ('priv_fnr', [0.29333735302984626, 0.4029011249259917, 0.47037593984962406, 0.27876376988984086, 0.36980903304031526, 0.3581183611532625, 0.2929262394195889, 0.3335375191424196, 0.44936708860759494, 0.2815328907664454, 0.39538414819313694, 0.32159904534606204, 0.29366543665436656, 0.25426263834878854, 0.27302730273027304, 0.2783258594917788, 0.39520776463451623, 0.2650565576276368, 0.36592009685230026, 0.37465732561681386])])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_metrics.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bf623751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)\n",
      "\n",
      "law_race_aif\n",
      "11171\n",
      "2)\n",
      "\n",
      "              total_priv  total_unpriv\n",
      "num_instance                          \n",
      "orig            10323.55        847.45\n",
      "3)\n",
      "\n",
      "         total_favor  total_unfavor  priv_favor  priv_unfavor  unpriv_favor  \\\n",
      "dataset                                                                       \n",
      "orig        0.300363       0.699637    0.319658      0.680342      0.065315   \n",
      "transf      0.319629       0.680371    0.319658      0.680342      0.319373   \n",
      "\n",
      "         unpriv_unfavor  \n",
      "dataset                  \n",
      "orig           0.934685  \n",
      "transf         0.680627  \n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "print('1)\\n')\n",
    "print(DATASET)\n",
    "print(dataset_orig_train.features.shape[0])\n",
    "\n",
    "print('2)\\n')\n",
    "priv_metric_orig = {k: [v/N] for (k,v) in priv_metric_orig.items()}\n",
    "results = [priv_metric_orig]\n",
    "tr = pd.Series(['orig'], name='num_instance')\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis = 0).set_index([tr])\n",
    "print(df)\n",
    "\n",
    "print('3)\\n')\n",
    "favor_metric_orig = {k: [v/N] for (k,v) in favor_metric_orig.items()}\n",
    "favor_metric_transf = {k: [v/N] for (k,v) in favor_metric_transf.items()}\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "results = [favor_metric_orig, favor_metric_transf]\n",
    "tr = pd.Series(['orig'] + ['transf'], name='dataset')\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis = 0).set_index([tr])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "23a78a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('4)\\n')\n",
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_error_metrics = {k: [statistics.stdev(v)] for (k,v) in orig_metrics.items()}\n",
    "transf_error_metrics = {k: [statistics.stdev(v)] for (k,v) in transf_metrics.items()}\n",
    "reweigh_error_metrics = {k: [statistics.stdev(v)] for (k,v) in reweigh_metrics.items()}\n",
    "dir_error_metrics = {k: [statistics.stdev(v)] for (k,v) in dir_metrics.items()}\n",
    "eg_error_metrics = {k: [statistics.stdev(v)] for (k,v) in eg_metrics.items()}\n",
    "# pr_orig_error_metrics = {k: [statistics.stdev(v)] for (k,v) in pr_orig_metrics.items()}\n",
    "# cpp_error_metrics = {k: [statistics.stdev(v)] for (k,v) in cpp_metrics.items()}\n",
    "# ro_error_metrics = {k: [statistics.stdev(v)] for (k,v) in ro_metrics.items()}\n",
    "\n",
    "# mean value metrics\n",
    "orig_metrics_mean = {k: [sum(v)/N] for (k,v) in orig_metrics.items()}\n",
    "transf_metrics_mean = {k: [sum(v)/N] for (k,v) in transf_metrics.items()}\n",
    "reweigh_metrics_mean = {k:[sum(v)/N] for (k,v) in reweigh_metrics.items()}\n",
    "dir_metrics_mean = {k:[sum(v)/N] for (k,v) in dir_metrics.items()}\n",
    "eg_metrics_mean = {k:[sum(v)/N] for (k,v) in eg_metrics.items()}\n",
    "# pr_orig_metrics_mean = {k: [sum(v)/N] for (k,v) in pr_orig_metrics.items()}\n",
    "# cpp_metrics_mean = {k: [sum(v)/N] for (k,v) in cpp_metrics.items()}\n",
    "# ro_metrics_mean = {k: [sum(v)/N] for (k,v) in ro_metrics.items()}\n",
    "\n",
    "# Python paired sample t-test\n",
    "from scipy.stats import ttest_rel\n",
    "def paired_t (a, b):\n",
    "    np_a = np.array(a)\n",
    "    np_b = np.array(b)\n",
    "    s, p = ttest_rel(np.absolute(np_a), np.absolute(np_b))\n",
    "    return p\n",
    "\n",
    "def acc_diff (a, b):\n",
    "    np_a = np.array(a)\n",
    "    np_b = np.array(b)\n",
    "    delta = np_a - np_b\n",
    "    m = statistics.mean(delta)\n",
    "    s = statistics.stdev(delta)\n",
    "    return [m, s]\n",
    "\n",
    "# if BASELINE == 'lr':\n",
    "#     plot_algo_lr(orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, eg_metrics_mean, pr_orig_metrics_mean, cpp_metrics_mean, ro_metrics_mean, orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, egr_error_metrics, pr_orig_error_metrics, cpp_error_metrics, ro_error_metrics, BASELINE)\n",
    "#     stat =  {k: [paired_t(transf_metrics[k], v)] for (k,v) in orig_metrics.items()}\n",
    "#     print(\"5)\")\n",
    "#     print(stat)\n",
    "# else:\n",
    "#     plot_algo(orig_metrics_mean, transf_metrics_mean, dir_metrics_mean, reweigh_metrics_mean, eg_metrics_mean, cpp_metrics_mean, ro_metrics_mean, orig_error_metrics, transf_error_metrics, dir_error_metrics, reweigh_error_metrics, egr_error_metrics, cpp_error_metrics, ro_error_metrics, BASELINE)\n",
    "#     stat =  {k: [paired_t(transf_metrics[k], v)] for (k,v) in orig_metrics.items()}\n",
    "#     print(stat)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1627a85",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f14ab",
   "metadata": {},
   "source": [
    "### Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "25c6d438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1fec02d0590>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_type = BASELINE\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_metrics_mean,\n",
    "        transf_metrics_mean,\n",
    "        dir_metrics_mean,\n",
    "        reweigh_metrics_mean,\n",
    "        eg_metrics_mean]\n",
    "#         pr_orig_metrics_mean,\n",
    "#         cpp_metrics_mean,\n",
    "#         ro_metrics_mean]\n",
    "\n",
    "\n",
    "errors = [orig_error_metrics,\n",
    "        transf_error_metrics,\n",
    "        dir_error_metrics,\n",
    "        reweigh_error_metrics,\n",
    "        eg_error_metrics]\n",
    "#         pr_orig_error_metrics,\n",
    "#         cpp_error_metrics,\n",
    "#         ro_error_metrics]\n",
    "\n",
    "index = pd.Series([model_type+'_orig']+ [model_type+'_syn'] + [model_type+'_dir'] + [model_type+'_rew'] + [model_type+'_eg'], name='Classifier Bias Mitigator')\n",
    "#                   + [model_type+'_rew']+  + [model_type+'_cpp'], name='Classifier Bias Mitigator')\n",
    "\n",
    "df = pd.concat([pd.DataFrame(metrics) for metrics in results], axis=0).set_index(index)\n",
    "df_error = pd.concat([pd.DataFrame(metrics) for metrics in errors], axis=0).set_index(index)\n",
    "ax = df.plot.bar(yerr=df_error, capsize=4, rot=0, subplots=True, title=['','','','','', '', '', '', '', ''], fontsize = 12, figsize=(10,10))\n",
    "plot1 = ax[0]\n",
    "plot1.set_ylim=([0, 0.8])\n",
    "plot2 = ax[1]\n",
    "plot2.set_ylim=([-0.5, 0])\n",
    "plot3 = ax[2]\n",
    "plot3.set_ylim=([0, 1])\n",
    "plot4 = ax[3]\n",
    "plot4.set_ylim=([-0.5, 0])\n",
    "plot5 = ax[4]\n",
    "plot5.set_ylim=([-0.5, 0])\n",
    "plot5 = ax[5]\n",
    "plot5.set_ylim=([0, 0.2])\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.5, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7aff8d",
   "metadata": {},
   "source": [
    "## Visualization of MIA results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588cc377",
   "metadata": {},
   "source": [
    "### Visualization of MIA Attacks against various Fairness Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a42bd",
   "metadata": {},
   "source": [
    "#### Privacy risk subpopulations vs Fairness with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8dddfde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "%matplotlib inline\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "eg_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in eg_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "# cpp_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in cpp_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "eg_mia_metrics_mean = {k:sum(v)/N for (k,v) in eg_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "# cpp_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d6882740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entire_dataset_mia_privacy_risk</th>\n",
       "      <th>entire_dataset_label_0.0_mia_privacy_risk</th>\n",
       "      <th>entire_dataset_label_1.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_0.0_label_0.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_0.0_label_1.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_1.0_label_0.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_1.0_label_1.0_mia_privacy_risk</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier MIA Attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>orig</th>\n",
       "      <td>0.518597</td>\n",
       "      <td>0.519305</td>\n",
       "      <td>0.541496</td>\n",
       "      <td>0.527101</td>\n",
       "      <td>0.799938</td>\n",
       "      <td>0.519727</td>\n",
       "      <td>0.538967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syn</th>\n",
       "      <td>0.516570</td>\n",
       "      <td>0.516546</td>\n",
       "      <td>0.535535</td>\n",
       "      <td>0.529604</td>\n",
       "      <td>0.740392</td>\n",
       "      <td>0.516075</td>\n",
       "      <td>0.532996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dir</th>\n",
       "      <td>0.533728</td>\n",
       "      <td>0.541662</td>\n",
       "      <td>0.549046</td>\n",
       "      <td>0.527670</td>\n",
       "      <td>0.806501</td>\n",
       "      <td>0.544310</td>\n",
       "      <td>0.546198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rew</th>\n",
       "      <td>0.517552</td>\n",
       "      <td>0.517822</td>\n",
       "      <td>0.540492</td>\n",
       "      <td>0.525226</td>\n",
       "      <td>0.829838</td>\n",
       "      <td>0.517785</td>\n",
       "      <td>0.535869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eg</th>\n",
       "      <td>0.512465</td>\n",
       "      <td>0.510484</td>\n",
       "      <td>0.522423</td>\n",
       "      <td>0.511084</td>\n",
       "      <td>0.675116</td>\n",
       "      <td>0.510303</td>\n",
       "      <td>0.520486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        entire_dataset_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                    \n",
       "orig                                           0.518597   \n",
       "syn                                            0.516570   \n",
       "dir                                            0.533728   \n",
       "rew                                            0.517552   \n",
       "eg                                             0.512465   \n",
       "\n",
       "                        entire_dataset_label_0.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                              \n",
       "orig                                                     0.519305   \n",
       "syn                                                      0.516546   \n",
       "dir                                                      0.541662   \n",
       "rew                                                      0.517822   \n",
       "eg                                                       0.510484   \n",
       "\n",
       "                        entire_dataset_label_1.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                              \n",
       "orig                                                     0.541496   \n",
       "syn                                                      0.535535   \n",
       "dir                                                      0.549046   \n",
       "rew                                                      0.540492   \n",
       "eg                                                       0.522423   \n",
       "\n",
       "                        subpopulation_0.0_label_0.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                                 \n",
       "orig                                                        0.527101   \n",
       "syn                                                         0.529604   \n",
       "dir                                                         0.527670   \n",
       "rew                                                         0.525226   \n",
       "eg                                                          0.511084   \n",
       "\n",
       "                        subpopulation_0.0_label_1.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                                 \n",
       "orig                                                        0.799938   \n",
       "syn                                                         0.740392   \n",
       "dir                                                         0.806501   \n",
       "rew                                                         0.829838   \n",
       "eg                                                          0.675116   \n",
       "\n",
       "                        subpopulation_1.0_label_0.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                                 \n",
       "orig                                                        0.519727   \n",
       "syn                                                         0.516075   \n",
       "dir                                                         0.544310   \n",
       "rew                                                         0.517785   \n",
       "eg                                                          0.510303   \n",
       "\n",
       "                        subpopulation_1.0_label_1.0_mia_privacy_risk  \n",
       "Classifier MIA Attacks                                                \n",
       "orig                                                        0.538967  \n",
       "syn                                                         0.532996  \n",
       "dir                                                         0.546198  \n",
       "rew                                                         0.535869  \n",
       "eg                                                          0.520486  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "           transf_mia_metrics_mean,\n",
    "           dir_mia_metrics_mean,\n",
    "           reweigh_mia_metrics_mean,\n",
    "           eg_mia_metrics_mean\n",
    "          ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "          transf_mia_error_metrics,\n",
    "          dir_mia_error_metrics,\n",
    "          reweigh_mia_error_metrics,\n",
    "          eg_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn'] + ['dir'] + ['rew'] + ['eg'], name='Classifier MIA Attacks')\n",
    "#                   + ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3881013e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'entire_dataset_mia_auc': [0.5288299000087674,\n",
       "              0.5269621447229618,\n",
       "              0.523760714103324,\n",
       "              0.5194454593171327,\n",
       "              0.5217538905635212,\n",
       "              0.5226839197792736,\n",
       "              0.5274211673237547,\n",
       "              0.5205047964864777,\n",
       "              0.5272408982614413,\n",
       "              0.5285484339401674,\n",
       "              0.5216698462033886,\n",
       "              0.5273207195687717,\n",
       "              0.5206292363099426,\n",
       "              0.5272035358635467,\n",
       "              0.533583923570405,\n",
       "              0.5295168512668289,\n",
       "              0.5270621236950437,\n",
       "              0.5228106834837871,\n",
       "              0.5246015303269562,\n",
       "              0.5229603494367044],\n",
       "             'entire_dataset_mia_privacy_risk': [0.5213051651597888,\n",
       "              0.5192910213946826,\n",
       "              0.5188881926416614,\n",
       "              0.5152179751141348,\n",
       "              0.5155312863664847,\n",
       "              0.5179930176349477,\n",
       "              0.5187091576403187,\n",
       "              0.517366395130248,\n",
       "              0.5184406051383046,\n",
       "              0.5208575776564318,\n",
       "              0.515486527616149,\n",
       "              0.5209023364067675,\n",
       "              0.5162921851221914,\n",
       "              0.5202309551517321,\n",
       "              0.5244830364336228,\n",
       "              0.5201414376510608,\n",
       "              0.5184853638886402,\n",
       "              0.5171873601289052,\n",
       "              0.5173216363799122,\n",
       "              0.5178139826336048],\n",
       "             'entire_dataset_mia_ppv': [0.542713567839196,\n",
       "              0.5394105551747772,\n",
       "              0.5297595585337013,\n",
       "              0.5439093484419264,\n",
       "              0.5523520485584219,\n",
       "              0.5401069518716578,\n",
       "              0.552614590058102,\n",
       "              0.527970600244998,\n",
       "              0.5375803297010338,\n",
       "              0.5365699873896596,\n",
       "              0.5375302663438257,\n",
       "              0.5327462850853054,\n",
       "              0.5298892988929889,\n",
       "              0.5461279461279461,\n",
       "              0.5498853211009174,\n",
       "              0.5419401896425966,\n",
       "              0.5580623755806238,\n",
       "              0.5430985915492959,\n",
       "              0.534767383691846,\n",
       "              0.5303929884082556],\n",
       "             'entire_dataset_mia_attacker_advantage': [0.042610330319577505,\n",
       "              0.038582042789365334,\n",
       "              0.037776385283322944,\n",
       "              0.030435950228269615,\n",
       "              0.031062572732969307,\n",
       "              0.0359860352698953,\n",
       "              0.037418315280637326,\n",
       "              0.034732790260495916,\n",
       "              0.03688121027660912,\n",
       "              0.04171515531286363,\n",
       "              0.030973055232297986,\n",
       "              0.04180467281353506,\n",
       "              0.032584370244382876,\n",
       "              0.040461910303464355,\n",
       "              0.048966072867245525,\n",
       "              0.04028287530212149,\n",
       "              0.03697072777728044,\n",
       "              0.03437472025781041,\n",
       "              0.034643272759824484,\n",
       "              0.03562796526720968],\n",
       "             'entire_dataset_mia_result': [MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.06991317, 0.07143497, 0.07268821, 0.07456808,\n",
       "                     0.07940202, 0.08047623, 0.08101334, 0.08307224, 0.08423597,\n",
       "                     0.08960702, 0.09945394, 0.10303464, 0.10366127, 0.10598872,\n",
       "                     0.11708889, 0.11861069, 0.12675678, 0.13830454, 0.14295945,\n",
       "                     0.14421269, 0.14645063, 0.14868857, 0.15808791, 0.16166861,\n",
       "                     0.16220571, 0.166234  , 0.16874049, 0.17894548, 0.1810939 ,\n",
       "                     0.18333184, 0.18816579, 0.20141438, 0.20275714, 0.20526363,\n",
       "                     0.23328261, 0.23525199, 0.2383851 , 0.24080208, 0.24411422,\n",
       "                     0.24742637, 0.26165965, 0.27866798, 0.28448662, 0.28905201,\n",
       "                     0.29182705, 0.29469161, 0.30400143, 0.31796616, 0.3207412 ,\n",
       "                     0.33014054, 0.3339898 , 0.34267299, 0.35180378, 0.35842807,\n",
       "                     0.36558947, 0.36836452, 0.37722675, 0.37839048, 0.38993823,\n",
       "                     0.39262376, 0.39325038, 0.40300779, 0.42109032, 0.42520813,\n",
       "                     0.42860979, 0.429684  , 0.43460747, 0.43809865, 0.44069466,\n",
       "                     0.45456987, 0.46182079, 0.47247337, 0.47596455, 0.48724376,\n",
       "                     0.49163011, 0.49494226, 0.49744875, 0.49995524, 0.50335691,\n",
       "                     0.51588936, 0.52260317, 0.52358786, 0.52439352, 0.52681049,\n",
       "                     0.53182347, 0.53835825, 0.54596724, 0.54856324, 0.5488318 ,\n",
       "                     0.5524125 , 0.55357622, 0.55581416, 0.56807806, 0.56870468,\n",
       "                     0.57058455, 0.57434428, 0.58096858, 0.58320652, 0.58580252,\n",
       "                     0.58705577, 0.58768239, 0.59206875, 0.59350103, 0.59421717,\n",
       "                     0.60630203, 0.60782383, 0.60916659, 0.6132844 , 0.61623847,\n",
       "                     0.62017724, 0.62635395, 0.63065079, 0.631725  , 0.63960254,\n",
       "                     0.64085579, 0.64425745, 0.64765912, 0.65079223, 0.65356727,\n",
       "                     0.6552681 , 0.65938591, 0.66153433, 0.66457792, 0.66780056,\n",
       "                     0.66824814, 0.66896428, 0.67003849, 0.67200788, 0.67406678,\n",
       "                     0.67684182, 0.69170173, 0.6941187 , 0.69662519, 0.69940023,\n",
       "                     0.6997583 , 0.70083251, 0.7012801 , 0.70611405, 0.70808343,\n",
       "                     0.70951571, 0.71676663, 0.71837794, 0.72169009, 0.72356996,\n",
       "                     0.72455465, 0.72831439, 0.73073136, 0.7314475 , 0.73592337,\n",
       "                     0.73825083, 0.74192105, 0.74496464, 0.74675499, 0.74872438,\n",
       "                     0.74953003, 0.75194701, 0.75409543, 0.75633336, 0.76206248,\n",
       "                     0.76251007, 0.7642109 , 0.76707546, 0.76734402, 0.76859726,\n",
       "                     0.77029809, 0.77423686, 0.77942888, 0.78095068, 0.78220392,\n",
       "                     0.78292006, 0.78766449, 0.78990243, 0.79115567, 0.79258795,\n",
       "                     0.7928565 , 0.79455734, 0.80010742, 0.80279295, 0.80556799,\n",
       "                     0.80700027, 0.80789544, 0.80896965, 0.81058097, 0.8158625 ,\n",
       "                     0.81836899, 0.82069645, 0.82275535, 0.82418763, 0.82615701,\n",
       "                     0.83045385, 0.83448214, 0.84030078, 0.84343389, 0.84925253,\n",
       "                     0.85005819, 0.85229612, 0.85462358, 0.85489213, 0.85704055,\n",
       "                     0.85838331, 0.86643989, 0.86912541, 0.86984155, 0.87118432,\n",
       "                     0.87172142, 0.87888282, 0.88040462, 0.88371677, 0.88461194,\n",
       "                     0.88667084, 0.89007251, 0.8941008 , 0.89982992, 0.90108316,\n",
       "                     0.90403724, 0.90555904, 0.91137767, 0.91298899, 0.91424223,\n",
       "                     0.91603258, 0.91719631, 0.91907618, 0.92426819, 0.92829648,\n",
       "                     0.93142959, 0.93384657, 0.93626354, 0.93805389, 0.9391281 ,\n",
       "                     0.94646853, 0.94727419, 0.94772178, 0.95354042, 0.95586787,\n",
       "                     0.95667353, 0.95765822, 0.96088085, 0.96159699, 0.96311879,\n",
       "                     0.96347686, 0.96356638, 0.96464059, 0.96759466, 0.96813177,\n",
       "                     0.96813177, 0.9683108 , 0.96992212, 0.97162295, 0.97332378,\n",
       "                     0.97430848, 0.97735207, 0.97744159, 0.97788918, 0.97896339,\n",
       "                     0.9820965 , 0.98281264, 0.98370781, 0.98424492, 0.98451347,\n",
       "                     0.98487154, 0.98558768, 0.98576672, 0.98594575, 1.        ]), tpr=array([0.        , 0.08172948, 0.0838779 , 0.0859368 , 0.08790619,\n",
       "                     0.09336675, 0.09479903, 0.09605228, 0.09802166, 0.09990153,\n",
       "                     0.10634679, 0.11619372, 0.12066959, 0.12210187, 0.12344463,\n",
       "                     0.13535046, 0.1396473 , 0.14877809, 0.15880405, 0.16354847,\n",
       "                     0.16551786, 0.16739773, 0.17008325, 0.17912452, 0.18342136,\n",
       "                     0.18422702, 0.18780772, 0.18986662, 0.20213052, 0.20571122,\n",
       "                     0.20830722, 0.21475248, 0.2291648 , 0.23041805, 0.23256647,\n",
       "                     0.26112255, 0.26488228, 0.26891057, 0.27222272, 0.27607197,\n",
       "                     0.28072688, 0.29388595, 0.31044669, 0.31671292, 0.32083072,\n",
       "                     0.32467997, 0.32772357, 0.33631725, 0.34992391, 0.35251992,\n",
       "                     0.36147167, 0.3646943 , 0.37454122, 0.38358249, 0.38966968,\n",
       "                     0.39772626, 0.39987468, 0.40757318, 0.40990064, 0.42431295,\n",
       "                     0.42717751, 0.42798317, 0.43621878, 0.45707636, 0.46047802,\n",
       "                     0.46486438, 0.46665473, 0.47220482, 0.47659117, 0.47865008,\n",
       "                     0.4915406 , 0.49789634, 0.51007072, 0.51472563, 0.52591532,\n",
       "                     0.53083878, 0.53522514, 0.53889535, 0.54193895, 0.54596724,\n",
       "                     0.55769403, 0.56154328, 0.56333363, 0.56413929, 0.56655626,\n",
       "                     0.57103214, 0.57613463, 0.58472831, 0.58741384, 0.58804046,\n",
       "                     0.59036792, 0.59144213, 0.59412765, 0.60585444, 0.60657058,\n",
       "                     0.60827142, 0.61095694, 0.61713365, 0.62143049, 0.62429505,\n",
       "                     0.62635395, 0.62724913, 0.63181452, 0.63369439, 0.63432101,\n",
       "                     0.64542118, 0.64676394, 0.64882284, 0.65240354, 0.65535762,\n",
       "                     0.65768508, 0.66251902, 0.66780056, 0.66914332, 0.6756781 ,\n",
       "                     0.67711038, 0.68006445, 0.68436129, 0.68668875, 0.68973234,\n",
       "                     0.69098559, 0.69662519, 0.69805747, 0.70029541, 0.70351804,\n",
       "                     0.70441321, 0.70530839, 0.7063826 , 0.70871005, 0.71041089,\n",
       "                     0.71291738, 0.72795632, 0.73037329, 0.7319846 , 0.73413302,\n",
       "                     0.73511772, 0.73592337, 0.73672903, 0.73959359, 0.74156298,\n",
       "                     0.74281622, 0.74773968, 0.74881389, 0.7514099 , 0.75337929,\n",
       "                     0.75427446, 0.75695999, 0.75937696, 0.76054069, 0.76582222,\n",
       "                     0.76689643, 0.77101423, 0.77477397, 0.77656432, 0.77880226,\n",
       "                     0.77933936, 0.78148778, 0.78300958, 0.78399427, 0.79205085,\n",
       "                     0.79249843, 0.7938412 , 0.79706383, 0.79769045, 0.79912273,\n",
       "                     0.80109211, 0.80395667, 0.80798496, 0.80968579, 0.81076   ,\n",
       "                     0.81120759, 0.81845851, 0.82006982, 0.82069645, 0.82203921,\n",
       "                     0.82239728, 0.82391908, 0.82875302, 0.83161758, 0.83412407,\n",
       "                     0.83546683, 0.83591442, 0.83689911, 0.83895802, 0.84522424,\n",
       "                     0.84737266, 0.84898398, 0.85086384, 0.85310178, 0.85560827,\n",
       "                     0.86124787, 0.86357533, 0.86966252, 0.87279563, 0.87897234,\n",
       "                     0.87995703, 0.88201593, 0.88461194, 0.8854176 , 0.88738698,\n",
       "                     0.88890878, 0.8982186 , 0.90188882, 0.90224689, 0.90350013,\n",
       "                     0.90403724, 0.90967684, 0.91066153, 0.91388416, 0.91477934,\n",
       "                     0.91800197, 0.92041894, 0.92399964, 0.92784889, 0.92910214,\n",
       "                     0.9325038 , 0.9334885 , 0.93841196, 0.94145555, 0.94252976,\n",
       "                     0.94387253, 0.94530481, 0.94745323, 0.95309283, 0.95747919,\n",
       "                     0.95900098, 0.96025423, 0.96132844, 0.96258168, 0.96374541,\n",
       "                     0.97242861, 0.97305523, 0.9734133 , 0.97744159, 0.97923194,\n",
       "                     0.97994808, 0.98093277, 0.9841554 , 0.98469251, 0.98549816,\n",
       "                     0.98558768, 0.98576672, 0.98666189, 0.98854176, 0.98907886,\n",
       "                     0.98943693, 0.989795  , 0.99060066, 0.99230149, 0.99382329,\n",
       "                     0.99444991, 0.99615075, 0.99632978, 0.99650882, 0.99704592,\n",
       "                     0.99820965, 0.99892579, 0.99910482, 0.99919434, 0.99928386,\n",
       "                     0.99946289, 0.99973145, 0.99982096, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.08219945e-02, -4.25596144e-02,\n",
       "                     -4.44517626e-02, -4.80092192e-02, -6.06246218e-02, -6.89928715e-02,\n",
       "                     -8.70113770e-02, -9.09717782e-02, -1.05360516e-01, -1.11703990e-01,\n",
       "                     -1.13328685e-01, -1.17783036e-01, -1.25163143e-01, -1.33531393e-01,\n",
       "                     -1.36132174e-01, -1.54150680e-01, -1.56698452e-01, -1.56842471e-01,\n",
       "                     -1.67054085e-01, -1.74353387e-01, -1.82321557e-01, -1.88900528e-01,\n",
       "                     -1.89242000e-01, -2.00670695e-01, -2.23143551e-01, -2.31801614e-01,\n",
       "                     -2.33310669e-01, -2.42946179e-01, -2.43622083e-01, -2.45122458e-01,\n",
       "                     -2.46471804e-01, -2.51314428e-01, -2.55933374e-01, -2.65494157e-01,\n",
       "                     -2.69663567e-01, -2.70874954e-01, -2.80902385e-01, -2.81851152e-01,\n",
       "                     -2.82862786e-01, -2.87682072e-01, -2.93072921e-01, -2.94799540e-01,\n",
       "                     -2.98492989e-01, -2.99242895e-01, -3.02280872e-01, -3.03186259e-01,\n",
       "                     -3.08838272e-01, -3.21583624e-01, -3.22083499e-01, -3.28504067e-01,\n",
       "                     -3.29957556e-01, -3.33639374e-01, -3.34369186e-01, -3.36472237e-01,\n",
       "                     -3.48306694e-01, -3.49673748e-01, -3.52821375e-01, -3.56674944e-01,\n",
       "                     -3.62905494e-01, -3.67724780e-01, -3.68560551e-01, -3.69044477e-01,\n",
       "                     -3.69747026e-01, -3.70859579e-01, -3.71563556e-01, -3.83725121e-01,\n",
       "                     -3.84845821e-01, -3.90866309e-01, -3.91478866e-01, -4.00759217e-01,\n",
       "                     -4.05465108e-01, -4.05465108e-01, -4.08128226e-01, -4.11507423e-01,\n",
       "                     -4.12244795e-01, -4.13562318e-01, -4.24883194e-01, -4.27444015e-01,\n",
       "                     -4.28107585e-01, -4.28454626e-01, -4.38254931e-01, -4.41832752e-01,\n",
       "                     -4.41832752e-01, -4.44685821e-01, -4.45585102e-01, -4.46287103e-01,\n",
       "                     -4.48950220e-01, -4.51985124e-01, -4.55475529e-01, -4.59532329e-01,\n",
       "                     -4.70003629e-01, -4.81388951e-01, -4.85507816e-01, -4.89548225e-01,\n",
       "                     -4.90622916e-01, -5.02091944e-01, -5.10825624e-01, -5.23248144e-01,\n",
       "                     -5.28067430e-01, -5.30628251e-01, -5.34082486e-01, -5.38996501e-01,\n",
       "                     -5.38996501e-01, -5.45694449e-01, -5.50046337e-01, -5.53385238e-01,\n",
       "                     -5.59615788e-01, -5.63935449e-01, -5.70544858e-01, -5.75364145e-01,\n",
       "                     -5.76422906e-01, -5.87786665e-01, -5.92342481e-01, -5.94707108e-01,\n",
       "                     -5.97837001e-01, -6.06135804e-01, -6.13104473e-01, -6.16774202e-01,\n",
       "                     -6.19039208e-01, -6.27549898e-01, -6.28608659e-01, -6.31271777e-01,\n",
       "                     -6.35988767e-01, -6.41853886e-01, -6.41853886e-01, -6.50587566e-01,\n",
       "                     -6.53926467e-01, -6.66478933e-01, -6.75128675e-01, -6.93147181e-01,\n",
       "                     -7.11496319e-01, -7.20546155e-01, -7.33969175e-01, -7.37598943e-01,\n",
       "                     -7.47214402e-01, -7.47214402e-01, -7.53771802e-01, -7.59105148e-01,\n",
       "                     -7.62140052e-01, -7.63351439e-01, -7.73189888e-01, -7.75838896e-01,\n",
       "                     -7.80158558e-01, -7.88457360e-01, -7.88457360e-01, -7.98507696e-01,\n",
       "                     -8.02346473e-01, -8.05264479e-01, -8.10930216e-01, -8.25318954e-01,\n",
       "                     -8.26678573e-01, -8.32909123e-01, -8.41567186e-01, -8.47297860e-01,\n",
       "                     -8.47297860e-01, -8.55666110e-01, -8.60201265e-01, -8.66166345e-01,\n",
       "                     -8.75468737e-01, -8.75468737e-01, -8.82389180e-01, -8.87303195e-01,\n",
       "                     -8.90972924e-01, -8.97941593e-01, -9.16290732e-01, -9.29535959e-01,\n",
       "                     -9.47381319e-01, -9.49080555e-01, -9.55511445e-01, -9.62137120e-01,\n",
       "                     -9.80829253e-01, -9.98528830e-01, -1.00552187e+00, -1.01160091e+00,\n",
       "                     -1.01693426e+00, -1.02165125e+00, -1.02290047e+00, -1.02450432e+00,\n",
       "                     -1.02961942e+00, -1.02961942e+00, -1.03609193e+00, -1.05416053e+00,\n",
       "                     -1.05480967e+00, -1.05605267e+00, -1.06087196e+00, -1.08261195e+00,\n",
       "                     -1.08518927e+00, -1.08663610e+00, -1.09330724e+00, -1.09861229e+00,\n",
       "                     -1.09861229e+00, -1.10809103e+00, -1.12718566e+00, -1.12846525e+00,\n",
       "                     -1.14117190e+00, -1.14356368e+00, -1.17007125e+00, -1.17163742e+00,\n",
       "                     -1.17411984e+00, -1.17569203e+00, -1.17677706e+00, -1.17865500e+00,\n",
       "                     -1.18958407e+00, -1.20397280e+00, -1.20397280e+00, -1.21302264e+00,\n",
       "                     -1.22050211e+00, -1.22377543e+00, -1.25276297e+00, -1.25804003e+00,\n",
       "                     -1.25988044e+00, -1.26923781e+00, -1.27296568e+00, -1.28966753e+00,\n",
       "                     -1.29098418e+00, -1.32538561e+00, -1.34117393e+00, -1.34373475e+00,\n",
       "                     -1.35239281e+00, -1.35454566e+00, -1.36524095e+00, -1.37029402e+00,\n",
       "                     -1.38629436e+00, -1.40089316e+00, -1.40399394e+00, -1.40691365e+00,\n",
       "                     -1.43848011e+00, -1.44238383e+00, -1.45597428e+00, -1.48807706e+00,\n",
       "                     -1.50407740e+00, -1.52121368e+00, -1.52605630e+00, -1.53147637e+00,\n",
       "                     -1.53393036e+00, -1.56977266e+00, -1.57553636e+00, -1.60943791e+00,\n",
       "                     -1.60943791e+00, -1.70474809e+00, -1.75785792e+00, -1.75949861e+00,\n",
       "                     -1.79175947e+00, -1.83258146e+00, -1.87180218e+00, -1.92990981e+00,\n",
       "                     -1.93075834e+00, -1.94591015e+00, -2.06142304e+00, -2.07944154e+00,\n",
       "                     -2.14006616e+00, -2.19722458e+00, -2.23359222e+00, -2.24723500e+00,\n",
       "                     -2.30258509e+00, -2.44234704e+00, -2.48490665e+00, -2.48490665e+00,\n",
       "                     -2.83321334e+00, -3.06027079e+00, -3.13549422e+00, -3.21887582e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5288299000087674, privacy_risk=0.5213051651597888, accuracy=0.5213051651597888, tpr_ind=0.5459672365947543, tnr_ind=0.4966430937248232, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.05469519, 0.06015576, 0.06722764, 0.06946558,\n",
       "                     0.07197207, 0.0736729 , 0.07438904, 0.08280369, 0.08826426,\n",
       "                     0.0915764 , 0.09381434, 0.09462   , 0.09837973, 0.117626  ,\n",
       "                     0.11887924, 0.12075911, 0.12362367, 0.12675678, 0.1375884 ,\n",
       "                     0.13973682, 0.14286993, 0.16292185, 0.16560738, 0.1733954 ,\n",
       "                     0.1754543 , 0.17581237, 0.19344732, 0.19872885, 0.21573718,\n",
       "                     0.21806463, 0.21976546, 0.22737445, 0.23131322, 0.23310357,\n",
       "                     0.2414287 , 0.24805299, 0.25602005, 0.27911557, 0.28072688,\n",
       "                     0.28448662, 0.28788828, 0.29173753, 0.3243219 , 0.33014054,\n",
       "                     0.33210993, 0.34705935, 0.34956584, 0.35484737, 0.35887566,\n",
       "                     0.36102408, 0.37212425, 0.37266136, 0.37516785, 0.37713723,\n",
       "                     0.37910662, 0.38161311, 0.38680512, 0.41464506, 0.41562976,\n",
       "                     0.42341778, 0.42476054, 0.43048966, 0.43245905, 0.43505505,\n",
       "                     0.45251097, 0.45868767, 0.46056754, 0.46379017, 0.4705935 ,\n",
       "                     0.47972429, 0.48232029, 0.48402113, 0.48670665, 0.48939218,\n",
       "                     0.50980217, 0.53021216, 0.53200251, 0.53289768, 0.5335243 ,\n",
       "                     0.53773163, 0.53952198, 0.54981649, 0.55393429, 0.57121117,\n",
       "                     0.58132665, 0.58284845, 0.58732432, 0.59215827, 0.595918  ,\n",
       "                     0.59851401, 0.60791335, 0.61802882, 0.61838689, 0.61919255,\n",
       "                     0.63047176, 0.63163548, 0.6347686 , 0.63691702, 0.63799123,\n",
       "                     0.63906544, 0.64193   , 0.64372035, 0.64953898, 0.65294065,\n",
       "                     0.65517859, 0.65670038, 0.65723749, 0.66090771, 0.66627876,\n",
       "                     0.66968042, 0.67514099, 0.68104915, 0.69089607, 0.69447677,\n",
       "                     0.69940023, 0.70503984, 0.71130606, 0.71479724, 0.71524483,\n",
       "                     0.71649808, 0.71900457, 0.72258527, 0.72670307, 0.72813535,\n",
       "                     0.73073136, 0.73180557, 0.73305881, 0.73493868, 0.73681855,\n",
       "                     0.73851938, 0.73887745, 0.74550175, 0.74585982, 0.74594933,\n",
       "                     0.75382687, 0.76403187, 0.76653836, 0.76788112, 0.77011906,\n",
       "                     0.77181989, 0.772357  , 0.77701191, 0.79035001, 0.79160326,\n",
       "                     0.79581058, 0.79715334, 0.7994808 , 0.8000179 , 0.80118163,\n",
       "                     0.80234536, 0.81460926, 0.82535136, 0.82615701, 0.82893206,\n",
       "                     0.83054337, 0.83278131, 0.83654104, 0.84173306, 0.84406051,\n",
       "                     0.84513472, 0.85005819, 0.85793573, 0.85999463, 0.86080029,\n",
       "                     0.86456002, 0.86500761, 0.8690359 , 0.87019962, 0.87986751,\n",
       "                     0.88174738, 0.88300063, 0.88398532, 0.8854176 , 0.88774505,\n",
       "                     0.88872975, 0.89302659, 0.89365321, 0.89535404, 0.89786053,\n",
       "                     0.89866619, 0.90645421, 0.9074389 , 0.90994539, 0.92373109,\n",
       "                     0.92507385, 0.92623758, 0.92793841, 0.92820696, 0.93617402,\n",
       "                     0.93939665, 0.94100797, 0.94378301, 0.9447677 , 0.94619998,\n",
       "                     0.94852744, 0.94888551, 0.94978068, 0.95515173, 0.95542028,\n",
       "                     0.9570316 , 0.96034375, 0.96123892, 0.96177603, 0.96464059,\n",
       "                     0.96517769, 0.97198102, 0.97233909, 0.97359234, 0.97377137,\n",
       "                     0.97726255, 0.97878435, 0.97941097, 0.97959001, 0.97959001,\n",
       "                     0.98299167, 0.98388685, 0.9841554 , 0.9841554 , 0.98505058,\n",
       "                     0.98612479, 0.98648286, 0.98648286, 0.98701996, 0.98701996,\n",
       "                     0.98710948, 0.987199  , 0.98737803, 1.        ]), tpr=array([0.        , 0.06400501, 0.07045027, 0.0782383 , 0.08038672,\n",
       "                     0.08244562, 0.08468356, 0.08575777, 0.09426193, 0.10052815,\n",
       "                     0.10563065, 0.10804762, 0.1094799 , 0.11431385, 0.13633515,\n",
       "                     0.1375884 , 0.13937875, 0.14224331, 0.14600304, 0.15826694,\n",
       "                     0.16014681, 0.16381703, 0.18753916, 0.18968758, 0.19908692,\n",
       "                     0.20159341, 0.20239907, 0.21958643, 0.22433086, 0.24008594,\n",
       "                     0.24178677, 0.24339808, 0.24975383, 0.25476681, 0.25691523,\n",
       "                     0.26640408, 0.27329693, 0.28108495, 0.30265867, 0.30444902,\n",
       "                     0.30749261, 0.31125235, 0.31519112, 0.35529496, 0.36129263,\n",
       "                     0.36344105, 0.37892758, 0.38125504, 0.38564139, 0.3897592 ,\n",
       "                     0.39226569, 0.40220213, 0.40399248, 0.40685704, 0.40927401,\n",
       "                     0.41079581, 0.41294423, 0.41813625, 0.44445439, 0.44606571,\n",
       "                     0.45304807, 0.45483842, 0.46217886, 0.46352162, 0.46674425,\n",
       "                     0.48509534, 0.4920777 , 0.49431564, 0.49897055, 0.50693761,\n",
       "                     0.51579984, 0.5186644 , 0.52152896, 0.52484111, 0.52797422,\n",
       "                     0.54614627, 0.56548205, 0.56763047, 0.56924179, 0.57049503,\n",
       "                     0.57541849, 0.5774774 , 0.58598156, 0.58929371, 0.60683914,\n",
       "                     0.61641751, 0.6174022 , 0.62071435, 0.62510071, 0.62751768,\n",
       "                     0.63145645, 0.6439889 , 0.65428341, 0.65491003, 0.65553666,\n",
       "                     0.66484648, 0.6669949 , 0.66959091, 0.67191836, 0.67308209,\n",
       "                     0.67433533, 0.67791603, 0.6797959 , 0.6848984 , 0.68794199,\n",
       "                     0.68982186, 0.69116462, 0.69188076, 0.69662519, 0.70342852,\n",
       "                     0.70674067, 0.71211172, 0.71685615, 0.72598693, 0.73055232,\n",
       "                     0.73565482, 0.73878793, 0.74514368, 0.74944052, 0.75006714,\n",
       "                     0.75123087, 0.75284218, 0.75543819, 0.75964551, 0.76116731,\n",
       "                     0.76403187, 0.76501656, 0.76591174, 0.76770209, 0.76967147,\n",
       "                     0.77074568, 0.77128279, 0.77817563, 0.77862322, 0.77907081,\n",
       "                     0.78632173, 0.79491541, 0.79760093, 0.79921225, 0.80207681,\n",
       "                     0.80422523, 0.80485185, 0.81084952, 0.82177066, 0.82382956,\n",
       "                     0.82911109, 0.83036434, 0.83331841, 0.83403455, 0.83492973,\n",
       "                     0.83609346, 0.84638797, 0.85596634, 0.85757766, 0.85927849,\n",
       "                     0.86071077, 0.86214305, 0.86652941, 0.87046818, 0.87270611,\n",
       "                     0.87378032, 0.87709247, 0.88577567, 0.88729747, 0.88792409,\n",
       "                     0.89123624, 0.89204189, 0.89517501, 0.89589115, 0.90752842,\n",
       "                     0.90976636, 0.91066153, 0.91128816, 0.91227285, 0.91343658,\n",
       "                     0.91415272, 0.91809149, 0.91907618, 0.92068749, 0.92238833,\n",
       "                     0.9232835 , 0.92919166, 0.92999731, 0.93223525, 0.94691612,\n",
       "                     0.9483484 , 0.94969116, 0.95076537, 0.951392  , 0.95891147,\n",
       "                     0.96150747, 0.96365589, 0.96660997, 0.96723659, 0.96866887,\n",
       "                     0.97045922, 0.97090681, 0.9713544 , 0.97520365, 0.97529317,\n",
       "                     0.9764569 , 0.9805747 , 0.98075374, 0.98129084, 0.98326023,\n",
       "                     0.98370781, 0.98836272, 0.98845224, 0.98916838, 0.98952645,\n",
       "                     0.99176439, 0.99239101, 0.9928386 , 0.99310715, 0.99328619,\n",
       "                     0.99624026, 0.99686689, 0.99704592, 0.99731447, 0.99785158,\n",
       "                     0.9984782 , 0.99919434, 0.99928386, 0.99946289, 0.99955241,\n",
       "                     0.99964193, 0.99991048, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.37933221e-02, -3.39015517e-02,\n",
       "                     -4.08219945e-02, -4.25596144e-02, -7.69610411e-02, -8.00427077e-02,\n",
       "                     -8.08520966e-02, -9.53101798e-02, -1.00083459e-01, -1.05360516e-01,\n",
       "                     -1.17783036e-01, -1.21889818e-01, -1.25880246e-01, -1.33531393e-01,\n",
       "                     -1.39761942e-01, -1.45182010e-01, -1.54150680e-01, -1.67615409e-01,\n",
       "                     -1.74353387e-01, -1.78248231e-01, -1.82321557e-01, -1.89242000e-01,\n",
       "                     -1.90226736e-01, -1.94156014e-01, -2.00670695e-01, -2.14775302e-01,\n",
       "                     -2.19362828e-01, -2.23143551e-01, -2.33614851e-01, -2.45122458e-01,\n",
       "                     -2.48179629e-01, -2.51314428e-01, -2.55933374e-01, -2.71034839e-01,\n",
       "                     -2.71315095e-01, -2.87682072e-01, -2.99028249e-01, -3.00104592e-01,\n",
       "                     -3.02280872e-01, -3.05381650e-01, -3.10154928e-01, -3.11939050e-01,\n",
       "                     -3.17095958e-01, -3.18453731e-01, -3.23171957e-01, -3.25422400e-01,\n",
       "                     -3.27687407e-01, -3.30241687e-01, -3.31357136e-01, -3.33894916e-01,\n",
       "                     -3.36472237e-01, -3.40926587e-01, -3.41749294e-01, -3.44840486e-01,\n",
       "                     -3.48306694e-01, -3.58397597e-01, -3.66153688e-01, -3.67724780e-01,\n",
       "                     -3.70678992e-01, -3.71563556e-01, -3.72404246e-01, -3.82992252e-01,\n",
       "                     -3.86772975e-01, -3.87417038e-01, -3.88223302e-01, -3.92042088e-01,\n",
       "                     -3.92561703e-01, -4.01712758e-01, -4.02092424e-01, -4.05465108e-01,\n",
       "                     -4.05465108e-01, -4.14433778e-01, -4.14943852e-01, -4.23366318e-01,\n",
       "                     -4.26839968e-01, -4.32864082e-01, -4.41832752e-01, -4.51985124e-01,\n",
       "                     -4.70003629e-01, -4.75423697e-01, -4.83075711e-01, -4.83426650e-01,\n",
       "                     -4.83936724e-01, -4.86226465e-01, -4.92476485e-01, -4.99955952e-01,\n",
       "                     -5.02628857e-01, -5.10825624e-01, -5.19875459e-01, -5.22189382e-01,\n",
       "                     -5.33182531e-01, -5.38996501e-01, -5.38996501e-01, -5.54106132e-01,\n",
       "                     -5.59615788e-01, -5.64529803e-01, -5.70544858e-01, -5.70544858e-01,\n",
       "                     -5.79818495e-01, -5.87786665e-01, -5.93063722e-01, -6.01339631e-01,\n",
       "                     -6.16774202e-01, -6.19039208e-01, -6.24154309e-01, -6.28608659e-01,\n",
       "                     -6.44828603e-01, -6.59699246e-01, -6.65748206e-01, -6.67829373e-01,\n",
       "                     -6.74098986e-01, -6.93147181e-01, -7.12565266e-01, -7.19122667e-01,\n",
       "                     -7.21318058e-01, -7.27752710e-01, -7.43919506e-01, -7.62140052e-01,\n",
       "                     -7.67255153e-01, -7.73189888e-01, -7.75838896e-01, -7.94243297e-01,\n",
       "                     -8.04372816e-01, -8.10930216e-01, -8.20980552e-01, -8.32909123e-01,\n",
       "                     -8.32909123e-01, -8.40783179e-01, -8.47297860e-01, -8.47297860e-01,\n",
       "                     -8.54691609e-01, -8.75468737e-01, -8.75468737e-01, -8.83665505e-01,\n",
       "                     -8.99483614e-01, -9.02867712e-01, -9.16290732e-01, -9.28713252e-01,\n",
       "                     -9.32820034e-01, -9.44461609e-01, -9.54362680e-01, -9.58030338e-01,\n",
       "                     -9.58850346e-01, -9.59415159e-01, -9.71860583e-01, -9.80829253e-01,\n",
       "                     -1.01160091e+00, -1.02961942e+00, -1.04596856e+00, -1.05718625e+00,\n",
       "                     -1.06374346e+00, -1.07992016e+00, -1.08091271e+00, -1.09861229e+00,\n",
       "                     -1.09861229e+00, -1.10539198e+00, -1.10615949e+00, -1.12492960e+00,\n",
       "                     -1.12601126e+00, -1.13401422e+00, -1.13571604e+00, -1.13707857e+00,\n",
       "                     -1.14513230e+00, -1.16820558e+00, -1.17007125e+00, -1.17203976e+00,\n",
       "                     -1.17865500e+00, -1.18219900e+00, -1.19996478e+00, -1.22377543e+00,\n",
       "                     -1.23214368e+00, -1.23969089e+00, -1.24171313e+00, -1.25276297e+00,\n",
       "                     -1.25923548e+00, -1.26566637e+00, -1.26851133e+00, -1.27506873e+00,\n",
       "                     -1.28093385e+00, -1.28680881e+00, -1.29928298e+00, -1.30291275e+00,\n",
       "                     -1.31686585e+00, -1.32175584e+00, -1.33500107e+00, -1.34373475e+00,\n",
       "                     -1.34992672e+00, -1.35300838e+00, -1.38629436e+00, -1.43706669e+00,\n",
       "                     -1.43796637e+00, -1.48807706e+00, -1.50407740e+00, -1.51512723e+00,\n",
       "                     -1.52605630e+00, -1.56861592e+00, -1.60943791e+00, -1.60943791e+00,\n",
       "                     -1.62470538e+00, -1.64362928e+00, -1.70474809e+00, -1.73460106e+00,\n",
       "                     -1.75314463e+00, -1.75785792e+00, -1.79175947e+00, -1.79175947e+00,\n",
       "                     -1.81237876e+00, -1.83258146e+00, -1.86872051e+00, -1.94591015e+00,\n",
       "                     -2.00148000e+00, -2.03688193e+00, -2.07944154e+00, -2.13470422e+00,\n",
       "                     -2.16496372e+00, -2.19722458e+00, -2.30258509e+00, -2.35137526e+00,\n",
       "                     -2.39789527e+00, -2.55528745e+00, -2.56494936e+00, -2.60268969e+00,\n",
       "                     -3.17805383e+00, -3.21887582e+00, -3.40119738e+00, -4.29045944e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5269621447229618, privacy_risk=0.5192910213946826, accuracy=0.5192910213946826, tpr_ind=0.5279742189598067, tnr_ind=0.5106078238295587, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.07412049, 0.07734312, 0.08011816, 0.08611584,\n",
       "                     0.08987557, 0.09220303, 0.09327724, 0.0951571 , 0.10061767,\n",
       "                     0.10115478, 0.10160236, 0.10679438, 0.1089428 , 0.10992749,\n",
       "                     0.11825262, 0.12129621, 0.12237042, 0.12451884, 0.12666726,\n",
       "                     0.12872617, 0.13642467, 0.13714081, 0.14152717, 0.14537642,\n",
       "                     0.15567093, 0.15764032, 0.16533882, 0.16838242, 0.17097843,\n",
       "                     0.17169457, 0.17590189, 0.18082535, 0.18521171, 0.18780772,\n",
       "                     0.18932951, 0.19120938, 0.1954167 , 0.20481604, 0.20651687,\n",
       "                     0.21421538, 0.21860174, 0.21985498, 0.24572554, 0.25584102,\n",
       "                     0.25879509, 0.26353952, 0.27759377, 0.28538179, 0.28941008,\n",
       "                     0.29164802, 0.29934652, 0.30247963, 0.30695551, 0.31062573,\n",
       "                     0.31161042, 0.32136783, 0.32297914, 0.32754453, 0.33166234,\n",
       "                     0.36156119, 0.36397816, 0.36612658, 0.36997583, 0.37722675,\n",
       "                     0.38761078, 0.39020679, 0.40363441, 0.40435055, 0.41249664,\n",
       "                     0.42297019, 0.42368633, 0.42619282, 0.42744607, 0.43371229,\n",
       "                     0.43550264, 0.44221645, 0.44570764, 0.4577925 , 0.46101513,\n",
       "                     0.47650166, 0.48178319, 0.50174559, 0.50273028, 0.50971265,\n",
       "                     0.53209202, 0.53513562, 0.5524125 , 0.55357622, 0.55661982,\n",
       "                     0.56771999, 0.57103214, 0.57273297, 0.57658222, 0.57702981,\n",
       "                     0.57908871, 0.59063647, 0.59976725, 0.6097037 , 0.6122997 ,\n",
       "                     0.6132844 , 0.61364247, 0.61516426, 0.61543282, 0.61919255,\n",
       "                     0.62160952, 0.63611136, 0.63897592, 0.64237758, 0.64300421,\n",
       "                     0.64461552, 0.65347775, 0.654731  , 0.65732701, 0.65786411,\n",
       "                     0.66323516, 0.66502551, 0.66645779, 0.6746934 , 0.67603617,\n",
       "                     0.67899024, 0.68194432, 0.69814699, 0.700743  , 0.70235431,\n",
       "                     0.70351804, 0.71300689, 0.71363352, 0.71533435, 0.71927312,\n",
       "                     0.71963119, 0.72088443, 0.72231671, 0.72974667, 0.73162653,\n",
       "                     0.73314833, 0.73377495, 0.73520723, 0.73574434, 0.74684451,\n",
       "                     0.7478292 , 0.74979859, 0.75024617, 0.7508728 , 0.75149942,\n",
       "                     0.75248411, 0.75284218, 0.75955599, 0.76492704, 0.77226748,\n",
       "                     0.77271507, 0.77325217, 0.77522156, 0.77638528, 0.77817563,\n",
       "                     0.78614269, 0.7887387 , 0.79124519, 0.80028646, 0.8015397 ,\n",
       "                     0.81550443, 0.81917465, 0.82033838, 0.82839495, 0.83081192,\n",
       "                     0.83967416, 0.84137499, 0.84611942, 0.85104288, 0.85211709,\n",
       "                     0.85265419, 0.85399696, 0.85542924, 0.85596634, 0.85695103,\n",
       "                     0.86303822, 0.86697699, 0.86831976, 0.87395936, 0.87440695,\n",
       "                     0.879778  , 0.88255304, 0.88398532, 0.8854176 , 0.88622326,\n",
       "                     0.89991943, 0.90144123, 0.90269448, 0.9038582 , 0.90645421,\n",
       "                     0.90681228, 0.90878167, 0.91066153, 0.91236237, 0.91513741,\n",
       "                     0.91683824, 0.91800197, 0.92006087, 0.92758034, 0.92847552,\n",
       "                     0.92919166, 0.93268284, 0.9396652 , 0.94002327, 0.94082893,\n",
       "                     0.94306687, 0.94799033, 0.94861695, 0.95282428, 0.95416704,\n",
       "                     0.95425656, 0.95533077, 0.95622594, 0.95685256, 0.95783726,\n",
       "                     0.95792677, 0.95873243, 0.95873243, 0.96025423, 0.96123892,\n",
       "                     0.96249217, 0.96311879, 0.96822129, 0.9683108 , 0.9698326 ,\n",
       "                     0.97063826, 0.97117536, 0.97233909, 0.97278668, 0.97314475,\n",
       "                     0.9734133 , 0.97439799, 0.97511413, 0.97663593, 0.97726255,\n",
       "                     0.97762062, 0.97896339, 0.97914242, 0.97923194, 0.98066422,\n",
       "                     0.98075374, 0.98102229, 0.98120132, 0.98138036, 0.98218602,\n",
       "                     0.98227553, 0.9826336 , 1.        ]), tpr=array([0.        , 0.081819  , 0.08638439, 0.0895175 , 0.09542566,\n",
       "                     0.10043864, 0.10249754, 0.10446692, 0.10607824, 0.11127025,\n",
       "                     0.1125235 , 0.11368723, 0.12031152, 0.12245994, 0.12344463,\n",
       "                     0.13230687, 0.13445529, 0.13696178, 0.13875213, 0.14161669,\n",
       "                     0.14331752, 0.15083699, 0.1519112 , 0.15683466, 0.16140005,\n",
       "                     0.17438009, 0.17643899, 0.18297377, 0.18539074, 0.18852386,\n",
       "                     0.18968758, 0.19344732, 0.19917644, 0.20222003, 0.20490556,\n",
       "                     0.20723301, 0.20821771, 0.21242503, 0.2240623 , 0.22656879,\n",
       "                     0.23534151, 0.23954883, 0.24133918, 0.26595649, 0.27902605,\n",
       "                     0.28180109, 0.2859189 , 0.30337481, 0.30964103, 0.31349029,\n",
       "                     0.31599678, 0.3243219 , 0.32772357, 0.33184137, 0.33712291,\n",
       "                     0.33855519, 0.34661176, 0.34849163, 0.35278847, 0.35636917,\n",
       "                     0.38644705, 0.38841644, 0.39146003, 0.39530928, 0.40273924,\n",
       "                     0.41285471, 0.41410796, 0.427088  , 0.42852028, 0.43738251,\n",
       "                     0.44812461, 0.4491093 , 0.45125772, 0.45260048, 0.45680781,\n",
       "                     0.4583296 , 0.46316355, 0.4685346 , 0.48106705, 0.48384209,\n",
       "                     0.49941814, 0.50416256, 0.52206606, 0.52305076, 0.52895891,\n",
       "                     0.55330767, 0.55590368, 0.57479187, 0.57792498, 0.58177424,\n",
       "                     0.59403813, 0.59735028, 0.59958822, 0.6030794 , 0.60379554,\n",
       "                     0.60504879, 0.61910303, 0.62635395, 0.63691702, 0.6388864 ,\n",
       "                     0.64005013, 0.64067675, 0.64193   , 0.64291469, 0.64658491,\n",
       "                     0.64792767, 0.6634142 , 0.66583117, 0.66869573, 0.67021753,\n",
       "                     0.6726345 , 0.68203384, 0.68445081, 0.68740489, 0.6884791 ,\n",
       "                     0.6941187 , 0.69581953, 0.69707278, 0.70521887, 0.70629308,\n",
       "                     0.70879957, 0.7114851 , 0.72741921, 0.73001522, 0.73234267,\n",
       "                     0.73332737, 0.74075732, 0.74183153, 0.74326381, 0.74800824,\n",
       "                     0.74890341, 0.75132038, 0.75328977, 0.76080924, 0.76268911,\n",
       "                     0.76385283, 0.76465849, 0.76600125, 0.7677916 , 0.77924984,\n",
       "                     0.78023454, 0.78292006, 0.7836362 , 0.78453138, 0.78497896,\n",
       "                     0.78578462, 0.78712738, 0.79419927, 0.79903321, 0.80834303,\n",
       "                     0.80914869, 0.80959628, 0.8117447 , 0.81308746, 0.81505684,\n",
       "                     0.82230776, 0.8245457 , 0.82633605, 0.83698863, 0.83842091,\n",
       "                     0.85184854, 0.85507117, 0.85560827, 0.86536568, 0.86787217,\n",
       "                     0.87601826, 0.87745054, 0.8838958 , 0.88658133, 0.8889983 ,\n",
       "                     0.88971444, 0.89168382, 0.89231045, 0.89329514, 0.89374273,\n",
       "                     0.89857667, 0.90251544, 0.90314206, 0.90878167, 0.90931877,\n",
       "                     0.91361561, 0.91674872, 0.91836004, 0.91961328, 0.92041894,\n",
       "                     0.93268284, 0.93411512, 0.93581595, 0.93653209, 0.93957569,\n",
       "                     0.94011279, 0.94208218, 0.94360397, 0.94485722, 0.94790081,\n",
       "                     0.94879599, 0.95013875, 0.95228717, 0.95810581, 0.95944857,\n",
       "                     0.96034375, 0.96437203, 0.97180199, 0.97207054, 0.97233909,\n",
       "                     0.97359234, 0.97618834, 0.97690448, 0.98012711, 0.98129084,\n",
       "                     0.98155939, 0.98218602, 0.98290216, 0.98370781, 0.98496106,\n",
       "                     0.98514009, 0.98603527, 0.98630382, 0.98701996, 0.98755707,\n",
       "                     0.98898935, 0.98943693, 0.99194342, 0.99203294, 0.99292812,\n",
       "                     0.99382329, 0.99400233, 0.99525557, 0.99552412, 0.99597171,\n",
       "                     0.99624026, 0.99659833, 0.99686689, 0.99785158, 0.9979411 ,\n",
       "                     0.99812013, 0.99865724, 0.99874675, 0.99883627, 0.99919434,\n",
       "                     0.99928386, 0.99937338, 0.99946289, 0.99964193, 0.99982096,\n",
       "                     0.99991048, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.94180859e-02, -2.81708770e-02,\n",
       "                     -2.98529631e-02, -3.50913198e-02, -4.25596144e-02, -4.44517626e-02,\n",
       "                     -5.40672213e-02, -6.66913745e-02, -6.89928715e-02, -7.41079722e-02,\n",
       "                     -7.79615415e-02, -8.00427077e-02, -8.70113770e-02, -1.05360516e-01,\n",
       "                     -1.17783036e-01, -1.33531393e-01, -1.39761942e-01, -1.45182010e-01,\n",
       "                     -1.46603474e-01, -1.54150680e-01, -1.54150680e-01, -1.67054085e-01,\n",
       "                     -1.79048231e-01, -1.82321557e-01, -1.96710294e-01, -1.98176929e-01,\n",
       "                     -2.00670695e-01, -2.05852054e-01, -2.07639365e-01, -2.13574100e-01,\n",
       "                     -2.23143551e-01, -2.34839591e-01, -2.36388778e-01, -2.38411023e-01,\n",
       "                     -2.41162057e-01, -2.44196961e-01, -2.44453338e-01, -2.51314428e-01,\n",
       "                     -2.59219608e-01, -2.60726262e-01, -2.62364264e-01, -2.63761889e-01,\n",
       "                     -2.68666806e-01, -2.79584862e-01, -2.82232468e-01, -2.87682072e-01,\n",
       "                     -2.94799540e-01, -2.99242895e-01, -3.05381650e-01, -3.11587593e-01,\n",
       "                     -3.13657559e-01, -3.14493330e-01, -3.16911711e-01, -3.18453731e-01,\n",
       "                     -3.20471895e-01, -3.22773392e-01, -3.33491608e-01, -3.36472237e-01,\n",
       "                     -3.41984229e-01, -3.42944751e-01, -3.44840486e-01, -3.49673748e-01,\n",
       "                     -3.51844017e-01, -3.54016546e-01, -3.56674944e-01, -3.60804337e-01,\n",
       "                     -3.62905494e-01, -3.67724780e-01, -3.71563556e-01, -3.74693449e-01,\n",
       "                     -3.77294231e-01, -3.82992252e-01, -3.83958903e-01, -3.85662481e-01,\n",
       "                     -4.05465108e-01, -4.05465108e-01, -4.14943852e-01, -4.16160397e-01,\n",
       "                     -4.20674527e-01, -4.24157241e-01, -4.35023910e-01, -4.35318071e-01,\n",
       "                     -4.35318071e-01, -4.39203248e-01, -4.39366660e-01, -4.47234521e-01,\n",
       "                     -4.51985124e-01, -4.58307589e-01, -4.64514137e-01, -4.66619531e-01,\n",
       "                     -4.70003629e-01, -4.79573080e-01, -4.85507816e-01, -4.96436886e-01,\n",
       "                     -5.08274602e-01, -5.10825624e-01, -5.12519104e-01, -5.19875459e-01,\n",
       "                     -5.26093096e-01, -5.38996501e-01, -5.38996501e-01, -5.46543706e-01,\n",
       "                     -5.49107810e-01, -5.50046337e-01, -5.53818670e-01, -5.54310736e-01,\n",
       "                     -5.59615788e-01, -5.67984038e-01, -5.75364145e-01, -5.87786665e-01,\n",
       "                     -5.95983432e-01, -5.97837001e-01, -6.06135804e-01, -6.10455465e-01,\n",
       "                     -6.10909082e-01, -6.19039208e-01, -6.48195793e-01, -6.50587566e-01,\n",
       "                     -6.56779536e-01, -6.76340062e-01, -6.93147181e-01, -7.10241614e-01,\n",
       "                     -7.30887509e-01, -7.37598943e-01, -7.40214691e-01, -7.73189888e-01,\n",
       "                     -7.82759339e-01, -7.83298278e-01, -7.88457360e-01, -7.98507696e-01,\n",
       "                     -8.00777845e-01, -8.10930216e-01, -8.26678573e-01, -8.36248024e-01,\n",
       "                     -8.47297860e-01, -8.47297860e-01, -8.54415328e-01, -8.55080001e-01,\n",
       "                     -8.60201265e-01, -8.61482495e-01, -8.64997437e-01, -8.75468737e-01,\n",
       "                     -8.75468737e-01, -8.93817876e-01, -9.02867712e-01, -9.13755876e-01,\n",
       "                     -9.16290732e-01, -9.20129508e-01, -9.38269639e-01, -9.55511445e-01,\n",
       "                     -9.65080896e-01, -9.80829253e-01, -9.86494991e-01, -9.90045908e-01,\n",
       "                     -1.00063188e+00, -1.01160091e+00, -1.01996916e+00, -1.03407377e+00,\n",
       "                     -1.03437002e+00, -1.04145387e+00, -1.04145387e+00, -1.04199339e+00,\n",
       "                     -1.06224464e+00, -1.06887032e+00, -1.07755888e+00, -1.07992016e+00,\n",
       "                     -1.09861229e+00, -1.09861229e+00, -1.13943428e+00, -1.14306405e+00,\n",
       "                     -1.14513230e+00, -1.15745279e+00, -1.16315081e+00, -1.17007125e+00,\n",
       "                     -1.17865500e+00, -1.18958407e+00, -1.19440335e+00, -1.20397280e+00,\n",
       "                     -1.21020335e+00, -1.21533656e+00, -1.22050211e+00, -1.23214368e+00,\n",
       "                     -1.23676263e+00, -1.23911446e+00, -1.25276297e+00, -1.26025364e+00,\n",
       "                     -1.28785429e+00, -1.29392104e+00, -1.29928298e+00, -1.30340670e+00,\n",
       "                     -1.30992138e+00, -1.31218639e+00, -1.31782656e+00, -1.33500107e+00,\n",
       "                     -1.35239281e+00, -1.36524095e+00, -1.38629436e+00, -1.40282366e+00,\n",
       "                     -1.41098697e+00, -1.44561094e+00, -1.46169238e+00, -1.46633707e+00,\n",
       "                     -1.46633707e+00, -1.47181653e+00, -1.47689126e+00, -1.50407740e+00,\n",
       "                     -1.52846885e+00, -1.52939520e+00, -1.54044504e+00, -1.55059741e+00,\n",
       "                     -1.55814462e+00, -1.56397554e+00, -1.60943791e+00, -1.60943791e+00,\n",
       "                     -1.64865863e+00, -1.67397643e+00, -1.68175857e+00, -1.70474809e+00,\n",
       "                     -1.71604765e+00, -1.72276660e+00, -1.79175947e+00, -1.79175947e+00,\n",
       "                     -1.80828877e+00, -1.87180218e+00, -1.94591015e+00, -1.94591015e+00,\n",
       "                     -1.99243016e+00, -2.00148000e+00, -2.03688193e+00, -2.07944154e+00,\n",
       "                     -2.19722458e+00, -2.30258509e+00, -2.48490665e+00, -2.56494936e+00,\n",
       "                     -2.59026717e+00, -2.63905733e+00, -2.70805020e+00, -2.74084002e+00,\n",
       "                     -2.94443898e+00, -3.13549422e+00, -3.17805383e+00, -3.36729583e+00,\n",
       "                     -3.52636052e+00, -3.58351894e+00, -3.95124372e+00, -3.45387764e+01]), auc_score=0.523760714103324, privacy_risk=0.5188881926416614, accuracy=0.5188881926416614, tpr_ind=0.8838958016292185, tnr_ind=0.15388058365410437, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.05899203, 0.07206159, 0.07662698, 0.08137141,\n",
       "                     0.08396742, 0.08656342, 0.08835377, 0.09077075, 0.0925611 ,\n",
       "                     0.09354579, 0.10133381, 0.10446692, 0.11010653, 0.11323964,\n",
       "                     0.11520902, 0.117626  , 0.12675678, 0.12720437, 0.13015845,\n",
       "                     0.13185928, 0.13561901, 0.14224331, 0.14403366, 0.14600304,\n",
       "                     0.15352251, 0.15441769, 0.15943067, 0.16104198, 0.17831886,\n",
       "                     0.18064632, 0.18288425, 0.19237311, 0.19496912, 0.20678543,\n",
       "                     0.21099275, 0.21537911, 0.21725897, 0.22173485, 0.22307761,\n",
       "                     0.22459941, 0.23023901, 0.25324501, 0.25405067, 0.25816847,\n",
       "                     0.26264435, 0.26506132, 0.26729926, 0.27267031, 0.27589294,\n",
       "                     0.28171157, 0.28385999, 0.29272223, 0.29531823, 0.30838779,\n",
       "                     0.31116283, 0.33282607, 0.36084505, 0.36335154, 0.3703339 ,\n",
       "                     0.37292991, 0.37400412, 0.38483574, 0.38662609, 0.38841644,\n",
       "                     0.4020231 , 0.40703608, 0.41043774, 0.41974756, 0.42628234,\n",
       "                     0.42771462, 0.43514457, 0.44839316, 0.45295855, 0.45662877,\n",
       "                     0.47838152, 0.48044043, 0.48616955, 0.48751231, 0.4941366 ,\n",
       "                     0.49449467, 0.49637454, 0.498702  , 0.50040283, 0.50210366,\n",
       "                     0.50273028, 0.51221914, 0.51776922, 0.52305076, 0.52510966,\n",
       "                     0.53728404, 0.53800018, 0.54516158, 0.55339719, 0.58016292,\n",
       "                     0.58150568, 0.58257989, 0.58401217, 0.58607108, 0.59009936,\n",
       "                     0.59905111, 0.60648107, 0.60782383, 0.60961418, 0.61453764,\n",
       "                     0.62715961, 0.62894996, 0.63217259, 0.63342583, 0.63602184,\n",
       "                     0.63897592, 0.64407842, 0.64783815, 0.64873333, 0.66028108,\n",
       "                     0.66377227, 0.66663683, 0.66780056, 0.66985946, 0.67227643,\n",
       "                     0.67997494, 0.70602453, 0.70951571, 0.71085847, 0.71363352,\n",
       "                     0.71461821, 0.71694566, 0.71775132, 0.73010474, 0.73064184,\n",
       "                     0.73189509, 0.73547579, 0.73637096, 0.73887745, 0.73995166,\n",
       "                     0.74183153, 0.74299526, 0.7457703 , 0.74756065, 0.75355832,\n",
       "                     0.75472205, 0.7585713 , 0.75919792, 0.75973503, 0.76438994,\n",
       "                     0.77011906, 0.77208844, 0.77361024, 0.77513204, 0.77575866,\n",
       "                     0.77701191, 0.79214036, 0.79751141, 0.8045833 , 0.80637365,\n",
       "                     0.81210277, 0.81335601, 0.8153254 , 0.8194432 , 0.82588846,\n",
       "                     0.8266046 , 0.82714171, 0.82767881, 0.82955868, 0.82973771,\n",
       "                     0.83054337, 0.83385552, 0.83421359, 0.83842091, 0.8409274 ,\n",
       "                     0.85059529, 0.85229612, 0.85310178, 0.85847283, 0.8618745 ,\n",
       "                     0.86303822, 0.86554471, 0.87019962, 0.87198997, 0.87395936,\n",
       "                     0.88058365, 0.88112076, 0.88219497, 0.88846119, 0.88890878,\n",
       "                     0.89007251, 0.89365321, 0.89571211, 0.90681228, 0.9120043 ,\n",
       "                     0.91370513, 0.91737535, 0.91889714, 0.92149315, 0.9227464 ,\n",
       "                     0.92525289, 0.92570047, 0.92802793, 0.92981828, 0.93098201,\n",
       "                     0.93313043, 0.93465222, 0.93518933, 0.94351446, 0.94467818,\n",
       "                     0.94548384, 0.94557336, 0.94700564, 0.94852744, 0.9504073 ,\n",
       "                     0.95246621, 0.95452511, 0.95524125, 0.95846388, 0.95864291,\n",
       "                     0.95926954, 0.96365589, 0.96508817, 0.96652045, 0.96660997,\n",
       "                     0.96938501, 0.96956405, 0.97063826, 0.97233909, 0.97296571,\n",
       "                     0.97395041, 0.97457703, 0.97502462, 0.97529317, 0.97717304,\n",
       "                     0.97753111, 0.97842628, 0.9785158 , 0.97985856, 0.98084325,\n",
       "                     0.98146988, 0.98173843, 0.98236505, 0.98326023, 0.98343926,\n",
       "                     0.98388685, 0.9841554 , 0.98433444, 0.98540865, 1.        ]), tpr=array([0.        , 0.06919703, 0.0859368 , 0.09094978, 0.09533614,\n",
       "                     0.09748456, 0.09900636, 0.10151285, 0.10366127, 0.10572017,\n",
       "                     0.10670486, 0.11288157, 0.11637275, 0.12138573, 0.12469788,\n",
       "                     0.12756244, 0.12962134, 0.13803599, 0.13857309, 0.14215379,\n",
       "                     0.14466028, 0.14788291, 0.15370155, 0.15584997, 0.15835646,\n",
       "                     0.16793483, 0.16874049, 0.17312685, 0.1754543 , 0.19317877,\n",
       "                     0.19505863, 0.19729657, 0.2076806 , 0.21045564, 0.22119774,\n",
       "                     0.22576314, 0.23059708, 0.23283502, 0.23793752, 0.23919076,\n",
       "                     0.24071256, 0.24608361, 0.26810491, 0.26926864, 0.27356548,\n",
       "                     0.27839943, 0.28180109, 0.28565034, 0.29182705, 0.29415451,\n",
       "                     0.30086832, 0.3028377 , 0.31089428, 0.31429594, 0.32682839,\n",
       "                     0.33112523, 0.3503715 , 0.37991227, 0.38304539, 0.38966968,\n",
       "                     0.39253424, 0.39360845, 0.40515621, 0.40793125, 0.40963208,\n",
       "                     0.4240444 , 0.42887835, 0.43183242, 0.43944141, 0.44606571,\n",
       "                     0.4475875 , 0.45582311, 0.46862412, 0.47139916, 0.47471131,\n",
       "                     0.49852296, 0.50156656, 0.50890699, 0.51007072, 0.51723212,\n",
       "                     0.51803778, 0.51884343, 0.52134992, 0.52305076, 0.52412497,\n",
       "                     0.52564676, 0.53674693, 0.54211798, 0.54641482, 0.5488318 ,\n",
       "                     0.55903679, 0.56029004, 0.56754095, 0.57676126, 0.60316892,\n",
       "                     0.6046012 , 0.60639155, 0.60791335, 0.6102408 , 0.61364247,\n",
       "                     0.62008773, 0.62644347, 0.6276072 , 0.62921851, 0.63450004,\n",
       "                     0.64577925, 0.64748008, 0.65195596, 0.65338824, 0.65634231,\n",
       "                     0.66063915, 0.6660102 , 0.66806911, 0.66878525, 0.68346612,\n",
       "                     0.68507743, 0.68776296, 0.68874765, 0.69089607, 0.69322353,\n",
       "                     0.69940023, 0.72339092, 0.72912004, 0.73126846, 0.73323785,\n",
       "                     0.73413302, 0.73655   , 0.73798228, 0.7508728 , 0.75149942,\n",
       "                     0.75328977, 0.75794468, 0.75839227, 0.76152538, 0.76233104,\n",
       "                     0.76394235, 0.76510608, 0.76868678, 0.77002954, 0.77790708,\n",
       "                     0.77889177, 0.78300958, 0.78426282, 0.785158  , 0.78999194,\n",
       "                     0.79482589, 0.79733238, 0.79903321, 0.80010742, 0.80136067,\n",
       "                     0.80234536, 0.82033838, 0.82651508, 0.83134903, 0.83215469,\n",
       "                     0.83859995, 0.84012174, 0.84280727, 0.8460299 , 0.85256468,\n",
       "                     0.85345985, 0.85408647, 0.85507117, 0.85650345, 0.85695103,\n",
       "                     0.85739862, 0.86133739, 0.86196401, 0.86572375, 0.86724555,\n",
       "                     0.87915137, 0.88076269, 0.88210545, 0.88828216, 0.89222093,\n",
       "                     0.89293707, 0.89598066, 0.89947185, 0.90081461, 0.90296303,\n",
       "                     0.90913974, 0.90985588, 0.9110196 , 0.91585355, 0.91630114,\n",
       "                     0.91746486, 0.92015039, 0.92140363, 0.93295139, 0.94038134,\n",
       "                     0.94199266, 0.94664757, 0.94790081, 0.95085489, 0.95157103,\n",
       "                     0.95389849, 0.95470414, 0.95676305, 0.95801629, 0.9590905 ,\n",
       "                     0.9606123 , 0.96195506, 0.96231313, 0.96893743, 0.97054874,\n",
       "                     0.97099633, 0.9713544 , 0.97278668, 0.9734133 , 0.97475606,\n",
       "                     0.97600931, 0.97878435, 0.97950049, 0.9820965 , 0.9826336 ,\n",
       "                     0.98308119, 0.98728851, 0.98782562, 0.98881031, 0.98898935,\n",
       "                     0.99104825, 0.99158535, 0.99203294, 0.99301763, 0.99319667,\n",
       "                     0.99382329, 0.99427088, 0.9948975 , 0.99498702, 0.99615075,\n",
       "                     0.9964193 , 0.99677737, 0.99713544, 0.99767254, 0.99803061,\n",
       "                     0.99865724, 0.99874675, 0.99892579, 0.99928386, 0.99937338,\n",
       "                     0.99946289, 0.99964193, 0.99982096, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.06383982e-02, -3.50913198e-02,\n",
       "                     -4.00053346e-02, -4.08219945e-02, -5.71584138e-02, -6.89928715e-02,\n",
       "                     -8.00427077e-02, -8.33816089e-02, -8.70113770e-02, -9.66268357e-02,\n",
       "                     -9.76384696e-02, -1.01782694e-01, -1.02654154e-01, -1.17783036e-01,\n",
       "                     -1.22602322e-01, -1.29534052e-01, -1.54150680e-01, -1.61268148e-01,\n",
       "                     -1.64303051e-01, -1.77681177e-01, -1.82321557e-01, -1.89242000e-01,\n",
       "                     -1.94156014e-01, -1.94705616e-01, -2.00670695e-01, -2.02524264e-01,\n",
       "                     -2.07639365e-01, -2.12991180e-01, -2.13574100e-01, -2.15111380e-01,\n",
       "                     -2.23143551e-01, -2.29574442e-01, -2.29788094e-01, -2.42561637e-01,\n",
       "                     -2.45122458e-01, -2.46860078e-01, -2.47408173e-01, -2.51314428e-01,\n",
       "                     -2.57829109e-01, -2.62364264e-01, -2.62989460e-01, -2.68263987e-01,\n",
       "                     -2.71933715e-01, -2.73695830e-01, -2.74436846e-01, -2.81851152e-01,\n",
       "                     -2.87682072e-01, -2.97251523e-01, -2.97632403e-01, -3.10154928e-01,\n",
       "                     -3.12374685e-01, -3.13657559e-01, -3.15852949e-01, -3.18453731e-01,\n",
       "                     -3.26455458e-01, -3.29957556e-01, -3.36472237e-01, -3.40325806e-01,\n",
       "                     -3.40926587e-01, -3.48306694e-01, -3.49673748e-01, -3.50202429e-01,\n",
       "                     -3.51397887e-01, -3.56674944e-01, -3.67724780e-01, -3.74693449e-01,\n",
       "                     -3.77630309e-01, -3.78066134e-01, -3.85662481e-01, -3.90866309e-01,\n",
       "                     -3.93741644e-01, -3.94654192e-01, -3.96415273e-01, -4.05465108e-01,\n",
       "                     -4.05465108e-01, -4.13562318e-01, -4.30782916e-01, -4.38254931e-01,\n",
       "                     -4.41832752e-01, -4.41832752e-01, -4.51985124e-01, -4.56758402e-01,\n",
       "                     -4.59532329e-01, -4.62623522e-01, -4.62922163e-01, -4.70003629e-01,\n",
       "                     -4.85507816e-01, -4.88352768e-01, -4.89548225e-01, -4.96436886e-01,\n",
       "                     -5.10825624e-01, -5.12765489e-01, -5.19600570e-01, -5.23248144e-01,\n",
       "                     -5.30628251e-01, -5.34082486e-01, -5.48565952e-01, -5.52068582e-01,\n",
       "                     -5.59615788e-01, -5.65633860e-01, -5.70544858e-01, -5.75364145e-01,\n",
       "                     -5.76422906e-01, -5.79818495e-01, -5.81921545e-01, -5.87786665e-01,\n",
       "                     -5.94707108e-01, -5.97837001e-01, -6.06135804e-01, -6.24154309e-01,\n",
       "                     -6.25705900e-01, -6.28608659e-01, -6.30233355e-01, -6.35988767e-01,\n",
       "                     -6.41853886e-01, -6.46627165e-01, -6.50587566e-01, -6.53926467e-01,\n",
       "                     -6.56242624e-01, -6.93147181e-01, -7.31466045e-01, -7.33969175e-01,\n",
       "                     -7.37598943e-01, -7.41937345e-01, -7.47214402e-01, -7.53771802e-01,\n",
       "                     -7.60286483e-01, -7.62140052e-01, -7.65467842e-01, -7.67255153e-01,\n",
       "                     -7.88457360e-01, -7.88457360e-01, -7.98507696e-01, -7.98507696e-01,\n",
       "                     -8.02346473e-01, -8.10930216e-01, -8.18310324e-01, -8.20980552e-01,\n",
       "                     -8.20980552e-01, -8.25318954e-01, -8.26678573e-01, -8.32909123e-01,\n",
       "                     -8.39329691e-01, -8.47297860e-01, -8.57450232e-01, -8.62223511e-01,\n",
       "                     -8.82389180e-01, -8.87303195e-01, -8.97941593e-01, -9.03271019e-01,\n",
       "                     -9.13387972e-01, -9.16290732e-01, -9.38269639e-01, -9.49080555e-01,\n",
       "                     -9.50976290e-01, -9.55511445e-01, -9.80829253e-01, -9.92744288e-01,\n",
       "                     -9.93251773e-01, -9.98528830e-01, -1.00330211e+00, -1.01160091e+00,\n",
       "                     -1.02961942e+00, -1.02961942e+00, -1.03609193e+00, -1.04982212e+00,\n",
       "                     -1.08261195e+00, -1.09861229e+00, -1.09861229e+00, -1.11696143e+00,\n",
       "                     -1.12059120e+00, -1.12247977e+00, -1.12846525e+00, -1.13943428e+00,\n",
       "                     -1.15577070e+00, -1.15671992e+00, -1.16315081e+00, -1.17865500e+00,\n",
       "                     -1.20397280e+00, -1.21639532e+00, -1.21924028e+00, -1.22050211e+00,\n",
       "                     -1.22377543e+00, -1.24171313e+00, -1.24319352e+00, -1.25276297e+00,\n",
       "                     -1.26923781e+00, -1.27825288e+00, -1.29928298e+00, -1.30625165e+00,\n",
       "                     -1.31218639e+00, -1.31567679e+00, -1.32175584e+00, -1.35702398e+00,\n",
       "                     -1.35812348e+00, -1.38629436e+00, -1.40399394e+00, -1.42711636e+00,\n",
       "                     -1.42946653e+00, -1.43508453e+00, -1.44691898e+00, -1.46425590e+00,\n",
       "                     -1.46633707e+00, -1.48160454e+00, -1.50407740e+00, -1.51787072e+00,\n",
       "                     -1.51982575e+00, -1.52605630e+00, -1.53532994e+00, -1.58329263e+00,\n",
       "                     -1.58412010e+00, -1.60943791e+00, -1.64222774e+00, -1.64865863e+00,\n",
       "                     -1.65111061e+00, -1.67397643e+00, -1.69644929e+00, -1.70474809e+00,\n",
       "                     -1.73204023e+00, -1.73460106e+00, -1.75785792e+00, -1.79175947e+00,\n",
       "                     -1.79175947e+00, -1.81528997e+00, -1.88706965e+00, -1.90423745e+00,\n",
       "                     -1.94591015e+00, -2.10787948e+00, -2.15948425e+00, -2.19722458e+00,\n",
       "                     -2.32727771e+00, -2.33537492e+00, -2.37490575e+00, -2.38482319e+00,\n",
       "                     -2.48490665e+00, -2.52572864e+00, -2.70805020e+00, -2.89037176e+00,\n",
       "                     -3.21887582e+00, -3.23867845e+00, -3.36729583e+00, -4.54859983e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5194454593171327, privacy_risk=0.5152179751141348, accuracy=0.5152179751141348, tpr_ind=0.895980664219855, tnr_ind=0.13445528600841464, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.05281533, 0.05585892, 0.05854445, 0.05952914,\n",
       "                     0.06946558, 0.07179304, 0.07931251, 0.08065527, 0.08325128,\n",
       "                     0.08495211, 0.08584728, 0.08674246, 0.09300868, 0.09739504,\n",
       "                     0.09927491, 0.10115478, 0.10366127, 0.10607824, 0.10930087,\n",
       "                     0.11171784, 0.11538806, 0.117626  , 0.11807358, 0.13114314,\n",
       "                     0.13159073, 0.13714081, 0.14179572, 0.15021037, 0.15271686,\n",
       "                     0.17652851, 0.17715513, 0.18046728, 0.18127294, 0.18297377,\n",
       "                     0.18637544, 0.21188792, 0.2143049 , 0.21564766, 0.22307761,\n",
       "                     0.22692686, 0.24491988, 0.24626264, 0.25073852, 0.25261839,\n",
       "                     0.25798944, 0.26398711, 0.27284934, 0.27499776, 0.27813087,\n",
       "                     0.28341241, 0.28385999, 0.28448662, 0.28618745, 0.29630293,\n",
       "                     0.31384836, 0.31832423, 0.32083072, 0.35941277, 0.37865903,\n",
       "                     0.38089697, 0.38170262, 0.39163907, 0.39620446, 0.39915854,\n",
       "                     0.40882643, 0.41312327, 0.43111628, 0.43254856, 0.43451795,\n",
       "                     0.43917286, 0.44570764, 0.45385373, 0.45653925, 0.46164175,\n",
       "                     0.48939218, 0.49082446, 0.49180915, 0.4977173 , 0.51839585,\n",
       "                     0.52161848, 0.5237669 , 0.52681049, 0.53110733, 0.53880584,\n",
       "                     0.54901083, 0.55214394, 0.55277057, 0.55724644, 0.55814162,\n",
       "                     0.56995793, 0.57112165, 0.57228538, 0.5780145 , 0.58168472,\n",
       "                     0.58472831, 0.58642915, 0.58929371, 0.60057291, 0.60782383,\n",
       "                     0.60934563, 0.61292633, 0.6158804 , 0.61758124, 0.61856593,\n",
       "                     0.62169904, 0.62536926, 0.62975562, 0.6388864 , 0.6424671 ,\n",
       "                     0.64855429, 0.64989705, 0.65508907, 0.65813266, 0.66019157,\n",
       "                     0.66484648, 0.66690538, 0.66923284, 0.67030705, 0.67129174,\n",
       "                     0.67442485, 0.67549906, 0.67755796, 0.70387611, 0.7063826 ,\n",
       "                     0.70736729, 0.71121654, 0.7120222 , 0.71211172, 0.71318593,\n",
       "                     0.7140811 , 0.71784084, 0.71855698, 0.71998926, 0.72285382,\n",
       "                     0.72330141, 0.72437562, 0.72867246, 0.73314833, 0.73950407,\n",
       "                     0.74326381, 0.74496464, 0.74657596, 0.74908245, 0.75015666,\n",
       "                     0.75132038, 0.75284218, 0.75490108, 0.75624385, 0.7636738 ,\n",
       "                     0.77047713, 0.77226748, 0.77343121, 0.77396831, 0.77522156,\n",
       "                     0.77611673, 0.77835467, 0.77844419, 0.78121923, 0.7821144 ,\n",
       "                     0.78336765, 0.79070808, 0.79097664, 0.79258795, 0.79428878,\n",
       "                     0.7959001 , 0.80252439, 0.80655268, 0.80807448, 0.80932772,\n",
       "                     0.80959628, 0.81111807, 0.82472473, 0.82732074, 0.82902157,\n",
       "                     0.83036434, 0.84253872, 0.84441858, 0.84665652, 0.85202757,\n",
       "                     0.85587682, 0.85775669, 0.85865187, 0.86080029, 0.87028914,\n",
       "                     0.87243756, 0.87682392, 0.87762958, 0.87915137, 0.88058365,\n",
       "                     0.88317966, 0.88362725, 0.88523856, 0.89392176, 0.90869215,\n",
       "                     0.90905022, 0.91003491, 0.91630114, 0.92158267, 0.92185122,\n",
       "                     0.92220929, 0.92301495, 0.9253424 , 0.92641661, 0.92749082,\n",
       "                     0.93134008, 0.93357801, 0.93536836, 0.93680064, 0.93823292,\n",
       "                     0.93850148, 0.94521529, 0.94664757, 0.94763226, 0.94763226,\n",
       "                     0.94870647, 0.95595739, 0.95649449, 0.95765822, 0.95953809,\n",
       "                     0.95998568, 0.96123892, 0.96222361, 0.96804225, 0.96822129,\n",
       "                     0.97072778, 0.97198102, 0.97224957, 0.97323427, 0.9734133 ,\n",
       "                     0.97681497, 0.97726255, 0.97771014, 0.97833676, 0.97896339,\n",
       "                     0.97959001, 0.98012711, 0.98093277, 0.98146988, 0.98218602,\n",
       "                     0.98290216, 0.98576672, 0.98612479, 0.9862143 , 0.98648286,\n",
       "                     0.98693044, 0.987199  , 0.98728851, 0.98764658, 0.98782562,\n",
       "                     0.98872079, 1.        ]), tpr=array([0.        , 0.06516874, 0.0680333 , 0.07071883, 0.07331483,\n",
       "                     0.08172948, 0.08369886, 0.0915764 , 0.0930982 , 0.09533614,\n",
       "                     0.09641035, 0.09739504, 0.09829022, 0.10401934, 0.10885328,\n",
       "                     0.11082267, 0.11395578, 0.11699937, 0.11870021, 0.12263898,\n",
       "                     0.12595112, 0.13033748, 0.13141169, 0.1319488 , 0.14331752,\n",
       "                     0.14430221, 0.14994181, 0.15531286, 0.16435413, 0.1667711 ,\n",
       "                     0.19022469, 0.19138842, 0.19711754, 0.19863933, 0.20159341,\n",
       "                     0.20517411, 0.23050756, 0.23346164, 0.23471489, 0.2414287 ,\n",
       "                     0.24626264, 0.26550891, 0.26729926, 0.27132754, 0.27302838,\n",
       "                     0.27866798, 0.28368096, 0.29254319, 0.29460209, 0.29737714,\n",
       "                     0.3023006 , 0.30328529, 0.30498612, 0.3064184 , 0.31823471,\n",
       "                     0.33622773, 0.3401665 , 0.34222541, 0.3795542 , 0.39862143,\n",
       "                     0.40085937, 0.40193358, 0.41133292, 0.41554024, 0.41867335,\n",
       "                     0.43084773, 0.43505505, 0.45465939, 0.45662877, 0.45797153,\n",
       "                     0.4619103 , 0.46987736, 0.47900815, 0.48223078, 0.48688569,\n",
       "                     0.51472563, 0.51642646, 0.51776922, 0.52358786, 0.5452511 ,\n",
       "                     0.54802614, 0.54963745, 0.55348671, 0.5565303 , 0.5636917 ,\n",
       "                     0.57479187, 0.5774774 , 0.57873064, 0.58257989, 0.58410169,\n",
       "                     0.59842449, 0.60021484, 0.60182616, 0.60648107, 0.60934563,\n",
       "                     0.6117626 , 0.61373198, 0.61874496, 0.62903948, 0.6388864 ,\n",
       "                     0.64022916, 0.64380986, 0.64631635, 0.64801719, 0.64918091,\n",
       "                     0.65222451, 0.65580521, 0.66063915, 0.66896428, 0.67254498,\n",
       "                     0.67916928, 0.68069108, 0.68445081, 0.68731537, 0.6884791 ,\n",
       "                     0.69349208, 0.69483484, 0.69698326, 0.69796795, 0.69904216,\n",
       "                     0.70145914, 0.7028019 , 0.70512935, 0.73019425, 0.73243219,\n",
       "                     0.73368544, 0.73592337, 0.73690807, 0.73780324, 0.73968311,\n",
       "                     0.74084684, 0.74514368, 0.74612837, 0.74854534, 0.75123087,\n",
       "                     0.75167845, 0.7529317 , 0.75830275, 0.76116731, 0.76770209,\n",
       "                     0.77146182, 0.77253603, 0.77414735, 0.77629577, 0.77710142,\n",
       "                     0.77826515, 0.77996598, 0.78238296, 0.78327813, 0.78981291,\n",
       "                     0.79661624, 0.79903321, 0.79983887, 0.80046549, 0.80109211,\n",
       "                     0.80261391, 0.80395667, 0.80440426, 0.80726882, 0.80825351,\n",
       "                     0.80932772, 0.81783189, 0.81872706, 0.820965  , 0.82168114,\n",
       "                     0.82320294, 0.82946916, 0.83349745, 0.83519828, 0.8373467 ,\n",
       "                     0.83824188, 0.83976367, 0.85157998, 0.8547131 , 0.85542924,\n",
       "                     0.85632441, 0.87082625, 0.87324322, 0.87485453, 0.87941993,\n",
       "                     0.8833587 , 0.88523856, 0.88586519, 0.88676036, 0.89553308,\n",
       "                     0.89741294, 0.90278399, 0.90305255, 0.90412676, 0.90591711,\n",
       "                     0.90985588, 0.91030346, 0.91119864, 0.91880763, 0.9334885 ,\n",
       "                     0.93429415, 0.93581595, 0.9427088 , 0.94718467, 0.94772178,\n",
       "                     0.9483484 , 0.94870647, 0.95049682, 0.95148151, 0.95219765,\n",
       "                     0.95515173, 0.95676305, 0.9585534 , 0.9590905 , 0.96034375,\n",
       "                     0.96088085, 0.96660997, 0.96804225, 0.97001164, 0.97036971,\n",
       "                     0.97117536, 0.97762062, 0.97806821, 0.9785158 , 0.97923194,\n",
       "                     0.97959001, 0.98093277, 0.98120132, 0.98657237, 0.98710948,\n",
       "                     0.98907886, 0.99006356, 0.99015307, 0.99122728, 0.99140632,\n",
       "                     0.9933757 , 0.99346522, 0.99364426, 0.9943604 , 0.9948975 ,\n",
       "                     0.99552412, 0.99579268, 0.99624026, 0.99668785, 0.9969564 ,\n",
       "                     0.99758303, 0.99829917, 0.9984782 , 0.99856772, 0.99874675,\n",
       "                     0.99883627, 0.99928386, 0.99937338, 0.99973145, 0.99982096,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.07716587e-02, -3.27898228e-02,\n",
       "                     -3.39015517e-02, -4.16726964e-02, -4.44517626e-02, -5.52626787e-02,\n",
       "                     -5.71584138e-02, -7.69610411e-02, -8.00427077e-02, -8.70113770e-02,\n",
       "                     -9.53101798e-02, -1.17783036e-01, -1.21889818e-01, -1.27833372e-01,\n",
       "                     -1.33531393e-01, -1.37201122e-01, -1.46603474e-01, -1.47635999e-01,\n",
       "                     -1.50282203e-01, -1.51230970e-01, -1.54150680e-01, -1.54150680e-01,\n",
       "                     -1.59759219e-01, -1.67054085e-01, -1.74353387e-01, -1.82321557e-01,\n",
       "                     -1.97063839e-01, -2.00670695e-01, -2.06207042e-01, -2.07639365e-01,\n",
       "                     -2.10564769e-01, -2.11309094e-01, -2.17064505e-01, -2.23143551e-01,\n",
       "                     -2.26670892e-01, -2.41162057e-01, -2.51314428e-01, -2.57222865e-01,\n",
       "                     -2.59511195e-01, -2.60573754e-01, -2.62364264e-01, -2.70874954e-01,\n",
       "                     -2.74436846e-01, -2.75705881e-01, -2.78713402e-01, -2.87682072e-01,\n",
       "                     -2.98492989e-01, -3.03682414e-01, -3.10154928e-01, -3.10154928e-01,\n",
       "                     -3.13657559e-01, -3.18453731e-01, -3.21204764e-01, -3.24316206e-01,\n",
       "                     -3.26684230e-01, -3.30241687e-01, -3.31664535e-01, -3.35801321e-01,\n",
       "                     -3.36472237e-01, -3.48306694e-01, -3.49985956e-01, -3.54545018e-01,\n",
       "                     -3.56674944e-01, -3.65459773e-01, -3.69360103e-01, -3.69830044e-01,\n",
       "                     -3.74693449e-01, -3.82992252e-01, -3.90197636e-01, -4.01712758e-01,\n",
       "                     -4.05465108e-01, -4.05465108e-01, -4.18204134e-01, -4.19302476e-01,\n",
       "                     -4.22856851e-01, -4.27444015e-01, -4.30782916e-01, -4.35318071e-01,\n",
       "                     -4.37213806e-01, -4.41832752e-01, -4.43492504e-01, -4.43931389e-01,\n",
       "                     -4.46287103e-01, -4.47576593e-01, -4.48950220e-01, -4.51985124e-01,\n",
       "                     -4.58307589e-01, -4.62623522e-01, -4.66089730e-01, -4.70003629e-01,\n",
       "                     -4.76924072e-01, -4.79573080e-01, -4.85507816e-01, -4.88352768e-01,\n",
       "                     -4.92476485e-01, -4.96436886e-01, -5.07341300e-01, -5.09005787e-01,\n",
       "                     -5.10825624e-01, -5.15813165e-01, -5.17943092e-01, -5.21296924e-01,\n",
       "                     -5.26093096e-01, -5.34082486e-01, -5.59615788e-01, -5.75364145e-01,\n",
       "                     -5.79388295e-01, -5.87786665e-01, -5.93774707e-01, -6.00773860e-01,\n",
       "                     -6.06135804e-01, -6.11801541e-01, -6.13104473e-01, -6.19039208e-01,\n",
       "                     -6.24154309e-01, -6.28608659e-01, -6.46627165e-01, -6.50587566e-01,\n",
       "                     -6.55406853e-01, -6.59245629e-01, -6.73729095e-01, -6.93147181e-01,\n",
       "                     -7.12949808e-01, -7.28238500e-01, -7.32367894e-01, -7.37598943e-01,\n",
       "                     -7.41937345e-01, -7.62140052e-01, -7.67255153e-01, -7.73189888e-01,\n",
       "                     -7.80158558e-01, -7.81700578e-01, -7.88457360e-01, -7.88457360e-01,\n",
       "                     -7.94929875e-01, -8.03495238e-01, -8.10930216e-01, -8.21528347e-01,\n",
       "                     -8.26678573e-01, -8.47297860e-01, -8.47297860e-01, -8.82389180e-01,\n",
       "                     -8.93817876e-01, -9.00786545e-01, -9.05708623e-01, -9.08855753e-01,\n",
       "                     -9.16290732e-01, -9.19026712e-01, -9.21540088e-01, -9.38269639e-01,\n",
       "                     -9.38269639e-01, -9.44461609e-01, -9.44461609e-01, -9.50976290e-01,\n",
       "                     -9.55511445e-01, -9.55511445e-01, -9.65080896e-01, -9.69400557e-01,\n",
       "                     -9.80829253e-01, -9.87386654e-01, -9.93251773e-01, -1.00063188e+00,\n",
       "                     -1.01160091e+00, -1.01693426e+00, -1.01936292e+00, -1.02165125e+00,\n",
       "                     -1.02585293e+00, -1.02663879e+00, -1.02961942e+00, -1.03798767e+00,\n",
       "                     -1.04145387e+00, -1.04982212e+00, -1.05605267e+00, -1.06471074e+00,\n",
       "                     -1.07149905e+00, -1.07361099e+00, -1.09861229e+00, -1.09861229e+00,\n",
       "                     -1.10615949e+00, -1.12986483e+00, -1.14513230e+00, -1.16315081e+00,\n",
       "                     -1.17393430e+00, -1.17498527e+00, -1.18377010e+00, -1.20397280e+00,\n",
       "                     -1.20397280e+00, -1.20896035e+00, -1.21975667e+00, -1.22377543e+00,\n",
       "                     -1.25276297e+00, -1.25444223e+00, -1.26488433e+00, -1.26851133e+00,\n",
       "                     -1.27766052e+00, -1.28381569e+00, -1.29198368e+00, -1.29928298e+00,\n",
       "                     -1.31218639e+00, -1.32175584e+00, -1.32175584e+00, -1.33977435e+00,\n",
       "                     -1.35454566e+00, -1.38629436e+00, -1.41369334e+00, -1.42310833e+00,\n",
       "                     -1.42711636e+00, -1.43848011e+00, -1.46633707e+00, -1.47232870e+00,\n",
       "                     -1.47590652e+00, -1.48366853e+00, -1.50407740e+00, -1.54044504e+00,\n",
       "                     -1.59545167e+00, -1.60943791e+00, -1.60943791e+00, -1.63413053e+00,\n",
       "                     -1.65822808e+00, -1.66139765e+00, -1.67397643e+00, -1.68020698e+00,\n",
       "                     -1.70474809e+00, -1.72114190e+00, -1.79175947e+00, -1.79175947e+00,\n",
       "                     -1.83258146e+00, -1.87180218e+00, -1.91290385e+00, -1.94591015e+00,\n",
       "                     -1.94591015e+00, -1.96360973e+00, -1.96944065e+00, -1.98591548e+00,\n",
       "                     -1.99243016e+00, -2.05412373e+00, -2.07944154e+00, -2.12026354e+00,\n",
       "                     -2.16496372e+00, -2.19722458e+00, -2.48490665e+00, -2.56494936e+00,\n",
       "                     -2.60268969e+00, -2.89037176e+00, -2.92316158e+00, -3.13549422e+00,\n",
       "                     -3.19867312e+00, -3.40119738e+00, -3.49650756e+00, -3.45387764e+01]), auc_score=0.5217538905635212, privacy_risk=0.5155312863664847, accuracy=0.5155312863664846, tpr_ind=0.6388864022916481, tnr_ind=0.3921761704413213, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.04619103, 0.05397905, 0.05487423, 0.05639603,\n",
       "                     0.0879957 , 0.09077075, 0.09282965, 0.09345627, 0.09390386,\n",
       "                     0.09497807, 0.09632083, 0.09739504, 0.10348223, 0.10437741,\n",
       "                     0.11377674, 0.11529854, 0.12595112, 0.1283681 , 0.13015845,\n",
       "                     0.13033748, 0.130427  , 0.13373915, 0.1375884 , 0.1411691 ,\n",
       "                     0.14439173, 0.15012085, 0.16077343, 0.17661803, 0.18118342,\n",
       "                     0.18216811, 0.19219407, 0.20132486, 0.2035628 , 0.20929192,\n",
       "                     0.21081371, 0.23301405, 0.23355116, 0.2363262 , 0.23847462,\n",
       "                     0.24035449, 0.24930624, 0.25199176, 0.25360308, 0.25646764,\n",
       "                     0.26183869, 0.28018978, 0.28529227, 0.29182705, 0.29791424,\n",
       "                     0.30059977, 0.30820875, 0.31313222, 0.3145645 , 0.31698147,\n",
       "                     0.3186823 , 0.37346701, 0.37776385, 0.381076  , 0.38501477,\n",
       "                     0.38778981, 0.39316086, 0.39709963, 0.40345538, 0.42216453,\n",
       "                     0.42690896, 0.42843076, 0.43084773, 0.43389133, 0.44114224,\n",
       "                     0.44526005, 0.45448035, 0.45662877, 0.46504342, 0.46558052,\n",
       "                     0.4670128 , 0.46880315, 0.47533793, 0.48097753, 0.49252529,\n",
       "                     0.50523677, 0.51767971, 0.51812729, 0.5273476 , 0.52851132,\n",
       "                     0.53316623, 0.5365679 , 0.53737356, 0.54954794, 0.55169636,\n",
       "                     0.55563513, 0.55876824, 0.56145376, 0.56324411, 0.56431832,\n",
       "                     0.5652135 , 0.56888372, 0.57380718, 0.57658222, 0.58607108,\n",
       "                     0.59215827, 0.59421717, 0.59484379, 0.59940918, 0.60030436,\n",
       "                     0.60531734, 0.60683914, 0.60737624, 0.61077791, 0.61158356,\n",
       "                     0.61238922, 0.61453764, 0.62366843, 0.62420553, 0.62769671,\n",
       "                     0.63548474, 0.64273565, 0.64354131, 0.65052368, 0.65535762,\n",
       "                     0.65813266, 0.66108674, 0.66439889, 0.66762152, 0.66878525,\n",
       "                     0.6726345 , 0.67505147, 0.68060156, 0.69286546, 0.69931072,\n",
       "                     0.70217528, 0.70441321, 0.70548742, 0.70817295, 0.71273834,\n",
       "                     0.71381255, 0.7150658 , 0.71972071, 0.7248232 , 0.72562886,\n",
       "                     0.72885149, 0.73359592, 0.73834035, 0.74317429, 0.7437114 ,\n",
       "                     0.74639692, 0.74997762, 0.7508728 , 0.75391639, 0.75508012,\n",
       "                     0.75669143, 0.75785516, 0.75892937, 0.76107779, 0.76224152,\n",
       "                     0.76358428, 0.76582222, 0.76680691, 0.76967147, 0.77423686,\n",
       "                     0.77602721, 0.77898129, 0.7821144 , 0.78336765, 0.78399427,\n",
       "                     0.78506848, 0.78676931, 0.78900725, 0.79043953, 0.79169278,\n",
       "                     0.79625817, 0.79715334, 0.79760093, 0.79912273, 0.80243488,\n",
       "                     0.80350909, 0.80977531, 0.8102229 , 0.81711575, 0.8250828 ,\n",
       "                     0.8317071 , 0.83555635, 0.83859995, 0.8394056 , 0.84289679,\n",
       "                     0.84432907, 0.85023722, 0.85122191, 0.85507117, 0.85686152,\n",
       "                     0.85981559, 0.86115836, 0.8624116 , 0.86348581, 0.8654552 ,\n",
       "                     0.87360129, 0.87601826, 0.87771909, 0.88192642, 0.88353773,\n",
       "                     0.88568615, 0.88729747, 0.88962492, 0.91030346, 0.91155671,\n",
       "                     0.9125414 , 0.91307851, 0.9161221 , 0.91827052, 0.91925521,\n",
       "                     0.92203026, 0.9263271 , 0.92865455, 0.93384657, 0.93590547,\n",
       "                     0.93697968, 0.93823292, 0.93948617, 0.94190314, 0.94252976,\n",
       "                     0.94297735, 0.94387253, 0.94396204, 0.94942261, 0.95022827,\n",
       "                     0.95031779, 0.95210814, 0.95300331, 0.95730015, 0.95828484,\n",
       "                     0.96177603, 0.96231313, 0.96356638, 0.96616238, 0.96938501,\n",
       "                     0.97081729, 0.97153343, 0.97269716, 0.97377137, 0.97412944,\n",
       "                     0.97439799, 0.97439799, 0.97484558, 0.9754722 , 0.97887387,\n",
       "                     0.97941097, 0.9805747 , 0.98120132, 0.98236505, 0.98254409,\n",
       "                     0.98299167, 0.9836183 , 0.98379733, 0.98397637, 0.98469251,\n",
       "                     0.98505058, 0.9862143 , 0.98666189, 0.98701996, 0.98755707,\n",
       "                     1.        ]), tpr=array([0.        , 0.05424761, 0.05988721, 0.06158804, 0.06310984,\n",
       "                     0.09462   , 0.09712649, 0.09945394, 0.10133381, 0.10222899,\n",
       "                     0.1038403 , 0.1068839 , 0.10831618, 0.11574613, 0.11708889,\n",
       "                     0.12630919, 0.12881568, 0.14242234, 0.1447498 , 0.14645063,\n",
       "                     0.14698774, 0.14752484, 0.15119506, 0.15584997, 0.15889356,\n",
       "                     0.16157909, 0.16596545, 0.17831886, 0.19317877, 0.19747561,\n",
       "                     0.1989974 , 0.20705398, 0.21815415, 0.22164533, 0.22674783,\n",
       "                     0.22871721, 0.24850058, 0.24975383, 0.25342404, 0.25584102,\n",
       "                     0.25673619, 0.26586698, 0.26908961, 0.27052189, 0.27222272,\n",
       "                     0.27759377, 0.2936174 , 0.29880942, 0.30776117, 0.31420643,\n",
       "                     0.3186823 , 0.32593322, 0.33309462, 0.33407931, 0.33578015,\n",
       "                     0.33819712, 0.39307135, 0.3969206 , 0.40121744, 0.40587235,\n",
       "                     0.40909498, 0.41625638, 0.42001611, 0.42619282, 0.44445439,\n",
       "                     0.44848268, 0.45081013, 0.45456987, 0.45698684, 0.46280548,\n",
       "                     0.46871363, 0.47748635, 0.47918718, 0.48903411, 0.49046639,\n",
       "                     0.49324143, 0.49494226, 0.50237221, 0.50926506, 0.51991764,\n",
       "                     0.5329872 , 0.54560917, 0.54641482, 0.55679885, 0.55823113,\n",
       "                     0.56387074, 0.56816758, 0.56968937, 0.5795363 , 0.58186375,\n",
       "                     0.58445976, 0.58732432, 0.59072599, 0.59341151, 0.5943962 ,\n",
       "                     0.595918  , 0.59976725, 0.60469072, 0.60782383, 0.61552233,\n",
       "                     0.62169904, 0.62366843, 0.62536926, 0.62939755, 0.63056127,\n",
       "                     0.63414197, 0.63629039, 0.63817026, 0.64067675, 0.64228807,\n",
       "                     0.64524214, 0.64658491, 0.65446245, 0.6552681 , 0.65929639,\n",
       "                     0.66592069, 0.67451437, 0.6756781 , 0.6818548 , 0.68749441,\n",
       "                     0.69035897, 0.6920598 , 0.69644616, 0.69940023, 0.70047444,\n",
       "                     0.70315997, 0.7063826 , 0.71246979, 0.7242861 , 0.73028377,\n",
       "                     0.73341688, 0.73592337, 0.73690807, 0.73959359, 0.74353236,\n",
       "                     0.74505416, 0.74756065, 0.75239459, 0.75767613, 0.75866082,\n",
       "                     0.76179393, 0.76582222, 0.77119327, 0.7744159 , 0.77504252,\n",
       "                     0.77692239, 0.78095068, 0.78193537, 0.78408379, 0.78524752,\n",
       "                     0.78703787, 0.78838063, 0.78990243, 0.79240892, 0.79321457,\n",
       "                     0.79598962, 0.79715334, 0.79849611, 0.80261391, 0.80771641,\n",
       "                     0.80977531, 0.81299794, 0.81550443, 0.81648912, 0.81711575,\n",
       "                     0.81881658, 0.820965  , 0.82275535, 0.82436666, 0.82579894,\n",
       "                     0.8317071 , 0.83260227, 0.8332289 , 0.83510876, 0.83833139,\n",
       "                     0.83913705, 0.84495569, 0.84540328, 0.85238564, 0.85954704,\n",
       "                     0.86527616, 0.86894638, 0.87288515, 0.87378032, 0.8752126 ,\n",
       "                     0.87592874, 0.88085221, 0.88165786, 0.88577567, 0.88846119,\n",
       "                     0.8910572 , 0.89213141, 0.89374273, 0.89472742, 0.89642825,\n",
       "                     0.90403724, 0.90654373, 0.90806553, 0.91093009, 0.91218333,\n",
       "                     0.91397368, 0.915585  , 0.91701728, 0.93742727, 0.93832244,\n",
       "                     0.93894906, 0.93930713, 0.94190314, 0.94449915, 0.94602095,\n",
       "                     0.94816937, 0.95112344, 0.95282428, 0.95792677, 0.95962761,\n",
       "                     0.96016471, 0.9606123 , 0.96159699, 0.96437203, 0.96464059,\n",
       "                     0.96535673, 0.96643094, 0.96678901, 0.97233909, 0.97260764,\n",
       "                     0.9728762 , 0.97421896, 0.97511413, 0.97762062, 0.97788918,\n",
       "                     0.97985856, 0.98021663, 0.98120132, 0.98460299, 0.987199  ,\n",
       "                     0.98809417, 0.98863128, 0.98916838, 0.98997404, 0.99060066,\n",
       "                     0.99069018, 0.9907797 , 0.99104825, 0.99140632, 0.99346522,\n",
       "                     0.99382329, 0.99507654, 0.99525557, 0.99624026, 0.9964193 ,\n",
       "                     0.99677737, 0.9969564 , 0.99704592, 0.99722496, 0.99740399,\n",
       "                     0.99758303, 0.99955241, 0.99964193, 0.99973145, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.65200156e-02, -5.12932944e-02,\n",
       "                     -5.71584138e-02, -6.06246218e-02, -6.89928715e-02, -7.41079722e-02,\n",
       "                     -9.09717782e-02, -9.53101798e-02, -1.05360516e-01, -1.11225635e-01,\n",
       "                     -1.17783036e-01, -1.24454174e-01, -1.25163143e-01, -1.27444947e-01,\n",
       "                     -1.33531393e-01, -1.40905453e-01, -1.43100844e-01, -1.46603474e-01,\n",
       "                     -1.54150680e-01, -1.54150680e-01, -1.57628944e-01, -1.59630146e-01,\n",
       "                     -1.62518929e-01, -1.82321557e-01, -1.85717146e-01, -1.90740127e-01,\n",
       "                     -2.06132205e-01, -2.06336433e-01, -2.11309094e-01, -2.18689201e-01,\n",
       "                     -2.23143551e-01, -2.28258652e-01, -2.33614851e-01, -2.41162057e-01,\n",
       "                     -2.47284196e-01, -2.51314428e-01, -2.56719847e-01, -2.59511195e-01,\n",
       "                     -2.62364264e-01, -2.65376315e-01, -2.66628663e-01, -2.71933715e-01,\n",
       "                     -2.74436846e-01, -2.75103290e-01, -2.76445999e-01, -2.83362411e-01,\n",
       "                     -2.85178942e-01, -2.87682072e-01, -2.92669614e-01, -3.06031211e-01,\n",
       "                     -3.09321248e-01, -3.10154928e-01, -3.13657559e-01, -3.15081047e-01,\n",
       "                     -3.16226724e-01, -3.16337328e-01, -3.18453731e-01, -3.25422400e-01,\n",
       "                     -3.28504067e-01, -3.36472237e-01, -3.39867826e-01, -3.40604474e-01,\n",
       "                     -3.48306694e-01, -3.52220594e-01, -3.52821375e-01, -3.56674944e-01,\n",
       "                     -3.67724780e-01, -3.68907512e-01, -3.74693449e-01, -3.84845821e-01,\n",
       "                     -3.87765531e-01, -4.05465108e-01, -4.05465108e-01, -4.16160397e-01,\n",
       "                     -4.22856851e-01, -4.25346479e-01, -4.26879203e-01, -4.30362660e-01,\n",
       "                     -4.36928378e-01, -4.40311839e-01, -4.41832752e-01, -4.44906840e-01,\n",
       "                     -4.46287103e-01, -4.51985124e-01, -4.59532329e-01, -4.62623522e-01,\n",
       "                     -4.70003629e-01, -4.79573080e-01, -4.82851772e-01, -4.85507816e-01,\n",
       "                     -4.89548225e-01, -4.90622916e-01, -4.92476485e-01, -4.98991166e-01,\n",
       "                     -5.01479761e-01, -5.03526321e-01, -5.05094949e-01, -5.08497334e-01,\n",
       "                     -5.10825624e-01, -5.19875459e-01, -5.21296924e-01, -5.24070851e-01,\n",
       "                     -5.26093096e-01, -5.30628251e-01, -5.35518236e-01, -5.38996501e-01,\n",
       "                     -5.38996501e-01, -5.43615447e-01, -5.46543706e-01, -5.50046337e-01,\n",
       "                     -5.59615788e-01, -5.75364145e-01, -5.87786665e-01, -5.93774707e-01,\n",
       "                     -6.06135804e-01, -6.13104473e-01, -6.17923759e-01, -6.19039208e-01,\n",
       "                     -6.28608659e-01, -6.39079959e-01, -6.40779195e-01, -6.46627165e-01,\n",
       "                     -6.50587566e-01, -6.59245629e-01, -6.79160939e-01, -6.85767073e-01,\n",
       "                     -6.93147181e-01, -7.00582159e-01, -7.07331816e-01, -7.28238500e-01,\n",
       "                     -7.37598943e-01, -7.41937345e-01, -7.48409859e-01, -7.50305594e-01,\n",
       "                     -7.62140052e-01, -7.73189888e-01, -7.74492820e-01, -7.80158558e-01,\n",
       "                     -7.88457360e-01, -7.88457360e-01, -8.03495238e-01, -8.10930216e-01,\n",
       "                     -8.26678573e-01, -8.47297860e-01, -8.47297860e-01, -8.60201265e-01,\n",
       "                     -8.64997437e-01, -8.69037847e-01, -8.75468737e-01, -8.75468737e-01,\n",
       "                     -8.80358723e-01, -8.87303195e-01, -8.93817876e-01, -8.96746136e-01,\n",
       "                     -9.00786545e-01, -9.02867712e-01, -9.16290732e-01, -9.19793362e-01,\n",
       "                     -9.24948795e-01, -9.27340568e-01, -9.30475367e-01, -9.34309237e-01,\n",
       "                     -9.44461609e-01, -9.47381319e-01, -9.49080555e-01, -9.55511445e-01,\n",
       "                     -9.59775844e-01, -9.65080896e-01, -9.80829253e-01, -9.93251773e-01,\n",
       "                     -9.98528830e-01, -9.98528830e-01, -1.01160091e+00, -1.02165125e+00,\n",
       "                     -1.02410976e+00, -1.02961942e+00, -1.03236290e+00, -1.03850836e+00,\n",
       "                     -1.05060307e+00, -1.05711256e+00, -1.05999745e+00, -1.06471074e+00,\n",
       "                     -1.07755888e+00, -1.09861229e+00, -1.09861229e+00, -1.13497993e+00,\n",
       "                     -1.14117190e+00, -1.16315081e+00, -1.17599895e+00, -1.17865500e+00,\n",
       "                     -1.20397280e+00, -1.21302264e+00, -1.21444410e+00, -1.22377543e+00,\n",
       "                     -1.24250647e+00, -1.24432410e+00, -1.25276297e+00, -1.27296568e+00,\n",
       "                     -1.28093385e+00, -1.29928298e+00, -1.30494872e+00, -1.30524603e+00,\n",
       "                     -1.30833282e+00, -1.31218639e+00, -1.32175584e+00, -1.32405205e+00,\n",
       "                     -1.33318454e+00, -1.37147928e+00, -1.38629436e+00, -1.39384157e+00,\n",
       "                     -1.39936644e+00, -1.42078054e+00, -1.42500887e+00, -1.42711636e+00,\n",
       "                     -1.43508453e+00, -1.45225233e+00, -1.45636192e+00, -1.46633707e+00,\n",
       "                     -1.47590652e+00, -1.48538526e+00, -1.50407740e+00, -1.51831251e+00,\n",
       "                     -1.54044504e+00, -1.54044504e+00, -1.56861592e+00, -1.58923521e+00,\n",
       "                     -1.60943791e+00, -1.60943791e+00, -1.62745642e+00, -1.65822808e+00,\n",
       "                     -1.67964217e+00, -1.68053383e+00, -1.75069798e+00, -1.77495235e+00,\n",
       "                     -1.79175947e+00, -1.89711998e+00, -1.91364929e+00, -1.92529086e+00,\n",
       "                     -1.94591015e+00, -1.94591015e+00, -1.99243016e+00, -2.01490302e+00,\n",
       "                     -2.02929176e+00, -2.07944154e+00, -2.12311661e+00, -2.14006616e+00,\n",
       "                     -2.14539951e+00, -2.19722458e+00, -2.25129180e+00, -2.30258509e+00,\n",
       "                     -2.39789527e+00, -2.44234704e+00, -2.63905733e+00, -2.70805020e+00,\n",
       "                     -2.83321334e+00, -2.89037176e+00, -2.99573227e+00, -3.09104245e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5226839197792736, privacy_risk=0.5179930176349477, accuracy=0.5179930176349477, tpr_ind=0.8351087637633158, tnr_ind=0.20087727150657952, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.06203563, 0.06642199, 0.07018172, 0.07295676,\n",
       "                     0.0736729 , 0.07752216, 0.07984961, 0.08736908, 0.0889804 ,\n",
       "                     0.0925611 , 0.09291917, 0.09417241, 0.09533614, 0.09793215,\n",
       "                     0.1002596 , 0.10169188, 0.10222899, 0.10392982, 0.12058007,\n",
       "                     0.12192284, 0.12559305, 0.12801003, 0.14063199, 0.14403366,\n",
       "                     0.1462716 , 0.15737177, 0.16515979, 0.16578641, 0.16695014,\n",
       "                     0.17250022, 0.17276878, 0.17733417, 0.17939307, 0.18181004,\n",
       "                     0.1877182 , 0.18879241, 0.19174649, 0.20329424, 0.20839674,\n",
       "                     0.20893385, 0.20964999, 0.22844866, 0.22952287, 0.26327097,\n",
       "                     0.2649718 , 0.2706114 , 0.2757139 , 0.27705666, 0.30059977,\n",
       "                     0.30785068, 0.31608629, 0.32306866, 0.32450094, 0.33882374,\n",
       "                     0.34025602, 0.34419479, 0.34840211, 0.3539522 , 0.35699579,\n",
       "                     0.35789097, 0.37292991, 0.37642109, 0.37821144, 0.37856951,\n",
       "                     0.39871095, 0.4020231 , 0.40264972, 0.41768866, 0.42261212,\n",
       "                     0.42664041, 0.4306687 , 0.43380181, 0.43845672, 0.44105273,\n",
       "                     0.4455286 , 0.4506311 , 0.48724376, 0.49503178, 0.49682213,\n",
       "                     0.49941814, 0.49977621, 0.501298  , 0.5043416 , 0.50890699,\n",
       "                     0.52322979, 0.52609435, 0.53415093, 0.53558321, 0.53996956,\n",
       "                     0.54614627, 0.55232298, 0.5800734 , 0.58213231, 0.58275893,\n",
       "                     0.58651866, 0.5918002 , 0.59448572, 0.59555993, 0.60379554,\n",
       "                     0.60585444, 0.60728672, 0.60845045, 0.61095694, 0.61596992,\n",
       "                     0.62715961, 0.62805478, 0.63029272, 0.63127741, 0.63432101,\n",
       "                     0.63575329, 0.63987109, 0.64497359, 0.64703249, 0.6490914 ,\n",
       "                     0.65088175, 0.65276161, 0.6598335 , 0.66287709, 0.66323516,\n",
       "                     0.66413034, 0.66762152, 0.66896428, 0.67335064, 0.69760988,\n",
       "                     0.69984782, 0.70110107, 0.70369707, 0.7048608 , 0.70566646,\n",
       "                     0.70853102, 0.71282786, 0.71461821, 0.71801987, 0.72061588,\n",
       "                     0.72312237, 0.72625548, 0.73135798, 0.73171605, 0.73216364,\n",
       "                     0.73458061, 0.73538627, 0.73583386, 0.7370871 , 0.74523319,\n",
       "                     0.7463074 , 0.74899293, 0.75248411, 0.75364784, 0.75579626,\n",
       "                     0.7570495 , 0.76089876, 0.76197297, 0.76385283, 0.76671739,\n",
       "                     0.76814967, 0.7693134 , 0.77056665, 0.78820159, 0.79106615,\n",
       "                     0.79402023, 0.79822755, 0.7994808 , 0.80037597, 0.80440426,\n",
       "                     0.80565751, 0.81657864, 0.81863754, 0.82060693, 0.82105452,\n",
       "                     0.82168114, 0.82293438, 0.8245457 , 0.8286635 , 0.84280727,\n",
       "                     0.84674604, 0.8496106 , 0.85345985, 0.85489213, 0.85632441,\n",
       "                     0.85784621, 0.85936801, 0.86196401, 0.86867783, 0.86966252,\n",
       "                     0.87064721, 0.87798765, 0.87816668, 0.87897234, 0.88058365,\n",
       "                     0.88676036, 0.88801361, 0.8895354 , 0.8941008 , 0.89633873,\n",
       "                     0.89911378, 0.8997404 , 0.90591711, 0.90591711, 0.90788649,\n",
       "                     0.91146719, 0.91397368, 0.92382061, 0.9248053 , 0.92677468,\n",
       "                     0.92802793, 0.92865455, 0.93957569, 0.9396652 , 0.94494674,\n",
       "                     0.94548384, 0.94584191, 0.94825888, 0.94951213, 0.95085489,\n",
       "                     0.95175007, 0.95371945, 0.95506221, 0.9555098 , 0.95730015,\n",
       "                     0.95864291, 0.96007519, 0.96088085, 0.96141796, 0.9621341 ,\n",
       "                     0.96428252, 0.96741563, 0.96795273, 0.96804225, 0.96947453,\n",
       "                     0.97278668, 0.9734133 , 0.97403992, 0.97430848, 0.97726255,\n",
       "                     0.97896339, 0.97950049, 0.97976904, 0.98039567, 0.9805747 ,\n",
       "                     0.98075374, 0.98075374, 0.98075374, 0.98218602, 0.98227553,\n",
       "                     0.98433444, 0.98496106, 0.98576672, 0.98630382, 0.98630382,\n",
       "                     0.98657237, 0.98684093, 0.98684093, 1.        ]), tpr=array([0.        , 0.07662698, 0.07976009, 0.08450452, 0.08602632,\n",
       "                     0.08736908, 0.09059171, 0.09265061, 0.10070719, 0.10267657,\n",
       "                     0.10840569, 0.10930087, 0.1110017 , 0.11341867, 0.11646227,\n",
       "                     0.11861069, 0.12066959, 0.12129621, 0.12398174, 0.13902068,\n",
       "                     0.14107958, 0.14403366, 0.14645063, 0.16050488, 0.1641751 ,\n",
       "                     0.16686062, 0.17921404, 0.18870289, 0.18950855, 0.19147793,\n",
       "                     0.19649091, 0.19819175, 0.20320473, 0.20553218, 0.20848626,\n",
       "                     0.21403634, 0.21627428, 0.21913884, 0.22871721, 0.2348044 ,\n",
       "                     0.23569958, 0.23659475, 0.25414018, 0.25557246, 0.29021574,\n",
       "                     0.29191657, 0.29800376, 0.30310626, 0.30543371, 0.33175186,\n",
       "                     0.33900278, 0.34795453, 0.35341509, 0.35439979, 0.3703339 ,\n",
       "                     0.37176618, 0.37570495, 0.37973324, 0.3861785 , 0.38904306,\n",
       "                     0.39056486, 0.40569331, 0.40891594, 0.41061678, 0.4112434 ,\n",
       "                     0.43031063, 0.43308567, 0.43407036, 0.45000448, 0.45582311,\n",
       "                     0.45868767, 0.46316355, 0.4670128 , 0.47184675, 0.47614359,\n",
       "                     0.48178319, 0.48733327, 0.52233462, 0.52913795, 0.5314654 ,\n",
       "                     0.53361382, 0.53459851, 0.53638886, 0.53898487, 0.54381882,\n",
       "                     0.55733596, 0.56109569, 0.56959986, 0.57174828, 0.57711933,\n",
       "                     0.58356459, 0.58911467, 0.61632799, 0.61847641, 0.61972966,\n",
       "                     0.6225047 , 0.62787575, 0.63038224, 0.63154597, 0.63915495,\n",
       "                     0.6409453 , 0.64291469, 0.64425745, 0.64837526, 0.65159789,\n",
       "                     0.66081819, 0.66207143, 0.66377227, 0.66466744, 0.667532  ,\n",
       "                     0.6685167 , 0.67227643, 0.67558858, 0.67809507, 0.68033301,\n",
       "                     0.68194432, 0.68364515, 0.68991138, 0.69304449, 0.6941187 ,\n",
       "                     0.69528243, 0.69984782, 0.70163817, 0.70539791, 0.72885149,\n",
       "                     0.73252171, 0.73422254, 0.73851938, 0.73959359, 0.74057828,\n",
       "                     0.74344284, 0.74908245, 0.75060424, 0.75203652, 0.75400591,\n",
       "                     0.75615433, 0.75892937, 0.7616149 , 0.76206248, 0.76286814,\n",
       "                     0.7651956 , 0.76591174, 0.7672545 , 0.76823919, 0.77540059,\n",
       "                     0.7759377 , 0.77781756, 0.78086116, 0.78184585, 0.78327813,\n",
       "                     0.78453138, 0.78981291, 0.79061857, 0.7923194 , 0.7959001 ,\n",
       "                     0.79769045, 0.79849611, 0.79983887, 0.81666816, 0.82006982,\n",
       "                     0.82400859, 0.82723122, 0.82785785, 0.82848447, 0.83340793,\n",
       "                     0.83555635, 0.84307582, 0.84576135, 0.84719363, 0.84817832,\n",
       "                     0.84871542, 0.84987915, 0.8511324 , 0.8547131 , 0.87297467,\n",
       "                     0.87583923, 0.87870379, 0.88085221, 0.88326918, 0.88514905,\n",
       "                     0.88729747, 0.88864023, 0.89132575, 0.89857667, 0.89902426,\n",
       "                     0.9002775 , 0.90887118, 0.90913974, 0.90985588, 0.91119864,\n",
       "                     0.91746486, 0.91809149, 0.91925521, 0.92185122, 0.92346254,\n",
       "                     0.92498433, 0.92552144, 0.93134008, 0.93169815, 0.93366753,\n",
       "                     0.93689016, 0.93948617, 0.94861695, 0.94942261, 0.95112344,\n",
       "                     0.95309283, 0.95362993, 0.96446155, 0.96490914, 0.97019067,\n",
       "                     0.97045922, 0.97072778, 0.97251813, 0.97529317, 0.97609883,\n",
       "                     0.97672545, 0.97824725, 0.9790529 , 0.97967953, 0.98102229,\n",
       "                     0.98146988, 0.98245457, 0.98272312, 0.98317071, 0.98334974,\n",
       "                     0.98531913, 0.98782562, 0.98827321, 0.98836272, 0.98907886,\n",
       "                     0.99176439, 0.99221198, 0.99274908, 0.99310715, 0.99570316,\n",
       "                     0.99615075, 0.99624026, 0.99650882, 0.99677737, 0.99713544,\n",
       "                     0.99740399, 0.99758303, 0.99767254, 0.99820965, 0.99838868,\n",
       "                     0.99910482, 0.99928386, 0.99946289, 0.99955241, 0.99964193,\n",
       "                     0.99973145, 0.99991048, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.81708770e-02, -3.70412717e-02,\n",
       "                     -5.71584138e-02, -6.45385211e-02, -8.00427077e-02, -8.33816089e-02,\n",
       "                     -8.51578083e-02, -8.70113770e-02, -8.96121587e-02, -9.53101798e-02,\n",
       "                     -1.00083459e-01, -1.05360516e-01, -1.11225635e-01, -1.17783036e-01,\n",
       "                     -1.22602322e-01, -1.33531393e-01, -1.54150680e-01, -1.59239749e-01,\n",
       "                     -1.60342650e-01, -1.67054085e-01, -1.69899037e-01, -1.74862812e-01,\n",
       "                     -1.78248231e-01, -1.82321557e-01, -1.84734103e-01, -1.88591170e-01,\n",
       "                     -2.00670695e-01, -2.04794413e-01, -2.23143551e-01, -2.33614851e-01,\n",
       "                     -2.37328186e-01, -2.38411023e-01, -2.41162057e-01, -2.42313467e-01,\n",
       "                     -2.46860078e-01, -2.47836164e-01, -2.54424851e-01, -2.57829109e-01,\n",
       "                     -2.62364264e-01, -2.62364264e-01, -2.63148886e-01, -2.71933715e-01,\n",
       "                     -2.72056755e-01, -2.74436846e-01, -2.80301965e-01, -2.87682072e-01,\n",
       "                     -2.97251523e-01, -2.97834444e-01, -3.06031211e-01, -3.07484700e-01,\n",
       "                     -3.07966744e-01, -3.10154928e-01, -3.11277893e-01, -3.18453731e-01,\n",
       "                     -3.26684230e-01, -3.36472237e-01, -3.38454398e-01, -3.40926587e-01,\n",
       "                     -3.44840486e-01, -3.46564837e-01, -3.48306694e-01, -3.51397887e-01,\n",
       "                     -3.56674944e-01, -3.72049111e-01, -3.72675285e-01, -3.74693449e-01,\n",
       "                     -3.75044511e-01, -3.79489622e-01, -3.84411699e-01, -3.92042088e-01,\n",
       "                     -3.97682968e-01, -4.05465108e-01, -4.05465108e-01, -4.10742165e-01,\n",
       "                     -4.16160397e-01, -4.19853846e-01, -4.22856851e-01, -4.30782916e-01,\n",
       "                     -4.32864082e-01, -4.35318071e-01, -4.38254931e-01, -4.39366660e-01,\n",
       "                     -4.41832752e-01, -4.42305677e-01, -4.51985124e-01, -4.56758402e-01,\n",
       "                     -4.59532329e-01, -4.70003629e-01, -4.76924072e-01, -4.78035801e-01,\n",
       "                     -4.81451015e-01, -4.85507816e-01, -4.96436886e-01, -4.97838428e-01,\n",
       "                     -5.10825624e-01, -5.17943092e-01, -5.26093096e-01, -5.27162043e-01,\n",
       "                     -5.30628251e-01, -5.46543706e-01, -5.50046337e-01, -5.53385238e-01,\n",
       "                     -5.59615788e-01, -5.74757165e-01, -5.79818495e-01, -5.81921545e-01,\n",
       "                     -5.87786665e-01, -5.94707108e-01, -5.97837001e-01, -6.06135804e-01,\n",
       "                     -6.08589793e-01, -6.19039208e-01, -6.31271777e-01, -6.35988767e-01,\n",
       "                     -6.39079959e-01, -6.41853886e-01, -6.49344558e-01, -6.50587566e-01,\n",
       "                     -6.53926467e-01, -6.63294217e-01, -6.67829373e-01, -6.81170990e-01,\n",
       "                     -6.93147181e-01, -7.05268541e-01, -7.19122667e-01, -7.23918839e-01,\n",
       "                     -7.33969175e-01, -7.37598943e-01, -7.38956717e-01, -7.47214402e-01,\n",
       "                     -7.50305594e-01, -7.53771802e-01, -7.59105148e-01, -7.73189888e-01,\n",
       "                     -7.85520501e-01, -7.88457360e-01, -7.88457360e-01, -7.98507696e-01,\n",
       "                     -8.02346473e-01, -8.10930216e-01, -8.18310324e-01, -8.20980552e-01,\n",
       "                     -8.27459518e-01, -8.47297860e-01, -8.47297860e-01, -8.55666110e-01,\n",
       "                     -8.60201265e-01, -8.64997437e-01, -8.87303195e-01, -8.92275856e-01,\n",
       "                     -8.93817876e-01, -9.05708623e-01, -9.16290732e-01, -9.36093359e-01,\n",
       "                     -9.38269639e-01, -9.55511445e-01, -9.62036754e-01, -9.67584026e-01,\n",
       "                     -9.69400557e-01, -9.80829253e-01, -9.98528830e-01, -9.98528830e-01,\n",
       "                     -1.00330211e+00, -1.01160091e+00, -1.02876872e+00, -1.02961942e+00,\n",
       "                     -1.03407377e+00, -1.03609193e+00, -1.04145387e+00, -1.04596856e+00,\n",
       "                     -1.04982212e+00, -1.06471074e+00, -1.07044141e+00, -1.07755888e+00,\n",
       "                     -1.08814099e+00, -1.09861229e+00, -1.09861229e+00, -1.11436065e+00,\n",
       "                     -1.12601126e+00, -1.14209740e+00, -1.15267951e+00, -1.16237891e+00,\n",
       "                     -1.16315081e+00, -1.16760516e+00, -1.16899309e+00, -1.20397280e+00,\n",
       "                     -1.21639532e+00, -1.22377543e+00, -1.22796831e+00, -1.23214368e+00,\n",
       "                     -1.24171313e+00, -1.24782469e+00, -1.25276297e+00, -1.27766052e+00,\n",
       "                     -1.29928298e+00, -1.31867417e+00, -1.32175584e+00, -1.32779815e+00,\n",
       "                     -1.32913595e+00, -1.33318454e+00, -1.35644140e+00, -1.35812348e+00,\n",
       "                     -1.38629436e+00, -1.40876722e+00, -1.42711636e+00, -1.43469090e+00,\n",
       "                     -1.43508453e+00, -1.46372610e+00, -1.46633707e+00, -1.46633707e+00,\n",
       "                     -1.48160454e+00, -1.49326648e+00, -1.51634749e+00, -1.51982575e+00,\n",
       "                     -1.53623451e+00, -1.54044504e+00, -1.55059741e+00, -1.55462968e+00,\n",
       "                     -1.56861592e+00, -1.60943791e+00, -1.60943791e+00, -1.68639895e+00,\n",
       "                     -1.70474809e+00, -1.76098781e+00, -1.77978328e+00, -1.79175947e+00,\n",
       "                     -1.79175947e+00, -1.81237876e+00, -1.82991124e+00, -1.85629799e+00,\n",
       "                     -1.87180218e+00, -1.90954250e+00, -1.91590790e+00, -1.94591015e+00,\n",
       "                     -2.07944154e+00, -2.15948425e+00, -2.19722458e+00, -2.25129180e+00,\n",
       "                     -2.30258509e+00, -2.35137526e+00, -2.39789527e+00, -2.45673577e+00,\n",
       "                     -2.48490665e+00, -2.50552594e+00, -2.52572864e+00, -2.56494936e+00,\n",
       "                     -2.56494936e+00, -2.77258872e+00, -2.89037176e+00, -3.31418600e+00,\n",
       "                     -3.58351894e+00, -3.45387764e+01]), auc_score=0.5274211673237547, privacy_risk=0.5187091576403187, accuracy=0.5187091576403187, tpr_ind=0.5835645868767344, tnr_ind=0.453853728403903, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.06212515, 0.06606392, 0.07080834, 0.07358339,\n",
       "                     0.08369886, 0.08620535, 0.08790619, 0.09336675, 0.09497807,\n",
       "                     0.09703697, 0.09882732, 0.0997225 , 0.10348223, 0.10956942,\n",
       "                     0.11162832, 0.11341867, 0.12416077, 0.12702533, 0.12845761,\n",
       "                     0.13051652, 0.13436577, 0.13624564, 0.14358607, 0.15808791,\n",
       "                     0.16175812, 0.17921404, 0.17957211, 0.18154149, 0.18386895,\n",
       "                     0.18968758, 0.19344732, 0.19398442, 0.19479008, 0.20105631,\n",
       "                     0.21081371, 0.2199445 , 0.22468893, 0.22782204, 0.23256647,\n",
       "                     0.23328261, 0.24966431, 0.25136514, 0.25754185, 0.26165965,\n",
       "                     0.26837347, 0.28368096, 0.28565034, 0.29415451, 0.29898845,\n",
       "                     0.30409095, 0.30489661, 0.30802972, 0.32754453, 0.3288873 ,\n",
       "                     0.33882374, 0.34598514, 0.37105004, 0.37328798, 0.37722675,\n",
       "                     0.38044938, 0.38403008, 0.38608898, 0.39432459, 0.40533524,\n",
       "                     0.40990064, 0.41061678, 0.42681944, 0.42780414, 0.43254856,\n",
       "                     0.43335422, 0.44320115, 0.44588667, 0.44731895, 0.45269   ,\n",
       "                     0.45609167, 0.46370065, 0.46710232, 0.47023543, 0.47157819,\n",
       "                     0.4726524 , 0.49028735, 0.49073494, 0.49189867, 0.50317787,\n",
       "                     0.50389401, 0.50559484, 0.50684809, 0.50836989, 0.52573628,\n",
       "                     0.53119685, 0.5386268 , 0.53988005, 0.54346075, 0.5452511 ,\n",
       "                     0.55017456, 0.55250201, 0.55679885, 0.56360218, 0.56834661,\n",
       "                     0.56977889, 0.59072599, 0.59188971, 0.59368006, 0.60137857,\n",
       "                     0.60907707, 0.61077791, 0.61149405, 0.62438457, 0.63011369,\n",
       "                     0.63082983, 0.63199355, 0.63342583, 0.63825978, 0.64005013,\n",
       "                     0.64228807, 0.64900188, 0.6516874 , 0.65213499, 0.65401486,\n",
       "                     0.66028108, 0.66207143, 0.66323516, 0.66404082, 0.66448841,\n",
       "                     0.66896428, 0.66959091, 0.67406678, 0.67961687, 0.68060156,\n",
       "                     0.68301853, 0.68364515, 0.68507743, 0.6864202 , 0.69340256,\n",
       "                     0.69537195, 0.69635664, 0.6971623 , 0.69778892, 0.69841554,\n",
       "                     0.70181721, 0.70700922, 0.70799391, 0.71220124, 0.71238027,\n",
       "                     0.71443917, 0.71488676, 0.71801987, 0.72455465, 0.72527079,\n",
       "                     0.72598693, 0.72795632, 0.73287978, 0.73395399, 0.73511772,\n",
       "                     0.73574434, 0.73887745, 0.74004118, 0.74075732, 0.74210008,\n",
       "                     0.74442754, 0.75132038, 0.75158894, 0.75239459, 0.75740757,\n",
       "                     0.76331573, 0.76528511, 0.76671739, 0.78166682, 0.78247247,\n",
       "                     0.78292006, 0.78488945, 0.78936532, 0.7902605 , 0.79357264,\n",
       "                     0.79554203, 0.7974219 , 0.79885418, 0.80055501, 0.80082356,\n",
       "                     0.8030615 , 0.80753737, 0.81541491, 0.81657864, 0.81783189,\n",
       "                     0.81827947, 0.8189061 , 0.82374004, 0.82409811, 0.82463522,\n",
       "                     0.83448214, 0.83555635, 0.83600394, 0.83752574, 0.8388685 ,\n",
       "                     0.84200161, 0.84513472, 0.84862591, 0.84952108, 0.85050577,\n",
       "                     0.85363889, 0.85381792, 0.85578731, 0.85587682, 0.86482857,\n",
       "                     0.8659923 , 0.86733506, 0.87082625, 0.87440695, 0.87557067,\n",
       "                     0.87646585, 0.87906186, 0.88121028, 0.88344821, 0.88559663,\n",
       "                     0.89508549, 0.89866619, 0.90153075, 0.90260496, 0.9104825 ,\n",
       "                     0.91236237, 0.91325754, 0.91486886, 0.91674872, 0.92006087,\n",
       "                     0.92095605, 0.92561096, 0.92820696, 0.9299078 , 0.93187718,\n",
       "                     0.9319667 , 0.93859099, 0.93885955, 0.94002327, 0.94091845,\n",
       "                     0.94217169, 0.94611046, 0.95094441, 0.95210814, 0.95327186,\n",
       "                     0.95354042, 0.95452511, 0.95479366, 0.95721063, 0.95837436,\n",
       "                     0.95873243, 0.95882195, 0.96222361, 0.96329782, 0.96634142,\n",
       "                     0.96813177, 0.96840032, 0.96920598, 0.97028019, 0.97090681,\n",
       "                     0.97162295, 0.97314475, 0.97591979, 0.97609883, 0.97636738,\n",
       "                     0.97654641, 0.97887387, 0.97914242, 0.97914242, 0.97932146,\n",
       "                     0.98030615, 0.9805747 , 0.98102229, 0.98272312, 0.98308119,\n",
       "                     0.98326023, 0.98352878, 1.        ]), tpr=array([0.        , 0.06812282, 0.07295676, 0.07644795, 0.08110286,\n",
       "                     0.09139737, 0.09488855, 0.09784263, 0.10339271, 0.10518306,\n",
       "                     0.1068839 , 0.10849521, 0.11001701, 0.11574613, 0.12040104,\n",
       "                     0.12237042, 0.12353415, 0.13499239, 0.13830454, 0.14045296,\n",
       "                     0.14304897, 0.14654015, 0.14922567, 0.15584997, 0.16865097,\n",
       "                     0.17276878, 0.19004565, 0.19085131, 0.19201504, 0.19461105,\n",
       "                     0.20150389, 0.20508459, 0.20642736, 0.20741205, 0.21323069,\n",
       "                     0.22325665, 0.23355116, 0.23883269, 0.24250291, 0.24671023,\n",
       "                     0.24787396, 0.26631456, 0.2680154 , 0.273655  , 0.27804136,\n",
       "                     0.28421806, 0.29970459, 0.30176349, 0.309462  , 0.31581774,\n",
       "                     0.31984603, 0.32109927, 0.3243219 , 0.3437472 , 0.34589562,\n",
       "                     0.35636917, 0.36272491, 0.38904306, 0.391281  , 0.39736819,\n",
       "                     0.4010384 , 0.40426103, 0.40676752, 0.41625638, 0.42485006,\n",
       "                     0.43013159, 0.43174291, 0.44991496, 0.45089965, 0.45403276,\n",
       "                     0.45519649, 0.46199982, 0.46441679, 0.4670128 , 0.47309999,\n",
       "                     0.47668069, 0.48411064, 0.48760183, 0.4905559 , 0.49243577,\n",
       "                     0.49395757, 0.5135619 , 0.51490466, 0.51606839, 0.52761615,\n",
       "                     0.52860084, 0.53021216, 0.53227106, 0.53415093, 0.54901083,\n",
       "                     0.55670934, 0.56208039, 0.56360218, 0.56754095, 0.5693313 ,\n",
       "                     0.57344911, 0.57622415, 0.58016292, 0.5887566 , 0.59287441,\n",
       "                     0.59484379, 0.61668606, 0.61793931, 0.61972966, 0.62671202,\n",
       "                     0.63405246, 0.63521618, 0.63611136, 0.64783815, 0.65177692,\n",
       "                     0.65365679, 0.6552681 , 0.65696894, 0.6618924 , 0.66368275,\n",
       "                     0.66609972, 0.67245547, 0.67540954, 0.67594665, 0.67711038,\n",
       "                     0.68400322, 0.68677827, 0.68821055, 0.68973234, 0.690538  ,\n",
       "                     0.69483484, 0.69573002, 0.70136962, 0.70611405, 0.70709874,\n",
       "                     0.70835198, 0.70960523, 0.71103751, 0.71255931, 0.72079492,\n",
       "                     0.7222272 , 0.72356996, 0.72473369, 0.72589741, 0.72679259,\n",
       "                     0.73108943, 0.73619193, 0.73699758, 0.74084684, 0.74156298,\n",
       "                     0.74290574, 0.74415898, 0.74657596, 0.75248411, 0.7534688 ,\n",
       "                     0.75391639, 0.75633336, 0.76134634, 0.76322621, 0.76403187,\n",
       "                     0.76456897, 0.76823919, 0.76949244, 0.77065616, 0.77199893,\n",
       "                     0.77477397, 0.78300958, 0.7836362 , 0.78444186, 0.78936532,\n",
       "                     0.79402023, 0.79518396, 0.79598962, 0.80995435, 0.81058097,\n",
       "                     0.81120759, 0.8138036 , 0.81872706, 0.81917465, 0.82159162,\n",
       "                     0.82329245, 0.82579894, 0.82687315, 0.82920061, 0.83009578,\n",
       "                     0.8332289 , 0.83770477, 0.84620893, 0.84728314, 0.84844687,\n",
       "                     0.84934205, 0.84987915, 0.85614538, 0.856772  , 0.85748814,\n",
       "                     0.86787217, 0.86867783, 0.86966252, 0.87118432, 0.87297467,\n",
       "                     0.8767344 , 0.87852475, 0.88156835, 0.88282159, 0.88398532,\n",
       "                     0.88720795, 0.88774505, 0.88917733, 0.88962492, 0.89786053,\n",
       "                     0.89857667, 0.90090413, 0.90466386, 0.90878167, 0.90931877,\n",
       "                     0.90985588, 0.91119864, 0.91272044, 0.91522693, 0.9161221 ,\n",
       "                     0.92650613, 0.9289231 , 0.93286187, 0.93366753, 0.94073941,\n",
       "                     0.94190314, 0.94235073, 0.94378301, 0.94602095, 0.94870647,\n",
       "                     0.94942261, 0.95470414, 0.95676305, 0.95819533, 0.95998568,\n",
       "                     0.96052278, 0.9662519 , 0.96660997, 0.96786322, 0.96893743,\n",
       "                     0.97045922, 0.9734133 , 0.97627786, 0.97788918, 0.97815773,\n",
       "                     0.9785158 , 0.97932146, 0.97941097, 0.98111181, 0.98173843,\n",
       "                     0.98200698, 0.98218602, 0.98594575, 0.98684093, 0.98961597,\n",
       "                     0.99095873, 0.9913168 , 0.99149584, 0.99212246, 0.99257005,\n",
       "                     0.99292812, 0.99346522, 0.99525557, 0.99543461, 0.99570316,\n",
       "                     0.99632978, 0.99704592, 0.99722496, 0.99758303, 0.99776206,\n",
       "                     0.99829917, 0.99856772, 0.99883627, 0.99955241, 0.99982096,\n",
       "                     0.99991048, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.83491387e-02, -2.53178080e-02,\n",
       "                     -5.60894667e-02, -6.72522270e-02, -7.41079722e-02, -8.70113770e-02,\n",
       "                     -9.23733201e-02, -9.53101798e-02, -1.00083459e-01, -1.05360516e-01,\n",
       "                     -1.11225635e-01, -1.17783036e-01, -1.26293725e-01, -1.27833372e-01,\n",
       "                     -1.43100844e-01, -1.45182010e-01, -1.50282203e-01, -1.54150680e-01,\n",
       "                     -1.59064695e-01, -1.65079750e-01, -1.82321557e-01, -1.84571277e-01,\n",
       "                     -1.96210669e-01, -1.96710294e-01, -1.96895325e-01, -2.00670695e-01,\n",
       "                     -2.07639365e-01, -2.16223108e-01, -2.20542770e-01, -2.23143551e-01,\n",
       "                     -2.36388778e-01, -2.41162057e-01, -2.44453338e-01, -2.51314428e-01,\n",
       "                     -2.52280145e-01, -2.53195896e-01, -2.56719847e-01, -2.60726262e-01,\n",
       "                     -2.68263987e-01, -2.70545790e-01, -2.74436846e-01, -2.75705881e-01,\n",
       "                     -2.82566972e-01, -2.87682072e-01, -2.93445777e-01, -2.98492989e-01,\n",
       "                     -2.99242895e-01, -3.01668314e-01, -3.04211374e-01, -3.05381650e-01,\n",
       "                     -3.08301360e-01, -3.10462101e-01, -3.18453731e-01, -3.19230430e-01,\n",
       "                     -3.22287602e-01, -3.32577392e-01, -3.36472237e-01, -3.44840486e-01,\n",
       "                     -3.46870944e-01, -3.48306694e-01, -3.56674944e-01, -3.60441427e-01,\n",
       "                     -3.62905494e-01, -3.65113813e-01, -3.67724780e-01, -3.73769377e-01,\n",
       "                     -3.74693449e-01, -3.76477571e-01, -3.79489622e-01, -3.87765531e-01,\n",
       "                     -3.93042588e-01, -3.93904286e-01, -4.05465108e-01, -4.05465108e-01,\n",
       "                     -4.09473130e-01, -4.13975798e-01, -4.15515444e-01, -4.21213465e-01,\n",
       "                     -4.24883194e-01, -4.25058802e-01, -4.27444015e-01, -4.30782916e-01,\n",
       "                     -4.33492420e-01, -4.35318071e-01, -4.41832752e-01, -4.48024723e-01,\n",
       "                     -4.51985124e-01, -4.52532619e-01, -4.58307589e-01, -4.59532329e-01,\n",
       "                     -4.62623522e-01, -4.64305608e-01, -4.70003629e-01, -4.75423697e-01,\n",
       "                     -4.78035801e-01, -4.78490243e-01, -4.85507816e-01, -4.88846717e-01,\n",
       "                     -4.92476485e-01, -4.94296322e-01, -4.96436886e-01, -5.00775288e-01,\n",
       "                     -5.10825624e-01, -5.13261679e-01, -5.26093096e-01, -5.30628251e-01,\n",
       "                     -5.31974448e-01, -5.33298480e-01, -5.38996501e-01, -5.43615447e-01,\n",
       "                     -5.52068582e-01, -5.57015006e-01, -5.59615788e-01, -5.75364145e-01,\n",
       "                     -5.81507209e-01, -5.97837001e-01, -6.06135804e-01, -6.13104473e-01,\n",
       "                     -6.19039208e-01, -6.26455806e-01, -6.28608659e-01, -6.32522559e-01,\n",
       "                     -6.35988767e-01, -6.39658496e-01, -6.41853886e-01, -6.44357016e-01,\n",
       "                     -6.44828603e-01, -6.46627165e-01, -6.56779536e-01, -6.56779536e-01,\n",
       "                     -6.61398482e-01, -6.63294217e-01, -6.93147181e-01, -7.23918839e-01,\n",
       "                     -7.25937003e-01, -7.30887509e-01, -7.30887509e-01, -7.41937345e-01,\n",
       "                     -7.43919506e-01, -7.44440475e-01, -7.47214402e-01, -7.49659391e-01,\n",
       "                     -7.53771802e-01, -7.57685702e-01, -7.62140052e-01, -7.64606145e-01,\n",
       "                     -7.73189888e-01, -7.80158558e-01, -7.88457360e-01, -7.98507696e-01,\n",
       "                     -8.18835396e-01, -8.26678573e-01, -8.47297860e-01, -8.47297860e-01,\n",
       "                     -8.50776125e-01, -8.57450232e-01, -8.69037847e-01, -8.75468737e-01,\n",
       "                     -8.83500909e-01, -8.85383194e-01, -8.87303195e-01, -8.93817876e-01,\n",
       "                     -9.12647741e-01, -9.16290732e-01, -9.31558204e-01, -9.38269639e-01,\n",
       "                     -9.41608540e-01, -9.44461609e-01, -9.44461609e-01, -9.50192284e-01,\n",
       "                     -9.55511445e-01, -9.55511445e-01, -9.66843011e-01, -9.67584026e-01,\n",
       "                     -9.71860583e-01, -9.80829253e-01, -9.90398704e-01, -9.93251773e-01,\n",
       "                     -9.98528830e-01, -1.00063188e+00, -1.01064352e+00, -1.01160091e+00,\n",
       "                     -1.01856958e+00, -1.02961942e+00, -1.04145387e+00, -1.04480958e+00,\n",
       "                     -1.04982212e+00, -1.05605267e+00, -1.06054034e+00, -1.06087196e+00,\n",
       "                     -1.06784063e+00, -1.07880966e+00, -1.08180517e+00, -1.09064412e+00,\n",
       "                     -1.09861229e+00, -1.09861229e+00, -1.12214279e+00, -1.12393010e+00,\n",
       "                     -1.13497993e+00, -1.15267951e+00, -1.15923691e+00, -1.16315081e+00,\n",
       "                     -1.16518678e+00, -1.17865500e+00, -1.18455472e+00, -1.18958407e+00,\n",
       "                     -1.19523912e+00, -1.20397280e+00, -1.20397280e+00, -1.22377543e+00,\n",
       "                     -1.22722967e+00, -1.23214368e+00, -1.25276297e+00, -1.26256697e+00,\n",
       "                     -1.28913061e+00, -1.29721473e+00, -1.29928298e+00, -1.32091160e+00,\n",
       "                     -1.32687094e+00, -1.33500107e+00, -1.33828514e+00, -1.34547237e+00,\n",
       "                     -1.35239281e+00, -1.35454566e+00, -1.36919993e+00, -1.38629436e+00,\n",
       "                     -1.40179855e+00, -1.42310833e+00, -1.42711636e+00, -1.43953888e+00,\n",
       "                     -1.44691898e+00, -1.47181653e+00, -1.48538526e+00, -1.49752000e+00,\n",
       "                     -1.50070471e+00, -1.50407740e+00, -1.52846885e+00, -1.54044504e+00,\n",
       "                     -1.55814462e+00, -1.60943791e+00, -1.60943791e+00, -1.61990921e+00,\n",
       "                     -1.63760879e+00, -1.67397643e+00, -1.70474809e+00, -1.72191590e+00,\n",
       "                     -1.72276660e+00, -1.72506809e+00, -1.78058617e+00, -1.79175947e+00,\n",
       "                     -1.79175947e+00, -1.88273125e+00, -1.91692261e+00, -1.94591015e+00,\n",
       "                     -1.96944065e+00, -2.00148000e+00, -2.01490302e+00, -2.12026354e+00,\n",
       "                     -2.13162729e+00, -2.19722458e+00, -2.25129180e+00, -2.35137526e+00,\n",
       "                     -2.39789527e+00, -2.42774824e+00, -2.48490665e+00, -2.63905733e+00,\n",
       "                     -2.73274281e+00, -2.90872090e+00, -3.68887945e+00, -4.00733319e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5205047964864777, privacy_risk=0.517366395130248, accuracy=0.517366395130248, tpr_ind=0.876734401575508, tnr_ind=0.15799838868498792, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.07653746, 0.07805926, 0.08253514, 0.08620535,\n",
       "                     0.08969654, 0.0930982 , 0.09596276, 0.09900636, 0.10213947,\n",
       "                     0.10509355, 0.11270253, 0.11413481, 0.11699937, 0.11887924,\n",
       "                     0.12138573, 0.12353415, 0.12675678, 0.12845761, 0.12988989,\n",
       "                     0.13060603, 0.13293349, 0.13463432, 0.13570853, 0.13848357,\n",
       "                     0.14099006, 0.14609256, 0.14815146, 0.16220571, 0.16802435,\n",
       "                     0.17062036, 0.18422702, 0.18718109, 0.19273118, 0.19461105,\n",
       "                     0.19675947, 0.19863933, 0.20230955, 0.20544266, 0.20857578,\n",
       "                     0.20893385, 0.21045564, 0.2143049 , 0.21716946, 0.23543103,\n",
       "                     0.23740041, 0.24787396, 0.25548295, 0.27893653, 0.28627697,\n",
       "                     0.28824635, 0.29057381, 0.29245367, 0.29343837, 0.29487065,\n",
       "                     0.3135798 , 0.31537015, 0.32136783, 0.32521708, 0.35305702,\n",
       "                     0.36594754, 0.36773789, 0.36988631, 0.38134455, 0.38420911,\n",
       "                     0.3897592 , 0.40649897, 0.4133023 , 0.41607734, 0.41831528,\n",
       "                     0.42153791, 0.42520813, 0.43165339, 0.43183242, 0.43979948,\n",
       "                     0.44749799, 0.47336854, 0.47748635, 0.47936622, 0.4807985 ,\n",
       "                     0.48420016, 0.48670665, 0.48760183, 0.48975025, 0.51588936,\n",
       "                     0.5186644 , 0.52108137, 0.56512398, 0.56601916, 0.56906275,\n",
       "                     0.58061051, 0.5851759 , 0.58732432, 0.58992033, 0.59090502,\n",
       "                     0.59430669, 0.59600752, 0.59806642, 0.59842449, 0.59914063,\n",
       "                     0.60415361, 0.61614896, 0.62107242, 0.62268373, 0.62751768,\n",
       "                     0.62868141, 0.6302032 , 0.63253066, 0.64175096, 0.6439889 ,\n",
       "                     0.64676394, 0.64980754, 0.65016561, 0.65356727, 0.66144481,\n",
       "                     0.66251902, 0.66511503, 0.6660102 , 0.6669949 , 0.67030705,\n",
       "                     0.67236595, 0.67639424, 0.67755796, 0.69322353, 0.69447677,\n",
       "                     0.70011637, 0.70110107, 0.7043237 , 0.70503984, 0.70557694,\n",
       "                     0.70665115, 0.70862054, 0.71578194, 0.71801987, 0.7186465 ,\n",
       "                     0.72133202, 0.72267478, 0.72455465, 0.73037329, 0.73270074,\n",
       "                     0.73431206, 0.73520723, 0.74084684, 0.74093635, 0.74612837,\n",
       "                     0.74675499, 0.75481157, 0.76036165, 0.76089876, 0.76179393,\n",
       "                     0.76295766, 0.76412139, 0.76635932, 0.7672545 , 0.76958195,\n",
       "                     0.7708352 , 0.77405783, 0.78050309, 0.78139826, 0.78193537,\n",
       "                     0.8071793 , 0.80798496, 0.80950676, 0.82490377, 0.82785785,\n",
       "                     0.82920061, 0.83000627, 0.83242324, 0.83448214, 0.83636201,\n",
       "                     0.83788381, 0.85005819, 0.85292275, 0.85623489, 0.85704055,\n",
       "                     0.86026318, 0.86276967, 0.86375436, 0.86429147, 0.86482857,\n",
       "                     0.86724555, 0.87279563, 0.87494405, 0.87574971, 0.88112076,\n",
       "                     0.88264256, 0.8833587 , 0.88828216, 0.89786053, 0.90081461,\n",
       "                     0.90358965, 0.90493241, 0.91272044, 0.91352609, 0.91415272,\n",
       "                     0.91495837, 0.91594307, 0.91755438, 0.92113508, 0.92937069,\n",
       "                     0.93134008, 0.93671113, 0.93733775, 0.9432459 , 0.94432011,\n",
       "                     0.94584191, 0.9468266 , 0.94718467, 0.94799033, 0.94969116,\n",
       "                     0.95076537, 0.95157103, 0.95201862, 0.95219765, 0.95318235,\n",
       "                     0.953988  , 0.95479366, 0.95774774, 0.95819533, 0.96052278,\n",
       "                     0.96437203, 0.96553576, 0.96687852, 0.96759466, 0.96822129,\n",
       "                     0.96893743, 0.9692955 , 0.97144392, 0.97216006, 0.97260764,\n",
       "                     0.97332378, 0.97439799, 0.97511413, 0.97600931, 0.976994  ,\n",
       "                     0.97797869, 0.97923194, 0.97959001, 0.98111181, 0.98120132,\n",
       "                     0.98227553, 0.98245457, 0.98299167, 0.98308119, 0.98451347,\n",
       "                     0.98540865, 0.9856772 , 1.        ]), tpr=array([0.        , 0.08504163, 0.08692149, 0.09247158, 0.09587324,\n",
       "                     0.09909587, 0.10204995, 0.10464596, 0.10697341, 0.11127025,\n",
       "                     0.11502999, 0.12317608, 0.12657775, 0.12980038, 0.13203831,\n",
       "                     0.13570853, 0.13857309, 0.14251186, 0.14439173, 0.1468087 ,\n",
       "                     0.14797243, 0.15119506, 0.15370155, 0.15468624, 0.15853549,\n",
       "                     0.16211619, 0.16874049, 0.17223167, 0.18780772, 0.19470056,\n",
       "                     0.19666995, 0.2092024 , 0.21242503, 0.21734849, 0.22012353,\n",
       "                     0.22218244, 0.22513651, 0.22997046, 0.23498344, 0.23802703,\n",
       "                     0.23892221, 0.24098111, 0.24536747, 0.25002238, 0.26756781,\n",
       "                     0.26900009, 0.27893653, 0.28511324, 0.30982007, 0.31859278,\n",
       "                     0.3217259 , 0.3243219 , 0.3258437 , 0.32682839, 0.32969295,\n",
       "                     0.34858115, 0.35064005, 0.35672724, 0.36209829, 0.38725271,\n",
       "                     0.39853191, 0.40068033, 0.40390296, 0.41571927, 0.41903142,\n",
       "                     0.42368633, 0.43657685, 0.44167935, 0.44373825, 0.44633426,\n",
       "                     0.44946737, 0.45385373, 0.46262644, 0.46316355, 0.47202578,\n",
       "                     0.47918718, 0.50389401, 0.50872796, 0.51177155, 0.51427804,\n",
       "                     0.51830633, 0.52054427, 0.52197655, 0.52403545, 0.55124877,\n",
       "                     0.55375526, 0.55527706, 0.59788739, 0.59878256, 0.60173664,\n",
       "                     0.6122997 , 0.61650703, 0.61847641, 0.62169904, 0.62339987,\n",
       "                     0.62769671, 0.62948706, 0.63163548, 0.63226211, 0.63288873,\n",
       "                     0.63879688, 0.64900188, 0.65329872, 0.65446245, 0.66171336,\n",
       "                     0.66296661, 0.66511503, 0.66735297, 0.67523051, 0.67693134,\n",
       "                     0.6792588 , 0.68221287, 0.6828395 , 0.6854355 , 0.6925969 ,\n",
       "                     0.69402918, 0.69573002, 0.69662519, 0.6976994 , 0.70136962,\n",
       "                     0.70262286, 0.70781488, 0.70969475, 0.72491272, 0.72670307,\n",
       "                     0.73162653, 0.73279026, 0.73619193, 0.73717662, 0.73798228,\n",
       "                     0.73950407, 0.74075732, 0.74693403, 0.74917196, 0.74970907,\n",
       "                     0.75221556, 0.75418494, 0.75561722, 0.76206248, 0.76385283,\n",
       "                     0.76555367, 0.76653836, 0.77217796, 0.77307314, 0.77575866,\n",
       "                     0.77629577, 0.78390475, 0.78820159, 0.78864918, 0.78909677,\n",
       "                     0.79061857, 0.79187181, 0.79482589, 0.79598962, 0.79813804,\n",
       "                     0.79939128, 0.80198729, 0.80843255, 0.8102229 , 0.81076   ,\n",
       "                     0.83609346, 0.83698863, 0.83842091, 0.85390744, 0.85507117,\n",
       "                     0.85587682, 0.85713007, 0.85936801, 0.86071077, 0.86232208,\n",
       "                     0.86482857, 0.87762958, 0.88129979, 0.88577567, 0.88604422,\n",
       "                     0.89043058, 0.892579  , 0.8941008 , 0.89535404, 0.89633873,\n",
       "                     0.89875571, 0.90475338, 0.9069018 , 0.9084236 , 0.91379465,\n",
       "                     0.91522693, 0.9161221 , 0.92077701, 0.93098201, 0.93313043,\n",
       "                     0.9355474 , 0.93635306, 0.94351446, 0.94458867, 0.94494674,\n",
       "                     0.94548384, 0.94637902, 0.94745323, 0.9504073 , 0.95864291,\n",
       "                     0.9606123 , 0.96374541, 0.964193  , 0.96965357, 0.97108585,\n",
       "                     0.97242861, 0.97305523, 0.97332378, 0.97421896, 0.97565124,\n",
       "                     0.976994  , 0.97779966, 0.97833676, 0.9790529 , 0.98030615,\n",
       "                     0.98102229, 0.98111181, 0.98406588, 0.98451347, 0.98603527,\n",
       "                     0.98943693, 0.99015307, 0.99149584, 0.99203294, 0.99221198,\n",
       "                     0.99292812, 0.99310715, 0.99355474, 0.99409184, 0.99427088,\n",
       "                     0.99462895, 0.9948975 , 0.99543461, 0.99579268, 0.99624026,\n",
       "                     0.99650882, 0.99686689, 0.99722496, 0.99803061, 0.99838868,\n",
       "                     0.99874675, 0.99892579, 0.99910482, 0.99928386, 0.99964193,\n",
       "                     0.99991048, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.65200156e-02, -4.72528849e-02,\n",
       "                     -5.12932944e-02, -5.40672213e-02, -5.88405000e-02, -6.66913745e-02,\n",
       "                     -7.41079722e-02, -8.00427077e-02, -9.09717782e-02, -9.43106795e-02,\n",
       "                     -1.00083459e-01, -1.05360516e-01, -1.13328685e-01, -1.15069330e-01,\n",
       "                     -1.17783036e-01, -1.27833372e-01, -1.33531393e-01, -1.38150338e-01,\n",
       "                     -1.43100844e-01, -1.54150680e-01, -1.64303051e-01, -1.67054085e-01,\n",
       "                     -1.70625517e-01, -1.82321557e-01, -1.84571277e-01, -1.86585956e-01,\n",
       "                     -1.97530975e-01, -1.99489360e-01, -2.04794413e-01, -2.11649172e-01,\n",
       "                     -2.23143551e-01, -2.26773319e-01, -2.29574442e-01, -2.31801614e-01,\n",
       "                     -2.41162057e-01, -2.45122458e-01, -2.51314428e-01, -2.57829109e-01,\n",
       "                     -2.62364264e-01, -2.65703166e-01, -2.67062785e-01, -2.68263987e-01,\n",
       "                     -2.70961426e-01, -2.71933715e-01, -2.74076420e-01, -2.76753002e-01,\n",
       "                     -2.87682072e-01, -2.90229845e-01, -2.94799540e-01, -2.96265816e-01,\n",
       "                     -3.02280872e-01, -3.10154928e-01, -3.18453731e-01, -3.21465134e-01,\n",
       "                     -3.30241687e-01, -3.34369186e-01, -3.36472237e-01, -3.40531096e-01,\n",
       "                     -3.45501643e-01, -3.48306694e-01, -3.67724780e-01, -3.74693449e-01,\n",
       "                     -3.78066134e-01, -3.79489622e-01, -3.82044834e-01, -3.87765531e-01,\n",
       "                     -3.90866309e-01, -3.93904286e-01, -3.95895657e-01, -3.98639143e-01,\n",
       "                     -4.05465108e-01, -4.05465108e-01, -4.08826456e-01, -4.13763911e-01,\n",
       "                     -4.17470054e-01, -4.17735201e-01, -4.24883194e-01, -4.28995606e-01,\n",
       "                     -4.41832752e-01, -4.44685821e-01, -4.46287103e-01, -4.48024723e-01,\n",
       "                     -4.50488789e-01, -4.51985124e-01, -4.62623522e-01, -4.66583923e-01,\n",
       "                     -4.70003629e-01, -4.73784352e-01, -4.76339448e-01, -4.80585739e-01,\n",
       "                     -4.92476485e-01, -5.10825624e-01, -5.21296924e-01, -5.23248144e-01,\n",
       "                     -5.30628251e-01, -5.35518236e-01, -5.38996501e-01, -5.38996501e-01,\n",
       "                     -5.46543706e-01, -5.57106376e-01, -5.59615788e-01, -5.70544858e-01,\n",
       "                     -5.75364145e-01, -5.79818495e-01, -5.83146285e-01, -5.87786665e-01,\n",
       "                     -5.97837001e-01, -6.10909082e-01, -6.13104473e-01, -6.14366303e-01,\n",
       "                     -6.19039208e-01, -6.21688217e-01, -6.21919671e-01, -6.28608659e-01,\n",
       "                     -6.39079959e-01, -6.41853886e-01, -6.50587566e-01, -6.55875786e-01,\n",
       "                     -6.56779536e-01, -6.66944808e-01, -6.69049629e-01, -6.93147181e-01,\n",
       "                     -7.17839793e-01, -7.20054633e-01, -7.30887509e-01, -7.31861693e-01,\n",
       "                     -7.37598943e-01, -7.47214402e-01, -7.50305594e-01, -7.62140052e-01,\n",
       "                     -7.69839801e-01, -7.70108222e-01, -7.73189888e-01, -7.78669354e-01,\n",
       "                     -7.80158558e-01, -7.82759339e-01, -7.98507696e-01, -8.10930216e-01,\n",
       "                     -8.16761137e-01, -8.20980552e-01, -8.26678573e-01, -8.32909123e-01,\n",
       "                     -8.47297860e-01, -8.47297860e-01, -8.50653568e-01, -8.64997437e-01,\n",
       "                     -8.75468737e-01, -8.75468737e-01, -8.80358723e-01, -8.87303195e-01,\n",
       "                     -8.97941593e-01, -9.00786545e-01, -9.16290732e-01, -9.44461609e-01,\n",
       "                     -9.63437510e-01, -9.70357953e-01, -9.74559640e-01, -9.80829253e-01,\n",
       "                     -9.86554880e-01, -9.93251773e-01, -1.01160091e+00, -1.01422490e+00,\n",
       "                     -1.01856958e+00, -1.02165125e+00, -1.02450432e+00, -1.02961942e+00,\n",
       "                     -1.05314991e+00, -1.06087196e+00, -1.07451474e+00, -1.07502629e+00,\n",
       "                     -1.08221848e+00, -1.09192330e+00, -1.09861229e+00, -1.09861229e+00,\n",
       "                     -1.11240561e+00, -1.11803037e+00, -1.12214279e+00, -1.12846525e+00,\n",
       "                     -1.13497993e+00, -1.14716551e+00, -1.15267951e+00, -1.15577070e+00,\n",
       "                     -1.16315081e+00, -1.17865500e+00, -1.22377543e+00, -1.23053983e+00,\n",
       "                     -1.24268732e+00, -1.25276297e+00, -1.25804003e+00, -1.26851133e+00,\n",
       "                     -1.29129663e+00, -1.29928298e+00, -1.32175584e+00, -1.34373475e+00,\n",
       "                     -1.36097655e+00, -1.36524095e+00, -1.37868976e+00, -1.38629436e+00,\n",
       "                     -1.41981705e+00, -1.42825856e+00, -1.43508453e+00, -1.43820222e+00,\n",
       "                     -1.44691898e+00, -1.45083288e+00, -1.45528723e+00, -1.46633707e+00,\n",
       "                     -1.48160454e+00, -1.50407740e+00, -1.52605630e+00, -1.54044504e+00,\n",
       "                     -1.57553636e+00, -1.58412010e+00, -1.59504917e+00, -1.60943791e+00,\n",
       "                     -1.60943791e+00, -1.65678403e+00, -1.68639895e+00, -1.71008144e+00,\n",
       "                     -1.71900011e+00, -1.77070606e+00, -1.78058617e+00, -1.79175947e+00,\n",
       "                     -1.79175947e+00, -1.85238409e+00, -1.87180218e+00, -1.88706965e+00,\n",
       "                     -1.94591015e+00, -2.01490302e+00, -2.04769284e+00, -2.07944154e+00,\n",
       "                     -2.12026354e+00, -2.19722458e+00, -2.21920348e+00, -2.23359222e+00,\n",
       "                     -2.30258509e+00, -2.35137526e+00, -2.40794561e+00, -2.44234704e+00,\n",
       "                     -2.56494936e+00, -2.63905733e+00, -2.74084002e+00, -2.86220088e+00,\n",
       "                     -2.99573227e+00, -3.07577498e+00, -3.09104245e+00, -3.45387764e+01]), auc_score=0.5272408982614413, privacy_risk=0.5184406051383046, accuracy=0.5184406051383046, tpr_ind=0.3620982902157372, tnr_ind=0.6747829200608719, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.0572912 , 0.06579536, 0.06883896, 0.07358339,\n",
       "                     0.07832781, 0.07984961, 0.09444096, 0.09560469, 0.09793215,\n",
       "                     0.10017008, 0.10070719, 0.10652583, 0.10706293, 0.11377674,\n",
       "                     0.11646227, 0.11753648, 0.11878972, 0.1247874 , 0.12711485,\n",
       "                     0.12908424, 0.12971086, 0.130427  , 0.13266494, 0.13329156,\n",
       "                     0.14036344, 0.15047892, 0.16838242, 0.1698147 , 0.17178408,\n",
       "                     0.17446961, 0.17706562, 0.18888193, 0.19622236, 0.19854982,\n",
       "                     0.19854982, 0.21645332, 0.21976546, 0.225047  , 0.23256647,\n",
       "                     0.237848  , 0.24671023, 0.29343837, 0.29863038, 0.30113687,\n",
       "                     0.32163638, 0.32360576, 0.32682839, 0.32861874, 0.33801808,\n",
       "                     0.33891326, 0.35323606, 0.35950228, 0.36388864, 0.38841644,\n",
       "                     0.39083341, 0.39163907, 0.42073225, 0.42162743, 0.4219855 ,\n",
       "                     0.42386537, 0.42887835, 0.43263808, 0.43568168, 0.44275356,\n",
       "                     0.44767702, 0.45081013, 0.45251097, 0.45456987, 0.45815057,\n",
       "                     0.46235789, 0.49046639, 0.49163011, 0.50299884, 0.50989168,\n",
       "                     0.51168203, 0.51347238, 0.51687405, 0.5186644 , 0.52054427,\n",
       "                     0.52143944, 0.52403545, 0.52439352, 0.52475159, 0.53817921,\n",
       "                     0.5493689 , 0.55160684, 0.55491899, 0.55948438, 0.56145376,\n",
       "                     0.5672724 , 0.5738967 , 0.57738788, 0.58419121, 0.59242682,\n",
       "                     0.60191567, 0.61050935, 0.61292633, 0.61990869, 0.6209829 ,\n",
       "                     0.64166144, 0.64372035, 0.64586877, 0.65240354, 0.65365679,\n",
       "                     0.65437293, 0.65598424, 0.65777459, 0.66099722, 0.66368275,\n",
       "                     0.66466744, 0.66771104, 0.66878525, 0.66923284, 0.67281354,\n",
       "                     0.67406678, 0.67549906, 0.67630472, 0.67890073, 0.68391371,\n",
       "                     0.68821055, 0.68946379, 0.6900009 , 0.69134366, 0.69787844,\n",
       "                     0.69940023, 0.70101155, 0.70495032, 0.70674067, 0.70906812,\n",
       "                     0.71085847, 0.71130606, 0.71318593, 0.71452869, 0.71515531,\n",
       "                     0.71784084, 0.72007878, 0.72160057, 0.72330141, 0.72509176,\n",
       "                     0.74004118, 0.7401307 , 0.74093635, 0.74460657, 0.74541223,\n",
       "                     0.75015666, 0.75839227, 0.76358428, 0.7687763 , 0.77173037,\n",
       "                     0.77808612, 0.78023454, 0.78112971, 0.78327813, 0.78372572,\n",
       "                     0.78435234, 0.78587414, 0.78685883, 0.79357264, 0.80377764,\n",
       "                     0.80386716, 0.80413571, 0.80601558, 0.80619461, 0.80753737,\n",
       "                     0.80825351, 0.81013338, 0.81084952, 0.81219228, 0.81648912,\n",
       "                     0.82141259, 0.82400859, 0.83645153, 0.83779429, 0.83922657,\n",
       "                     0.83994271, 0.84021126, 0.84200161, 0.84406051, 0.84585086,\n",
       "                     0.84853639, 0.85050577, 0.85220661, 0.85292275, 0.85328082,\n",
       "                     0.85551875, 0.869573  , 0.86975204, 0.87082625, 0.88121028,\n",
       "                     0.88434339, 0.88819264, 0.89293707, 0.89374273, 0.89786053,\n",
       "                     0.89866619, 0.90072509, 0.90108316, 0.91263092, 0.91415272,\n",
       "                     0.91594307, 0.93259332, 0.93465222, 0.93697968, 0.93823292,\n",
       "                     0.93993376, 0.941187  , 0.94978068, 0.94995972, 0.95094441,\n",
       "                     0.95362993, 0.95685256, 0.95846388, 0.95962761, 0.96034375,\n",
       "                     0.96043326, 0.96079133, 0.96589383, 0.96822129, 0.97028019,\n",
       "                     0.97126488, 0.97171247, 0.97260764, 0.97296571, 0.97359234,\n",
       "                     0.97368185, 0.97556172, 0.97574076, 0.97627786, 0.9764569 ,\n",
       "                     0.97771014, 0.97797869, 0.97932146, 0.97941097, 0.97950049,\n",
       "                     0.98030615, 0.98039567, 0.98129084, 0.98191746, 0.98343926,\n",
       "                     0.98388685, 0.98406588, 0.98442395, 1.        ]), tpr=array([0.        , 0.06579536, 0.07617939, 0.07895444, 0.08360935,\n",
       "                     0.08844329, 0.09077075, 0.10437741, 0.10545162, 0.10858473,\n",
       "                     0.11055411, 0.11144929, 0.11717841, 0.11878972, 0.12496643,\n",
       "                     0.12756244, 0.12944231, 0.13060603, 0.13749888, 0.13919971,\n",
       "                     0.14143765, 0.14251186, 0.14358607, 0.14671918, 0.14770388,\n",
       "                     0.15683466, 0.16480172, 0.18386895, 0.18556978, 0.18753916,\n",
       "                     0.19103035, 0.19675947, 0.21000806, 0.21681139, 0.21904932,\n",
       "                     0.21967595, 0.24107063, 0.24518843, 0.25163369, 0.25718378,\n",
       "                     0.26300242, 0.27293886, 0.31537015, 0.32011458, 0.32369528,\n",
       "                     0.34840211, 0.35046102, 0.35431027, 0.3560111 , 0.3667532 ,\n",
       "                     0.36791693, 0.37964372, 0.38886402, 0.39513025, 0.41974756,\n",
       "                     0.42386537, 0.42493958, 0.45806105, 0.4593143 , 0.46011995,\n",
       "                     0.4619103 , 0.46763942, 0.47193626, 0.47641214, 0.48205174,\n",
       "                     0.48688569, 0.4905559 , 0.49189867, 0.49342046, 0.49682213,\n",
       "                     0.50049235, 0.52770567, 0.53021216, 0.53970101, 0.54668338,\n",
       "                     0.54892131, 0.55044311, 0.55429236, 0.55545609, 0.55760451,\n",
       "                     0.5585892 , 0.56136425, 0.5621699 , 0.56279653, 0.57756691,\n",
       "                     0.58777191, 0.59135261, 0.59475427, 0.59869304, 0.59994629,\n",
       "                     0.60352699, 0.61238922, 0.61570137, 0.62232566, 0.63109838,\n",
       "                     0.64121386, 0.64873333, 0.65007609, 0.6552681 , 0.65705845,\n",
       "                     0.67675231, 0.6782741 , 0.68069108, 0.68570406, 0.68794199,\n",
       "                     0.68892669, 0.69098559, 0.69313401, 0.69599857, 0.69841554,\n",
       "                     0.70029541, 0.70477128, 0.70611405, 0.70754633, 0.71264882,\n",
       "                     0.71443917, 0.71542387, 0.71649808, 0.71972071, 0.72562886,\n",
       "                     0.72867246, 0.72965715, 0.73055232, 0.73216364, 0.73672903,\n",
       "                     0.73798228, 0.739146  , 0.74299526, 0.74460657, 0.74666547,\n",
       "                     0.74908245, 0.74953003, 0.7508728 , 0.75257363, 0.75337929,\n",
       "                     0.75516964, 0.75812371, 0.75910841, 0.76098827, 0.762152  ,\n",
       "                     0.77710142, 0.77736998, 0.77844419, 0.78229344, 0.78327813,\n",
       "                     0.78864918, 0.79581058, 0.80198729, 0.8066422 , 0.80888014,\n",
       "                     0.81478829, 0.81711575, 0.8179214 , 0.81980127, 0.82042789,\n",
       "                     0.82257631, 0.82391908, 0.82481425, 0.83099096, 0.83985319,\n",
       "                     0.84021126, 0.84065885, 0.84218065, 0.84271775, 0.84388148,\n",
       "                     0.8445081 , 0.846567  , 0.84737266, 0.84853639, 0.85211709,\n",
       "                     0.85695103, 0.85820428, 0.87181094, 0.87360129, 0.8752126 ,\n",
       "                     0.87592874, 0.87655537, 0.8782562 , 0.88049414, 0.88309014,\n",
       "                     0.88514905, 0.88711843, 0.88971444, 0.8905201 , 0.89087817,\n",
       "                     0.89141527, 0.90538   , 0.90582759, 0.90752842, 0.9176439 ,\n",
       "                     0.92015039, 0.92382061, 0.928386  , 0.92883359, 0.93286187,\n",
       "                     0.9334885 , 0.93483126, 0.9355474 , 0.94378301, 0.94494674,\n",
       "                     0.94646853, 0.95989616, 0.96302927, 0.96481962, 0.96652045,\n",
       "                     0.96848984, 0.96974308, 0.97609883, 0.97627786, 0.97690448,\n",
       "                     0.97869483, 0.9820965 , 0.98290216, 0.98352878, 0.98433444,\n",
       "                     0.98478202, 0.98514009, 0.98889983, 0.99042163, 0.99212246,\n",
       "                     0.99230149, 0.9928386 , 0.99301763, 0.99319667, 0.99355474,\n",
       "                     0.99382329, 0.9948975 , 0.99507654, 0.99534509, 0.99570316,\n",
       "                     0.99650882, 0.99668785, 0.99731447, 0.99740399, 0.99758303,\n",
       "                     0.99785158, 0.9979411 , 0.99901531, 0.99919434, 0.99946289,\n",
       "                     0.99964193, 0.99973145, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.55333020e-02, -3.17486983e-02,\n",
       "                     -3.77403280e-02, -5.40672213e-02, -7.41079722e-02, -7.59859070e-02,\n",
       "                     -8.00427077e-02, -8.22380982e-02, -8.70113770e-02, -9.53101798e-02,\n",
       "                     -1.03796794e-01, -1.05360516e-01, -1.22602322e-01, -1.29211731e-01,\n",
       "                     -1.33531393e-01, -1.43100844e-01, -1.44830948e-01, -1.46603474e-01,\n",
       "                     -1.48420005e-01, -1.54150680e-01, -1.54150680e-01, -1.58224005e-01,\n",
       "                     -1.67054085e-01, -1.70817732e-01, -1.74802724e-01, -1.79971379e-01,\n",
       "                     -1.91055237e-01, -2.04794413e-01, -2.07639365e-01, -2.23143551e-01,\n",
       "                     -2.28534400e-01, -2.33614851e-01, -2.46860078e-01, -2.51314428e-01,\n",
       "                     -2.60108746e-01, -2.65703166e-01, -2.66628663e-01, -2.67314770e-01,\n",
       "                     -2.68263987e-01, -2.74076420e-01, -2.74943047e-01, -2.78203328e-01,\n",
       "                     -2.81412459e-01, -2.87682072e-01, -2.98492989e-01, -2.99242895e-01,\n",
       "                     -3.13657559e-01, -3.18453731e-01, -3.25422400e-01, -3.28809364e-01,\n",
       "                     -3.35084311e-01, -3.36472237e-01, -3.44234242e-01, -3.45745873e-01,\n",
       "                     -3.48306694e-01, -3.51798207e-01, -3.56674944e-01, -3.67724780e-01,\n",
       "                     -3.71563556e-01, -3.73716410e-01, -3.77294231e-01, -3.78436436e-01,\n",
       "                     -3.78653851e-01, -3.80463806e-01, -3.80772496e-01, -3.82992252e-01,\n",
       "                     -3.85662481e-01, -3.87765531e-01, -3.97301797e-01, -4.05465108e-01,\n",
       "                     -4.05465108e-01, -4.11734721e-01, -4.13975798e-01, -4.18710335e-01,\n",
       "                     -4.24883194e-01, -4.28454626e-01, -4.30782916e-01, -4.32864082e-01,\n",
       "                     -4.35318071e-01, -4.37213806e-01, -4.41832752e-01, -4.51985124e-01,\n",
       "                     -4.70003629e-01, -4.73287704e-01, -4.85507816e-01, -4.89548225e-01,\n",
       "                     -4.92476485e-01, -4.96436886e-01, -5.00775288e-01, -5.10825624e-01,\n",
       "                     -5.16216472e-01, -5.32216814e-01, -5.33026334e-01, -5.35302370e-01,\n",
       "                     -5.38996501e-01, -5.50046337e-01, -5.54677506e-01, -5.59615788e-01,\n",
       "                     -5.64797147e-01, -5.67984038e-01, -5.75364145e-01, -5.79818495e-01,\n",
       "                     -5.87786665e-01, -5.97837001e-01, -6.02175402e-01, -6.06135804e-01,\n",
       "                     -6.11801541e-01, -6.16186139e-01, -6.19039208e-01, -6.20576488e-01,\n",
       "                     -6.24154309e-01, -6.28608659e-01, -6.39079959e-01, -6.41853886e-01,\n",
       "                     -6.46627165e-01, -6.50587566e-01, -6.64976304e-01, -6.93147181e-01,\n",
       "                     -7.22134717e-01, -7.37598943e-01, -7.41937345e-01, -7.47214402e-01,\n",
       "                     -7.50305594e-01, -7.62140052e-01, -7.67255153e-01, -7.71399377e-01,\n",
       "                     -7.73189888e-01, -7.76528789e-01, -7.81700578e-01, -7.88457360e-01,\n",
       "                     -7.88457360e-01, -7.93230639e-01, -7.98507696e-01, -8.10930216e-01,\n",
       "                     -8.20980552e-01, -8.20980552e-01, -8.26678573e-01, -8.36248024e-01,\n",
       "                     -8.40430881e-01, -8.47297860e-01, -8.47297860e-01, -8.53920401e-01,\n",
       "                     -8.60201265e-01, -8.75468737e-01, -8.80663554e-01, -8.83887308e-01,\n",
       "                     -8.85038188e-01, -9.08258560e-01, -9.16290732e-01, -9.31558204e-01,\n",
       "                     -9.38269639e-01, -9.44461609e-01, -9.44461609e-01, -9.49080555e-01,\n",
       "                     -9.55511445e-01, -9.55511445e-01, -9.75379648e-01, -9.80829253e-01,\n",
       "                     -1.01160091e+00, -1.02961942e+00, -1.03798767e+00, -1.04145387e+00,\n",
       "                     -1.04596856e+00, -1.04982212e+00, -1.05416053e+00, -1.06087196e+00,\n",
       "                     -1.07263680e+00, -1.08180517e+00, -1.08618977e+00, -1.09861229e+00,\n",
       "                     -1.09861229e+00, -1.11514159e+00, -1.13497993e+00, -1.13943428e+00,\n",
       "                     -1.14513230e+00, -1.14990558e+00, -1.15057203e+00, -1.15449275e+00,\n",
       "                     -1.15496523e+00, -1.15745279e+00, -1.16530366e+00, -1.17007125e+00,\n",
       "                     -1.17865500e+00, -1.20397280e+00, -1.21544521e+00, -1.22377543e+00,\n",
       "                     -1.22994829e+00, -1.23361752e+00, -1.25276297e+00, -1.25624123e+00,\n",
       "                     -1.27218105e+00, -1.28093385e+00, -1.29928298e+00, -1.31218639e+00,\n",
       "                     -1.35239281e+00, -1.35454566e+00, -1.38629436e+00, -1.40534256e+00,\n",
       "                     -1.41528190e+00, -1.42551507e+00, -1.42825856e+00, -1.44691898e+00,\n",
       "                     -1.45001018e+00, -1.45225233e+00, -1.45528723e+00, -1.47389242e+00,\n",
       "                     -1.50407740e+00, -1.51982575e+00, -1.56861592e+00, -1.58816051e+00,\n",
       "                     -1.60943791e+00, -1.60943791e+00, -1.67397643e+00, -1.68639895e+00,\n",
       "                     -1.74919985e+00, -1.80359393e+00, -1.83022575e+00, -1.85135157e+00,\n",
       "                     -1.87180218e+00, -1.92181260e+00, -1.94591015e+00, -1.94591015e+00,\n",
       "                     -1.98100147e+00, -1.99243016e+00, -2.00372972e+00, -2.01490302e+00,\n",
       "                     -2.07944154e+00, -2.11021320e+00, -2.15948425e+00, -2.30258509e+00,\n",
       "                     -2.31676973e+00, -2.39789527e+00, -2.48490665e+00, -2.53897387e+00,\n",
       "                     -2.56494936e+00, -2.61495978e+00, -2.63905733e+00, -2.94443898e+00,\n",
       "                     -3.29583687e+00, -3.46573590e+00, -3.68051120e+00, -3.45387764e+01]), auc_score=0.5285484339401674, privacy_risk=0.5208575776564318, accuracy=0.5208575776564318, tpr_ind=0.7256288604422164, tnr_ind=0.3160862948706472, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.05129353, 0.05308388, 0.09372482, 0.09488855,\n",
       "                     0.09578373, 0.0982007 , 0.0997225 , 0.1023185 , 0.10366127,\n",
       "                     0.10786859, 0.11449288, 0.1217438 , 0.12398174, 0.12774147,\n",
       "                     0.12953182, 0.13212783, 0.1381255 , 0.14027392, 0.14331752,\n",
       "                     0.14510787, 0.14600304, 0.16489124, 0.16883001, 0.17402202,\n",
       "                     0.17706562, 0.1784979 , 0.18476412, 0.18968758, 0.19219407,\n",
       "                     0.19944499, 0.20472652, 0.20696446, 0.20902336, 0.21018709,\n",
       "                     0.21833318, 0.2199445 , 0.22979142, 0.23766896, 0.25324501,\n",
       "                     0.25960075, 0.27275982, 0.28001074, 0.2956763 , 0.29827231,\n",
       "                     0.30274819, 0.30543371, 0.30686599, 0.31921941, 0.3237848 ,\n",
       "                     0.32727598, 0.33228896, 0.33407931, 0.33945036, 0.34508997,\n",
       "                     0.35592158, 0.36003939, 0.36344105, 0.37087101, 0.37767434,\n",
       "                     0.3795542 , 0.38125504, 0.38403008, 0.38555188, 0.39119148,\n",
       "                     0.40282875, 0.40730463, 0.41267568, 0.41491362, 0.41876287,\n",
       "                     0.42189598, 0.4347865 , 0.43747203, 0.44642378, 0.45412228,\n",
       "                     0.46405872, 0.46692328, 0.4690717 , 0.48088801, 0.48205174,\n",
       "                     0.48384209, 0.48581148, 0.48957121, 0.49386805, 0.4956584 ,\n",
       "                     0.51705308, 0.52403545, 0.5273476 , 0.53030167, 0.53191299,\n",
       "                     0.53325575, 0.53683645, 0.5508907 , 0.56458688, 0.57962582,\n",
       "                     0.60648107, 0.61265777, 0.61928207, 0.62357891, 0.62590636,\n",
       "                     0.62617492, 0.62635395, 0.62751768, 0.62939755, 0.63351535,\n",
       "                     0.63539522, 0.63772267, 0.64953898, 0.65329872, 0.66028108,\n",
       "                     0.66099722, 0.66207143, 0.66690538, 0.67442485, 0.67639424,\n",
       "                     0.67764748, 0.68015397, 0.6828395 , 0.68427178, 0.70378659,\n",
       "                     0.70530839, 0.7079044 , 0.70942619, 0.71014233, 0.7120222 ,\n",
       "                     0.72007878, 0.72303285, 0.72410706, 0.72464417, 0.72903053,\n",
       "                     0.72974667, 0.7314475 , 0.73851938, 0.74030973, 0.74227912,\n",
       "                     0.74532271, 0.74738161, 0.74854534, 0.74908245, 0.74970907,\n",
       "                     0.75033569, 0.75096231, 0.75561722, 0.75901889, 0.76080924,\n",
       "                     0.77602721, 0.78399427, 0.79142422, 0.80073404, 0.80261391,\n",
       "                     0.80350909, 0.80476233, 0.80556799, 0.80646316, 0.81013338,\n",
       "                     0.82427715, 0.82472473, 0.82767881, 0.82955868, 0.83063289,\n",
       "                     0.83206517, 0.83251276, 0.83985319, 0.84056933, 0.84200161,\n",
       "                     0.84549279, 0.84970012, 0.85345985, 0.85865187, 0.86420195,\n",
       "                     0.86643989, 0.86831976, 0.87002059, 0.87234804, 0.87431743,\n",
       "                     0.87762958, 0.87906186, 0.87941993, 0.88013607, 0.88156835,\n",
       "                     0.88210545, 0.88452242, 0.88765554, 0.88980396, 0.89239996,\n",
       "                     0.89562259, 0.89839764, 0.90144123, 0.90314206, 0.9048429 ,\n",
       "                     0.90708083, 0.9089607 , 0.91325754, 0.91397368, 0.91477934,\n",
       "                     0.91567451, 0.91683824, 0.92552144, 0.92946021, 0.93563692,\n",
       "                     0.93832244, 0.94261928, 0.94530481, 0.94736371, 0.9478113 ,\n",
       "                     0.95049682, 0.95067586, 0.95112344, 0.95121296, 0.95362993,\n",
       "                     0.9549727 , 0.95622594, 0.95846388, 0.95971712, 0.96043326,\n",
       "                     0.96079133, 0.96159699, 0.96249217, 0.96669949, 0.96678901,\n",
       "                     0.96750515, 0.96768418, 0.96965357, 0.97090681, 0.97278668,\n",
       "                     0.97296571, 0.97305523, 0.97421896, 0.9754722 , 0.97753111,\n",
       "                     0.97833676, 0.97887387, 0.9790529 , 0.97932146, 0.9800376 ,\n",
       "                     0.98039567, 0.98093277, 0.98129084, 0.98182795, 0.98460299,\n",
       "                     0.98522961, 1.        ]), tpr=array([0.        , 0.05961866, 0.06149852, 0.10321368, 0.10473548,\n",
       "                     0.10616776, 0.10858473, 0.11037508, 0.11297109, 0.11467192,\n",
       "                     0.11870021, 0.1268463 , 0.13347059, 0.1360666 , 0.14045296,\n",
       "                     0.14224331, 0.14394414, 0.1503894 , 0.15235879, 0.15719273,\n",
       "                     0.1590726 , 0.16086295, 0.17939307, 0.1841375 , 0.19013517,\n",
       "                     0.19308925, 0.19514815, 0.20132486, 0.20624832, 0.21018709,\n",
       "                     0.21672187, 0.2235252 , 0.22674783, 0.22961239, 0.23086563,\n",
       "                     0.23883269, 0.23972787, 0.24733685, 0.25503536, 0.26819443,\n",
       "                     0.27446066, 0.28967863, 0.29854086, 0.31563871, 0.3171605 ,\n",
       "                     0.32190493, 0.32539611, 0.32763405, 0.34141975, 0.34750694,\n",
       "                     0.35162474, 0.35690628, 0.36048698, 0.36684272, 0.37310894,\n",
       "                     0.38215021, 0.38537284, 0.38949065, 0.3984424 , 0.40569331,\n",
       "                     0.40721511, 0.40828932, 0.4112434 , 0.41249664, 0.41804673,\n",
       "                     0.42932593, 0.43433891, 0.44051562, 0.44284308, 0.44651329,\n",
       "                     0.44955689, 0.46352162, 0.46799749, 0.4741742 , 0.48240981,\n",
       "                     0.49019783, 0.49261481, 0.49485274, 0.5094441 , 0.51042879,\n",
       "                     0.5120401 , 0.51472563, 0.5186644 , 0.52305076, 0.52475159,\n",
       "                     0.54659386, 0.55438188, 0.55635127, 0.55876824, 0.56055859,\n",
       "                     0.56199087, 0.56592964, 0.57873064, 0.59269537, 0.60621251,\n",
       "                     0.63029272, 0.6337839 , 0.63933399, 0.64461552, 0.64640587,\n",
       "                     0.64765912, 0.64828574, 0.6496285 , 0.65249306, 0.65687942,\n",
       "                     0.65893832, 0.66117626, 0.67236595, 0.67558858, 0.68122818,\n",
       "                     0.68248143, 0.68391371, 0.68838958, 0.6961776 , 0.69805747,\n",
       "                     0.69904216, 0.70145914, 0.70414466, 0.70620356, 0.72392803,\n",
       "                     0.72589741, 0.7284039 , 0.73064184, 0.73153702, 0.73323785,\n",
       "                     0.74022021, 0.74415898, 0.74541223, 0.74648644, 0.75123087,\n",
       "                     0.75212604, 0.75391639, 0.76295766, 0.76474801, 0.76635932,\n",
       "                     0.76967147, 0.77074568, 0.77181989, 0.77280458, 0.77325217,\n",
       "                     0.77414735, 0.77540059, 0.77907081, 0.78292006, 0.78533703,\n",
       "                     0.80189777, 0.81111807, 0.82042789, 0.82875302, 0.83125951,\n",
       "                     0.83215469, 0.8332289 , 0.83466118, 0.8358249 , 0.8403903 ,\n",
       "                     0.8531913 , 0.85417599, 0.85668248, 0.85892042, 0.86044222,\n",
       "                     0.86133739, 0.8618745 , 0.869573  , 0.87073673, 0.87198997,\n",
       "                     0.87601826, 0.88022558, 0.8833587 , 0.88559663, 0.892579  ,\n",
       "                     0.89401128, 0.89571211, 0.89678632, 0.89956136, 0.9017993 ,\n",
       "                     0.90681228, 0.90922925, 0.90976636, 0.9110196 , 0.91146719,\n",
       "                     0.91209381, 0.91504789, 0.91862859, 0.92023991, 0.92149315,\n",
       "                     0.92498433, 0.92740131, 0.92981828, 0.93116104, 0.93313043,\n",
       "                     0.93465222, 0.93689016, 0.94190314, 0.9427088 , 0.94396204,\n",
       "                     0.94566288, 0.94619998, 0.9519291 , 0.95488318, 0.95989616,\n",
       "                     0.96195506, 0.96616238, 0.96857936, 0.97090681, 0.97117536,\n",
       "                     0.97350282, 0.97386089, 0.97466655, 0.97556172, 0.97744159,\n",
       "                     0.97914242, 0.98012711, 0.98129084, 0.98272312, 0.98317071,\n",
       "                     0.98379733, 0.98505058, 0.98603527, 0.989795  , 0.98988452,\n",
       "                     0.99015307, 0.99051114, 0.99140632, 0.99176439, 0.9928386 ,\n",
       "                     0.99310715, 0.9933757 , 0.99400233, 0.9943604 , 0.99516605,\n",
       "                     0.99615075, 0.99650882, 0.99659833, 0.99677737, 0.99704592,\n",
       "                     0.99722496, 0.99740399, 0.99749351, 0.99758303, 0.99991048,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.65200156e-02, -5.42930824e-02,\n",
       "                     -5.71584138e-02, -6.06246218e-02, -7.14589640e-02, -9.53101798e-02,\n",
       "                     -9.84400728e-02, -1.00083459e-01, -1.05360516e-01, -1.14113307e-01,\n",
       "                     -1.14775515e-01, -1.29211731e-01, -1.33531393e-01, -1.39761942e-01,\n",
       "                     -1.46603474e-01, -1.54150680e-01, -1.67054085e-01, -1.69899037e-01,\n",
       "                     -1.74353387e-01, -1.82321557e-01, -1.84734103e-01, -1.88591170e-01,\n",
       "                     -1.89756535e-01, -1.92371893e-01, -1.96710294e-01, -2.08544752e-01,\n",
       "                     -2.12174520e-01, -2.23143551e-01, -2.31329136e-01, -2.43977638e-01,\n",
       "                     -2.45122458e-01, -2.47836164e-01, -2.51314428e-01, -2.56295759e-01,\n",
       "                     -2.62364264e-01, -2.66878945e-01, -2.73040522e-01, -2.77425572e-01,\n",
       "                     -2.84104251e-01, -2.84736562e-01, -2.87682072e-01, -2.88990117e-01,\n",
       "                     -3.02280872e-01, -3.06374205e-01, -3.06730267e-01, -3.07484700e-01,\n",
       "                     -3.10154928e-01, -3.13091788e-01, -3.14493330e-01, -3.16911711e-01,\n",
       "                     -3.18453731e-01, -3.22287602e-01, -3.26215736e-01, -3.26521906e-01,\n",
       "                     -3.28504067e-01, -3.30241687e-01, -3.36472237e-01, -3.41749294e-01,\n",
       "                     -3.44840486e-01, -3.48306694e-01, -3.53640040e-01, -3.56674944e-01,\n",
       "                     -3.61501985e-01, -3.67724780e-01, -3.69097464e-01, -3.71063681e-01,\n",
       "                     -3.79489622e-01, -3.80772496e-01, -3.85662481e-01, -4.05465108e-01,\n",
       "                     -4.05465108e-01, -4.10284395e-01, -4.12685356e-01, -4.16893804e-01,\n",
       "                     -4.17735201e-01, -4.18710335e-01, -4.23702696e-01, -4.35318071e-01,\n",
       "                     -4.41832752e-01, -4.48950220e-01, -4.49916871e-01, -4.51985124e-01,\n",
       "                     -4.56758402e-01, -4.61256468e-01, -4.61345567e-01, -4.64305608e-01,\n",
       "                     -4.65363250e-01, -4.70003629e-01, -4.85507816e-01, -4.92476485e-01,\n",
       "                     -5.00987175e-01, -5.10825624e-01, -5.20054430e-01, -5.23385818e-01,\n",
       "                     -5.26093096e-01, -5.26825965e-01, -5.27632742e-01, -5.30628251e-01,\n",
       "                     -5.38996501e-01, -5.38996501e-01, -5.50046337e-01, -5.59615788e-01,\n",
       "                     -5.62526998e-01, -5.78077851e-01, -5.87786665e-01, -5.92221262e-01,\n",
       "                     -6.06135804e-01, -6.10455465e-01, -6.19039208e-01, -6.28608659e-01,\n",
       "                     -6.31271777e-01, -6.40037355e-01, -6.44357016e-01, -6.46627165e-01,\n",
       "                     -6.55406853e-01, -6.59245629e-01, -6.71168274e-01, -6.93147181e-01,\n",
       "                     -7.15620036e-01, -7.28238500e-01, -7.32367894e-01, -7.41937345e-01,\n",
       "                     -7.44440475e-01, -7.49236647e-01, -7.59105148e-01, -7.62140052e-01,\n",
       "                     -7.73189888e-01, -7.83298278e-01, -7.88457360e-01, -7.88457360e-01,\n",
       "                     -8.05414482e-01, -8.10930216e-01, -8.23200309e-01, -8.43429384e-01,\n",
       "                     -8.47297860e-01, -8.47297860e-01, -8.60201265e-01, -8.75468737e-01,\n",
       "                     -8.75468737e-01, -8.87303195e-01, -8.91598119e-01, -8.92760234e-01,\n",
       "                     -8.93817876e-01, -8.97741373e-01, -9.02605279e-01, -9.16290732e-01,\n",
       "                     -9.31232312e-01, -9.44461609e-01, -9.55511445e-01, -9.80829253e-01,\n",
       "                     -9.88611393e-01, -9.90398704e-01, -9.95428052e-01, -9.95580063e-01,\n",
       "                     -1.00330211e+00, -1.01160091e+00, -1.01523068e+00, -1.01693426e+00,\n",
       "                     -1.02961942e+00, -1.04145387e+00, -1.06310560e+00, -1.07263680e+00,\n",
       "                     -1.07451474e+00, -1.07613943e+00, -1.08432633e+00, -1.08904284e+00,\n",
       "                     -1.09861229e+00, -1.09861229e+00, -1.13943428e+00, -1.14990558e+00,\n",
       "                     -1.15267951e+00, -1.17118298e+00, -1.17557333e+00, -1.17865500e+00,\n",
       "                     -1.19279950e+00, -1.20397280e+00, -1.21109027e+00, -1.22377543e+00,\n",
       "                     -1.23214368e+00, -1.23969089e+00, -1.25276297e+00, -1.26851133e+00,\n",
       "                     -1.27296568e+00, -1.27808078e+00, -1.27887411e+00, -1.28913061e+00,\n",
       "                     -1.29928298e+00, -1.30340670e+00, -1.30992138e+00, -1.31372367e+00,\n",
       "                     -1.32175584e+00, -1.32913595e+00, -1.33123458e+00, -1.33222714e+00,\n",
       "                     -1.34373475e+00, -1.38238046e+00, -1.38629436e+00, -1.39518331e+00,\n",
       "                     -1.39710528e+00, -1.41771056e+00, -1.43155095e+00, -1.45143366e+00,\n",
       "                     -1.46633707e+00, -1.48683559e+00, -1.50407740e+00, -1.51634749e+00,\n",
       "                     -1.52605630e+00, -1.53018854e+00, -1.57734960e+00, -1.60943791e+00,\n",
       "                     -1.65455835e+00, -1.67006253e+00, -1.72276660e+00, -1.74296931e+00,\n",
       "                     -1.75539183e+00, -1.76098781e+00, -1.77978328e+00, -1.79175947e+00,\n",
       "                     -1.79175947e+00, -1.83258146e+00, -1.85629799e+00, -1.87180218e+00,\n",
       "                     -1.94591015e+00, -1.99243016e+00, -2.03688193e+00, -2.07944154e+00,\n",
       "                     -2.11021320e+00, -2.22161603e+00, -2.22707754e+00, -2.30258509e+00,\n",
       "                     -2.30258509e+00, -2.35137526e+00, -2.36712361e+00, -2.39789527e+00,\n",
       "                     -2.67414865e+00, -2.83321334e+00, -2.89037176e+00, -2.94038218e+00,\n",
       "                     -3.09104245e+00, -3.45387764e+01]), auc_score=0.5216698462033886, privacy_risk=0.515486527616149, accuracy=0.515486527616149, tpr_ind=0.9186285918897145, tnr_ind=0.11234446334258348, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.07206159, 0.07600036, 0.081819  , 0.08325128,\n",
       "                     0.08701101, 0.0910393 , 0.10151285, 0.10258706, 0.10312416,\n",
       "                     0.10491451, 0.11001701, 0.11315012, 0.11350819, 0.11619372,\n",
       "                     0.12801003, 0.1289052 , 0.12980038, 0.13239638, 0.15692418,\n",
       "                     0.15871453, 0.1626533 , 0.16533882, 0.16596545, 0.17106794,\n",
       "                     0.17742369, 0.19174649, 0.19783368, 0.2143049 , 0.21824367,\n",
       "                     0.21940739, 0.22307761, 0.22728493, 0.23202936, 0.23462537,\n",
       "                     0.2363262 , 0.26425566, 0.26461373, 0.26891057, 0.27553487,\n",
       "                     0.28368096, 0.29102139, 0.29979411, 0.30695551, 0.31698147,\n",
       "                     0.32297914, 0.32396383, 0.32450094, 0.32467997, 0.32843971,\n",
       "                     0.33649629, 0.34303106, 0.35377316, 0.35520544, 0.3560111 ,\n",
       "                     0.36639513, 0.38761078, 0.38922209, 0.40148599, 0.41079581,\n",
       "                     0.41222809, 0.41795721, 0.42359681, 0.427088  , 0.4332647 ,\n",
       "                     0.43639782, 0.44132128, 0.44239549, 0.47865008, 0.48187271,\n",
       "                     0.49064542, 0.49297288, 0.49968669, 0.50093993, 0.51400949,\n",
       "                     0.51776922, 0.51964909, 0.52099185, 0.53110733, 0.53970101,\n",
       "                     0.54077522, 0.54677289, 0.54766807, 0.55357622, 0.55509802,\n",
       "                     0.56172232, 0.56440784, 0.57067407, 0.57506042, 0.58150568,\n",
       "                     0.58338555, 0.58481783, 0.58598156, 0.60173664, 0.60800286,\n",
       "                     0.61274729, 0.61749172, 0.61883448, 0.62268373, 0.62438457,\n",
       "                     0.62859189, 0.63181452, 0.63244114, 0.63843881, 0.64443649,\n",
       "                     0.64882284, 0.65061319, 0.65616328, 0.65947543, 0.66278757,\n",
       "                     0.66502551, 0.66609972, 0.66681586, 0.66842718, 0.6711127 ,\n",
       "                     0.67200788, 0.67335064, 0.6741563 , 0.67594665, 0.67782652,\n",
       "                     0.6797959 , 0.68713634, 0.68785248, 0.68910572, 0.69295497,\n",
       "                     0.69644616, 0.69707278, 0.69814699, 0.69904216, 0.700743  ,\n",
       "                     0.70154865, 0.70360756, 0.70450273, 0.70763584, 0.7105004 ,\n",
       "                     0.71094799, 0.71175365, 0.7212425 , 0.72294334, 0.72562886,\n",
       "                     0.72858294, 0.73332737, 0.73377495, 0.73413302, 0.73619193,\n",
       "                     0.73986214, 0.74075732, 0.74389043, 0.74469609, 0.74675499,\n",
       "                     0.75194701, 0.75454301, 0.76340525, 0.76474801, 0.76591174,\n",
       "                     0.76653836, 0.77047713, 0.77378928, 0.77584818, 0.77772805,\n",
       "                     0.78130875, 0.7836362 , 0.78793304, 0.78990243, 0.79187181,\n",
       "                     0.79276699, 0.79876466, 0.80449378, 0.80610509, 0.80726882,\n",
       "                     0.80861158, 0.81460926, 0.81648912, 0.81881658, 0.82159162,\n",
       "                     0.82615701, 0.82830543, 0.84558231, 0.84629845, 0.8480888 ,\n",
       "                     0.84826784, 0.85157998, 0.85354937, 0.85533972, 0.85811476,\n",
       "                     0.85918897, 0.86357533, 0.86697699, 0.86724555, 0.86760362,\n",
       "                     0.88210545, 0.88711843, 0.88855071, 0.88864023, 0.89320562,\n",
       "                     0.89607018, 0.89839764, 0.89982992, 0.9002775 , 0.90081461,\n",
       "                     0.9012622 , 0.9038582 , 0.90761794, 0.90976636, 0.91272044,\n",
       "                     0.91683824, 0.91961328, 0.92310447, 0.92462626, 0.92596903,\n",
       "                     0.93393608, 0.93474174, 0.93653209, 0.93850148, 0.9396652 ,\n",
       "                     0.94208218, 0.9427088 , 0.94432011, 0.95130248, 0.95309283,\n",
       "                     0.95747919, 0.95971712, 0.96097037, 0.96141796, 0.96141796,\n",
       "                     0.96168651, 0.96240265, 0.9626712 , 0.96356638, 0.97001164,\n",
       "                     0.97054874, 0.97063826, 0.97126488, 0.97180199, 0.97395041,\n",
       "                     0.97457703, 0.9749351 , 0.9754722 , 0.97717304, 0.97717304,\n",
       "                     0.97771014, 0.97771014, 0.97815773, 0.97869483, 0.98030615,\n",
       "                     0.98075374, 0.98093277, 0.98173843, 1.        ]), tpr=array([0.        , 0.0808343 , 0.08665294, 0.09238206, 0.09426193,\n",
       "                     0.09891684, 0.10321368, 0.11225495, 0.11323964, 0.11413481,\n",
       "                     0.11574613, 0.1232656 , 0.12621968, 0.1268463 , 0.12863665,\n",
       "                     0.13857309, 0.13973682, 0.14081103, 0.14394414, 0.17223167,\n",
       "                     0.17455913, 0.17858741, 0.18118342, 0.18198908, 0.1877182 ,\n",
       "                     0.19255214, 0.20597977, 0.21287262, 0.2312237 , 0.23543103,\n",
       "                     0.23731089, 0.24259243, 0.24662071, 0.2521708 , 0.25646764,\n",
       "                     0.25879509, 0.28457613, 0.28627697, 0.29039477, 0.29898845,\n",
       "                     0.30802972, 0.31680243, 0.32602274, 0.33228896, 0.34285203,\n",
       "                     0.34902874, 0.35081909, 0.35180378, 0.35251992, 0.35627965,\n",
       "                     0.3646943 , 0.37105004, 0.38232925, 0.38367201, 0.38519381,\n",
       "                     0.3969206 , 0.41947901, 0.42135888, 0.43093725, 0.43997852,\n",
       "                     0.4414108 , 0.44812461, 0.45251097, 0.45644974, 0.46271596,\n",
       "                     0.46522245, 0.46978784, 0.47166771, 0.50828037, 0.51230866,\n",
       "                     0.52358786, 0.52752663, 0.53182347, 0.53370334, 0.54632531,\n",
       "                     0.55035359, 0.55286008, 0.55527706, 0.56557157, 0.5744338 ,\n",
       "                     0.57613463, 0.58025244, 0.58177424, 0.58965178, 0.59251634,\n",
       "                     0.59878256, 0.60200519, 0.60639155, 0.61104646, 0.61838689,\n",
       "                     0.62053531, 0.62295229, 0.62393698, 0.6404082 , 0.64801719,\n",
       "                     0.65365679, 0.65786411, 0.65902784, 0.66278757, 0.66413034,\n",
       "                     0.6685167 , 0.67173933, 0.67254498, 0.67746845, 0.68212336,\n",
       "                     0.68516695, 0.6869573 , 0.69420822, 0.6956405 , 0.69993734,\n",
       "                     0.70163817, 0.7028019 , 0.70405514, 0.70539791, 0.70745681,\n",
       "                     0.70888909, 0.71041089, 0.71121654, 0.71390207, 0.71685615,\n",
       "                     0.71936264, 0.72849342, 0.72965715, 0.73082088, 0.7335064 ,\n",
       "                     0.73592337, 0.73663951, 0.73798228, 0.73923552, 0.74102587,\n",
       "                     0.7421896 , 0.74326381, 0.7442485 , 0.74568078, 0.74881389,\n",
       "                     0.74926148, 0.75042521, 0.75624385, 0.75767613, 0.7600931 ,\n",
       "                     0.76376332, 0.76761257, 0.76823919, 0.7687763 , 0.77065616,\n",
       "                     0.77387879, 0.77486349, 0.77754901, 0.77835467, 0.78121923,\n",
       "                     0.78497896, 0.78999194, 0.80064453, 0.80127115, 0.80279295,\n",
       "                     0.80413571, 0.8087011 , 0.81156566, 0.81425119, 0.81622057,\n",
       "                     0.81998031, 0.82168114, 0.82633605, 0.82723122, 0.8296482 ,\n",
       "                     0.83063289, 0.83573539, 0.84164354, 0.8429863 , 0.84432907,\n",
       "                     0.84647749, 0.85310178, 0.85408647, 0.85632441, 0.8582938 ,\n",
       "                     0.8639334 , 0.86590278, 0.88371677, 0.88461194, 0.88676036,\n",
       "                     0.88792409, 0.89078865, 0.892579  , 0.89454838, 0.89750246,\n",
       "                     0.89812908, 0.90206785, 0.90618566, 0.90645421, 0.90699132,\n",
       "                     0.91648017, 0.92140363, 0.92203026, 0.92256736, 0.92704324,\n",
       "                     0.92954973, 0.93286187, 0.93429415, 0.93456271, 0.93492078,\n",
       "                     0.9355474 , 0.93769582, 0.94136604, 0.94351446, 0.94664757,\n",
       "                     0.94960165, 0.95264524, 0.9555098 , 0.95685256, 0.95738967,\n",
       "                     0.96544624, 0.96616238, 0.96741563, 0.96902694, 0.97019067,\n",
       "                     0.97171247, 0.97224957, 0.9734133 , 0.97842628, 0.98030615,\n",
       "                     0.98388685, 0.98514009, 0.98648286, 0.98657237, 0.98675141,\n",
       "                     0.98728851, 0.98800465, 0.98809417, 0.98854176, 0.99373377,\n",
       "                     0.99427088, 0.9943604 , 0.99444991, 0.99462895, 0.99615075,\n",
       "                     0.9964193 , 0.99650882, 0.99686689, 0.99776206, 0.99785158,\n",
       "                     0.9979411 , 0.99812013, 0.99892579, 0.99928386, 0.99955241,\n",
       "                     0.99964193, 0.99991048, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.52674721e-02, -4.58095360e-02,\n",
       "                     -4.65200156e-02, -5.60894667e-02, -8.00427077e-02, -8.53598490e-02,\n",
       "                     -8.70113770e-02, -9.53101798e-02, -1.05360516e-01, -1.12477983e-01,\n",
       "                     -1.14410351e-01, -1.33531393e-01, -1.39761942e-01, -1.42500063e-01,\n",
       "                     -1.43100844e-01, -1.54150680e-01, -1.58224005e-01, -1.68513584e-01,\n",
       "                     -1.75890666e-01, -1.82321557e-01, -1.88052232e-01, -2.00670695e-01,\n",
       "                     -2.23143551e-01, -2.30523659e-01, -2.36388778e-01, -2.41162057e-01,\n",
       "                     -2.41510428e-01, -2.44196961e-01, -2.51314428e-01, -2.53195896e-01,\n",
       "                     -2.53780521e-01, -2.54892250e-01, -2.55933374e-01, -2.68263987e-01,\n",
       "                     -2.71933715e-01, -2.74436846e-01, -2.82232468e-01, -2.87682072e-01,\n",
       "                     -2.90154262e-01, -2.90229845e-01, -2.92524697e-01, -2.94799540e-01,\n",
       "                     -2.98219578e-01, -2.98492989e-01, -3.00104592e-01, -3.10154928e-01,\n",
       "                     -3.18453731e-01, -3.22773392e-01, -3.31902541e-01, -3.32439973e-01,\n",
       "                     -3.34202088e-01, -3.36472237e-01, -3.44840486e-01, -3.50549351e-01,\n",
       "                     -3.51103899e-01, -3.56674944e-01, -3.57609087e-01, -3.61613226e-01,\n",
       "                     -3.62905494e-01, -3.64643114e-01, -3.70859579e-01, -3.74693449e-01,\n",
       "                     -3.76477571e-01, -3.81367557e-01, -3.85662481e-01, -3.89464767e-01,\n",
       "                     -3.96459726e-01, -3.98030130e-01, -4.05465108e-01, -4.05465108e-01,\n",
       "                     -4.19258430e-01, -4.21213465e-01, -4.21878138e-01, -4.27444015e-01,\n",
       "                     -4.28995606e-01, -4.41832752e-01, -4.53564903e-01, -4.54736157e-01,\n",
       "                     -4.56758402e-01, -4.61818045e-01, -4.62623522e-01, -4.64305608e-01,\n",
       "                     -4.66089730e-01, -4.70003629e-01, -4.76924072e-01, -4.77627554e-01,\n",
       "                     -4.79573080e-01, -4.83629881e-01, -4.85507816e-01, -4.88352768e-01,\n",
       "                     -4.92476485e-01, -4.98797048e-01, -5.06108634e-01, -5.10825624e-01,\n",
       "                     -5.19300251e-01, -5.26093096e-01, -5.38996501e-01, -5.50046337e-01,\n",
       "                     -5.50830958e-01, -5.59615788e-01, -5.75364145e-01, -5.77634293e-01,\n",
       "                     -5.81355775e-01, -5.84513340e-01, -5.87786665e-01, -5.89157467e-01,\n",
       "                     -5.94707108e-01, -6.06135804e-01, -6.10909082e-01, -6.13104473e-01,\n",
       "                     -6.19039208e-01, -6.24154309e-01, -6.25705900e-01, -6.28608659e-01,\n",
       "                     -6.32522559e-01, -6.35988767e-01, -6.41853886e-01, -6.46627165e-01,\n",
       "                     -6.56779536e-01, -6.93147181e-01, -7.30887509e-01, -7.30887509e-01,\n",
       "                     -7.41937345e-01, -7.47214402e-01, -7.53771802e-01, -7.57685702e-01,\n",
       "                     -7.62140052e-01, -7.65467842e-01, -7.67255153e-01, -7.73189888e-01,\n",
       "                     -7.80158558e-01, -7.82759339e-01, -7.88457360e-01, -7.88457360e-01,\n",
       "                     -8.02346473e-01, -8.09219352e-01, -8.10930216e-01, -8.15036998e-01,\n",
       "                     -8.19027426e-01, -8.23767363e-01, -8.26678573e-01, -8.47297860e-01,\n",
       "                     -8.47297860e-01, -8.59132318e-01, -8.60201265e-01, -8.75468737e-01,\n",
       "                     -8.93817876e-01, -9.03711950e-01, -9.16290732e-01, -9.23408200e-01,\n",
       "                     -9.34609312e-01, -9.44461609e-01, -9.50976290e-01, -9.55511445e-01,\n",
       "                     -9.58523495e-01, -9.65080896e-01, -9.68250471e-01, -9.69400557e-01,\n",
       "                     -9.80829253e-01, -9.87386654e-01, -9.90398704e-01, -9.93251773e-01,\n",
       "                     -9.94622575e-01, -1.00330211e+00, -1.00680474e+00, -1.00884229e+00,\n",
       "                     -1.02961942e+00, -1.05314991e+00, -1.05605267e+00, -1.06657293e+00,\n",
       "                     -1.06784063e+00, -1.07158362e+00, -1.09861229e+00, -1.09861229e+00,\n",
       "                     -1.11365017e+00, -1.11687006e+00, -1.13140211e+00, -1.13943428e+00,\n",
       "                     -1.14862271e+00, -1.15923691e+00, -1.16315081e+00, -1.17163742e+00,\n",
       "                     -1.18562367e+00, -1.18958407e+00, -1.19254411e+00, -1.20179652e+00,\n",
       "                     -1.20397280e+00, -1.20397280e+00, -1.21709389e+00, -1.21841349e+00,\n",
       "                     -1.23214368e+00, -1.25276297e+00, -1.25846099e+00, -1.26291534e+00,\n",
       "                     -1.26427941e+00, -1.28785429e+00, -1.29928298e+00, -1.32175584e+00,\n",
       "                     -1.34992672e+00, -1.35454566e+00, -1.35533214e+00, -1.36524095e+00,\n",
       "                     -1.37190562e+00, -1.37868976e+00, -1.37891425e+00, -1.38629436e+00,\n",
       "                     -1.40282366e+00, -1.42711636e+00, -1.43508453e+00, -1.44691898e+00,\n",
       "                     -1.48807706e+00, -1.49165488e+00, -1.49549365e+00, -1.49752000e+00,\n",
       "                     -1.50407740e+00, -1.52939520e+00, -1.53916872e+00, -1.54044504e+00,\n",
       "                     -1.55814462e+00, -1.58045038e+00, -1.60943791e+00, -1.60943791e+00,\n",
       "                     -1.70474809e+00, -1.76358859e+00, -1.79175947e+00, -1.79175947e+00,\n",
       "                     -1.82454929e+00, -1.86381279e+00, -1.92181260e+00, -1.94591015e+00,\n",
       "                     -1.94591015e+00, -2.01490302e+00, -2.01881692e+00, -2.03688193e+00,\n",
       "                     -2.07944154e+00, -2.22462355e+00, -2.24070969e+00, -2.30258509e+00,\n",
       "                     -2.30258509e+00, -2.48490665e+00, -2.50325579e+00, -2.56494936e+00,\n",
       "                     -2.90872090e+00, -3.09104245e+00, -3.10608033e+00, -4.18965474e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5273207195687717, privacy_risk=0.5209023364067675, accuracy=0.5209023364067675, tpr_ind=0.7296571479724286, tnr_ind=0.3121475248411064, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.05192015, 0.05702265, 0.07295676, 0.07510518,\n",
       "                     0.07859637, 0.08719005, 0.08996509, 0.09274013, 0.09381434,\n",
       "                     0.09542566, 0.10133381, 0.10348223, 0.10751052, 0.10956942,\n",
       "                     0.1125235 , 0.11592516, 0.13320204, 0.13893116, 0.14278041,\n",
       "                     0.14349655, 0.14421269, 0.17357443, 0.17572285, 0.18145197,\n",
       "                     0.191836  , 0.20947095, 0.21591621, 0.21931788, 0.22612121,\n",
       "                     0.2271059 , 0.22934384, 0.23963835, 0.24796348, 0.25163369,\n",
       "                     0.2649718 , 0.26908961, 0.27687763, 0.28215916, 0.2843971 ,\n",
       "                     0.28735118, 0.28887297, 0.29889893, 0.29997314, 0.30113687,\n",
       "                     0.33774953, 0.34455286, 0.34616418, 0.34795453, 0.368275  ,\n",
       "                     0.36970728, 0.37140811, 0.37570495, 0.38268732, 0.38438815,\n",
       "                     0.38743174, 0.4097216 , 0.41213857, 0.41598783, 0.41786769,\n",
       "                     0.41947901, 0.42672993, 0.4542118 , 0.45680781, 0.45859816,\n",
       "                     0.4772178 , 0.48652762, 0.49950765, 0.49986572, 0.50192463,\n",
       "                     0.50666905, 0.50756423, 0.51454659, 0.52143944, 0.52403545,\n",
       "                     0.52519918, 0.52663146, 0.54005908, 0.54498254, 0.54722048,\n",
       "                     0.54820517, 0.56843613, 0.56959986, 0.57121117, 0.5723749 ,\n",
       "                     0.58830901, 0.58956226, 0.59206875, 0.59555993, 0.59869304,\n",
       "                     0.59967774, 0.60379554, 0.6046012 , 0.60630203, 0.60907707,\n",
       "                     0.61283681, 0.61793931, 0.62868141, 0.62993465, 0.63074031,\n",
       "                     0.63441053, 0.63593232, 0.63781219, 0.63942351, 0.64175096,\n",
       "                     0.64416793, 0.64542118, 0.64613732, 0.64971802, 0.65338824,\n",
       "                     0.65499955, 0.65643183, 0.65875929, 0.66466744, 0.67021753,\n",
       "                     0.6711127 , 0.67245547, 0.70512935, 0.70709874, 0.70862054,\n",
       "                     0.71246979, 0.71676663, 0.72043685, 0.72151106, 0.72365948,\n",
       "                     0.72724018, 0.72894101, 0.73037329, 0.73082088, 0.73216364,\n",
       "                     0.73323785, 0.73422254, 0.73628144, 0.73681855, 0.73798228,\n",
       "                     0.73986214, 0.74263719, 0.74353236, 0.74487512, 0.75123087,\n",
       "                     0.75382687, 0.75472205, 0.75642288, 0.7580342 , 0.75901889,\n",
       "                     0.75964551, 0.76116731, 0.76304718, 0.76447946, 0.77029809,\n",
       "                     0.77092472, 0.77253603, 0.78390475, 0.78506848, 0.78605317,\n",
       "                     0.78641124, 0.78685883, 0.79769045, 0.79983887, 0.80082356,\n",
       "                     0.8045833 , 0.80914869, 0.81120759, 0.81326649, 0.81407215,\n",
       "                     0.8179214 , 0.82186017, 0.82320294, 0.82597798, 0.82696267,\n",
       "                     0.82749978, 0.8322442 , 0.83537732, 0.84415003, 0.84486617,\n",
       "                     0.84773073, 0.86312774, 0.86679796, 0.86787217, 0.86849879,\n",
       "                     0.87127383, 0.87198997, 0.88246352, 0.8838958 , 0.8838958 ,\n",
       "                     0.88416435, 0.88711843, 0.88971444, 0.8905201 , 0.89195238,\n",
       "                     0.90144123, 0.90170978, 0.90188882, 0.90403724, 0.91836004,\n",
       "                     0.91853907, 0.91943425, 0.92301495, 0.92310447, 0.92408916,\n",
       "                     0.92444723, 0.92578999, 0.93026587, 0.93134008, 0.93581595,\n",
       "                     0.9370692 , 0.93957569, 0.94333542, 0.94387253, 0.94405156,\n",
       "                     0.94637902, 0.94736371, 0.94807985, 0.95362993, 0.95738967,\n",
       "                     0.95900098, 0.95962761, 0.96088085, 0.96956405, 0.9698326 ,\n",
       "                     0.97001164, 0.97081729, 0.97090681, 0.97216006, 0.97744159,\n",
       "                     0.97797869, 0.97824725, 0.97842628, 0.97860532, 0.97914242,\n",
       "                     0.97932146, 0.97967953, 0.98129084, 0.98146988, 0.98200698,\n",
       "                     0.98254409, 0.98290216, 0.98370781, 0.98397637, 0.98442395,\n",
       "                     0.98522961, 0.98531913, 1.        ]), tpr=array([0.        , 0.05764927, 0.06427357, 0.07967058, 0.08208755,\n",
       "                     0.08468356, 0.09220303, 0.09444096, 0.09766359, 0.0997225 ,\n",
       "                     0.10160236, 0.10885328, 0.11153881, 0.11529854, 0.11887924,\n",
       "                     0.12281801, 0.12657775, 0.14421269, 0.14994181, 0.15352251,\n",
       "                     0.15477576, 0.15638707, 0.18861337, 0.19085131, 0.19837078,\n",
       "                     0.21117178, 0.22755349, 0.2327455 , 0.2357891 , 0.24214484,\n",
       "                     0.24312953, 0.24474085, 0.25602005, 0.26389759, 0.26747829,\n",
       "                     0.28171157, 0.28708262, 0.29621341, 0.30104735, 0.30256915,\n",
       "                     0.30534419, 0.30632889, 0.31689195, 0.31859278, 0.32002506,\n",
       "                     0.35475786, 0.3611136 , 0.36299347, 0.36460478, 0.38662609,\n",
       "                     0.38886402, 0.39101244, 0.39656253, 0.40327634, 0.40515621,\n",
       "                     0.40927401, 0.43657685, 0.43818817, 0.44373825, 0.44543908,\n",
       "                     0.44731895, 0.45519649, 0.4843792 , 0.48742279, 0.48894459,\n",
       "                     0.50461015, 0.51400949, 0.52537821, 0.52716856, 0.52922746,\n",
       "                     0.53441948, 0.53567272, 0.54238654, 0.54892131, 0.55124877,\n",
       "                     0.55339719, 0.55536657, 0.56592964, 0.57174828, 0.57380718,\n",
       "                     0.57541849, 0.5943962 , 0.59582848, 0.59824546, 0.59994629,\n",
       "                     0.61856593, 0.61981917, 0.62241518, 0.62805478, 0.63082983,\n",
       "                     0.63226211, 0.63620088, 0.6368275 , 0.63808074, 0.64058723,\n",
       "                     0.64318324, 0.64586877, 0.65482052, 0.65643183, 0.65768508,\n",
       "                     0.66108674, 0.6624295 , 0.66439889, 0.66592069, 0.66797959,\n",
       "                     0.67012801, 0.67129174, 0.67245547, 0.67558858, 0.67988542,\n",
       "                     0.68140722, 0.68301853, 0.68570406, 0.69161221, 0.69734133,\n",
       "                     0.69868409, 0.70029541, 0.72912004, 0.73064184, 0.73189509,\n",
       "                     0.73717662, 0.74254767, 0.74496464, 0.74639692, 0.74773968,\n",
       "                     0.75149942, 0.75418494, 0.75516964, 0.75615433, 0.75660192,\n",
       "                     0.75794468, 0.75964551, 0.76089876, 0.76170441, 0.76251007,\n",
       "                     0.76358428, 0.76626981, 0.7672545 , 0.76850774, 0.77540059,\n",
       "                     0.77745949, 0.77942888, 0.78023454, 0.78130875, 0.78220392,\n",
       "                     0.78265151, 0.78542655, 0.78641124, 0.78829111, 0.79205085,\n",
       "                     0.79375168, 0.79455734, 0.80637365, 0.80744786, 0.80896965,\n",
       "                     0.80941724, 0.80986483, 0.82168114, 0.82266583, 0.82391908,\n",
       "                     0.82741026, 0.83367648, 0.83484021, 0.83609346, 0.83743622,\n",
       "                     0.84119595, 0.84504521, 0.84576135, 0.84871542, 0.84987915,\n",
       "                     0.85086384, 0.85704055, 0.86214305, 0.87046818, 0.87127383,\n",
       "                     0.87279563, 0.88738698, 0.89123624, 0.89213141, 0.89293707,\n",
       "                     0.89553308, 0.89624922, 0.90815504, 0.90994539, 0.91021395,\n",
       "                     0.91075105, 0.91361561, 0.91594307, 0.91683824, 0.91773342,\n",
       "                     0.92650613, 0.92713275, 0.92784889, 0.93026587, 0.94342494,\n",
       "                     0.94396204, 0.94458867, 0.94843792, 0.94879599, 0.94978068,\n",
       "                     0.95031779, 0.95201862, 0.95506221, 0.95676305, 0.9611494 ,\n",
       "                     0.96222361, 0.96455107, 0.9677737 , 0.96822129, 0.96848984,\n",
       "                     0.97019067, 0.97099633, 0.97233909, 0.97654641, 0.97976904,\n",
       "                     0.98120132, 0.98164891, 0.98218602, 0.98952645, 0.98988452,\n",
       "                     0.99015307, 0.9907797 , 0.99086921, 0.99185391, 0.99480798,\n",
       "                     0.99534509, 0.99588219, 0.99597171, 0.99632978, 0.99677737,\n",
       "                     0.99686689, 0.99704592, 0.99776206, 0.9979411 , 0.99812013,\n",
       "                     0.99838868, 0.99856772, 0.99910482, 0.99928386, 0.99937338,\n",
       "                     0.99991048, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.34230203e-02, -3.42890735e-02,\n",
       "                     -3.63676442e-02, -6.66913745e-02, -6.89928715e-02, -7.69610411e-02,\n",
       "                     -8.00427077e-02, -8.33816089e-02, -9.09717782e-02, -9.41872151e-02,\n",
       "                     -9.53101798e-02, -1.12477983e-01, -1.17783036e-01, -1.27833372e-01,\n",
       "                     -1.33531393e-01, -1.54875580e-01, -1.58605030e-01, -1.82321557e-01,\n",
       "                     -1.94156014e-01, -2.00670695e-01, -2.05205851e-01, -2.15111380e-01,\n",
       "                     -2.23143551e-01, -2.24541176e-01, -2.28593156e-01, -2.30016431e-01,\n",
       "                     -2.34839591e-01, -2.37129793e-01, -2.41162057e-01, -2.45122458e-01,\n",
       "                     -2.51314428e-01, -2.58861634e-01, -2.62364264e-01, -2.68633877e-01,\n",
       "                     -2.75103290e-01, -2.87682072e-01, -3.01475395e-01, -3.02280872e-01,\n",
       "                     -3.03682414e-01, -3.10154928e-01, -3.10719741e-01, -3.13657559e-01,\n",
       "                     -3.18453731e-01, -3.21261407e-01, -3.22287602e-01, -3.22773392e-01,\n",
       "                     -3.28504067e-01, -3.35310121e-01, -3.36472237e-01, -3.48306694e-01,\n",
       "                     -3.50202429e-01, -3.55340721e-01, -3.56674944e-01, -3.61013346e-01,\n",
       "                     -3.61907134e-01, -3.67724780e-01, -3.83725121e-01, -3.87765531e-01,\n",
       "                     -3.89464767e-01, -3.97860509e-01, -4.05465108e-01, -4.05465108e-01,\n",
       "                     -4.24883194e-01, -4.26201007e-01, -4.33635985e-01, -4.33927573e-01,\n",
       "                     -4.38254931e-01, -4.48024723e-01, -4.50416496e-01, -4.51985124e-01,\n",
       "                     -4.53196511e-01, -4.54472687e-01, -4.55475529e-01, -4.59532329e-01,\n",
       "                     -4.64305608e-01, -4.65757338e-01, -4.70003629e-01, -4.75423697e-01,\n",
       "                     -4.76924072e-01, -4.84055383e-01, -4.85507816e-01, -4.88352768e-01,\n",
       "                     -4.89548225e-01, -4.91407538e-01, -4.96436886e-01, -5.03905181e-01,\n",
       "                     -5.10825624e-01, -5.17256514e-01, -5.23248144e-01, -5.33298480e-01,\n",
       "                     -5.38996501e-01, -5.38996501e-01, -5.59615788e-01, -5.64529803e-01,\n",
       "                     -5.69094532e-01, -5.70979547e-01, -5.75364145e-01, -5.79818495e-01,\n",
       "                     -5.81921545e-01, -5.87786665e-01, -5.97837001e-01, -6.00773860e-01,\n",
       "                     -6.02175402e-01, -6.06135804e-01, -6.13104473e-01, -6.13104473e-01,\n",
       "                     -6.19039208e-01, -6.28608659e-01, -6.32522559e-01, -6.35988767e-01,\n",
       "                     -6.41853886e-01, -6.46627165e-01, -6.53301272e-01, -6.59245629e-01,\n",
       "                     -6.64976304e-01, -6.93147181e-01, -7.22134717e-01, -7.28238500e-01,\n",
       "                     -7.34646911e-01, -7.41937345e-01, -7.47214402e-01, -7.53771802e-01,\n",
       "                     -7.57685702e-01, -7.62140052e-01, -7.73189888e-01, -7.80158558e-01,\n",
       "                     -7.80158558e-01, -7.88457360e-01, -7.88457360e-01, -7.93230639e-01,\n",
       "                     -7.94929875e-01, -7.98507696e-01, -7.98507696e-01, -8.10930216e-01,\n",
       "                     -8.18310324e-01, -8.20980552e-01, -8.26678573e-01, -8.32344311e-01,\n",
       "                     -8.34797698e-01, -8.40783179e-01, -8.47297860e-01, -8.47297860e-01,\n",
       "                     -8.75468737e-01, -8.75468737e-01, -8.83500909e-01, -8.97941593e-01,\n",
       "                     -9.06721281e-01, -9.16290732e-01, -9.26762032e-01, -9.38269639e-01,\n",
       "                     -9.46143695e-01, -9.49080555e-01, -9.50976290e-01, -9.55511445e-01,\n",
       "                     -9.55511445e-01, -9.57839735e-01, -9.69400557e-01, -9.71860583e-01,\n",
       "                     -9.80829253e-01, -9.87946721e-01, -9.90398704e-01, -9.98528830e-01,\n",
       "                     -1.00552187e+00, -1.00726251e+00, -1.00948451e+00, -1.01160091e+00,\n",
       "                     -1.01435195e+00, -1.01856958e+00, -1.03609193e+00, -1.04400815e+00,\n",
       "                     -1.04454507e+00, -1.05838749e+00, -1.06087196e+00, -1.09861229e+00,\n",
       "                     -1.09861229e+00, -1.11399721e+00, -1.13140211e+00, -1.13497993e+00,\n",
       "                     -1.14356368e+00, -1.17865500e+00, -1.19186978e+00, -1.19392247e+00,\n",
       "                     -1.20397280e+00, -1.20397280e+00, -1.20709293e+00, -1.21924028e+00,\n",
       "                     -1.22377543e+00, -1.25276297e+00, -1.25567418e+00, -1.27296568e+00,\n",
       "                     -1.28785429e+00, -1.28913061e+00, -1.29183416e+00, -1.29928298e+00,\n",
       "                     -1.31218639e+00, -1.32020425e+00, -1.32175584e+00, -1.33977435e+00,\n",
       "                     -1.34373475e+00, -1.34602046e+00, -1.38629436e+00, -1.42500887e+00,\n",
       "                     -1.44571778e+00, -1.46633707e+00, -1.47810191e+00, -1.50407740e+00,\n",
       "                     -1.52605630e+00, -1.54044504e+00, -1.55537069e+00, -1.56397554e+00,\n",
       "                     -1.58240924e+00, -1.58793171e+00, -1.60386687e+00, -1.60943791e+00,\n",
       "                     -1.60943791e+00, -1.64222774e+00, -1.68459063e+00, -1.70474809e+00,\n",
       "                     -1.73460106e+00, -1.79175947e+00, -1.79175947e+00, -1.91959284e+00,\n",
       "                     -1.94157175e+00, -2.07944154e+00, -2.12026354e+00, -2.19722458e+00,\n",
       "                     -2.19722458e+00, -2.24070969e+00, -2.39789527e+00, -2.39789527e+00,\n",
       "                     -2.40919483e+00, -2.44234704e+00, -2.52572864e+00, -2.56494936e+00,\n",
       "                     -2.60268969e+00, -2.70805020e+00, -2.74084002e+00, -3.33220451e+00,\n",
       "                     -3.39002408e+00, -4.31748811e+00, -3.45387764e+01]), auc_score=0.5206292363099426, privacy_risk=0.5162921851221914, accuracy=0.5162921851221914, tpr_ind=0.6322621072419659, tnr_ind=0.40032226300241697, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.05532182, 0.0603348 , 0.07152448, 0.07358339,\n",
       "                     0.07716409, 0.07752216, 0.08674246, 0.0879957 , 0.09766359,\n",
       "                     0.09918539, 0.0997225 , 0.10124429, 0.10607824, 0.10724197,\n",
       "                     0.10858473, 0.11001701, 0.11726793, 0.11878972, 0.12765196,\n",
       "                     0.13024796, 0.13409722, 0.13767792, 0.14430221, 0.14922567,\n",
       "                     0.15182168, 0.16256378, 0.1641751 , 0.19049324, 0.19425298,\n",
       "                     0.19756512, 0.20213052, 0.21439441, 0.21528959, 0.2255841 ,\n",
       "                     0.23041805, 0.23865366, 0.2393698 , 0.24518843, 0.24805299,\n",
       "                     0.25190225, 0.25333453, 0.26004834, 0.26685167, 0.27105899,\n",
       "                     0.27401307, 0.27499776, 0.27857846, 0.28672455, 0.29970459,\n",
       "                     0.30409095, 0.30731358, 0.30874586, 0.32253155, 0.32709695,\n",
       "                     0.32799212, 0.33407931, 0.33909229, 0.34034554, 0.36048698,\n",
       "                     0.36129263, 0.38035986, 0.39629398, 0.39969564, 0.40578283,\n",
       "                     0.41473458, 0.41903142, 0.42109032, 0.42368633, 0.42896786,\n",
       "                     0.43818817, 0.44740847, 0.44991496, 0.45313759, 0.45591263,\n",
       "                     0.45877719, 0.46334258, 0.46459583, 0.46558052, 0.46942977,\n",
       "                     0.4726524 , 0.4843792 , 0.48876555, 0.49037687, 0.49449467,\n",
       "                     0.49673261, 0.50344642, 0.50756423, 0.51383045, 0.51624743,\n",
       "                     0.51642646, 0.51803778, 0.52913795, 0.52967505, 0.5329872 ,\n",
       "                     0.53379286, 0.54560917, 0.55357622, 0.55796258, 0.56780951,\n",
       "                     0.57067407, 0.57532898, 0.57864112, 0.57989437, 0.58848805,\n",
       "                     0.5902784 , 0.59072599, 0.5943962 , 0.59761883, 0.59815594,\n",
       "                     0.5989616 , 0.60648107, 0.60809238, 0.61910303, 0.62134097,\n",
       "                     0.62411601, 0.62536926, 0.63288873, 0.6373646 , 0.63969206,\n",
       "                     0.64184048, 0.64389938, 0.644526  , 0.64900188, 0.65231403,\n",
       "                     0.65643183, 0.65705845, 0.66063915, 0.66287709, 0.66609972,\n",
       "                     0.66797959, 0.67218691, 0.69626712, 0.69841554, 0.6997583 ,\n",
       "                     0.70378659, 0.70754633, 0.71309641, 0.71372303, 0.71614001,\n",
       "                     0.71900457, 0.72365948, 0.72401755, 0.72509176, 0.72589741,\n",
       "                     0.72750873, 0.72831439, 0.73225316, 0.73941456, 0.74084684,\n",
       "                     0.74236863, 0.74353236, 0.74541223, 0.7514099 , 0.75257363,\n",
       "                     0.75821323, 0.75875034, 0.75901889, 0.76080924, 0.76295766,\n",
       "                     0.76349476, 0.76483753, 0.77020858, 0.77155134, 0.77244651,\n",
       "                     0.77790708, 0.77969743, 0.78533703, 0.78909677, 0.79276699,\n",
       "                     0.79867514, 0.79894369, 0.8010026 , 0.80136067, 0.80726882,\n",
       "                     0.80959628, 0.80977531, 0.81058097, 0.81505684, 0.81648912,\n",
       "                     0.81863754, 0.82177066, 0.8230239 , 0.82472473, 0.82803688,\n",
       "                     0.83251276, 0.83457166, 0.8368096 , 0.83716767, 0.83761525,\n",
       "                     0.84119595, 0.84262823, 0.84388148, 0.84504521, 0.84620893,\n",
       "                     0.84880494, 0.85444454, 0.85641393, 0.8588309 , 0.85990511,\n",
       "                     0.86330678, 0.8659923 , 0.86993107, 0.87118432, 0.87601826,\n",
       "                     0.88479098, 0.88577567, 0.89302659, 0.89401128, 0.89660729,\n",
       "                     0.90000895, 0.90054606, 0.90296303, 0.91057202, 0.91146719,\n",
       "                     0.91298899, 0.91522693, 0.91862859, 0.92194074, 0.92426819,\n",
       "                     0.92489482, 0.92641661, 0.92802793, 0.93017635, 0.93241429,\n",
       "                     0.9334885 , 0.9340256 , 0.93411512, 0.93787485, 0.93885955,\n",
       "                     0.94145555, 0.94306687, 0.9468266 , 0.94718467, 0.94995972,\n",
       "                     0.95166055, 0.95201862, 0.95246621, 0.9534509 , 0.96043326,\n",
       "                     0.96159699, 0.96374541, 0.9662519 , 0.96705756, 0.96920598,\n",
       "                     0.97045922, 0.97162295, 0.97305523, 0.97395041, 0.976994  ,\n",
       "                     0.97708352, 0.97896339, 0.97941097, 0.97976904, 0.97994808,\n",
       "                     0.98021663, 0.98030615, 0.98048518, 0.98111181, 0.98146988,\n",
       "                     0.98164891, 0.98245457, 0.98245457, 0.98308119, 0.98352878,\n",
       "                     0.98406588, 0.98505058, 1.        ]), tpr=array([0.        , 0.0659744 , 0.07259869, 0.08226658, 0.08432549,\n",
       "                     0.08942798, 0.09068123, 0.1002596 , 0.10240802, 0.10930087,\n",
       "                     0.11118074, 0.11207591, 0.11377674, 0.1161042 , 0.11825262,\n",
       "                     0.11959538, 0.12210187, 0.12872617, 0.130427  , 0.14260138,\n",
       "                     0.14564497, 0.1503894 , 0.15441769, 0.16292185, 0.16757676,\n",
       "                     0.17106794, 0.1810939 , 0.18368991, 0.20956047, 0.21358876,\n",
       "                     0.21681139, 0.22128726, 0.23462537, 0.23561006, 0.24563602,\n",
       "                     0.25073852, 0.25870558, 0.26058544, 0.26774684, 0.27079044,\n",
       "                     0.27320741, 0.27499776, 0.28153254, 0.28976815, 0.29442306,\n",
       "                     0.29934652, 0.30131591, 0.30516516, 0.31375884, 0.32539611,\n",
       "                     0.33139379, 0.33524304, 0.33703339, 0.35287799, 0.35807   ,\n",
       "                     0.3590547 , 0.36558947, 0.37087101, 0.37203473, 0.39056486,\n",
       "                     0.39217617, 0.41079581, 0.42565572, 0.429684  , 0.43559216,\n",
       "                     0.44311163, 0.44651329, 0.44901978, 0.45170531, 0.45680781,\n",
       "                     0.46737087, 0.475696  , 0.47829201, 0.48187271, 0.48384209,\n",
       "                     0.4869752 , 0.4935995 , 0.49476323, 0.49610599, 0.50031331,\n",
       "                     0.50425208, 0.51597887, 0.52099185, 0.52296124, 0.52591532,\n",
       "                     0.52931698, 0.53334527, 0.53764211, 0.54516158, 0.54695193,\n",
       "                     0.54775759, 0.55017456, 0.56118521, 0.56181183, 0.5652135 ,\n",
       "                     0.56628771, 0.57819354, 0.58535494, 0.59054695, 0.60057291,\n",
       "                     0.60334795, 0.60898756, 0.61095694, 0.61265777, 0.62232566,\n",
       "                     0.62438457, 0.62527974, 0.62859189, 0.63136693, 0.63199355,\n",
       "                     0.63262018, 0.63969206, 0.64139289, 0.6532092 , 0.65544714,\n",
       "                     0.65777459, 0.65920687, 0.66654731, 0.67147077, 0.67299257,\n",
       "                     0.67514099, 0.67693134, 0.67755796, 0.68239191, 0.68597261,\n",
       "                     0.68964283, 0.69062752, 0.69510339, 0.69877361, 0.70369707,\n",
       "                     0.70495032, 0.70853102, 0.73216364, 0.7355653 , 0.73672903,\n",
       "                     0.74129442, 0.74469609, 0.74881389, 0.74970907, 0.75302122,\n",
       "                     0.75615433, 0.76036165, 0.76089876, 0.76242055, 0.76286814,\n",
       "                     0.7642109 , 0.76546415, 0.76949244, 0.77549011, 0.77665384,\n",
       "                     0.7785337 , 0.78032405, 0.78220392, 0.78918629, 0.79043953,\n",
       "                     0.79554203, 0.79598962, 0.7964372 , 0.79840659, 0.80073404,\n",
       "                     0.80136067, 0.80279295, 0.80950676, 0.81067049, 0.81201325,\n",
       "                     0.81577298, 0.81756333, 0.82400859, 0.82723122, 0.83152806,\n",
       "                     0.83859995, 0.83922657, 0.84119595, 0.84155402, 0.84773073,\n",
       "                     0.84907349, 0.84952108, 0.85050577, 0.85462358, 0.85695103,\n",
       "                     0.85909945, 0.8608898 , 0.8624116 , 0.86339629, 0.86590278,\n",
       "                     0.8716319 , 0.87351177, 0.87548116, 0.87610778, 0.87664488,\n",
       "                     0.87968848, 0.88112076, 0.88201593, 0.88362725, 0.88479098,\n",
       "                     0.88846119, 0.8931161 , 0.89535404, 0.89651777, 0.89759198,\n",
       "                     0.89902426, 0.90215737, 0.90457434, 0.90618566, 0.9120043 ,\n",
       "                     0.91925521, 0.91988184, 0.92704324, 0.92749082, 0.92946021,\n",
       "                     0.93187718, 0.93223525, 0.93411512, 0.93975472, 0.94038134,\n",
       "                     0.94172411, 0.94378301, 0.94772178, 0.95058634, 0.95183958,\n",
       "                     0.95246621, 0.953988  , 0.95542028, 0.95792677, 0.95989616,\n",
       "                     0.96043326, 0.9611494 , 0.96204458, 0.96410348, 0.96464059,\n",
       "                     0.96687852, 0.9683108 , 0.97108585, 0.9713544 , 0.97484558,\n",
       "                     0.97600931, 0.97663593, 0.97681497, 0.97779966, 0.98406588,\n",
       "                     0.98469251, 0.98701996, 0.98782562, 0.98881031, 0.99060066,\n",
       "                     0.99113777, 0.99140632, 0.99230149, 0.9928386 , 0.99480798,\n",
       "                     0.99507654, 0.99606123, 0.9964193 , 0.99659833, 0.99713544,\n",
       "                     0.99731447, 0.99740399, 0.99758303, 0.99820965, 0.99829917,\n",
       "                     0.99838868, 0.99910482, 0.99919434, 0.99955241, 0.99964193,\n",
       "                     0.99991048, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.34230203e-02, -2.73989742e-02,\n",
       "                     -4.25596144e-02, -6.78225963e-02, -6.89928715e-02, -7.21032939e-02,\n",
       "                     -8.00427077e-02, -8.70113770e-02, -9.09717782e-02, -9.53101798e-02,\n",
       "                     -1.00083459e-01, -1.09199292e-01, -1.17783036e-01, -1.25163143e-01,\n",
       "                     -1.33531393e-01, -1.38586163e-01, -1.46603474e-01, -1.49940147e-01,\n",
       "                     -1.62518929e-01, -1.72842813e-01, -1.82321557e-01, -1.91055237e-01,\n",
       "                     -1.91891008e-01, -2.07639365e-01, -2.08754814e-01, -2.16223108e-01,\n",
       "                     -2.16895700e-01, -2.18689201e-01, -2.23143551e-01, -2.31111721e-01,\n",
       "                     -2.32495657e-01, -2.41162057e-01, -2.44345759e-01, -2.47408173e-01,\n",
       "                     -2.47562079e-01, -2.51314428e-01, -2.52702354e-01, -2.57829109e-01,\n",
       "                     -2.59511195e-01, -2.62364264e-01, -2.63417450e-01, -2.65703166e-01,\n",
       "                     -2.68263987e-01, -2.69332934e-01, -2.76253377e-01, -2.81851152e-01,\n",
       "                     -2.87682072e-01, -2.91520849e-01, -2.95117051e-01, -2.99242895e-01,\n",
       "                     -3.00104592e-01, -3.04489191e-01, -3.09004842e-01, -3.10154928e-01,\n",
       "                     -3.14710745e-01, -3.16911711e-01, -3.25422400e-01, -3.26763422e-01,\n",
       "                     -3.28504067e-01, -3.28888608e-01, -3.30429922e-01, -3.36472237e-01,\n",
       "                     -3.42944751e-01, -3.48306694e-01, -3.51397887e-01, -3.56674944e-01,\n",
       "                     -3.60002734e-01, -3.63667979e-01, -3.65113813e-01, -3.65240307e-01,\n",
       "                     -3.70373788e-01, -3.71563556e-01, -3.74693449e-01, -3.76477571e-01,\n",
       "                     -3.78066134e-01, -3.79489622e-01, -3.82992252e-01, -3.83958903e-01,\n",
       "                     -3.90197636e-01, -3.97802235e-01, -4.05465108e-01, -4.05465108e-01,\n",
       "                     -4.15515444e-01, -4.22856851e-01, -4.27444015e-01, -4.32864082e-01,\n",
       "                     -4.36717652e-01, -4.38254931e-01, -4.41832752e-01, -4.41832752e-01,\n",
       "                     -4.45311017e-01, -4.51985124e-01, -4.56758402e-01, -4.59532329e-01,\n",
       "                     -4.66237146e-01, -4.70003629e-01, -4.82851772e-01, -4.96436886e-01,\n",
       "                     -4.97838428e-01, -5.10825624e-01, -5.19875459e-01, -5.21296924e-01,\n",
       "                     -5.27354926e-01, -5.28067430e-01, -5.30628251e-01, -5.32216814e-01,\n",
       "                     -5.36304709e-01, -5.38996501e-01, -5.38996501e-01, -5.43207033e-01,\n",
       "                     -5.52068582e-01, -5.59615788e-01, -5.87786665e-01, -5.92051064e-01,\n",
       "                     -5.94707108e-01, -5.97227059e-01, -5.97837001e-01, -6.00773860e-01,\n",
       "                     -6.06135804e-01, -6.15185639e-01, -6.19039208e-01, -6.26136470e-01,\n",
       "                     -6.28608659e-01, -6.43136760e-01, -6.46627165e-01, -6.52325186e-01,\n",
       "                     -6.55875786e-01, -6.56105909e-01, -6.56779536e-01, -6.67829373e-01,\n",
       "                     -6.93147181e-01, -7.19122667e-01, -7.30887509e-01, -7.31613461e-01,\n",
       "                     -7.31861693e-01, -7.35706795e-01, -7.41937345e-01, -7.45790914e-01,\n",
       "                     -7.62140052e-01, -7.64972915e-01, -7.73189888e-01, -7.77704569e-01,\n",
       "                     -7.88457360e-01, -7.88457360e-01, -7.94929875e-01, -7.98507696e-01,\n",
       "                     -7.99253687e-01, -8.02346473e-01, -8.05625164e-01, -8.10930216e-01,\n",
       "                     -8.47297860e-01, -8.47297860e-01, -8.57450232e-01, -8.69603618e-01,\n",
       "                     -8.75468737e-01, -8.75468737e-01, -8.79249460e-01, -8.85038188e-01,\n",
       "                     -8.87303195e-01, -8.90972924e-01, -8.91998039e-01, -9.00786545e-01,\n",
       "                     -9.02867712e-01, -9.16290732e-01, -9.36093359e-01, -9.38269639e-01,\n",
       "                     -9.59775844e-01, -9.80829253e-01, -9.87138422e-01, -9.98528830e-01,\n",
       "                     -1.00330211e+00, -1.01160091e+00, -1.02338887e+00, -1.02961942e+00,\n",
       "                     -1.02961942e+00, -1.03609193e+00, -1.03889305e+00, -1.04596856e+00,\n",
       "                     -1.05605267e+00, -1.06471074e+00, -1.07880966e+00, -1.09861229e+00,\n",
       "                     -1.09861229e+00, -1.11411648e+00, -1.12986483e+00, -1.14306405e+00,\n",
       "                     -1.14513230e+00, -1.15267951e+00, -1.15577070e+00, -1.15923691e+00,\n",
       "                     -1.16315081e+00, -1.17007125e+00, -1.17272026e+00, -1.18426773e+00,\n",
       "                     -1.18455472e+00, -1.18784342e+00, -1.19625076e+00, -1.20397280e+00,\n",
       "                     -1.21639532e+00, -1.22377543e+00, -1.23676263e+00, -1.25276297e+00,\n",
       "                     -1.26803044e+00, -1.27197753e+00, -1.27296568e+00, -1.27745558e+00,\n",
       "                     -1.28093385e+00, -1.30340670e+00, -1.30933332e+00, -1.32175584e+00,\n",
       "                     -1.32492541e+00, -1.33750420e+00, -1.34992672e+00, -1.35239281e+00,\n",
       "                     -1.36431545e+00, -1.37486567e+00, -1.38629436e+00, -1.40399394e+00,\n",
       "                     -1.42138568e+00, -1.44345277e+00, -1.44691898e+00, -1.45528723e+00,\n",
       "                     -1.46283444e+00, -1.46633707e+00, -1.47590652e+00, -1.48160454e+00,\n",
       "                     -1.49923477e+00, -1.50407740e+00, -1.51732262e+00, -1.51787072e+00,\n",
       "                     -1.52885743e+00, -1.54044504e+00, -1.57288032e+00, -1.57818537e+00,\n",
       "                     -1.60943791e+00, -1.60943791e+00, -1.62745642e+00, -1.63482715e+00,\n",
       "                     -1.63760879e+00, -1.66915715e+00, -1.67397643e+00, -1.74523945e+00,\n",
       "                     -1.74919985e+00, -1.79175947e+00, -1.79175947e+00, -1.84054963e+00,\n",
       "                     -1.89711998e+00, -1.97155258e+00, -1.99243016e+00, -2.04475598e+00,\n",
       "                     -2.07944154e+00, -2.14006616e+00, -2.26868354e+00, -2.35137526e+00,\n",
       "                     -2.39789527e+00, -2.44234704e+00, -2.48490665e+00, -2.56494936e+00,\n",
       "                     -2.56494936e+00, -2.66549059e+00, -2.70805020e+00, -2.72457950e+00,\n",
       "                     -3.17805383e+00, -3.61091791e+00, -4.31748811e+00, -3.45387764e+01]), auc_score=0.5272035358635467, privacy_risk=0.5202309551517321, accuracy=0.5202309551517321, tpr_ind=0.8477307313579805, tnr_ind=0.19273117894548383, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.07027124, 0.07608988, 0.07805926, 0.08396742,\n",
       "                     0.08575777, 0.08763763, 0.09068123, 0.09265061, 0.09560469,\n",
       "                     0.09560469, 0.09766359, 0.09990153, 0.1038403 , 0.10724197,\n",
       "                     0.1089428 , 0.10965894, 0.1130606 , 0.11798407, 0.11834214,\n",
       "                     0.12013249, 0.12156477, 0.12407126, 0.12541402, 0.14689822,\n",
       "                     0.15003133, 0.15047892, 0.15719273, 0.15817742, 0.17258974,\n",
       "                     0.20087727, 0.20580073, 0.21081371, 0.21242503, 0.21394683,\n",
       "                     0.23185033, 0.23408826, 0.23569958, 0.23910124, 0.24008594,\n",
       "                     0.24259243, 0.24957479, 0.25378211, 0.27804136, 0.28663504,\n",
       "                     0.29191657, 0.30104735, 0.31241608, 0.3145645 , 0.31599678,\n",
       "                     0.32253155, 0.3309462 , 0.3314833 , 0.33416883, 0.34392624,\n",
       "                     0.3473279 , 0.34983439, 0.35225137, 0.35556351, 0.3688121 ,\n",
       "                     0.37060245, 0.3759735 , 0.38152359, 0.3841196 , 0.38510429,\n",
       "                     0.38832692, 0.39110196, 0.39396652, 0.40640945, 0.40945305,\n",
       "                     0.4383672 , 0.44024707, 0.44373825, 0.44597619, 0.45286904,\n",
       "                     0.46898219, 0.47041447, 0.49279384, 0.49673261, 0.50801182,\n",
       "                     0.51257721, 0.51311431, 0.51669501, 0.51678453, 0.51803778,\n",
       "                     0.52484111, 0.52752663, 0.534509  , 0.53531465, 0.53826873,\n",
       "                     0.54355026, 0.54820517, 0.55178587, 0.56628771, 0.5672724 ,\n",
       "                     0.56986841, 0.57076358, 0.5744338 , 0.59188971, 0.59341151,\n",
       "                     0.59636559, 0.6025423 , 0.60397458, 0.61212067, 0.61641751,\n",
       "                     0.61784979, 0.62017724, 0.62178856, 0.62384746, 0.6245636 ,\n",
       "                     0.62483215, 0.63056127, 0.63226211, 0.63432101, 0.63942351,\n",
       "                     0.64309372, 0.65052368, 0.65106078, 0.6526721 , 0.65356727,\n",
       "                     0.6598335 , 0.66251902, 0.66314564, 0.66421985, 0.66690538,\n",
       "                     0.67012801, 0.67702086, 0.69698326, 0.70145914, 0.70387611,\n",
       "                     0.70557694, 0.70709874, 0.70736729, 0.71121654, 0.71381255,\n",
       "                     0.71417062, 0.71694566, 0.71775132, 0.71837794, 0.72294334,\n",
       "                     0.72544983, 0.72903053, 0.73108943, 0.73135798, 0.73305881,\n",
       "                     0.7335064 , 0.73395399, 0.73422254, 0.73646048, 0.73744517,\n",
       "                     0.7386089 , 0.74048877, 0.74245815, 0.74657596, 0.74711306,\n",
       "                     0.75132038, 0.75221556, 0.75320025, 0.76510608, 0.76868678,\n",
       "                     0.76967147, 0.77181989, 0.77280458, 0.77298362, 0.78193537,\n",
       "                     0.78354668, 0.78793304, 0.79178229, 0.79455734, 0.79509444,\n",
       "                     0.79930176, 0.80028646, 0.80288246, 0.80288246, 0.80431474,\n",
       "                     0.80610509, 0.80673172, 0.80771641, 0.81568347, 0.81720526,\n",
       "                     0.82481425, 0.82732074, 0.83672008, 0.84128547, 0.84235968,\n",
       "                     0.84370244, 0.84468714, 0.85668248, 0.85775669, 0.86214305,\n",
       "                     0.86321726, 0.8639334 , 0.86473906, 0.86590278, 0.86867783,\n",
       "                     0.87190046, 0.87333274, 0.87539164, 0.87610778, 0.88264256,\n",
       "                     0.88398532, 0.88640229, 0.8874765 , 0.88908782, 0.8961597 ,\n",
       "                     0.8966968 , 0.89705487, 0.90188882, 0.90493241, 0.90546952,\n",
       "                     0.90681228, 0.91039298, 0.91361561, 0.9146003 , 0.9191657 ,\n",
       "                     0.92668517, 0.93062394, 0.93393608, 0.93518933, 0.93536836,\n",
       "                     0.93653209, 0.93787485, 0.93868051, 0.94369349, 0.9442306 ,\n",
       "                     0.94485722, 0.94646853, 0.94816937, 0.95577835, 0.95577835,\n",
       "                     0.96222361, 0.96240265, 0.96446155, 0.96517769, 0.96598335,\n",
       "                     0.97126488, 0.97216006, 0.97224957, 0.97305523, 0.97332378,\n",
       "                     0.97386089, 0.97448751, 0.97690448, 0.97735207, 0.97779966,\n",
       "                     0.97815773, 0.97967953, 0.97967953, 0.98039567, 0.98084325,\n",
       "                     0.98129084, 0.9820965 , 0.98236505, 0.98281264, 0.98317071,\n",
       "                     0.98334974, 0.98406588, 0.98442395, 0.98469251, 1.        ]), tpr=array([0.        , 0.08584728, 0.0910393 , 0.09274013, 0.09846925,\n",
       "                     0.10097574, 0.10339271, 0.10661534, 0.10974846, 0.11279205,\n",
       "                     0.11377674, 0.1166413 , 0.11941635, 0.12344463, 0.12783099,\n",
       "                     0.12962134, 0.13078507, 0.13409722, 0.14000537, 0.14054248,\n",
       "                     0.14260138, 0.14412318, 0.14922567, 0.15146361, 0.17590189,\n",
       "                     0.17921404, 0.18001969, 0.18521171, 0.18637544, 0.20490556,\n",
       "                     0.23211888, 0.23811655, 0.2429505 , 0.24527795, 0.24626264,\n",
       "                     0.26389759, 0.26640408, 0.2685525 , 0.27186465, 0.27275982,\n",
       "                     0.27598245, 0.28314385, 0.29120043, 0.31554919, 0.32709695,\n",
       "                     0.33291558, 0.34070361, 0.35359413, 0.35538448, 0.35735386,\n",
       "                     0.36442575, 0.37373557, 0.37489929, 0.37740578, 0.38814788,\n",
       "                     0.39190762, 0.39477218, 0.39826336, 0.40085937, 0.41455555,\n",
       "                     0.41625638, 0.42126936, 0.42852028, 0.43263808, 0.43407036,\n",
       "                     0.43648733, 0.43908334, 0.44203742, 0.45089965, 0.45358518,\n",
       "                     0.47677021, 0.47882911, 0.48348402, 0.48590099, 0.49386805,\n",
       "                     0.5099812 , 0.51266673, 0.52976457, 0.5329872 , 0.54569868,\n",
       "                     0.54954794, 0.55071166, 0.55491899, 0.55572464, 0.5565303 ,\n",
       "                     0.56234894, 0.56422881, 0.57344911, 0.57452332, 0.57864112,\n",
       "                     0.5846388 , 0.59000985, 0.59368006, 0.60630203, 0.60845045,\n",
       "                     0.61158356, 0.6132844 , 0.61749172, 0.63405246, 0.63584281,\n",
       "                     0.63817026, 0.64515263, 0.64658491, 0.6526721 , 0.65696894,\n",
       "                     0.6588488 , 0.66046012, 0.66216095, 0.66421985, 0.66529406,\n",
       "                     0.66681586, 0.67066512, 0.67147077, 0.67361919, 0.67809507,\n",
       "                     0.68095963, 0.68785248, 0.68892669, 0.69143318, 0.69214932,\n",
       "                     0.69662519, 0.70038493, 0.7012801 , 0.70226479, 0.70441321,\n",
       "                     0.70674067, 0.71282786, 0.73287978, 0.7386089 , 0.74075732,\n",
       "                     0.7427267 , 0.74362188, 0.74442754, 0.74773968, 0.75167845,\n",
       "                     0.75230508, 0.7544535 , 0.75490108, 0.75534867, 0.76098827,\n",
       "                     0.76331573, 0.76689643, 0.76859726, 0.76922388, 0.77217796,\n",
       "                     0.77334169, 0.77361024, 0.77414735, 0.77566914, 0.77692239,\n",
       "                     0.77808612, 0.77942888, 0.78247247, 0.7866798 , 0.78766449,\n",
       "                     0.7923194 , 0.7938412 , 0.79500492, 0.80565751, 0.80834303,\n",
       "                     0.80941724, 0.81138663, 0.8122818 , 0.81272939, 0.82060693,\n",
       "                     0.82284487, 0.8260675 , 0.8296482 , 0.83206517, 0.83269179,\n",
       "                     0.83806284, 0.83913705, 0.8424492 , 0.84289679, 0.84334437,\n",
       "                     0.84567183, 0.84629845, 0.84835735, 0.85507117, 0.856772  ,\n",
       "                     0.8654552 , 0.86679796, 0.87485453, 0.87870379, 0.87986751,\n",
       "                     0.88210545, 0.88309014, 0.8941008 , 0.89535404, 0.89947185,\n",
       "                     0.90081461, 0.90197834, 0.90305255, 0.90367917, 0.90546952,\n",
       "                     0.90860263, 0.90913974, 0.91075105, 0.91146719, 0.91719631,\n",
       "                     0.91827052, 0.9197028 , 0.92086653, 0.92238833, 0.92668517,\n",
       "                     0.92766986, 0.92811745, 0.93160863, 0.93420464, 0.93492078,\n",
       "                     0.9355474 , 0.94002327, 0.9427088 , 0.94467818, 0.94852744,\n",
       "                     0.95658401, 0.95918002, 0.96141796, 0.96240265, 0.9626712 ,\n",
       "                     0.96365589, 0.96428252, 0.96499866, 0.97001164, 0.97028019,\n",
       "                     0.97090681, 0.97216006, 0.97368185, 0.98039567, 0.98048518,\n",
       "                     0.98487154, 0.98514009, 0.98630382, 0.98648286, 0.987199  ,\n",
       "                     0.99221198, 0.99257005, 0.99265956, 0.99364426, 0.99391281,\n",
       "                     0.99427088, 0.9943604 , 0.99534509, 0.99588219, 0.99606123,\n",
       "                     0.99632978, 0.9969564 , 0.99749351, 0.99785158, 0.99820965,\n",
       "                     0.99829917, 0.99856772, 0.99883627, 0.99910482, 0.99928386,\n",
       "                     0.99946289, 0.99982096, 0.99991048, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.70944334e-02, -5.12932944e-02,\n",
       "                     -6.06246218e-02, -6.89928715e-02, -7.14589640e-02, -8.00427077e-02,\n",
       "                     -8.22380982e-02, -8.45573880e-02, -8.70113770e-02, -1.17783036e-01,\n",
       "                     -1.21360857e-01, -1.25163143e-01, -1.33531393e-01, -1.39761942e-01,\n",
       "                     -1.43100844e-01, -1.50282203e-01, -1.54150680e-01, -1.54150680e-01,\n",
       "                     -1.60342650e-01, -1.62518929e-01, -1.76456437e-01, -1.82321557e-01,\n",
       "                     -1.86585956e-01, -1.95744577e-01, -2.00670695e-01, -2.02236866e-01,\n",
       "                     -2.07639365e-01, -2.12458651e-01, -2.23143551e-01, -2.26124179e-01,\n",
       "                     -2.30523659e-01, -2.38411023e-01, -2.41162057e-01, -2.50185760e-01,\n",
       "                     -2.51314428e-01, -2.55933374e-01, -2.60283098e-01, -2.62364264e-01,\n",
       "                     -2.66628663e-01, -2.71933715e-01, -2.79313823e-01, -2.85842146e-01,\n",
       "                     -2.87682072e-01, -2.91520849e-01, -2.96265816e-01, -2.98044859e-01,\n",
       "                     -3.00104592e-01, -3.10154928e-01, -3.12683375e-01, -3.18453731e-01,\n",
       "                     -3.25422400e-01, -3.31357136e-01, -3.36472237e-01, -3.39867826e-01,\n",
       "                     -3.40926587e-01, -3.43771539e-01, -3.46276237e-01, -3.49459432e-01,\n",
       "                     -3.51397887e-01, -3.56674944e-01, -3.59141036e-01, -3.61013346e-01,\n",
       "                     -3.62905494e-01, -3.67724780e-01, -3.70373788e-01, -3.74693449e-01,\n",
       "                     -3.81613892e-01, -3.82992252e-01, -3.88592547e-01, -3.90866309e-01,\n",
       "                     -3.92561703e-01, -3.93042588e-01, -3.94165553e-01, -4.05465108e-01,\n",
       "                     -4.05465108e-01, -4.10687052e-01, -4.23814247e-01, -4.24070296e-01,\n",
       "                     -4.28454626e-01, -4.30782916e-01, -4.40311839e-01, -4.41832752e-01,\n",
       "                     -4.41832752e-01, -4.50585543e-01, -4.51985124e-01, -4.59021213e-01,\n",
       "                     -4.59532329e-01, -4.61818045e-01, -4.68136215e-01, -4.70003629e-01,\n",
       "                     -4.76082675e-01, -4.84962113e-01, -4.85507816e-01, -4.87703206e-01,\n",
       "                     -4.89548225e-01, -4.93657820e-01, -4.96671876e-01, -5.00775288e-01,\n",
       "                     -5.03103578e-01, -5.10825624e-01, -5.23248144e-01, -5.25424423e-01,\n",
       "                     -5.35518236e-01, -5.38996501e-01, -5.43615447e-01, -5.52068582e-01,\n",
       "                     -5.53385238e-01, -5.59615788e-01, -5.67984038e-01, -5.69533225e-01,\n",
       "                     -5.75364145e-01, -5.83146285e-01, -5.87786665e-01, -5.94707108e-01,\n",
       "                     -5.97837001e-01, -6.06135804e-01, -6.19039208e-01, -6.28608659e-01,\n",
       "                     -6.31271777e-01, -6.31778234e-01, -6.41853886e-01, -6.46627165e-01,\n",
       "                     -6.50587566e-01, -6.53926467e-01, -6.63294217e-01, -6.93147181e-01,\n",
       "                     -7.23918839e-01, -7.33969175e-01, -7.37598943e-01, -7.41937345e-01,\n",
       "                     -7.47214402e-01, -7.58529940e-01, -7.59105148e-01, -7.62140052e-01,\n",
       "                     -7.73189888e-01, -7.88457360e-01, -7.88457360e-01, -7.98507696e-01,\n",
       "                     -8.02346473e-01, -8.10930216e-01, -8.16761137e-01, -8.26678573e-01,\n",
       "                     -8.34225779e-01, -8.36248024e-01, -8.47297860e-01, -8.47297860e-01,\n",
       "                     -8.55666110e-01, -8.57450232e-01, -8.69037847e-01, -8.75468737e-01,\n",
       "                     -8.80358723e-01, -8.94784527e-01, -8.97941593e-01, -9.16290732e-01,\n",
       "                     -9.27986772e-01, -9.31558204e-01, -9.37904208e-01, -9.42608040e-01,\n",
       "                     -9.49080555e-01, -9.52008814e-01, -9.55511445e-01, -9.55511445e-01,\n",
       "                     -9.56385189e-01, -9.70778917e-01, -9.80829253e-01, -9.83949380e-01,\n",
       "                     -9.94622575e-01, -9.98528830e-01, -9.99405639e-01, -1.01160091e+00,\n",
       "                     -1.01405490e+00, -1.02961942e+00, -1.02961942e+00, -1.03236290e+00,\n",
       "                     -1.04982212e+00, -1.05416053e+00, -1.06240924e+00, -1.06289421e+00,\n",
       "                     -1.08824950e+00, -1.09861229e+00, -1.09861229e+00, -1.12160181e+00,\n",
       "                     -1.12393010e+00, -1.12492960e+00, -1.12846525e+00, -1.13323625e+00,\n",
       "                     -1.14513230e+00, -1.14809235e+00, -1.16315081e+00, -1.17272026e+00,\n",
       "                     -1.17865500e+00, -1.18958407e+00, -1.19392247e+00, -1.19824213e+00,\n",
       "                     -1.20397280e+00, -1.20397280e+00, -1.21639532e+00, -1.22101427e+00,\n",
       "                     -1.22866542e+00, -1.23474446e+00, -1.24171313e+00, -1.24432410e+00,\n",
       "                     -1.25276297e+00, -1.26566637e+00, -1.28093385e+00, -1.29928298e+00,\n",
       "                     -1.31483540e+00, -1.32175584e+00, -1.34992672e+00, -1.35583515e+00,\n",
       "                     -1.36097655e+00, -1.37486567e+00, -1.38629436e+00, -1.39183454e+00,\n",
       "                     -1.41182766e+00, -1.43508453e+00, -1.45225233e+00, -1.46633707e+00,\n",
       "                     -1.47330574e+00, -1.48807706e+00, -1.50407740e+00, -1.50803780e+00,\n",
       "                     -1.54044504e+00, -1.55059741e+00, -1.58045038e+00, -1.59760345e+00,\n",
       "                     -1.60943791e+00, -1.60943791e+00, -1.65335715e+00, -1.67397643e+00,\n",
       "                     -1.69773052e+00, -1.70474809e+00, -1.72722095e+00, -1.77070606e+00,\n",
       "                     -1.79175947e+00, -1.79175947e+00, -1.82161243e+00, -1.89711998e+00,\n",
       "                     -1.90954250e+00, -1.94591015e+00, -1.94591015e+00, -1.96944065e+00,\n",
       "                     -2.01490302e+00, -2.03688193e+00, -2.07944154e+00, -2.14006616e+00,\n",
       "                     -2.16905370e+00, -2.19722458e+00, -2.48490665e+00, -2.51230562e+00,\n",
       "                     -2.53897387e+00, -2.56494936e+00, -2.67414865e+00, -2.70805020e+00,\n",
       "                     -2.83321334e+00, -2.99573227e+00, -4.07753744e+00, -3.45387764e+01]), auc_score=0.533583923570405, privacy_risk=0.5244830364336228, accuracy=0.5244830364336228, tpr_ind=0.4340703607555277, tnr_ind=0.6148957121117179, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.05621699, 0.06248322, 0.07528422, 0.08190851,\n",
       "                     0.08262465, 0.08360935, 0.08906991, 0.09005461, 0.10106526,\n",
       "                     0.10616776, 0.10768955, 0.10786859, 0.11055411, 0.11332916,\n",
       "                     0.1145824 , 0.11735744, 0.1181631 , 0.1217438 , 0.12290753,\n",
       "                     0.12621968, 0.13015845, 0.14358607, 0.14770388, 0.14824098,\n",
       "                     0.1605944 , 0.16301137, 0.16345896, 0.16703966, 0.17026229,\n",
       "                     0.17563334, 0.18718109, 0.18959807, 0.19103035, 0.19138842,\n",
       "                     0.19774416, 0.20311521, 0.20490556, 0.20669591, 0.21502104,\n",
       "                     0.22191388, 0.22334616, 0.22621072, 0.23552054, 0.24957479,\n",
       "                     0.25091755, 0.27410259, 0.2757139 , 0.28045833, 0.28144302,\n",
       "                     0.29200609, 0.29907797, 0.30051025, 0.3145645 , 0.31554919,\n",
       "                     0.32056217, 0.32235252, 0.32288962, 0.34043506, 0.3483126 ,\n",
       "                     0.35162474, 0.35386268, 0.3595918 , 0.36657417, 0.39351893,\n",
       "                     0.41983708, 0.42243309, 0.4240444 , 0.42807269, 0.42878883,\n",
       "                     0.43791961, 0.44633426, 0.44982544, 0.45242145, 0.46092561,\n",
       "                     0.46334258, 0.47193626, 0.47659117, 0.48858652, 0.49127204,\n",
       "                     0.4956584 , 0.50067138, 0.50702712, 0.51490466, 0.51973861,\n",
       "                     0.52197655, 0.52331931, 0.52493062, 0.5299436 , 0.53334527,\n",
       "                     0.5350461 , 0.53844777, 0.54086474, 0.54381882, 0.54480351,\n",
       "                     0.54901083, 0.55062215, 0.55473995, 0.55912631, 0.56646674,\n",
       "                     0.56798854, 0.57371766, 0.58795094, 0.59197923, 0.59394862,\n",
       "                     0.59529138, 0.59860353, 0.60093098, 0.6046012 , 0.60585444,\n",
       "                     0.60657058, 0.61561185, 0.61722317, 0.62053531, 0.62313132,\n",
       "                     0.62465312, 0.62868141, 0.63082983, 0.63226211, 0.63799123,\n",
       "                     0.63996061, 0.64175096, 0.64201951, 0.64461552, 0.65696894,\n",
       "                     0.65974398, 0.66117626, 0.6624295 , 0.66511503, 0.6660102 ,\n",
       "                     0.67021753, 0.67156029, 0.67451437, 0.67639424, 0.68024349,\n",
       "                     0.68982186, 0.69429774, 0.69805747, 0.70110107, 0.70271238,\n",
       "                     0.70378659, 0.70477128, 0.70611405, 0.70781488, 0.71076896,\n",
       "                     0.71255931, 0.71981022, 0.72177961, 0.72267478, 0.72392803,\n",
       "                     0.72446513, 0.72867246, 0.73010474, 0.73108943, 0.73422254,\n",
       "                     0.73646048, 0.74048877, 0.74111539, 0.74380091, 0.74415898,\n",
       "                     0.75203652, 0.75248411, 0.75311073, 0.75910841, 0.75955599,\n",
       "                     0.76045117, 0.76116731, 0.76197297, 0.76438994, 0.77450542,\n",
       "                     0.78095068, 0.78202489, 0.7856951 , 0.78802256, 0.79097664,\n",
       "                     0.79303554, 0.79491541, 0.79581058, 0.79625817, 0.79715334,\n",
       "                     0.79849611, 0.79912273, 0.80028646, 0.80333005, 0.80485185,\n",
       "                     0.80610509, 0.80843255, 0.81076   , 0.81702623, 0.81899561,\n",
       "                     0.82078596, 0.82329245, 0.82400859, 0.83081192, 0.83215469,\n",
       "                     0.83618297, 0.83788381, 0.84200161, 0.84370244, 0.84549279,\n",
       "                     0.85005819, 0.85453406, 0.85480261, 0.85605586, 0.85641393,\n",
       "                     0.85641393, 0.85874138, 0.86975204, 0.88004655, 0.88398532,\n",
       "                     0.88738698, 0.88846119, 0.8905201 , 0.89302659, 0.90287351,\n",
       "                     0.90323158, 0.90475338, 0.90609614, 0.90627518, 0.91164623,\n",
       "                     0.91182526, 0.91719631, 0.92068749, 0.92194074, 0.92417868,\n",
       "                     0.92507385, 0.93384657, 0.9340256 , 0.93787485, 0.93957569,\n",
       "                     0.94136604, 0.94315639, 0.94503625, 0.94825888, 0.94942261,\n",
       "                     0.94969116, 0.95183958, 0.95524125, 0.95542028, 0.95604691,\n",
       "                     0.95658401, 0.95846388, 0.96034375, 0.96097037, 0.96240265,\n",
       "                     0.96320831, 0.96356638, 0.96535673, 0.96875839, 0.96893743,\n",
       "                     0.97054874, 0.97538269, 0.97672545, 0.97717304, 0.97797869,\n",
       "                     0.97869483, 0.97869483, 0.97932146, 0.97950049, 0.97950049,\n",
       "                     0.97994808, 0.98039567, 0.98048518, 0.98066422, 0.98138036,\n",
       "                     0.98388685, 0.98442395, 0.98531913, 0.9856772 , 0.9856772 ,\n",
       "                     0.98594575, 0.98693044, 0.98746755, 1.        ]), tpr=array([0.        , 0.0665115 , 0.07259869, 0.08683198, 0.09363531,\n",
       "                     0.09497807, 0.09605228, 0.10294513, 0.10482499, 0.11646227,\n",
       "                     0.12263898, 0.12514547, 0.12595112, 0.12899472, 0.13123266,\n",
       "                     0.13266494, 0.13651419, 0.13714081, 0.14018441, 0.14134813,\n",
       "                     0.14421269, 0.14850953, 0.16524931, 0.16918808, 0.17008325,\n",
       "                     0.18476412, 0.18691254, 0.1877182 , 0.19111986, 0.19371587,\n",
       "                     0.19908692, 0.21108227, 0.21457345, 0.21591621, 0.2169009 ,\n",
       "                     0.22442037, 0.22988094, 0.23211888, 0.23498344, 0.24420374,\n",
       "                     0.25082804, 0.25333453, 0.2572733 , 0.26452421, 0.27651956,\n",
       "                     0.27768329, 0.30346433, 0.30597082, 0.3115209 , 0.31366932,\n",
       "                     0.32351625, 0.33031958, 0.33157282, 0.34625369, 0.34723839,\n",
       "                     0.35359413, 0.3560111 , 0.35672724, 0.37498881, 0.38241876,\n",
       "                     0.38635753, 0.38796885, 0.39432459, 0.40193358, 0.43022111,\n",
       "                     0.45680781, 0.46056754, 0.46235789, 0.46567004, 0.4670128 ,\n",
       "                     0.47659117, 0.48536389, 0.4879599 , 0.49073494, 0.49843344,\n",
       "                     0.5007609 , 0.50890699, 0.51221914, 0.52421448, 0.52681049,\n",
       "                     0.53137588, 0.53603079, 0.54095426, 0.55062215, 0.5550085 ,\n",
       "                     0.55760451, 0.55921583, 0.56145376, 0.56861516, 0.57156924,\n",
       "                     0.57309104, 0.57622415, 0.57828305, 0.57989437, 0.5810581 ,\n",
       "                     0.58410169, 0.58598156, 0.5902784 , 0.59448572, 0.60111002,\n",
       "                     0.60290037, 0.60827142, 0.62169904, 0.62501119, 0.62724913,\n",
       "                     0.62894996, 0.63270969, 0.63387342, 0.63924447, 0.64076627,\n",
       "                     0.64201951, 0.65294065, 0.65392534, 0.65750604, 0.66251902,\n",
       "                     0.66493599, 0.66824814, 0.67039656, 0.67129174, 0.67728941,\n",
       "                     0.67899024, 0.68087011, 0.68158625, 0.68462985, 0.69385015,\n",
       "                     0.69626712, 0.69796795, 0.69993734, 0.70199624, 0.703339  ,\n",
       "                     0.7063826 , 0.70826247, 0.7105004 , 0.71327545, 0.71676663,\n",
       "                     0.7248232 , 0.72822487, 0.73091039, 0.73305881, 0.73484916,\n",
       "                     0.73771372, 0.73896697, 0.74084684, 0.74263719, 0.74415898,\n",
       "                     0.7463074 , 0.7544535 , 0.75713902, 0.75776564, 0.75937696,\n",
       "                     0.76080924, 0.76582222, 0.76653836, 0.76823919, 0.7708352 ,\n",
       "                     0.77271507, 0.77656432, 0.77710142, 0.77924984, 0.77996598,\n",
       "                     0.78784352, 0.7887387 , 0.78981291, 0.79357264, 0.7943783 ,\n",
       "                     0.79697431, 0.79813804, 0.79965983, 0.80189777, 0.81093904,\n",
       "                     0.81451974, 0.81568347, 0.81998031, 0.82266583, 0.82535136,\n",
       "                     0.82651508, 0.82839495, 0.82911109, 0.83009578, 0.83134903,\n",
       "                     0.8332289 , 0.83412407, 0.8358249 , 0.83994271, 0.84119595,\n",
       "                     0.84209113, 0.84352341, 0.84594038, 0.85122191, 0.85390744,\n",
       "                     0.85641393, 0.8588309 , 0.86017366, 0.86635037, 0.8680512 ,\n",
       "                     0.87216901, 0.87333274, 0.87718199, 0.87852475, 0.879778  ,\n",
       "                     0.88398532, 0.88855071, 0.88917733, 0.89069913, 0.89150479,\n",
       "                     0.89177334, 0.8931161 , 0.90448483, 0.91630114, 0.91934473,\n",
       "                     0.92185122, 0.92247784, 0.92399964, 0.9268642 , 0.93384657,\n",
       "                     0.93411512, 0.93501029, 0.93733775, 0.93769582, 0.94297735,\n",
       "                     0.94342494, 0.94575239, 0.94906454, 0.94978068, 0.95157103,\n",
       "                     0.95237669, 0.96043326, 0.96079133, 0.96437203, 0.96652045,\n",
       "                     0.96768418, 0.96840032, 0.97028019, 0.9728762 , 0.97368185,\n",
       "                     0.97430848, 0.97583027, 0.97788918, 0.97815773, 0.9785158 ,\n",
       "                     0.97941097, 0.98245457, 0.9836183 , 0.98379733, 0.98442395,\n",
       "                     0.98522961, 0.98540865, 0.98585623, 0.98889983, 0.98907886,\n",
       "                     0.989795  , 0.99265956, 0.9933757 , 0.99382329, 0.99400233,\n",
       "                     0.99444991, 0.99453943, 0.99507654, 0.99516605, 0.99525557,\n",
       "                     0.99552412, 0.99588219, 0.99597171, 0.99624026, 0.99686689,\n",
       "                     0.99803061, 0.99820965, 0.99883627, 0.99892579, 0.99901531,\n",
       "                     0.99946289, 0.99991048, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.45987994e-02, -3.09622256e-02,\n",
       "                     -6.37158144e-02, -6.45385211e-02, -8.00427077e-02, -8.70113770e-02,\n",
       "                     -9.09717782e-02, -9.53101798e-02, -9.66268357e-02, -1.01782694e-01,\n",
       "                     -1.05360516e-01, -1.11225635e-01, -1.13328685e-01, -1.17783036e-01,\n",
       "                     -1.30620182e-01, -1.33531393e-01, -1.37201122e-01, -1.43100844e-01,\n",
       "                     -1.45182010e-01, -1.54150680e-01, -1.57963113e-01, -1.67054085e-01,\n",
       "                     -1.82321557e-01, -1.88400603e-01, -1.89242000e-01, -2.00670695e-01,\n",
       "                     -2.12561442e-01, -2.16223108e-01, -2.23143551e-01, -2.26124179e-01,\n",
       "                     -2.28258652e-01, -2.36388778e-01, -2.41162057e-01, -2.42012036e-01,\n",
       "                     -2.45834963e-01, -2.46860078e-01, -2.47836164e-01, -2.48072934e-01,\n",
       "                     -2.49811798e-01, -2.51314428e-01, -2.58861634e-01, -2.59511195e-01,\n",
       "                     -2.61215499e-01, -2.68263987e-01, -2.71933715e-01, -2.78713402e-01,\n",
       "                     -2.79584862e-01, -2.87682072e-01, -2.89952221e-01, -2.94239473e-01,\n",
       "                     -3.05381650e-01, -3.07305344e-01, -3.10154928e-01, -3.12031101e-01,\n",
       "                     -3.15081047e-01, -3.18453731e-01, -3.23787077e-01, -3.26091521e-01,\n",
       "                     -3.26684230e-01, -3.28504067e-01, -3.32439973e-01, -3.36472237e-01,\n",
       "                     -3.49051019e-01, -3.56001316e-01, -3.56674944e-01, -3.71563556e-01,\n",
       "                     -3.78066134e-01, -3.82992252e-01, -3.89766199e-01, -3.91766264e-01,\n",
       "                     -3.93904286e-01, -3.94654192e-01, -4.05465108e-01, -4.05465108e-01,\n",
       "                     -4.09121419e-01, -4.14433778e-01, -4.15366179e-01, -4.16893804e-01,\n",
       "                     -4.24883194e-01, -4.30782916e-01, -4.35318071e-01, -4.35862585e-01,\n",
       "                     -4.38913042e-01, -4.39366660e-01, -4.41832752e-01, -4.44685821e-01,\n",
       "                     -4.54255272e-01, -4.54736157e-01, -4.62623522e-01, -4.70003629e-01,\n",
       "                     -4.75423697e-01, -4.76924072e-01, -4.79573080e-01, -4.80972661e-01,\n",
       "                     -4.81838087e-01, -4.85507816e-01, -4.93657820e-01, -4.99955952e-01,\n",
       "                     -5.00775288e-01, -5.10825624e-01, -5.14817645e-01, -5.16216472e-01,\n",
       "                     -5.18793793e-01, -5.21296924e-01, -5.25010259e-01, -5.26093096e-01,\n",
       "                     -5.30628251e-01, -5.34082486e-01, -5.38996501e-01, -5.43086486e-01,\n",
       "                     -5.46543706e-01, -5.59615788e-01, -5.69768159e-01, -5.75364145e-01,\n",
       "                     -5.78736829e-01, -5.83146285e-01, -5.87786665e-01, -6.07491736e-01,\n",
       "                     -6.10909082e-01, -6.19039208e-01, -6.28608659e-01, -6.32522559e-01,\n",
       "                     -6.33129171e-01, -6.35988767e-01, -6.39079959e-01, -6.46627165e-01,\n",
       "                     -6.48695418e-01, -6.59245629e-01, -6.63294217e-01, -6.69049629e-01,\n",
       "                     -6.72944473e-01, -6.76886660e-01, -6.80243776e-01, -6.93147181e-01,\n",
       "                     -7.06219262e-01, -7.09676483e-01, -7.13766468e-01, -7.17839793e-01,\n",
       "                     -7.23918839e-01, -7.28238500e-01, -7.39667196e-01, -7.41937345e-01,\n",
       "                     -7.50305594e-01, -7.53771802e-01, -7.56998653e-01, -7.57685702e-01,\n",
       "                     -7.62140052e-01, -7.73189888e-01, -7.82759339e-01, -7.86832665e-01,\n",
       "                     -8.10930216e-01, -8.16761137e-01, -8.22358912e-01, -8.26678573e-01,\n",
       "                     -8.33919734e-01, -8.47297860e-01, -8.47297860e-01, -8.64997437e-01,\n",
       "                     -8.69770716e-01, -8.75468737e-01, -8.82389180e-01, -8.87303195e-01,\n",
       "                     -8.93817876e-01, -8.95384047e-01, -9.00786545e-01, -9.04456274e-01,\n",
       "                     -9.08258560e-01, -9.10332422e-01, -9.16290732e-01, -9.31558204e-01,\n",
       "                     -9.32820034e-01, -9.42608040e-01, -9.55511445e-01, -9.61411167e-01,\n",
       "                     -9.62810748e-01, -9.65080896e-01, -9.69400557e-01, -9.71860583e-01,\n",
       "                     -9.80829253e-01, -9.93251773e-01, -1.00680474e+00, -1.00764051e+00,\n",
       "                     -1.02450432e+00, -1.02961942e+00, -1.03407377e+00, -1.03489647e+00,\n",
       "                     -1.04045637e+00, -1.04145387e+00, -1.04982212e+00, -1.06087196e+00,\n",
       "                     -1.07613943e+00, -1.07909947e+00, -1.08091271e+00, -1.09133953e+00,\n",
       "                     -1.09861229e+00, -1.09861229e+00, -1.12059120e+00, -1.12214279e+00,\n",
       "                     -1.12658614e+00, -1.13076940e+00, -1.14513230e+00, -1.15577070e+00,\n",
       "                     -1.17007125e+00, -1.20397280e+00, -1.20397280e+00, -1.20554637e+00,\n",
       "                     -1.22199131e+00, -1.25276297e+00, -1.26291534e+00, -1.27296568e+00,\n",
       "                     -1.27766052e+00, -1.27919623e+00, -1.28519824e+00, -1.29928298e+00,\n",
       "                     -1.30833282e+00, -1.31661444e+00, -1.32175584e+00, -1.32963433e+00,\n",
       "                     -1.33500107e+00, -1.36687628e+00, -1.37951467e+00, -1.38629436e+00,\n",
       "                     -1.41098697e+00, -1.41369334e+00, -1.43508453e+00, -1.44691898e+00,\n",
       "                     -1.47017585e+00, -1.47590652e+00, -1.47810191e+00, -1.50407740e+00,\n",
       "                     -1.50935445e+00, -1.51550609e+00, -1.51634749e+00, -1.51982575e+00,\n",
       "                     -1.52349548e+00, -1.53733462e+00, -1.54044504e+00, -1.55814462e+00,\n",
       "                     -1.58923521e+00, -1.59760345e+00, -1.60943791e+00, -1.60943791e+00,\n",
       "                     -1.63760879e+00, -1.65292302e+00, -1.70474809e+00, -1.75785792e+00,\n",
       "                     -1.76190651e+00, -1.79175947e+00, -1.87180218e+00, -1.92333583e+00,\n",
       "                     -1.94591015e+00, -2.00148000e+00, -2.01490302e+00, -2.05412373e+00,\n",
       "                     -2.07944154e+00, -2.10006083e+00, -2.19722458e+00, -2.19722458e+00,\n",
       "                     -2.23359222e+00, -2.25129180e+00, -2.30258509e+00, -2.33537492e+00,\n",
       "                     -2.38482319e+00, -2.39789527e+00, -2.44234704e+00, -2.48490665e+00,\n",
       "                     -2.56494936e+00, -2.77258872e+00, -2.78501124e+00, -3.49042852e+00,\n",
       "                     -4.23410650e+00, -3.45387764e+01]), auc_score=0.5295168512668289, privacy_risk=0.5201414376510608, accuracy=0.5201414376510608, tpr_ind=0.6649359949870199, tnr_ind=0.3753468803151016, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.05782831, 0.05961866, 0.06257273, 0.08011816,\n",
       "                     0.08119237, 0.08289321, 0.09632083, 0.09685794, 0.09766359,\n",
       "                     0.10133381, 0.10482499, 0.10661534, 0.11037508, 0.11091218,\n",
       "                     0.12263898, 0.12299705, 0.12720437, 0.13069555, 0.13105362,\n",
       "                     0.14036344, 0.14242234, 0.14358607, 0.1570137 , 0.15978874,\n",
       "                     0.17984066, 0.18127294, 0.18485364, 0.18736013, 0.19326828,\n",
       "                     0.19470056, 0.1969385 , 0.19863933, 0.20239907, 0.22307761,\n",
       "                     0.22907528, 0.23023901, 0.23677379, 0.24411422, 0.24760541,\n",
       "                     0.25995882, 0.26157014, 0.26577746, 0.26774684, 0.27320741,\n",
       "                     0.27455017, 0.27687763, 0.27795184, 0.28385999, 0.28600841,\n",
       "                     0.29012622, 0.29889893, 0.30006266, 0.30498612, 0.30695551,\n",
       "                     0.3115209 , 0.31608629, 0.32271059, 0.32870826, 0.33864471,\n",
       "                     0.33953988, 0.34893922, 0.35278847, 0.35404172, 0.35511593,\n",
       "                     0.35896518, 0.36370961, 0.39557784, 0.39754722, 0.40318682,\n",
       "                     0.40739415, 0.40927401, 0.41106436, 0.41187002, 0.41374989,\n",
       "                     0.41580879, 0.42064274, 0.42314923, 0.427088  , 0.43031063,\n",
       "                     0.43505505, 0.43845672, 0.44132128, 0.44275356, 0.44785606,\n",
       "                     0.45644974, 0.46414824, 0.51732164, 0.53137588, 0.53441948,\n",
       "                     0.53764211, 0.53961149, 0.54623579, 0.55026408, 0.55205443,\n",
       "                     0.55688837, 0.56261749, 0.57022648, 0.57532898, 0.58195327,\n",
       "                     0.58499687, 0.59099454, 0.59153164, 0.59502283, 0.5979769 ,\n",
       "                     0.60263181, 0.60316892, 0.60621251, 0.60773431, 0.60907707,\n",
       "                     0.61570137, 0.61990869, 0.62268373, 0.62357891, 0.62590636,\n",
       "                     0.62644347, 0.62877092, 0.64515263, 0.64792767, 0.6496285 ,\n",
       "                     0.65222451, 0.65661087, 0.65875929, 0.66010205, 0.66144481,\n",
       "                     0.66207143, 0.66332468, 0.66538358, 0.6685167 , 0.67764748,\n",
       "                     0.68078059, 0.69573002, 0.69904216, 0.7063826 , 0.70951571,\n",
       "                     0.71094799, 0.71282786, 0.71372303, 0.71452869, 0.7156029 ,\n",
       "                     0.71846746, 0.72410706, 0.72777728, 0.72974667, 0.73055232,\n",
       "                     0.74022021, 0.74156298, 0.74263719, 0.74335333, 0.74460657,\n",
       "                     0.74648644, 0.74890341, 0.75328977, 0.75597529, 0.75687047,\n",
       "                     0.75946648, 0.76224152, 0.7636738 , 0.76501656, 0.76662788,\n",
       "                     0.76761257, 0.76832871, 0.77146182, 0.77432638, 0.77808612,\n",
       "                     0.77933936, 0.78068212, 0.78551607, 0.78954436, 0.79446782,\n",
       "                     0.79625817, 0.79867514, 0.80082356, 0.80207681, 0.80440426,\n",
       "                     0.80610509, 0.81425119, 0.83994271, 0.84549279, 0.84853639,\n",
       "                     0.85229612, 0.85283323, 0.85337033, 0.8552502 , 0.85721959,\n",
       "                     0.8582938 , 0.85981559, 0.86366485, 0.86661892, 0.86867783,\n",
       "                     0.86939397, 0.86975204, 0.87046818, 0.87127383, 0.87279563,\n",
       "                     0.87458598, 0.87583923, 0.88792409, 0.89025154, 0.89195238,\n",
       "                     0.8931161 , 0.89365321, 0.89499597, 0.89902426, 0.89911378,\n",
       "                     0.90538   , 0.90725987, 0.90913974, 0.91137767, 0.91263092,\n",
       "                     0.91298899, 0.9140632 , 0.9140632 , 0.91692776, 0.92041894,\n",
       "                     0.92167219, 0.92417868, 0.92471578, 0.92570047, 0.92641661,\n",
       "                     0.92820696, 0.92928117, 0.93080297, 0.93232477, 0.93644257,\n",
       "                     0.93733775, 0.93993376, 0.94020231, 0.94073941, 0.94217169,\n",
       "                     0.94825888, 0.94933309, 0.95004923, 0.95103393, 0.95157103,\n",
       "                     0.95291379, 0.95559932, 0.95694208, 0.95694208, 0.9626712 ,\n",
       "                     0.96365589, 0.96813177, 0.96840032, 0.96893743, 0.97162295,\n",
       "                     0.97171247, 0.97233909, 0.97377137, 0.97386089, 0.9754722 ,\n",
       "                     0.97565124, 0.97717304, 0.97762062, 0.97815773, 0.97824725,\n",
       "                     0.9790529 , 0.97932146, 0.97967953, 0.98030615, 0.98066422,\n",
       "                     0.98129084, 0.98200698, 0.98272312, 0.98326023, 1.        ]), tpr=array([0.        , 0.07179304, 0.07528422, 0.07805926, 0.09327724,\n",
       "                     0.09506759, 0.0966789 , 0.11153881, 0.1125235 , 0.11341867,\n",
       "                     0.117626  , 0.12165428, 0.1247874 , 0.12908424, 0.130427  ,\n",
       "                     0.14331752, 0.14385462, 0.14859905, 0.15298541, 0.153433  ,\n",
       "                     0.16372751, 0.16542834, 0.16668159, 0.18082535, 0.18440605,\n",
       "                     0.20830722, 0.20982902, 0.21323069, 0.2178856 , 0.22415182,\n",
       "                     0.22585265, 0.22818011, 0.23014949, 0.23328261, 0.25637812,\n",
       "                     0.2629129 , 0.26434518, 0.26917912, 0.27813087, 0.28063736,\n",
       "                     0.2915585 , 0.29397547, 0.2987199 , 0.30212156, 0.30731358,\n",
       "                     0.30964103, 0.31241608, 0.31366932, 0.3181452 , 0.32011458,\n",
       "                     0.32521708, 0.33273655, 0.33345269, 0.33766001, 0.33998747,\n",
       "                     0.34392624, 0.34947632, 0.35627965, 0.36236684, 0.37561543,\n",
       "                     0.37651061, 0.38555188, 0.38814788, 0.38922209, 0.3902963 ,\n",
       "                     0.39495121, 0.39915854, 0.42771462, 0.42977352, 0.43469698,\n",
       "                     0.43854624, 0.44051562, 0.44203742, 0.44391729, 0.44597619,\n",
       "                     0.44821413, 0.45483842, 0.45913526, 0.46352162, 0.46611763,\n",
       "                     0.46916122, 0.47318951, 0.47551696, 0.47650166, 0.4833945 ,\n",
       "                     0.49198818, 0.50004476, 0.54874228, 0.56225942, 0.56628771,\n",
       "                     0.56995793, 0.57192731, 0.57828305, 0.58266941, 0.58445976,\n",
       "                     0.59063647, 0.5979769 , 0.60442216, 0.60880852, 0.61596992,\n",
       "                     0.61937159, 0.62527974, 0.62689106, 0.62805478, 0.63074031,\n",
       "                     0.63503715, 0.63629039, 0.63915495, 0.64013965, 0.64228807,\n",
       "                     0.64900188, 0.65240354, 0.654731  , 0.65598424, 0.65777459,\n",
       "                     0.65875929, 0.66198192, 0.67299257, 0.6741563 , 0.67594665,\n",
       "                     0.67907976, 0.68346612, 0.68713634, 0.68865813, 0.68946379,\n",
       "                     0.69035897, 0.69179125, 0.69349208, 0.69698326, 0.70521887,\n",
       "                     0.70826247, 0.72348044, 0.72643452, 0.73431206, 0.73762421,\n",
       "                     0.73923552, 0.74057828, 0.74138394, 0.74210008, 0.74344284,\n",
       "                     0.74666547, 0.75051473, 0.75320025, 0.75472205, 0.75570674,\n",
       "                     0.76492704, 0.76761257, 0.76841823, 0.76985051, 0.7708352 ,\n",
       "                     0.77262555, 0.77522156, 0.78032405, 0.78193537, 0.78265151,\n",
       "                     0.78471041, 0.78560559, 0.78712738, 0.78864918, 0.79052905,\n",
       "                     0.79133471, 0.79240892, 0.79616865, 0.79831707, 0.80234536,\n",
       "                     0.80279295, 0.80547847, 0.80941724, 0.81389312, 0.81765285,\n",
       "                     0.81872706, 0.82132307, 0.8250828 , 0.82624653, 0.82839495,\n",
       "                     0.83072241, 0.83833139, 0.8654552 , 0.86993107, 0.8746755 ,\n",
       "                     0.87843523, 0.87897234, 0.88022558, 0.882374  , 0.88398532,\n",
       "                     0.88532808, 0.88756602, 0.88971444, 0.89302659, 0.8941008 ,\n",
       "                     0.89508549, 0.89598066, 0.8966968 , 0.89759198, 0.89929281,\n",
       "                     0.90144123, 0.90233641, 0.9146003 , 0.91639065, 0.91836004,\n",
       "                     0.91880763, 0.91925521, 0.92032942, 0.92399964, 0.92435771,\n",
       "                     0.92963924, 0.93205622, 0.93474174, 0.93689016, 0.93841196,\n",
       "                     0.93930713, 0.94091845, 0.941187  , 0.94396204, 0.94584191,\n",
       "                     0.94655805, 0.94816937, 0.94861695, 0.94960165, 0.9504073 ,\n",
       "                     0.95219765, 0.95336138, 0.9549727 , 0.95577835, 0.95935905,\n",
       "                     0.96016471, 0.96302927, 0.96455107, 0.96499866, 0.96696804,\n",
       "                     0.97368185, 0.97457703, 0.97511413, 0.97574076, 0.97618834,\n",
       "                     0.97779966, 0.97896339, 0.97976904, 0.98012711, 0.98558768,\n",
       "                     0.98639334, 0.98943693, 0.98970549, 0.99006356, 0.99221198,\n",
       "                     0.99230149, 0.99310715, 0.99391281, 0.99400233, 0.99579268,\n",
       "                     0.99597171, 0.99650882, 0.99686689, 0.99722496, 0.99731447,\n",
       "                     0.99776206, 0.99785158, 0.9979411 , 0.99910482, 0.99919434,\n",
       "                     0.99928386, 0.99982096, 0.99991048, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.53178080e-02, -3.17486983e-02,\n",
       "                     -3.46855580e-02, -4.87901642e-02, -5.40672213e-02, -7.53980175e-02,\n",
       "                     -8.70113770e-02, -9.53101798e-02, -1.01096117e-01, -1.05360516e-01,\n",
       "                     -1.08213585e-01, -1.17783036e-01, -1.25163143e-01, -1.30053128e-01,\n",
       "                     -1.54150680e-01, -1.56842471e-01, -1.68622712e-01, -1.82321557e-01,\n",
       "                     -1.89541805e-01, -1.91055237e-01, -1.94156014e-01, -1.94900339e-01,\n",
       "                     -2.02940844e-01, -2.05764950e-01, -2.11309094e-01, -2.12561442e-01,\n",
       "                     -2.23143551e-01, -2.28841572e-01, -2.33614851e-01, -2.38411023e-01,\n",
       "                     -2.41162057e-01, -2.51314428e-01, -2.55182905e-01, -2.63417450e-01,\n",
       "                     -2.71933715e-01, -2.73695830e-01, -2.77631737e-01, -2.78713402e-01,\n",
       "                     -2.83575290e-01, -2.87682072e-01, -2.92387963e-01, -2.94239473e-01,\n",
       "                     -2.96265816e-01, -2.97251523e-01, -3.03682414e-01, -3.05381650e-01,\n",
       "                     -3.07484700e-01, -3.10154928e-01, -3.13657559e-01, -3.14115330e-01,\n",
       "                     -3.18453731e-01, -3.24239668e-01, -3.25422400e-01, -3.26684230e-01,\n",
       "                     -3.27212911e-01, -3.32705754e-01, -3.34369186e-01, -3.35506520e-01,\n",
       "                     -3.36472237e-01, -3.40706541e-01, -3.46276237e-01, -3.48306694e-01,\n",
       "                     -3.48306694e-01, -3.52821375e-01, -3.54545018e-01, -3.57301707e-01,\n",
       "                     -3.61013346e-01, -3.62114667e-01, -3.65934269e-01, -3.74693449e-01,\n",
       "                     -3.85662481e-01, -3.89464767e-01, -3.90866309e-01, -3.92042088e-01,\n",
       "                     -4.05465108e-01, -4.05465108e-01, -4.12244795e-01, -4.16893804e-01,\n",
       "                     -4.24883194e-01, -4.27444015e-01, -4.30782916e-01, -4.35318071e-01,\n",
       "                     -4.35318071e-01, -4.39598114e-01, -4.41832752e-01, -4.42751448e-01,\n",
       "                     -4.46551968e-01, -4.56017387e-01, -4.60815203e-01, -4.64305608e-01,\n",
       "                     -4.64707942e-01, -4.64888529e-01, -4.70003629e-01, -4.75423697e-01,\n",
       "                     -4.76082675e-01, -4.76924072e-01, -4.77627554e-01, -4.85507816e-01,\n",
       "                     -4.89548225e-01, -4.92476485e-01, -5.10825624e-01, -5.26093096e-01,\n",
       "                     -5.30628251e-01, -5.35518236e-01, -5.38996501e-01, -5.41597282e-01,\n",
       "                     -5.46543706e-01, -5.59615788e-01, -5.65313809e-01, -5.67106460e-01,\n",
       "                     -5.70544858e-01, -5.79818495e-01, -5.87786665e-01, -5.97837001e-01,\n",
       "                     -6.06135804e-01, -6.08350644e-01, -6.13104473e-01, -6.15185639e-01,\n",
       "                     -6.19039208e-01, -6.29968279e-01, -6.30233355e-01, -6.32522559e-01,\n",
       "                     -6.35988767e-01, -6.41853886e-01, -6.61398482e-01, -6.66478933e-01,\n",
       "                     -6.67171694e-01, -6.71168274e-01, -6.78332095e-01, -6.93147181e-01,\n",
       "                     -7.08185058e-01, -7.15620036e-01, -7.19815428e-01, -7.20546155e-01,\n",
       "                     -7.25937003e-01, -7.47214402e-01, -7.53771802e-01, -7.57685702e-01,\n",
       "                     -7.60286483e-01, -7.60588461e-01, -7.73189888e-01, -7.77704569e-01,\n",
       "                     -7.80158558e-01, -7.85806011e-01, -7.88457360e-01, -7.98507696e-01,\n",
       "                     -8.10930216e-01, -8.20980552e-01, -8.32909123e-01, -8.37396789e-01,\n",
       "                     -8.39750655e-01, -8.47297860e-01, -8.64997437e-01, -8.71838969e-01,\n",
       "                     -8.75468737e-01, -8.80358723e-01, -8.80358723e-01, -8.87303195e-01,\n",
       "                     -8.93817876e-01, -9.16290732e-01, -9.44461609e-01, -9.49080555e-01,\n",
       "                     -9.55511445e-01, -9.55511445e-01, -9.68250471e-01, -9.69400557e-01,\n",
       "                     -9.70778917e-01, -9.71860583e-01, -9.80829253e-01, -9.89412997e-01,\n",
       "                     -9.89718200e-01, -9.90398704e-01, -9.96333440e-01, -1.00458334e+00,\n",
       "                     -1.02118055e+00, -1.02796789e+00, -1.02961942e+00, -1.03365439e+00,\n",
       "                     -1.04145387e+00, -1.04145387e+00, -1.04982212e+00, -1.05605267e+00,\n",
       "                     -1.06087196e+00, -1.07613943e+00, -1.08518927e+00, -1.09861229e+00,\n",
       "                     -1.09861229e+00, -1.12601126e+00, -1.12846525e+00, -1.13140211e+00,\n",
       "                     -1.13943428e+00, -1.16315081e+00, -1.18269541e+00, -1.19139402e+00,\n",
       "                     -1.19392247e+00, -1.20251188e+00, -1.20896035e+00, -1.21302264e+00,\n",
       "                     -1.22377543e+00, -1.22377543e+00, -1.22866542e+00, -1.24225499e+00,\n",
       "                     -1.25276297e+00, -1.25518135e+00, -1.25804003e+00, -1.26224171e+00,\n",
       "                     -1.27629347e+00, -1.27766052e+00, -1.28093385e+00, -1.28401551e+00,\n",
       "                     -1.29928298e+00, -1.31094492e+00, -1.31218639e+00, -1.32175584e+00,\n",
       "                     -1.32913595e+00, -1.33500107e+00, -1.33977435e+00, -1.35812348e+00,\n",
       "                     -1.36097655e+00, -1.36687628e+00, -1.37230812e+00, -1.38629436e+00,\n",
       "                     -1.39871688e+00, -1.41369334e+00, -1.41706602e+00, -1.42946653e+00,\n",
       "                     -1.43508453e+00, -1.46283444e+00, -1.49065438e+00, -1.50407740e+00,\n",
       "                     -1.54044504e+00, -1.55059741e+00, -1.56861592e+00, -1.58696506e+00,\n",
       "                     -1.60943791e+00, -1.65292302e+00, -1.65822808e+00, -1.68213974e+00,\n",
       "                     -1.69459572e+00, -1.73113485e+00, -1.73460106e+00, -1.74919985e+00,\n",
       "                     -1.75642010e+00, -1.79175947e+00, -1.86321843e+00, -1.92990981e+00,\n",
       "                     -1.94591015e+00, -2.10413415e+00, -2.14006616e+00, -2.19722458e+00,\n",
       "                     -2.27726729e+00, -2.30258509e+00, -2.30258509e+00, -2.34180581e+00,\n",
       "                     -2.39789527e+00, -2.48490665e+00, -2.62243645e+00, -2.94443898e+00,\n",
       "                     -3.04452244e+00, -3.37872453e+00, -3.46573590e+00, -3.68887945e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5270621236950437, privacy_risk=0.5184853638886402, accuracy=0.5184853638886402, tpr_ind=0.37561543281711574, tnr_ind=0.6613552949601648, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.0695551 , 0.07259869, 0.07850685, 0.08423597,\n",
       "                     0.08692149, 0.08906991, 0.09211351, 0.09265061, 0.09462   ,\n",
       "                     0.09578373, 0.09775311, 0.1110017 , 0.11261302, 0.11431385,\n",
       "                     0.11959538, 0.12093814, 0.12165428, 0.12648823, 0.12783099,\n",
       "                     0.12854713, 0.12944231, 0.13857309, 0.14421269, 0.1462716 ,\n",
       "                     0.14877809, 0.16283233, 0.18727061, 0.19147793, 0.19273118,\n",
       "                     0.19953451, 0.20383135, 0.20633784, 0.20821771, 0.21188792,\n",
       "                     0.21376779, 0.21958643, 0.22370423, 0.2271059 , 0.22943335,\n",
       "                     0.24375615, 0.24572554, 0.25091755, 0.25897413, 0.26774684,\n",
       "                     0.27123803, 0.27813087, 0.28099543, 0.28430758, 0.31295318,\n",
       "                     0.31438546, 0.31465401, 0.31581774, 0.31957748, 0.32154686,\n",
       "                     0.3401665 , 0.34294155, 0.34446334, 0.36934921, 0.37436219,\n",
       "                     0.37803241, 0.38143407, 0.38698416, 0.3902963 , 0.39593591,\n",
       "                     0.39915854, 0.40694656, 0.40927401, 0.41813625, 0.41965804,\n",
       "                     0.42377585, 0.4347865 , 0.44696088, 0.45036255, 0.46056754,\n",
       "                     0.47542745, 0.475696  , 0.48142512, 0.49906007, 0.50085042,\n",
       "                     0.50899651, 0.511503  , 0.51481515, 0.51776922, 0.52179751,\n",
       "                     0.52824277, 0.53424044, 0.53585176, 0.54462447, 0.54650434,\n",
       "                     0.54722048, 0.55277057, 0.5559932 , 0.5580521 , 0.56073762,\n",
       "                     0.56592964, 0.57165876, 0.57353863, 0.57756691, 0.57783547,\n",
       "                     0.58213231, 0.58356459, 0.58428073, 0.58830901, 0.59529138,\n",
       "                     0.59788739, 0.60048339, 0.60701817, 0.62169904, 0.62859189,\n",
       "                     0.63244114, 0.63458956, 0.63646943, 0.64085579, 0.64622684,\n",
       "                     0.64685346, 0.64873333, 0.65186644, 0.65517859, 0.65822218,\n",
       "                     0.66457792, 0.66654731, 0.66762152, 0.66842718, 0.67021753,\n",
       "                     0.67397726, 0.67496196, 0.67549906, 0.67684182, 0.70772536,\n",
       "                     0.7099633 , 0.71112703, 0.71246979, 0.7156029 , 0.71658759,\n",
       "                     0.71721422, 0.71819891, 0.71981022, 0.72267478, 0.72437562,\n",
       "                     0.72562886, 0.72876197, 0.73091039, 0.73225316, 0.73332737,\n",
       "                     0.73699758, 0.74111539, 0.74201056, 0.74299526, 0.74979859,\n",
       "                     0.75436398, 0.76259959, 0.76510608, 0.7677916 , 0.76806016,\n",
       "                     0.76949244, 0.77405783, 0.77602721, 0.77692239, 0.7779966 ,\n",
       "                     0.78086116, 0.78130875, 0.78426282, 0.78605317, 0.78829111,\n",
       "                     0.79222988, 0.79294602, 0.79393071, 0.79536299, 0.79706383,\n",
       "                     0.79903321, 0.79974935, 0.80046549, 0.80628413, 0.80682123,\n",
       "                     0.80843255, 0.81317698, 0.81478829, 0.81684719, 0.81765285,\n",
       "                     0.81962224, 0.82427715, 0.82544087, 0.83457166, 0.83600394,\n",
       "                     0.83707815, 0.84468714, 0.84773073, 0.84871542, 0.85390744,\n",
       "                     0.85972608, 0.86106884, 0.86169546, 0.8639334 , 0.86482857,\n",
       "                     0.86948348, 0.86948348, 0.87136335, 0.87342225, 0.87548116,\n",
       "                     0.87762958, 0.87933041, 0.88138931, 0.8833587 , 0.89526452,\n",
       "                     0.89624922, 0.89830812, 0.90618566, 0.90752842, 0.90931877,\n",
       "                     0.90985588, 0.91030346, 0.91155671, 0.91961328, 0.92095605,\n",
       "                     0.92283591, 0.92570047, 0.92856503, 0.93304091, 0.93536836,\n",
       "                     0.93724823, 0.93796437, 0.94235073, 0.94297735, 0.94342494,\n",
       "                     0.94548384, 0.94924358, 0.94995972, 0.95076537, 0.95166055,\n",
       "                     0.95219765, 0.95318235, 0.95443559, 0.95586787, 0.95918002,\n",
       "                     0.95918002, 0.96097037, 0.96696804, 0.97036971, 0.97108585,\n",
       "                     0.9713544 , 0.97314475, 0.9734133 , 0.9764569 , 0.97717304,\n",
       "                     0.97744159, 0.97815773, 0.97842628, 0.97869483, 0.97878435,\n",
       "                     0.97950049, 0.98012711, 0.98021663, 0.98182795, 0.98245457,\n",
       "                     0.98272312, 0.98379733, 0.98406588, 0.98460299, 0.98478202,\n",
       "                     0.98522961, 0.98540865, 0.98576672, 0.98612479, 1.        ]), tpr=array([0.        , 0.08172948, 0.08629487, 0.09291917, 0.09703697,\n",
       "                     0.10070719, 0.10294513, 0.10607824, 0.10706293, 0.10974846,\n",
       "                     0.11118074, 0.11323964, 0.12595112, 0.12783099, 0.13024796,\n",
       "                     0.1360666 , 0.13714081, 0.13821502, 0.14286993, 0.14439173,\n",
       "                     0.14537642, 0.1468087 , 0.15459672, 0.16086295, 0.16256378,\n",
       "                     0.166234  , 0.18082535, 0.20365231, 0.20678543, 0.20794915,\n",
       "                     0.21546862, 0.22119774, 0.22433086, 0.22665831, 0.23059708,\n",
       "                     0.23346164, 0.24098111, 0.24563602, 0.24805299, 0.2501119 ,\n",
       "                     0.26470325, 0.26729926, 0.27293886, 0.28072688, 0.29030525,\n",
       "                     0.29433354, 0.30203205, 0.30507564, 0.30731358, 0.33381076,\n",
       "                     0.33578015, 0.33748098, 0.33891326, 0.34285203, 0.34562707,\n",
       "                     0.36496285, 0.36997583, 0.37131859, 0.39835288, 0.40318682,\n",
       "                     0.40712559, 0.4112434 , 0.41768866, 0.42171695, 0.42869931,\n",
       "                     0.43245905, 0.44132128, 0.44311163, 0.45009399, 0.45161579,\n",
       "                     0.45501746, 0.46629666, 0.47829201, 0.48106705, 0.49028735,\n",
       "                     0.50568436, 0.50657954, 0.51096589, 0.52663146, 0.52833229,\n",
       "                     0.53549369, 0.53791066, 0.54095426, 0.54381882, 0.54659386,\n",
       "                     0.55473995, 0.55885776, 0.56082714, 0.5693313 , 0.57139021,\n",
       "                     0.57255393, 0.57702981, 0.58132665, 0.58302748, 0.58607108,\n",
       "                     0.59224778, 0.59618655, 0.59878256, 0.60370602, 0.60433265,\n",
       "                     0.60809238, 0.60907707, 0.61077791, 0.61426909, 0.61955062,\n",
       "                     0.62241518, 0.62501119, 0.62877092, 0.64533166, 0.65222451,\n",
       "                     0.65759556, 0.65875929, 0.66072867, 0.66636827, 0.67039656,\n",
       "                     0.67138126, 0.67352968, 0.67693134, 0.6792588 , 0.68113866,\n",
       "                     0.68480888, 0.68704682, 0.68785248, 0.68874765, 0.69062752,\n",
       "                     0.69456629, 0.69573002, 0.6971623 , 0.69904216, 0.73126846,\n",
       "                     0.73305881, 0.73440158, 0.73547579, 0.73905649, 0.74075732,\n",
       "                     0.74156298, 0.74227912, 0.7442485 , 0.74747113, 0.74908245,\n",
       "                     0.75105183, 0.75391639, 0.75481157, 0.75570674, 0.7565124 ,\n",
       "                     0.75973503, 0.76412139, 0.76564318, 0.76653836, 0.77065616,\n",
       "                     0.7759377 , 0.78855966, 0.79142422, 0.79339361, 0.79366216,\n",
       "                     0.79554203, 0.7994808 , 0.80207681, 0.80333005, 0.80404619,\n",
       "                     0.80673172, 0.8071793 , 0.81067049, 0.81246084, 0.81514636,\n",
       "                     0.81926417, 0.82123355, 0.82230776, 0.82365052, 0.82499329,\n",
       "                     0.82776833, 0.82848447, 0.82973771, 0.83484021, 0.83600394,\n",
       "                     0.83842091, 0.84316534, 0.84477665, 0.84638797, 0.8480888 ,\n",
       "                     0.84943156, 0.85337033, 0.85426551, 0.86232208, 0.86456002,\n",
       "                     0.86500761, 0.87270611, 0.87727151, 0.87861427, 0.88434339,\n",
       "                     0.88971444, 0.89132575, 0.89204189, 0.89526452, 0.89607018,\n",
       "                     0.90000895, 0.9002775 , 0.90162027, 0.90457434, 0.90627518,\n",
       "                     0.9089607 , 0.91066153, 0.91227285, 0.91424223, 0.92507385,\n",
       "                     0.92561096, 0.92758034, 0.93509981, 0.93617402, 0.93769582,\n",
       "                     0.93823292, 0.93885955, 0.93957569, 0.94915406, 0.94995972,\n",
       "                     0.95103393, 0.95371945, 0.95506221, 0.95819533, 0.96070182,\n",
       "                     0.96249217, 0.96329782, 0.9677737 , 0.96840032, 0.96911646,\n",
       "                     0.97045922, 0.97260764, 0.9734133 , 0.97368185, 0.97448751,\n",
       "                     0.97511413, 0.97591979, 0.97681497, 0.97735207, 0.97914242,\n",
       "                     0.97941097, 0.98012711, 0.98531913, 0.98863128, 0.98943693,\n",
       "                     0.989795  , 0.99086921, 0.99104825, 0.99257005, 0.9928386 ,\n",
       "                     0.99301763, 0.99328619, 0.99409184, 0.99427088, 0.99444991,\n",
       "                     0.99534509, 0.99570316, 0.99597171, 0.99767254, 0.9979411 ,\n",
       "                     0.99812013, 0.99838868, 0.9984782 , 0.99874675, 0.99892579,\n",
       "                     0.99919434, 0.99946289, 0.99982096, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.84662808e-02, -5.26437335e-02,\n",
       "                     -6.31789016e-02, -7.06175672e-02, -7.69610411e-02, -8.22380982e-02,\n",
       "                     -8.70113770e-02, -9.53101798e-02, -1.17783036e-01, -1.22602322e-01,\n",
       "                     -1.25577307e-01, -1.33531393e-01, -1.38150338e-01, -1.43100844e-01,\n",
       "                     -1.54150680e-01, -1.54150680e-01, -1.59630146e-01, -1.62518929e-01,\n",
       "                     -1.67054085e-01, -1.71850257e-01, -1.78482780e-01, -1.82321557e-01,\n",
       "                     -1.91055237e-01, -1.98450939e-01, -2.04567166e-01, -2.04939645e-01,\n",
       "                     -2.05852054e-01, -2.07639365e-01, -2.13574100e-01, -2.23143551e-01,\n",
       "                     -2.28841572e-01, -2.38411023e-01, -2.41162057e-01, -2.47836164e-01,\n",
       "                     -2.51314428e-01, -2.53448901e-01, -2.59511195e-01, -2.65703166e-01,\n",
       "                     -2.67541965e-01, -2.70290330e-01, -2.75705881e-01, -2.79024010e-01,\n",
       "                     -2.82998223e-01, -2.87682072e-01, -2.99242895e-01, -3.02280872e-01,\n",
       "                     -3.07484700e-01, -3.08577108e-01, -3.10154928e-01, -3.13657559e-01,\n",
       "                     -3.18453731e-01, -3.26684230e-01, -3.27212911e-01, -3.28504067e-01,\n",
       "                     -3.31357136e-01, -3.36472237e-01, -3.36945162e-01, -3.41749294e-01,\n",
       "                     -3.42944751e-01, -3.45745873e-01, -3.48306694e-01, -3.52220594e-01,\n",
       "                     -3.52821375e-01, -3.56674944e-01, -3.67724780e-01, -3.71563556e-01,\n",
       "                     -3.79489622e-01, -3.85662481e-01, -3.87765531e-01, -3.89464767e-01,\n",
       "                     -3.90427231e-01, -3.94654192e-01, -4.02223614e-01, -4.05465108e-01,\n",
       "                     -4.05465108e-01, -4.12244795e-01, -4.14943852e-01, -4.22856851e-01,\n",
       "                     -4.38254931e-01, -4.41832752e-01, -4.43931389e-01, -4.46287103e-01,\n",
       "                     -4.57833094e-01, -4.58953793e-01, -4.61818045e-01, -4.64305608e-01,\n",
       "                     -4.70003629e-01, -4.75423697e-01, -4.79573080e-01, -4.82426149e-01,\n",
       "                     -4.85507816e-01, -4.89548225e-01, -4.98991166e-01, -5.10825624e-01,\n",
       "                     -5.19875459e-01, -5.24524468e-01, -5.35961597e-01, -5.38996501e-01,\n",
       "                     -5.38996501e-01, -5.46543706e-01, -5.52068582e-01, -5.55946059e-01,\n",
       "                     -5.57191544e-01, -5.59615788e-01, -5.64529803e-01, -5.66395475e-01,\n",
       "                     -5.66541556e-01, -5.68849464e-01, -5.69094532e-01, -5.70544858e-01,\n",
       "                     -5.72519193e-01, -5.75364145e-01, -5.87786665e-01, -5.97837001e-01,\n",
       "                     -6.06135804e-01, -6.10909082e-01, -6.13104473e-01, -6.19039208e-01,\n",
       "                     -6.30233355e-01, -6.31271777e-01, -6.35988767e-01, -6.41853886e-01,\n",
       "                     -6.44357016e-01, -6.46627165e-01, -6.53926467e-01, -6.61398482e-01,\n",
       "                     -6.69049629e-01, -6.93147181e-01, -7.17839793e-01, -7.25937003e-01,\n",
       "                     -7.33969175e-01, -7.41937345e-01, -7.44440475e-01, -7.47214402e-01,\n",
       "                     -7.53771802e-01, -7.59105148e-01, -7.60286483e-01, -7.73189888e-01,\n",
       "                     -7.80158558e-01, -7.82759339e-01, -7.88457360e-01, -7.88457360e-01,\n",
       "                     -7.98507696e-01, -8.10930216e-01, -8.26678573e-01, -8.30348302e-01,\n",
       "                     -8.32909123e-01, -8.34797698e-01, -8.35117442e-01, -8.38137491e-01,\n",
       "                     -8.38329190e-01, -8.40783179e-01, -8.47297860e-01, -8.47297860e-01,\n",
       "                     -8.50539354e-01, -8.52211875e-01, -8.57450232e-01, -8.64997437e-01,\n",
       "                     -8.75468737e-01, -8.75468737e-01, -8.79733136e-01, -8.96088025e-01,\n",
       "                     -9.02867712e-01, -9.16290732e-01, -9.34309237e-01, -9.49080555e-01,\n",
       "                     -9.55511445e-01, -9.55511445e-01, -9.60461950e-01, -9.65080896e-01,\n",
       "                     -9.71860583e-01, -9.80829253e-01, -9.90398704e-01, -9.94622575e-01,\n",
       "                     -9.99521386e-01, -1.00144854e+00, -1.02165125e+00, -1.02585293e+00,\n",
       "                     -1.02961942e+00, -1.03609193e+00, -1.06471074e+00, -1.07992016e+00,\n",
       "                     -1.08518927e+00, -1.09861229e+00, -1.09861229e+00, -1.10512697e+00,\n",
       "                     -1.12059120e+00, -1.12938395e+00, -1.13140211e+00, -1.13497993e+00,\n",
       "                     -1.13943428e+00, -1.15267951e+00, -1.17007125e+00, -1.17865500e+00,\n",
       "                     -1.20397280e+00, -1.20397280e+00, -1.21302264e+00, -1.21444410e+00,\n",
       "                     -1.22377543e+00, -1.22994829e+00, -1.23676263e+00, -1.23969089e+00,\n",
       "                     -1.25158163e+00, -1.25276297e+00, -1.26566637e+00, -1.27296568e+00,\n",
       "                     -1.27629347e+00, -1.27766052e+00, -1.29928298e+00, -1.31218639e+00,\n",
       "                     -1.32175584e+00, -1.32610773e+00, -1.32913595e+00, -1.34373475e+00,\n",
       "                     -1.35239281e+00, -1.38629436e+00, -1.40047900e+00, -1.41272762e+00,\n",
       "                     -1.42310833e+00, -1.44036158e+00, -1.44926916e+00, -1.45528723e+00,\n",
       "                     -1.47590652e+00, -1.49664242e+00, -1.50407740e+00, -1.51634749e+00,\n",
       "                     -1.54044504e+00, -1.54044504e+00, -1.55059741e+00, -1.58696506e+00,\n",
       "                     -1.60943791e+00, -1.60943791e+00, -1.64865863e+00, -1.67397643e+00,\n",
       "                     -1.68175857e+00, -1.68576018e+00, -1.68739945e+00, -1.71479843e+00,\n",
       "                     -1.74919985e+00, -1.79175947e+00, -1.79175947e+00, -1.81117756e+00,\n",
       "                     -1.84582669e+00, -1.87180218e+00, -1.89711998e+00, -1.91364929e+00,\n",
       "                     -1.94591015e+00, -1.94591015e+00, -2.01490302e+00, -2.04769284e+00,\n",
       "                     -2.07944154e+00, -2.13696539e+00, -2.15948425e+00, -2.19722458e+00,\n",
       "                     -2.39789527e+00, -2.48490665e+00, -2.53897387e+00, -2.60268969e+00,\n",
       "                     -2.68557735e+00, -2.79320801e+00, -2.97041447e+00, -3.27714473e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5228106834837871, privacy_risk=0.5171873601289052, accuracy=0.5171873601289052, tpr_ind=0.4413212783099096, tnr_ind=0.5930534419479008, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.07250918, 0.07421001, 0.08208755, 0.08924895,\n",
       "                     0.09023364, 0.09238206, 0.09426193, 0.09766359, 0.09829022,\n",
       "                     0.09963298, 0.09963298, 0.10088622, 0.1068839 , 0.10768955,\n",
       "                     0.10795811, 0.10992749, 0.11243398, 0.11315012, 0.12084863,\n",
       "                     0.13230687, 0.1340077 , 0.13624564, 0.13776743, 0.14018441,\n",
       "                     0.14224331, 0.14501835, 0.14609256, 0.14958374, 0.15593949,\n",
       "                     0.15692418, 0.15889356, 0.16050488, 0.16650255, 0.19210456,\n",
       "                     0.19514815, 0.19962403, 0.21511055, 0.21824367, 0.22075016,\n",
       "                     0.22549458, 0.23014949, 0.25503536, 0.26049593, 0.26765733,\n",
       "                     0.27857846, 0.29066332, 0.2987199 , 0.3028377 , 0.30543371,\n",
       "                     0.30704503, 0.32602274, 0.3273655 , 0.3314833 , 0.33586966,\n",
       "                     0.33891326, 0.34088264, 0.34616418, 0.36576851, 0.36639513,\n",
       "                     0.37865903, 0.38394056, 0.38590995, 0.39441411, 0.39709963,\n",
       "                     0.40220213, 0.40515621, 0.41357085, 0.41616686, 0.41974756,\n",
       "                     0.42279116, 0.42950497, 0.43657685, 0.44946737, 0.45188434,\n",
       "                     0.4613732 , 0.46450631, 0.47014591, 0.47408468, 0.47471131,\n",
       "                     0.48563244, 0.49127204, 0.49180915, 0.50980217, 0.511503  ,\n",
       "                     0.51293528, 0.51472563, 0.51964909, 0.52161848, 0.5237669 ,\n",
       "                     0.53012264, 0.53558321, 0.53746307, 0.54480351, 0.55008504,\n",
       "                     0.55133829, 0.56745144, 0.572912  , 0.57416525, 0.60236326,\n",
       "                     0.60424313, 0.6081819 , 0.60961418, 0.60997225, 0.61301584,\n",
       "                     0.64792767, 0.64927043, 0.65034464, 0.65365679, 0.65446245,\n",
       "                     0.65795363, 0.66054964, 0.66126578, 0.66233999, 0.66296661,\n",
       "                     0.66529406, 0.66583117, 0.66672635, 0.67030705, 0.67299257,\n",
       "                     0.67433533, 0.67961687, 0.68203384, 0.6864202 , 0.69671471,\n",
       "                     0.69957927, 0.70190672, 0.70548742, 0.70611405, 0.70763584,\n",
       "                     0.71291738, 0.71426014, 0.71443917, 0.71676663, 0.71703518,\n",
       "                     0.7186465 , 0.71927312, 0.72034733, 0.72267478, 0.72330141,\n",
       "                     0.72410706, 0.72598693, 0.72706114, 0.72920956, 0.75203652,\n",
       "                     0.75472205, 0.75525915, 0.75740757, 0.75839227, 0.76045117,\n",
       "                     0.7785337 , 0.77933936, 0.78148778, 0.79151374, 0.79214036,\n",
       "                     0.79446782, 0.79769045, 0.79894369, 0.80010742, 0.80279295,\n",
       "                     0.80744786, 0.80825351, 0.80879062, 0.81067049, 0.81183421,\n",
       "                     0.81425119, 0.81496733, 0.82311342, 0.82391908, 0.82615701,\n",
       "                     0.833766  , 0.83439262, 0.8358249 , 0.83824188, 0.83967416,\n",
       "                     0.84289679, 0.84629845, 0.85435503, 0.85739862, 0.86276967,\n",
       "                     0.86375436, 0.86527616, 0.86608182, 0.86984155, 0.87198997,\n",
       "                     0.87476502, 0.8761973 , 0.87950944, 0.87986751, 0.8803151 ,\n",
       "                     0.88353773, 0.88613374, 0.88631277, 0.89374273, 0.89535404,\n",
       "                     0.89651777, 0.8982186 , 0.90036702, 0.90153075, 0.90170978,\n",
       "                     0.91137767, 0.91245188, 0.91289947, 0.91451079, 0.91836004,\n",
       "                     0.9227464 , 0.92758034, 0.93187718, 0.93492078, 0.94226121,\n",
       "                     0.94387253, 0.94611046, 0.94709516, 0.94763226, 0.95166055,\n",
       "                     0.95210814, 0.95282428, 0.95309283, 0.96007519, 0.96285024,\n",
       "                     0.96329782, 0.96365589, 0.96401396, 0.96580431, 0.96616238,\n",
       "                     0.96705756, 0.96795273, 0.96857936, 0.96938501, 0.97010115,\n",
       "                     0.97081729, 0.9713544 , 0.97180199, 0.97430848, 0.97583027,\n",
       "                     0.97600931, 0.97663593, 0.97726255, 0.97824725, 0.9785158 ,\n",
       "                     0.97950049, 0.97967953, 0.98012711, 0.98021663, 0.98021663,\n",
       "                     0.98129084, 0.98129084, 0.98146988, 0.98173843, 0.98236505,\n",
       "                     0.9836183 , 0.98424492, 1.        ]), tpr=array([0.        , 0.08056575, 0.08226658, 0.09121833, 0.09829022,\n",
       "                     0.09963298, 0.10204995, 0.10321368, 0.10768955, 0.10876376,\n",
       "                     0.10974846, 0.11064363, 0.11234446, 0.11870021, 0.12013249,\n",
       "                     0.12138573, 0.12317608, 0.12666726, 0.12720437, 0.13347059,\n",
       "                     0.14537642, 0.14734581, 0.15021037, 0.15209023, 0.15611852,\n",
       "                     0.15916212, 0.16390654, 0.16641303, 0.17008325, 0.17652851,\n",
       "                     0.17805031, 0.17993018, 0.18216811, 0.19138842, 0.21860174,\n",
       "                     0.22254051, 0.22531555, 0.24008594, 0.24304001, 0.24465133,\n",
       "                     0.24966431, 0.25414018, 0.27947364, 0.28627697, 0.29379644,\n",
       "                     0.3058813 , 0.3181452 , 0.32638081, 0.3309462 , 0.33372124,\n",
       "                     0.33497449, 0.35332558, 0.35529496, 0.35968132, 0.36379912,\n",
       "                     0.36737982, 0.37113956, 0.37579447, 0.39405604, 0.39450363,\n",
       "                     0.40497717, 0.41007967, 0.41133292, 0.41921046, 0.4225226 ,\n",
       "                     0.42780414, 0.43102677, 0.44033659, 0.44230597, 0.44597619,\n",
       "                     0.44839316, 0.45761346, 0.46414824, 0.47703876, 0.48115657,\n",
       "                     0.49064542, 0.49377853, 0.49897055, 0.50290932, 0.50389401,\n",
       "                     0.51436756, 0.52090234, 0.52269269, 0.53916391, 0.54158088,\n",
       "                     0.54381882, 0.5452511 , 0.54963745, 0.55133829, 0.55420285,\n",
       "                     0.56091666, 0.56655626, 0.56942082, 0.57685077, 0.58195327,\n",
       "                     0.58293796, 0.59788739, 0.60245278, 0.60415361, 0.63190404,\n",
       "                     0.63423149, 0.63655895, 0.63924447, 0.63987109, 0.64300421,\n",
       "                     0.67549906, 0.67711038, 0.67845314, 0.68167577, 0.6828395 ,\n",
       "                     0.68597261, 0.68838958, 0.68937427, 0.69044848, 0.69161221,\n",
       "                     0.69465581, 0.69528243, 0.69662519, 0.70145914, 0.70369707,\n",
       "                     0.70459225, 0.70924716, 0.71130606, 0.71390207, 0.72339092,\n",
       "                     0.72589741, 0.7278668 , 0.73207412, 0.73287978, 0.73484916,\n",
       "                     0.73905649, 0.74022021, 0.74075732, 0.74335333, 0.74433802,\n",
       "                     0.74523319, 0.74603885, 0.74800824, 0.75051473, 0.7514099 ,\n",
       "                     0.75248411, 0.75382687, 0.75481157, 0.75597529, 0.77924984,\n",
       "                     0.78148778, 0.78193537, 0.78381524, 0.78542655, 0.78703787,\n",
       "                     0.80619461, 0.80735834, 0.81040193, 0.81998031, 0.82060693,\n",
       "                     0.82382956, 0.82848447, 0.82937964, 0.83027482, 0.833766  ,\n",
       "                     0.83779429, 0.83949512, 0.84047981, 0.8429863 , 0.84379196,\n",
       "                     0.84504521, 0.84638797, 0.85551875, 0.85650345, 0.86008415,\n",
       "                     0.86581327, 0.86635037, 0.86840927, 0.8710948 , 0.87270611,\n",
       "                     0.87754006, 0.87959896, 0.88604422, 0.88926685, 0.89374273,\n",
       "                     0.89490645, 0.89660729, 0.89750246, 0.90170978, 0.90314206,\n",
       "                     0.90546952, 0.9069018 , 0.91030346, 0.91057202, 0.91084057,\n",
       "                     0.91298899, 0.91728583, 0.91746486, 0.92462626, 0.92641661,\n",
       "                     0.92784889, 0.92919166, 0.93071345, 0.93232477, 0.93304091,\n",
       "                     0.9396652 , 0.94011279, 0.94109748, 0.9427088 , 0.94557336,\n",
       "                     0.94978068, 0.95389849, 0.95640498, 0.9585534 , 0.9662519 ,\n",
       "                     0.96759466, 0.96902694, 0.96947453, 0.97028019, 0.97412944,\n",
       "                     0.97484558, 0.97556172, 0.97583027, 0.98254409, 0.98478202,\n",
       "                     0.98531913, 0.98576672, 0.98612479, 0.98755707, 0.98836272,\n",
       "                     0.98889983, 0.98988452, 0.99051114, 0.99104825, 0.9913168 ,\n",
       "                     0.99167487, 0.99221198, 0.99257005, 0.99471847, 0.99579268,\n",
       "                     0.99588219, 0.9964193 , 0.99668785, 0.99686689, 0.99704592,\n",
       "                     0.99776206, 0.9979411 , 0.99803061, 0.99812013, 0.99820965,\n",
       "                     0.99856772, 0.99865724, 0.99883627, 0.99892579, 0.99937338,\n",
       "                     0.99991048, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.12932944e-02, -5.82689081e-02,\n",
       "                     -6.13689464e-02, -6.45385211e-02, -7.14589640e-02, -7.41079722e-02,\n",
       "                     -7.69610411e-02, -8.00427077e-02, -8.70113770e-02, -9.53101798e-02,\n",
       "                     -1.00083459e-01, -1.06767975e-01, -1.17783036e-01, -1.33531393e-01,\n",
       "                     -1.39761942e-01, -1.43100844e-01, -1.54150680e-01, -1.58224005e-01,\n",
       "                     -1.65896677e-01, -1.67054085e-01, -1.71850257e-01, -1.74353387e-01,\n",
       "                     -1.82321557e-01, -1.87211542e-01, -1.88591170e-01, -1.94156014e-01,\n",
       "                     -1.98450939e-01, -2.00670695e-01, -2.11309094e-01, -2.13574100e-01,\n",
       "                     -2.15111380e-01, -2.17301276e-01, -2.20508504e-01, -2.23143551e-01,\n",
       "                     -2.29574442e-01, -2.31592606e-01, -2.41162057e-01, -2.45122458e-01,\n",
       "                     -2.51314428e-01, -2.62364264e-01, -2.65349746e-01, -2.74436846e-01,\n",
       "                     -2.87682072e-01, -2.93222253e-01, -2.94954832e-01, -2.98492989e-01,\n",
       "                     -3.02280872e-01, -3.03682414e-01, -3.05381650e-01, -3.08201803e-01,\n",
       "                     -3.10154928e-01, -3.12872321e-01, -3.14493330e-01, -3.18453731e-01,\n",
       "                     -3.22773392e-01, -3.25422400e-01, -3.30854244e-01, -3.36472237e-01,\n",
       "                     -3.43771539e-01, -3.51397887e-01, -3.56674944e-01, -3.58945092e-01,\n",
       "                     -3.59374001e-01, -3.65113813e-01, -3.67724780e-01, -3.72888938e-01,\n",
       "                     -3.74693449e-01, -3.80772496e-01, -3.93042588e-01, -3.95708933e-01,\n",
       "                     -4.00888441e-01, -4.05465108e-01, -4.05465108e-01, -4.11734721e-01,\n",
       "                     -4.14943852e-01, -4.16893804e-01, -4.20502985e-01, -4.35318071e-01,\n",
       "                     -4.36323096e-01, -4.36928378e-01, -4.38254931e-01, -4.41056053e-01,\n",
       "                     -4.41832752e-01, -4.44685821e-01, -4.46287103e-01, -4.51985124e-01,\n",
       "                     -4.56758402e-01, -4.66089730e-01, -4.70003629e-01, -4.81838087e-01,\n",
       "                     -4.85507816e-01, -4.86434171e-01, -4.89548225e-01, -4.92476485e-01,\n",
       "                     -4.95134294e-01, -5.10825624e-01, -5.21296924e-01, -5.24919387e-01,\n",
       "                     -5.26093096e-01, -5.26093096e-01, -5.30628251e-01, -5.38996501e-01,\n",
       "                     -5.38996501e-01, -5.40143685e-01, -5.43615447e-01, -5.50046337e-01,\n",
       "                     -5.59615788e-01, -5.70544858e-01, -5.87786665e-01, -5.95983432e-01,\n",
       "                     -5.97837001e-01, -6.06135804e-01, -6.13104473e-01, -6.16774202e-01,\n",
       "                     -6.19039208e-01, -6.24154309e-01, -6.26136470e-01, -6.31271777e-01,\n",
       "                     -6.41853886e-01, -6.43876132e-01, -6.71168274e-01, -6.75755438e-01,\n",
       "                     -6.93147181e-01, -7.10846758e-01, -7.15620036e-01, -7.44972248e-01,\n",
       "                     -7.47214402e-01, -7.59105148e-01, -7.64972915e-01, -7.67255153e-01,\n",
       "                     -7.73189888e-01, -7.75838896e-01, -7.80158558e-01, -7.88457360e-01,\n",
       "                     -7.98507696e-01, -8.00777845e-01, -8.10930216e-01, -8.32909123e-01,\n",
       "                     -8.47297860e-01, -8.47297860e-01, -8.60201265e-01, -8.69037847e-01,\n",
       "                     -8.73864888e-01, -8.75468737e-01, -8.75468737e-01, -8.87303195e-01,\n",
       "                     -8.93817876e-01, -8.93817876e-01, -8.95515669e-01, -9.00786545e-01,\n",
       "                     -9.16290732e-01, -9.40299272e-01, -9.44461609e-01, -9.49080555e-01,\n",
       "                     -9.54031060e-01, -9.55511445e-01, -9.55511445e-01, -9.61411167e-01,\n",
       "                     -9.80829253e-01, -9.87386654e-01, -1.00330211e+00, -1.01160091e+00,\n",
       "                     -1.02165125e+00, -1.02450432e+00, -1.02961942e+00, -1.03101900e+00,\n",
       "                     -1.03609193e+00, -1.03850836e+00, -1.03961395e+00, -1.04145387e+00,\n",
       "                     -1.06919840e+00, -1.07613943e+00, -1.07992016e+00, -1.08618977e+00,\n",
       "                     -1.09861229e+00, -1.09861229e+00, -1.10782894e+00, -1.11841492e+00,\n",
       "                     -1.12393010e+00, -1.14990558e+00, -1.16315081e+00, -1.16713224e+00,\n",
       "                     -1.17865500e+00, -1.18455472e+00, -1.19770319e+00, -1.19869575e+00,\n",
       "                     -1.20397280e+00, -1.20397280e+00, -1.21639532e+00, -1.23474446e+00,\n",
       "                     -1.25276297e+00, -1.26694760e+00, -1.28093385e+00, -1.28785429e+00,\n",
       "                     -1.29928298e+00, -1.30992138e+00, -1.31432086e+00, -1.32175584e+00,\n",
       "                     -1.32714669e+00, -1.33500107e+00, -1.33977435e+00, -1.34373475e+00,\n",
       "                     -1.35454566e+00, -1.36478816e+00, -1.36985563e+00, -1.38629436e+00,\n",
       "                     -1.42711636e+00, -1.45644935e+00, -1.46633707e+00, -1.50407740e+00,\n",
       "                     -1.52605630e+00, -1.54044504e+00, -1.57633796e+00, -1.58412010e+00,\n",
       "                     -1.60943791e+00, -1.60943791e+00, -1.62004809e+00, -1.63315444e+00,\n",
       "                     -1.64222774e+00, -1.64865863e+00, -1.65822808e+00, -1.70474809e+00,\n",
       "                     -1.71479843e+00, -1.73460106e+00, -1.76098781e+00, -1.76766192e+00,\n",
       "                     -1.79175947e+00, -1.79175947e+00, -1.83258146e+00, -1.84582669e+00,\n",
       "                     -1.87180218e+00, -1.87819198e+00, -1.92181260e+00, -1.94591015e+00,\n",
       "                     -2.01490302e+00, -2.03688193e+00, -2.07944154e+00, -2.19722458e+00,\n",
       "                     -2.29000631e+00, -2.35137526e+00, -2.39789527e+00, -2.48490665e+00,\n",
       "                     -2.56494936e+00, -2.60268969e+00, -2.63905733e+00, -2.67414865e+00,\n",
       "                     -2.77258872e+00, -2.82137889e+00, -2.87167962e+00, -2.99573227e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5246015303269562, privacy_risk=0.5173216363799122, accuracy=0.5173216363799122, tpr_ind=0.8775400590815504, tnr_ind=0.1571032136782741, test_train_ratio=1.0, dataset_size=[11171, 11171]),\n",
       "              MIA_Attack_Result(name='entire_dataset', fpr=array([0.        , 0.06704861, 0.07089786, 0.07501567, 0.07734312,\n",
       "                     0.07850685, 0.081819  , 0.08611584, 0.08969654, 0.0925611 ,\n",
       "                     0.09784263, 0.10213947, 0.10652583, 0.10715245, 0.10840569,\n",
       "                     0.1089428 , 0.11091218, 0.11843165, 0.11986393, 0.11995345,\n",
       "                     0.12093814, 0.12308656, 0.13150121, 0.13991585, 0.1447498 ,\n",
       "                     0.14555546, 0.14618208, 0.14868857, 0.19774416, 0.21439441,\n",
       "                     0.22271954, 0.22970191, 0.23032853, 0.23381971, 0.24429326,\n",
       "                     0.2455465 , 0.25467729, 0.27043237, 0.27401307, 0.28036881,\n",
       "                     0.28323337, 0.29675051, 0.30256915, 0.33595918, 0.34088264,\n",
       "                     0.34652225, 0.35511593, 0.3611136 , 0.36218781, 0.36532092,\n",
       "                     0.37660013, 0.37767434, 0.39011727, 0.39718915, 0.40059082,\n",
       "                     0.40282875, 0.40542476, 0.40596187, 0.41652493, 0.42305971,\n",
       "                     0.45546504, 0.45716588, 0.462895  , 0.46835556, 0.47014591,\n",
       "                     0.47238385, 0.47936622, 0.48455823, 0.50675857, 0.51311431,\n",
       "                     0.51427804, 0.52287172, 0.52502014, 0.5258258 , 0.52725808,\n",
       "                     0.52806374, 0.5335243 , 0.54453496, 0.55053263, 0.55841017,\n",
       "                     0.56127473, 0.56619819, 0.57774595, 0.59036792, 0.59153164,\n",
       "                     0.59368006, 0.59457524, 0.59627607, 0.60334795, 0.60531734,\n",
       "                     0.606123  , 0.60621251, 0.60746576, 0.608719  , 0.60916659,\n",
       "                     0.62832334, 0.63100886, 0.63646943, 0.63960254, 0.64586877,\n",
       "                     0.64935995, 0.65061319, 0.65338824, 0.65491003, 0.65643183,\n",
       "                     0.65840122, 0.66260854, 0.66386178, 0.6660102 , 0.66797959,\n",
       "                     0.67084415, 0.67236595, 0.67388775, 0.6782741 , 0.67934831,\n",
       "                     0.68006445, 0.68176529, 0.68391371, 0.69349208, 0.69734133,\n",
       "                     0.6997583 , 0.70083251, 0.70119058, 0.703339  , 0.70414466,\n",
       "                     0.70566646, 0.71023185, 0.71175365, 0.71246979, 0.71327545,\n",
       "                     0.71614001, 0.71739325, 0.71945215, 0.72079492, 0.72285382,\n",
       "                     0.72437562, 0.72724018, 0.73225316, 0.73395399, 0.73547579,\n",
       "                     0.73753469, 0.7386089 , 0.75149942, 0.75194701, 0.75409543,\n",
       "                     0.75543819, 0.75597529, 0.75713902, 0.7585713 , 0.76600125,\n",
       "                     0.76635932, 0.76743353, 0.76797064, 0.76886581, 0.76940292,\n",
       "                     0.76958195, 0.77692239, 0.78175633, 0.78462089, 0.78694835,\n",
       "                     0.79035001, 0.79330409, 0.7994808 , 0.80350909, 0.80386716,\n",
       "                     0.80476233, 0.80637365, 0.8071793 , 0.81281891, 0.81523588,\n",
       "                     0.81747382, 0.82723122, 0.83108048, 0.83475069, 0.83698863,\n",
       "                     0.83761525, 0.84119595, 0.84370244, 0.843971  , 0.8608898 ,\n",
       "                     0.86509713, 0.86867783, 0.86930445, 0.87145287, 0.87360129,\n",
       "                     0.87512309, 0.87915137, 0.88255304, 0.8833587 , 0.88819264,\n",
       "                     0.88998299, 0.89114672, 0.89392176, 0.89678632, 0.89830812,\n",
       "                     0.90054606, 0.91263092, 0.91540596, 0.92185122, 0.92203026,\n",
       "                     0.92399964, 0.92507385, 0.93169815, 0.93590547, 0.9376063 ,\n",
       "                     0.94002327, 0.94163459, 0.94199266, 0.94539432, 0.94763226,\n",
       "                     0.95273476, 0.96598335, 0.96759466, 0.96911646, 0.96920598,\n",
       "                     0.96938501, 0.97036971, 0.97045922, 0.97314475, 0.97511413,\n",
       "                     0.97538269, 0.97618834, 0.97663593, 0.97663593, 0.97824725,\n",
       "                     0.97842628, 0.97860532, 0.97887387, 0.9790529 , 0.97923194,\n",
       "                     0.97985856, 0.97994808, 0.9805747 , 0.98138036, 0.98155939,\n",
       "                     0.98155939, 0.98173843, 0.9826336 , 0.98379733, 0.9841554 ,\n",
       "                     1.        ]), tpr=array([0.        , 0.07340435, 0.07680602, 0.08056575, 0.08396742,\n",
       "                     0.08557873, 0.09032316, 0.09336675, 0.09703697, 0.10142333,\n",
       "                     0.10670486, 0.11118074, 0.11538806, 0.11619372, 0.11834214,\n",
       "                     0.11896876, 0.12138573, 0.12899472, 0.13015845, 0.13069555,\n",
       "                     0.13284397, 0.13570853, 0.14591353, 0.15504431, 0.16086295,\n",
       "                     0.16211619, 0.16327992, 0.16793483, 0.21716946, 0.23623668,\n",
       "                     0.24366664, 0.25100707, 0.25226032, 0.25602005, 0.26595649,\n",
       "                     0.26819443, 0.27857846, 0.29630293, 0.3002417 , 0.30516516,\n",
       "                     0.3064184 , 0.31930892, 0.32593322, 0.36174022, 0.3667532 ,\n",
       "                     0.37078149, 0.37946469, 0.38573091, 0.38662609, 0.38993823,\n",
       "                     0.40032226, 0.4020231 , 0.41187002, 0.41938949, 0.42305971,\n",
       "                     0.4261033 , 0.42932593, 0.43031063, 0.44033659, 0.44866171,\n",
       "                     0.47632262, 0.47766538, 0.48375257, 0.49019783, 0.49189867,\n",
       "                     0.49538985, 0.50237221, 0.50702712, 0.53128637, 0.53620983,\n",
       "                     0.53817921, 0.54910035, 0.5508907 , 0.55250201, 0.55411333,\n",
       "                     0.55554561, 0.56118521, 0.57076358, 0.57729836, 0.5836541 ,\n",
       "                     0.58633963, 0.59063647, 0.60048339, 0.61525378, 0.61668606,\n",
       "                     0.61964014, 0.62089338, 0.62268373, 0.63074031, 0.63244114,\n",
       "                     0.63396294, 0.63458956, 0.63646943, 0.63870737, 0.63969206,\n",
       "                     0.65768508, 0.66090771, 0.66386178, 0.66645779, 0.67120222,\n",
       "                     0.67523051, 0.67737893, 0.68051204, 0.68239191, 0.68382419,\n",
       "                     0.68579357, 0.69026945, 0.69179125, 0.69340256, 0.69510339,\n",
       "                     0.69948975, 0.70163817, 0.70324949, 0.70665115, 0.70763584,\n",
       "                     0.70906812, 0.71085847, 0.71390207, 0.7248232 , 0.72777728,\n",
       "                     0.72947811, 0.73082088, 0.73171605, 0.73475965, 0.73619193,\n",
       "                     0.73807179, 0.74183153, 0.74326381, 0.74460657, 0.74585982,\n",
       "                     0.74953003, 0.75114135, 0.75230508, 0.75382687, 0.75633336,\n",
       "                     0.7580342 , 0.76116731, 0.76483753, 0.76680691, 0.76904485,\n",
       "                     0.77038761, 0.77146182, 0.78479993, 0.78551607, 0.78712738,\n",
       "                     0.78847015, 0.78891773, 0.78999194, 0.79115567, 0.79652672,\n",
       "                     0.79769045, 0.79849611, 0.79974935, 0.80037597, 0.80082356,\n",
       "                     0.80127115, 0.81040193, 0.81639961, 0.81899561, 0.82060693,\n",
       "                     0.82436666, 0.82821592, 0.833766  , 0.83698863, 0.83779429,\n",
       "                     0.83868946, 0.83958464, 0.84056933, 0.846567  , 0.84764121,\n",
       "                     0.85023722, 0.86285919, 0.86518664, 0.86867783, 0.87037866,\n",
       "                     0.87118432, 0.87422791, 0.87709247, 0.87771909, 0.8905201 ,\n",
       "                     0.89436935, 0.89893474, 0.89938233, 0.90081461, 0.90215737,\n",
       "                     0.90376869, 0.90699132, 0.91119864, 0.91191478, 0.91621162,\n",
       "                     0.91755438, 0.91791245, 0.92032942, 0.92364157, 0.92516337,\n",
       "                     0.92704324, 0.94029183, 0.9427088 , 0.94736371, 0.9478113 ,\n",
       "                     0.94951213, 0.95085489, 0.95676305, 0.96016471, 0.96088085,\n",
       "                     0.96401396, 0.96517769, 0.96553576, 0.96759466, 0.96965357,\n",
       "                     0.97475606, 0.98728851, 0.98800465, 0.98845224, 0.98872079,\n",
       "                     0.98898935, 0.99006356, 0.99015307, 0.99194342, 0.99391281,\n",
       "                     0.99444991, 0.99480798, 0.9948975 , 0.99507654, 0.99624026,\n",
       "                     0.99659833, 0.99668785, 0.9969564 , 0.99704592, 0.99749351,\n",
       "                     0.9979411 , 0.99838868, 0.99874675, 0.99901531, 0.99919434,\n",
       "                     0.99946289, 0.99955241, 0.99973145, 0.99991048, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.59754864e-02, -4.65200156e-02,\n",
       "                     -5.12932944e-02, -5.40672213e-02, -5.50597772e-02, -5.71584138e-02,\n",
       "                     -7.06175672e-02, -7.84716154e-02, -8.13456395e-02, -9.53101798e-02,\n",
       "                     -1.01096117e-01, -1.05360516e-01, -1.17783036e-01, -1.33531393e-01,\n",
       "                     -1.38150338e-01, -1.42316222e-01, -1.43100844e-01, -1.54150680e-01,\n",
       "                     -1.54150680e-01, -1.71850257e-01, -1.76456437e-01, -1.79048231e-01,\n",
       "                     -1.82321557e-01, -1.94156014e-01, -2.07639365e-01, -2.23143551e-01,\n",
       "                     -2.26773319e-01, -2.37129793e-01, -2.44598486e-01, -2.47241103e-01,\n",
       "                     -2.51314428e-01, -2.69663567e-01, -2.74076420e-01, -2.77631737e-01,\n",
       "                     -2.83362411e-01, -2.87682072e-01, -2.93347810e-01, -2.96731908e-01,\n",
       "                     -3.05381650e-01, -3.08301360e-01, -3.11055424e-01, -3.14810740e-01,\n",
       "                     -3.18453731e-01, -3.20471895e-01, -3.23128821e-01, -3.26215736e-01,\n",
       "                     -3.36472237e-01, -3.40325806e-01, -3.46276237e-01, -3.51397887e-01,\n",
       "                     -3.55765440e-01, -3.56674944e-01, -3.63965377e-01, -3.65459773e-01,\n",
       "                     -3.67724780e-01, -3.74693449e-01, -3.75251330e-01, -3.80055393e-01,\n",
       "                     -3.80340903e-01, -3.82992252e-01, -3.85662481e-01, -3.86772975e-01,\n",
       "                     -3.87765531e-01, -3.96881364e-01, -4.05465108e-01, -4.05465108e-01,\n",
       "                     -4.18904528e-01, -4.23483614e-01, -4.35318071e-01, -4.37725970e-01,\n",
       "                     -4.38254931e-01, -4.41832752e-01, -4.41832752e-01, -4.46287103e-01,\n",
       "                     -4.51985124e-01, -4.57069880e-01, -4.63130750e-01, -4.64707942e-01,\n",
       "                     -4.70003629e-01, -4.72604411e-01, -4.75669367e-01, -4.81303184e-01,\n",
       "                     -4.85507816e-01, -4.92476485e-01, -4.96436886e-01, -5.00775288e-01,\n",
       "                     -5.10825624e-01, -5.21296924e-01, -5.34082486e-01, -5.38996501e-01,\n",
       "                     -5.38996501e-01, -5.42324291e-01, -5.46543706e-01, -5.54628246e-01,\n",
       "                     -5.59615788e-01, -5.63935449e-01, -5.64529803e-01, -5.73002869e-01,\n",
       "                     -5.75364145e-01, -5.83146285e-01, -5.87786665e-01, -5.93063722e-01,\n",
       "                     -5.94707108e-01, -5.97837001e-01, -5.98836501e-01, -6.00773860e-01,\n",
       "                     -6.06135804e-01, -6.10909082e-01, -6.19039208e-01, -6.28608659e-01,\n",
       "                     -6.35988767e-01, -6.39079959e-01, -6.46627165e-01, -6.61398482e-01,\n",
       "                     -6.67829373e-01, -6.78332095e-01, -6.93147181e-01, -7.08185058e-01,\n",
       "                     -7.19122667e-01, -7.25937003e-01, -7.41937345e-01, -7.50305594e-01,\n",
       "                     -7.53771802e-01, -7.62140052e-01, -7.73189888e-01, -7.82759339e-01,\n",
       "                     -7.88457360e-01, -7.94929875e-01, -7.97287440e-01, -7.98507696e-01,\n",
       "                     -8.02346473e-01, -8.04372816e-01, -8.10930216e-01, -8.16761137e-01,\n",
       "                     -8.26678573e-01, -8.29722716e-01, -8.40783179e-01, -8.41567186e-01,\n",
       "                     -8.47297860e-01, -8.47297860e-01, -8.53986849e-01, -8.64997437e-01,\n",
       "                     -8.70828358e-01, -8.75468737e-01, -8.75468737e-01, -8.82389180e-01,\n",
       "                     -9.00786545e-01, -9.16290732e-01, -9.31558204e-01, -9.38269639e-01,\n",
       "                     -9.44461609e-01, -9.44461609e-01, -9.55511445e-01, -9.55511445e-01,\n",
       "                     -9.62275845e-01, -9.71457113e-01, -9.76509592e-01, -9.80829253e-01,\n",
       "                     -9.89718200e-01, -9.92390075e-01, -1.00276433e+00, -1.01160091e+00,\n",
       "                     -1.02165125e+00, -1.02961942e+00, -1.02961942e+00, -1.03609193e+00,\n",
       "                     -1.03705440e+00, -1.04145387e+00, -1.06352097e+00, -1.07226346e+00,\n",
       "                     -1.09861229e+00, -1.09861229e+00, -1.11600403e+00, -1.13497993e+00,\n",
       "                     -1.13707857e+00, -1.13943428e+00, -1.14513230e+00, -1.15083755e+00,\n",
       "                     -1.15145477e+00, -1.16192457e+00, -1.16315081e+00, -1.17865500e+00,\n",
       "                     -1.18377010e+00, -1.18716569e+00, -1.20397280e+00, -1.20609820e+00,\n",
       "                     -1.21639532e+00, -1.22866542e+00, -1.24319352e+00, -1.25276297e+00,\n",
       "                     -1.27887411e+00, -1.28692189e+00, -1.29392104e+00, -1.29928298e+00,\n",
       "                     -1.30906301e+00, -1.31928365e+00, -1.32687094e+00, -1.33500107e+00,\n",
       "                     -1.35962611e+00, -1.36948724e+00, -1.38629436e+00, -1.39936644e+00,\n",
       "                     -1.41706602e+00, -1.42825856e+00, -1.44238383e+00, -1.50407740e+00,\n",
       "                     -1.51846613e+00, -1.52794488e+00, -1.55537069e+00, -1.59504917e+00,\n",
       "                     -1.60943791e+00, -1.60943791e+00, -1.67397643e+00, -1.73460106e+00,\n",
       "                     -1.79175947e+00, -1.79175947e+00, -1.80828877e+00, -1.82161243e+00,\n",
       "                     -1.84582669e+00, -1.94591015e+00, -1.94591015e+00, -2.01490302e+00,\n",
       "                     -2.02001812e+00, -2.04769284e+00, -2.07944154e+00, -2.19722458e+00,\n",
       "                     -2.30258509e+00, -2.34180581e+00, -2.39789527e+00, -2.54944517e+00,\n",
       "                     -2.58399755e+00, -2.68557735e+00, -2.89037176e+00, -2.92673940e+00,\n",
       "                     -2.94443898e+00, -2.99573227e+00, -3.09104245e+00, -3.66356165e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5229603494367044, privacy_risk=0.5178139826336048, accuracy=0.5178139826336049, tpr_ind=0.8628591889714439, tnr_ind=0.1727687762957658, test_train_ratio=1.0, dataset_size=[11171, 11171])],\n",
       "             'entire_dataset_label_0.0_mia_auc': [0.5314090932590082,\n",
       "              0.5205759212135129,\n",
       "              0.5180031457722714,\n",
       "              0.5211738599991915,\n",
       "              0.5206435167815923,\n",
       "              0.5203737795024496,\n",
       "              0.5318458148858649,\n",
       "              0.5225100257157197,\n",
       "              0.5273402584625629,\n",
       "              0.5255123639591708,\n",
       "              0.5209872987218627,\n",
       "              0.5192580488799279,\n",
       "              0.5244431186092012,\n",
       "              0.522110116198164,\n",
       "              0.5332592629831928,\n",
       "              0.5260924055867516,\n",
       "              0.5321906326017397,\n",
       "              0.5257269322109799,\n",
       "              0.5224436934368305,\n",
       "              0.522544040825466],\n",
       "             'entire_dataset_label_0.0_mia_privacy_risk': [0.5246284633785587,\n",
       "              0.5157172498695726,\n",
       "              0.5139873604110256,\n",
       "              0.5160850798983301,\n",
       "              0.5156810035842294,\n",
       "              0.517464366704435,\n",
       "              0.5224014336917563,\n",
       "              0.5178614224040353,\n",
       "              0.5210462513162202,\n",
       "              0.5222463025693063,\n",
       "              0.517538707794178,\n",
       "              0.516798460425166,\n",
       "              0.5217786054479713,\n",
       "              0.5167994323961708,\n",
       "              0.5276280035475638,\n",
       "              0.5193282358568164,\n",
       "              0.5229794943063699,\n",
       "              0.5228868171178314,\n",
       "              0.5167690732206861,\n",
       "              0.5164730667103198],\n",
       "             'entire_dataset_label_0.0_mia_ppv': [0.5338427947598253,\n",
       "              0.5295051600952633,\n",
       "              0.5254515599343186,\n",
       "              0.5332136445242369,\n",
       "              0.5416068866571019,\n",
       "              0.530552861299709,\n",
       "              0.5460845460845462,\n",
       "              0.523010752688172,\n",
       "              0.5335260115606937,\n",
       "              0.5256322624743677,\n",
       "              0.520814880425155,\n",
       "              0.5230146686899343,\n",
       "              0.5180917262041945,\n",
       "              0.5355859094176851,\n",
       "              0.5400870105655686,\n",
       "              0.5299844236760124,\n",
       "              0.543731778425656,\n",
       "              0.5323910482921084,\n",
       "              0.5283797729618163,\n",
       "              0.5220500595947556],\n",
       "             'entire_dataset_label_0.0_mia_attacker_advantage': [0.04925692675711746,\n",
       "              0.03143449973914514,\n",
       "              0.027974720822051102,\n",
       "              0.03217015979666016,\n",
       "              0.031362007168458716,\n",
       "              0.03492873340887004,\n",
       "              0.04480286738351247,\n",
       "              0.03572284480807064,\n",
       "              0.04209250263244052,\n",
       "              0.04449260513861242,\n",
       "              0.035077415588355976,\n",
       "              0.033596920850331835,\n",
       "              0.043557210895942666,\n",
       "              0.033598864792341476,\n",
       "              0.05525600709512768,\n",
       "              0.038656471713632956,\n",
       "              0.04595898861273995,\n",
       "              0.04577363423566283,\n",
       "              0.03353814644137226,\n",
       "              0.032946133420639456],\n",
       "             'entire_dataset_label_0.0_mia_result': [MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.09570788, 0.09788597, 0.09967969, 0.10237028,\n",
       "                     0.10928892, 0.11082639, 0.11159513, 0.11326073, 0.11492633,\n",
       "                     0.12261371, 0.13670724, 0.14183216, 0.14272902, 0.14606022,\n",
       "                     0.16194747, 0.16412556, 0.17578475, 0.19231262, 0.19897502,\n",
       "                     0.20076874, 0.20397181, 0.20717489, 0.2206278 , 0.22575272,\n",
       "                     0.23126201, 0.23484946, 0.24945548, 0.25253043, 0.2557335 ,\n",
       "                     0.26265215, 0.28161435, 0.28353619, 0.28712364, 0.32722614,\n",
       "                     0.33004484, 0.33452915, 0.33798847, 0.34272902, 0.34746957,\n",
       "                     0.36502242, 0.38936579, 0.39769379, 0.40422806, 0.40819987,\n",
       "                     0.41229981, 0.4256246 , 0.44561179, 0.4495836 , 0.46303652,\n",
       "                     0.4685458 , 0.48097373, 0.49404228, 0.50352338, 0.5136451 ,\n",
       "                     0.51761691, 0.53030109, 0.53196669, 0.54785394, 0.55169763,\n",
       "                     0.56566304, 0.59154388, 0.59743754, 0.60230621, 0.60384369,\n",
       "                     0.61089045, 0.61588725, 0.61960282, 0.63946188, 0.64983985,\n",
       "                     0.66508648, 0.68122998, 0.68750801, 0.69224856, 0.695836  ,\n",
       "                     0.69942345, 0.70429212, 0.72222934, 0.73183857, 0.73324792,\n",
       "                     0.73670724, 0.74388213, 0.75323511, 0.76412556, 0.76784113,\n",
       "                     0.7682255 , 0.77335042, 0.77501602, 0.77629725, 0.7938501 ,\n",
       "                     0.79474696, 0.79743754, 0.80281871, 0.81229981, 0.81268418,\n",
       "                     0.81639974, 0.81819347, 0.81909033, 0.82536835, 0.82639334,\n",
       "                     0.84368994, 0.84586803, 0.85099295, 0.85522101, 0.86085842,\n",
       "                     0.86828956, 0.87443946, 0.88571429, 0.88750801, 0.89237668,\n",
       "                     0.89634849, 0.9008328 , 0.90237028, 0.90544523, 0.90608584,\n",
       "                     0.91005766, 0.92453555, 0.928123  , 0.93209481, 0.9326073 ,\n",
       "                     0.93414478, 0.94106342, 0.94388213, 0.95426009, 0.9554132 ,\n",
       "                     0.96015375, 0.9615631 , 0.9648943 , 0.96591928, 0.96707239,\n",
       "                     0.97014734, 0.97258168, 0.97629725, 0.97834721, 0.97962844,\n",
       "                     0.98539398, 0.98641896, 0.9871877 , 0.98731582, 0.98923767,\n",
       "                     0.98975016, 0.98987828, 0.99064702, 1.        ]), tpr=array([0.        , 0.10627958, 0.10934902, 0.11229057, 0.11510423,\n",
       "                     0.12290574, 0.12495204, 0.12674255, 0.12814938, 0.13083515,\n",
       "                     0.14004348, 0.15411178, 0.16050646, 0.16255276, 0.16447116,\n",
       "                     0.18148101, 0.1876199 , 0.20066505, 0.21498913, 0.22176749,\n",
       "                     0.22458115, 0.22726691, 0.23110372, 0.24402097, 0.25015987,\n",
       "                     0.25476404, 0.25770559, 0.27522701, 0.28034275, 0.28405167,\n",
       "                     0.29326001, 0.31385088, 0.31564139, 0.31871083, 0.35950889,\n",
       "                     0.36488042, 0.37063563, 0.37536769, 0.38086712, 0.38751759,\n",
       "                     0.40363218, 0.42729249, 0.43624504, 0.44212815, 0.44762757,\n",
       "                     0.45197596, 0.46425374, 0.48369357, 0.48740248, 0.50019184,\n",
       "                     0.50479601, 0.5188643 , 0.53178156, 0.54047832, 0.55134928,\n",
       "                     0.55441872, 0.56541757, 0.56874281, 0.58754316, 0.59163576,\n",
       "                     0.60340197, 0.63320118, 0.63806113, 0.64432792, 0.64688579,\n",
       "                     0.65481519, 0.66108198, 0.66402353, 0.68244021, 0.69152065,\n",
       "                     0.70891418, 0.72490088, 0.73193503, 0.73820182, 0.74344545,\n",
       "                     0.74779384, 0.75354905, 0.77030311, 0.77580253, 0.7783604 ,\n",
       "                     0.78181353, 0.78820821, 0.79549815, 0.80777593, 0.81161274,\n",
       "                     0.81250799, 0.81583323, 0.81736795, 0.81864689, 0.83540095,\n",
       "                     0.8364241 , 0.83885407, 0.84269088, 0.85151554, 0.85305026,\n",
       "                     0.85714286, 0.86008441, 0.86136335, 0.86788592, 0.86878117,\n",
       "                     0.88463998, 0.88655838, 0.89065098, 0.89487147, 0.8981967 ,\n",
       "                     0.90395191, 0.91149763, 0.92083387, 0.92288016, 0.92710065,\n",
       "                     0.93170482, 0.93503005, 0.93592531, 0.93797161, 0.93925054,\n",
       "                     0.94283156, 0.95357463, 0.95587671, 0.95894616, 0.96035299,\n",
       "                     0.96150403, 0.96559662, 0.96841028, 0.97544443, 0.97621179,\n",
       "                     0.97992071, 0.98119964, 0.98273437, 0.98362962, 0.98439698,\n",
       "                     0.98657117, 0.98848958, 0.99155902, 0.99309375, 0.99373321,\n",
       "                     0.99705845, 0.99757002, 0.99833738, 0.99859317, 0.99948843,\n",
       "                     0.99961632, 0.99987211, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.08219945e-02, -4.25596144e-02,\n",
       "                     -4.44517626e-02, -4.80092192e-02, -6.06246218e-02, -6.89928715e-02,\n",
       "                     -8.70113770e-02, -9.09717782e-02, -1.05360516e-01, -1.11703990e-01,\n",
       "                     -1.13328685e-01, -1.17783036e-01, -1.25163143e-01, -1.33531393e-01,\n",
       "                     -1.36132174e-01, -1.54150680e-01, -1.56698452e-01, -1.56842471e-01,\n",
       "                     -1.67054085e-01, -1.74353387e-01, -1.82321557e-01, -1.88900528e-01,\n",
       "                     -1.89242000e-01, -2.23143551e-01, -2.31801614e-01, -2.33310669e-01,\n",
       "                     -2.42946179e-01, -2.43622083e-01, -2.45122458e-01, -2.46471804e-01,\n",
       "                     -2.51314428e-01, -2.55933374e-01, -2.65494157e-01, -2.69663567e-01,\n",
       "                     -2.70874954e-01, -2.80902385e-01, -2.81851152e-01, -2.82862786e-01,\n",
       "                     -2.87682072e-01, -2.93072921e-01, -2.94799540e-01, -2.98492989e-01,\n",
       "                     -2.99242895e-01, -3.02280872e-01, -3.03186259e-01, -3.08838272e-01,\n",
       "                     -3.21583624e-01, -3.22083499e-01, -3.28504067e-01, -3.29957556e-01,\n",
       "                     -3.33639374e-01, -3.34369186e-01, -3.36472237e-01, -3.48306694e-01,\n",
       "                     -3.49673748e-01, -3.52821375e-01, -3.56674944e-01, -3.62905494e-01,\n",
       "                     -3.68560551e-01, -3.69044477e-01, -3.69747026e-01, -3.70859579e-01,\n",
       "                     -3.71563556e-01, -3.83725121e-01, -3.84845821e-01, -3.90866309e-01,\n",
       "                     -3.91478866e-01, -4.00759217e-01, -4.05465108e-01, -4.08128226e-01,\n",
       "                     -4.11507423e-01, -4.12244795e-01, -4.13562318e-01, -4.24883194e-01,\n",
       "                     -4.27444015e-01, -4.28107585e-01, -4.28454626e-01, -4.38254931e-01,\n",
       "                     -4.41832752e-01, -4.44685821e-01, -4.45585102e-01, -4.46287103e-01,\n",
       "                     -4.48950220e-01, -4.51985124e-01, -4.55475529e-01, -4.59532329e-01,\n",
       "                     -4.70003629e-01, -4.81388951e-01, -4.85507816e-01, -4.89548225e-01,\n",
       "                     -4.90622916e-01, -5.02091944e-01, -5.10825624e-01, -5.23248144e-01,\n",
       "                     -5.28067430e-01, -5.30628251e-01, -5.34082486e-01, -5.38996501e-01,\n",
       "                     -5.45694449e-01, -5.50046337e-01, -5.59615788e-01, -5.63935449e-01,\n",
       "                     -5.70544858e-01, -5.75364145e-01, -5.76422906e-01, -5.92342481e-01,\n",
       "                     -5.94707108e-01, -5.97837001e-01, -6.06135804e-01, -6.13104473e-01,\n",
       "                     -6.19039208e-01, -6.28608659e-01, -6.41853886e-01, -6.75128675e-01,\n",
       "                     -6.93147181e-01, -7.20546155e-01, -7.33969175e-01, -7.37598943e-01,\n",
       "                     -7.47214402e-01, -7.53771802e-01, -7.59105148e-01, -7.63351439e-01,\n",
       "                     -7.73189888e-01, -7.75838896e-01, -7.88457360e-01, -8.10930216e-01,\n",
       "                     -8.26678573e-01, -8.47297860e-01, -8.55666110e-01, -8.75468737e-01,\n",
       "                     -9.16290732e-01, -9.80829253e-01, -1.02961942e+00, -1.09861229e+00,\n",
       "                     -1.17865500e+00, -1.20397280e+00, -1.25276297e+00, -1.38629436e+00,\n",
       "                     -1.60943791e+00, -1.70474809e+00, -2.48490665e+00, -3.45387764e+01]), auc_score=0.5314090932590082, privacy_risk=0.5246284633785587, accuracy=0.5248335893497184, tpr_ind=0.7535490471927356, tnr_ind=0.2957078795643818, test_train_ratio=0.9982094897045658, dataset_size=[7819, 7805]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.07517437, 0.08305347, 0.09325756, 0.0964867 ,\n",
       "                     0.10010333, 0.10255748, 0.1035908 , 0.11573237, 0.12361147,\n",
       "                     0.1283906 , 0.13161974, 0.13704469, 0.16481529, 0.16662361,\n",
       "                     0.16933609, 0.17346939, 0.17799018, 0.19361922, 0.19671919,\n",
       "                     0.20123999, 0.22965642, 0.23353139, 0.24476879, 0.2477396 ,\n",
       "                     0.27318522, 0.28080599, 0.30483079, 0.3081891 , 0.31064324,\n",
       "                     0.32162232, 0.32730561, 0.32988892, 0.34190132, 0.35145957,\n",
       "                     0.36230948, 0.3956342 , 0.39795918, 0.40338414, 0.40829243,\n",
       "                     0.41384655, 0.46086283, 0.46925859, 0.47210023, 0.49367089,\n",
       "                     0.49728752, 0.50490829, 0.51072074, 0.51382072, 0.52983725,\n",
       "                     0.52996642, 0.53358305, 0.5364247 , 0.53926634, 0.54288298,\n",
       "                     0.55037458, 0.59054508, 0.60178249, 0.60371997, 0.61198657,\n",
       "                     0.61482821, 0.61857401, 0.6437613 , 0.65267373, 0.65538621,\n",
       "                     0.66003617, 0.66985275, 0.68302764, 0.68677344, 0.69064841,\n",
       "                     0.69452338, 0.72397313, 0.75342289, 0.7560062 , 0.75729786,\n",
       "                     0.75820201, 0.7638853 , 0.76646861, 0.78132266, 0.78726427,\n",
       "                     0.81219323, 0.82678894, 0.82898476, 0.83544304, 0.84241798,\n",
       "                     0.84706794, 0.85081374, 0.86437613, 0.87897184, 0.88013433,\n",
       "                     0.8964092 , 0.89679669, 0.90131749, 0.90441746, 0.90596745,\n",
       "                     0.90790493, 0.91048825, 0.91539654, 0.9163007 , 0.91849651,\n",
       "                     0.91927151, 0.9245673 , 0.9324464 , 0.94097133, 0.94975459,\n",
       "                     0.95789202, 0.96693361, 0.97029191, 0.97623353, 0.97894601,\n",
       "                     0.98075433, 0.98320847, 0.98333764, 0.9834668 , 0.98450013,\n",
       "                     0.98682511, 0.98850426, 0.98940842, 0.99031258, 0.99070008,\n",
       "                     0.99199173, 0.9925084 , 0.99289589, 1.        ]), tpr=array([0.        , 0.08145141, 0.09058615, 0.10162395, 0.10466887,\n",
       "                     0.10758691, 0.11075869, 0.11228115, 0.12433393, 0.13321492,\n",
       "                     0.14044659, 0.14387211, 0.15072317, 0.18193352, 0.18370972,\n",
       "                     0.18624715, 0.19030703, 0.19563563, 0.213017  , 0.2156813 ,\n",
       "                     0.22088302, 0.25386958, 0.25691449, 0.27023598, 0.27378838,\n",
       "                     0.29814768, 0.30487186, 0.32669373, 0.32910429, 0.33138797,\n",
       "                     0.34039584, 0.34750063, 0.35054555, 0.36399391, 0.373763  ,\n",
       "                     0.38365897, 0.41423497, 0.41677239, 0.42108602, 0.42641462,\n",
       "                     0.43199696, 0.48883532, 0.4973357 , 0.50038061, 0.52232936,\n",
       "                     0.52562801, 0.53184471, 0.53768079, 0.54123319, 0.55531591,\n",
       "                     0.55658462, 0.56064451, 0.56407003, 0.56622685, 0.56927176,\n",
       "                     0.5766303 , 0.61393047, 0.62382644, 0.62636387, 0.63676732,\n",
       "                     0.63867039, 0.64323776, 0.66924638, 0.67914235, 0.68231413,\n",
       "                     0.68891144, 0.70020299, 0.71276326, 0.71682314, 0.72151738,\n",
       "                     0.72595788, 0.75171276, 0.77911698, 0.78216189, 0.78444557,\n",
       "                     0.78622177, 0.79193098, 0.79484902, 0.8069018 , 0.81159604,\n",
       "                     0.83646283, 0.85003806, 0.85143365, 0.85612789, 0.86234458,\n",
       "                     0.8653895 , 0.87097183, 0.88873382, 0.90332403, 0.90421213,\n",
       "                     0.91740675, 0.91842172, 0.92210099, 0.92539964, 0.92717584,\n",
       "                     0.92907891, 0.93174321, 0.93605684, 0.93694494, 0.93884801,\n",
       "                     0.93986298, 0.94658716, 0.95419944, 0.96092362, 0.96739406,\n",
       "                     0.97183456, 0.98084243, 0.98236488, 0.98832784, 0.99086526,\n",
       "                     0.99213398, 0.99365643, 0.99429079, 0.99454453, 0.99530576,\n",
       "                     0.9973357 , 0.99835067, 0.99885816, 0.99923877, 0.99936564,\n",
       "                     0.99961939, 0.99974626, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.37933221e-02, -3.39015517e-02,\n",
       "                     -4.08219945e-02, -4.25596144e-02, -7.69610411e-02, -8.00427077e-02,\n",
       "                     -8.08520966e-02, -9.53101798e-02, -1.00083459e-01, -1.05360516e-01,\n",
       "                     -1.21889818e-01, -1.25880246e-01, -1.33531393e-01, -1.39761942e-01,\n",
       "                     -1.45182010e-01, -1.54150680e-01, -1.67615409e-01, -1.74353387e-01,\n",
       "                     -1.78248231e-01, -1.82321557e-01, -1.89242000e-01, -1.90226736e-01,\n",
       "                     -1.94156014e-01, -2.14775302e-01, -2.19362828e-01, -2.23143551e-01,\n",
       "                     -2.33614851e-01, -2.45122458e-01, -2.48179629e-01, -2.51314428e-01,\n",
       "                     -2.55933374e-01, -2.71034839e-01, -2.71315095e-01, -2.87682072e-01,\n",
       "                     -2.99028249e-01, -3.00104592e-01, -3.02280872e-01, -3.05381650e-01,\n",
       "                     -3.10154928e-01, -3.11939050e-01, -3.17095958e-01, -3.18453731e-01,\n",
       "                     -3.23171957e-01, -3.25422400e-01, -3.27687407e-01, -3.30241687e-01,\n",
       "                     -3.31357136e-01, -3.33894916e-01, -3.36472237e-01, -3.40926587e-01,\n",
       "                     -3.41749294e-01, -3.44840486e-01, -3.48306694e-01, -3.58397597e-01,\n",
       "                     -3.66153688e-01, -3.70678992e-01, -3.71563556e-01, -3.72404246e-01,\n",
       "                     -3.82992252e-01, -3.86772975e-01, -3.87417038e-01, -3.88223302e-01,\n",
       "                     -3.92042088e-01, -3.92561703e-01, -4.01712758e-01, -4.02092424e-01,\n",
       "                     -4.05465108e-01, -4.14433778e-01, -4.14943852e-01, -4.23366318e-01,\n",
       "                     -4.26839968e-01, -4.32864082e-01, -4.41832752e-01, -4.51985124e-01,\n",
       "                     -4.70003629e-01, -4.75423697e-01, -4.83075711e-01, -4.83426650e-01,\n",
       "                     -4.83936724e-01, -4.86226465e-01, -4.92476485e-01, -4.99955952e-01,\n",
       "                     -5.02628857e-01, -5.10825624e-01, -5.19875459e-01, -5.22189382e-01,\n",
       "                     -5.33182531e-01, -5.38996501e-01, -5.54106132e-01, -5.59615788e-01,\n",
       "                     -5.64529803e-01, -5.70544858e-01, -5.79818495e-01, -5.87786665e-01,\n",
       "                     -5.93063722e-01, -6.16774202e-01, -6.19039208e-01, -6.24154309e-01,\n",
       "                     -6.28608659e-01, -6.44828603e-01, -6.67829373e-01, -6.74098986e-01,\n",
       "                     -6.93147181e-01, -7.21318058e-01, -7.27752710e-01, -7.73189888e-01,\n",
       "                     -7.94243297e-01, -8.10930216e-01, -8.32909123e-01, -8.47297860e-01,\n",
       "                     -8.75468737e-01, -9.16290732e-01, -9.80829253e-01, -1.09861229e+00,\n",
       "                     -1.17865500e+00, -1.25276297e+00, -1.38629436e+00, -1.60943791e+00,\n",
       "                     -1.70474809e+00, -1.79175947e+00, -2.19722458e+00, -3.45387764e+01]), auc_score=0.5205759212135129, privacy_risk=0.5157172498695726, accuracy=0.5176011264720942, tpr_ind=0.725957878710987, tnr_ind=0.3054766210281581, test_train_ratio=0.9822380106571936, dataset_size=[7882, 7742]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.1015926 , 0.10621629, 0.11019779, 0.11880298,\n",
       "                     0.12419728, 0.1275366 , 0.12907783, 0.13177498, 0.13960956,\n",
       "                     0.14038017, 0.14102235, 0.14847162, 0.15155407, 0.15296686,\n",
       "                     0.16491138, 0.16927819, 0.17081942, 0.17390188, 0.17698433,\n",
       "                     0.17993835, 0.19098382, 0.19727716, 0.2027999 , 0.21692782,\n",
       "                     0.2197534 , 0.23079887, 0.23516568, 0.23889032, 0.2399178 ,\n",
       "                     0.24595428, 0.2528898 , 0.25918315, 0.26290778, 0.26509119,\n",
       "                     0.26778834, 0.27382481, 0.28731056, 0.28949396, 0.30053943,\n",
       "                     0.30683278, 0.30773183, 0.34484973, 0.35936296, 0.36360134,\n",
       "                     0.37040843, 0.38838942, 0.39956332, 0.40534292, 0.40855381,\n",
       "                     0.41959928, 0.42409453, 0.43051631, 0.43578217, 0.43719497,\n",
       "                     0.45119445, 0.45350629, 0.46005651, 0.46596455, 0.50886206,\n",
       "                     0.51232982, 0.51541228, 0.52093501, 0.5313383 , 0.54623684,\n",
       "                     0.54996147, 0.56922682, 0.5702543 , 0.58194195, 0.59696892,\n",
       "                     0.5979964 , 0.6015926 , 0.6033907 , 0.6123812 , 0.61494991,\n",
       "                     0.62458258, 0.6419214 , 0.64654508, 0.66876445, 0.67634215,\n",
       "                     0.7049833 , 0.71500128, 0.7471102 , 0.75147701, 0.77626509,\n",
       "                     0.77742101, 0.78178782, 0.79771385, 0.80246596, 0.80387876,\n",
       "                     0.80940149, 0.81004367, 0.81299769, 0.82956589, 0.83984074,\n",
       "                     0.8540971 , 0.85782173, 0.85923452, 0.86141793, 0.86180324,\n",
       "                     0.86719753, 0.8706653 , 0.89147187, 0.89558181, 0.89917801,\n",
       "                     0.90071924, 0.91125096, 0.9149756 , 0.92268174, 0.92525045,\n",
       "                     0.92666324, 0.92858978, 0.93282815, 0.94644233, 0.95016697,\n",
       "                     0.96378115, 0.96429489, 0.96480863, 0.9668636 , 0.96968919,\n",
       "                     0.97020293, 0.97238633, 0.97328538, 0.97418443, 0.9762394 ,\n",
       "                     0.97726689, 0.97880812, 0.98047778, 0.98754174, 0.99023889,\n",
       "                     0.99139481, 0.99165168, 0.99178012, 0.99255073, 1.        ]), tpr=array([0.        , 0.10844603, 0.11495279, 0.11941822, 0.12783873,\n",
       "                     0.13498341, 0.13791784, 0.14072467, 0.14302118, 0.15042103,\n",
       "                     0.1522072 , 0.15386578, 0.16330697, 0.16636897, 0.16777239,\n",
       "                     0.18040316, 0.18346517, 0.18703751, 0.18958918, 0.19367186,\n",
       "                     0.19609594, 0.20681296, 0.21383006, 0.22033682, 0.23819852,\n",
       "                     0.24113294, 0.25044654, 0.2538913 , 0.25835672, 0.26001531,\n",
       "                     0.26537382, 0.2725185 , 0.27685634, 0.28068385, 0.28400102,\n",
       "                     0.28540444, 0.29140087, 0.30798673, 0.31066599, 0.32316918,\n",
       "                     0.3291656 , 0.33044144, 0.36552692, 0.38415412, 0.38810921,\n",
       "                     0.39397806, 0.41502934, 0.42396019, 0.42944629, 0.43301863,\n",
       "                     0.4448839 , 0.44973207, 0.45560092, 0.46312835, 0.46516969,\n",
       "                     0.47665221, 0.47933146, 0.48545547, 0.49055882, 0.53342689,\n",
       "                     0.53623373, 0.54057157, 0.54605767, 0.5566471 , 0.57106405,\n",
       "                     0.57285022, 0.59134983, 0.59339117, 0.60602194, 0.62133197,\n",
       "                     0.62273539, 0.6257974 , 0.62771115, 0.63370758, 0.6358765 ,\n",
       "                     0.64276601, 0.66062771, 0.6645828 , 0.68678234, 0.69354427,\n",
       "                     0.71906098, 0.7274815 , 0.76218423, 0.76588415, 0.79280429,\n",
       "                     0.79548354, 0.80096964, 0.81844858, 0.82316918, 0.82444501,\n",
       "                     0.82942077, 0.83044144, 0.83222761, 0.85225823, 0.86067874,\n",
       "                     0.87573361, 0.87854044, 0.88019903, 0.8819852 , 0.88338862,\n",
       "                     0.88861955, 0.8905333 , 0.91260526, 0.91605001, 0.91860168,\n",
       "                     0.92089819, 0.93238071, 0.93659097, 0.94462873, 0.94705282,\n",
       "                     0.9479459 , 0.94947691, 0.95304925, 0.96440418, 0.96810411,\n",
       "                     0.97869354, 0.97945905, 0.98073488, 0.98354172, 0.98507272,\n",
       "                     0.98596581, 0.98762439, 0.98877265, 0.98941056, 0.9906864 ,\n",
       "                     0.99183465, 0.99285532, 0.99362082, 0.99744833, 0.99872416,\n",
       "                     0.99910692, 0.99961725, 0.99974483, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.94180859e-02, -2.81708770e-02,\n",
       "                     -2.98529631e-02, -3.50913198e-02, -4.25596144e-02, -4.44517626e-02,\n",
       "                     -5.40672213e-02, -6.66913745e-02, -6.89928715e-02, -7.41079722e-02,\n",
       "                     -7.79615415e-02, -8.00427077e-02, -8.70113770e-02, -1.05360516e-01,\n",
       "                     -1.17783036e-01, -1.33531393e-01, -1.39761942e-01, -1.45182010e-01,\n",
       "                     -1.46603474e-01, -1.54150680e-01, -1.67054085e-01, -1.79048231e-01,\n",
       "                     -1.82321557e-01, -1.96710294e-01, -1.98176929e-01, -2.00670695e-01,\n",
       "                     -2.05852054e-01, -2.07639365e-01, -2.13574100e-01, -2.23143551e-01,\n",
       "                     -2.34839591e-01, -2.36388778e-01, -2.38411023e-01, -2.41162057e-01,\n",
       "                     -2.44196961e-01, -2.44453338e-01, -2.51314428e-01, -2.59219608e-01,\n",
       "                     -2.60726262e-01, -2.62364264e-01, -2.63761889e-01, -2.68666806e-01,\n",
       "                     -2.79584862e-01, -2.82232468e-01, -2.87682072e-01, -2.94799540e-01,\n",
       "                     -2.99242895e-01, -3.05381650e-01, -3.11587593e-01, -3.13657559e-01,\n",
       "                     -3.14493330e-01, -3.16911711e-01, -3.18453731e-01, -3.20471895e-01,\n",
       "                     -3.22773392e-01, -3.33491608e-01, -3.36472237e-01, -3.41984229e-01,\n",
       "                     -3.42944751e-01, -3.44840486e-01, -3.49673748e-01, -3.51844017e-01,\n",
       "                     -3.54016546e-01, -3.56674944e-01, -3.60804337e-01, -3.62905494e-01,\n",
       "                     -3.67724780e-01, -3.71563556e-01, -3.74693449e-01, -3.77294231e-01,\n",
       "                     -3.82992252e-01, -3.83958903e-01, -3.85662481e-01, -4.05465108e-01,\n",
       "                     -4.14943852e-01, -4.16160397e-01, -4.20674527e-01, -4.24157241e-01,\n",
       "                     -4.35023910e-01, -4.35318071e-01, -4.39203248e-01, -4.39366660e-01,\n",
       "                     -4.47234521e-01, -4.51985124e-01, -4.58307589e-01, -4.64514137e-01,\n",
       "                     -4.66619531e-01, -4.70003629e-01, -4.79573080e-01, -4.85507816e-01,\n",
       "                     -4.96436886e-01, -5.08274602e-01, -5.10825624e-01, -5.12519104e-01,\n",
       "                     -5.19875459e-01, -5.26093096e-01, -5.38996501e-01, -5.46543706e-01,\n",
       "                     -5.49107810e-01, -5.50046337e-01, -5.53818670e-01, -5.54310736e-01,\n",
       "                     -5.59615788e-01, -5.75364145e-01, -5.87786665e-01, -5.97837001e-01,\n",
       "                     -6.10455465e-01, -6.10909082e-01, -6.19039208e-01, -6.50587566e-01,\n",
       "                     -6.56779536e-01, -6.93147181e-01, -7.10241614e-01, -7.40214691e-01,\n",
       "                     -7.73189888e-01, -7.88457360e-01, -8.00777845e-01, -8.10930216e-01,\n",
       "                     -8.26678573e-01, -8.36248024e-01, -8.47297860e-01, -8.75468737e-01,\n",
       "                     -9.16290732e-01, -9.80829253e-01, -1.01160091e+00, -1.04145387e+00,\n",
       "                     -1.09861229e+00, -1.38629436e+00, -1.46633707e+00, -1.60943791e+00,\n",
       "                     -1.79175947e+00, -1.94591015e+00, -3.45387764e+01]), auc_score=0.5180031457722714, privacy_risk=0.5139873604110256, accuracy=0.5138248847926268, tpr_ind=0.4651696861444246, tnr_ind=0.5628050346776265, test_train_ratio=0.9933656545037, dataset_size=[7838, 7786]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.08079521, 0.09940104, 0.10590034, 0.11265452,\n",
       "                     0.1163502 , 0.12004588, 0.12259462, 0.12603543, 0.12858417,\n",
       "                     0.12998598, 0.14107302, 0.14553332, 0.15356187, 0.15802217,\n",
       "                     0.16082579, 0.1642666 , 0.1772652 , 0.17790238, 0.18210781,\n",
       "                     0.18452912, 0.18988148, 0.1981649 , 0.20071365, 0.20351727,\n",
       "                     0.214222  , 0.21549637, 0.22263285, 0.22492672, 0.24952211,\n",
       "                     0.25283548, 0.25602141, 0.26952976, 0.27322544, 0.29004715,\n",
       "                     0.2960367 , 0.30228113, 0.30495731, 0.31132917, 0.31324073,\n",
       "                     0.31540716, 0.32343571, 0.35618708, 0.35733401, 0.36319613,\n",
       "                     0.36956799, 0.37300879, 0.37619472, 0.38129221, 0.38587995,\n",
       "                     0.39416337, 0.39722187, 0.40983815, 0.41353383, 0.43213967,\n",
       "                     0.43468842, 0.46552823, 0.50541608, 0.50847458, 0.51841468,\n",
       "                     0.52211036, 0.52363961, 0.53905951, 0.54160826, 0.544157  ,\n",
       "                     0.56352746, 0.57066395, 0.57550656, 0.58876004, 0.59806295,\n",
       "                     0.60010195, 0.61067924, 0.62953995, 0.63603925, 0.64126418,\n",
       "                     0.67223143, 0.68038741, 0.68229897, 0.69172932, 0.69440551,\n",
       "                     0.69771887, 0.70014018, 0.70256149, 0.70345355, 0.7169619 ,\n",
       "                     0.72358863, 0.73110743, 0.73403849, 0.75136995, 0.7593985 ,\n",
       "                     0.77112272, 0.80922646, 0.81113801, 0.81266726, 0.81470626,\n",
       "                     0.82044093, 0.83318466, 0.84376195, 0.84567351, 0.84822225,\n",
       "                     0.8552313 , 0.87179814, 0.8737097 , 0.87549382, 0.87689563,\n",
       "                     0.88033643, 0.88760036, 0.89295272, 0.89422709, 0.9106665 ,\n",
       "                     0.91563655, 0.91971454, 0.9216261 , 0.9250669 , 0.93602651,\n",
       "                     0.95934752, 0.96176883, 0.96317064, 0.96444501, 0.96712119,\n",
       "                     0.96941506, 0.97196381, 0.97362049, 0.97578692, 0.98011979,\n",
       "                     0.98266854, 0.98458009, 0.98572703, 0.98929527, 0.99018733,\n",
       "                     0.99158914, 0.9924812 , 0.99337326, 1.        ]), tpr=array([0.        , 0.09052334, 0.1145686 , 0.12176932, 0.12806995,\n",
       "                     0.13115597, 0.13334191, 0.13694227, 0.14002829, 0.14298573,\n",
       "                     0.14440015, 0.15327247, 0.15828726, 0.16548798, 0.1702456 ,\n",
       "                     0.17436029, 0.17731773, 0.18940465, 0.19017616, 0.19531953,\n",
       "                     0.19891989, 0.20354893, 0.21062106, 0.21370708, 0.21730745,\n",
       "                     0.23106596, 0.23222322, 0.23852385, 0.24186704, 0.26732673,\n",
       "                     0.270027  , 0.27324161, 0.28815739, 0.2921435 , 0.30757361,\n",
       "                     0.31413141, 0.32107496, 0.32428957, 0.33161888, 0.33341906,\n",
       "                     0.33560499, 0.34332005, 0.37495178, 0.37662338, 0.38279542,\n",
       "                     0.38973897, 0.39462518, 0.4001543 , 0.40555484, 0.40889803,\n",
       "                     0.41854185, 0.42137071, 0.43294329, 0.4378295 , 0.4558313 ,\n",
       "                     0.45994599, 0.48759162, 0.53002443, 0.53388196, 0.5433972 ,\n",
       "                     0.54751189, 0.54905491, 0.56564228, 0.56962839, 0.57207149,\n",
       "                     0.59277356, 0.59971711, 0.6039604 , 0.61489006, 0.6244053 ,\n",
       "                     0.62659123, 0.63842098, 0.65680854, 0.66079465, 0.66555227,\n",
       "                     0.69975569, 0.7102996 , 0.7119712 , 0.72225794, 0.7234152 ,\n",
       "                     0.72701556, 0.72945866, 0.73100167, 0.7331876 , 0.74913206,\n",
       "                     0.75556127, 0.76173332, 0.76520509, 0.7798637 , 0.78796451,\n",
       "                     0.80120869, 0.83914106, 0.84119841, 0.84377009, 0.84595602,\n",
       "                     0.85084223, 0.8601003 , 0.86922978, 0.87090138, 0.87321589,\n",
       "                     0.88080237, 0.89520381, 0.89841841, 0.90047576, 0.90189019,\n",
       "                     0.90729073, 0.91500579, 0.91796322, 0.9189919 , 0.94007972,\n",
       "                     0.94239424, 0.94625177, 0.94779478, 0.95113797, 0.96001029,\n",
       "                     0.97724058, 0.97865501, 0.97994085, 0.98058377, 0.98289829,\n",
       "                     0.98546998, 0.98739874, 0.98881317, 0.99125627, 0.99279928,\n",
       "                     0.99395654, 0.99472804, 0.99537097, 0.9975569 , 0.99781407,\n",
       "                     0.99858557, 0.99974283, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.06383982e-02, -3.50913198e-02,\n",
       "                     -4.00053346e-02, -4.08219945e-02, -5.71584138e-02, -6.89928715e-02,\n",
       "                     -8.00427077e-02, -8.33816089e-02, -8.70113770e-02, -9.66268357e-02,\n",
       "                     -9.76384696e-02, -1.01782694e-01, -1.02654154e-01, -1.17783036e-01,\n",
       "                     -1.22602322e-01, -1.29534052e-01, -1.54150680e-01, -1.61268148e-01,\n",
       "                     -1.64303051e-01, -1.77681177e-01, -1.82321557e-01, -1.89242000e-01,\n",
       "                     -1.94156014e-01, -1.94705616e-01, -2.00670695e-01, -2.02524264e-01,\n",
       "                     -2.07639365e-01, -2.12991180e-01, -2.13574100e-01, -2.15111380e-01,\n",
       "                     -2.23143551e-01, -2.29574442e-01, -2.29788094e-01, -2.42561637e-01,\n",
       "                     -2.45122458e-01, -2.46860078e-01, -2.47408173e-01, -2.51314428e-01,\n",
       "                     -2.57829109e-01, -2.62364264e-01, -2.62989460e-01, -2.68263987e-01,\n",
       "                     -2.71933715e-01, -2.73695830e-01, -2.74436846e-01, -2.81851152e-01,\n",
       "                     -2.87682072e-01, -2.97251523e-01, -2.97632403e-01, -3.10154928e-01,\n",
       "                     -3.12374685e-01, -3.13657559e-01, -3.15852949e-01, -3.18453731e-01,\n",
       "                     -3.26455458e-01, -3.29957556e-01, -3.36472237e-01, -3.40325806e-01,\n",
       "                     -3.40926587e-01, -3.48306694e-01, -3.49673748e-01, -3.50202429e-01,\n",
       "                     -3.51397887e-01, -3.56674944e-01, -3.67724780e-01, -3.74693449e-01,\n",
       "                     -3.77630309e-01, -3.78066134e-01, -3.85662481e-01, -3.90866309e-01,\n",
       "                     -3.93741644e-01, -3.94654192e-01, -3.96415273e-01, -4.05465108e-01,\n",
       "                     -4.13562318e-01, -4.30782916e-01, -4.38254931e-01, -4.41832752e-01,\n",
       "                     -4.51985124e-01, -4.56758402e-01, -4.59532329e-01, -4.62623522e-01,\n",
       "                     -4.62922163e-01, -4.70003629e-01, -4.85507816e-01, -4.88352768e-01,\n",
       "                     -4.89548225e-01, -5.10825624e-01, -5.12765489e-01, -5.19600570e-01,\n",
       "                     -5.23248144e-01, -5.30628251e-01, -5.34082486e-01, -5.52068582e-01,\n",
       "                     -5.59615788e-01, -5.65633860e-01, -5.70544858e-01, -5.75364145e-01,\n",
       "                     -5.76422906e-01, -5.79818495e-01, -5.87786665e-01, -5.94707108e-01,\n",
       "                     -5.97837001e-01, -6.06135804e-01, -6.24154309e-01, -6.25705900e-01,\n",
       "                     -6.28608659e-01, -6.30233355e-01, -6.35988767e-01, -6.41853886e-01,\n",
       "                     -6.50587566e-01, -6.53926467e-01, -6.56242624e-01, -6.93147181e-01,\n",
       "                     -7.37598943e-01, -7.41937345e-01, -7.88457360e-01, -7.98507696e-01,\n",
       "                     -8.10930216e-01, -8.18310324e-01, -8.20980552e-01, -8.62223511e-01,\n",
       "                     -9.16290732e-01, -9.38269639e-01, -9.80829253e-01, -1.02961942e+00,\n",
       "                     -1.09861229e+00, -1.25276297e+00, -1.29928298e+00, -1.38629436e+00,\n",
       "                     -1.79175947e+00, -3.45387764e+01]), auc_score=0.5211738599991915, privacy_risk=0.5160850798983301, accuracy=0.5150409626216078, tpr_ind=0.7491320560627491, tnr_ind=0.28303810373391103, test_train_ratio=1.009000900090009, dataset_size=[7777, 7847]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.07219662, 0.0765489 , 0.08038914, 0.08179724,\n",
       "                     0.09600614, 0.09933436, 0.11008705, 0.11200717, 0.11571941,\n",
       "                     0.11815156, 0.11943164, 0.12071173, 0.1296723 , 0.1359447 ,\n",
       "                     0.13863287, 0.14132104, 0.14490527, 0.1483615 , 0.15296979,\n",
       "                     0.15642601, 0.16167435, 0.16487455, 0.18356375, 0.18420379,\n",
       "                     0.1921403 , 0.19866871, 0.21070148, 0.21428571, 0.24833589,\n",
       "                     0.2530722 , 0.25422427, 0.25665643, 0.25947261, 0.29595494,\n",
       "                     0.29941116, 0.30133129, 0.31195597, 0.31746032, 0.34318996,\n",
       "                     0.34511009, 0.3515105 , 0.35419867, 0.36187916, 0.37045571,\n",
       "                     0.38261649, 0.38568868, 0.39016897, 0.39772145, 0.39861751,\n",
       "                     0.40104967, 0.41551459, 0.4406042 , 0.44700461, 0.45058884,\n",
       "                     0.50576037, 0.53328213, 0.53584229, 0.53699437, 0.55120328,\n",
       "                     0.55773169, 0.56080389, 0.57462878, 0.58077317, 0.60650282,\n",
       "                     0.60765489, 0.61047107, 0.6171275 , 0.62647209, 0.63812084,\n",
       "                     0.64541731, 0.68509985, 0.68650794, 0.69495648, 0.72452637,\n",
       "                     0.72913466, 0.73220686, 0.73655914, 0.74270353, 0.75371224,\n",
       "                     0.76830517, 0.77278546, 0.77918587, 0.78046595, 0.79736303,\n",
       "                     0.7985151 , 0.80017921, 0.80837174, 0.81349206, 0.81784434,\n",
       "                     0.81989247, 0.82334869, 0.83947773, 0.84984639, 0.85125448,\n",
       "                     0.85637481, 0.86059908, 0.86303123, 0.86751152, 0.87096774,\n",
       "                     0.87570405, 0.88876088, 0.89144905, 0.90015361, 0.90207373,\n",
       "                     0.9030978 , 0.90745008, 0.91039427, 0.9141065 , 0.91705069,\n",
       "                     0.91922683, 0.92076293, 0.94508449, 0.94866871, 0.9500768 ,\n",
       "                     0.95558116, 0.95673323, 0.95737327, 0.95929339, 0.96338966,\n",
       "                     0.9672299 , 0.96915003, 0.97158218, 0.97311828, 0.97401434,\n",
       "                     0.97567844, 0.97747056, 0.97759857, 0.97772657, 0.98015873,\n",
       "                     0.98207885, 0.98527906, 0.98668715, 0.98783922, 0.98835125,\n",
       "                     0.98950333, 0.99014337, 0.99180748, 0.99321557, 0.99359959,\n",
       "                     0.99423963, 1.        ]), tpr=array([0.        , 0.08499744, 0.0890937 , 0.09293395, 0.09664619,\n",
       "                     0.10867896, 0.11149514, 0.12275986, 0.124936  , 0.1281362 ,\n",
       "                     0.1296723 , 0.13108039, 0.13236047, 0.140553  , 0.14746544,\n",
       "                     0.15028162, 0.1547619 , 0.15911418, 0.16154634, 0.1671787 ,\n",
       "                     0.171915  , 0.1781874 , 0.1797235 , 0.19598054, 0.19738863,\n",
       "                     0.20545315, 0.2124936 , 0.22542243, 0.22887865, 0.26241679,\n",
       "                     0.27060932, 0.27278546, 0.27700973, 0.27956989, 0.31579621,\n",
       "                     0.32002048, 0.3218126 , 0.33141321, 0.33832565, 0.36584741,\n",
       "                     0.36840758, 0.37416795, 0.3766001 , 0.38466462, 0.39183308,\n",
       "                     0.40373784, 0.40668203, 0.41065028, 0.41769073, 0.42012289,\n",
       "                     0.42217102, 0.4390681 , 0.46479775, 0.47043011, 0.4733743 ,\n",
       "                     0.52675371, 0.55401946, 0.55657962, 0.55811572, 0.57155658,\n",
       "                     0.57757296, 0.58115719, 0.59856631, 0.60458269, 0.63261649,\n",
       "                     0.63402458, 0.6359447 , 0.64157706, 0.65296979, 0.66602663,\n",
       "                     0.67268305, 0.7124936 , 0.71441372, 0.72273425, 0.75371224,\n",
       "                     0.75768049, 0.75998464, 0.76548899, 0.76984127, 0.78008193,\n",
       "                     0.79595494, 0.79979519, 0.80529954, 0.80747568, 0.82795699,\n",
       "                     0.82923707, 0.83154122, 0.83819764, 0.84126984, 0.84472606,\n",
       "                     0.84613415, 0.8515105 , 0.86623144, 0.88031234, 0.88146441,\n",
       "                     0.88658474, 0.89016897, 0.89260113, 0.89695341, 0.9000256 ,\n",
       "                     0.9046339 , 0.91653866, 0.91845878, 0.92793139, 0.93010753,\n",
       "                     0.93087558, 0.93497184, 0.93663594, 0.94111623, 0.94303635,\n",
       "                     0.94508449, 0.94649258, 0.96441372, 0.96761393, 0.96940604,\n",
       "                     0.97260625, 0.97401434, 0.97491039, 0.97721454, 0.98105479,\n",
       "                     0.98361495, 0.98540707, 0.98694316, 0.98809524, 0.98860727,\n",
       "                     0.98975934, 0.9906554 , 0.99129544, 0.99206349, 0.99308756,\n",
       "                     0.99436764, 0.99667179, 0.99731183, 0.99769585, 0.99795187,\n",
       "                     0.9984639 , 0.99871992, 0.99935996, 0.99974398, 0.99987199,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.07716587e-02, -3.27898228e-02,\n",
       "                     -3.39015517e-02, -4.16726964e-02, -4.44517626e-02, -5.52626787e-02,\n",
       "                     -5.71584138e-02, -7.69610411e-02, -8.00427077e-02, -8.70113770e-02,\n",
       "                     -9.53101798e-02, -1.17783036e-01, -1.21889818e-01, -1.27833372e-01,\n",
       "                     -1.33531393e-01, -1.37201122e-01, -1.46603474e-01, -1.47635999e-01,\n",
       "                     -1.50282203e-01, -1.51230970e-01, -1.54150680e-01, -1.59759219e-01,\n",
       "                     -1.67054085e-01, -1.74353387e-01, -1.82321557e-01, -1.97063839e-01,\n",
       "                     -2.00670695e-01, -2.06207042e-01, -2.10564769e-01, -2.11309094e-01,\n",
       "                     -2.17064505e-01, -2.23143551e-01, -2.26670892e-01, -2.41162057e-01,\n",
       "                     -2.51314428e-01, -2.57222865e-01, -2.59511195e-01, -2.60573754e-01,\n",
       "                     -2.62364264e-01, -2.70874954e-01, -2.74436846e-01, -2.75705881e-01,\n",
       "                     -2.78713402e-01, -2.87682072e-01, -2.98492989e-01, -3.03682414e-01,\n",
       "                     -3.10154928e-01, -3.13657559e-01, -3.18453731e-01, -3.21204764e-01,\n",
       "                     -3.24316206e-01, -3.26684230e-01, -3.30241687e-01, -3.31664535e-01,\n",
       "                     -3.35801321e-01, -3.36472237e-01, -3.48306694e-01, -3.49985956e-01,\n",
       "                     -3.54545018e-01, -3.56674944e-01, -3.65459773e-01, -3.69360103e-01,\n",
       "                     -3.69830044e-01, -3.74693449e-01, -3.82992252e-01, -3.90197636e-01,\n",
       "                     -4.01712758e-01, -4.05465108e-01, -4.18204134e-01, -4.19302476e-01,\n",
       "                     -4.27444015e-01, -4.30782916e-01, -4.35318071e-01, -4.37213806e-01,\n",
       "                     -4.41832752e-01, -4.43492504e-01, -4.43931389e-01, -4.46287103e-01,\n",
       "                     -4.47576593e-01, -4.48950220e-01, -4.58307589e-01, -4.62623522e-01,\n",
       "                     -4.66089730e-01, -4.70003629e-01, -4.76924072e-01, -4.79573080e-01,\n",
       "                     -4.85507816e-01, -4.88352768e-01, -4.92476485e-01, -4.96436886e-01,\n",
       "                     -5.07341300e-01, -5.09005787e-01, -5.10825624e-01, -5.15813165e-01,\n",
       "                     -5.17943092e-01, -5.21296924e-01, -5.34082486e-01, -5.59615788e-01,\n",
       "                     -5.75364145e-01, -5.79388295e-01, -5.87786665e-01, -5.93774707e-01,\n",
       "                     -6.00773860e-01, -6.06135804e-01, -6.11801541e-01, -6.13104473e-01,\n",
       "                     -6.19039208e-01, -6.24154309e-01, -6.28608659e-01, -6.46627165e-01,\n",
       "                     -6.93147181e-01, -7.12949808e-01, -7.28238500e-01, -7.32367894e-01,\n",
       "                     -7.37598943e-01, -7.62140052e-01, -7.73189888e-01, -7.88457360e-01,\n",
       "                     -8.10930216e-01, -8.26678573e-01, -8.47297860e-01, -8.93817876e-01,\n",
       "                     -9.16290732e-01, -9.38269639e-01, -9.44461609e-01, -9.55511445e-01,\n",
       "                     -9.80829253e-01, -1.01160091e+00, -1.06471074e+00, -1.09861229e+00,\n",
       "                     -1.16315081e+00, -1.20397280e+00, -1.25276297e+00, -1.32175584e+00,\n",
       "                     -1.38629436e+00, -1.60943791e+00, -1.67397643e+00, -1.79175947e+00,\n",
       "                     -1.94591015e+00, -3.45387764e+01]), auc_score=0.5206435167815923, privacy_risk=0.5156810035842294, accuracy=0.5156810035842294, tpr_ind=0.8315412186379928, tnr_ind=0.19982078853046595, test_train_ratio=1.0, dataset_size=[7812, 7812]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.06188467, 0.07300857, 0.07428718, 0.07646081,\n",
       "                     0.1215957 , 0.12555939, 0.12850019, 0.12939522, 0.13092955,\n",
       "                     0.13284746, 0.13438179, 0.14307633, 0.14435494, 0.15778033,\n",
       "                     0.15995397, 0.17516942, 0.17862166, 0.18117888, 0.1814346 ,\n",
       "                     0.18616545, 0.19166347, 0.19677791, 0.2013809 , 0.20956399,\n",
       "                     0.22477944, 0.24741082, 0.25393172, 0.25533819, 0.26965861,\n",
       "                     0.28154967, 0.2847462 , 0.29292929, 0.29433576, 0.32604526,\n",
       "                     0.32681243, 0.33077612, 0.33384478, 0.33652986, 0.34931594,\n",
       "                     0.35315177, 0.35545327, 0.35954482, 0.36721647, 0.39342795,\n",
       "                     0.40071602, 0.41004987, 0.4174658 , 0.42130162, 0.4321698 ,\n",
       "                     0.43920215, 0.44124792, 0.44470017, 0.44712952, 0.52538039,\n",
       "                     0.53151771, 0.5361207 , 0.54072369, 0.54468738, 0.55184759,\n",
       "                     0.55747347, 0.56655159, 0.59327452, 0.60005114, 0.60222478,\n",
       "                     0.60567702, 0.61002429, 0.62038103, 0.62626263, 0.6394323 ,\n",
       "                     0.64250096, 0.65451988, 0.6570771 , 0.66641094, 0.67446618,\n",
       "                     0.69096024, 0.70911648, 0.72688914, 0.72752845, 0.74069812,\n",
       "                     0.74236031, 0.74900908, 0.75271704, 0.76946682, 0.77253548,\n",
       "                     0.77816136, 0.78263649, 0.78647232, 0.78902954, 0.79427183,\n",
       "                     0.80130418, 0.80526787, 0.81882112, 0.82713208, 0.83007288,\n",
       "                     0.83659379, 0.83787239, 0.84324255, 0.84541619, 0.8502749 ,\n",
       "                     0.85142565, 0.85449431, 0.8643396 , 0.86510676, 0.86779184,\n",
       "                     0.87891574, 0.88594809, 0.88709884, 0.89707199, 0.90167498,\n",
       "                     0.90512722, 0.90934663, 0.91228743, 0.91394962, 0.91944764,\n",
       "                     0.92788646, 0.93709244, 0.94118399, 0.94322977, 0.94975067,\n",
       "                     0.95013425, 0.9535865 , 0.95818949, 0.96138601, 0.96522184,\n",
       "                     0.96956911, 0.9712313 , 0.97225419, 0.97545071, 0.97621787,\n",
       "                     0.97800793, 0.97890295, 0.97915868, 0.98043728, 0.98107659,\n",
       "                     0.98606316, 0.98810894, 0.98862038, 0.9888761 , 0.98938755,\n",
       "                     0.99066616, 0.9918169 , 0.99322337, 0.99360696, 0.99386268,\n",
       "                     1.        ]), tpr=array([0.        , 0.07010124, 0.07817506, 0.08061002, 0.08278867,\n",
       "                     0.12789953, 0.13148789, 0.13481994, 0.13751121, 0.13981802,\n",
       "                     0.14417532, 0.14622581, 0.15686275, 0.15878508, 0.17198513,\n",
       "                     0.1755735 , 0.19505318, 0.19838524, 0.2008202 , 0.20158913,\n",
       "                     0.20684352, 0.21350763, 0.21786492, 0.2217096 , 0.22798923,\n",
       "                     0.24567474, 0.26694861, 0.27310009, 0.27527874, 0.28681276,\n",
       "                     0.30116622, 0.3061643 , 0.31346918, 0.31487889, 0.34320133,\n",
       "                     0.34499551, 0.3502499 , 0.35371011, 0.35499167, 0.36806357,\n",
       "                     0.37267718, 0.37472767, 0.37716263, 0.38485198, 0.40779187,\n",
       "                     0.41522491, 0.4280405 , 0.43496091, 0.4413687 , 0.45174933,\n",
       "                     0.46200179, 0.46341151, 0.46584647, 0.46930668, 0.54786621,\n",
       "                     0.55337691, 0.55850314, 0.56350122, 0.56811483, 0.57772652,\n",
       "                     0.58310906, 0.59195181, 0.6180956 , 0.62386262, 0.62719467,\n",
       "                     0.63257721, 0.63603742, 0.64436755, 0.65282584, 0.66538511,\n",
       "                     0.66782007, 0.68191721, 0.68435217, 0.69498911, 0.70485711,\n",
       "                     0.72010765, 0.7388184 , 0.75688838, 0.75804178, 0.77290786,\n",
       "                     0.77495835, 0.78303217, 0.78764578, 0.80110214, 0.80443419,\n",
       "                     0.80815071, 0.8122517 , 0.81712162, 0.8209663 , 0.826477  ,\n",
       "                     0.83352557, 0.83801102, 0.84903242, 0.85672177, 0.8595412 ,\n",
       "                     0.86530821, 0.86697424, 0.87081892, 0.87389466, 0.87748302,\n",
       "                     0.87978982, 0.88171216, 0.88940151, 0.89055491, 0.89375881,\n",
       "                     0.90324234, 0.91016276, 0.91182878, 0.92067154, 0.92605408,\n",
       "                     0.92912982, 0.93156478, 0.93438421, 0.93592208, 0.93976676,\n",
       "                     0.94822504, 0.95681148, 0.96129694, 0.9625785 , 0.96821735,\n",
       "                     0.96911444, 0.97142125, 0.9759067 , 0.9779572 , 0.98064847,\n",
       "                     0.98372421, 0.98564655, 0.98654364, 0.98820966, 0.9889786 ,\n",
       "                     0.99038831, 0.9912854 , 0.99166987, 0.99295143, 0.99384852,\n",
       "                     0.99589901, 0.99692426, 0.99718057, 0.99782135, 0.99820582,\n",
       "                     0.99897475, 0.99935922, 0.99974369, 0.99987184, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.65200156e-02, -5.12932944e-02,\n",
       "                     -5.71584138e-02, -6.06246218e-02, -6.89928715e-02, -7.41079722e-02,\n",
       "                     -9.09717782e-02, -1.05360516e-01, -1.11225635e-01, -1.17783036e-01,\n",
       "                     -1.24454174e-01, -1.25163143e-01, -1.27444947e-01, -1.33531393e-01,\n",
       "                     -1.40905453e-01, -1.43100844e-01, -1.46603474e-01, -1.54150680e-01,\n",
       "                     -1.57628944e-01, -1.59630146e-01, -1.62518929e-01, -1.82321557e-01,\n",
       "                     -1.85717146e-01, -1.90740127e-01, -2.06132205e-01, -2.06336433e-01,\n",
       "                     -2.11309094e-01, -2.18689201e-01, -2.23143551e-01, -2.28258652e-01,\n",
       "                     -2.33614851e-01, -2.41162057e-01, -2.47284196e-01, -2.51314428e-01,\n",
       "                     -2.56719847e-01, -2.59511195e-01, -2.62364264e-01, -2.65376315e-01,\n",
       "                     -2.66628663e-01, -2.71933715e-01, -2.74436846e-01, -2.75103290e-01,\n",
       "                     -2.76445999e-01, -2.83362411e-01, -2.85178942e-01, -2.87682072e-01,\n",
       "                     -2.92669614e-01, -3.06031211e-01, -3.09321248e-01, -3.10154928e-01,\n",
       "                     -3.13657559e-01, -3.15081047e-01, -3.16226724e-01, -3.16337328e-01,\n",
       "                     -3.18453731e-01, -3.25422400e-01, -3.28504067e-01, -3.36472237e-01,\n",
       "                     -3.39867826e-01, -3.40604474e-01, -3.48306694e-01, -3.52220594e-01,\n",
       "                     -3.52821375e-01, -3.56674944e-01, -3.67724780e-01, -3.68907512e-01,\n",
       "                     -3.74693449e-01, -3.84845821e-01, -3.87765531e-01, -4.05465108e-01,\n",
       "                     -4.22856851e-01, -4.25346479e-01, -4.26879203e-01, -4.30362660e-01,\n",
       "                     -4.36928378e-01, -4.40311839e-01, -4.41832752e-01, -4.44906840e-01,\n",
       "                     -4.46287103e-01, -4.51985124e-01, -4.59532329e-01, -4.70003629e-01,\n",
       "                     -4.79573080e-01, -4.82851772e-01, -4.85507816e-01, -4.89548225e-01,\n",
       "                     -4.90622916e-01, -5.01479761e-01, -5.03526321e-01, -5.05094949e-01,\n",
       "                     -5.08497334e-01, -5.10825624e-01, -5.19875459e-01, -5.24070851e-01,\n",
       "                     -5.26093096e-01, -5.30628251e-01, -5.35518236e-01, -5.38996501e-01,\n",
       "                     -5.43615447e-01, -5.50046337e-01, -5.59615788e-01, -5.75364145e-01,\n",
       "                     -5.87786665e-01, -5.93774707e-01, -6.06135804e-01, -6.13104473e-01,\n",
       "                     -6.17923759e-01, -6.19039208e-01, -6.28608659e-01, -6.39079959e-01,\n",
       "                     -6.46627165e-01, -6.50587566e-01, -6.59245629e-01, -6.93147181e-01,\n",
       "                     -7.00582159e-01, -7.07331816e-01, -7.41937345e-01, -7.48409859e-01,\n",
       "                     -7.62140052e-01, -7.73189888e-01, -7.88457360e-01, -8.10930216e-01,\n",
       "                     -8.47297860e-01, -8.64997437e-01, -8.75468737e-01, -8.87303195e-01,\n",
       "                     -9.00786545e-01, -9.16290732e-01, -9.34309237e-01, -9.44461609e-01,\n",
       "                     -9.80829253e-01, -9.93251773e-01, -9.98528830e-01, -1.07755888e+00,\n",
       "                     -1.09861229e+00, -1.25276297e+00, -1.28093385e+00, -1.29928298e+00,\n",
       "                     -1.38629436e+00, -1.54044504e+00, -1.60943791e+00, -1.94591015e+00,\n",
       "                     -2.39789527e+00, -3.45387764e+01]), auc_score=0.5203737795024496, privacy_risk=0.517464366704435, accuracy=0.5171530977982591, tpr_ind=0.7876457772651544, tnr_ind=0.24728295614371565, test_train_ratio=1.0023068050749713, dataset_size=[7803, 7821]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.08384537, 0.09011777, 0.09549411, 0.09946237,\n",
       "                     0.10048643, 0.10483871, 0.10816692, 0.11891961, 0.12122376,\n",
       "                     0.12634409, 0.12685612, 0.12864823, 0.13031234, 0.13402458,\n",
       "                     0.13735279, 0.13940092, 0.14183308, 0.1656426 , 0.16756272,\n",
       "                     0.17281106, 0.17626728, 0.19431644, 0.19918075, 0.20174091,\n",
       "                     0.21761393, 0.22875064, 0.2296467 , 0.2313108 , 0.23822325,\n",
       "                     0.23860727, 0.24513569, 0.24807988, 0.2515361 , 0.25998464,\n",
       "                     0.26152074, 0.26574501, 0.28225806, 0.28955453, 0.2905786 ,\n",
       "                     0.31746032, 0.31899642, 0.3672555 , 0.36968766, 0.37775218,\n",
       "                     0.38428059, 0.38620072, 0.41986687, 0.43023554, 0.44201229,\n",
       "                     0.45199693, 0.45404506, 0.47452637, 0.4765745 , 0.48220686,\n",
       "                     0.48553507, 0.49347158, 0.49782386, 0.49910394, 0.52060932,\n",
       "                     0.52560164, 0.5281618 , 0.52867384, 0.55747568, 0.56221198,\n",
       "                     0.56310804, 0.58461342, 0.59165387, 0.59741423, 0.6031746 ,\n",
       "                     0.60765489, 0.61431132, 0.62071173, 0.62800819, 0.68036354,\n",
       "                     0.69150026, 0.69406042, 0.69777266, 0.69828469, 0.70046083,\n",
       "                     0.70481311, 0.71134153, 0.73182284, 0.73502304, 0.74654378,\n",
       "                     0.74807988, 0.75345622, 0.76228879, 0.77112135, 0.81080389,\n",
       "                     0.81374808, 0.81912442, 0.82616487, 0.83000512, 0.83154122,\n",
       "                     0.84331797, 0.84498208, 0.84703021, 0.85061444, 0.85663082,\n",
       "                     0.87263185, 0.87391193, 0.87711214, 0.87800819, 0.8812084 ,\n",
       "                     0.88325653, 0.88607271, 0.89336918, 0.89439324, 0.89631336,\n",
       "                     0.89900154, 0.90911418, 0.91346646, 0.91973886, 0.94111623,\n",
       "                     0.94290835, 0.94662058, 0.94828469, 0.94943676, 0.95199693,\n",
       "                     0.95570917, 0.95852535, 0.96582181, 0.968766  , 0.96927803,\n",
       "                     0.97081413, 0.97247824, 0.97363031, 0.97427035, 0.97593446,\n",
       "                     0.9765745 , 0.97836662, 0.97875064, 0.98425499, 0.98643113,\n",
       "                     0.98694316, 0.9874552 , 0.98860727, 0.98873528, 0.99027138,\n",
       "                     1.        ]), tpr=array([0.        , 0.10087046, 0.10535074, 0.11213518, 0.11431132,\n",
       "                     0.11623144, 0.11930364, 0.12224782, 0.13376856, 0.13658474,\n",
       "                     0.14477727, 0.14605735, 0.1484895 , 0.15194572, 0.156298  ,\n",
       "                     0.1593702 , 0.16231439, 0.16615463, 0.18766001, 0.1906042 ,\n",
       "                     0.19482847, 0.19828469, 0.21838198, 0.22363031, 0.22683052,\n",
       "                     0.24449565, 0.25806452, 0.25921659, 0.26203277, 0.26766513,\n",
       "                     0.27009729, 0.27726575, 0.28059396, 0.28481823, 0.29275474,\n",
       "                     0.29595494, 0.3000512 , 0.31374808, 0.32245264, 0.32373272,\n",
       "                     0.34882232, 0.35087046, 0.40040963, 0.40284178, 0.41154634,\n",
       "                     0.41807476, 0.42140297, 0.45903738, 0.46940604, 0.48220686,\n",
       "                     0.49001536, 0.49142345, 0.51420891, 0.51625704, 0.5218894 ,\n",
       "                     0.52508961, 0.5343062 , 0.53840246, 0.5405786 , 0.56221198,\n",
       "                     0.56682028, 0.56925243, 0.57014849, 0.59741423, 0.60138249,\n",
       "                     0.60279058, 0.62557604, 0.63389657, 0.63799283, 0.64439324,\n",
       "                     0.64989759, 0.65681004, 0.66487455, 0.67281106, 0.72286226,\n",
       "                     0.73259089, 0.7359191 , 0.7389913 , 0.74039939, 0.74295955,\n",
       "                     0.74667179, 0.75358423, 0.77291347, 0.7764977 , 0.78865847,\n",
       "                     0.79019457, 0.79659498, 0.80581157, 0.81374808, 0.85266257,\n",
       "                     0.85573477, 0.85970302, 0.86661546, 0.87019969, 0.8718638 ,\n",
       "                     0.8827445 , 0.88402458, 0.88684076, 0.89272913, 0.89631336,\n",
       "                     0.90949821, 0.91129032, 0.91372248, 0.91436252, 0.91641065,\n",
       "                     0.91781874, 0.91858679, 0.92332309, 0.92421915, 0.92537122,\n",
       "                     0.92780338, 0.93676395, 0.94124424, 0.94662058, 0.96338966,\n",
       "                     0.96582181, 0.97196621, 0.9735023 , 0.97491039, 0.97593446,\n",
       "                     0.97875064, 0.98105479, 0.98489503, 0.98655914, 0.98707117,\n",
       "                     0.98783922, 0.98924731, 0.99014337, 0.9906554 , 0.99180748,\n",
       "                     0.99257552, 0.99347158, 0.99449565, 0.99756784, 0.99859191,\n",
       "                     0.99884793, 0.99923195, 0.99961598, 0.99974398, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.81708770e-02, -3.70412717e-02,\n",
       "                     -5.71584138e-02, -6.45385211e-02, -8.00427077e-02, -8.33816089e-02,\n",
       "                     -8.51578083e-02, -8.70113770e-02, -8.96121587e-02, -9.53101798e-02,\n",
       "                     -1.00083459e-01, -1.05360516e-01, -1.11225635e-01, -1.17783036e-01,\n",
       "                     -1.22602322e-01, -1.54150680e-01, -1.59239749e-01, -1.60342650e-01,\n",
       "                     -1.67054085e-01, -1.69899037e-01, -1.74862812e-01, -1.78248231e-01,\n",
       "                     -1.82321557e-01, -1.84734103e-01, -1.88591170e-01, -2.00670695e-01,\n",
       "                     -2.04794413e-01, -2.23143551e-01, -2.33614851e-01, -2.37328186e-01,\n",
       "                     -2.38411023e-01, -2.41162057e-01, -2.42313467e-01, -2.46860078e-01,\n",
       "                     -2.47836164e-01, -2.54424851e-01, -2.57829109e-01, -2.62364264e-01,\n",
       "                     -2.63148886e-01, -2.71933715e-01, -2.72056755e-01, -2.74436846e-01,\n",
       "                     -2.80301965e-01, -2.87682072e-01, -2.97251523e-01, -2.97834444e-01,\n",
       "                     -3.06031211e-01, -3.07484700e-01, -3.07966744e-01, -3.10154928e-01,\n",
       "                     -3.11277893e-01, -3.18453731e-01, -3.26684230e-01, -3.36472237e-01,\n",
       "                     -3.38454398e-01, -3.40926587e-01, -3.44840486e-01, -3.46564837e-01,\n",
       "                     -3.48306694e-01, -3.51397887e-01, -3.56674944e-01, -3.72049111e-01,\n",
       "                     -3.72675285e-01, -3.74693449e-01, -3.75044511e-01, -3.79489622e-01,\n",
       "                     -3.84411699e-01, -3.92042088e-01, -3.97682968e-01, -4.05465108e-01,\n",
       "                     -4.10742165e-01, -4.16160397e-01, -4.19853846e-01, -4.22856851e-01,\n",
       "                     -4.30782916e-01, -4.32864082e-01, -4.35318071e-01, -4.38254931e-01,\n",
       "                     -4.39366660e-01, -4.41832752e-01, -4.42305677e-01, -4.51985124e-01,\n",
       "                     -4.56758402e-01, -4.59532329e-01, -4.70003629e-01, -4.76924072e-01,\n",
       "                     -4.78035801e-01, -4.81451015e-01, -4.85507816e-01, -4.97838428e-01,\n",
       "                     -5.10825624e-01, -5.17943092e-01, -5.26093096e-01, -5.27162043e-01,\n",
       "                     -5.30628251e-01, -5.46543706e-01, -5.53385238e-01, -5.59615788e-01,\n",
       "                     -5.74757165e-01, -5.79818495e-01, -5.81921545e-01, -5.87786665e-01,\n",
       "                     -5.94707108e-01, -5.97837001e-01, -6.06135804e-01, -6.08589793e-01,\n",
       "                     -6.19039208e-01, -6.35988767e-01, -6.39079959e-01, -6.41853886e-01,\n",
       "                     -6.49344558e-01, -6.81170990e-01, -6.93147181e-01, -7.19122667e-01,\n",
       "                     -7.23918839e-01, -7.33969175e-01, -7.37598943e-01, -7.53771802e-01,\n",
       "                     -7.59105148e-01, -7.73189888e-01, -7.88457360e-01, -8.02346473e-01,\n",
       "                     -8.10930216e-01, -8.47297860e-01, -8.60201265e-01, -8.87303195e-01,\n",
       "                     -9.16290732e-01, -9.38269639e-01, -9.80829253e-01, -9.98528830e-01,\n",
       "                     -1.01160091e+00, -1.09861229e+00, -1.25276297e+00, -1.38629436e+00,\n",
       "                     -1.46633707e+00, -1.60943791e+00, -1.79175947e+00, -2.56494936e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5318458148858649, privacy_risk=0.5224014336917563, accuracy=0.5224014336917563, tpr_ind=0.6728110599078341, tnr_ind=0.37199180747567845, test_train_ratio=1.0, dataset_size=[7812, 7812]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.08234695, 0.08794705, 0.09469263, 0.09863816,\n",
       "                     0.11302024, 0.11658394, 0.11900216, 0.12676594, 0.12905689,\n",
       "                     0.13198422, 0.13452972, 0.13580247, 0.14114802, 0.14980272,\n",
       "                     0.15273005, 0.15527555, 0.17054856, 0.17462136, 0.17665776,\n",
       "                     0.17958508, 0.18505791, 0.18683976, 0.19727631, 0.21789487,\n",
       "                     0.22311315, 0.24793178, 0.24844088, 0.25124093, 0.25455008,\n",
       "                     0.26282296, 0.26804124, 0.26880489, 0.27771414, 0.28955072,\n",
       "                     0.30253277, 0.30927835, 0.31373298, 0.32047855, 0.34376989,\n",
       "                     0.34618811, 0.35497009, 0.36082474, 0.36986127, 0.3916253 ,\n",
       "                     0.39442535, 0.40651648, 0.41338933, 0.42064401, 0.42178949,\n",
       "                     0.42624411, 0.45399007, 0.4558992 , 0.47002673, 0.48020873,\n",
       "                     0.51584574, 0.51699122, 0.52259132, 0.52717322, 0.53226422,\n",
       "                     0.5339188 , 0.5456281 , 0.56128293, 0.56777396, 0.59081074,\n",
       "                     0.59221077, 0.59895634, 0.60010182, 0.61410207, 0.61792033,\n",
       "                     0.61995673, 0.62759323, 0.63841161, 0.64324806, 0.64770269,\n",
       "                     0.64961181, 0.67468499, 0.67633957, 0.69237623, 0.69479445,\n",
       "                     0.6965763 , 0.69873998, 0.72343134, 0.73119511, 0.74175894,\n",
       "                     0.74354079, 0.74863179, 0.75041364, 0.75741377, 0.76072292,\n",
       "                     0.76683212, 0.7761232 , 0.78286878, 0.78388698, 0.81366934,\n",
       "                     0.81621484, 0.82550592, 0.83645157, 0.8388698 , 0.8571974 ,\n",
       "                     0.86534301, 0.86699758, 0.86903398, 0.87590683, 0.87717959,\n",
       "                     0.88036146, 0.88990709, 0.89372534, 0.89639812, 0.90327097,\n",
       "                     0.90492554, 0.90556192, 0.91192567, 0.91981672, 0.92325315,\n",
       "                     0.92528955, 0.93127148, 0.93407153, 0.935217  , 0.93610793,\n",
       "                     0.94348988, 0.94488991, 0.94781723, 0.95227186, 0.95545374,\n",
       "                     0.95647194, 0.95812651, 0.96003564, 0.96041746, 0.96258114,\n",
       "                     0.96461754, 0.96525391, 0.96652666, 0.96754486, 0.96843579,\n",
       "                     0.96919944, 0.97072674, 0.97518137, 0.97683594, 0.97849052,\n",
       "                     0.98052692, 0.98243604, 0.98281787, 0.98485427, 0.98650885,\n",
       "                     0.98689067, 0.98803615, 1.        ]), tpr=array([0.        , 0.08806489, 0.09501738, 0.10003862, 0.10673362,\n",
       "                     0.12153985, 0.12656109, 0.13080984, 0.13879233, 0.14136732,\n",
       "                     0.14381357, 0.14613107, 0.14831981, 0.1565598 , 0.1632548 ,\n",
       "                     0.16608729, 0.16776104, 0.18424102, 0.18900476, 0.19209476,\n",
       "                     0.19582851, 0.20084975, 0.20342475, 0.21295223, 0.23136346,\n",
       "                     0.23728595, 0.26213467, 0.26329342, 0.26496717, 0.26870091,\n",
       "                     0.27861465, 0.28324965, 0.28518089, 0.29354963, 0.30616712,\n",
       "                     0.32097335, 0.32856959, 0.33384833, 0.33989958, 0.36642204,\n",
       "                     0.36886829, 0.37697953, 0.38328827, 0.39101326, 0.41328698,\n",
       "                     0.41624823, 0.42732072, 0.43646195, 0.4422557 , 0.44405819,\n",
       "                     0.44869319, 0.4766319 , 0.4797219 , 0.49478563, 0.50392687,\n",
       "                     0.54177932, 0.54306682, 0.55182181, 0.55710055, 0.56173555,\n",
       "                     0.56353805, 0.57718553, 0.58954551, 0.59714175, 0.62327797,\n",
       "                     0.62469422, 0.62920046, 0.63087421, 0.6406592 , 0.64413544,\n",
       "                     0.64786919, 0.65662418, 0.66731042, 0.67233166, 0.6765804 ,\n",
       "                     0.67928415, 0.70748037, 0.70915411, 0.72576284, 0.72808034,\n",
       "                     0.73104159, 0.73374533, 0.75511781, 0.76619029, 0.77391528,\n",
       "                     0.77610403, 0.78176902, 0.78370027, 0.78962276, 0.79361401,\n",
       "                     0.799279  , 0.81060899, 0.81653148, 0.81794773, 0.84936269,\n",
       "                     0.85193769, 0.86004892, 0.87060641, 0.87228016, 0.88914639,\n",
       "                     0.89481138, 0.89712888, 0.89957513, 0.90665637, 0.90768637,\n",
       "                     0.91116261, 0.92030385, 0.92455259, 0.92622634, 0.93343633,\n",
       "                     0.93549633, 0.93665508, 0.94283507, 0.94965881, 0.95146131,\n",
       "                     0.95352131, 0.9594438 , 0.9615038 , 0.96317755, 0.96446504,\n",
       "                     0.97180379, 0.97296253, 0.97489378, 0.97837003, 0.98068752,\n",
       "                     0.98133127, 0.98249002, 0.98442127, 0.98532252, 0.98661002,\n",
       "                     0.98776877, 0.98867001, 0.98931376, 0.98970001, 0.99047251,\n",
       "                     0.99150251, 0.99266126, 0.99523626, 0.99626625, 0.99703875,\n",
       "                     0.99781125, 0.9981975 , 0.9987125 , 0.9992275 , 0.99961375,\n",
       "                     0.9997425 , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.83491387e-02, -2.53178080e-02,\n",
       "                     -5.60894667e-02, -6.72522270e-02, -7.41079722e-02, -8.70113770e-02,\n",
       "                     -9.23733201e-02, -9.53101798e-02, -1.00083459e-01, -1.05360516e-01,\n",
       "                     -1.11225635e-01, -1.17783036e-01, -1.26293725e-01, -1.27833372e-01,\n",
       "                     -1.43100844e-01, -1.45182010e-01, -1.50282203e-01, -1.54150680e-01,\n",
       "                     -1.59064695e-01, -1.65079750e-01, -1.82321557e-01, -1.84571277e-01,\n",
       "                     -1.96210669e-01, -1.96710294e-01, -1.96895325e-01, -2.00670695e-01,\n",
       "                     -2.07639365e-01, -2.16223108e-01, -2.20542770e-01, -2.23143551e-01,\n",
       "                     -2.36388778e-01, -2.44453338e-01, -2.51314428e-01, -2.52280145e-01,\n",
       "                     -2.53195896e-01, -2.56719847e-01, -2.60726262e-01, -2.70545790e-01,\n",
       "                     -2.74436846e-01, -2.75705881e-01, -2.82566972e-01, -2.87682072e-01,\n",
       "                     -2.93445777e-01, -2.98492989e-01, -2.99242895e-01, -3.01668314e-01,\n",
       "                     -3.04211374e-01, -3.05381650e-01, -3.08301360e-01, -3.10462101e-01,\n",
       "                     -3.18453731e-01, -3.19230430e-01, -3.22287602e-01, -3.32577392e-01,\n",
       "                     -3.36472237e-01, -3.44840486e-01, -3.46870944e-01, -3.48306694e-01,\n",
       "                     -3.56674944e-01, -3.60441427e-01, -3.62905494e-01, -3.65113813e-01,\n",
       "                     -3.73769377e-01, -3.74693449e-01, -3.76477571e-01, -3.79489622e-01,\n",
       "                     -3.87765531e-01, -3.93042588e-01, -3.93904286e-01, -4.05465108e-01,\n",
       "                     -4.09473130e-01, -4.13975798e-01, -4.15515444e-01, -4.21213465e-01,\n",
       "                     -4.25058802e-01, -4.30782916e-01, -4.33492420e-01, -4.41832752e-01,\n",
       "                     -4.48024723e-01, -4.51985124e-01, -4.52532619e-01, -4.58307589e-01,\n",
       "                     -4.59532329e-01, -4.62623522e-01, -4.64305608e-01, -4.70003629e-01,\n",
       "                     -4.75423697e-01, -4.78035801e-01, -4.78490243e-01, -4.85507816e-01,\n",
       "                     -4.88846717e-01, -4.92476485e-01, -4.94296322e-01, -5.00775288e-01,\n",
       "                     -5.10825624e-01, -5.13261679e-01, -5.26093096e-01, -5.31974448e-01,\n",
       "                     -5.33298480e-01, -5.43615447e-01, -5.52068582e-01, -5.57015006e-01,\n",
       "                     -5.59615788e-01, -5.75364145e-01, -5.81507209e-01, -5.97837001e-01,\n",
       "                     -6.13104473e-01, -6.19039208e-01, -6.28608659e-01, -6.35988767e-01,\n",
       "                     -6.39658496e-01, -6.44828603e-01, -6.56779536e-01, -6.61398482e-01,\n",
       "                     -6.93147181e-01, -7.23918839e-01, -7.30887509e-01, -7.41937345e-01,\n",
       "                     -7.44440475e-01, -7.47214402e-01, -7.57685702e-01, -7.64606145e-01,\n",
       "                     -7.73189888e-01, -7.88457360e-01, -8.47297860e-01, -8.75468737e-01,\n",
       "                     -8.87303195e-01, -9.16290732e-01, -9.38269639e-01, -9.44461609e-01,\n",
       "                     -9.55511445e-01, -9.80829253e-01, -1.04145387e+00, -1.05605267e+00,\n",
       "                     -1.06087196e+00, -1.09861229e+00, -1.17865500e+00, -1.20397280e+00,\n",
       "                     -1.25276297e+00, -1.38629436e+00, -1.44691898e+00, -1.50407740e+00,\n",
       "                     -1.54044504e+00, -1.60943791e+00, -1.79175947e+00, -3.45387764e+01]), auc_score=0.5225100257157197, privacy_risk=0.5178614224040353, accuracy=0.515937019969278, tpr_ind=0.8519376850778937, tnr_ind=0.18378515973017692, test_train_ratio=1.011587485515643, dataset_size=[7767, 7857]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.10610726, 0.10828843, 0.11470362, 0.11996407,\n",
       "                     0.12496792, 0.12984347, 0.13394919, 0.13831152, 0.14280216,\n",
       "                     0.14703618, 0.15794201, 0.15999487, 0.16410059, 0.16679497,\n",
       "                     0.17038748, 0.17346677, 0.17808571, 0.18052348, 0.18257634,\n",
       "                     0.18591224, 0.18835001, 0.18988966, 0.19386708, 0.19681807,\n",
       "                     0.20413138, 0.20708237, 0.22722607, 0.23556582, 0.23928663,\n",
       "                     0.25878881, 0.26276623, 0.27072107, 0.27341545, 0.27649474,\n",
       "                     0.27918912, 0.28444958, 0.2886836 , 0.29317424, 0.2953554 ,\n",
       "                     0.30087247, 0.30497819, 0.33115217, 0.33397485, 0.3489864 ,\n",
       "                     0.35989222, 0.3924814 , 0.40300231, 0.40582499, 0.40916089,\n",
       "                     0.41185527, 0.41326662, 0.41531948, 0.44213498, 0.45073133,\n",
       "                     0.45599179, 0.49589428, 0.51437003, 0.5169361 , 0.51975879,\n",
       "                     0.53618168, 0.5402874 , 0.54824224, 0.57223505, 0.58198614,\n",
       "                     0.58596356, 0.58917116, 0.59379009, 0.59905055, 0.60828843,\n",
       "                     0.61970747, 0.6307416 , 0.6678214 , 0.67372338, 0.67539133,\n",
       "                     0.67744419, 0.68231973, 0.68591224, 0.68719528, 0.69027457,\n",
       "                     0.72773929, 0.73056197, 0.73402617, 0.79715166, 0.79766487,\n",
       "                     0.8020272 , 0.81857839, 0.82512189, 0.82820118, 0.83038235,\n",
       "                     0.83179369, 0.83666923, 0.83962022, 0.84064665, 0.84783167,\n",
       "                     0.86502438, 0.86707724, 0.86938671, 0.87554529, 0.87772646,\n",
       "                     0.88016423, 0.89337952, 0.89658712, 0.90056454, 0.90492687,\n",
       "                     0.90980241, 0.92109315, 0.92481396, 0.926097  , 0.92750834,\n",
       "                     0.93045933, 0.94611239, 0.94790865, 0.95599179, 0.96061073,\n",
       "                     0.96343341, 0.96433154, 0.96561458, 0.96689761, 0.96792404,\n",
       "                     0.97536567, 0.9766487 , 0.9799846 , 0.98024121, 0.98165255,\n",
       "                     0.98344881, 0.98460354, 0.98486015, 0.98537336, 0.98729792,\n",
       "                     0.98909418, 0.98960739, 0.99012061, 0.99127534, 0.99217347,\n",
       "                     0.99281499, 1.        ]), tpr=array([0.        , 0.11430396, 0.11698595, 0.12490421, 0.12975734,\n",
       "                     0.13435504, 0.1385696 , 0.14227331, 0.14559387, 0.15172414,\n",
       "                     0.15708812, 0.16871009, 0.17356322, 0.17816092, 0.18135377,\n",
       "                     0.18659004, 0.19067688, 0.1962963 , 0.19897829, 0.20242656,\n",
       "                     0.20702427, 0.21060026, 0.21200511, 0.21749681, 0.22132822,\n",
       "                     0.23077905, 0.2357599 , 0.25798212, 0.26781609, 0.2706258 ,\n",
       "                     0.28850575, 0.29259259, 0.29961686, 0.30357599, 0.30651341,\n",
       "                     0.31072797, 0.31762452, 0.3238825 , 0.32822478, 0.3311622 ,\n",
       "                     0.33742018, 0.3440613 , 0.36909323, 0.37113665, 0.3853129 ,\n",
       "                     0.39412516, 0.42707535, 0.43959132, 0.4440613 , 0.44776501,\n",
       "                     0.44993614, 0.451341  , 0.45542784, 0.48237548, 0.49106003,\n",
       "                     0.49808429, 0.5339719 , 0.55006386, 0.55312899, 0.55657727,\n",
       "                     0.5734355 , 0.57816092, 0.58480204, 0.60319285, 0.61047254,\n",
       "                     0.61340996, 0.61711367, 0.62158365, 0.62784163, 0.6403576 ,\n",
       "                     0.65300128, 0.66321839, 0.69846743, 0.70536398, 0.70753512,\n",
       "                     0.71111111, 0.71685824, 0.72005109, 0.72209451, 0.72503193,\n",
       "                     0.76385696, 0.76564496, 0.76781609, 0.82860792, 0.82924649,\n",
       "                     0.83346105, 0.84853129, 0.85453384, 0.85734355, 0.85925926,\n",
       "                     0.86168582, 0.86781609, 0.87088123, 0.87177522, 0.88020434,\n",
       "                     0.89476373, 0.89578544, 0.89744572, 0.90664112, 0.90970626,\n",
       "                     0.91226054, 0.92349936, 0.92592593, 0.92924649, 0.93346105,\n",
       "                     0.93716475, 0.94738186, 0.94980843, 0.95108557, 0.95261814,\n",
       "                     0.95440613, 0.96526181, 0.96781609, 0.97484036, 0.97969349,\n",
       "                     0.98148148, 0.98224777, 0.98275862, 0.98416347, 0.98505747,\n",
       "                     0.98888889, 0.98952746, 0.99310345, 0.99348659, 0.9945083 ,\n",
       "                     0.99565773, 0.99604087, 0.99655172, 0.99680715, 0.99795658,\n",
       "                     0.99872286, 0.999106  , 0.99936143, 0.99948914, 0.99974457,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.65200156e-02, -4.72528849e-02,\n",
       "                     -5.12932944e-02, -5.40672213e-02, -5.88405000e-02, -6.66913745e-02,\n",
       "                     -7.41079722e-02, -8.00427077e-02, -9.09717782e-02, -9.43106795e-02,\n",
       "                     -1.00083459e-01, -1.05360516e-01, -1.13328685e-01, -1.15069330e-01,\n",
       "                     -1.17783036e-01, -1.27833372e-01, -1.33531393e-01, -1.38150338e-01,\n",
       "                     -1.54150680e-01, -1.64303051e-01, -1.67054085e-01, -1.70625517e-01,\n",
       "                     -1.82321557e-01, -1.84571277e-01, -1.86585956e-01, -1.97530975e-01,\n",
       "                     -1.99489360e-01, -2.04794413e-01, -2.11649172e-01, -2.23143551e-01,\n",
       "                     -2.26773319e-01, -2.29574442e-01, -2.31801614e-01, -2.41162057e-01,\n",
       "                     -2.45122458e-01, -2.51314428e-01, -2.57829109e-01, -2.65703166e-01,\n",
       "                     -2.67062785e-01, -2.68263987e-01, -2.70961426e-01, -2.71933715e-01,\n",
       "                     -2.74076420e-01, -2.76753002e-01, -2.87682072e-01, -2.90229845e-01,\n",
       "                     -2.94799540e-01, -2.96265816e-01, -3.02280872e-01, -3.10154928e-01,\n",
       "                     -3.18453731e-01, -3.21465134e-01, -3.34369186e-01, -3.36472237e-01,\n",
       "                     -3.40531096e-01, -3.45501643e-01, -3.48306694e-01, -3.67724780e-01,\n",
       "                     -3.74693449e-01, -3.78066134e-01, -3.79489622e-01, -3.82044834e-01,\n",
       "                     -3.87765531e-01, -3.90866309e-01, -3.93904286e-01, -3.95895657e-01,\n",
       "                     -3.98639143e-01, -4.05465108e-01, -4.08826456e-01, -4.13763911e-01,\n",
       "                     -4.17470054e-01, -4.17735201e-01, -4.24883194e-01, -4.28995606e-01,\n",
       "                     -4.41832752e-01, -4.44685821e-01, -4.46287103e-01, -4.48024723e-01,\n",
       "                     -4.50488789e-01, -4.51985124e-01, -4.62623522e-01, -4.66583923e-01,\n",
       "                     -4.70003629e-01, -4.73784352e-01, -4.76339448e-01, -4.80585739e-01,\n",
       "                     -4.92476485e-01, -5.10825624e-01, -5.21296924e-01, -5.23248144e-01,\n",
       "                     -5.35518236e-01, -5.38996501e-01, -5.46543706e-01, -5.57106376e-01,\n",
       "                     -5.59615788e-01, -5.70544858e-01, -5.75364145e-01, -5.83146285e-01,\n",
       "                     -5.87786665e-01, -5.97837001e-01, -6.10909082e-01, -6.13104473e-01,\n",
       "                     -6.14366303e-01, -6.21688217e-01, -6.21919671e-01, -6.39079959e-01,\n",
       "                     -6.41853886e-01, -6.50587566e-01, -6.56779536e-01, -6.93147181e-01,\n",
       "                     -7.17839793e-01, -7.20054633e-01, -7.31861693e-01, -7.62140052e-01,\n",
       "                     -7.73189888e-01, -8.10930216e-01, -8.20980552e-01, -8.26678573e-01,\n",
       "                     -8.47297860e-01, -8.75468737e-01, -9.16290732e-01, -9.80829253e-01,\n",
       "                     -1.01160091e+00, -1.06087196e+00, -1.09861229e+00, -1.17865500e+00,\n",
       "                     -1.25276297e+00, -1.26851133e+00, -1.38629436e+00, -1.46633707e+00,\n",
       "                     -1.50407740e+00, -1.60943791e+00, -1.79175947e+00, -2.01490302e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5273402584625629, privacy_risk=0.5210462513162202, accuracy=0.5209933435739887, tpr_ind=0.49808429118773945, tnr_ind=0.544008211444701, test_train_ratio=0.9954022988505747, dataset_size=[7830, 7794]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.07680472, 0.08898577, 0.0933453 , 0.10014104,\n",
       "                     0.10693679, 0.10911655, 0.13001667, 0.13168355, 0.13501731,\n",
       "                     0.13822285, 0.13899218, 0.14732658, 0.14809591, 0.15771253,\n",
       "                     0.16155917, 0.16258495, 0.16438005, 0.17297089, 0.17630465,\n",
       "                     0.17912553, 0.18002308, 0.18322862, 0.18412617, 0.19425567,\n",
       "                     0.20874471, 0.23438902, 0.23644057, 0.23926144, 0.24310809,\n",
       "                     0.24503141, 0.26195666, 0.27247083, 0.27580459, 0.3014489 ,\n",
       "                     0.3061931 , 0.31375817, 0.32452879, 0.33209386, 0.34478779,\n",
       "                     0.41171945, 0.4191563 , 0.42274651, 0.45057059, 0.45339146,\n",
       "                     0.45800744, 0.46057187, 0.47403513, 0.49455058, 0.50352609,\n",
       "                     0.50903962, 0.54417233, 0.54763431, 0.58930632, 0.58981921,\n",
       "                     0.59251186, 0.59969227, 0.60507757, 0.60943711, 0.61956661,\n",
       "                     0.6266188 , 0.63110655, 0.63354276, 0.63649186, 0.64162072,\n",
       "                     0.64764713, 0.68790871, 0.70419285, 0.71406591, 0.71663034,\n",
       "                     0.71919477, 0.72406719, 0.72663162, 0.72932427, 0.73060649,\n",
       "                     0.73432491, 0.7348378 , 0.75163482, 0.76766252, 0.76958584,\n",
       "                     0.77433004, 0.7788178 , 0.78163867, 0.78997307, 0.79766637,\n",
       "                     0.80266701, 0.81241185, 0.82420823, 0.83779972, 0.85010899,\n",
       "                     0.85357097, 0.86357225, 0.86511091, 0.89473009, 0.89767919,\n",
       "                     0.90024362, 0.90793691, 0.9084498 , 0.90947557, 0.91114245,\n",
       "                     0.91575843, 0.91960508, 0.92024619, 0.92229773, 0.92345172,\n",
       "                     0.92691371, 0.93306834, 0.93499167, 0.94435184, 0.94653161,\n",
       "                     0.94883959, 0.95448134, 0.95602   , 0.95666111, 0.95858443,\n",
       "                     0.96191819, 0.96409796, 0.96499551, 0.96512373, 0.96897038,\n",
       "                     0.96961149, 0.97102193, 0.97371458, 0.97409924, 0.97781767,\n",
       "                     0.98102321, 0.98127965, 0.98281831, 0.9839723 , 0.98589563,\n",
       "                     0.98615207, 0.98781895, 0.98910117, 0.98961405, 1.        ]), tpr=array([0.        , 0.08345048, 0.09827476, 0.10223642, 0.10888179,\n",
       "                     0.11578275, 0.11910543, 0.13853035, 0.1400639 , 0.14453674,\n",
       "                     0.14734824, 0.1486262 , 0.15680511, 0.15910543, 0.16792332,\n",
       "                     0.17162939, 0.17341853, 0.17507987, 0.18492013, 0.18734824,\n",
       "                     0.19054313, 0.19207668, 0.19654952, 0.19795527, 0.21099042,\n",
       "                     0.22236422, 0.24958466, 0.25201278, 0.25482428, 0.25980831,\n",
       "                     0.26440895, 0.28332268, 0.29303514, 0.29623003, 0.32677316,\n",
       "                     0.33265176, 0.34185304, 0.34977636, 0.35808307, 0.37226837,\n",
       "                     0.43284345, 0.43961661, 0.44472843, 0.47808307, 0.48102236,\n",
       "                     0.48651757, 0.48894569, 0.50428115, 0.52102236, 0.5341853 ,\n",
       "                     0.54121406, 0.57635783, 0.58223642, 0.62952077, 0.63067093,\n",
       "                     0.63322684, 0.64140575, 0.64753994, 0.65392971, 0.66198083,\n",
       "                     0.66888179, 0.67412141, 0.67603834, 0.67821086, 0.68306709,\n",
       "                     0.68830671, 0.72715655, 0.74070288, 0.75067093, 0.75386581,\n",
       "                     0.75603834, 0.76153355, 0.76319489, 0.76626198, 0.76766773,\n",
       "                     0.77162939, 0.77252396, 0.79105431, 0.805623  , 0.8086901 ,\n",
       "                     0.81354633, 0.81776358, 0.81955272, 0.82466454, 0.8342492 ,\n",
       "                     0.83897764, 0.8484345 , 0.86095847, 0.87539936, 0.88613419,\n",
       "                     0.88805112, 0.89546326, 0.89750799, 0.925623  , 0.92779553,\n",
       "                     0.93009585, 0.93546326, 0.93610224, 0.93750799, 0.93980831,\n",
       "                     0.94389776, 0.94734824, 0.94824281, 0.94964856, 0.95118211,\n",
       "                     0.95539936, 0.95974441, 0.96204473, 0.9685623 , 0.97035144,\n",
       "                     0.97201278, 0.97750799, 0.97904153, 0.97968051, 0.98210863,\n",
       "                     0.98415335, 0.98555911, 0.98645367, 0.98683706, 0.98888179,\n",
       "                     0.98977636, 0.99105431, 0.99258786, 0.99322684, 0.99501597,\n",
       "                     0.99578275, 0.99642173, 0.9971885 , 0.99782748, 0.99846645,\n",
       "                     0.99872204, 0.99961661, 0.9998722 , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.55333020e-02, -3.17486983e-02,\n",
       "                     -3.77403280e-02, -5.40672213e-02, -7.41079722e-02, -7.59859070e-02,\n",
       "                     -8.00427077e-02, -8.22380982e-02, -8.70113770e-02, -9.53101798e-02,\n",
       "                     -1.03796794e-01, -1.05360516e-01, -1.22602322e-01, -1.29211731e-01,\n",
       "                     -1.33531393e-01, -1.43100844e-01, -1.44830948e-01, -1.46603474e-01,\n",
       "                     -1.48420005e-01, -1.54150680e-01, -1.58224005e-01, -1.67054085e-01,\n",
       "                     -1.70817732e-01, -1.74802724e-01, -1.79971379e-01, -1.91055237e-01,\n",
       "                     -2.04794413e-01, -2.07639365e-01, -2.23143551e-01, -2.28534400e-01,\n",
       "                     -2.33614851e-01, -2.46860078e-01, -2.60108746e-01, -2.65703166e-01,\n",
       "                     -2.66628663e-01, -2.67314770e-01, -2.68263987e-01, -2.74076420e-01,\n",
       "                     -2.74943047e-01, -2.78203328e-01, -2.81412459e-01, -2.87682072e-01,\n",
       "                     -2.98492989e-01, -2.99242895e-01, -3.13657559e-01, -3.18453731e-01,\n",
       "                     -3.28809364e-01, -3.35084311e-01, -3.36472237e-01, -3.44234242e-01,\n",
       "                     -3.45745873e-01, -3.51798207e-01, -3.67724780e-01, -3.71563556e-01,\n",
       "                     -3.73716410e-01, -3.77294231e-01, -3.78436436e-01, -3.78653851e-01,\n",
       "                     -3.80463806e-01, -3.80772496e-01, -3.82992252e-01, -3.85662481e-01,\n",
       "                     -3.87765531e-01, -3.97301797e-01, -4.05465108e-01, -4.11734721e-01,\n",
       "                     -4.13975798e-01, -4.18710335e-01, -4.24883194e-01, -4.28454626e-01,\n",
       "                     -4.30782916e-01, -4.32864082e-01, -4.35318071e-01, -4.37213806e-01,\n",
       "                     -4.51985124e-01, -4.70003629e-01, -4.73287704e-01, -4.85507816e-01,\n",
       "                     -4.89548225e-01, -4.92476485e-01, -4.96436886e-01, -5.00775288e-01,\n",
       "                     -5.10825624e-01, -5.16216472e-01, -5.32216814e-01, -5.33026334e-01,\n",
       "                     -5.35302370e-01, -5.38996501e-01, -5.50046337e-01, -5.54677506e-01,\n",
       "                     -5.59615788e-01, -5.64797147e-01, -5.67984038e-01, -5.75364145e-01,\n",
       "                     -5.79818495e-01, -5.87786665e-01, -5.97837001e-01, -6.06135804e-01,\n",
       "                     -6.11801541e-01, -6.16186139e-01, -6.19039208e-01, -6.46627165e-01,\n",
       "                     -6.50587566e-01, -6.93147181e-01, -7.22134717e-01, -7.47214402e-01,\n",
       "                     -7.50305594e-01, -7.62140052e-01, -7.67255153e-01, -7.71399377e-01,\n",
       "                     -7.73189888e-01, -7.88457360e-01, -7.93230639e-01, -8.10930216e-01,\n",
       "                     -8.20980552e-01, -8.26678573e-01, -8.47297860e-01, -9.16290732e-01,\n",
       "                     -9.44461609e-01, -9.55511445e-01, -9.80829253e-01, -1.02961942e+00,\n",
       "                     -1.09861229e+00, -1.20397280e+00, -1.22377543e+00, -1.25276297e+00,\n",
       "                     -1.28093385e+00, -1.38629436e+00, -1.50407740e+00, -1.60943791e+00,\n",
       "                     -1.94591015e+00, -2.07944154e+00, -3.45387764e+01]), auc_score=0.5255123639591708, privacy_risk=0.5222463025693063, accuracy=0.5224654377880185, tpr_ind=0.6539297124600639, tnr_ind=0.39056289267854855, test_train_ratio=0.9966773162939297, dataset_size=[7825, 7799]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.0691639 , 0.07172079, 0.12976221, 0.13142419,\n",
       "                     0.13270263, 0.13615444, 0.13832779, 0.14203529, 0.14395295,\n",
       "                     0.14919458, 0.15865508, 0.16901048, 0.1722066 , 0.17757607,\n",
       "                     0.18013296, 0.18384045, 0.19240603, 0.1954743 , 0.19982102,\n",
       "                     0.20237791, 0.2026336 , 0.2296088 , 0.23523396, 0.24264894,\n",
       "                     0.24699565, 0.24904117, 0.25799028, 0.26502173, 0.26860138,\n",
       "                     0.27895679, 0.28649962, 0.28969573, 0.29263615, 0.29429813,\n",
       "                     0.30593199, 0.30823319, 0.32229609, 0.33354641, 0.35579136,\n",
       "                     0.36486832, 0.38366147, 0.39324981, 0.4156226 , 0.41933009,\n",
       "                     0.42572232, 0.42955766, 0.43160317, 0.44924572, 0.45576579,\n",
       "                     0.46075173, 0.46791102, 0.46970084, 0.47737152, 0.48542572,\n",
       "                     0.50089491, 0.50677576, 0.51163385, 0.52224495, 0.53196114,\n",
       "                     0.53464587, 0.53707492, 0.5410381 , 0.54321145, 0.55126566,\n",
       "                     0.56788545, 0.57427768, 0.58194835, 0.58514446, 0.59064178,\n",
       "                     0.59511634, 0.61352595, 0.62631041, 0.63730504, 0.65149578,\n",
       "                     0.65558681, 0.65865508, 0.67553055, 0.67808745, 0.68090003,\n",
       "                     0.6862695 , 0.69061621, 0.6931731 , 0.72372795, 0.73369982,\n",
       "                     0.73843007, 0.74264894, 0.74431092, 0.7494247 , 0.76949629,\n",
       "                     0.78752237, 0.80900026, 0.84735362, 0.85617489, 0.86563539,\n",
       "                     0.87177193, 0.87509588, 0.87535157, 0.87701355, 0.87905906,\n",
       "                     0.88493991, 0.88698543, 0.90386091, 0.90731271, 0.91728458,\n",
       "                     0.91805165, 0.91958578, 0.92342112, 0.93416006, 0.93594988,\n",
       "                     0.93952953, 0.94336487, 0.94541038, 0.95998466, 0.96266939,\n",
       "                     0.96573766, 0.9661212 , 0.96714395, 0.96829455, 0.97110713,\n",
       "                     0.97404756, 0.97494247, 0.97698798, 0.97826643, 0.97864996,\n",
       "                     0.9790335 , 0.97967272, 0.9870877 , 0.98874968, 0.99079519,\n",
       "                     0.99105088, 1.        ]), tpr=array([0.        , 0.07536529, 0.07805691, 0.13778518, 0.13996411,\n",
       "                     0.14201487, 0.14547552, 0.14803896, 0.15175596, 0.15419123,\n",
       "                     0.15880543, 0.17046911, 0.17995386, 0.18367085, 0.18995129,\n",
       "                     0.19251474, 0.19495001, 0.20417842, 0.20699821, 0.21391951,\n",
       "                     0.21661113, 0.21725199, 0.24378365, 0.25057678, 0.25916432,\n",
       "                     0.263394  , 0.26634196, 0.27518585, 0.28223532, 0.2878749 ,\n",
       "                     0.29723148, 0.30697257, 0.31158677, 0.31568829, 0.3174827 ,\n",
       "                     0.32889003, 0.33017175, 0.34106639, 0.35208921, 0.37093053,\n",
       "                     0.37990259, 0.40169187, 0.41322738, 0.43770828, 0.43988721,\n",
       "                     0.44668034, 0.45167906, 0.45488336, 0.47462189, 0.48333761,\n",
       "                     0.48923353, 0.49679569, 0.49987183, 0.50897206, 0.51794412,\n",
       "                     0.53088952, 0.53550372, 0.54139964, 0.55421687, 0.56459882,\n",
       "                     0.56677775, 0.56831582, 0.5725455 , 0.57433991, 0.58228659,\n",
       "                     0.5984363 , 0.60561395, 0.61445783, 0.61779031, 0.62304537,\n",
       "                     0.62740323, 0.6473981 , 0.65624199, 0.66803384, 0.67918482,\n",
       "                     0.68264548, 0.68584978, 0.70674186, 0.70904896, 0.71289413,\n",
       "                     0.71853371, 0.72391694, 0.72635222, 0.75762625, 0.76877724,\n",
       "                     0.77159703, 0.77505768, 0.77698026, 0.78261984, 0.80094847,\n",
       "                     0.81786721, 0.83722123, 0.87169956, 0.87669828, 0.88464496,\n",
       "                     0.89220713, 0.89477057, 0.89566778, 0.89759036, 0.89964112,\n",
       "                     0.90592156, 0.90784414, 0.92386568, 0.92694181, 0.93501666,\n",
       "                     0.93591387, 0.93796462, 0.94116893, 0.95231992, 0.95372981,\n",
       "                     0.95719046, 0.96103563, 0.96398359, 0.97667265, 0.97910792,\n",
       "                     0.98192771, 0.98269674, 0.98397847, 0.98500385, 0.98731095,\n",
       "                     0.98884901, 0.99013074, 0.99218149, 0.99346321, 0.99384773,\n",
       "                     0.99436042, 0.99512945, 0.99833376, 0.99910279, 0.99987183,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.65200156e-02, -5.42930824e-02,\n",
       "                     -5.71584138e-02, -6.06246218e-02, -7.14589640e-02, -9.53101798e-02,\n",
       "                     -9.84400728e-02, -1.00083459e-01, -1.05360516e-01, -1.14113307e-01,\n",
       "                     -1.14775515e-01, -1.29211731e-01, -1.33531393e-01, -1.39761942e-01,\n",
       "                     -1.46603474e-01, -1.54150680e-01, -1.67054085e-01, -1.69899037e-01,\n",
       "                     -1.74353387e-01, -1.82321557e-01, -1.84734103e-01, -1.88591170e-01,\n",
       "                     -1.89756535e-01, -1.92371893e-01, -1.96710294e-01, -2.08544752e-01,\n",
       "                     -2.12174520e-01, -2.23143551e-01, -2.31329136e-01, -2.43977638e-01,\n",
       "                     -2.45122458e-01, -2.47836164e-01, -2.51314428e-01, -2.56295759e-01,\n",
       "                     -2.62364264e-01, -2.66878945e-01, -2.73040522e-01, -2.77425572e-01,\n",
       "                     -2.84104251e-01, -2.84736562e-01, -2.87682072e-01, -2.88990117e-01,\n",
       "                     -3.02280872e-01, -3.06374205e-01, -3.06730267e-01, -3.07484700e-01,\n",
       "                     -3.10154928e-01, -3.13091788e-01, -3.14493330e-01, -3.16911711e-01,\n",
       "                     -3.18453731e-01, -3.22287602e-01, -3.26215736e-01, -3.26521906e-01,\n",
       "                     -3.28504067e-01, -3.30241687e-01, -3.36472237e-01, -3.41749294e-01,\n",
       "                     -3.44840486e-01, -3.48306694e-01, -3.53640040e-01, -3.56674944e-01,\n",
       "                     -3.61501985e-01, -3.67724780e-01, -3.69097464e-01, -3.71063681e-01,\n",
       "                     -3.79489622e-01, -3.80772496e-01, -3.85662481e-01, -4.05465108e-01,\n",
       "                     -4.10284395e-01, -4.12685356e-01, -4.16893804e-01, -4.17735201e-01,\n",
       "                     -4.18710335e-01, -4.23702696e-01, -4.41832752e-01, -4.48950220e-01,\n",
       "                     -4.49916871e-01, -4.51985124e-01, -4.56758402e-01, -4.61256468e-01,\n",
       "                     -4.61345567e-01, -4.64305608e-01, -4.65363250e-01, -4.70003629e-01,\n",
       "                     -4.92476485e-01, -5.00987175e-01, -5.10825624e-01, -5.20054430e-01,\n",
       "                     -5.23385818e-01, -5.26093096e-01, -5.26825965e-01, -5.27632742e-01,\n",
       "                     -5.30628251e-01, -5.38996501e-01, -5.50046337e-01, -5.59615788e-01,\n",
       "                     -5.62526998e-01, -5.87786665e-01, -5.92221262e-01, -6.06135804e-01,\n",
       "                     -6.10455465e-01, -6.19039208e-01, -6.28608659e-01, -6.31271777e-01,\n",
       "                     -6.40037355e-01, -6.46627165e-01, -6.55406853e-01, -6.59245629e-01,\n",
       "                     -6.71168274e-01, -6.93147181e-01, -7.44440475e-01, -7.59105148e-01,\n",
       "                     -7.73189888e-01, -7.88457360e-01, -8.10930216e-01, -8.23200309e-01,\n",
       "                     -8.47297860e-01, -8.75468737e-01, -9.16290732e-01, -9.55511445e-01,\n",
       "                     -9.80829253e-01, -1.01160091e+00, -1.04145387e+00, -1.09861229e+00,\n",
       "                     -1.29928298e+00, -1.79175947e+00, -2.30258509e+00, -3.45387764e+01]), auc_score=0.5209872987218627, privacy_risk=0.517538707794178, accuracy=0.5172171018945213, tpr_ind=0.7687772366059985, tnr_ind=0.26630017898235747, test_train_ratio=1.0025634452704435, dataset_size=[7802, 7822]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.1       , 0.1056701 , 0.11404639, 0.11610825,\n",
       "                     0.12152062, 0.12731959, 0.14239691, 0.1439433 , 0.14471649,\n",
       "                     0.14574742, 0.15309278, 0.15760309, 0.16146907, 0.17847938,\n",
       "                     0.17976804, 0.18041237, 0.18414948, 0.21945876, 0.22203608,\n",
       "                     0.22719072, 0.2310567 , 0.23195876, 0.23878866, 0.24793814,\n",
       "                     0.2685567 , 0.27731959, 0.30103093, 0.30670103, 0.31198454,\n",
       "                     0.31804124, 0.32487113, 0.32860825, 0.3310567 , 0.37126289,\n",
       "                     0.37744845, 0.38595361, 0.39768041, 0.40824742, 0.42087629,\n",
       "                     0.43118557, 0.44561856, 0.45425258, 0.4556701 , 0.4564433 ,\n",
       "                     0.45670103, 0.4621134 , 0.47371134, 0.48311856, 0.49858247,\n",
       "                     0.5       , 0.50115979, 0.51610825, 0.54664948, 0.54845361,\n",
       "                     0.56610825, 0.57951031, 0.58157216, 0.58981959, 0.59793814,\n",
       "                     0.60180412, 0.61069588, 0.61520619, 0.62229381, 0.62384021,\n",
       "                     0.67603093, 0.6806701 , 0.69329897, 0.70296392, 0.70476804,\n",
       "                     0.72358247, 0.72899485, 0.73170103, 0.73363402, 0.74819588,\n",
       "                     0.76056701, 0.7621134 , 0.77074742, 0.77203608, 0.78054124,\n",
       "                     0.78273196, 0.79226804, 0.79613402, 0.80515464, 0.81146907,\n",
       "                     0.82074742, 0.82345361, 0.82551546, 0.82719072, 0.84987113,\n",
       "                     0.85889175, 0.86340206, 0.87023196, 0.87216495, 0.87770619,\n",
       "                     0.88376289, 0.8875    , 0.89613402, 0.90476804, 0.91108247,\n",
       "                     0.91353093, 0.91829897, 0.91881443, 0.92036082, 0.92268041,\n",
       "                     0.92654639, 0.92783505, 0.92976804, 0.93118557, 0.93621134,\n",
       "                     0.93724227, 0.94278351, 0.94780928, 0.94871134, 0.95167526,\n",
       "                     0.95618557, 0.96030928, 0.97396907, 0.9746134 , 0.97525773,\n",
       "                     0.9757732 , 0.97706186, 0.98002577, 0.98402062, 0.98518041,\n",
       "                     0.98556701, 0.98556701, 0.9867268 , 0.98865979, 0.98956186,\n",
       "                     0.99020619, 0.99059278, 0.99072165, 0.99123711, 0.99201031,\n",
       "                     1.        ]), tpr=array([0.        , 0.10579858, 0.11406409, 0.12220244, 0.12487284,\n",
       "                     0.13148525, 0.13758901, 0.15043235, 0.15183113, 0.15310275,\n",
       "                     0.1542472 , 0.16492879, 0.16912513, 0.17166836, 0.18578332,\n",
       "                     0.18743642, 0.18819939, 0.19265005, 0.23283316, 0.23613937,\n",
       "                     0.24122584, 0.24491353, 0.24605799, 0.25368769, 0.26055443,\n",
       "                     0.27962869, 0.28942014, 0.3154883 , 0.3214649 , 0.32896745,\n",
       "                     0.33468973, 0.34257375, 0.34867752, 0.35198372, 0.38860631,\n",
       "                     0.39445575, 0.40475585, 0.41759919, 0.43006104, 0.4431587 ,\n",
       "                     0.45206002, 0.46706511, 0.47583927, 0.4783825 , 0.47978128,\n",
       "                     0.48079858, 0.48613937, 0.49809257, 0.50712106, 0.52314344,\n",
       "                     0.52441506, 0.52657681, 0.54323499, 0.57527976, 0.57706002,\n",
       "                     0.59066633, 0.60350966, 0.60554425, 0.61508138, 0.62131231,\n",
       "                     0.62550865, 0.63440997, 0.6379705 , 0.64445575, 0.64712614,\n",
       "                     0.6991353 , 0.70485758, 0.72087996, 0.72698372, 0.72965412,\n",
       "                     0.74758393, 0.75330621, 0.75686673, 0.7603001 , 0.7749237 ,\n",
       "                     0.78751272, 0.78992879, 0.79577823, 0.79793998, 0.80913021,\n",
       "                     0.81319939, 0.82210071, 0.82667854, 0.83290946, 0.83952187,\n",
       "                     0.84994914, 0.85300102, 0.85643438, 0.85783316, 0.88123093,\n",
       "                     0.89203967, 0.89699898, 0.90297558, 0.90462869, 0.90996948,\n",
       "                     0.91620041, 0.91976094, 0.92675483, 0.93336724, 0.93769074,\n",
       "                     0.93959817, 0.94163276, 0.94239573, 0.94404883, 0.94595626,\n",
       "                     0.94888098, 0.95091556, 0.95307731, 0.95485758, 0.96134283,\n",
       "                     0.96299593, 0.96681078, 0.97024415, 0.97126144, 0.97278739,\n",
       "                     0.97482197, 0.97927263, 0.98753815, 0.9880468 , 0.98893693,\n",
       "                     0.9896999 , 0.99109868, 0.99313327, 0.99593082, 0.99656663,\n",
       "                     0.99694812, 0.99720244, 0.99783825, 0.99860122, 0.99936419,\n",
       "                     0.99949135, 0.99961851, 0.99974568, 0.99987284, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.52674721e-02, -4.58095360e-02,\n",
       "                     -4.65200156e-02, -5.60894667e-02, -8.00427077e-02, -8.53598490e-02,\n",
       "                     -8.70113770e-02, -9.53101798e-02, -1.05360516e-01, -1.12477983e-01,\n",
       "                     -1.14410351e-01, -1.39761942e-01, -1.42500063e-01, -1.43100844e-01,\n",
       "                     -1.54150680e-01, -1.58224005e-01, -1.68513584e-01, -1.75890666e-01,\n",
       "                     -1.82321557e-01, -1.88052232e-01, -2.00670695e-01, -2.23143551e-01,\n",
       "                     -2.30523659e-01, -2.36388778e-01, -2.41162057e-01, -2.41510428e-01,\n",
       "                     -2.44196961e-01, -2.53195896e-01, -2.53780521e-01, -2.54892250e-01,\n",
       "                     -2.55933374e-01, -2.68263987e-01, -2.71933715e-01, -2.82232468e-01,\n",
       "                     -2.87682072e-01, -2.90154262e-01, -2.90229845e-01, -2.92524697e-01,\n",
       "                     -2.94799540e-01, -2.98219578e-01, -2.98492989e-01, -3.00104592e-01,\n",
       "                     -3.10154928e-01, -3.18453731e-01, -3.22773392e-01, -3.31902541e-01,\n",
       "                     -3.32439973e-01, -3.34202088e-01, -3.36472237e-01, -3.44840486e-01,\n",
       "                     -3.50549351e-01, -3.51103899e-01, -3.56674944e-01, -3.57609087e-01,\n",
       "                     -3.61613226e-01, -3.62905494e-01, -3.64643114e-01, -3.70859579e-01,\n",
       "                     -3.74693449e-01, -3.76477571e-01, -3.81367557e-01, -3.85662481e-01,\n",
       "                     -3.89464767e-01, -3.96459726e-01, -3.98030130e-01, -4.05465108e-01,\n",
       "                     -4.19258430e-01, -4.21213465e-01, -4.21878138e-01, -4.27444015e-01,\n",
       "                     -4.28995606e-01, -4.41832752e-01, -4.53564903e-01, -4.54736157e-01,\n",
       "                     -4.56758402e-01, -4.61818045e-01, -4.62623522e-01, -4.64305608e-01,\n",
       "                     -4.66089730e-01, -4.70003629e-01, -4.76924072e-01, -4.77627554e-01,\n",
       "                     -4.79573080e-01, -4.83629881e-01, -4.85507816e-01, -4.88352768e-01,\n",
       "                     -4.92476485e-01, -4.98797048e-01, -5.06108634e-01, -5.10825624e-01,\n",
       "                     -5.19300251e-01, -5.26093096e-01, -5.38996501e-01, -5.50830958e-01,\n",
       "                     -5.59615788e-01, -5.77634293e-01, -5.81355775e-01, -5.84513340e-01,\n",
       "                     -5.87786665e-01, -5.94707108e-01, -6.06135804e-01, -6.13104473e-01,\n",
       "                     -6.24154309e-01, -6.25705900e-01, -6.28608659e-01, -6.32522559e-01,\n",
       "                     -6.56779536e-01, -6.93147181e-01, -7.30887509e-01, -7.41937345e-01,\n",
       "                     -7.47214402e-01, -7.53771802e-01, -7.73189888e-01, -7.82759339e-01,\n",
       "                     -7.88457360e-01, -8.09219352e-01, -8.10930216e-01, -8.26678573e-01,\n",
       "                     -8.47297860e-01, -8.60201265e-01, -9.16290732e-01, -1.09861229e+00,\n",
       "                     -1.16315081e+00, -1.20397280e+00, -1.25276297e+00, -1.38629436e+00,\n",
       "                     -1.42711636e+00, -1.50407740e+00, -1.60943791e+00, -1.79175947e+00,\n",
       "                     -1.94591015e+00, -2.07944154e+00, -2.30258509e+00, -3.45387764e+01]), auc_score=0.5192580488799279, privacy_risk=0.516798460425166, accuracy=0.5193292370711725, tpr_ind=0.896998982706002, tnr_ind=0.13659793814432988, test_train_ratio=0.9867751780264497, dataset_size=[7864, 7760]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.07059272, 0.07784279, 0.10048334, 0.103536  ,\n",
       "                     0.10849657, 0.1207072 , 0.12465022, 0.12859323, 0.13011956,\n",
       "                     0.13240906, 0.14080387, 0.14322055, 0.14894429, 0.15123378,\n",
       "                     0.15543119, 0.16026456, 0.18481302, 0.19295345, 0.19765963,\n",
       "                     0.19867718, 0.19969473, 0.2414144 , 0.24446706, 0.25120834,\n",
       "                     0.26596286, 0.2910201 , 0.30017807, 0.30501145, 0.3146782 ,\n",
       "                     0.31607733, 0.31925719, 0.33363012, 0.34545917, 0.35067413,\n",
       "                     0.36962605, 0.37547698, 0.38590689, 0.39341135, 0.3965912 ,\n",
       "                     0.4007886 , 0.4029509 , 0.41719664, 0.41872297, 0.42037649,\n",
       "                     0.47239888, 0.48206563, 0.48435513, 0.48689901, 0.51577207,\n",
       "                     0.51640804, 0.51882473, 0.52493004, 0.53485118, 0.53701348,\n",
       "                     0.54133808, 0.57300941, 0.57644365, 0.581913  , 0.58458408,\n",
       "                     0.58687357, 0.59717629, 0.63622488, 0.63876876, 0.66522513,\n",
       "                     0.67845332, 0.69689646, 0.69740524, 0.7003307 , 0.70707199,\n",
       "                     0.70770796, 0.7176291 , 0.72742305, 0.73111168, 0.7327652 ,\n",
       "                     0.75184431, 0.75883999, 0.76023912, 0.78898499, 0.78974816,\n",
       "                     0.79203765, 0.8146782 , 0.81823963, 0.82091071, 0.8253625 ,\n",
       "                     0.83121343, 0.83363012, 0.83541084, 0.84075299, 0.84800305,\n",
       "                     0.86326634, 0.86453829, 0.86975324, 0.87051641, 0.87191554,\n",
       "                     0.87522259, 0.87789367, 0.87967438, 0.88412618, 0.88845078,\n",
       "                     0.88908675, 0.89748156, 0.90536759, 0.9072755 , 0.93563979,\n",
       "                     0.93780209, 0.94301704, 0.9440346 , 0.94708726, 0.9483592 ,\n",
       "                     0.94874078, 0.95077588, 0.9526838 , 0.95560926, 0.95726278,\n",
       "                     0.95942508, 0.96069702, 0.96158738, 0.96400407, 0.96489443,\n",
       "                     0.9675655 , 0.97278046, 0.97506996, 0.97672348, 0.97735945,\n",
       "                     0.97875859, 0.98168405, 0.98244721, 0.98651743, 0.98651743,\n",
       "                     0.98817095, 0.98855253, 0.9891885 , 0.99007886, 0.99020605,\n",
       "                     0.99071483, 1.        ]), tpr=array([0.        , 0.07420768, 0.0837413 , 0.10590054, 0.10937903,\n",
       "                     0.11311518, 0.12393713, 0.12715795, 0.13179593, 0.13475908,\n",
       "                     0.13746457, 0.14790003, 0.15047668, 0.15588766, 0.16001031,\n",
       "                     0.16567895, 0.17108993, 0.19646998, 0.20471528, 0.20922443,\n",
       "                     0.21102809, 0.21334708, 0.25972687, 0.26294769, 0.27119299,\n",
       "                     0.28961608, 0.31319248, 0.32066478, 0.32504509, 0.33419222,\n",
       "                     0.33560938, 0.33792837, 0.35325947, 0.36459675, 0.36975006,\n",
       "                     0.39023448, 0.39796444, 0.41071889, 0.41767586, 0.41986601,\n",
       "                     0.42385983, 0.42527699, 0.44047926, 0.44292708, 0.44498841,\n",
       "                     0.49497552, 0.50412265, 0.50682814, 0.50914713, 0.54083999,\n",
       "                     0.54212832, 0.5452203 , 0.55320794, 0.56287039, 0.56467405,\n",
       "                     0.57060036, 0.60989436, 0.61221335, 0.62020098, 0.6226488 ,\n",
       "                     0.62535429, 0.63669157, 0.67869106, 0.68088122, 0.70342695,\n",
       "                     0.71695439, 0.73331616, 0.73589281, 0.73885596, 0.74632827,\n",
       "                     0.7472301 , 0.75689255, 0.76629735, 0.769647  , 0.77273898,\n",
       "                     0.78794125, 0.79631538, 0.79863437, 0.82594692, 0.82697758,\n",
       "                     0.83045607, 0.85725329, 0.86098944, 0.86446792, 0.86846174,\n",
       "                     0.87413038, 0.87593404, 0.87799536, 0.88173151, 0.8855965 ,\n",
       "                     0.89847977, 0.89963927, 0.90453491, 0.90517908, 0.90659624,\n",
       "                     0.90955939, 0.91187838, 0.91355321, 0.91716053, 0.92231384,\n",
       "                     0.92347333, 0.93197629, 0.94022159, 0.94254058, 0.96328266,\n",
       "                     0.96508632, 0.9685648 , 0.96959547, 0.97152796, 0.97242979,\n",
       "                     0.97320278, 0.97461994, 0.97526411, 0.97706777, 0.97822726,\n",
       "                     0.97925792, 0.98067508, 0.98157691, 0.98273641, 0.98338057,\n",
       "                     0.98479773, 0.98788972, 0.98904921, 0.99059521, 0.99123937,\n",
       "                     0.99304303, 0.99471786, 0.99523319, 0.99742334, 0.99780984,\n",
       "                     0.99858284, 0.99871167, 0.99896934, 0.9996135 , 0.99974233,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.34230203e-02, -3.42890735e-02,\n",
       "                     -3.63676442e-02, -6.66913745e-02, -6.89928715e-02, -7.69610411e-02,\n",
       "                     -8.00427077e-02, -8.33816089e-02, -9.09717782e-02, -9.41872151e-02,\n",
       "                     -9.53101798e-02, -1.12477983e-01, -1.17783036e-01, -1.27833372e-01,\n",
       "                     -1.33531393e-01, -1.54875580e-01, -1.58605030e-01, -1.82321557e-01,\n",
       "                     -1.94156014e-01, -2.00670695e-01, -2.05205851e-01, -2.15111380e-01,\n",
       "                     -2.23143551e-01, -2.24541176e-01, -2.28593156e-01, -2.30016431e-01,\n",
       "                     -2.34839591e-01, -2.37129793e-01, -2.41162057e-01, -2.45122458e-01,\n",
       "                     -2.51314428e-01, -2.58861634e-01, -2.62364264e-01, -2.68633877e-01,\n",
       "                     -2.75103290e-01, -2.87682072e-01, -3.01475395e-01, -3.02280872e-01,\n",
       "                     -3.03682414e-01, -3.10154928e-01, -3.10719741e-01, -3.13657559e-01,\n",
       "                     -3.18453731e-01, -3.21261407e-01, -3.22287602e-01, -3.22773392e-01,\n",
       "                     -3.28504067e-01, -3.35310121e-01, -3.36472237e-01, -3.48306694e-01,\n",
       "                     -3.50202429e-01, -3.55340721e-01, -3.56674944e-01, -3.61013346e-01,\n",
       "                     -3.61907134e-01, -3.67724780e-01, -3.83725121e-01, -3.87765531e-01,\n",
       "                     -3.89464767e-01, -3.97860509e-01, -4.05465108e-01, -4.24883194e-01,\n",
       "                     -4.26201007e-01, -4.33635985e-01, -4.33927573e-01, -4.38254931e-01,\n",
       "                     -4.48024723e-01, -4.50416496e-01, -4.51985124e-01, -4.53196511e-01,\n",
       "                     -4.54472687e-01, -4.55475529e-01, -4.59532329e-01, -4.65757338e-01,\n",
       "                     -4.70003629e-01, -4.76924072e-01, -4.84055383e-01, -4.85507816e-01,\n",
       "                     -4.88352768e-01, -4.91407538e-01, -5.03905181e-01, -5.10825624e-01,\n",
       "                     -5.17256514e-01, -5.33298480e-01, -5.38996501e-01, -5.59615788e-01,\n",
       "                     -5.64529803e-01, -5.69094532e-01, -5.70979547e-01, -5.75364145e-01,\n",
       "                     -5.81921545e-01, -5.87786665e-01, -5.97837001e-01, -6.02175402e-01,\n",
       "                     -6.06135804e-01, -6.13104473e-01, -6.19039208e-01, -6.28608659e-01,\n",
       "                     -6.35988767e-01, -6.46627165e-01, -6.53301272e-01, -6.64976304e-01,\n",
       "                     -6.93147181e-01, -7.28238500e-01, -7.47214402e-01, -7.53771802e-01,\n",
       "                     -7.57685702e-01, -7.62140052e-01, -7.73189888e-01, -7.80158558e-01,\n",
       "                     -7.88457360e-01, -7.94929875e-01, -7.98507696e-01, -8.10930216e-01,\n",
       "                     -8.20980552e-01, -8.26678573e-01, -8.47297860e-01, -8.75468737e-01,\n",
       "                     -8.97941593e-01, -9.16290732e-01, -9.38269639e-01, -9.49080555e-01,\n",
       "                     -9.55511445e-01, -9.71860583e-01, -9.90398704e-01, -1.01160091e+00,\n",
       "                     -1.09861229e+00, -1.20397280e+00, -1.25276297e+00, -1.38629436e+00,\n",
       "                     -1.50407740e+00, -1.60943791e+00, -1.79175947e+00, -2.39789527e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5244431186092012, privacy_risk=0.5217786054479713, accuracy=0.5195852534562212, tpr_ind=0.8644679206390106, tnr_ind=0.17908929025693207, test_train_ratio=1.0128832775057974, dataset_size=[7762, 7862]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.0759233 , 0.08312958, 0.09921503, 0.10217475,\n",
       "                     0.10732209, 0.10783683, 0.12109124, 0.12250676, 0.13640458,\n",
       "                     0.1385922 , 0.1393643 , 0.14155192, 0.14850084, 0.15017372,\n",
       "                     0.15210398, 0.15416291, 0.16458628, 0.1667739 , 0.17951358,\n",
       "                     0.1832454 , 0.18877879, 0.19225325, 0.20177583, 0.20885343,\n",
       "                     0.21258525, 0.22802728, 0.23034359, 0.26817655, 0.27358126,\n",
       "                     0.27757045, 0.28413332, 0.30176296, 0.31656158, 0.32351049,\n",
       "                     0.33534938, 0.33637884, 0.34474328, 0.34886115, 0.35439454,\n",
       "                     0.35645348, 0.36610475, 0.3758847 , 0.38193283, 0.38617938,\n",
       "                     0.3875949 , 0.39274225, 0.40213615, 0.42079526, 0.42710076,\n",
       "                     0.43173337, 0.4337923 , 0.45360957, 0.46017244, 0.46145927,\n",
       "                     0.47020975, 0.47741603, 0.4792176 , 0.50817141, 0.50932956,\n",
       "                     0.53673916, 0.55964483, 0.56324797, 0.57199846, 0.58486681,\n",
       "                     0.59104362, 0.59400335, 0.59773517, 0.6053275 , 0.61858191,\n",
       "                     0.63183631, 0.63543945, 0.64007206, 0.64406125, 0.64817913,\n",
       "                     0.65474199, 0.65654356, 0.65795908, 0.66349247, 0.66812508,\n",
       "                     0.68498263, 0.69128812, 0.69720757, 0.70042466, 0.71007592,\n",
       "                     0.71599537, 0.72500322, 0.72847767, 0.73079398, 0.74675074,\n",
       "                     0.74752284, 0.75048256, 0.75164072, 0.76862695, 0.77969373,\n",
       "                     0.78599923, 0.80015442, 0.80427229, 0.80787543, 0.81263673,\n",
       "                     0.8144383 , 0.82679192, 0.82936559, 0.83000901, 0.83528503,\n",
       "                     0.83991764, 0.84107579, 0.85188521, 0.85420152, 0.86732724,\n",
       "                     0.86912881, 0.873118  , 0.88392742, 0.8903616 , 0.89370737,\n",
       "                     0.89602368, 0.8989834 , 0.90232917, 0.90824862, 0.9091494 ,\n",
       "                     0.91185176, 0.91789988, 0.94080556, 0.94659632, 0.95200103,\n",
       "                     0.95997941, 0.96152361, 0.96821516, 0.96872989, 0.96988805,\n",
       "                     0.97194698, 0.97284777, 0.97555012, 0.97593617, 0.98134088,\n",
       "                     0.98262772, 0.98442929, 0.98468666, 0.98713164, 0.98777506,\n",
       "                     0.98880453, 0.98931926, 0.98996268, 0.99163557, 0.99189294,\n",
       "                     1.        ]), tpr=array([0.        , 0.08544505, 0.0948682 , 0.10862091, 0.11154973,\n",
       "                     0.1188081 , 0.12059086, 0.13421622, 0.1357443 , 0.14554947,\n",
       "                     0.14822361, 0.14949701, 0.15191647, 0.1552273 , 0.15828346,\n",
       "                     0.16019356, 0.16375907, 0.17318222, 0.17560168, 0.1929199 ,\n",
       "                     0.19724946, 0.20399847, 0.20781867, 0.21991596, 0.22653763,\n",
       "                     0.23150388, 0.24576595, 0.24945881, 0.28626003, 0.29199032,\n",
       "                     0.29555584, 0.30192283, 0.32089647, 0.33515854, 0.34241691,\n",
       "                     0.35375016, 0.3564243 , 0.36661149, 0.37094104, 0.37437922,\n",
       "                     0.37692602, 0.38622183, 0.39793709, 0.40455877, 0.41156246,\n",
       "                     0.41436394, 0.41983955, 0.42977206, 0.44632624, 0.45485802,\n",
       "                     0.46033363, 0.46288043, 0.48541958, 0.4928053 , 0.49420604,\n",
       "                     0.50350185, 0.5110149 , 0.51267032, 0.53902967, 0.54132179,\n",
       "                     0.56780848, 0.5889469 , 0.59340379, 0.60180823, 0.61250478,\n",
       "                     0.61734369, 0.62090921, 0.6247294 , 0.63198778, 0.64701388,\n",
       "                     0.65885649, 0.66254934, 0.66764294, 0.67044442, 0.67490131,\n",
       "                     0.68432446, 0.68597988, 0.68788998, 0.69387495, 0.69947791,\n",
       "                     0.71615943, 0.72329046, 0.72749268, 0.73233159, 0.73806189,\n",
       "                     0.7441742 , 0.75487075, 0.75741755, 0.76085572, 0.77651853,\n",
       "                     0.77740991, 0.77982936, 0.78135744, 0.79829365, 0.80784414,\n",
       "                     0.81522985, 0.82949191, 0.83343945, 0.83725965, 0.84006112,\n",
       "                     0.84248058, 0.85623329, 0.8591621 , 0.8604355 , 0.86514708,\n",
       "                     0.86909461, 0.86998599, 0.88004584, 0.8824653 , 0.89570865,\n",
       "                     0.89698205, 0.90029288, 0.91073475, 0.91773844, 0.91990322,\n",
       "                     0.92219534, 0.92474214, 0.92779829, 0.93301923, 0.93441997,\n",
       "                     0.93620273, 0.94129632, 0.95810518, 0.96459952, 0.96943843,\n",
       "                     0.97529607, 0.97707882, 0.9830638 , 0.98382784, 0.98446454,\n",
       "                     0.98611995, 0.98764803, 0.99032217, 0.99095887, 0.99376035,\n",
       "                     0.99414237, 0.9955431 , 0.9961798 , 0.99758054, 0.9980899 ,\n",
       "                     0.99885394, 0.99923596, 0.99949064, 0.99987266, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.34230203e-02, -2.73989742e-02,\n",
       "                     -4.25596144e-02, -6.78225963e-02, -6.89928715e-02, -7.21032939e-02,\n",
       "                     -8.00427077e-02, -8.70113770e-02, -9.09717782e-02, -9.53101798e-02,\n",
       "                     -1.00083459e-01, -1.09199292e-01, -1.17783036e-01, -1.25163143e-01,\n",
       "                     -1.33531393e-01, -1.38586163e-01, -1.46603474e-01, -1.49940147e-01,\n",
       "                     -1.62518929e-01, -1.72842813e-01, -1.82321557e-01, -1.91055237e-01,\n",
       "                     -1.91891008e-01, -2.07639365e-01, -2.08754814e-01, -2.16223108e-01,\n",
       "                     -2.16895700e-01, -2.18689201e-01, -2.23143551e-01, -2.31111721e-01,\n",
       "                     -2.32495657e-01, -2.44345759e-01, -2.47408173e-01, -2.47562079e-01,\n",
       "                     -2.51314428e-01, -2.52702354e-01, -2.57829109e-01, -2.59511195e-01,\n",
       "                     -2.62364264e-01, -2.63417450e-01, -2.65703166e-01, -2.68263987e-01,\n",
       "                     -2.69332934e-01, -2.76253377e-01, -2.81851152e-01, -2.87682072e-01,\n",
       "                     -2.91520849e-01, -2.95117051e-01, -2.99242895e-01, -3.00104592e-01,\n",
       "                     -3.04489191e-01, -3.09004842e-01, -3.10154928e-01, -3.14710745e-01,\n",
       "                     -3.16911711e-01, -3.25422400e-01, -3.26763422e-01, -3.28504067e-01,\n",
       "                     -3.28888608e-01, -3.30429922e-01, -3.36472237e-01, -3.42944751e-01,\n",
       "                     -3.48306694e-01, -3.51397887e-01, -3.56674944e-01, -3.60002734e-01,\n",
       "                     -3.63667979e-01, -3.65113813e-01, -3.65240307e-01, -3.70373788e-01,\n",
       "                     -3.71563556e-01, -3.74693449e-01, -3.76477571e-01, -3.78066134e-01,\n",
       "                     -3.79489622e-01, -3.82992252e-01, -3.83958903e-01, -3.90197636e-01,\n",
       "                     -3.97802235e-01, -4.05465108e-01, -4.15515444e-01, -4.22856851e-01,\n",
       "                     -4.27444015e-01, -4.32864082e-01, -4.36717652e-01, -4.38254931e-01,\n",
       "                     -4.41832752e-01, -4.45311017e-01, -4.51985124e-01, -4.56758402e-01,\n",
       "                     -4.59532329e-01, -4.66237146e-01, -4.70003629e-01, -4.82851772e-01,\n",
       "                     -4.96436886e-01, -4.97838428e-01, -5.10825624e-01, -5.19875459e-01,\n",
       "                     -5.21296924e-01, -5.27354926e-01, -5.28067430e-01, -5.30628251e-01,\n",
       "                     -5.32216814e-01, -5.36304709e-01, -5.38996501e-01, -5.43207033e-01,\n",
       "                     -5.52068582e-01, -5.59615788e-01, -5.87786665e-01, -5.92051064e-01,\n",
       "                     -5.97227059e-01, -5.97837001e-01, -6.00773860e-01, -6.06135804e-01,\n",
       "                     -6.15185639e-01, -6.28608659e-01, -6.43136760e-01, -6.46627165e-01,\n",
       "                     -6.56779536e-01, -6.67829373e-01, -6.93147181e-01, -7.31613461e-01,\n",
       "                     -7.31861693e-01, -7.35706795e-01, -7.62140052e-01, -7.64972915e-01,\n",
       "                     -7.73189888e-01, -7.88457360e-01, -8.02346473e-01, -8.10930216e-01,\n",
       "                     -8.47297860e-01, -8.75468737e-01, -9.16290732e-01, -9.80829253e-01,\n",
       "                     -1.00330211e+00, -1.02961942e+00, -1.09861229e+00, -1.25276297e+00,\n",
       "                     -1.38629436e+00, -1.54044504e+00, -1.60943791e+00, -1.79175947e+00,\n",
       "                     -2.56494936e+00, -3.45387764e+01]), auc_score=0.522110116198164, privacy_risk=0.5167994323961708, accuracy=0.5167690732206861, tpr_ind=0.5110148987648032, tnr_ind=0.5225839660275383, test_train_ratio=0.9895581306507067, dataset_size=[7853, 7771]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.09504238, 0.1033907 , 0.10621629, 0.11469304,\n",
       "                     0.11726175, 0.1199589 , 0.12432571, 0.1271513 , 0.13138967,\n",
       "                     0.13434369, 0.13755459, 0.14320575, 0.14667352, 0.14911379,\n",
       "                     0.15399435, 0.16105831, 0.16362702, 0.16568199, 0.16927819,\n",
       "                     0.17043411, 0.20125867, 0.20575392, 0.2063961 , 0.21602877,\n",
       "                     0.21744156, 0.2381197 , 0.27870537, 0.28576933, 0.29296173,\n",
       "                     0.29527357, 0.29745697, 0.3231441 , 0.326355  , 0.32866684,\n",
       "                     0.33354739, 0.33496018, 0.33855638, 0.34857436, 0.35461084,\n",
       "                     0.3894169 , 0.40007706, 0.40765476, 0.4207552 , 0.43706653,\n",
       "                     0.44014899, 0.44220396, 0.45157976, 0.46365271, 0.46442332,\n",
       "                     0.46827639, 0.47919342, 0.48407398, 0.48767018, 0.49113794,\n",
       "                     0.49589006, 0.51489854, 0.51746725, 0.52350372, 0.53146674,\n",
       "                     0.53519137, 0.53660416, 0.54122784, 0.54520935, 0.54854868,\n",
       "                     0.56640123, 0.57076805, 0.61225276, 0.61494991, 0.6199589 ,\n",
       "                     0.62316979, 0.63305934, 0.65617775, 0.68828667, 0.69393784,\n",
       "                     0.71012073, 0.71667095, 0.71744156, 0.72257899, 0.72437709,\n",
       "                     0.7341382 , 0.73722065, 0.74723863, 0.74839455, 0.75263293,\n",
       "                     0.76021063, 0.76624711, 0.77138454, 0.79219111, 0.79334703,\n",
       "                     0.79707167, 0.79835602, 0.80362189, 0.82866684, 0.83085024,\n",
       "                     0.83508862, 0.84228102, 0.84433599, 0.85602363, 0.86218854,\n",
       "                     0.86424351, 0.86758284, 0.86989468, 0.8728487 , 0.87361932,\n",
       "                     0.8818392 , 0.88427948, 0.8872335 , 0.8930131 , 0.89827896,\n",
       "                     0.90893912, 0.9095813 , 0.91035191, 0.91163627, 0.92062677,\n",
       "                     0.92268174, 0.92537889, 0.93526843, 0.95247881, 0.95530439,\n",
       "                     0.95697406, 0.95915746, 0.95954277, 0.9650655 , 0.96699204,\n",
       "                     0.96814796, 0.96917544, 0.96981762, 0.9704598 , 0.97277164,\n",
       "                     0.97302851, 0.97431287, 0.97482661, 0.97688158, 0.98047778,\n",
       "                     0.98137683, 0.9834318 , 0.98689956, 0.98869766, 0.98869766,\n",
       "                     0.9888261 , 0.98972515, 0.99036733, 0.99075263, 0.99139481,\n",
       "                     1.        ]), tpr=array([0.        , 0.11087012, 0.11826997, 0.12069405, 0.1288594 ,\n",
       "                     0.13243174, 0.1358765 , 0.14046951, 0.14493493, 0.14927277,\n",
       "                     0.15335545, 0.15731054, 0.1630518 , 0.16751722, 0.1700689 ,\n",
       "                     0.17478949, 0.18321   , 0.18614442, 0.18831335, 0.19558561,\n",
       "                     0.19813728, 0.23296759, 0.23768819, 0.23883644, 0.24623628,\n",
       "                     0.24789487, 0.27430467, 0.31257974, 0.32112784, 0.32801735,\n",
       "                     0.33133452, 0.33273794, 0.35787191, 0.36144425, 0.36450625,\n",
       "                     0.36922684, 0.37050268, 0.37509569, 0.38530237, 0.39678489,\n",
       "                     0.43148762, 0.4456494 , 0.45394233, 0.4650421 , 0.48341414,\n",
       "                     0.48596581, 0.48877265, 0.49885175, 0.51212044, 0.51377903,\n",
       "                     0.51735137, 0.52819597, 0.53355448, 0.53763715, 0.54261291,\n",
       "                     0.54631283, 0.56583312, 0.56825721, 0.57361572, 0.58394999,\n",
       "                     0.58981883, 0.59186017, 0.59530492, 0.59900485, 0.60181169,\n",
       "                     0.61444246, 0.61826997, 0.65131411, 0.65424853, 0.66088288,\n",
       "                     0.66432763, 0.67568257, 0.69864761, 0.72301608, 0.72760908,\n",
       "                     0.74572595, 0.75121204, 0.75287063, 0.75886706, 0.76001531,\n",
       "                     0.76830824, 0.77009441, 0.78323552, 0.78476652, 0.79063537,\n",
       "                     0.79918347, 0.80556264, 0.81079357, 0.82878285, 0.83082419,\n",
       "                     0.83528961, 0.8377137 , 0.84371013, 0.86731309, 0.86986476,\n",
       "                     0.87318193, 0.8804542 , 0.88249553, 0.89117122, 0.89729523,\n",
       "                     0.89997448, 0.90227099, 0.90469508, 0.9076295 , 0.90865017,\n",
       "                     0.91413626, 0.91528451, 0.91834652, 0.92344986, 0.92753253,\n",
       "                     0.93735647, 0.93812197, 0.93990814, 0.94092881, 0.94730799,\n",
       "                     0.94883899, 0.95049758, 0.95917326, 0.97346262, 0.97499362,\n",
       "                     0.97639704, 0.97767288, 0.97882113, 0.98354172, 0.98507272,\n",
       "                     0.98571064, 0.98673131, 0.9883899 , 0.98877265, 0.99055882,\n",
       "                     0.99119673, 0.99196224, 0.99247257, 0.99311049, 0.99502424,\n",
       "                     0.99566216, 0.99642766, 0.99821383, 0.99897933, 0.99910692,\n",
       "                     0.9992345 , 0.99936208, 0.99961725, 0.99987242, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.70944334e-02, -5.12932944e-02,\n",
       "                     -6.06246218e-02, -6.89928715e-02, -7.14589640e-02, -8.00427077e-02,\n",
       "                     -8.22380982e-02, -8.45573880e-02, -1.17783036e-01, -1.21360857e-01,\n",
       "                     -1.25163143e-01, -1.33531393e-01, -1.39761942e-01, -1.50282203e-01,\n",
       "                     -1.54150680e-01, -1.60342650e-01, -1.62518929e-01, -1.76456437e-01,\n",
       "                     -1.82321557e-01, -1.86585956e-01, -1.95744577e-01, -2.00670695e-01,\n",
       "                     -2.02236866e-01, -2.07639365e-01, -2.12458651e-01, -2.23143551e-01,\n",
       "                     -2.26124179e-01, -2.30523659e-01, -2.38411023e-01, -2.41162057e-01,\n",
       "                     -2.50185760e-01, -2.51314428e-01, -2.55933374e-01, -2.60283098e-01,\n",
       "                     -2.62364264e-01, -2.66628663e-01, -2.71933715e-01, -2.79313823e-01,\n",
       "                     -2.85842146e-01, -2.87682072e-01, -2.91520849e-01, -2.96265816e-01,\n",
       "                     -2.98044859e-01, -3.00104592e-01, -3.10154928e-01, -3.12683375e-01,\n",
       "                     -3.18453731e-01, -3.25422400e-01, -3.31357136e-01, -3.36472237e-01,\n",
       "                     -3.39867826e-01, -3.40926587e-01, -3.43771539e-01, -3.46276237e-01,\n",
       "                     -3.49459432e-01, -3.51397887e-01, -3.56674944e-01, -3.59141036e-01,\n",
       "                     -3.61013346e-01, -3.62905494e-01, -3.67724780e-01, -3.70373788e-01,\n",
       "                     -3.74693449e-01, -3.81613892e-01, -3.82992252e-01, -3.88592547e-01,\n",
       "                     -3.90866309e-01, -3.92561703e-01, -3.93042588e-01, -3.94165553e-01,\n",
       "                     -4.05465108e-01, -4.10687052e-01, -4.23814247e-01, -4.24070296e-01,\n",
       "                     -4.28454626e-01, -4.30782916e-01, -4.40311839e-01, -4.41832752e-01,\n",
       "                     -4.50585543e-01, -4.51985124e-01, -4.59021213e-01, -4.59532329e-01,\n",
       "                     -4.61818045e-01, -4.68136215e-01, -4.70003629e-01, -4.76082675e-01,\n",
       "                     -4.84962113e-01, -4.85507816e-01, -4.87703206e-01, -4.89548225e-01,\n",
       "                     -4.93657820e-01, -4.96671876e-01, -5.00775288e-01, -5.03103578e-01,\n",
       "                     -5.10825624e-01, -5.23248144e-01, -5.25424423e-01, -5.35518236e-01,\n",
       "                     -5.38996501e-01, -5.43615447e-01, -5.52068582e-01, -5.53385238e-01,\n",
       "                     -5.59615788e-01, -5.69533225e-01, -5.75364145e-01, -5.83146285e-01,\n",
       "                     -5.87786665e-01, -5.94707108e-01, -5.97837001e-01, -6.06135804e-01,\n",
       "                     -6.19039208e-01, -6.28608659e-01, -6.31271777e-01, -6.50587566e-01,\n",
       "                     -6.53926467e-01, -6.63294217e-01, -6.93147181e-01, -7.33969175e-01,\n",
       "                     -7.37598943e-01, -7.41937345e-01, -7.47214402e-01, -7.58529940e-01,\n",
       "                     -7.73189888e-01, -7.88457360e-01, -8.10930216e-01, -8.36248024e-01,\n",
       "                     -8.47297860e-01, -9.16290732e-01, -9.55511445e-01, -9.80829253e-01,\n",
       "                     -1.01160091e+00, -1.02961942e+00, -1.09861229e+00, -1.16315081e+00,\n",
       "                     -1.20397280e+00, -1.25276297e+00, -1.38629436e+00, -1.60943791e+00,\n",
       "                     -1.79175947e+00, -1.94591015e+00, -2.01490302e+00, -2.07944154e+00,\n",
       "                     -2.48490665e+00, -3.45387764e+01]), auc_score=0.5332592629831928, privacy_risk=0.5276280035475638, accuracy=0.52784178187404, tpr_ind=0.5918601684103088, tnr_ind=0.46339583868481893, test_train_ratio=0.9933656545037, dataset_size=[7838, 7786]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.07751738, 0.08653103, 0.10494463, 0.11447335,\n",
       "                     0.11550348, 0.11691991, 0.12477466, 0.12619109, 0.14202936,\n",
       "                     0.14936904, 0.15155807, 0.15542107, 0.15941283, 0.16031419,\n",
       "                     0.16430595, 0.16546485, 0.1706155 , 0.17228947, 0.17705382,\n",
       "                     0.18271955, 0.20203451, 0.20795776, 0.20808653, 0.2258563 ,\n",
       "                     0.22933299, 0.22997682, 0.23512748, 0.23976307, 0.24645892,\n",
       "                     0.26306979, 0.26654648, 0.26860675, 0.26912181, 0.27826423,\n",
       "                     0.28599021, 0.28856554, 0.29114087, 0.30311615, 0.31303116,\n",
       "                     0.31509142, 0.31921195, 0.33260366, 0.35281998, 0.35475148,\n",
       "                     0.38810198, 0.39041978, 0.3972444 , 0.39853206, 0.4137265 ,\n",
       "                     0.42389905, 0.42595931, 0.44617564, 0.44759207, 0.45480299,\n",
       "                     0.45737832, 0.48261653, 0.49394798, 0.49871234, 0.5019315 ,\n",
       "                     0.51017255, 0.51854236, 0.55730106, 0.59515838, 0.59863508,\n",
       "                     0.60095287, 0.60674736, 0.60777749, 0.62091167, 0.63301571,\n",
       "                     0.6380376 , 0.64177183, 0.65400464, 0.66636621, 0.67306207,\n",
       "                     0.69031677, 0.69417976, 0.70048931, 0.70770023, 0.71684265,\n",
       "                     0.72817409, 0.73512748, 0.73834664, 0.74027814, 0.74259593,\n",
       "                     0.74980685, 0.75469997, 0.75714654, 0.76126706, 0.76474375,\n",
       "                     0.76899305, 0.77040948, 0.7764615 , 0.77877929, 0.78470255,\n",
       "                     0.7910121 , 0.80157095, 0.80375998, 0.80800927, 0.82848313,\n",
       "                     0.83427762, 0.83711048, 0.84187484, 0.84522277, 0.84689673,\n",
       "                     0.84869946, 0.84972959, 0.862735  , 0.86505279, 0.86852949,\n",
       "                     0.87071852, 0.87651301, 0.8796034 , 0.88063353, 0.88887458,\n",
       "                     0.89170744, 0.89428277, 0.89634303, 0.9141128 , 0.91810456,\n",
       "                     0.92196755, 0.92801957, 0.93226886, 0.94038115, 0.94681947,\n",
       "                     0.95222766, 0.95454545, 0.95596189, 0.95840845, 0.96265774,\n",
       "                     0.96407417, 0.96536183, 0.96677826, 0.97257275, 0.97347412,\n",
       "                     0.97991244, 0.98094257, 0.98493433, 0.98583569, 0.98828226,\n",
       "                     0.98828226, 0.98956992, 0.99008499, 0.99060005, 0.99085758,\n",
       "                     0.99175895, 0.99188772, 0.99214525, 0.99227401, 1.        ]), tpr=array([0.        , 0.08551794, 0.09417154, 0.1144057 , 0.12407737,\n",
       "                     0.12598626, 0.12751336, 0.13731229, 0.13998473, 0.15652838,\n",
       "                     0.16530924, 0.16887249, 0.17319929, 0.17638076, 0.17739883,\n",
       "                     0.18287096, 0.18376177, 0.18808857, 0.18974294, 0.19381522,\n",
       "                     0.19992364, 0.22372105, 0.22932044, 0.22995673, 0.25082718,\n",
       "                     0.25388139, 0.25502672, 0.25986256, 0.26355307, 0.27017053,\n",
       "                     0.28722321, 0.29218631, 0.29409519, 0.29549504, 0.30618478,\n",
       "                     0.31394757, 0.31712904, 0.32120132, 0.33430898, 0.34372614,\n",
       "                     0.34639857, 0.35199796, 0.36230593, 0.37935862, 0.38101298,\n",
       "                     0.41766353, 0.42122678, 0.42911682, 0.43140748, 0.44540596,\n",
       "                     0.45507763, 0.45685925, 0.4777297 , 0.47912955, 0.48816493,\n",
       "                     0.49160092, 0.51756172, 0.5281242 , 0.53372359, 0.53601425,\n",
       "                     0.54504963, 0.55395775, 0.59417154, 0.63196742, 0.63642148,\n",
       "                     0.63896666, 0.64367524, 0.64558412, 0.65920081, 0.67167218,\n",
       "                     0.67536269, 0.67930771, 0.69025197, 0.70183253, 0.7065411 ,\n",
       "                     0.72359379, 0.7272843 , 0.7337745 , 0.74039196, 0.74739119,\n",
       "                     0.76113515, 0.76737083, 0.77106134, 0.773352  , 0.77653347,\n",
       "                     0.78671418, 0.79091372, 0.79307712, 0.79625859, 0.79918554,\n",
       "                     0.8014762 , 0.80313057, 0.80745737, 0.8101298 , 0.81623823,\n",
       "                     0.82221939, 0.83163655, 0.83418173, 0.83838127, 0.85747009,\n",
       "                     0.86217867, 0.86536014, 0.87070501, 0.87235938, 0.87490456,\n",
       "                     0.87706796, 0.87884958, 0.89437516, 0.89577501, 0.89984729,\n",
       "                     0.90328328, 0.90799186, 0.91104607, 0.91168236, 0.9202087 ,\n",
       "                     0.92262662, 0.92529906, 0.92746246, 0.94057012, 0.94400611,\n",
       "                     0.94693306, 0.95125986, 0.95444133, 0.96016798, 0.96500382,\n",
       "                     0.96882158, 0.97136676, 0.97314838, 0.97569356, 0.97785696,\n",
       "                     0.97976584, 0.98065666, 0.98116569, 0.98663782, 0.98740137,\n",
       "                     0.99096462, 0.99261899, 0.99490965, 0.9956732 , 0.99732756,\n",
       "                     0.99770934, 0.99847289, 0.99885467, 0.99910919, 0.99936371,\n",
       "                     0.99961822, 0.99974548, 0.99987274, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.45987994e-02, -3.09622256e-02,\n",
       "                     -6.37158144e-02, -6.45385211e-02, -8.00427077e-02, -8.70113770e-02,\n",
       "                     -9.09717782e-02, -9.53101798e-02, -9.66268357e-02, -1.01782694e-01,\n",
       "                     -1.11225635e-01, -1.13328685e-01, -1.17783036e-01, -1.30620182e-01,\n",
       "                     -1.33531393e-01, -1.37201122e-01, -1.43100844e-01, -1.45182010e-01,\n",
       "                     -1.54150680e-01, -1.57963113e-01, -1.67054085e-01, -1.82321557e-01,\n",
       "                     -1.88400603e-01, -1.89242000e-01, -2.00670695e-01, -2.12561442e-01,\n",
       "                     -2.16223108e-01, -2.23143551e-01, -2.26124179e-01, -2.28258652e-01,\n",
       "                     -2.36388778e-01, -2.41162057e-01, -2.42012036e-01, -2.45834963e-01,\n",
       "                     -2.46860078e-01, -2.47836164e-01, -2.48072934e-01, -2.49811798e-01,\n",
       "                     -2.51314428e-01, -2.58861634e-01, -2.59511195e-01, -2.61215499e-01,\n",
       "                     -2.68263987e-01, -2.71933715e-01, -2.78713402e-01, -2.79584862e-01,\n",
       "                     -2.87682072e-01, -2.89952221e-01, -2.94239473e-01, -3.05381650e-01,\n",
       "                     -3.07305344e-01, -3.10154928e-01, -3.12031101e-01, -3.15081047e-01,\n",
       "                     -3.23787077e-01, -3.26091521e-01, -3.26684230e-01, -3.28504067e-01,\n",
       "                     -3.32439973e-01, -3.36472237e-01, -3.49051019e-01, -3.56001316e-01,\n",
       "                     -3.56674944e-01, -3.71563556e-01, -3.78066134e-01, -3.82992252e-01,\n",
       "                     -3.89766199e-01, -3.91766264e-01, -3.93904286e-01, -3.94654192e-01,\n",
       "                     -4.05465108e-01, -4.09121419e-01, -4.14433778e-01, -4.15366179e-01,\n",
       "                     -4.16893804e-01, -4.24883194e-01, -4.30782916e-01, -4.35318071e-01,\n",
       "                     -4.35862585e-01, -4.38913042e-01, -4.39366660e-01, -4.41832752e-01,\n",
       "                     -4.44685821e-01, -4.54255272e-01, -4.54736157e-01, -4.62623522e-01,\n",
       "                     -4.70003629e-01, -4.75423697e-01, -4.76924072e-01, -4.79573080e-01,\n",
       "                     -4.80972661e-01, -4.81838087e-01, -4.85507816e-01, -4.93657820e-01,\n",
       "                     -4.99955952e-01, -5.00775288e-01, -5.10825624e-01, -5.14817645e-01,\n",
       "                     -5.16216472e-01, -5.18793793e-01, -5.25010259e-01, -5.26093096e-01,\n",
       "                     -5.30628251e-01, -5.34082486e-01, -5.38996501e-01, -5.43086486e-01,\n",
       "                     -5.46543706e-01, -5.59615788e-01, -5.75364145e-01, -5.78736829e-01,\n",
       "                     -5.83146285e-01, -5.87786665e-01, -6.07491736e-01, -6.10909082e-01,\n",
       "                     -6.19039208e-01, -6.32522559e-01, -6.33129171e-01, -6.35988767e-01,\n",
       "                     -6.48695418e-01, -6.63294217e-01, -6.72944473e-01, -6.93147181e-01,\n",
       "                     -7.06219262e-01, -7.09676483e-01, -7.17839793e-01, -7.28238500e-01,\n",
       "                     -7.41937345e-01, -7.50305594e-01, -7.57685702e-01, -7.62140052e-01,\n",
       "                     -8.10930216e-01, -8.33919734e-01, -8.47297860e-01, -8.87303195e-01,\n",
       "                     -9.00786545e-01, -9.16290732e-01, -9.80829253e-01, -1.09861229e+00,\n",
       "                     -1.20397280e+00, -1.25276297e+00, -1.29928298e+00, -1.38629436e+00,\n",
       "                     -1.50407740e+00, -1.60943791e+00, -1.79175947e+00, -2.19722458e+00,\n",
       "                     -2.30258509e+00, -3.45387764e+01]), auc_score=0.5260924055867516, privacy_risk=0.5193282358568164, accuracy=0.5202252944188428, tpr_ind=0.6716721812165946, tnr_ind=0.36698429049703835, test_train_ratio=0.9882921863069484, dataset_size=[7858, 7766]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.07743419, 0.07998978, 0.08420649, 0.10925121,\n",
       "                     0.11078456, 0.11321237, 0.13237925, 0.13314592, 0.13429594,\n",
       "                     0.13953488, 0.14426271, 0.1468183 , 0.15218502, 0.1529517 ,\n",
       "                     0.16969077, 0.1756964 , 0.18067979, 0.1811909 , 0.19447994,\n",
       "                     0.19741886, 0.19907999, 0.21824687, 0.22220802, 0.25083056,\n",
       "                     0.25287503, 0.2579862 , 0.26156402, 0.26999744, 0.27204191,\n",
       "                     0.27523639, 0.2776642 , 0.28303092, 0.31254792, 0.32110912,\n",
       "                     0.32277025, 0.33209813, 0.34257603, 0.34755942, 0.36519295,\n",
       "                     0.36685408, 0.3728597 , 0.37567084, 0.38346537, 0.38538206,\n",
       "                     0.38870432, 0.39023767, 0.3986711 , 0.4017378 , 0.40761564,\n",
       "                     0.420138  , 0.42179913, 0.42882699, 0.43163813, 0.43815487,\n",
       "                     0.44467161, 0.45412727, 0.46268847, 0.47687197, 0.47814976,\n",
       "                     0.49156657, 0.49706108, 0.49859443, 0.50408893, 0.51086123,\n",
       "                     0.55635063, 0.55916177, 0.56721186, 0.57321748, 0.57590084,\n",
       "                     0.57845643, 0.57960644, 0.5822898 , 0.58522872, 0.5921288 ,\n",
       "                     0.59775109, 0.60235114, 0.60912343, 0.61397904, 0.61806798,\n",
       "                     0.62535139, 0.6376182 , 0.64860721, 0.72450805, 0.74456938,\n",
       "                     0.74891388, 0.75351393, 0.75632507, 0.76578073, 0.77153079,\n",
       "                     0.7739586 , 0.78085868, 0.78903654, 0.79989778, 0.80718119,\n",
       "                     0.8157424 , 0.82008689, 0.8286481 , 0.82928699, 0.83427038,\n",
       "                     0.83848709, 0.84180935, 0.8439816 , 0.85343726, 0.85944288,\n",
       "                     0.86340404, 0.86468183, 0.86800409, 0.87132635, 0.89470994,\n",
       "                     0.8986711 , 0.9010989 , 0.90736008, 0.90927677, 0.91119346,\n",
       "                     0.91413238, 0.91860465, 0.93163813, 0.94352159, 0.94824942,\n",
       "                     0.95093279, 0.95221058, 0.95629951, 0.96153846, 0.96307181,\n",
       "                     0.96690519, 0.97061078, 0.97457194, 0.97661641, 0.9772553 ,\n",
       "                     0.97904421, 0.97993867, 0.98070534, 0.98619985, 0.98696652,\n",
       "                     0.98862765, 0.98888321, 1.        ]), tpr=array([0.        , 0.09066427, 0.09566556, 0.09964093, 0.1214414 ,\n",
       "                     0.12400616, 0.12631444, 0.14760195, 0.14901257, 0.15029495,\n",
       "                     0.15632213, 0.1609387 , 0.16542703, 0.17158246, 0.17350603,\n",
       "                     0.1919723 , 0.19876892, 0.20505258, 0.20569377, 0.22044114,\n",
       "                     0.22287766, 0.22467299, 0.2449346 , 0.25006412, 0.28430367,\n",
       "                     0.28648371, 0.29135676, 0.29802513, 0.3070018 , 0.30943832,\n",
       "                     0.31277251, 0.31559374, 0.32008207, 0.35316748, 0.36252885,\n",
       "                     0.36458066, 0.37150551, 0.38432932, 0.38791998, 0.40356502,\n",
       "                     0.4058733 , 0.41266992, 0.41754296, 0.42498076, 0.42831495,\n",
       "                     0.43229033, 0.43408566, 0.44049756, 0.4433188 , 0.45062837,\n",
       "                     0.46140036, 0.46242626, 0.46845345, 0.47178764, 0.47743011,\n",
       "                     0.48538087, 0.49512696, 0.50384714, 0.52282637, 0.52410875,\n",
       "                     0.53706078, 0.54077969, 0.54231854, 0.54898692, 0.55501411,\n",
       "                     0.59592203, 0.59887151, 0.6059246 , 0.61143883, 0.61426007,\n",
       "                     0.61644011, 0.61913311, 0.62208259, 0.62528854, 0.63477815,\n",
       "                     0.64106181, 0.64478071, 0.64914081, 0.65491152, 0.6582457 ,\n",
       "                     0.66812003, 0.68043088, 0.6919723 , 0.76173378, 0.78109772,\n",
       "                     0.78686843, 0.79212619, 0.79494742, 0.80405232, 0.81033598,\n",
       "                     0.81225955, 0.82110798, 0.83162349, 0.84085663, 0.84714029,\n",
       "                     0.85637343, 0.86124647, 0.86971018, 0.87086432, 0.87253142,\n",
       "                     0.87637856, 0.87945627, 0.88086689, 0.89048474, 0.89535778,\n",
       "                     0.89869197, 0.9004873 , 0.90305206, 0.90766863, 0.92344191,\n",
       "                     0.925109  , 0.92767376, 0.93395742, 0.93613747, 0.93729161,\n",
       "                     0.93972814, 0.94472942, 0.95652731, 0.96742755, 0.9716594 ,\n",
       "                     0.97358297, 0.97473711, 0.97935368, 0.98320082, 0.98435496,\n",
       "                     0.98666325, 0.98961272, 0.9908951 , 0.99307515, 0.99384458,\n",
       "                     0.99448577, 0.99487048, 0.99563991, 0.99871762, 0.99935881,\n",
       "                     0.99974352, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.53178080e-02, -3.17486983e-02,\n",
       "                     -3.46855580e-02, -4.87901642e-02, -5.40672213e-02, -7.53980175e-02,\n",
       "                     -8.70113770e-02, -9.53101798e-02, -1.01096117e-01, -1.05360516e-01,\n",
       "                     -1.08213585e-01, -1.17783036e-01, -1.25163143e-01, -1.30053128e-01,\n",
       "                     -1.56842471e-01, -1.68622712e-01, -1.82321557e-01, -1.89541805e-01,\n",
       "                     -1.91055237e-01, -1.94156014e-01, -1.94900339e-01, -2.02940844e-01,\n",
       "                     -2.05764950e-01, -2.11309094e-01, -2.12561442e-01, -2.23143551e-01,\n",
       "                     -2.28841572e-01, -2.33614851e-01, -2.38411023e-01, -2.41162057e-01,\n",
       "                     -2.51314428e-01, -2.55182905e-01, -2.63417450e-01, -2.71933715e-01,\n",
       "                     -2.73695830e-01, -2.77631737e-01, -2.78713402e-01, -2.83575290e-01,\n",
       "                     -2.87682072e-01, -2.92387963e-01, -2.94239473e-01, -2.96265816e-01,\n",
       "                     -2.97251523e-01, -3.03682414e-01, -3.05381650e-01, -3.07484700e-01,\n",
       "                     -3.10154928e-01, -3.13657559e-01, -3.14115330e-01, -3.18453731e-01,\n",
       "                     -3.24239668e-01, -3.25422400e-01, -3.26684230e-01, -3.27212911e-01,\n",
       "                     -3.32705754e-01, -3.34369186e-01, -3.35506520e-01, -3.36472237e-01,\n",
       "                     -3.40706541e-01, -3.46276237e-01, -3.48306694e-01, -3.52821375e-01,\n",
       "                     -3.54545018e-01, -3.57301707e-01, -3.61013346e-01, -3.62114667e-01,\n",
       "                     -3.65934269e-01, -3.74693449e-01, -3.85662481e-01, -3.89464767e-01,\n",
       "                     -3.90866309e-01, -3.92042088e-01, -4.05465108e-01, -4.12244795e-01,\n",
       "                     -4.16893804e-01, -4.24883194e-01, -4.27444015e-01, -4.30782916e-01,\n",
       "                     -4.35318071e-01, -4.39598114e-01, -4.41832752e-01, -4.42751448e-01,\n",
       "                     -4.46551968e-01, -4.56017387e-01, -4.60815203e-01, -4.64305608e-01,\n",
       "                     -4.64707942e-01, -4.64888529e-01, -4.70003629e-01, -4.75423697e-01,\n",
       "                     -4.76082675e-01, -4.76924072e-01, -4.77627554e-01, -4.85507816e-01,\n",
       "                     -4.89548225e-01, -4.92476485e-01, -5.10825624e-01, -5.26093096e-01,\n",
       "                     -5.30628251e-01, -5.35518236e-01, -5.46543706e-01, -5.65313809e-01,\n",
       "                     -5.67106460e-01, -5.70544858e-01, -5.79818495e-01, -5.87786665e-01,\n",
       "                     -6.06135804e-01, -6.08350644e-01, -6.13104473e-01, -6.15185639e-01,\n",
       "                     -6.29968279e-01, -6.32522559e-01, -6.35988767e-01, -6.66478933e-01,\n",
       "                     -6.67171694e-01, -6.71168274e-01, -6.93147181e-01, -7.08185058e-01,\n",
       "                     -7.25937003e-01, -7.47214402e-01, -7.60286483e-01, -7.73189888e-01,\n",
       "                     -7.98507696e-01, -8.47297860e-01, -8.71838969e-01, -8.75468737e-01,\n",
       "                     -8.80358723e-01, -9.16290732e-01, -9.55511445e-01, -9.80829253e-01,\n",
       "                     -1.04145387e+00, -1.09861229e+00, -1.22377543e+00, -1.38629436e+00,\n",
       "                     -2.30258509e+00, -3.45387764e+01]), auc_score=0.5321906326017397, privacy_risk=0.5229794943063699, accuracy=0.5229774705581157, tpr_ind=0.5241087458322646, tnr_ind=0.5218502427804753, test_train_ratio=1.0035906642728905, dataset_size=[7798, 7826]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.09683996, 0.10117227, 0.10958206, 0.117737  ,\n",
       "                     0.12155963, 0.12461774, 0.12895005, 0.12971458, 0.13251784,\n",
       "                     0.13417431, 0.13697757, 0.15583588, 0.15812946, 0.16055046,\n",
       "                     0.1680683 , 0.16997961, 0.17686035, 0.17877166, 0.17979103,\n",
       "                     0.18106524, 0.19406218, 0.20170744, 0.20463812, 0.20820591,\n",
       "                     0.22821101, 0.26299694, 0.26898573, 0.27076962, 0.28045362,\n",
       "                     0.28453109, 0.28809888, 0.29077472, 0.29523445, 0.2979103 ,\n",
       "                     0.30593782, 0.31179918, 0.31664118, 0.31995413, 0.34034149,\n",
       "                     0.34314475, 0.35053517, 0.36200306, 0.37449032, 0.37818552,\n",
       "                     0.38799694, 0.39207441, 0.39678899, 0.43756371, 0.43960245,\n",
       "                     0.43998471, 0.44164118, 0.44699286, 0.44979613, 0.47629969,\n",
       "                     0.48024975, 0.48063201, 0.51605505, 0.52319062, 0.52841488,\n",
       "                     0.53325688, 0.54115698, 0.54587156, 0.55389908, 0.55746687,\n",
       "                     0.5685525 , 0.57186544, 0.58448012, 0.59034149, 0.60601427,\n",
       "                     0.62334353, 0.62818552, 0.64271152, 0.6638634 , 0.67201835,\n",
       "                     0.69712029, 0.69966871, 0.71126402, 0.7148318 , 0.71954638,\n",
       "                     0.72375127, 0.72948522, 0.73865953, 0.74719674, 0.74949032,\n",
       "                     0.76121305, 0.76388889, 0.77178899, 0.77446483, 0.77739551,\n",
       "                     0.78121814, 0.78555046, 0.7937054 , 0.79638124, 0.80211519,\n",
       "                     0.8082314 , 0.81027013, 0.8112895 , 0.81702345, 0.82696228,\n",
       "                     0.83065749, 0.8343527 , 0.84365443, 0.86455148, 0.8743629 ,\n",
       "                     0.877421  , 0.88009684, 0.88315494, 0.88685015, 0.88876147,\n",
       "                     0.89347604, 0.89780836, 0.90685525, 0.90965851, 0.9108053 ,\n",
       "                     0.91335372, 0.91513761, 0.91653925, 0.94189602, 0.94508155,\n",
       "                     0.94673802, 0.94979613, 0.95119776, 0.95565749, 0.9587156 ,\n",
       "                     0.96024465, 0.96355759, 0.96648828, 0.97617227, 0.97655454,\n",
       "                     0.97719164, 0.98050459, 0.98292559, 0.98394495, 0.98445464,\n",
       "                     0.98598369, 0.98687564, 0.98687564, 0.98814985, 0.99006116,\n",
       "                     0.99018858, 0.99133537, 0.99337411, 0.99413863, 1.        ]), tpr=array([0.        , 0.1096965 , 0.11625514, 0.1257716 , 0.13168724,\n",
       "                     0.13695988, 0.1401749 , 0.14467593, 0.14609053, 0.14994856,\n",
       "                     0.15200617, 0.15496399, 0.17322531, 0.17592593, 0.17939815,\n",
       "                     0.1877572 , 0.18930041, 0.19598765, 0.19817387, 0.19958848,\n",
       "                     0.20164609, 0.21283436, 0.22055041, 0.22299383, 0.22826646,\n",
       "                     0.2492284 , 0.2820216 , 0.28652263, 0.28819444, 0.29899691,\n",
       "                     0.30414095, 0.30864198, 0.3119856 , 0.31622942, 0.32034465,\n",
       "                     0.33024691, 0.33693416, 0.34040638, 0.3433642 , 0.36432613,\n",
       "                     0.36805556, 0.37615741, 0.38734568, 0.40110597, 0.40534979,\n",
       "                     0.41640947, 0.42078189, 0.42399691, 0.46206276, 0.46489198,\n",
       "                     0.46733539, 0.469393  , 0.47505144, 0.47903807, 0.50681584,\n",
       "                     0.51401749, 0.51466049, 0.55349794, 0.56044239, 0.56610082,\n",
       "                     0.57201646, 0.58127572, 0.58706276, 0.59709362, 0.60159465,\n",
       "                     0.61432613, 0.61689815, 0.62692901, 0.63181584, 0.64801955,\n",
       "                     0.66525206, 0.66923868, 0.68248457, 0.70460391, 0.71090535,\n",
       "                     0.73341049, 0.73585391, 0.74614198, 0.7496142 , 0.75398663,\n",
       "                     0.75810185, 0.76208848, 0.77379115, 0.77970679, 0.78253601,\n",
       "                     0.79411008, 0.7970679 , 0.80349794, 0.80658436, 0.80902778,\n",
       "                     0.81340021, 0.81880144, 0.82445988, 0.8281893 , 0.83526235,\n",
       "                     0.84066358, 0.84207819, 0.8445216 , 0.84953704, 0.85712449,\n",
       "                     0.86072531, 0.86445473, 0.86985597, 0.89364712, 0.90354938,\n",
       "                     0.90522119, 0.90805041, 0.91152263, 0.91345165, 0.91499486,\n",
       "                     0.91833848, 0.92103909, 0.92631173, 0.92952675, 0.93081276,\n",
       "                     0.93351337, 0.93492798, 0.93659979, 0.95974794, 0.96231996,\n",
       "                     0.96424897, 0.968107  , 0.9691358 , 0.97325103, 0.97453704,\n",
       "                     0.97569444, 0.97878086, 0.98238169, 0.98829733, 0.98868313,\n",
       "                     0.98932613, 0.99164095, 0.99356996, 0.99459877, 0.99498457,\n",
       "                     0.99562757, 0.99665638, 0.99704218, 0.99755658, 0.99807099,\n",
       "                     0.99832819, 0.99871399, 0.9994856 , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.84662808e-02, -5.26437335e-02,\n",
       "                     -6.31789016e-02, -7.06175672e-02, -7.69610411e-02, -8.22380982e-02,\n",
       "                     -8.70113770e-02, -9.53101798e-02, -1.17783036e-01, -1.22602322e-01,\n",
       "                     -1.25577307e-01, -1.33531393e-01, -1.38150338e-01, -1.43100844e-01,\n",
       "                     -1.54150680e-01, -1.59630146e-01, -1.62518929e-01, -1.67054085e-01,\n",
       "                     -1.71850257e-01, -1.78482780e-01, -1.82321557e-01, -1.91055237e-01,\n",
       "                     -1.98450939e-01, -2.04567166e-01, -2.04939645e-01, -2.05852054e-01,\n",
       "                     -2.07639365e-01, -2.13574100e-01, -2.23143551e-01, -2.28841572e-01,\n",
       "                     -2.38411023e-01, -2.41162057e-01, -2.47836164e-01, -2.51314428e-01,\n",
       "                     -2.53448901e-01, -2.59511195e-01, -2.65703166e-01, -2.67541965e-01,\n",
       "                     -2.70290330e-01, -2.75705881e-01, -2.79024010e-01, -2.82998223e-01,\n",
       "                     -2.87682072e-01, -2.99242895e-01, -3.02280872e-01, -3.07484700e-01,\n",
       "                     -3.08577108e-01, -3.10154928e-01, -3.13657559e-01, -3.18453731e-01,\n",
       "                     -3.26684230e-01, -3.27212911e-01, -3.28504067e-01, -3.31357136e-01,\n",
       "                     -3.36472237e-01, -3.36945162e-01, -3.41749294e-01, -3.42944751e-01,\n",
       "                     -3.45745873e-01, -3.48306694e-01, -3.52220594e-01, -3.52821375e-01,\n",
       "                     -3.56674944e-01, -3.67724780e-01, -3.71563556e-01, -3.79489622e-01,\n",
       "                     -3.87765531e-01, -3.89464767e-01, -3.90427231e-01, -3.94654192e-01,\n",
       "                     -4.02223614e-01, -4.05465108e-01, -4.12244795e-01, -4.14943852e-01,\n",
       "                     -4.22856851e-01, -4.38254931e-01, -4.41832752e-01, -4.43931389e-01,\n",
       "                     -4.46287103e-01, -4.57833094e-01, -4.58953793e-01, -4.61818045e-01,\n",
       "                     -4.64305608e-01, -4.70003629e-01, -4.75423697e-01, -4.82426149e-01,\n",
       "                     -4.85507816e-01, -4.89548225e-01, -4.98991166e-01, -5.10825624e-01,\n",
       "                     -5.19875459e-01, -5.24524468e-01, -5.35961597e-01, -5.38996501e-01,\n",
       "                     -5.46543706e-01, -5.52068582e-01, -5.55946059e-01, -5.57191544e-01,\n",
       "                     -5.59615788e-01, -5.64529803e-01, -5.66395475e-01, -5.66541556e-01,\n",
       "                     -5.68849464e-01, -5.70544858e-01, -5.72519193e-01, -5.75364145e-01,\n",
       "                     -5.87786665e-01, -6.06135804e-01, -6.13104473e-01, -6.19039208e-01,\n",
       "                     -6.30233355e-01, -6.31271777e-01, -6.41853886e-01, -6.44357016e-01,\n",
       "                     -6.46627165e-01, -6.53926467e-01, -6.93147181e-01, -7.17839793e-01,\n",
       "                     -7.25937003e-01, -7.41937345e-01, -7.53771802e-01, -7.82759339e-01,\n",
       "                     -7.88457360e-01, -7.98507696e-01, -8.10930216e-01, -8.26678573e-01,\n",
       "                     -8.34797698e-01, -8.47297860e-01, -8.75468737e-01, -9.16290732e-01,\n",
       "                     -9.55511445e-01, -9.65080896e-01, -9.80829253e-01, -1.09861229e+00,\n",
       "                     -1.13943428e+00, -1.20397280e+00, -1.25276297e+00, -1.38629436e+00,\n",
       "                     -1.50407740e+00, -1.54044504e+00, -1.60943791e+00, -1.94591015e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5257269322109799, privacy_risk=0.5228868171178314, accuracy=0.5224654377880185, tpr_ind=0.6143261316872428, tnr_ind=0.43144750254841996, test_train_ratio=1.0092592592592593, dataset_size=[7776, 7848]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.10074245, 0.1031746 , 0.11443932, 0.12467998,\n",
       "                     0.12608807, 0.12916027, 0.13184844, 0.13671275, 0.13760881,\n",
       "                     0.13952893, 0.13952893, 0.14132104, 0.14989759, 0.15104967,\n",
       "                     0.15143369, 0.15424987, 0.1578341 , 0.15885817, 0.16986687,\n",
       "                     0.18625192, 0.18868408, 0.19188428, 0.19406042, 0.19636457,\n",
       "                     0.19930876, 0.20327701, 0.20481311, 0.20980543, 0.21889401,\n",
       "                     0.2203021 , 0.22311828, 0.22542243, 0.23399898, 0.27060932,\n",
       "                     0.27457757, 0.28097798, 0.3031234 , 0.30760369, 0.31118792,\n",
       "                     0.31746032, 0.32411674, 0.35970302, 0.36751152, 0.3766001 ,\n",
       "                     0.3922171 , 0.40949821, 0.42101895, 0.42690732, 0.43061956,\n",
       "                     0.43292371, 0.46006144, 0.46198157, 0.46786994, 0.47414235,\n",
       "                     0.47849462, 0.4813108 , 0.48886329, 0.51689708, 0.51779314,\n",
       "                     0.53533026, 0.54288274, 0.54480287, 0.55696365, 0.56080389,\n",
       "                     0.56810036, 0.57232463, 0.5843574 , 0.58806964, 0.59318996,\n",
       "                     0.59754224, 0.60714286, 0.6172555 , 0.63568868, 0.64925755,\n",
       "                     0.65373784, 0.66180236, 0.66743472, 0.66833077, 0.68394777,\n",
       "                     0.69201229, 0.71774194, 0.72017409, 0.72222222, 0.72478239,\n",
       "                     0.73182284, 0.73463902, 0.73771121, 0.74308756, 0.75089606,\n",
       "                     0.75230415, 0.76280082, 0.7703533 , 0.77214542, 0.79518689,\n",
       "                     0.80145929, 0.80325141, 0.84357399, 0.84920635, 0.85355863,\n",
       "                     0.90348182, 0.90501792, 0.9078341 , 0.90898618, 0.9125704 ,\n",
       "                     0.91628264, 0.91730671, 0.92063492, 0.92140297, 0.92268305,\n",
       "                     0.92460317, 0.93215566, 0.93561188, 0.94188428, 0.95071685,\n",
       "                     0.95289299, 0.96044547, 0.96082949, 0.96313364, 0.96530978,\n",
       "                     0.96646185, 0.96953405, 0.9703021 , 0.9733743 , 0.97631848,\n",
       "                     0.97785458, 0.97951869, 0.98297491, 0.98412698, 0.9889913 ,\n",
       "                     0.98950333, 0.99001536, 0.99039939, 0.99078341, 0.99180748,\n",
       "                     1.        ]), tpr=array([0.        , 0.10560676, 0.10803891, 0.12083973, 0.13095238,\n",
       "                     0.1328725 , 0.13632873, 0.13799283, 0.14439324, 0.14592934,\n",
       "                     0.14733743, 0.14861751, 0.15104967, 0.16013825, 0.16218638,\n",
       "                     0.16397849, 0.16653866, 0.17153098, 0.17229903, 0.1812596 ,\n",
       "                     0.19828469, 0.20110087, 0.20519713, 0.2078853 , 0.21172555,\n",
       "                     0.21607783, 0.22286226, 0.22644649, 0.23169483, 0.24091142,\n",
       "                     0.24308756, 0.24577573, 0.24897593, 0.26216078, 0.30107527,\n",
       "                     0.30517153, 0.30913978, 0.33026114, 0.33448541, 0.33678955,\n",
       "                     0.34306196, 0.34946237, 0.38568868, 0.39541731, 0.40424987,\n",
       "                     0.42153098, 0.4390681 , 0.45084485, 0.45737327, 0.46134153,\n",
       "                     0.46313364, 0.48937532, 0.4921915 , 0.4984639 , 0.50435228,\n",
       "                     0.50947261, 0.51484895, 0.52150538, 0.54761905, 0.54825909,\n",
       "                     0.56323605, 0.57053251, 0.57142857, 0.58269329, 0.5874296 ,\n",
       "                     0.59498208, 0.59959037, 0.61290323, 0.61571941, 0.62096774,\n",
       "                     0.62442396, 0.63760881, 0.64695341, 0.66538658, 0.67895545,\n",
       "                     0.68343574, 0.69086022, 0.69649258, 0.69790067, 0.71287762,\n",
       "                     0.72222222, 0.74577573, 0.74923195, 0.75243216, 0.75448029,\n",
       "                     0.76075269, 0.76318484, 0.76728111, 0.77240143, 0.78046595,\n",
       "                     0.78251408, 0.79313876, 0.80043523, 0.80184332, 0.82322069,\n",
       "                     0.82821301, 0.83064516, 0.8703277 , 0.87365591, 0.8781362 ,\n",
       "                     0.92460317, 0.9265233 , 0.92908346, 0.93074757, 0.93330773,\n",
       "                     0.93676395, 0.93817204, 0.94252432, 0.94342038, 0.9453405 ,\n",
       "                     0.94662058, 0.95327701, 0.9562212 , 0.95993344, 0.96671787,\n",
       "                     0.96953405, 0.97555044, 0.97695853, 0.97823861, 0.97977471,\n",
       "                     0.9813108 , 0.98297491, 0.98361495, 0.98630312, 0.98860727,\n",
       "                     0.98963134, 0.99091142, 0.99359959, 0.99500768, 0.99795187,\n",
       "                     0.99833589, 0.99897593, 0.99923195, 0.99961598, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.12932944e-02, -5.82689081e-02,\n",
       "                     -6.13689464e-02, -6.45385211e-02, -7.14589640e-02, -7.41079722e-02,\n",
       "                     -7.69610411e-02, -8.00427077e-02, -8.70113770e-02, -9.53101798e-02,\n",
       "                     -1.00083459e-01, -1.06767975e-01, -1.17783036e-01, -1.33531393e-01,\n",
       "                     -1.39761942e-01, -1.43100844e-01, -1.54150680e-01, -1.58224005e-01,\n",
       "                     -1.65896677e-01, -1.67054085e-01, -1.71850257e-01, -1.74353387e-01,\n",
       "                     -1.82321557e-01, -1.87211542e-01, -1.88591170e-01, -1.94156014e-01,\n",
       "                     -1.98450939e-01, -2.00670695e-01, -2.11309094e-01, -2.13574100e-01,\n",
       "                     -2.15111380e-01, -2.17301276e-01, -2.20508504e-01, -2.23143551e-01,\n",
       "                     -2.29574442e-01, -2.31592606e-01, -2.41162057e-01, -2.45122458e-01,\n",
       "                     -2.51314428e-01, -2.62364264e-01, -2.65349746e-01, -2.74436846e-01,\n",
       "                     -2.87682072e-01, -2.93222253e-01, -2.94954832e-01, -2.98492989e-01,\n",
       "                     -3.02280872e-01, -3.03682414e-01, -3.05381650e-01, -3.08201803e-01,\n",
       "                     -3.10154928e-01, -3.12872321e-01, -3.14493330e-01, -3.18453731e-01,\n",
       "                     -3.22773392e-01, -3.25422400e-01, -3.30854244e-01, -3.36472237e-01,\n",
       "                     -3.43771539e-01, -3.51397887e-01, -3.56674944e-01, -3.58945092e-01,\n",
       "                     -3.59374001e-01, -3.65113813e-01, -3.67724780e-01, -3.72888938e-01,\n",
       "                     -3.74693449e-01, -3.80772496e-01, -3.93042588e-01, -3.95708933e-01,\n",
       "                     -4.00888441e-01, -4.05465108e-01, -4.11734721e-01, -4.14943852e-01,\n",
       "                     -4.16893804e-01, -4.20502985e-01, -4.35318071e-01, -4.36323096e-01,\n",
       "                     -4.36928378e-01, -4.41056053e-01, -4.41832752e-01, -4.44685821e-01,\n",
       "                     -4.46287103e-01, -4.51985124e-01, -4.56758402e-01, -4.66089730e-01,\n",
       "                     -4.70003629e-01, -4.81838087e-01, -4.85507816e-01, -4.86434171e-01,\n",
       "                     -4.89548225e-01, -4.92476485e-01, -4.95134294e-01, -5.10825624e-01,\n",
       "                     -5.21296924e-01, -5.24919387e-01, -5.26093096e-01, -5.38996501e-01,\n",
       "                     -5.40143685e-01, -5.50046337e-01, -5.59615788e-01, -5.70544858e-01,\n",
       "                     -5.87786665e-01, -5.95983432e-01, -5.97837001e-01, -6.16774202e-01,\n",
       "                     -6.19039208e-01, -6.24154309e-01, -6.41853886e-01, -6.43876132e-01,\n",
       "                     -6.71168274e-01, -6.75755438e-01, -6.93147181e-01, -7.59105148e-01,\n",
       "                     -7.64972915e-01, -7.80158558e-01, -7.88457360e-01, -8.10930216e-01,\n",
       "                     -8.47297860e-01, -8.69037847e-01, -8.75468737e-01, -8.87303195e-01,\n",
       "                     -8.93817876e-01, -9.16290732e-01, -9.55511445e-01, -9.80829253e-01,\n",
       "                     -1.03609193e+00, -1.09861229e+00, -1.20397280e+00, -1.38629436e+00,\n",
       "                     -1.50407740e+00, -1.60943791e+00, -1.79175947e+00, -3.45387764e+01]), auc_score=0.5224436934368305, privacy_risk=0.5167690732206861, accuracy=0.5167690732206861, tpr_ind=0.5148489503328213, tnr_ind=0.5186891961085509, test_train_ratio=1.0, dataset_size=[7812, 7812]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_0.0', fpr=array([0.        , 0.09057278, 0.09605817, 0.10192627, 0.10524302,\n",
       "                     0.10690139, 0.11162138, 0.11774461, 0.1228473 , 0.12692946,\n",
       "                     0.13445593, 0.14057916, 0.14682995, 0.14772292, 0.14950887,\n",
       "                     0.15027427, 0.15308075, 0.1637964 , 0.16583748, 0.16596505,\n",
       "                     0.16902666, 0.18101799, 0.19300931, 0.19989795, 0.20104605,\n",
       "                     0.20193902, 0.20461794, 0.27452481, 0.29825233, 0.31011609,\n",
       "                     0.32006633, 0.32095931, 0.32593443, 0.3408598 , 0.34264575,\n",
       "                     0.35565761, 0.37721648, 0.38231917, 0.39137645, 0.3954586 ,\n",
       "                     0.41472127, 0.42301314, 0.47059574, 0.4769741 , 0.48501084,\n",
       "                     0.4972573 , 0.50580431, 0.51026917, 0.52634265, 0.52787345,\n",
       "                     0.54560531, 0.55568312, 0.56053068, 0.56371986, 0.56741931,\n",
       "                     0.58247225, 0.59178467, 0.63796403, 0.6403878 , 0.64855211,\n",
       "                     0.65633372, 0.65888506, 0.66207424, 0.67202449, 0.70366118,\n",
       "                     0.71271846, 0.72496492, 0.72802653, 0.73006761, 0.73121572,\n",
       "                     0.73759408, 0.75328486, 0.76183187, 0.77305779, 0.77586427,\n",
       "                     0.78288047, 0.79933665, 0.81732364, 0.81821661, 0.82038525,\n",
       "                     0.82166093, 0.8240847 , 0.83288685, 0.83569333, 0.83747927,\n",
       "                     0.83811711, 0.86541651, 0.86745758, 0.87523919, 0.87970404,\n",
       "                     0.88863375, 0.89182294, 0.89411915, 0.89628779, 0.89909427,\n",
       "                     0.90508993, 0.90687588, 0.90993749, 0.91274397, 0.91376451,\n",
       "                     0.91452991, 0.91669856, 0.92294936, 0.92448016, 0.93187907,\n",
       "                     0.93736446, 0.94080878, 0.94233958, 0.94412553, 0.94871795,\n",
       "                     0.951652  , 0.95331037, 0.95547902, 0.95662712, 0.95956117,\n",
       "                     0.96262278, 0.96338819, 0.96504656, 0.96708764, 0.96836331,\n",
       "                     0.96861845, 0.96963898, 0.97168006, 0.97397627, 0.97742059,\n",
       "                     0.98290598, 0.98379895, 0.98545733, 0.98609517, 0.9863503 ,\n",
       "                     0.98851894, 0.98864651, 0.98979462, 1.        ]), tpr=array([0.        , 0.09569685, 0.10057803, 0.10597303, 0.11085421,\n",
       "                     0.11316635, 0.11997431, 0.12434168, 0.12960822, 0.13590238,\n",
       "                     0.14348105, 0.14990366, 0.15594091, 0.15709698, 0.16017983,\n",
       "                     0.161079  , 0.16454721, 0.17546564, 0.17713552, 0.17790623,\n",
       "                     0.1820167 , 0.19666024, 0.20976236, 0.21746949, 0.21926782,\n",
       "                     0.2209377 , 0.22504817, 0.29569685, 0.32305716, 0.33371869,\n",
       "                     0.34425177, 0.3460501 , 0.35144509, 0.36570328, 0.36891458,\n",
       "                     0.38381503, 0.40770713, 0.41335902, 0.42042389, 0.42222222,\n",
       "                     0.44071933, 0.45022479, 0.50160565, 0.50777136, 0.5135517 ,\n",
       "                     0.52601156, 0.53500321, 0.53975594, 0.55465639, 0.55709698,\n",
       "                     0.57122672, 0.5820167 , 0.58728324, 0.59165061, 0.59627489,\n",
       "                     0.61066153, 0.62260758, 0.66229929, 0.66422608, 0.67296082,\n",
       "                     0.68220938, 0.68464997, 0.6896596 , 0.69967887, 0.7344894 ,\n",
       "                     0.74155427, 0.75722543, 0.75979448, 0.76210662, 0.76416185,\n",
       "                     0.76955684, 0.78330122, 0.79267823, 0.80179833, 0.80500963,\n",
       "                     0.81117534, 0.82530507, 0.84649968, 0.8475273 , 0.85035324,\n",
       "                     0.85215157, 0.85472062, 0.86435453, 0.86679512, 0.86949261,\n",
       "                     0.87090559, 0.89672447, 0.8987797 , 0.90301863, 0.90674374,\n",
       "                     0.9135517 , 0.91701991, 0.91894669, 0.92164419, 0.92447013,\n",
       "                     0.93089274, 0.93307643, 0.93538857, 0.93782916, 0.93962749,\n",
       "                     0.94065511, 0.94296724, 0.94784843, 0.9492614 , 0.95709698,\n",
       "                     0.9613359 , 0.96377649, 0.96570328, 0.96750161, 0.97135517,\n",
       "                     0.97302505, 0.97508028, 0.97752087, 0.9793192 , 0.98124599,\n",
       "                     0.98355812, 0.98420039, 0.98574181, 0.98702633, 0.9879255 ,\n",
       "                     0.98856776, 0.98895311, 0.99049454, 0.99177906, 0.99332049,\n",
       "                     0.99666024, 0.9973025 , 0.99781631, 0.99820167, 0.99871548,\n",
       "                     0.99935774, 0.99948619, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.59754864e-02, -4.65200156e-02,\n",
       "                     -5.12932944e-02, -5.40672213e-02, -5.50597772e-02, -5.71584138e-02,\n",
       "                     -7.06175672e-02, -7.84716154e-02, -8.13456395e-02, -9.53101798e-02,\n",
       "                     -1.01096117e-01, -1.05360516e-01, -1.17783036e-01, -1.33531393e-01,\n",
       "                     -1.38150338e-01, -1.42316222e-01, -1.43100844e-01, -1.54150680e-01,\n",
       "                     -1.71850257e-01, -1.76456437e-01, -1.79048231e-01, -1.82321557e-01,\n",
       "                     -1.94156014e-01, -2.07639365e-01, -2.23143551e-01, -2.26773319e-01,\n",
       "                     -2.37129793e-01, -2.44598486e-01, -2.47241103e-01, -2.51314428e-01,\n",
       "                     -2.69663567e-01, -2.74076420e-01, -2.77631737e-01, -2.83362411e-01,\n",
       "                     -2.87682072e-01, -2.93347810e-01, -2.96731908e-01, -3.05381650e-01,\n",
       "                     -3.08301360e-01, -3.11055424e-01, -3.14810740e-01, -3.18453731e-01,\n",
       "                     -3.20471895e-01, -3.23128821e-01, -3.26215736e-01, -3.40325806e-01,\n",
       "                     -3.46276237e-01, -3.51397887e-01, -3.55765440e-01, -3.56674944e-01,\n",
       "                     -3.63965377e-01, -3.65459773e-01, -3.67724780e-01, -3.75251330e-01,\n",
       "                     -3.80055393e-01, -3.80340903e-01, -3.82992252e-01, -3.85662481e-01,\n",
       "                     -3.86772975e-01, -3.87765531e-01, -3.96881364e-01, -4.05465108e-01,\n",
       "                     -4.18904528e-01, -4.23483614e-01, -4.37725970e-01, -4.38254931e-01,\n",
       "                     -4.41832752e-01, -4.46287103e-01, -4.51985124e-01, -4.57069880e-01,\n",
       "                     -4.63130750e-01, -4.64707942e-01, -4.70003629e-01, -4.72604411e-01,\n",
       "                     -4.75669367e-01, -4.81303184e-01, -4.85507816e-01, -4.92476485e-01,\n",
       "                     -4.96436886e-01, -5.00775288e-01, -5.10825624e-01, -5.21296924e-01,\n",
       "                     -5.38996501e-01, -5.46543706e-01, -5.54628246e-01, -5.59615788e-01,\n",
       "                     -5.63935449e-01, -5.64529803e-01, -5.73002869e-01, -5.75364145e-01,\n",
       "                     -5.87786665e-01, -5.93063722e-01, -5.97837001e-01, -5.98836501e-01,\n",
       "                     -6.00773860e-01, -6.06135804e-01, -6.10909082e-01, -6.19039208e-01,\n",
       "                     -6.28608659e-01, -6.35988767e-01, -6.39079959e-01, -6.46627165e-01,\n",
       "                     -6.93147181e-01, -7.08185058e-01, -7.19122667e-01, -7.25937003e-01,\n",
       "                     -7.62140052e-01, -7.73189888e-01, -8.02346473e-01, -8.10930216e-01,\n",
       "                     -8.16761137e-01, -8.26678573e-01, -8.47297860e-01, -8.70828358e-01,\n",
       "                     -8.75468737e-01, -8.82389180e-01, -9.16290732e-01, -9.44461609e-01,\n",
       "                     -9.55511445e-01, -9.80829253e-01, -1.01160091e+00, -1.02961942e+00,\n",
       "                     -1.04145387e+00, -1.09861229e+00, -1.16315081e+00, -1.25276297e+00,\n",
       "                     -1.29928298e+00, -1.38629436e+00, -1.60943791e+00, -1.79175947e+00,\n",
       "                     -1.94591015e+00, -3.45387764e+01]), auc_score=0.522544040825466, privacy_risk=0.5164730667103198, accuracy=0.5156169994879672, tpr_ind=0.7641618497109827, tnr_ind=0.26878428370965685, test_train_ratio=1.0069364161849712, dataset_size=[7785, 7839])],\n",
       "             'entire_dataset_label_1.0_mia_auc': [0.5553982812116673,\n",
       "              0.546461551939128,\n",
       "              0.5674998814504788,\n",
       "              0.5622132513170053,\n",
       "              0.5517200792953502,\n",
       "              0.5665582568156841,\n",
       "              0.5522504846058378,\n",
       "              0.5556529575415199,\n",
       "              0.5576616187270315,\n",
       "              0.5642027820970703,\n",
       "              0.5541998909665977,\n",
       "              0.5668164604154705,\n",
       "              0.5540931640518171,\n",
       "              0.5674613516292593,\n",
       "              0.5679875963962718,\n",
       "              0.5644728438186595,\n",
       "              0.547807237373019,\n",
       "              0.564798563322441,\n",
       "              0.5633517272760388,\n",
       "              0.5610551958527061],\n",
       "             'entire_dataset_label_1.0_mia_privacy_risk': [0.5401839715418966,\n",
       "              0.5320293588010123,\n",
       "              0.548070035954851,\n",
       "              0.5449118462750504,\n",
       "              0.5336409645727895,\n",
       "              0.5465056546247385,\n",
       "              0.5360226257814825,\n",
       "              0.538801310822512,\n",
       "              0.540121889036324,\n",
       "              0.542139779868528,\n",
       "              0.539313091338031,\n",
       "              0.5469187673207611,\n",
       "              0.5365804133743355,\n",
       "              0.5487759280927561,\n",
       "              0.5451097990153521,\n",
       "              0.5450125501240386,\n",
       "              0.5316012544886257,\n",
       "              0.5447278906288433,\n",
       "              0.5449538553140816,\n",
       "              0.5445082640262248],\n",
       "             'entire_dataset_label_1.0_mia_ppv': [0.706896551724138,\n",
       "              0.7156862745098039,\n",
       "              0.6442953020134228,\n",
       "              0.7340425531914894,\n",
       "              0.7111111111111111,\n",
       "              0.6637168141592921,\n",
       "              0.6415094339622642,\n",
       "              0.6232876712328768,\n",
       "              0.6724137931034484,\n",
       "              0.6699507389162561,\n",
       "              0.7090909090909091,\n",
       "              0.71,\n",
       "              0.7311827956989247,\n",
       "              0.7155963302752294,\n",
       "              0.6917808219178082,\n",
       "              0.7407407407407407,\n",
       "              0.7123287671232877,\n",
       "              0.7792207792207793,\n",
       "              0.7653061224489797,\n",
       "              0.6850828729281767],\n",
       "             'entire_dataset_label_1.0_mia_attacker_advantage': [0.08036794308379314,\n",
       "              0.0640587176020247,\n",
       "              0.09614007190970197,\n",
       "              0.08982369255010081,\n",
       "              0.06728192914557907,\n",
       "              0.09301130924947709,\n",
       "              0.07204525156296515,\n",
       "              0.07760262164502407,\n",
       "              0.08024377807264793,\n",
       "              0.08427955973705603,\n",
       "              0.0786261826760618,\n",
       "              0.093837534641522,\n",
       "              0.07316082674867097,\n",
       "              0.09755185618551221,\n",
       "              0.09021959803070406,\n",
       "              0.0900251002480772,\n",
       "              0.06320250897725144,\n",
       "              0.08945578125768672,\n",
       "              0.08990771062816316,\n",
       "              0.08901652805244953],\n",
       "             'entire_dataset_label_1.0_mia_result': [MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.01010101, 0.0130719 , 0.01485443, 0.0154486 ,\n",
       "                     0.02198455, 0.02228164, 0.02376708, 0.0258467 , 0.03743316,\n",
       "                     0.04010695, 0.04456328, 0.05109923, 0.05585264, 0.06030897,\n",
       "                     0.0620915 , 0.06535948, 0.06892454, 0.07100416, 0.0802139 ,\n",
       "                     0.08229352, 0.0959596 , 0.10606061, 0.11675579, 0.1191325 ,\n",
       "                     0.12269756, 0.12923351, 0.13606655, 0.15181224, 0.15983363,\n",
       "                     0.16131907, 0.16607249, 0.16874629, 0.17498515, 0.18746286,\n",
       "                     0.19548425, 0.19786096, 0.21271539, 0.22489602, 0.23262032,\n",
       "                     0.23856209, 0.24509804, 0.25311943, 0.26054664, 0.27956031,\n",
       "                     0.28104575, 0.29055258, 0.29144385, 0.29560309, 0.30124777,\n",
       "                     0.3057041 , 0.32293523, 0.32798574, 0.33214498, 0.33452169,\n",
       "                     0.35026738, 0.35294118, 0.35710042, 0.36185383, 0.3627451 ,\n",
       "                     0.36838978, 0.38680927, 0.39572193, 0.40493167, 0.40968509,\n",
       "                     0.41325015, 0.41859774, 0.43612597, 0.44444444, 0.45216875,\n",
       "                     0.45900178, 0.4637552 , 0.47029115, 0.4845514 , 0.50386215,\n",
       "                     0.51426025, 0.533571  , 0.5362448 , 0.54367201, 0.55139632,\n",
       "                     0.55228758, 0.55941771, 0.56387403, 0.590612  , 0.59952466,\n",
       "                     0.60398099, 0.62774807, 0.63279857, 0.64379085, 0.64676173,\n",
       "                     0.65329768, 0.66458705, 0.67795603, 0.6969697 , 0.70112894,\n",
       "                     0.71093286, 0.71598336, 0.73529412, 0.74064171, 0.74480095,\n",
       "                     0.75074272, 0.75460487, 0.76084373, 0.77807487, 0.78698752,\n",
       "                     0.79738562, 0.80540701, 0.8134284 , 0.81937017, 0.82293523,\n",
       "                     0.84729649, 0.84997029, 0.85145573, 0.87076649, 0.87849079,\n",
       "                     0.88116459, 0.88443256, 0.89512775, 0.89750446, 0.90255496,\n",
       "                     0.90612002, 0.91592395, 0.91770648, 0.91770648, 0.91830065,\n",
       "                     0.92364825, 0.92929293, 0.93493761, 0.93820559, 0.9483066 ,\n",
       "                     0.94860368, 0.95008913, 0.95365419, 0.96405229, 0.966429  ,\n",
       "                     0.96939988, 0.97029115, 0.9714795 , 0.97385621, 0.97445039,\n",
       "                     0.97504456, 1.        ]), tpr=array([0.        , 0.02446301, 0.02774463, 0.03042959, 0.03162291,\n",
       "                     0.03788783, 0.03937947, 0.04355609, 0.04624105, 0.06175418,\n",
       "                     0.06443914, 0.07040573, 0.08114558, 0.0874105 , 0.09427208,\n",
       "                     0.09665871, 0.09934368, 0.10381862, 0.10739857, 0.11754177,\n",
       "                     0.11963007, 0.13842482, 0.14588305, 0.15662291, 0.15960621,\n",
       "                     0.16318616, 0.17094272, 0.17661098, 0.20167064, 0.20972554,\n",
       "                     0.2124105 , 0.21658711, 0.21837709, 0.22494033, 0.23389021,\n",
       "                     0.24194511, 0.24582339, 0.26342482, 0.27714797, 0.2875895 ,\n",
       "                     0.29355609, 0.30101432, 0.30817422, 0.31145585, 0.33830549,\n",
       "                     0.33979714, 0.35053699, 0.3526253 , 0.35739857, 0.36396181,\n",
       "                     0.36634845, 0.37977327, 0.38544153, 0.38902148, 0.39051313,\n",
       "                     0.4146778 , 0.41646778, 0.41855609, 0.42303103, 0.42422434,\n",
       "                     0.42929594, 0.44540573, 0.45495227, 0.46330549, 0.46778043,\n",
       "                     0.47106205, 0.47792363, 0.49880668, 0.50596659, 0.51133652,\n",
       "                     0.51760143, 0.52505967, 0.53341289, 0.55220764, 0.57249403,\n",
       "                     0.58293556, 0.60352029, 0.60680191, 0.61366348, 0.62231504,\n",
       "                     0.625     , 0.63156325, 0.63663484, 0.6676611 , 0.6798926 ,\n",
       "                     0.68406921, 0.70286396, 0.70614558, 0.71688544, 0.71986874,\n",
       "                     0.73001193, 0.73806683, 0.75      , 0.76282816, 0.76700477,\n",
       "                     0.77834129, 0.78162291, 0.79803103, 0.80817422, 0.81175418,\n",
       "                     0.81622912, 0.82100239, 0.82816229, 0.84695704, 0.85948687,\n",
       "                     0.86455847, 0.86873508, 0.87231504, 0.87649165, 0.88036993,\n",
       "                     0.90930788, 0.91139618, 0.9125895 , 0.92601432, 0.93198091,\n",
       "                     0.93436754, 0.93764916, 0.94838902, 0.950179  , 0.95286396,\n",
       "                     0.95584726, 0.96211217, 0.96390215, 0.96509547, 0.96628878,\n",
       "                     0.96897375, 0.974642  , 0.9797136 , 0.98180191, 0.98747017,\n",
       "                     0.98806683, 0.98866348, 0.99045346, 0.99433174, 0.99671838,\n",
       "                     0.99731504, 0.99761337, 0.99821002, 0.99910501, 0.99940334,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -8.70113770e-02, -2.00670695e-01,\n",
       "                     -2.23143551e-01, -2.87682072e-01, -3.36472237e-01, -3.56674944e-01,\n",
       "                     -3.67724780e-01, -4.05465108e-01, -4.41832752e-01, -4.70003629e-01,\n",
       "                     -5.10825624e-01, -5.38996501e-01, -5.53385238e-01, -5.59615788e-01,\n",
       "                     -5.75364145e-01, -5.87786665e-01, -6.06135804e-01, -6.16774202e-01,\n",
       "                     -6.19039208e-01, -6.27549898e-01, -6.31271777e-01, -6.35988767e-01,\n",
       "                     -6.41853886e-01, -6.50587566e-01, -6.53926467e-01, -6.66478933e-01,\n",
       "                     -6.93147181e-01, -7.11496319e-01, -7.47214402e-01, -7.62140052e-01,\n",
       "                     -7.73189888e-01, -7.80158558e-01, -7.88457360e-01, -7.98507696e-01,\n",
       "                     -8.02346473e-01, -8.05264479e-01, -8.25318954e-01, -8.26678573e-01,\n",
       "                     -8.32909123e-01, -8.41567186e-01, -8.47297860e-01, -8.60201265e-01,\n",
       "                     -8.66166345e-01, -8.75468737e-01, -8.82389180e-01, -8.87303195e-01,\n",
       "                     -8.90972924e-01, -8.97941593e-01, -9.16290732e-01, -9.29535959e-01,\n",
       "                     -9.47381319e-01, -9.49080555e-01, -9.55511445e-01, -9.62137120e-01,\n",
       "                     -9.80829253e-01, -9.98528830e-01, -1.00552187e+00, -1.01160091e+00,\n",
       "                     -1.01693426e+00, -1.02165125e+00, -1.02290047e+00, -1.02450432e+00,\n",
       "                     -1.02961942e+00, -1.03609193e+00, -1.05416053e+00, -1.05480967e+00,\n",
       "                     -1.05605267e+00, -1.06087196e+00, -1.08261195e+00, -1.08518927e+00,\n",
       "                     -1.08663610e+00, -1.09330724e+00, -1.09861229e+00, -1.10809103e+00,\n",
       "                     -1.12718566e+00, -1.12846525e+00, -1.14117190e+00, -1.14356368e+00,\n",
       "                     -1.17007125e+00, -1.17163742e+00, -1.17411984e+00, -1.17569203e+00,\n",
       "                     -1.17677706e+00, -1.18958407e+00, -1.20397280e+00, -1.21302264e+00,\n",
       "                     -1.22050211e+00, -1.22377543e+00, -1.25276297e+00, -1.25804003e+00,\n",
       "                     -1.25988044e+00, -1.26923781e+00, -1.27296568e+00, -1.28966753e+00,\n",
       "                     -1.29098418e+00, -1.32538561e+00, -1.34117393e+00, -1.34373475e+00,\n",
       "                     -1.35239281e+00, -1.35454566e+00, -1.36524095e+00, -1.37029402e+00,\n",
       "                     -1.38629436e+00, -1.40089316e+00, -1.40399394e+00, -1.40691365e+00,\n",
       "                     -1.43848011e+00, -1.44238383e+00, -1.45597428e+00, -1.48807706e+00,\n",
       "                     -1.50407740e+00, -1.52121368e+00, -1.52605630e+00, -1.53147637e+00,\n",
       "                     -1.53393036e+00, -1.56977266e+00, -1.57553636e+00, -1.60943791e+00,\n",
       "                     -1.75785792e+00, -1.75949861e+00, -1.79175947e+00, -1.83258146e+00,\n",
       "                     -1.87180218e+00, -1.92990981e+00, -1.93075834e+00, -1.94591015e+00,\n",
       "                     -2.06142304e+00, -2.07944154e+00, -2.14006616e+00, -2.19722458e+00,\n",
       "                     -2.23359222e+00, -2.24723500e+00, -2.30258509e+00, -2.44234704e+00,\n",
       "                     -2.48490665e+00, -2.83321334e+00, -3.06027079e+00, -3.13549422e+00,\n",
       "                     -3.21887582e+00, -3.45387764e+01]), auc_score=0.5553982812116673, privacy_risk=0.5401839715418966, accuracy=0.5398928252456088, tpr_ind=0.6798926014319809, tnr_ind=0.40047534165181226, test_train_ratio=1.0041766109785202, dataset_size=[3352, 3366]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00845728, 0.01108195, 0.01224847, 0.01341499,\n",
       "                     0.01458151, 0.01603966, 0.01749781, 0.02070575, 0.02624672,\n",
       "                     0.02712161, 0.02887139, 0.03003791, 0.03295421, 0.03645378,\n",
       "                     0.04141149, 0.06036745, 0.0656168 , 0.08311461, 0.09419656,\n",
       "                     0.10644503, 0.11811024, 0.1341499 , 0.14552348, 0.14698163,\n",
       "                     0.15106445, 0.15164771, 0.16331292, 0.167979  , 0.17031204,\n",
       "                     0.17381161, 0.17993584, 0.18606008, 0.1872266 , 0.20880723,\n",
       "                     0.20997375, 0.23563721, 0.26888306, 0.2770487 , 0.28113153,\n",
       "                     0.28842228, 0.29396325, 0.29571304, 0.31087781, 0.35433071,\n",
       "                     0.35841353, 0.37212015, 0.3764946 , 0.38174395, 0.38349373,\n",
       "                     0.38728492, 0.39107612, 0.43102945, 0.46602508, 0.46864975,\n",
       "                     0.47769029, 0.48498104, 0.49722951, 0.51414407, 0.52172645,\n",
       "                     0.52522601, 0.54126568, 0.56692913, 0.57363663, 0.5762613 ,\n",
       "                     0.58850977, 0.58996792, 0.60309128, 0.63458734, 0.64071158,\n",
       "                     0.6447944 , 0.64800233, 0.65266842, 0.6602508 , 0.66141732,\n",
       "                     0.67541557, 0.67745698, 0.68299796, 0.6911636 , 0.69378828,\n",
       "                     0.7191601 , 0.72236804, 0.73053368, 0.77544474, 0.77981919,\n",
       "                     0.78361038, 0.78915136, 0.79002625, 0.81598134, 0.82443861,\n",
       "                     0.82968796, 0.83872849, 0.84193642, 0.84660251, 0.85418489,\n",
       "                     0.85535141, 0.85826772, 0.87576553, 0.88101487, 0.89180519,\n",
       "                     0.89355497, 0.90288714, 0.90463692, 0.92680082, 0.93088364,\n",
       "                     0.9314669 , 0.94284048, 0.94779819, 0.9498396 , 0.95042286,\n",
       "                     0.95042286, 0.96150481, 0.96442111, 0.96442111, 0.96733742,\n",
       "                     0.97083698, 0.9720035 , 0.9720035 , 0.97375328, 0.97375328,\n",
       "                     0.97404491, 0.97433654, 0.9749198 , 1.        ]), tpr=array([0.        , 0.0221952 , 0.0270599 , 0.02858012, 0.03131651,\n",
       "                     0.03253268, 0.03526908, 0.03830952, 0.0437823 , 0.05351171,\n",
       "                     0.05655214, 0.05746427, 0.05959258, 0.06445728, 0.06840985,\n",
       "                     0.07601095, 0.09334144, 0.09759805, 0.12070538, 0.131955  ,\n",
       "                     0.14746123, 0.16296747, 0.18029796, 0.19489206, 0.19702037,\n",
       "                     0.20097294, 0.2027972 , 0.21161447, 0.21678322, 0.22043174,\n",
       "                     0.22377622, 0.2298571 , 0.23654606, 0.23837033, 0.2617817 ,\n",
       "                     0.26330192, 0.28792946, 0.31711766, 0.32623898, 0.33110368,\n",
       "                     0.34083308, 0.34813013, 0.35025844, 0.37062937, 0.40772271,\n",
       "                     0.41471572, 0.4326543 , 0.43691092, 0.4451201 , 0.44755245,\n",
       "                     0.45059289, 0.45454545, 0.48951049, 0.52204317, 0.52751596,\n",
       "                     0.53329279, 0.53815749, 0.55305564, 0.56643357, 0.57403466,\n",
       "                     0.57768319, 0.58893281, 0.61842505, 0.6235938 , 0.6257221 ,\n",
       "                     0.63697172, 0.63970812, 0.65034965, 0.68987534, 0.69747644,\n",
       "                     0.70051687, 0.70264518, 0.70598966, 0.70994223, 0.71115841,\n",
       "                     0.72453633, 0.72788081, 0.7333536 , 0.73913043, 0.74217087,\n",
       "                     0.76223776, 0.76497416, 0.77257525, 0.82243843, 0.82730313,\n",
       "                     0.83186379, 0.83551231, 0.83764062, 0.8631803 , 0.87108544,\n",
       "                     0.87838249, 0.88841593, 0.89054424, 0.89540894, 0.90148981,\n",
       "                     0.90301003, 0.90453025, 0.91760413, 0.9215567 , 0.93554272,\n",
       "                     0.93736698, 0.94405594, 0.94557616, 0.96138644, 0.96381879,\n",
       "                     0.96503497, 0.97263606, 0.97476437, 0.97628458, 0.97719672,\n",
       "                     0.9778048 , 0.98783825, 0.98996656, 0.99087869, 0.99270295,\n",
       "                     0.99483126, 0.99726361, 0.99756765, 0.99817574, 0.99847978,\n",
       "                     0.99878382, 0.99969596, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.17783036e-01, -1.82321557e-01,\n",
       "                     -2.00670695e-01, -2.23143551e-01, -2.87682072e-01, -3.36472237e-01,\n",
       "                     -3.67724780e-01, -4.05465108e-01, -4.70003629e-01, -5.10825624e-01,\n",
       "                     -5.38996501e-01, -5.59615788e-01, -5.70544858e-01, -5.87786665e-01,\n",
       "                     -6.01339631e-01, -6.19039208e-01, -6.59699246e-01, -6.65748206e-01,\n",
       "                     -6.93147181e-01, -7.12565266e-01, -7.19122667e-01, -7.43919506e-01,\n",
       "                     -7.62140052e-01, -7.67255153e-01, -7.73189888e-01, -7.75838896e-01,\n",
       "                     -8.04372816e-01, -8.10930216e-01, -8.20980552e-01, -8.32909123e-01,\n",
       "                     -8.40783179e-01, -8.47297860e-01, -8.54691609e-01, -8.75468737e-01,\n",
       "                     -8.83665505e-01, -8.99483614e-01, -9.02867712e-01, -9.16290732e-01,\n",
       "                     -9.28713252e-01, -9.32820034e-01, -9.44461609e-01, -9.54362680e-01,\n",
       "                     -9.58030338e-01, -9.58850346e-01, -9.59415159e-01, -9.71860583e-01,\n",
       "                     -9.80829253e-01, -1.01160091e+00, -1.02961942e+00, -1.04596856e+00,\n",
       "                     -1.05718625e+00, -1.06374346e+00, -1.07992016e+00, -1.08091271e+00,\n",
       "                     -1.09861229e+00, -1.10539198e+00, -1.10615949e+00, -1.12492960e+00,\n",
       "                     -1.12601126e+00, -1.13401422e+00, -1.13571604e+00, -1.13707857e+00,\n",
       "                     -1.14513230e+00, -1.16820558e+00, -1.17007125e+00, -1.17203976e+00,\n",
       "                     -1.18219900e+00, -1.19996478e+00, -1.22377543e+00, -1.23214368e+00,\n",
       "                     -1.23969089e+00, -1.24171313e+00, -1.25276297e+00, -1.25923548e+00,\n",
       "                     -1.26566637e+00, -1.26851133e+00, -1.27506873e+00, -1.28093385e+00,\n",
       "                     -1.28680881e+00, -1.29928298e+00, -1.30291275e+00, -1.31686585e+00,\n",
       "                     -1.32175584e+00, -1.33500107e+00, -1.34373475e+00, -1.34992672e+00,\n",
       "                     -1.35300838e+00, -1.38629436e+00, -1.43706669e+00, -1.43796637e+00,\n",
       "                     -1.48807706e+00, -1.50407740e+00, -1.51512723e+00, -1.52605630e+00,\n",
       "                     -1.56861592e+00, -1.60943791e+00, -1.62470538e+00, -1.64362928e+00,\n",
       "                     -1.73460106e+00, -1.75314463e+00, -1.75785792e+00, -1.79175947e+00,\n",
       "                     -1.81237876e+00, -1.83258146e+00, -1.86872051e+00, -1.94591015e+00,\n",
       "                     -2.00148000e+00, -2.03688193e+00, -2.07944154e+00, -2.13470422e+00,\n",
       "                     -2.16496372e+00, -2.30258509e+00, -2.35137526e+00, -2.39789527e+00,\n",
       "                     -2.55528745e+00, -2.56494936e+00, -2.60268969e+00, -3.17805383e+00,\n",
       "                     -3.21887582e+00, -3.40119738e+00, -4.29045944e+00, -3.45387764e+01]), auc_score=0.546461551939128, privacy_risk=0.5320293588010123, accuracy=0.5337898183983328, tpr_ind=0.44755244755244755, tnr_ind=0.6165062700495771, test_train_ratio=1.0425661295226512, dataset_size=[3289, 3429]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.01093058, 0.01329394, 0.01477105, 0.01506647,\n",
       "                     0.01565731, 0.01772526, 0.02274742, 0.03426883, 0.03751846,\n",
       "                     0.03870015, 0.04106352, 0.04756278, 0.04874446, 0.05169867,\n",
       "                     0.05376662, 0.05553914, 0.0605613 , 0.06469719, 0.06646972,\n",
       "                     0.06794682, 0.09512555, 0.10487445, 0.12703102, 0.1323486 ,\n",
       "                     0.13618907, 0.13707533, 0.14268833, 0.15568685, 0.15982275,\n",
       "                     0.17784343, 0.18286558, 0.18759232, 0.18936484, 0.22599705,\n",
       "                     0.22924668, 0.23574594, 0.23722304, 0.23929099, 0.24254062,\n",
       "                     0.2437223 , 0.26587888, 0.2788774 , 0.30310192, 0.30457903,\n",
       "                     0.30635155, 0.31285081, 0.31432792, 0.32023634, 0.3465288 ,\n",
       "                     0.35509601, 0.35982275, 0.38966027, 0.39379616, 0.43988183,\n",
       "                     0.45199409, 0.47858198, 0.48655835, 0.51580502, 0.52141802,\n",
       "                     0.53707533, 0.54062038, 0.54239291, 0.54682422, 0.55155096,\n",
       "                     0.55332349, 0.55657312, 0.57666174, 0.58966027, 0.59409158,\n",
       "                     0.6127031 , 0.61418021, 0.63190547, 0.64106352, 0.64579025,\n",
       "                     0.65051699, 0.65317578, 0.69837518, 0.70339734, 0.70753323,\n",
       "                     0.71137371, 0.71994092, 0.7211226 , 0.72762186, 0.7338257 ,\n",
       "                     0.7394387 , 0.74859675, 0.75420975, 0.75805022, 0.7648449 ,\n",
       "                     0.78345643, 0.78641064, 0.788774  , 0.80029542, 0.82333826,\n",
       "                     0.82451994, 0.83190547, 0.84815362, 0.84992614, 0.86381093,\n",
       "                     0.86824225, 0.86853767, 0.87208272, 0.87503693, 0.87710487,\n",
       "                     0.88035451, 0.88301329, 0.88301329, 0.88803545, 0.89128508,\n",
       "                     0.89542097, 0.89748892, 0.91432792, 0.91935007, 0.92200886,\n",
       "                     0.92584934, 0.92732644, 0.92850812, 0.92939439, 0.93264402,\n",
       "                     0.93500739, 0.94002954, 0.94209749, 0.94327917, 0.94771049,\n",
       "                     0.94830133, 0.94859675, 0.95332349, 0.95361891, 0.95450517,\n",
       "                     0.95509601, 0.95568685, 0.95834564, 0.95864106, 0.95982275,\n",
       "                     1.        ]), tpr=array([0.        , 0.01920192, 0.02280228, 0.02430243, 0.02670267,\n",
       "                     0.02880288, 0.03180318, 0.04080408, 0.05880588, 0.06210621,\n",
       "                     0.06630663, 0.07080708, 0.07530753, 0.07740774, 0.0810081 ,\n",
       "                     0.08610861, 0.08880888, 0.09330933, 0.10141014, 0.1050105 ,\n",
       "                     0.10711071, 0.13441344, 0.14341434, 0.17011701, 0.17791779,\n",
       "                     0.18121812, 0.1830183 , 0.18781878, 0.20372037, 0.21182118,\n",
       "                     0.23342334, 0.23762376, 0.24212421, 0.24812481, 0.28652865,\n",
       "                     0.28982898, 0.29882988, 0.30123012, 0.30423042, 0.30693069,\n",
       "                     0.31143114, 0.33513351, 0.34833483, 0.37953795, 0.38223822,\n",
       "                     0.38373837, 0.39093909, 0.39273927, 0.39933993, 0.42364236,\n",
       "                     0.43114311, 0.43474347, 0.47044704, 0.47524752, 0.52025203,\n",
       "                     0.53105311, 0.56375638, 0.57215722, 0.59945995, 0.60426043,\n",
       "                     0.62586259, 0.6339634 , 0.63636364, 0.6429643 , 0.64506451,\n",
       "                     0.64836484, 0.64986499, 0.66606661, 0.67926793, 0.68136814,\n",
       "                     0.70027003, 0.70207021, 0.71647165, 0.7269727 , 0.73237324,\n",
       "                     0.73657366, 0.73927393, 0.78037804, 0.78517852, 0.79087909,\n",
       "                     0.79327933, 0.80348035, 0.80528053, 0.81188119, 0.8169817 ,\n",
       "                     0.82118212, 0.83138314, 0.83438344, 0.83888389, 0.84608461,\n",
       "                     0.86258626, 0.86708671, 0.87008701, 0.88358836, 0.90849085,\n",
       "                     0.90939094, 0.91359136, 0.92229223, 0.92409241, 0.93489349,\n",
       "                     0.93879388, 0.93969397, 0.94179418, 0.94419442, 0.94689469,\n",
       "                     0.95109511, 0.95409541, 0.9549955 , 0.95739574, 0.95919592,\n",
       "                     0.9639964 , 0.96549655, 0.97389739, 0.97689769, 0.97989799,\n",
       "                     0.98409841, 0.9849985 , 0.98649865, 0.98739874, 0.98859886,\n",
       "                     0.98949895, 0.99279928, 0.99309931, 0.99369937, 0.99549955,\n",
       "                     0.99579958, 0.99609961, 0.99729973, 0.99759976, 0.99789979,\n",
       "                     0.99819982, 0.99879988, 0.99939994, 0.99969997, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.54150680e-01, -1.82321557e-01,\n",
       "                     -2.23143551e-01, -2.51314428e-01, -2.62364264e-01, -2.87682072e-01,\n",
       "                     -4.05465108e-01, -4.35318071e-01, -4.51985124e-01, -4.70003629e-01,\n",
       "                     -5.10825624e-01, -5.38996501e-01, -5.59615788e-01, -5.67984038e-01,\n",
       "                     -5.75364145e-01, -5.87786665e-01, -5.95983432e-01, -6.06135804e-01,\n",
       "                     -6.19039208e-01, -6.48195793e-01, -6.76340062e-01, -6.93147181e-01,\n",
       "                     -7.30887509e-01, -7.37598943e-01, -7.73189888e-01, -7.82759339e-01,\n",
       "                     -7.83298278e-01, -7.98507696e-01, -8.10930216e-01, -8.26678573e-01,\n",
       "                     -8.47297860e-01, -8.54415328e-01, -8.55080001e-01, -8.60201265e-01,\n",
       "                     -8.61482495e-01, -8.64997437e-01, -8.75468737e-01, -8.93817876e-01,\n",
       "                     -9.02867712e-01, -9.13755876e-01, -9.16290732e-01, -9.20129508e-01,\n",
       "                     -9.38269639e-01, -9.55511445e-01, -9.65080896e-01, -9.80829253e-01,\n",
       "                     -9.86494991e-01, -9.90045908e-01, -1.00063188e+00, -1.01160091e+00,\n",
       "                     -1.01996916e+00, -1.03407377e+00, -1.03437002e+00, -1.04145387e+00,\n",
       "                     -1.04199339e+00, -1.06224464e+00, -1.06887032e+00, -1.07755888e+00,\n",
       "                     -1.07992016e+00, -1.09861229e+00, -1.13943428e+00, -1.14306405e+00,\n",
       "                     -1.14513230e+00, -1.15745279e+00, -1.16315081e+00, -1.17007125e+00,\n",
       "                     -1.17865500e+00, -1.18958407e+00, -1.19440335e+00, -1.20397280e+00,\n",
       "                     -1.21020335e+00, -1.21533656e+00, -1.22050211e+00, -1.23214368e+00,\n",
       "                     -1.23676263e+00, -1.23911446e+00, -1.25276297e+00, -1.26025364e+00,\n",
       "                     -1.28785429e+00, -1.29392104e+00, -1.29928298e+00, -1.30340670e+00,\n",
       "                     -1.30992138e+00, -1.31218639e+00, -1.31782656e+00, -1.33500107e+00,\n",
       "                     -1.35239281e+00, -1.36524095e+00, -1.38629436e+00, -1.40282366e+00,\n",
       "                     -1.41098697e+00, -1.44561094e+00, -1.46169238e+00, -1.46633707e+00,\n",
       "                     -1.47181653e+00, -1.47689126e+00, -1.50407740e+00, -1.52846885e+00,\n",
       "                     -1.52939520e+00, -1.54044504e+00, -1.55059741e+00, -1.55814462e+00,\n",
       "                     -1.56397554e+00, -1.60943791e+00, -1.64865863e+00, -1.67397643e+00,\n",
       "                     -1.68175857e+00, -1.70474809e+00, -1.71604765e+00, -1.72276660e+00,\n",
       "                     -1.79175947e+00, -1.80828877e+00, -1.87180218e+00, -1.94591015e+00,\n",
       "                     -1.99243016e+00, -2.00148000e+00, -2.03688193e+00, -2.07944154e+00,\n",
       "                     -2.19722458e+00, -2.30258509e+00, -2.48490665e+00, -2.56494936e+00,\n",
       "                     -2.59026717e+00, -2.63905733e+00, -2.70805020e+00, -2.74084002e+00,\n",
       "                     -2.94443898e+00, -3.13549422e+00, -3.17805383e+00, -3.36729583e+00,\n",
       "                     -3.52636052e+00, -3.58351894e+00, -3.95124372e+00, -3.45387764e+01]), auc_score=0.5674998814504788, privacy_risk=0.548070035954851, accuracy=0.5473355165227747, tpr_ind=0.6429642964296429, tnr_ind=0.4531757754800591, test_train_ratio=1.0156015601560155, dataset_size=[3333, 3385]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00752106, 0.01022864, 0.01624549, 0.01955475,\n",
       "                     0.02075812, 0.0276775 , 0.02888087, 0.03188929, 0.03429603,\n",
       "                     0.03941035, 0.04632972, 0.04963899, 0.05565584, 0.06197353,\n",
       "                     0.06738869, 0.06919374, 0.07310469, 0.07551143, 0.10800241,\n",
       "                     0.11973526, 0.12424789, 0.127858  , 0.1356799 , 0.13838748,\n",
       "                     0.17990373, 0.18170878, 0.18592058, 0.19795427, 0.20637786,\n",
       "                     0.20998797, 0.21389892, 0.21780987, 0.23796631, 0.25090253,\n",
       "                     0.25300842, 0.25481348, 0.27045728, 0.28971119, 0.29632972,\n",
       "                     0.30144404, 0.30354994, 0.30776173, 0.35860409, 0.37665463,\n",
       "                     0.39019254, 0.40944645, 0.41365824, 0.42027677, 0.42960289,\n",
       "                     0.45126354, 0.45367028, 0.45547533, 0.45728039, 0.46359807,\n",
       "                     0.46419976, 0.47533093, 0.4765343 , 0.49067389, 0.52316486,\n",
       "                     0.52888087, 0.53158845, 0.54963899, 0.561071  , 0.56498195,\n",
       "                     0.57340554, 0.58904934, 0.59506619, 0.60168472, 0.62394705,\n",
       "                     0.62575211, 0.62936221, 0.65042118, 0.65192539, 0.65583634,\n",
       "                     0.66787004, 0.67268351, 0.70998797, 0.72743682, 0.72984356,\n",
       "                     0.7421781 , 0.74729242, 0.75601685, 0.76022864, 0.76865223,\n",
       "                     0.77015644, 0.77587244, 0.78188929, 0.78580024, 0.79302046,\n",
       "                     0.79813478, 0.79993983, 0.82791817, 0.83182912, 0.8345367 ,\n",
       "                     0.83483755, 0.83965102, 0.84476534, 0.85108303, 0.85800241,\n",
       "                     0.86492178, 0.86732852, 0.87815884, 0.87876053, 0.88086643,\n",
       "                     0.8956077 , 0.90042118, 0.90523466, 0.9055355 , 0.91486161,\n",
       "                     0.9154633 , 0.91907341, 0.92478941, 0.92809868, 0.93020457,\n",
       "                     0.93170878, 0.93261131, 0.938929  , 0.94013237, 0.94314079,\n",
       "                     0.94344164, 0.94795427, 0.95126354, 0.95336943, 0.95427196,\n",
       "                     0.95637786, 0.95938628, 0.95998797, 0.96149218, 0.96239471,\n",
       "                     0.96299639, 0.9666065 , 1.        ]), tpr=array([0.        , 0.02032999, 0.02327637, 0.03123159, 0.03594579,\n",
       "                     0.03741897, 0.04743665, 0.05008839, 0.05303477, 0.05715969,\n",
       "                     0.06246317, 0.07012375, 0.07424867, 0.07984679, 0.08721273,\n",
       "                     0.09369476, 0.09546258, 0.09870359, 0.10223925, 0.14172068,\n",
       "                     0.16057749, 0.16764879, 0.17088981, 0.17884502, 0.18355922,\n",
       "                     0.22598704, 0.2280495 , 0.23394225, 0.24926341, 0.25957572,\n",
       "                     0.26222746, 0.26605775, 0.2719505 , 0.29787861, 0.31143194,\n",
       "                     0.31555687, 0.31850324, 0.33441367, 0.3503241 , 0.35857395,\n",
       "                     0.36210961, 0.36623453, 0.36947555, 0.4286977 , 0.4490277 ,\n",
       "                     0.46140247, 0.48261638, 0.48762522, 0.49646435, 0.50530348,\n",
       "                     0.52681202, 0.5297584 , 0.53182086, 0.53506187, 0.53977608,\n",
       "                     0.54124926, 0.55421332, 0.55627578, 0.56865056, 0.60783736,\n",
       "                     0.61314084, 0.6175604 , 0.63789039, 0.65085445, 0.65321155,\n",
       "                     0.66322923, 0.67472009, 0.67913966, 0.68621096, 0.70654095,\n",
       "                     0.70889806, 0.71272834, 0.72863877, 0.73011196, 0.73394225,\n",
       "                     0.74278138, 0.74631703, 0.78432528, 0.8087802 , 0.81231585,\n",
       "                     0.82763701, 0.83176193, 0.84148497, 0.84384207, 0.85150265,\n",
       "                     0.85415439, 0.85827932, 0.86240424, 0.86593989, 0.87094873,\n",
       "                     0.8753683 , 0.87654685, 0.89835003, 0.90365351, 0.90512669,\n",
       "                     0.90630524, 0.91101945, 0.91308191, 0.91750147, 0.9216264 ,\n",
       "                     0.93076016, 0.93311727, 0.94166176, 0.94342958, 0.94490277,\n",
       "                     0.95875074, 0.96051856, 0.96375958, 0.96434885, 0.97112552,\n",
       "                     0.97289334, 0.97436653, 0.97760754, 0.97967001, 0.98114319,\n",
       "                     0.98320566, 0.98350029, 0.98733058, 0.9882145 , 0.98939305,\n",
       "                     0.9905716 , 0.99233942, 0.99351797, 0.99558044, 0.99587507,\n",
       "                     0.99646435, 0.9976429 , 0.99793754, 0.99823217, 0.99882145,\n",
       "                     0.99941072, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.82321557e-01, -2.87682072e-01,\n",
       "                     -3.18453731e-01, -3.36472237e-01, -4.05465108e-01, -4.41832752e-01,\n",
       "                     -4.70003629e-01, -4.96436886e-01, -5.10825624e-01, -5.48565952e-01,\n",
       "                     -5.79818495e-01, -5.81921545e-01, -5.87786665e-01, -5.97837001e-01,\n",
       "                     -6.06135804e-01, -6.46627165e-01, -6.50587566e-01, -6.93147181e-01,\n",
       "                     -7.31466045e-01, -7.33969175e-01, -7.37598943e-01, -7.47214402e-01,\n",
       "                     -7.53771802e-01, -7.60286483e-01, -7.62140052e-01, -7.65467842e-01,\n",
       "                     -7.67255153e-01, -7.88457360e-01, -7.98507696e-01, -8.02346473e-01,\n",
       "                     -8.10930216e-01, -8.20980552e-01, -8.25318954e-01, -8.26678573e-01,\n",
       "                     -8.32909123e-01, -8.39329691e-01, -8.47297860e-01, -8.57450232e-01,\n",
       "                     -8.82389180e-01, -8.87303195e-01, -8.97941593e-01, -9.03271019e-01,\n",
       "                     -9.13387972e-01, -9.16290732e-01, -9.49080555e-01, -9.50976290e-01,\n",
       "                     -9.55511445e-01, -9.80829253e-01, -9.92744288e-01, -9.93251773e-01,\n",
       "                     -9.98528830e-01, -1.00330211e+00, -1.01160091e+00, -1.02961942e+00,\n",
       "                     -1.03609193e+00, -1.04982212e+00, -1.08261195e+00, -1.09861229e+00,\n",
       "                     -1.11696143e+00, -1.12059120e+00, -1.12247977e+00, -1.12846525e+00,\n",
       "                     -1.13943428e+00, -1.15577070e+00, -1.15671992e+00, -1.16315081e+00,\n",
       "                     -1.17865500e+00, -1.20397280e+00, -1.21639532e+00, -1.21924028e+00,\n",
       "                     -1.22050211e+00, -1.22377543e+00, -1.24171313e+00, -1.24319352e+00,\n",
       "                     -1.25276297e+00, -1.26923781e+00, -1.27825288e+00, -1.29928298e+00,\n",
       "                     -1.30625165e+00, -1.31218639e+00, -1.31567679e+00, -1.32175584e+00,\n",
       "                     -1.35702398e+00, -1.35812348e+00, -1.38629436e+00, -1.40399394e+00,\n",
       "                     -1.42711636e+00, -1.42946653e+00, -1.43508453e+00, -1.44691898e+00,\n",
       "                     -1.46425590e+00, -1.46633707e+00, -1.48160454e+00, -1.50407740e+00,\n",
       "                     -1.51787072e+00, -1.51982575e+00, -1.52605630e+00, -1.53532994e+00,\n",
       "                     -1.58329263e+00, -1.58412010e+00, -1.60943791e+00, -1.64222774e+00,\n",
       "                     -1.64865863e+00, -1.65111061e+00, -1.67397643e+00, -1.69644929e+00,\n",
       "                     -1.70474809e+00, -1.73204023e+00, -1.73460106e+00, -1.75785792e+00,\n",
       "                     -1.79175947e+00, -1.81528997e+00, -1.88706965e+00, -1.90423745e+00,\n",
       "                     -1.94591015e+00, -2.10787948e+00, -2.15948425e+00, -2.19722458e+00,\n",
       "                     -2.32727771e+00, -2.33537492e+00, -2.37490575e+00, -2.38482319e+00,\n",
       "                     -2.48490665e+00, -2.52572864e+00, -2.70805020e+00, -2.89037176e+00,\n",
       "                     -3.21887582e+00, -3.23867845e+00, -3.36729583e+00, -4.54859983e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5622132513170053, privacy_risk=0.5449118462750504, accuracy=0.5461446859184281, tpr_ind=0.6632292280494991, tnr_ind=0.4265944645006017, test_train_ratio=0.9793753682969947, dataset_size=[3394, 3324]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.0077404 , 0.00922894, 0.00952664, 0.0116106 ,\n",
       "                     0.01637392, 0.01756475, 0.01905329, 0.02054183, 0.0232212 ,\n",
       "                     0.02530515, 0.03423638, 0.0389997 , 0.04108366, 0.04227449,\n",
       "                     0.04257219, 0.04346532, 0.04495386, 0.0467401 , 0.05001489,\n",
       "                     0.05418279, 0.05775528, 0.06341173, 0.07829711, 0.08514439,\n",
       "                     0.08782376, 0.09109854, 0.10151831, 0.1050908 , 0.11193808,\n",
       "                     0.14289967, 0.14319738, 0.14528133, 0.14825841, 0.15629652,\n",
       "                     0.15867818, 0.1634415 , 0.16493004, 0.16850253, 0.1827925 ,\n",
       "                     0.18874665, 0.20988389, 0.217922  , 0.22328074, 0.23161655,\n",
       "                     0.23548675, 0.24054778, 0.24739506, 0.24977672, 0.27448645,\n",
       "                     0.29711224, 0.30306639, 0.30485263, 0.30782971, 0.3152724 ,\n",
       "                     0.32450134, 0.32747842, 0.33134862, 0.35576064, 0.35665377,\n",
       "                     0.3620125 , 0.36737124, 0.38940161, 0.40279845, 0.40785948,\n",
       "                     0.41202739, 0.41292051, 0.41798154, 0.46323311, 0.47186663,\n",
       "                     0.47752307, 0.51801131, 0.52426317, 0.54212563, 0.55492706,\n",
       "                     0.56117892, 0.564156  , 0.5680262 , 0.59958321, 0.60672819,\n",
       "                     0.62131587, 0.6263769 , 0.63114022, 0.63977374, 0.64126228,\n",
       "                     0.64543019, 0.67430783, 0.72342959, 0.72462042, 0.72789521,\n",
       "                     0.74873474, 0.76629949, 0.76719262, 0.76838345, 0.77612385,\n",
       "                     0.77969634, 0.78326883, 0.79458172, 0.80202441, 0.80797857,\n",
       "                     0.81274189, 0.81750521, 0.81839833, 0.84072641, 0.84548973,\n",
       "                     0.84876451, 0.84876451, 0.85233701, 0.87645132, 0.87823757,\n",
       "                     0.88448943, 0.88597797, 0.89014588, 0.90949687, 0.91009229,\n",
       "                     0.9184281 , 0.92259601, 0.92587079, 0.92646621, 0.9377791 ,\n",
       "                     0.93926764, 0.94135159, 0.94343555, 0.9455195 , 0.94730575,\n",
       "                     0.94998511, 0.95177136, 0.95415302, 0.95653468, 0.96606133,\n",
       "                     0.96725216, 0.96754987, 0.96844299, 0.96993153, 0.97082465,\n",
       "                     0.97112236, 0.97231319, 0.9729086 , 0.97588568, 1.        ]), tpr=array([0.        , 0.01905329, 0.02083954, 0.02232807, 0.02619827,\n",
       "                     0.03215243, 0.03393867, 0.03721346, 0.03870199, 0.04078595,\n",
       "                     0.04406073, 0.05477821, 0.06043465, 0.06460256, 0.06757964,\n",
       "                     0.0699613 , 0.07323608, 0.07740399, 0.07919024, 0.08306043,\n",
       "                     0.08782376, 0.09318249, 0.10062519, 0.11134266, 0.11759452,\n",
       "                     0.11997618, 0.12354868, 0.13158678, 0.1360524 , 0.1437928 ,\n",
       "                     0.18547187, 0.18844894, 0.19261685, 0.19648705, 0.20541828,\n",
       "                     0.20869306, 0.21673117, 0.21821971, 0.22238762, 0.24025007,\n",
       "                     0.24382257, 0.26555522, 0.27389104, 0.27924978, 0.28639476,\n",
       "                     0.29026496, 0.29592141, 0.30395951, 0.30574576, 0.32747842,\n",
       "                     0.3501042 , 0.3581423 , 0.36022626, 0.36528729, 0.3697529 ,\n",
       "                     0.37927955, 0.38255433, 0.38434058, 0.4126228 , 0.41559988,\n",
       "                     0.42304257, 0.4281036 , 0.44894314, 0.46233998, 0.46799643,\n",
       "                     0.47514141, 0.47811849, 0.48317952, 0.52247693, 0.5328967 ,\n",
       "                     0.53527836, 0.583507  , 0.5915451 , 0.60672819, 0.61982733,\n",
       "                     0.62607919, 0.62816314, 0.62965168, 0.65882703, 0.66507889,\n",
       "                     0.68294135, 0.68651384, 0.692468  , 0.70556713, 0.70705567,\n",
       "                     0.70943733, 0.73474248, 0.78356654, 0.78624591, 0.79130694,\n",
       "                     0.81423043, 0.82911581, 0.83090205, 0.83298601, 0.83894016,\n",
       "                     0.84221494, 0.84459661, 0.85382554, 0.85918428, 0.86513843,\n",
       "                     0.86692468, 0.87109259, 0.87287883, 0.89193212, 0.89669545,\n",
       "                     0.90324501, 0.90443584, 0.90711521, 0.92855016, 0.9300387 ,\n",
       "                     0.93242036, 0.93361119, 0.93807681, 0.95593927, 0.95772551,\n",
       "                     0.96427508, 0.96754987, 0.97112236, 0.97171777, 0.97826734,\n",
       "                     0.97886276, 0.98124442, 0.98303066, 0.98511462, 0.98600774,\n",
       "                     0.98749628, 0.98898482, 0.98987794, 0.99196189, 0.99434355,\n",
       "                     0.99493897, 0.99523668, 0.99583209, 0.9961298 , 0.99761834,\n",
       "                     0.99791605, 0.99910688, 0.99940458, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.54150680e-01, -1.82321557e-01,\n",
       "                     -2.07639365e-01, -2.23143551e-01, -2.87682072e-01, -3.10154928e-01,\n",
       "                     -3.36472237e-01, -3.56674944e-01, -3.74693449e-01, -4.05465108e-01,\n",
       "                     -4.22856851e-01, -4.51985124e-01, -4.70003629e-01, -4.85507816e-01,\n",
       "                     -4.92476485e-01, -4.96436886e-01, -5.10825624e-01, -5.26093096e-01,\n",
       "                     -5.59615788e-01, -5.75364145e-01, -5.87786665e-01, -6.06135804e-01,\n",
       "                     -6.19039208e-01, -6.28608659e-01, -6.50587566e-01, -6.55406853e-01,\n",
       "                     -6.59245629e-01, -6.73729095e-01, -6.93147181e-01, -7.41937345e-01,\n",
       "                     -7.62140052e-01, -7.67255153e-01, -7.73189888e-01, -7.80158558e-01,\n",
       "                     -7.81700578e-01, -7.88457360e-01, -7.94929875e-01, -8.03495238e-01,\n",
       "                     -8.10930216e-01, -8.21528347e-01, -8.26678573e-01, -8.47297860e-01,\n",
       "                     -8.82389180e-01, -9.00786545e-01, -9.05708623e-01, -9.08855753e-01,\n",
       "                     -9.16290732e-01, -9.19026712e-01, -9.21540088e-01, -9.38269639e-01,\n",
       "                     -9.44461609e-01, -9.50976290e-01, -9.55511445e-01, -9.65080896e-01,\n",
       "                     -9.69400557e-01, -9.80829253e-01, -9.87386654e-01, -9.93251773e-01,\n",
       "                     -1.00063188e+00, -1.01693426e+00, -1.01936292e+00, -1.02165125e+00,\n",
       "                     -1.02585293e+00, -1.02663879e+00, -1.02961942e+00, -1.03798767e+00,\n",
       "                     -1.04145387e+00, -1.04982212e+00, -1.05605267e+00, -1.07149905e+00,\n",
       "                     -1.07361099e+00, -1.09861229e+00, -1.10615949e+00, -1.12986483e+00,\n",
       "                     -1.14513230e+00, -1.16315081e+00, -1.17393430e+00, -1.17498527e+00,\n",
       "                     -1.18377010e+00, -1.20397280e+00, -1.20896035e+00, -1.21975667e+00,\n",
       "                     -1.22377543e+00, -1.25276297e+00, -1.25444223e+00, -1.26488433e+00,\n",
       "                     -1.26851133e+00, -1.27766052e+00, -1.28381569e+00, -1.29198368e+00,\n",
       "                     -1.29928298e+00, -1.31218639e+00, -1.32175584e+00, -1.33977435e+00,\n",
       "                     -1.35454566e+00, -1.38629436e+00, -1.41369334e+00, -1.42310833e+00,\n",
       "                     -1.42711636e+00, -1.43848011e+00, -1.46633707e+00, -1.47232870e+00,\n",
       "                     -1.47590652e+00, -1.48366853e+00, -1.50407740e+00, -1.54044504e+00,\n",
       "                     -1.59545167e+00, -1.60943791e+00, -1.63413053e+00, -1.65822808e+00,\n",
       "                     -1.66139765e+00, -1.68020698e+00, -1.70474809e+00, -1.72114190e+00,\n",
       "                     -1.79175947e+00, -1.83258146e+00, -1.87180218e+00, -1.91290385e+00,\n",
       "                     -1.94591015e+00, -1.96360973e+00, -1.96944065e+00, -1.98591548e+00,\n",
       "                     -1.99243016e+00, -2.05412373e+00, -2.07944154e+00, -2.12026354e+00,\n",
       "                     -2.16496372e+00, -2.19722458e+00, -2.48490665e+00, -2.56494936e+00,\n",
       "                     -2.60268969e+00, -2.89037176e+00, -2.92316158e+00, -3.13549422e+00,\n",
       "                     -3.19867312e+00, -3.40119738e+00, -3.49650756e+00, -3.45387764e+01]), auc_score=0.5517200792953502, privacy_risk=0.5336409645727895, accuracy=0.5336409645727895, tpr_ind=0.5915451027091396, tnr_ind=0.47573682643643944, test_train_ratio=1.0, dataset_size=[3359, 3359]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00955224, 0.01104478, 0.01134328, 0.01402985,\n",
       "                     0.0158209 , 0.01880597, 0.01910448, 0.02149254, 0.02268657,\n",
       "                     0.02447761, 0.02925373, 0.0319403 , 0.03462687, 0.0361194 ,\n",
       "                     0.03970149, 0.04268657, 0.04358209, 0.04567164, 0.04985075,\n",
       "                     0.05164179, 0.05432836, 0.06179104, 0.06716418, 0.07492537,\n",
       "                     0.08029851, 0.08149254, 0.09253731, 0.09641791, 0.10447761,\n",
       "                     0.12298507, 0.1441791 , 0.15164179, 0.15522388, 0.15940299,\n",
       "                     0.16298507, 0.16626866, 0.17373134, 0.19074627, 0.19343284,\n",
       "                     0.20925373, 0.22507463, 0.23373134, 0.23552239, 0.24746269,\n",
       "                     0.25044776, 0.25432836, 0.25970149, 0.26328358, 0.2680597 ,\n",
       "                     0.2719403 , 0.27641791, 0.27970149, 0.28746269, 0.30268657,\n",
       "                     0.30865672, 0.31850746, 0.32895522, 0.33253731, 0.33820896,\n",
       "                     0.34567164, 0.35044776, 0.35462687, 0.36925373, 0.37432836,\n",
       "                     0.38537313, 0.38895522, 0.40985075, 0.41134328, 0.43432836,\n",
       "                     0.46089552, 0.48298507, 0.4958209 , 0.50597015, 0.50865672,\n",
       "                     0.52835821, 0.53164179, 0.54447761, 0.55044776, 0.56029851,\n",
       "                     0.56477612, 0.56895522, 0.57253731, 0.57910448, 0.60626866,\n",
       "                     0.61432836, 0.62      , 0.63283582, 0.63820896, 0.64477612,\n",
       "                     0.64895522, 0.65671642, 0.72567164, 0.72985075, 0.73313433,\n",
       "                     0.73492537, 0.74507463, 0.75223881, 0.75552239, 0.76179104,\n",
       "                     0.7761194 , 0.7838806 , 0.80119403, 0.8080597 , 0.81164179,\n",
       "                     0.8158209 , 0.82      , 0.8280597 , 0.83014925, 0.83164179,\n",
       "                     0.83462687, 0.83492537, 0.85313433, 0.85343284, 0.85940299,\n",
       "                     0.86238806, 0.87671642, 0.88835821, 0.89014925, 0.89432836,\n",
       "                     0.90298507, 0.91373134, 0.91850746, 0.92089552, 0.92477612,\n",
       "                     0.92835821, 0.92955224, 0.92955224, 0.93104478, 0.93313433,\n",
       "                     0.94447761, 0.94626866, 0.95014925, 0.95223881, 0.9561194 ,\n",
       "                     0.95671642, 0.95820896, 0.96029851, 0.96089552, 0.96328358,\n",
       "                     0.96447761, 0.96835821, 0.96985075, 0.97104478, 0.97283582,\n",
       "                     1.        ]), tpr=array([0.        , 0.01751781, 0.02048694, 0.02226841, 0.02583135,\n",
       "                     0.02909739, 0.03444181, 0.0368171 , 0.04067696, 0.04216152,\n",
       "                     0.04691211, 0.05611639, 0.05967933, 0.06472684, 0.0662114 ,\n",
       "                     0.06947743, 0.07452494, 0.07719715, 0.08283848, 0.0858076 ,\n",
       "                     0.09204276, 0.10184086, 0.11015439, 0.11609264, 0.12856295,\n",
       "                     0.1347981 , 0.1371734 , 0.15172209, 0.15498812, 0.16567696,\n",
       "                     0.18586698, 0.20546318, 0.21377672, 0.21704276, 0.222981  ,\n",
       "                     0.2280285 , 0.23426366, 0.24495249, 0.26247031, 0.26573634,\n",
       "                     0.27909739, 0.29691211, 0.30285036, 0.30492874, 0.31828979,\n",
       "                     0.32155582, 0.32541568, 0.33135392, 0.33640143, 0.34263658,\n",
       "                     0.34530879, 0.35451306, 0.35896675, 0.37084323, 0.38776722,\n",
       "                     0.3945962 , 0.40528504, 0.41359857, 0.4192399 , 0.4263658 ,\n",
       "                     0.43230404, 0.43764846, 0.44239905, 0.46110451, 0.46733967,\n",
       "                     0.4780285 , 0.48070071, 0.5       , 0.50148456, 0.52464371,\n",
       "                     0.54839667, 0.56739905, 0.57957245, 0.59263658, 0.5956057 ,\n",
       "                     0.61193587, 0.61460808, 0.62826603, 0.6371734 , 0.64578385,\n",
       "                     0.64934679, 0.65469121, 0.65795724, 0.66359857, 0.6888361 ,\n",
       "                     0.69714964, 0.70219715, 0.71110451, 0.71526128, 0.71971496,\n",
       "                     0.72416865, 0.72891924, 0.7966152 , 0.79958432, 0.80166271,\n",
       "                     0.80285036, 0.81146081, 0.82007126, 0.82511876, 0.83046318,\n",
       "                     0.84026128, 0.84590261, 0.8628266 , 0.86846793, 0.87024941,\n",
       "                     0.87173397, 0.875     , 0.88420428, 0.88509501, 0.88747031,\n",
       "                     0.89103325, 0.8922209 , 0.91062945, 0.91152019, 0.91597387,\n",
       "                     0.91894299, 0.92725653, 0.9337886 , 0.93497625, 0.93824228,\n",
       "                     0.94952494, 0.95813539, 0.96110451, 0.96288599, 0.96466746,\n",
       "                     0.96733967, 0.96941805, 0.96971496, 0.9706057 , 0.97179335,\n",
       "                     0.97862233, 0.97980998, 0.98396675, 0.98456057, 0.9878266 ,\n",
       "                     0.98842043, 0.98960808, 0.9902019 , 0.99079572, 0.99138955,\n",
       "                     0.99198337, 0.99851544, 0.99881235, 0.99910926, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -9.53101798e-02, -1.54150680e-01,\n",
       "                     -2.23143551e-01, -2.41162057e-01, -2.87682072e-01, -3.18453731e-01,\n",
       "                     -3.25422400e-01, -3.36472237e-01, -4.05465108e-01, -4.16160397e-01,\n",
       "                     -4.59532329e-01, -4.62623522e-01, -4.70003629e-01, -4.92476485e-01,\n",
       "                     -4.98991166e-01, -5.10825624e-01, -5.21296924e-01, -5.30628251e-01,\n",
       "                     -5.38996501e-01, -5.46543706e-01, -5.59615788e-01, -5.87786665e-01,\n",
       "                     -6.06135804e-01, -6.19039208e-01, -6.28608659e-01, -6.40779195e-01,\n",
       "                     -6.46627165e-01, -6.79160939e-01, -6.85767073e-01, -6.93147181e-01,\n",
       "                     -7.28238500e-01, -7.37598943e-01, -7.41937345e-01, -7.50305594e-01,\n",
       "                     -7.62140052e-01, -7.73189888e-01, -7.74492820e-01, -7.80158558e-01,\n",
       "                     -7.88457360e-01, -8.03495238e-01, -8.10930216e-01, -8.26678573e-01,\n",
       "                     -8.47297860e-01, -8.60201265e-01, -8.69037847e-01, -8.75468737e-01,\n",
       "                     -8.80358723e-01, -8.87303195e-01, -8.93817876e-01, -8.96746136e-01,\n",
       "                     -9.02867712e-01, -9.16290732e-01, -9.19793362e-01, -9.24948795e-01,\n",
       "                     -9.27340568e-01, -9.30475367e-01, -9.47381319e-01, -9.49080555e-01,\n",
       "                     -9.55511445e-01, -9.59775844e-01, -9.65080896e-01, -9.80829253e-01,\n",
       "                     -9.98528830e-01, -1.01160091e+00, -1.02165125e+00, -1.02410976e+00,\n",
       "                     -1.02961942e+00, -1.03236290e+00, -1.03850836e+00, -1.05060307e+00,\n",
       "                     -1.05711256e+00, -1.05999745e+00, -1.06471074e+00, -1.09861229e+00,\n",
       "                     -1.13497993e+00, -1.14117190e+00, -1.16315081e+00, -1.17599895e+00,\n",
       "                     -1.17865500e+00, -1.20397280e+00, -1.21302264e+00, -1.21444410e+00,\n",
       "                     -1.22377543e+00, -1.24250647e+00, -1.24432410e+00, -1.25276297e+00,\n",
       "                     -1.27296568e+00, -1.28093385e+00, -1.29928298e+00, -1.30494872e+00,\n",
       "                     -1.30524603e+00, -1.30833282e+00, -1.31218639e+00, -1.32175584e+00,\n",
       "                     -1.32405205e+00, -1.33318454e+00, -1.37147928e+00, -1.38629436e+00,\n",
       "                     -1.39384157e+00, -1.39936644e+00, -1.42078054e+00, -1.42500887e+00,\n",
       "                     -1.42711636e+00, -1.43508453e+00, -1.45225233e+00, -1.45636192e+00,\n",
       "                     -1.46633707e+00, -1.47590652e+00, -1.48538526e+00, -1.50407740e+00,\n",
       "                     -1.51831251e+00, -1.54044504e+00, -1.56861592e+00, -1.58923521e+00,\n",
       "                     -1.60943791e+00, -1.62745642e+00, -1.65822808e+00, -1.67964217e+00,\n",
       "                     -1.68053383e+00, -1.75069798e+00, -1.77495235e+00, -1.79175947e+00,\n",
       "                     -1.89711998e+00, -1.91364929e+00, -1.92529086e+00, -1.94591015e+00,\n",
       "                     -1.99243016e+00, -2.01490302e+00, -2.02929176e+00, -2.07944154e+00,\n",
       "                     -2.12311661e+00, -2.14006616e+00, -2.14539951e+00, -2.19722458e+00,\n",
       "                     -2.25129180e+00, -2.30258509e+00, -2.44234704e+00, -2.63905733e+00,\n",
       "                     -2.70805020e+00, -2.83321334e+00, -2.89037176e+00, -2.99573227e+00,\n",
       "                     -3.09104245e+00, -3.45387764e+01]), auc_score=0.5665582568156841, privacy_risk=0.5465056546247385, accuracy=0.5462935397439714, tpr_ind=0.4673396674584323, tnr_ind=0.6256716417910447, test_train_ratio=0.9946555819477435, dataset_size=[3368, 3350]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.01131289, 0.01399226, 0.01577851, 0.01726704,\n",
       "                     0.0196487 , 0.02143495, 0.0232212 , 0.02947306, 0.03810658,\n",
       "                     0.04019053, 0.04138136, 0.04346532, 0.04554927, 0.0467401 ,\n",
       "                     0.04971718, 0.05358738, 0.05626675, 0.05745758, 0.06013695,\n",
       "                     0.06728193, 0.07174754, 0.07859482, 0.08008336, 0.08127419,\n",
       "                     0.08425127, 0.09586186, 0.10032748, 0.13128907, 0.13873177,\n",
       "                     0.14825841, 0.16254838, 0.16850253, 0.17386127, 0.17564751,\n",
       "                     0.18606728, 0.18725811, 0.18874665, 0.18993748, 0.19142602,\n",
       "                     0.19291456, 0.19708247, 0.22417386, 0.23310509, 0.24471569,\n",
       "                     0.25186067, 0.25334921, 0.26615064, 0.26972313, 0.27597499,\n",
       "                     0.2840131 , 0.28877642, 0.29294433, 0.35159274, 0.36111938,\n",
       "                     0.37094373, 0.38344745, 0.38642453, 0.39982138, 0.40309616,\n",
       "                     0.43941649, 0.44626377, 0.45281334, 0.45430188, 0.45638583,\n",
       "                     0.46055374, 0.46591247, 0.47960703, 0.52664483, 0.53974397,\n",
       "                     0.54927062, 0.55403394, 0.55879726, 0.56385829, 0.56891932,\n",
       "                     0.57755284, 0.59988092, 0.6031557 , 0.60643049, 0.63084251,\n",
       "                     0.63143793, 0.6341173 , 0.63947603, 0.66001786, 0.66418577,\n",
       "                     0.6692468 , 0.68442989, 0.68681155, 0.69604049, 0.69812444,\n",
       "                     0.71866627, 0.71866627, 0.72521584, 0.73712414, 0.74545996,\n",
       "                     0.7782078 , 0.78148258, 0.78684132, 0.79100923, 0.79309318,\n",
       "                     0.82941352, 0.82971122, 0.84727597, 0.84906222, 0.85710033,\n",
       "                     0.86126823, 0.86573385, 0.86871093, 0.87526049, 0.87972611,\n",
       "                     0.88121465, 0.8871688 , 0.89163442, 0.89639774, 0.89818398,\n",
       "                     0.90056564, 0.90771063, 0.9181304 , 0.91991664, 0.92467996,\n",
       "                     0.93569515, 0.9377791 , 0.93986305, 0.94075618, 0.95058053,\n",
       "                     0.95623698, 0.9571301 , 0.95921405, 0.95980947, 0.96040488,\n",
       "                     0.96040488, 0.96040488, 0.9651682 , 0.96546591, 0.97231319,\n",
       "                     0.97439714, 0.97707651, 0.97707651, 0.97796963, 0.97886276,\n",
       "                     0.97886276, 1.        ]), tpr=array([0.        , 0.02024412, 0.02381661, 0.02590057, 0.0273891 ,\n",
       "                     0.0309616 , 0.03393867, 0.03572492, 0.04167907, 0.05596904,\n",
       "                     0.06013695, 0.06370944, 0.06668651, 0.07085442, 0.07264067,\n",
       "                     0.07561774, 0.08008336, 0.08246502, 0.08395356, 0.08871688,\n",
       "                     0.09943436, 0.10568622, 0.11312891, 0.11580828, 0.11938077,\n",
       "                     0.12325097, 0.13843406, 0.14438821, 0.18338791, 0.19559393,\n",
       "                     0.20512057, 0.22387615, 0.22893718, 0.23131884, 0.23310509,\n",
       "                     0.24233403, 0.24382257, 0.24650194, 0.25037213, 0.25156297,\n",
       "                     0.25602858, 0.25930336, 0.28311998, 0.28937184, 0.2994939 ,\n",
       "                     0.30425722, 0.30634117, 0.32390592, 0.32658529, 0.33224174,\n",
       "                     0.34295921, 0.34891337, 0.35337898, 0.40934802, 0.42066091,\n",
       "                     0.43376005, 0.44269128, 0.44477523, 0.46114915, 0.46591247,\n",
       "                     0.49091992, 0.49985115, 0.50461447, 0.50788925, 0.5096755 ,\n",
       "                     0.5135457 , 0.51771361, 0.52962191, 0.59035427, 0.59988092,\n",
       "                     0.60940756, 0.61744567, 0.62369753, 0.63084251, 0.63530813,\n",
       "                     0.64423936, 0.66835368, 0.66984221, 0.67401012, 0.70259006,\n",
       "                     0.70348318, 0.70586484, 0.71033046, 0.73116999, 0.73325394,\n",
       "                     0.73712414, 0.74575767, 0.74873474, 0.75379577, 0.75558202,\n",
       "                     0.77493302, 0.77612385, 0.78267341, 0.79339089, 0.80202441,\n",
       "                     0.83239059, 0.83506996, 0.84013099, 0.84668056, 0.84846681,\n",
       "                     0.88448943, 0.88597797, 0.90354272, 0.90443584, 0.91039   ,\n",
       "                     0.91961893, 0.9222983 , 0.92438226, 0.92944329, 0.93212266,\n",
       "                     0.93420661, 0.93867222, 0.94016076, 0.94343555, 0.94492408,\n",
       "                     0.9455195 , 0.95206907, 0.96040488, 0.96189342, 0.96427508,\n",
       "                     0.97320631, 0.97469485, 0.9764811 , 0.97767193, 0.98630545,\n",
       "                     0.98779399, 0.98868711, 0.98958023, 0.99077106, 0.99166419,\n",
       "                     0.9922596 , 0.99255731, 0.99434355, 0.99493897, 0.99732063,\n",
       "                     0.99791605, 0.99851146, 0.99880917, 0.99910688, 0.99970229,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -8.00427077e-02, -1.33531393e-01,\n",
       "                     -1.82321557e-01, -2.23143551e-01, -2.62364264e-01, -2.87682072e-01,\n",
       "                     -3.36472237e-01, -4.05465108e-01, -4.51985124e-01, -4.59532329e-01,\n",
       "                     -4.70003629e-01, -4.96436886e-01, -5.10825624e-01, -5.30628251e-01,\n",
       "                     -5.50046337e-01, -5.59615788e-01, -5.87786665e-01, -5.94707108e-01,\n",
       "                     -6.06135804e-01, -6.19039208e-01, -6.31271777e-01, -6.35988767e-01,\n",
       "                     -6.50587566e-01, -6.53926467e-01, -6.63294217e-01, -6.67829373e-01,\n",
       "                     -6.93147181e-01, -7.05268541e-01, -7.38956717e-01, -7.47214402e-01,\n",
       "                     -7.50305594e-01, -7.53771802e-01, -7.73189888e-01, -7.85520501e-01,\n",
       "                     -7.88457360e-01, -7.98507696e-01, -8.02346473e-01, -8.10930216e-01,\n",
       "                     -8.18310324e-01, -8.20980552e-01, -8.27459518e-01, -8.47297860e-01,\n",
       "                     -8.55666110e-01, -8.64997437e-01, -8.87303195e-01, -8.92275856e-01,\n",
       "                     -8.93817876e-01, -9.05708623e-01, -9.16290732e-01, -9.36093359e-01,\n",
       "                     -9.55511445e-01, -9.62036754e-01, -9.67584026e-01, -9.69400557e-01,\n",
       "                     -9.80829253e-01, -9.98528830e-01, -1.00330211e+00, -1.01160091e+00,\n",
       "                     -1.02876872e+00, -1.02961942e+00, -1.03407377e+00, -1.03609193e+00,\n",
       "                     -1.04145387e+00, -1.04596856e+00, -1.04982212e+00, -1.06471074e+00,\n",
       "                     -1.07044141e+00, -1.07755888e+00, -1.08814099e+00, -1.09861229e+00,\n",
       "                     -1.11436065e+00, -1.12601126e+00, -1.14209740e+00, -1.15267951e+00,\n",
       "                     -1.16237891e+00, -1.16315081e+00, -1.16760516e+00, -1.16899309e+00,\n",
       "                     -1.20397280e+00, -1.21639532e+00, -1.22377543e+00, -1.22796831e+00,\n",
       "                     -1.23214368e+00, -1.24171313e+00, -1.24782469e+00, -1.25276297e+00,\n",
       "                     -1.27766052e+00, -1.29928298e+00, -1.31867417e+00, -1.32175584e+00,\n",
       "                     -1.32779815e+00, -1.32913595e+00, -1.33318454e+00, -1.35644140e+00,\n",
       "                     -1.35812348e+00, -1.38629436e+00, -1.40876722e+00, -1.42711636e+00,\n",
       "                     -1.43469090e+00, -1.43508453e+00, -1.46372610e+00, -1.46633707e+00,\n",
       "                     -1.48160454e+00, -1.49326648e+00, -1.51634749e+00, -1.51982575e+00,\n",
       "                     -1.53623451e+00, -1.54044504e+00, -1.55059741e+00, -1.55462968e+00,\n",
       "                     -1.56861592e+00, -1.60943791e+00, -1.68639895e+00, -1.70474809e+00,\n",
       "                     -1.76098781e+00, -1.77978328e+00, -1.79175947e+00, -1.81237876e+00,\n",
       "                     -1.82991124e+00, -1.85629799e+00, -1.87180218e+00, -1.90954250e+00,\n",
       "                     -1.91590790e+00, -1.94591015e+00, -2.15948425e+00, -2.19722458e+00,\n",
       "                     -2.25129180e+00, -2.30258509e+00, -2.35137526e+00, -2.39789527e+00,\n",
       "                     -2.45673577e+00, -2.48490665e+00, -2.50552594e+00, -2.52572864e+00,\n",
       "                     -2.56494936e+00, -2.77258872e+00, -2.89037176e+00, -3.31418600e+00,\n",
       "                     -3.58351894e+00, -3.45387764e+01]), auc_score=0.5522504846058378, privacy_risk=0.5360226257814825, accuracy=0.5360226257814826, tpr_ind=0.7034831795177136, tnr_ind=0.36856207204525154, test_train_ratio=1.0, dataset_size=[3359, 3359]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.01418226, 0.01629451, 0.01659626, 0.01931201,\n",
       "                     0.02414001, 0.02655401, 0.02776101, 0.03258902, 0.03560652,\n",
       "                     0.03802052, 0.04948702, 0.05310803, 0.05461678, 0.05703078,\n",
       "                     0.05884128, 0.05974653, 0.06216053, 0.06608328, 0.07000604,\n",
       "                     0.07242004, 0.07483404, 0.07785154, 0.07936029, 0.08418829,\n",
       "                     0.0902233 , 0.09293905, 0.0950513 , 0.11013881, 0.11345806,\n",
       "                     0.11557031, 0.12009656, 0.12945081, 0.13277007, 0.13488232,\n",
       "                     0.14634882, 0.16053108, 0.16113458, 0.16264333, 0.17712734,\n",
       "                     0.17954134, 0.18617984, 0.2027761 , 0.2063971 , 0.20850935,\n",
       "                     0.21907061, 0.22299336, 0.22540736, 0.23325287, 0.25648763,\n",
       "                     0.25920338, 0.27610139, 0.29088715, 0.29752565, 0.34791792,\n",
       "                     0.35063368, 0.35727218, 0.37235969, 0.38352444, 0.39016295,\n",
       "                     0.3964997 , 0.3989137 , 0.40464695, 0.4055522 , 0.41309596,\n",
       "                     0.42818346, 0.45473748, 0.45866023, 0.46288473, 0.46439348,\n",
       "                     0.48068799, 0.48189499, 0.51508751, 0.51659626, 0.52172601,\n",
       "                     0.52625226, 0.53681352, 0.54858177, 0.55159928, 0.55491853,\n",
       "                     0.56547978, 0.56608328, 0.57272179, 0.57302354, 0.60319855,\n",
       "                     0.6077248 , 0.61949306, 0.63156307, 0.63458057, 0.64333132,\n",
       "                     0.65057333, 0.65811708, 0.66053108, 0.6925166 , 0.7045866 ,\n",
       "                     0.71424261, 0.71786361, 0.74441762, 0.75075438, 0.75377188,\n",
       "                     0.75920338, 0.76554013, 0.77670489, 0.77972239, 0.7954134 ,\n",
       "                     0.7996379 , 0.80537115, 0.81200966, 0.81231141, 0.83464092,\n",
       "                     0.83856367, 0.84158117, 0.84580567, 0.85908268, 0.87054919,\n",
       "                     0.87447194, 0.87537719, 0.87869644, 0.88684369, 0.89076645,\n",
       "                     0.89197345, 0.8922752 , 0.9037417 , 0.9073627 , 0.91762221,\n",
       "                     0.92365721, 0.92456246, 0.92818346, 0.93029572, 0.93270972,\n",
       "                     0.93783947, 0.94719372, 0.94779722, 0.94870247, 0.94930597,\n",
       "                     0.95715148, 0.95805673, 0.95805673, 0.95866023, 0.96197948,\n",
       "                     0.96288473, 0.96439348, 0.97012674, 0.97133374, 0.97193724,\n",
       "                     0.97284249, 1.        ]), tpr=array([0.        , 0.02262045, 0.02555817, 0.02673325, 0.02996475,\n",
       "                     0.03407756, 0.03789659, 0.04054054, 0.04494712, 0.04905993,\n",
       "                     0.05434783, 0.06609871, 0.07109283, 0.07549941, 0.0787309 ,\n",
       "                     0.08019976, 0.08254994, 0.08578143, 0.08989424, 0.09430082,\n",
       "                     0.09723854, 0.10340776, 0.10693302, 0.10869565, 0.11486486,\n",
       "                     0.1239718 , 0.12896592, 0.13190364, 0.15041128, 0.15364277,\n",
       "                     0.15775558, 0.16274971, 0.17626322, 0.1806698 , 0.18448884,\n",
       "                     0.19858989, 0.21122209, 0.21357227, 0.21768508, 0.23178613,\n",
       "                     0.23501763, 0.24294947, 0.25940071, 0.26556992, 0.26733255,\n",
       "                     0.2793772 , 0.28349001, 0.28730905, 0.29641598, 0.32344301,\n",
       "                     0.32608696, 0.34224442, 0.35458284, 0.35840188, 0.40423032,\n",
       "                     0.40628672, 0.41480611, 0.43096357, 0.43889542, 0.44447709,\n",
       "                     0.4527027 , 0.45534665, 0.46298472, 0.46592244, 0.47620447,\n",
       "                     0.49089307, 0.51880141, 0.52232667, 0.52614571, 0.52908343,\n",
       "                     0.54964747, 0.55170388, 0.58578143, 0.58901293, 0.59400705,\n",
       "                     0.59988249, 0.61222092, 0.62220917, 0.62632197, 0.63014101,\n",
       "                     0.6407168 , 0.64247944, 0.64717979, 0.64864865, 0.67567568,\n",
       "                     0.68331375, 0.69565217, 0.70916569, 0.71092832, 0.7153349 ,\n",
       "                     0.72032902, 0.72855464, 0.72972973, 0.76380729, 0.77173913,\n",
       "                     0.7846651 , 0.78730905, 0.81051704, 0.81433608, 0.81580494,\n",
       "                     0.82050529, 0.82784959, 0.83666275, 0.83901293, 0.85634548,\n",
       "                     0.86222092, 0.86692127, 0.87279671, 0.87455934, 0.89336075,\n",
       "                     0.89747356, 0.90099882, 0.90599295, 0.91568743, 0.92391304,\n",
       "                     0.92920094, 0.93037603, 0.93301998, 0.93860165, 0.94065805,\n",
       "                     0.94153937, 0.94212691, 0.95446533, 0.95740306, 0.96650999,\n",
       "                     0.97091657, 0.97209166, 0.97414806, 0.97561692, 0.97679201,\n",
       "                     0.97855464, 0.98443008, 0.98501763, 0.98589894, 0.98795535,\n",
       "                     0.99030552, 0.99089307, 0.99206816, 0.9926557 , 0.99441833,\n",
       "                     0.99529965, 0.99618096, 0.99853114, 0.99941246, 0.99970623,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.82321557e-01, -2.23143551e-01,\n",
       "                     -2.41162057e-01, -2.51314428e-01, -2.68263987e-01, -2.87682072e-01,\n",
       "                     -3.36472237e-01, -3.56674944e-01, -3.67724780e-01, -4.05465108e-01,\n",
       "                     -4.24883194e-01, -4.27444015e-01, -4.35318071e-01, -4.70003629e-01,\n",
       "                     -4.85507816e-01, -4.92476485e-01, -4.96436886e-01, -5.10825624e-01,\n",
       "                     -5.30628251e-01, -5.38996501e-01, -5.59615788e-01, -6.06135804e-01,\n",
       "                     -6.19039208e-01, -6.26455806e-01, -6.32522559e-01, -6.41853886e-01,\n",
       "                     -6.44357016e-01, -6.46627165e-01, -6.56779536e-01, -6.63294217e-01,\n",
       "                     -6.93147181e-01, -7.25937003e-01, -7.30887509e-01, -7.43919506e-01,\n",
       "                     -7.49659391e-01, -7.53771802e-01, -7.62140052e-01, -7.73189888e-01,\n",
       "                     -7.80158558e-01, -7.98507696e-01, -8.18835396e-01, -8.26678573e-01,\n",
       "                     -8.47297860e-01, -8.50776125e-01, -8.57450232e-01, -8.69037847e-01,\n",
       "                     -8.83500909e-01, -8.85383194e-01, -8.93817876e-01, -9.12647741e-01,\n",
       "                     -9.16290732e-01, -9.31558204e-01, -9.41608540e-01, -9.44461609e-01,\n",
       "                     -9.50192284e-01, -9.55511445e-01, -9.66843011e-01, -9.67584026e-01,\n",
       "                     -9.71860583e-01, -9.80829253e-01, -9.90398704e-01, -9.93251773e-01,\n",
       "                     -9.98528830e-01, -1.00063188e+00, -1.01064352e+00, -1.01160091e+00,\n",
       "                     -1.01856958e+00, -1.02961942e+00, -1.04480958e+00, -1.04982212e+00,\n",
       "                     -1.06054034e+00, -1.06784063e+00, -1.07880966e+00, -1.08180517e+00,\n",
       "                     -1.09064412e+00, -1.09861229e+00, -1.12214279e+00, -1.12393010e+00,\n",
       "                     -1.13497993e+00, -1.15267951e+00, -1.15923691e+00, -1.16315081e+00,\n",
       "                     -1.16518678e+00, -1.18455472e+00, -1.18958407e+00, -1.19523912e+00,\n",
       "                     -1.20397280e+00, -1.22377543e+00, -1.22722967e+00, -1.23214368e+00,\n",
       "                     -1.25276297e+00, -1.26256697e+00, -1.28913061e+00, -1.29721473e+00,\n",
       "                     -1.29928298e+00, -1.32091160e+00, -1.32687094e+00, -1.33500107e+00,\n",
       "                     -1.33828514e+00, -1.34547237e+00, -1.35239281e+00, -1.35454566e+00,\n",
       "                     -1.36919993e+00, -1.38629436e+00, -1.40179855e+00, -1.42310833e+00,\n",
       "                     -1.42711636e+00, -1.43953888e+00, -1.47181653e+00, -1.48538526e+00,\n",
       "                     -1.49752000e+00, -1.50070471e+00, -1.50407740e+00, -1.52846885e+00,\n",
       "                     -1.55814462e+00, -1.60943791e+00, -1.61990921e+00, -1.63760879e+00,\n",
       "                     -1.67397643e+00, -1.70474809e+00, -1.72191590e+00, -1.72276660e+00,\n",
       "                     -1.72506809e+00, -1.78058617e+00, -1.79175947e+00, -1.88273125e+00,\n",
       "                     -1.91692261e+00, -1.94591015e+00, -1.96944065e+00, -2.00148000e+00,\n",
       "                     -2.01490302e+00, -2.12026354e+00, -2.13162729e+00, -2.19722458e+00,\n",
       "                     -2.25129180e+00, -2.35137526e+00, -2.39789527e+00, -2.42774824e+00,\n",
       "                     -2.48490665e+00, -2.63905733e+00, -2.73274281e+00, -2.90872090e+00,\n",
       "                     -3.68887945e+00, -4.00733319e+00, -3.45387764e+01]), auc_score=0.5556529575415199, privacy_risk=0.538801310822512, accuracy=0.5410836558499553, tpr_ind=0.709165687426557, tnr_ind=0.3684369342184671, test_train_ratio=0.9735605170387779, dataset_size=[3404, 3314]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00829138, 0.01066035, 0.01214095, 0.0127332 ,\n",
       "                     0.01332544, 0.01450992, 0.01687889, 0.0228013 , 0.02339354,\n",
       "                     0.02398579, 0.02457803, 0.02694699, 0.02961208, 0.03138881,\n",
       "                     0.03494226, 0.04056855, 0.04175304, 0.05330175, 0.05507847,\n",
       "                     0.05892804, 0.06100089, 0.06218537, 0.06573882, 0.07669529,\n",
       "                     0.09002073, 0.0938703 , 0.1095647 , 0.11282203, 0.115191  ,\n",
       "                     0.11696772, 0.12052117, 0.14421084, 0.15161386, 0.16049748,\n",
       "                     0.1649393 , 0.17115783, 0.19040569, 0.19514362, 0.20047379,\n",
       "                     0.21676044, 0.21705656, 0.2191294 , 0.24578028, 0.26413977,\n",
       "                     0.26591649, 0.26976606, 0.27716908, 0.28013029, 0.28397986,\n",
       "                     0.28812556, 0.2987859 , 0.3201066 , 0.32306781, 0.32425229,\n",
       "                     0.40775837, 0.41042345, 0.41220018, 0.46313296, 0.47290495,\n",
       "                     0.47734676, 0.48001184, 0.48800711, 0.49481789, 0.49689073,\n",
       "                     0.50192479, 0.54219722, 0.55167308, 0.56262955, 0.5732899 ,\n",
       "                     0.58158129, 0.58483861, 0.58661534, 0.58839206, 0.59638733,\n",
       "                     0.61474682, 0.62185372, 0.6245188 , 0.64228605, 0.64672786,\n",
       "                     0.64909683, 0.66538348, 0.6970684 , 0.70565591, 0.71483565,\n",
       "                     0.74059816, 0.74326325, 0.7453361 , 0.74800118, 0.75125851,\n",
       "                     0.75658869, 0.76843352, 0.79153094, 0.7980456 , 0.81581285,\n",
       "                     0.8178857 , 0.83742967, 0.84098312, 0.84601718, 0.8492745 ,\n",
       "                     0.85193959, 0.8563814 , 0.85993485, 0.86259994, 0.86408054,\n",
       "                     0.86467279, 0.86793012, 0.8705952 , 0.88036719, 0.88184779,\n",
       "                     0.88954694, 0.90228013, 0.9061297 , 0.91057151, 0.91294048,\n",
       "                     0.91530945, 0.91649393, 0.92360083, 0.9259698 , 0.92833876,\n",
       "                     0.93189221, 0.93426118, 0.93722239, 0.94047972, 0.94373704,\n",
       "                     0.94788274, 0.94906722, 0.95410127, 0.95439739, 0.95795084,\n",
       "                     0.95854309, 0.96031981, 0.96061593, 0.96535386, 0.96831507,\n",
       "                     0.96920344, 1.        ]), tpr=array([0.        , 0.01646214, 0.02035319, 0.0233463 , 0.02454355,\n",
       "                     0.02663873, 0.02963185, 0.03501946, 0.04190362, 0.04340018,\n",
       "                     0.04609398, 0.04788985, 0.05297815, 0.05716851, 0.05866507,\n",
       "                     0.06495061, 0.07093685, 0.07303203, 0.08500449, 0.08769829,\n",
       "                     0.09188866, 0.09338521, 0.0954804 , 0.10026938, 0.11254116,\n",
       "                     0.12990123, 0.13618677, 0.16162826, 0.16551931, 0.16881173,\n",
       "                     0.17150554, 0.17659383, 0.19724633, 0.20472912, 0.21310985,\n",
       "                     0.2196947 , 0.22448369, 0.24603412, 0.25082311, 0.25651003,\n",
       "                     0.27327148, 0.27626459, 0.27806046, 0.30350195, 0.3178689 ,\n",
       "                     0.31936546, 0.32445376, 0.33433104, 0.33822209, 0.34121521,\n",
       "                     0.34540557, 0.3540856 , 0.37563604, 0.38162227, 0.3825202 ,\n",
       "                     0.46722538, 0.4702185 , 0.47261299, 0.52439389, 0.52828494,\n",
       "                     0.53097875, 0.53516911, 0.5426519 , 0.54714157, 0.54983538,\n",
       "                     0.5582161 , 0.60101766, 0.61328943, 0.62825501, 0.64292128,\n",
       "                     0.65010476, 0.65519306, 0.65938342, 0.66267585, 0.67075726,\n",
       "                     0.69081113, 0.69799461, 0.70308291, 0.7210416 , 0.72463334,\n",
       "                     0.72762646, 0.74319066, 0.77731218, 0.78389704, 0.79197845,\n",
       "                     0.81592338, 0.81951512, 0.82071236, 0.82250823, 0.82550135,\n",
       "                     0.82909309, 0.83897037, 0.86471116, 0.87129602, 0.88177192,\n",
       "                     0.88326848, 0.90152649, 0.90631547, 0.91080515, 0.91290033,\n",
       "                     0.91589345, 0.92008381, 0.92457348, 0.92726729, 0.92906315,\n",
       "                     0.93145765, 0.93564801, 0.9380425 , 0.94791978, 0.94941634,\n",
       "                     0.95450464, 0.96587848, 0.96827297, 0.97276265, 0.97455852,\n",
       "                     0.97695301, 0.97755163, 0.97904819, 0.98084406, 0.9820413 ,\n",
       "                     0.98293924, 0.98473511, 0.98593236, 0.98742891, 0.98832685,\n",
       "                     0.98952409, 0.99072134, 0.99341515, 0.99461239, 0.99580964,\n",
       "                     0.99640826, 0.99700688, 0.99760551, 0.99880275, 0.99970069,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.43100844e-01, -1.82321557e-01,\n",
       "                     -2.23143551e-01, -2.51314428e-01, -2.62364264e-01, -2.87682072e-01,\n",
       "                     -3.30241687e-01, -3.36472237e-01, -3.67724780e-01, -4.05465108e-01,\n",
       "                     -4.24883194e-01, -4.51985124e-01, -4.70003629e-01, -5.10825624e-01,\n",
       "                     -5.30628251e-01, -5.38996501e-01, -5.59615788e-01, -5.75364145e-01,\n",
       "                     -5.79818495e-01, -5.87786665e-01, -6.19039208e-01, -6.28608659e-01,\n",
       "                     -6.55875786e-01, -6.66944808e-01, -6.69049629e-01, -6.93147181e-01,\n",
       "                     -7.30887509e-01, -7.37598943e-01, -7.47214402e-01, -7.50305594e-01,\n",
       "                     -7.69839801e-01, -7.70108222e-01, -7.78669354e-01, -7.80158558e-01,\n",
       "                     -7.82759339e-01, -7.98507696e-01, -8.10930216e-01, -8.16761137e-01,\n",
       "                     -8.26678573e-01, -8.32909123e-01, -8.47297860e-01, -8.50653568e-01,\n",
       "                     -8.64997437e-01, -8.75468737e-01, -8.80358723e-01, -8.97941593e-01,\n",
       "                     -9.00786545e-01, -9.16290732e-01, -9.44461609e-01, -9.63437510e-01,\n",
       "                     -9.70357953e-01, -9.74559640e-01, -9.80829253e-01, -9.86554880e-01,\n",
       "                     -9.93251773e-01, -1.01160091e+00, -1.01422490e+00, -1.01856958e+00,\n",
       "                     -1.02165125e+00, -1.02450432e+00, -1.02961942e+00, -1.05314991e+00,\n",
       "                     -1.06087196e+00, -1.07451474e+00, -1.07502629e+00, -1.08221848e+00,\n",
       "                     -1.09192330e+00, -1.09861229e+00, -1.11240561e+00, -1.11803037e+00,\n",
       "                     -1.12214279e+00, -1.12846525e+00, -1.13497993e+00, -1.14716551e+00,\n",
       "                     -1.15267951e+00, -1.15577070e+00, -1.16315081e+00, -1.17865500e+00,\n",
       "                     -1.22377543e+00, -1.23053983e+00, -1.24268732e+00, -1.25276297e+00,\n",
       "                     -1.25804003e+00, -1.29129663e+00, -1.29928298e+00, -1.32175584e+00,\n",
       "                     -1.34373475e+00, -1.36097655e+00, -1.36524095e+00, -1.37868976e+00,\n",
       "                     -1.38629436e+00, -1.41981705e+00, -1.42825856e+00, -1.43508453e+00,\n",
       "                     -1.43820222e+00, -1.44691898e+00, -1.45083288e+00, -1.45528723e+00,\n",
       "                     -1.48160454e+00, -1.50407740e+00, -1.52605630e+00, -1.54044504e+00,\n",
       "                     -1.57553636e+00, -1.58412010e+00, -1.59504917e+00, -1.60943791e+00,\n",
       "                     -1.65678403e+00, -1.68639895e+00, -1.71008144e+00, -1.71900011e+00,\n",
       "                     -1.77070606e+00, -1.78058617e+00, -1.79175947e+00, -1.85238409e+00,\n",
       "                     -1.87180218e+00, -1.88706965e+00, -1.94591015e+00, -2.04769284e+00,\n",
       "                     -2.07944154e+00, -2.12026354e+00, -2.19722458e+00, -2.21920348e+00,\n",
       "                     -2.23359222e+00, -2.30258509e+00, -2.35137526e+00, -2.40794561e+00,\n",
       "                     -2.44234704e+00, -2.56494936e+00, -2.63905733e+00, -2.74084002e+00,\n",
       "                     -2.86220088e+00, -2.99573227e+00, -3.07577498e+00, -3.09104245e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5576616187270315, privacy_risk=0.540121889036324, accuracy=0.5388508484668056, tpr_ind=0.7773121819814427, tnr_ind=0.30293159609120524, test_train_ratio=1.010775217000898, dataset_size=[3341, 3377]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.01215896, 0.0133452 , 0.01571767, 0.01986951,\n",
       "                     0.01986951, 0.02342823, 0.02639383, 0.02817319, 0.03084223,\n",
       "                     0.03380783, 0.03766311, 0.03884935, 0.04448399, 0.04744958,\n",
       "                     0.05219454, 0.05634638, 0.05634638, 0.05753262, 0.0613879 ,\n",
       "                     0.0643535 , 0.06969158, 0.0717675 , 0.07354686, 0.08362989,\n",
       "                     0.08718861, 0.08867141, 0.10053381, 0.10468565, 0.11328588,\n",
       "                     0.12188612, 0.12603796, 0.12781732, 0.1301898 , 0.13790036,\n",
       "                     0.14383155, 0.15005931, 0.15213523, 0.15332147, 0.16073547,\n",
       "                     0.16429419, 0.17022539, 0.21975089, 0.22241993, 0.23457888,\n",
       "                     0.23724792, 0.2529656 , 0.28024911, 0.29744958, 0.31465006,\n",
       "                     0.32443654, 0.33659549, 0.34371293, 0.34667853, 0.35379597,\n",
       "                     0.35587189, 0.3609134 , 0.3831554 , 0.41073547, 0.41103203,\n",
       "                     0.41725979, 0.41785291, 0.4223013 , 0.42467378, 0.43090154,\n",
       "                     0.43327402, 0.43772242, 0.4519573 , 0.46826809, 0.50948992,\n",
       "                     0.51393832, 0.51868327, 0.52105575, 0.52194543, 0.52787663,\n",
       "                     0.53469751, 0.54062871, 0.5495255 , 0.55604982, 0.56168446,\n",
       "                     0.56405694, 0.56524318, 0.61180308, 0.6153618 , 0.64976275,\n",
       "                     0.65658363, 0.66933571, 0.68505338, 0.69869514, 0.70136418,\n",
       "                     0.70818505, 0.70937129, 0.74317912, 0.74822064, 0.75415184,\n",
       "                     0.80931198, 0.81613286, 0.82384342, 0.82799526, 0.83362989,\n",
       "                     0.83778173, 0.86625148, 0.86951364, 0.87841044, 0.8890866 ,\n",
       "                     0.89442467, 0.89679715, 0.89709371, 0.89827995, 0.91518387,\n",
       "                     0.92289442, 0.9297153 , 0.93297746, 0.93446026, 0.9356465 ,\n",
       "                     0.93772242, 0.93801898, 0.94424674, 0.94543298, 0.9460261 ,\n",
       "                     0.95017794, 0.95106762, 0.95551601, 0.95581257, 0.95610913,\n",
       "                     0.95877817, 0.95907473, 0.96204033, 0.96411625, 0.96915777,\n",
       "                     0.97064057, 0.97123369, 0.97241993, 1.        ]), tpr=array([0.        , 0.02450687, 0.02659892, 0.0301853 , 0.0385535 ,\n",
       "                     0.04064555, 0.04512851, 0.04901375, 0.05349671, 0.05708308,\n",
       "                     0.06126718, 0.06963539, 0.07232516, 0.07830245, 0.08308428,\n",
       "                     0.08637179, 0.09354453, 0.09473999, 0.09742977, 0.10161387,\n",
       "                     0.10759115, 0.11446503, 0.11625822, 0.12044232, 0.13538553,\n",
       "                     0.1398685 , 0.14465033, 0.16168559, 0.16766288, 0.178422  ,\n",
       "                     0.18828452, 0.19157203, 0.19456067, 0.19635386, 0.20322773,\n",
       "                     0.21129707, 0.21578004, 0.21846981, 0.21966527, 0.22952779,\n",
       "                     0.23371189, 0.23759713, 0.28750747, 0.29109384, 0.30394501,\n",
       "                     0.30723252, 0.32516438, 0.34907352, 0.36969516, 0.3852361 ,\n",
       "                     0.39270771, 0.40765093, 0.4154214 , 0.41811118, 0.42438733,\n",
       "                     0.43156007, 0.43604304, 0.45666467, 0.48266587, 0.48386133,\n",
       "                     0.48894202, 0.49073521, 0.49462044, 0.49671249, 0.50358637,\n",
       "                     0.50627615, 0.51016139, 0.52211596, 0.53825463, 0.58368201,\n",
       "                     0.58965929, 0.59503885, 0.59742977, 0.59952182, 0.60520024,\n",
       "                     0.61267185, 0.62133891, 0.62821279, 0.63478781, 0.64345487,\n",
       "                     0.64614465, 0.64734011, 0.69396294, 0.69964136, 0.73341303,\n",
       "                     0.73998805, 0.75224148, 0.76748356, 0.78093246, 0.78302451,\n",
       "                     0.78750747, 0.78989839, 0.81589958, 0.81978482, 0.82486551,\n",
       "                     0.86969516, 0.88015541, 0.8861327 , 0.89181112, 0.89838613,\n",
       "                     0.90257023, 0.9237896 , 0.92588165, 0.93185894, 0.94321578,\n",
       "                     0.94590556, 0.94859534, 0.95008966, 0.95128512, 0.96383742,\n",
       "                     0.96891811, 0.97459653, 0.97519426, 0.97698745, 0.97758518,\n",
       "                     0.97878063, 0.97967723, 0.9832636 , 0.98445906, 0.98565451,\n",
       "                     0.98834429, 0.98894202, 0.99103407, 0.99133293, 0.99193066,\n",
       "                     0.99282726, 0.99312612, 0.99671249, 0.99731022, 0.99820681,\n",
       "                     0.99880454, 0.99910341, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -1.54150680e-01,\n",
       "                     -2.23143551e-01, -2.51314428e-01, -2.87682072e-01, -3.25422400e-01,\n",
       "                     -3.36472237e-01, -3.48306694e-01, -3.56674944e-01, -4.05465108e-01,\n",
       "                     -4.41832752e-01, -4.70003629e-01, -4.85507816e-01, -4.92476485e-01,\n",
       "                     -5.10825624e-01, -5.59615788e-01, -5.75364145e-01, -5.79818495e-01,\n",
       "                     -5.87786665e-01, -6.02175402e-01, -6.06135804e-01, -6.19039208e-01,\n",
       "                     -6.20576488e-01, -6.24154309e-01, -6.28608659e-01, -6.39079959e-01,\n",
       "                     -6.41853886e-01, -6.64976304e-01, -6.93147181e-01, -7.37598943e-01,\n",
       "                     -7.41937345e-01, -7.73189888e-01, -7.76528789e-01, -7.81700578e-01,\n",
       "                     -7.88457360e-01, -7.98507696e-01, -8.10930216e-01, -8.20980552e-01,\n",
       "                     -8.26678573e-01, -8.36248024e-01, -8.40430881e-01, -8.47297860e-01,\n",
       "                     -8.53920401e-01, -8.60201265e-01, -8.75468737e-01, -8.80663554e-01,\n",
       "                     -8.83887308e-01, -8.85038188e-01, -9.08258560e-01, -9.16290732e-01,\n",
       "                     -9.31558204e-01, -9.38269639e-01, -9.44461609e-01, -9.49080555e-01,\n",
       "                     -9.55511445e-01, -9.75379648e-01, -9.80829253e-01, -1.01160091e+00,\n",
       "                     -1.03798767e+00, -1.04145387e+00, -1.04596856e+00, -1.04982212e+00,\n",
       "                     -1.05416053e+00, -1.06087196e+00, -1.07263680e+00, -1.08180517e+00,\n",
       "                     -1.08618977e+00, -1.09861229e+00, -1.11514159e+00, -1.13497993e+00,\n",
       "                     -1.13943428e+00, -1.14513230e+00, -1.14990558e+00, -1.15057203e+00,\n",
       "                     -1.15449275e+00, -1.15496523e+00, -1.15745279e+00, -1.16530366e+00,\n",
       "                     -1.17007125e+00, -1.17865500e+00, -1.21544521e+00, -1.22994829e+00,\n",
       "                     -1.23361752e+00, -1.25276297e+00, -1.25624123e+00, -1.27218105e+00,\n",
       "                     -1.29928298e+00, -1.31218639e+00, -1.35239281e+00, -1.35454566e+00,\n",
       "                     -1.38629436e+00, -1.40534256e+00, -1.41528190e+00, -1.42551507e+00,\n",
       "                     -1.42825856e+00, -1.44691898e+00, -1.45001018e+00, -1.45225233e+00,\n",
       "                     -1.45528723e+00, -1.47389242e+00, -1.51982575e+00, -1.56861592e+00,\n",
       "                     -1.58816051e+00, -1.60943791e+00, -1.67397643e+00, -1.68639895e+00,\n",
       "                     -1.74919985e+00, -1.80359393e+00, -1.83022575e+00, -1.85135157e+00,\n",
       "                     -1.87180218e+00, -1.92181260e+00, -1.94591015e+00, -1.98100147e+00,\n",
       "                     -1.99243016e+00, -2.00372972e+00, -2.07944154e+00, -2.11021320e+00,\n",
       "                     -2.15948425e+00, -2.30258509e+00, -2.31676973e+00, -2.39789527e+00,\n",
       "                     -2.48490665e+00, -2.53897387e+00, -2.56494936e+00, -2.61495978e+00,\n",
       "                     -2.63905733e+00, -2.94443898e+00, -3.29583687e+00, -3.46573590e+00,\n",
       "                     -3.68051120e+00, -3.45387764e+01]), auc_score=0.5642027820970703, privacy_risk=0.542139779868528, accuracy=0.5415302173265852, tpr_ind=0.6996413628212791, tnr_ind=0.384638196915777, test_train_ratio=1.0077704722056187, dataset_size=[3346, 3372]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00955509, 0.01134667, 0.01373544, 0.01552702,\n",
       "                     0.0173186 , 0.0262765 , 0.03015826, 0.03433861, 0.03583159,\n",
       "                     0.04031054, 0.0438937 , 0.04478949, 0.04628247, 0.052553  ,\n",
       "                     0.05553897, 0.06001792, 0.06061511, 0.06778143, 0.07435055,\n",
       "                     0.1054046 , 0.11048074, 0.11914004, 0.12421618, 0.12660496,\n",
       "                     0.15347865, 0.15616602, 0.15974918, 0.16064497, 0.1752762 ,\n",
       "                     0.18094954, 0.20453867, 0.20782323, 0.21797552, 0.22185727,\n",
       "                     0.22364885, 0.22573903, 0.2278292 , 0.24335623, 0.2547029 ,\n",
       "                     0.26067483, 0.31143625, 0.33801135, 0.35801732, 0.38907136,\n",
       "                     0.39534189, 0.39862646, 0.40131383, 0.40429979, 0.41654225,\n",
       "                     0.46372051, 0.4652135 , 0.47417139, 0.48044192, 0.48402508,\n",
       "                     0.48880263, 0.51328755, 0.51567632, 0.52045387, 0.53209913,\n",
       "                     0.54613317, 0.55867423, 0.57718722, 0.58465213, 0.59092266,\n",
       "                     0.596596  , 0.60435951, 0.61092864, 0.62197671, 0.62675426,\n",
       "                     0.62794864, 0.63033741, 0.63511496, 0.63690654, 0.64496865,\n",
       "                     0.65541953, 0.66258585, 0.67124515, 0.68199463, 0.69125112,\n",
       "                     0.7014034 , 0.70319498, 0.70886832, 0.71633323, 0.72260376,\n",
       "                     0.7369364 , 0.73932517, 0.74201254, 0.74499851, 0.74888026,\n",
       "                     0.77784413, 0.78859361, 0.80919678, 0.81815467, 0.83248731,\n",
       "                     0.84144521, 0.84831293, 0.84980591, 0.85876381, 0.859361  ,\n",
       "                     0.86085399, 0.86115258, 0.86921469, 0.87369364, 0.87787399,\n",
       "                     0.88533891, 0.88951926, 0.89190803, 0.89310242, 0.89578979,\n",
       "                     0.89877575, 0.91280979, 0.91310839, 0.91370558, 0.92027471,\n",
       "                     0.92445506, 0.93072559, 0.93132278, 0.93162138, 0.93550314,\n",
       "                     0.93968349, 0.94655121, 0.94923858, 0.95103016, 0.95192595,\n",
       "                     0.95431472, 0.95550911, 0.95730069, 0.95849507, 0.96028665,\n",
       "                     0.96954315, 0.97163332, 1.        ]), tpr=array([0.        , 0.02315227, 0.02582369, 0.03027605, 0.03294746,\n",
       "                     0.03769665, 0.05253785, 0.05580291, 0.05788068, 0.0593648 ,\n",
       "                     0.06411398, 0.07123776, 0.07539329, 0.08014248, 0.08696943,\n",
       "                     0.08993767, 0.09349955, 0.09557732, 0.10299792, 0.10923123,\n",
       "                     0.1386168 , 0.14514693, 0.153458  , 0.1608786 , 0.16384684,\n",
       "                     0.18699911, 0.19352924, 0.19768477, 0.19946572, 0.21519739,\n",
       "                     0.22113387, 0.25111309, 0.25467498, 0.26565747, 0.26921935,\n",
       "                     0.27248442, 0.27396854, 0.27812407, 0.29029386, 0.30305729,\n",
       "                     0.31107153, 0.36598397, 0.39655684, 0.42267735, 0.45028198,\n",
       "                     0.45859305, 0.46126447, 0.46601365, 0.46987237, 0.48501039,\n",
       "                     0.52745622, 0.53072128, 0.53784506, 0.54526566, 0.55031167,\n",
       "                     0.55327991, 0.57880677, 0.58266548, 0.58682102, 0.60017809,\n",
       "                     0.61412882, 0.62451766, 0.64766993, 0.65241912, 0.65805877,\n",
       "                     0.66162066, 0.6708222 , 0.6782428 , 0.69486495, 0.70287919,\n",
       "                     0.70466014, 0.70881567, 0.71029979, 0.71237756, 0.72217275,\n",
       "                     0.73404571, 0.73938854, 0.74354408, 0.75512021, 0.76313446,\n",
       "                     0.77114871, 0.77382012, 0.78035025, 0.78539626, 0.79281686,\n",
       "                     0.809439  , 0.81211042, 0.81626595, 0.82190561, 0.82368655,\n",
       "                     0.84268329, 0.85158801, 0.86821015, 0.8750371 , 0.88898783,\n",
       "                     0.89700208, 0.9047195 , 0.90560997, 0.9133274 , 0.91451469,\n",
       "                     0.91718611, 0.92015435, 0.92638765, 0.93202731, 0.93529237,\n",
       "                     0.93915108, 0.94390027, 0.94538439, 0.94746215, 0.95161769,\n",
       "                     0.95488275, 0.96734936, 0.96764619, 0.96883348, 0.97180172,\n",
       "                     0.97298902, 0.97655091, 0.97744138, 0.97833185, 0.98040962,\n",
       "                     0.98159691, 0.98426833, 0.98753339, 0.98872069, 0.98931434,\n",
       "                     0.99020481, 0.99079846, 0.9913921 , 0.99168893, 0.99198575,\n",
       "                     0.99970318, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.05360516e-01, -1.82321557e-01,\n",
       "                     -2.87682072e-01, -3.18453731e-01, -4.05465108e-01, -4.35318071e-01,\n",
       "                     -4.51985124e-01, -4.70003629e-01, -4.85507816e-01, -5.10825624e-01,\n",
       "                     -5.38996501e-01, -5.59615788e-01, -5.78077851e-01, -5.87786665e-01,\n",
       "                     -6.06135804e-01, -6.19039208e-01, -6.31271777e-01, -6.44357016e-01,\n",
       "                     -6.93147181e-01, -7.15620036e-01, -7.28238500e-01, -7.32367894e-01,\n",
       "                     -7.41937345e-01, -7.49236647e-01, -7.59105148e-01, -7.62140052e-01,\n",
       "                     -7.73189888e-01, -7.83298278e-01, -7.88457360e-01, -8.05414482e-01,\n",
       "                     -8.10930216e-01, -8.43429384e-01, -8.47297860e-01, -8.60201265e-01,\n",
       "                     -8.75468737e-01, -8.87303195e-01, -8.91598119e-01, -8.92760234e-01,\n",
       "                     -8.93817876e-01, -8.97741373e-01, -9.02605279e-01, -9.16290732e-01,\n",
       "                     -9.31232312e-01, -9.44461609e-01, -9.80829253e-01, -9.88611393e-01,\n",
       "                     -9.90398704e-01, -9.95428052e-01, -9.95580063e-01, -1.00330211e+00,\n",
       "                     -1.01160091e+00, -1.01523068e+00, -1.01693426e+00, -1.02961942e+00,\n",
       "                     -1.06310560e+00, -1.07263680e+00, -1.07451474e+00, -1.07613943e+00,\n",
       "                     -1.08432633e+00, -1.08904284e+00, -1.09861229e+00, -1.13943428e+00,\n",
       "                     -1.14990558e+00, -1.15267951e+00, -1.17118298e+00, -1.17557333e+00,\n",
       "                     -1.17865500e+00, -1.19279950e+00, -1.20397280e+00, -1.21109027e+00,\n",
       "                     -1.22377543e+00, -1.23214368e+00, -1.23969089e+00, -1.25276297e+00,\n",
       "                     -1.26851133e+00, -1.27296568e+00, -1.27808078e+00, -1.27887411e+00,\n",
       "                     -1.28913061e+00, -1.29928298e+00, -1.30340670e+00, -1.30992138e+00,\n",
       "                     -1.31372367e+00, -1.32175584e+00, -1.32913595e+00, -1.33123458e+00,\n",
       "                     -1.33222714e+00, -1.34373475e+00, -1.38238046e+00, -1.38629436e+00,\n",
       "                     -1.39518331e+00, -1.39710528e+00, -1.41771056e+00, -1.43155095e+00,\n",
       "                     -1.45143366e+00, -1.46633707e+00, -1.48683559e+00, -1.50407740e+00,\n",
       "                     -1.51634749e+00, -1.52605630e+00, -1.53018854e+00, -1.57734960e+00,\n",
       "                     -1.60943791e+00, -1.65455835e+00, -1.67006253e+00, -1.72276660e+00,\n",
       "                     -1.74296931e+00, -1.75539183e+00, -1.76098781e+00, -1.77978328e+00,\n",
       "                     -1.79175947e+00, -1.83258146e+00, -1.85629799e+00, -1.87180218e+00,\n",
       "                     -1.94591015e+00, -1.99243016e+00, -2.03688193e+00, -2.07944154e+00,\n",
       "                     -2.11021320e+00, -2.22161603e+00, -2.22707754e+00, -2.30258509e+00,\n",
       "                     -2.35137526e+00, -2.36712361e+00, -2.39789527e+00, -2.67414865e+00,\n",
       "                     -2.83321334e+00, -2.89037176e+00, -2.94038218e+00, -3.09104245e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5541998909665977, privacy_risk=0.539313091338031, accuracy=0.5398928252456088, tpr_ind=0.7340457108934402, tnr_ind=0.3445804717826217, test_train_ratio=0.9940635203324428, dataset_size=[3369, 3349]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00850191, 0.01201994, 0.01319261, 0.01465846,\n",
       "                     0.01583113, 0.01700381, 0.02081501, 0.02198769, 0.02433304,\n",
       "                     0.02579889, 0.02697156, 0.02961009, 0.03723248, 0.04250953,\n",
       "                     0.04807974, 0.05013193, 0.05218411, 0.05247728, 0.07065377,\n",
       "                     0.08032835, 0.08765758, 0.09000293, 0.09264145, 0.09850484,\n",
       "                     0.10466139, 0.10788625, 0.12049252, 0.12459689, 0.12811492,\n",
       "                     0.13104661, 0.13661683, 0.13925535, 0.14218704, 0.14365289,\n",
       "                     0.14629141, 0.15039578, 0.15919085, 0.16886544, 0.1844034 ,\n",
       "                     0.19114629, 0.20316623, 0.21342715, 0.21606567, 0.22280856,\n",
       "                     0.23306948, 0.24157139, 0.27059513, 0.27499267, 0.27880387,\n",
       "                     0.28085605, 0.2937555 , 0.30460276, 0.31134565, 0.3175022 ,\n",
       "                     0.32922897, 0.33685136, 0.35092348, 0.3573732 , 0.36382293,\n",
       "                     0.36675462, 0.38639695, 0.40515978, 0.41043682, 0.41424802,\n",
       "                     0.41864556, 0.43828789, 0.44444444, 0.45206684, 0.46701847,\n",
       "                     0.47405453, 0.53063618, 0.53298153, 0.53884491, 0.53943125,\n",
       "                     0.55027851, 0.55408971, 0.55995309, 0.56904134, 0.57255937,\n",
       "                     0.58692466, 0.59806508, 0.59923776, 0.64673116, 0.66314864,\n",
       "                     0.66783934, 0.66813251, 0.68308414, 0.69246555, 0.70008795,\n",
       "                     0.70477866, 0.7062445 , 0.70800352, 0.70946936, 0.71797127,\n",
       "                     0.73028437, 0.73732043, 0.74699502, 0.7604808 , 0.76956904,\n",
       "                     0.77836412, 0.78334799, 0.80944005, 0.81207857, 0.81794195,\n",
       "                     0.82439167, 0.82820287, 0.83611844, 0.84139549, 0.86426268,\n",
       "                     0.87012606, 0.88449135, 0.89182058, 0.89592495, 0.89592495,\n",
       "                     0.89680446, 0.89914981, 0.9020815 , 0.92318968, 0.9249487 ,\n",
       "                     0.92700088, 0.92875989, 0.93579595, 0.93784814, 0.93960715,\n",
       "                     0.94517737, 0.94517737, 0.94664321, 0.94840223, 0.95367927,\n",
       "                     0.95514512, 0.95573146, 0.95836998, 1.        ]), tpr=array([0.        , 0.02146961, 0.02419111, 0.02630783, 0.02812217,\n",
       "                     0.02963411, 0.03084366, 0.03719383, 0.04293922, 0.04747505,\n",
       "                     0.048987  , 0.05110372, 0.05443   , 0.06773511, 0.07499244,\n",
       "                     0.07952827, 0.08194738, 0.08466888, 0.08618083, 0.11067433,\n",
       "                     0.12337466, 0.12912005, 0.13335349, 0.13607499, 0.14514666,\n",
       "                     0.15512549, 0.15935894, 0.17478077, 0.17871182, 0.18324766,\n",
       "                     0.1874811 , 0.19352888, 0.19745993, 0.20078621, 0.20229816,\n",
       "                     0.20622921, 0.20985788, 0.21802238, 0.23042032, 0.24342304,\n",
       "                     0.24977321, 0.26065921, 0.26973087, 0.27245237, 0.28212882,\n",
       "                     0.28999093, 0.30692471, 0.34290898, 0.3450257 , 0.35016631,\n",
       "                     0.35470215, 0.37012398, 0.37980042, 0.38887209, 0.39552464,\n",
       "                     0.40822498, 0.41397037, 0.42969459, 0.43271848, 0.44088298,\n",
       "                     0.44420925, 0.46144542, 0.48140308, 0.48593892, 0.49047475,\n",
       "                     0.49773208, 0.52010886, 0.52343514, 0.53099486, 0.55004536,\n",
       "                     0.55669791, 0.6168733 , 0.61989719, 0.62715452, 0.63108558,\n",
       "                     0.64076202, 0.64529785, 0.65195041, 0.66192924, 0.66404596,\n",
       "                     0.67735107, 0.69126096, 0.69307529, 0.72512852, 0.7417599 ,\n",
       "                     0.74387663, 0.74508618, 0.76020562, 0.76867251, 0.7798609 ,\n",
       "                     0.78469912, 0.78560629, 0.78681585, 0.78893257, 0.7961899 ,\n",
       "                     0.80858784, 0.81584518, 0.82642879, 0.83640762, 0.84668884,\n",
       "                     0.85485334, 0.85938917, 0.88660417, 0.88902328, 0.89325673,\n",
       "                     0.89869973, 0.90263078, 0.90777139, 0.91170245, 0.92863623,\n",
       "                     0.93498639, 0.94708195, 0.95131539, 0.95585122, 0.956456  ,\n",
       "                     0.95827034, 0.96068945, 0.96220139, 0.97973995, 0.98155428,\n",
       "                     0.98185667, 0.98246145, 0.98760206, 0.98850922, 0.98971878,\n",
       "                     0.99274267, 0.99364983, 0.99637133, 0.99758089, 0.99848806,\n",
       "                     0.99879044, 0.99969761, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.05360516e-01, -1.33531393e-01,\n",
       "                     -1.54150680e-01, -1.82321557e-01, -2.23143551e-01, -2.51314428e-01,\n",
       "                     -2.74436846e-01, -2.87682072e-01, -3.36472237e-01, -3.56674944e-01,\n",
       "                     -3.74693449e-01, -4.05465108e-01, -5.10825624e-01, -5.50046337e-01,\n",
       "                     -5.59615788e-01, -5.75364145e-01, -5.87786665e-01, -5.89157467e-01,\n",
       "                     -6.06135804e-01, -6.10909082e-01, -6.19039208e-01, -6.35988767e-01,\n",
       "                     -6.41853886e-01, -6.46627165e-01, -6.56779536e-01, -6.93147181e-01,\n",
       "                     -7.30887509e-01, -7.57685702e-01, -7.62140052e-01, -7.65467842e-01,\n",
       "                     -7.67255153e-01, -7.80158558e-01, -7.88457360e-01, -8.02346473e-01,\n",
       "                     -8.10930216e-01, -8.15036998e-01, -8.19027426e-01, -8.23767363e-01,\n",
       "                     -8.47297860e-01, -8.59132318e-01, -8.75468737e-01, -8.93817876e-01,\n",
       "                     -9.03711950e-01, -9.16290732e-01, -9.23408200e-01, -9.34609312e-01,\n",
       "                     -9.44461609e-01, -9.50976290e-01, -9.55511445e-01, -9.58523495e-01,\n",
       "                     -9.65080896e-01, -9.68250471e-01, -9.69400557e-01, -9.80829253e-01,\n",
       "                     -9.87386654e-01, -9.90398704e-01, -9.93251773e-01, -9.94622575e-01,\n",
       "                     -1.00330211e+00, -1.00680474e+00, -1.00884229e+00, -1.02961942e+00,\n",
       "                     -1.05314991e+00, -1.05605267e+00, -1.06657293e+00, -1.06784063e+00,\n",
       "                     -1.07158362e+00, -1.09861229e+00, -1.11365017e+00, -1.11687006e+00,\n",
       "                     -1.13140211e+00, -1.13943428e+00, -1.14862271e+00, -1.15923691e+00,\n",
       "                     -1.16315081e+00, -1.17163742e+00, -1.18562367e+00, -1.18958407e+00,\n",
       "                     -1.19254411e+00, -1.20179652e+00, -1.20397280e+00, -1.21709389e+00,\n",
       "                     -1.21841349e+00, -1.23214368e+00, -1.25276297e+00, -1.25846099e+00,\n",
       "                     -1.26291534e+00, -1.26427941e+00, -1.28785429e+00, -1.29928298e+00,\n",
       "                     -1.32175584e+00, -1.34992672e+00, -1.35454566e+00, -1.35533214e+00,\n",
       "                     -1.36524095e+00, -1.37190562e+00, -1.37868976e+00, -1.37891425e+00,\n",
       "                     -1.38629436e+00, -1.40282366e+00, -1.43508453e+00, -1.44691898e+00,\n",
       "                     -1.48807706e+00, -1.49165488e+00, -1.49549365e+00, -1.49752000e+00,\n",
       "                     -1.52939520e+00, -1.53916872e+00, -1.54044504e+00, -1.55814462e+00,\n",
       "                     -1.58045038e+00, -1.60943791e+00, -1.70474809e+00, -1.76358859e+00,\n",
       "                     -1.79175947e+00, -1.82454929e+00, -1.86381279e+00, -1.92181260e+00,\n",
       "                     -1.94591015e+00, -2.01490302e+00, -2.01881692e+00, -2.03688193e+00,\n",
       "                     -2.22462355e+00, -2.24070969e+00, -2.48490665e+00, -2.50325579e+00,\n",
       "                     -2.56494936e+00, -2.90872090e+00, -3.09104245e+00, -3.10608033e+00,\n",
       "                     -4.18965474e+00, -3.45387764e+01]), auc_score=0.5668164604154705, privacy_risk=0.5469187673207611, accuracy=0.544656147662995, tpr_ind=0.6930752948291503, tnr_ind=0.40076223981237175, test_train_ratio=1.0314484426973087, dataset_size=[3307, 3411]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00755515, 0.00906618, 0.01057721, 0.01239045,\n",
       "                     0.01571472, 0.01631913, 0.01783016, 0.02115443, 0.02175884,\n",
       "                     0.03052282, 0.03203385, 0.03686914, 0.0444243 , 0.04653974,\n",
       "                     0.05046842, 0.0546993 , 0.06013901, 0.06346328, 0.06618314,\n",
       "                     0.07132064, 0.07252947, 0.07524932, 0.07857359, 0.08159565,\n",
       "                     0.08703536, 0.08884859, 0.09126624, 0.09277727, 0.09489272,\n",
       "                     0.10033243, 0.10365669, 0.11151405, 0.11453611, 0.15744938,\n",
       "                     0.16409791, 0.17709278, 0.19159867, 0.19280749, 0.20187368,\n",
       "                     0.20670898, 0.20822001, 0.21184648, 0.21517075, 0.21698398,\n",
       "                     0.21819281, 0.2275612 , 0.22997885, 0.25143548, 0.26019946,\n",
       "                     0.26322152, 0.26866123, 0.27198549, 0.277123  , 0.2819583 ,\n",
       "                     0.28921124, 0.29132668, 0.32970686, 0.33303113, 0.33423995,\n",
       "                     0.37080689, 0.37805984, 0.39075249, 0.406165  , 0.41311574,\n",
       "                     0.4158356 , 0.42883046, 0.44212753, 0.44484739, 0.45421578,\n",
       "                     0.45754004, 0.45935328, 0.4753702 , 0.48594742, 0.51556361,\n",
       "                     0.51798126, 0.56996071, 0.58235116, 0.58597764, 0.58809308,\n",
       "                     0.59746147, 0.59987912, 0.63523723, 0.64007253, 0.64097915,\n",
       "                     0.65095195, 0.65971593, 0.66243578, 0.6633424 , 0.69537625,\n",
       "                     0.69628286, 0.69688728, 0.70414022, 0.7524932 , 0.75309761,\n",
       "                     0.75611967, 0.76820792, 0.76851012, 0.77183439, 0.77304322,\n",
       "                     0.77757631, 0.79177999, 0.79540647, 0.81051677, 0.81474766,\n",
       "                     0.82320943, 0.83439105, 0.83620429, 0.8368087 , 0.84466606,\n",
       "                     0.84799033, 0.85040798, 0.86914476, 0.88183741, 0.88727712,\n",
       "                     0.89150801, 0.920822  , 0.92172862, 0.92233303, 0.92505289,\n",
       "                     0.92928377, 0.94711393, 0.94892717, 0.94983379, 0.9504382 ,\n",
       "                     0.95225144, 0.95346026, 0.95889997, 0.95950438, 0.96131762,\n",
       "                     0.96313086, 0.96433968, 0.96705953, 0.96796615, 0.96947718,\n",
       "                     0.97219704, 0.97249924, 1.        ]), tpr=array([0.        , 0.0199472 , 0.02288061, 0.02522734, 0.02669405,\n",
       "                     0.03256087, 0.03461426, 0.03549428, 0.0398944 , 0.04194779,\n",
       "                     0.05192138, 0.05397477, 0.06042828, 0.06717512, 0.06952185,\n",
       "                     0.07509534, 0.07920211, 0.08976239, 0.09445585, 0.09650924,\n",
       "                     0.10002933, 0.1026694 , 0.10677618, 0.10970959, 0.11293634,\n",
       "                     0.11792314, 0.11968319, 0.12349663, 0.12555001, 0.12789674,\n",
       "                     0.13288354, 0.13552361, 0.14432385, 0.14872397, 0.19595189,\n",
       "                     0.20093869, 0.21824582, 0.23584629, 0.23819302, 0.24845996,\n",
       "                     0.25550015, 0.2587269 , 0.26312702, 0.2687005 , 0.27134057,\n",
       "                     0.27251393, 0.28131417, 0.28336756, 0.30595483, 0.31270167,\n",
       "                     0.31915518, 0.32267527, 0.32560868, 0.33470226, 0.34086242,\n",
       "                     0.34614256, 0.35171605, 0.39043708, 0.39542388, 0.39689058,\n",
       "                     0.43561162, 0.43883837, 0.45027867, 0.47081256, 0.47491933,\n",
       "                     0.47931945, 0.49163978, 0.50425345, 0.50542681, 0.51510707,\n",
       "                     0.5189205 , 0.52214726, 0.5423878 , 0.55910824, 0.58638897,\n",
       "                     0.58902904, 0.63684365, 0.64945732, 0.65239073, 0.6550308 ,\n",
       "                     0.66353769, 0.66588442, 0.7048988 , 0.71076562, 0.71252567,\n",
       "                     0.72191258, 0.72953945, 0.73247287, 0.73364623, 0.76239366,\n",
       "                     0.76444705, 0.76679378, 0.77471399, 0.81783514, 0.81959519,\n",
       "                     0.82164858, 0.83426225, 0.83543561, 0.83866236, 0.84042241,\n",
       "                     0.84599589, 0.85567615, 0.86124963, 0.87562335, 0.87914344,\n",
       "                     0.88677031, 0.89674391, 0.89821062, 0.89909064, 0.90466412,\n",
       "                     0.90730419, 0.91170431, 0.92549135, 0.93605163, 0.94074509,\n",
       "                     0.94250513, 0.96655911, 0.96773247, 0.9686125 , 0.97066588,\n",
       "                     0.97389264, 0.9835729 , 0.98533294, 0.98709299, 0.98826635,\n",
       "                     0.98973306, 0.99031974, 0.99266647, 0.99325315, 0.99383984,\n",
       "                     0.99471986, 0.99530654, 0.99706659, 0.99765327, 0.99794661,\n",
       "                     0.99970666, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -9.53101798e-02, -1.17783036e-01,\n",
       "                     -1.82321557e-01, -2.23143551e-01, -2.51314428e-01, -2.87682072e-01,\n",
       "                     -3.36472237e-01, -3.56674944e-01, -4.05465108e-01, -4.51985124e-01,\n",
       "                     -4.64305608e-01, -4.75423697e-01, -4.85507816e-01, -4.89548225e-01,\n",
       "                     -4.96436886e-01, -5.10825624e-01, -5.23248144e-01, -5.38996501e-01,\n",
       "                     -5.59615788e-01, -5.75364145e-01, -5.79818495e-01, -5.87786665e-01,\n",
       "                     -5.97837001e-01, -6.00773860e-01, -6.06135804e-01, -6.13104473e-01,\n",
       "                     -6.19039208e-01, -6.28608659e-01, -6.32522559e-01, -6.35988767e-01,\n",
       "                     -6.41853886e-01, -6.59245629e-01, -6.93147181e-01, -7.22134717e-01,\n",
       "                     -7.34646911e-01, -7.41937345e-01, -7.53771802e-01, -7.62140052e-01,\n",
       "                     -7.73189888e-01, -7.80158558e-01, -7.88457360e-01, -7.93230639e-01,\n",
       "                     -7.98507696e-01, -8.10930216e-01, -8.18310324e-01, -8.26678573e-01,\n",
       "                     -8.32344311e-01, -8.34797698e-01, -8.40783179e-01, -8.47297860e-01,\n",
       "                     -8.75468737e-01, -8.83500909e-01, -9.06721281e-01, -9.16290732e-01,\n",
       "                     -9.26762032e-01, -9.46143695e-01, -9.50976290e-01, -9.55511445e-01,\n",
       "                     -9.57839735e-01, -9.69400557e-01, -9.80829253e-01, -9.87946721e-01,\n",
       "                     -9.98528830e-01, -1.00552187e+00, -1.00726251e+00, -1.00948451e+00,\n",
       "                     -1.01160091e+00, -1.01435195e+00, -1.01856958e+00, -1.03609193e+00,\n",
       "                     -1.04400815e+00, -1.04454507e+00, -1.05838749e+00, -1.06087196e+00,\n",
       "                     -1.09861229e+00, -1.11399721e+00, -1.13140211e+00, -1.13497993e+00,\n",
       "                     -1.14356368e+00, -1.17865500e+00, -1.19186978e+00, -1.19392247e+00,\n",
       "                     -1.20397280e+00, -1.20709293e+00, -1.21924028e+00, -1.22377543e+00,\n",
       "                     -1.25276297e+00, -1.25567418e+00, -1.27296568e+00, -1.28785429e+00,\n",
       "                     -1.28913061e+00, -1.29183416e+00, -1.29928298e+00, -1.31218639e+00,\n",
       "                     -1.32020425e+00, -1.32175584e+00, -1.33977435e+00, -1.34373475e+00,\n",
       "                     -1.34602046e+00, -1.38629436e+00, -1.42500887e+00, -1.44571778e+00,\n",
       "                     -1.46633707e+00, -1.47810191e+00, -1.50407740e+00, -1.52605630e+00,\n",
       "                     -1.54044504e+00, -1.55537069e+00, -1.56397554e+00, -1.58240924e+00,\n",
       "                     -1.58793171e+00, -1.60386687e+00, -1.60943791e+00, -1.64222774e+00,\n",
       "                     -1.68459063e+00, -1.70474809e+00, -1.73460106e+00, -1.79175947e+00,\n",
       "                     -1.91959284e+00, -1.94157175e+00, -2.07944154e+00, -2.12026354e+00,\n",
       "                     -2.19722458e+00, -2.24070969e+00, -2.39789527e+00, -2.40919483e+00,\n",
       "                     -2.44234704e+00, -2.52572864e+00, -2.56494936e+00, -2.60268969e+00,\n",
       "                     -2.70805020e+00, -2.74084002e+00, -3.33220451e+00, -3.39002408e+00,\n",
       "                     -4.31748811e+00, -3.45387764e+01]), auc_score=0.5540931640518171, privacy_risk=0.5365804133743355, accuracy=0.5369157487347425, tpr_ind=0.559108242886477, tnr_ind=0.514052583862194, test_train_ratio=0.9706658844235846, dataset_size=[3409, 3309]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00823529, 0.00911765, 0.01294118, 0.01470588,\n",
       "                     0.01764706, 0.02294118, 0.02588235, 0.03117647, 0.03176471,\n",
       "                     0.03588235, 0.03676471, 0.04382353, 0.04558824, 0.05176471,\n",
       "                     0.055     , 0.05911765, 0.06088235, 0.06294118, 0.07764706,\n",
       "                     0.08088235, 0.09264706, 0.1       , 0.11058824, 0.13735294,\n",
       "                     0.14441176, 0.14882353, 0.15088235, 0.15882353, 0.16470588,\n",
       "                     0.16823529, 0.17352941, 0.17617647, 0.18911765, 0.21264706,\n",
       "                     0.21764706, 0.21941176, 0.23911765, 0.24294118, 0.26147059,\n",
       "                     0.26323529, 0.26911765, 0.27617647, 0.27794118, 0.28235294,\n",
       "                     0.3       , 0.30441176, 0.30735294, 0.31294118, 0.31882353,\n",
       "                     0.33735294, 0.34970588, 0.35882353, 0.37823529, 0.37911765,\n",
       "                     0.38176471, 0.38294118, 0.40235294, 0.41      , 0.41264706,\n",
       "                     0.42735294, 0.43205882, 0.43911765, 0.44941176, 0.45352941,\n",
       "                     0.46441176, 0.47911765, 0.48588235, 0.49323529, 0.49441176,\n",
       "                     0.49588235, 0.50764706, 0.51235294, 0.51647059, 0.52029412,\n",
       "                     0.52411765, 0.53264706, 0.55117647, 0.55764706, 0.56558824,\n",
       "                     0.56911765, 0.58029412, 0.58911765, 0.60205882, 0.60470588,\n",
       "                     0.62058824, 0.64941176, 0.65264706, 0.67647059, 0.67970588,\n",
       "                     0.68823529, 0.69941176, 0.70117647, 0.70911765, 0.73411765,\n",
       "                     0.73705882, 0.74205882, 0.74941176, 0.76058824, 0.76911765,\n",
       "                     0.77676471, 0.77882353, 0.78382353, 0.78911765, 0.79617647,\n",
       "                     0.80352941, 0.80705882, 0.80882353, 0.80911765, 0.82147059,\n",
       "                     0.82470588, 0.83323529, 0.83852941, 0.85088235, 0.86      ,\n",
       "                     0.86558824, 0.86676471, 0.87      , 0.89294118, 0.89676471,\n",
       "                     0.90382353, 0.91205882, 0.91470588, 0.92176471, 0.92588235,\n",
       "                     0.93058824, 0.93352941, 0.94352941, 0.94382353, 0.95      ,\n",
       "                     0.95147059, 0.95264706, 0.95323529, 0.95411765, 0.95441176,\n",
       "                     0.955     , 0.95705882, 0.95823529, 0.96088235, 0.96088235,\n",
       "                     0.96294118, 0.96441176, 0.96617647, 0.96941176, 1.        ]), tpr=array([0.        , 0.0198915 , 0.02350814, 0.02802893, 0.03044002,\n",
       "                     0.03375527, 0.03918023, 0.04219409, 0.04882459, 0.05153707,\n",
       "                     0.05726341, 0.05877034, 0.06871609, 0.0708258 , 0.07926462,\n",
       "                     0.08378541, 0.08860759, 0.09041591, 0.09252562, 0.10880048,\n",
       "                     0.11362266, 0.12869198, 0.14104882, 0.15762508, 0.19740808,\n",
       "                     0.20886076, 0.21277878, 0.21579265, 0.22694394, 0.23327306,\n",
       "                     0.23839662, 0.24291742, 0.24713683, 0.26069922, 0.2808921 ,\n",
       "                     0.28722122, 0.28963231, 0.31314045, 0.31735986, 0.33453888,\n",
       "                     0.33604581, 0.34267631, 0.35051236, 0.35262206, 0.35744424,\n",
       "                     0.38004822, 0.38396624, 0.38848704, 0.39451477, 0.4005425 ,\n",
       "                     0.42224231, 0.43309222, 0.44665461, 0.47046414, 0.47257384,\n",
       "                     0.47588909, 0.47709464, 0.4978903 , 0.50241109, 0.50572634,\n",
       "                     0.51959011, 0.52742616, 0.53465943, 0.54068716, 0.54581073,\n",
       "                     0.55424955, 0.57353828, 0.57986739, 0.58649789, 0.58860759,\n",
       "                     0.59041591, 0.60066305, 0.60548523, 0.6084991 , 0.61392405,\n",
       "                     0.61784207, 0.63019892, 0.64587101, 0.65340567, 0.65732369,\n",
       "                     0.66094033, 0.66576251, 0.67631103, 0.68444846, 0.68866787,\n",
       "                     0.70825799, 0.73267028, 0.73477999, 0.7588909 , 0.76039783,\n",
       "                     0.76702833, 0.77516576, 0.77637131, 0.78270042, 0.80168776,\n",
       "                     0.80379747, 0.80831826, 0.81525015, 0.82851115, 0.8363472 ,\n",
       "                     0.84056661, 0.84267631, 0.84779988, 0.85262206, 0.86106088,\n",
       "                     0.86769138, 0.8694997 , 0.87191079, 0.87492465, 0.88185654,\n",
       "                     0.88366486, 0.89119952, 0.8960217 , 0.90536468, 0.91711875,\n",
       "                     0.92103677, 0.92314647, 0.92646172, 0.94755877, 0.94966847,\n",
       "                     0.95750452, 0.960217  , 0.96353225, 0.96955998, 0.97136829,\n",
       "                     0.97438216, 0.97619048, 0.98282098, 0.98372514, 0.98704039,\n",
       "                     0.98824593, 0.9888487 , 0.99065702, 0.9912598 , 0.99156118,\n",
       "                     0.99216395, 0.99427366, 0.99457505, 0.99698614, 0.99728752,\n",
       "                     0.99849307, 0.99879445, 0.99969861, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -8.00427077e-02, -1.82321557e-01,\n",
       "                     -2.23143551e-01, -2.41162057e-01, -2.87682072e-01, -3.36472237e-01,\n",
       "                     -4.05465108e-01, -4.41832752e-01, -4.56758402e-01, -4.70003629e-01,\n",
       "                     -5.10825624e-01, -5.38996501e-01, -5.59615788e-01, -5.87786665e-01,\n",
       "                     -5.94707108e-01, -6.06135804e-01, -6.19039208e-01, -6.26136470e-01,\n",
       "                     -6.28608659e-01, -6.52325186e-01, -6.55875786e-01, -6.56105909e-01,\n",
       "                     -6.93147181e-01, -7.19122667e-01, -7.30887509e-01, -7.41937345e-01,\n",
       "                     -7.45790914e-01, -7.62140052e-01, -7.77704569e-01, -7.88457360e-01,\n",
       "                     -7.94929875e-01, -7.98507696e-01, -7.99253687e-01, -8.05625164e-01,\n",
       "                     -8.10930216e-01, -8.47297860e-01, -8.57450232e-01, -8.69603618e-01,\n",
       "                     -8.75468737e-01, -8.79249460e-01, -8.85038188e-01, -8.87303195e-01,\n",
       "                     -8.90972924e-01, -8.91998039e-01, -9.00786545e-01, -9.02867712e-01,\n",
       "                     -9.16290732e-01, -9.36093359e-01, -9.38269639e-01, -9.59775844e-01,\n",
       "                     -9.80829253e-01, -9.87138422e-01, -9.98528830e-01, -1.00330211e+00,\n",
       "                     -1.01160091e+00, -1.02338887e+00, -1.02961942e+00, -1.03609193e+00,\n",
       "                     -1.03889305e+00, -1.04596856e+00, -1.05605267e+00, -1.06471074e+00,\n",
       "                     -1.07880966e+00, -1.09861229e+00, -1.11411648e+00, -1.12986483e+00,\n",
       "                     -1.14306405e+00, -1.14513230e+00, -1.15267951e+00, -1.15577070e+00,\n",
       "                     -1.15923691e+00, -1.16315081e+00, -1.17007125e+00, -1.17272026e+00,\n",
       "                     -1.18426773e+00, -1.18455472e+00, -1.18784342e+00, -1.19625076e+00,\n",
       "                     -1.20397280e+00, -1.21639532e+00, -1.22377543e+00, -1.23676263e+00,\n",
       "                     -1.25276297e+00, -1.26803044e+00, -1.27197753e+00, -1.27296568e+00,\n",
       "                     -1.27745558e+00, -1.28093385e+00, -1.30340670e+00, -1.30933332e+00,\n",
       "                     -1.32175584e+00, -1.32492541e+00, -1.33750420e+00, -1.34992672e+00,\n",
       "                     -1.35239281e+00, -1.36431545e+00, -1.37486567e+00, -1.38629436e+00,\n",
       "                     -1.40399394e+00, -1.42138568e+00, -1.44345277e+00, -1.44691898e+00,\n",
       "                     -1.45528723e+00, -1.46283444e+00, -1.46633707e+00, -1.47590652e+00,\n",
       "                     -1.48160454e+00, -1.49923477e+00, -1.50407740e+00, -1.51732262e+00,\n",
       "                     -1.51787072e+00, -1.52885743e+00, -1.57288032e+00, -1.57818537e+00,\n",
       "                     -1.60943791e+00, -1.62745642e+00, -1.63482715e+00, -1.63760879e+00,\n",
       "                     -1.66915715e+00, -1.67397643e+00, -1.74523945e+00, -1.74919985e+00,\n",
       "                     -1.79175947e+00, -1.84054963e+00, -1.89711998e+00, -1.97155258e+00,\n",
       "                     -1.99243016e+00, -2.04475598e+00, -2.07944154e+00, -2.14006616e+00,\n",
       "                     -2.26868354e+00, -2.35137526e+00, -2.39789527e+00, -2.44234704e+00,\n",
       "                     -2.48490665e+00, -2.56494936e+00, -2.66549059e+00, -2.70805020e+00,\n",
       "                     -2.72457950e+00, -3.17805383e+00, -3.61091791e+00, -4.31748811e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5674613516292593, privacy_risk=0.5487759280927561, accuracy=0.5477820779994046, tpr_ind=0.6301989150090416, tnr_ind=0.4673529411764706, test_train_ratio=1.024713682941531, dataset_size=[3318, 3400]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.01329394, 0.01329394, 0.01654357, 0.01890694,\n",
       "                     0.02008863, 0.02186115, 0.02186115, 0.02570162, 0.03279173,\n",
       "                     0.0366322 , 0.03840473, 0.04313146, 0.04342688, 0.04519941,\n",
       "                     0.04667651, 0.04726736, 0.05110783, 0.05169867, 0.05258493,\n",
       "                     0.05612999, 0.05642541, 0.05997046, 0.06883309, 0.07090103,\n",
       "                     0.07444609, 0.07858198, 0.08301329, 0.10930576, 0.12407681,\n",
       "                     0.12555391, 0.12732644, 0.13589365, 0.13707533, 0.14180207,\n",
       "                     0.14387001, 0.15893648, 0.16720827, 0.17666174, 0.18345643,\n",
       "                     0.18434269, 0.18995569, 0.19084195, 0.19822747, 0.2014771 ,\n",
       "                     0.20531758, 0.21152142, 0.21802068, 0.23161004, 0.23338257,\n",
       "                     0.24194978, 0.24490399, 0.24815362, 0.28744461, 0.29926145,\n",
       "                     0.30251108, 0.30960118, 0.31285081, 0.34239291, 0.34771049,\n",
       "                     0.35923191, 0.37193501, 0.38109306, 0.38286558, 0.39675037,\n",
       "                     0.39881832, 0.40738552, 0.40738552, 0.41329394, 0.41536189,\n",
       "                     0.41861152, 0.44490399, 0.44992614, 0.47503693, 0.50605613,\n",
       "                     0.5211226 , 0.52466765, 0.52909897, 0.5323486 , 0.57193501,\n",
       "                     0.57548006, 0.58995569, 0.59143279, 0.59379616, 0.59645495,\n",
       "                     0.60029542, 0.60945347, 0.62008863, 0.62688331, 0.62924668,\n",
       "                     0.65081241, 0.65524372, 0.66322009, 0.66676514, 0.67208272,\n",
       "                     0.68744461, 0.68921713, 0.69039882, 0.70635155, 0.71639586,\n",
       "                     0.71816839, 0.7225997 , 0.73441654, 0.7450517 , 0.74830133,\n",
       "                     0.75923191, 0.78404727, 0.79704579, 0.80797637, 0.81211226,\n",
       "                     0.8127031 , 0.81654357, 0.82097489, 0.82363368, 0.84017725,\n",
       "                     0.84194978, 0.84401773, 0.8493353 , 0.8549483 , 0.88005908,\n",
       "                     0.90132939, 0.90192024, 0.90871492, 0.91107829, 0.91373708,\n",
       "                     0.93116691, 0.93412112, 0.93677991, 0.93766617, 0.9394387 ,\n",
       "                     0.94741507, 0.94889217, 0.95007386, 0.95420975, 0.95420975,\n",
       "                     0.95657312, 0.95805022, 0.96070901, 0.96159527, 0.96307238,\n",
       "                     0.96425406, 0.9648449 , 0.96720827, 0.96838996, 0.96927622,\n",
       "                     1.        ]), tpr=array([0.        , 0.0270027 , 0.03030303, 0.03450345, 0.03840384,\n",
       "                     0.04020402, 0.04170417, 0.04290429, 0.04830483, 0.05880588,\n",
       "                     0.0630063 , 0.06630663, 0.07530753, 0.0780078 , 0.08010801,\n",
       "                     0.08310831, 0.08550855, 0.09180918, 0.0930093 , 0.09810981,\n",
       "                     0.10111011, 0.10291029, 0.10711071, 0.11971197, 0.12271227,\n",
       "                     0.1260126 , 0.12961296, 0.13351335, 0.16711671, 0.18631863,\n",
       "                     0.18991899, 0.19321932, 0.20642064, 0.20852085, 0.21212121,\n",
       "                     0.21362136, 0.23252325, 0.24032403, 0.24992499, 0.25562556,\n",
       "                     0.25772577, 0.26762676, 0.26942694, 0.27452745, 0.27872787,\n",
       "                     0.28262826, 0.28712871, 0.29732973, 0.31143114, 0.31473147,\n",
       "                     0.32613261, 0.33123312, 0.33513351, 0.37083708, 0.37983798,\n",
       "                     0.38343834, 0.390039  , 0.3930393 , 0.41944194, 0.42694269,\n",
       "                     0.43594359, 0.44794479, 0.4560456 , 0.45814581, 0.47614761,\n",
       "                     0.47854785, 0.48964896, 0.49114911, 0.49894989, 0.50105011,\n",
       "                     0.5079508 , 0.53045305, 0.53615362, 0.56525653, 0.59225923,\n",
       "                     0.60516052, 0.60906091, 0.61656166, 0.61986199, 0.65676568,\n",
       "                     0.6609661 , 0.67476748, 0.67776778, 0.68166817, 0.68526853,\n",
       "                     0.68736874, 0.69336934, 0.70387039, 0.70927093, 0.71167117,\n",
       "                     0.73087309, 0.73447345, 0.73927393, 0.74317432, 0.74827483,\n",
       "                     0.75847585, 0.76177618, 0.76327633, 0.7749775 , 0.78367837,\n",
       "                     0.78607861, 0.78817882, 0.80318032, 0.81218122, 0.81878188,\n",
       "                     0.82988299, 0.85688569, 0.86558656, 0.87308731, 0.87638764,\n",
       "                     0.87728773, 0.88058806, 0.88268827, 0.88508851, 0.90189019,\n",
       "                     0.90279028, 0.90489049, 0.90909091, 0.91419142, 0.93669367,\n",
       "                     0.95139514, 0.95229523, 0.95619562, 0.95679568, 0.95919592,\n",
       "                     0.9759976 , 0.97719772, 0.98049805, 0.98139814, 0.98259826,\n",
       "                     0.98589859, 0.98769877, 0.98859886, 0.99009901, 0.99189919,\n",
       "                     0.99309931, 0.99429943, 0.99519952, 0.99609961, 0.9969997 ,\n",
       "                     0.99759976, 0.99819982, 0.99939994, 0.99969997, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -8.70113770e-02, -1.33531393e-01,\n",
       "                     -1.43100844e-01, -1.54150680e-01, -1.82321557e-01, -2.23143551e-01,\n",
       "                     -2.87682072e-01, -3.36472237e-01, -3.56674944e-01, -3.74693449e-01,\n",
       "                     -4.05465108e-01, -4.41832752e-01, -4.51985124e-01, -4.70003629e-01,\n",
       "                     -4.85507816e-01, -5.10825624e-01, -5.59615788e-01, -5.67984038e-01,\n",
       "                     -5.87786665e-01, -6.06135804e-01, -6.19039208e-01, -6.31778234e-01,\n",
       "                     -6.41853886e-01, -6.46627165e-01, -6.50587566e-01, -6.53926467e-01,\n",
       "                     -6.93147181e-01, -7.23918839e-01, -7.33969175e-01, -7.37598943e-01,\n",
       "                     -7.59105148e-01, -7.62140052e-01, -7.73189888e-01, -7.88457360e-01,\n",
       "                     -7.98507696e-01, -8.02346473e-01, -8.10930216e-01, -8.16761137e-01,\n",
       "                     -8.26678573e-01, -8.34225779e-01, -8.47297860e-01, -8.55666110e-01,\n",
       "                     -8.57450232e-01, -8.69037847e-01, -8.75468737e-01, -8.80358723e-01,\n",
       "                     -8.94784527e-01, -8.97941593e-01, -9.16290732e-01, -9.27986772e-01,\n",
       "                     -9.31558204e-01, -9.37904208e-01, -9.42608040e-01, -9.49080555e-01,\n",
       "                     -9.52008814e-01, -9.55511445e-01, -9.56385189e-01, -9.70778917e-01,\n",
       "                     -9.80829253e-01, -9.83949380e-01, -9.94622575e-01, -9.98528830e-01,\n",
       "                     -9.99405639e-01, -1.01160091e+00, -1.01405490e+00, -1.02961942e+00,\n",
       "                     -1.03236290e+00, -1.04982212e+00, -1.05416053e+00, -1.06240924e+00,\n",
       "                     -1.06289421e+00, -1.08824950e+00, -1.09861229e+00, -1.12160181e+00,\n",
       "                     -1.12393010e+00, -1.12492960e+00, -1.12846525e+00, -1.13323625e+00,\n",
       "                     -1.14513230e+00, -1.14809235e+00, -1.16315081e+00, -1.17272026e+00,\n",
       "                     -1.17865500e+00, -1.18958407e+00, -1.19392247e+00, -1.19824213e+00,\n",
       "                     -1.20397280e+00, -1.21639532e+00, -1.22101427e+00, -1.22866542e+00,\n",
       "                     -1.23474446e+00, -1.24171313e+00, -1.24432410e+00, -1.25276297e+00,\n",
       "                     -1.26566637e+00, -1.28093385e+00, -1.29928298e+00, -1.31483540e+00,\n",
       "                     -1.32175584e+00, -1.34992672e+00, -1.35583515e+00, -1.36097655e+00,\n",
       "                     -1.37486567e+00, -1.38629436e+00, -1.39183454e+00, -1.41182766e+00,\n",
       "                     -1.43508453e+00, -1.45225233e+00, -1.46633707e+00, -1.47330574e+00,\n",
       "                     -1.48807706e+00, -1.50407740e+00, -1.50803780e+00, -1.54044504e+00,\n",
       "                     -1.55059741e+00, -1.58045038e+00, -1.59760345e+00, -1.60943791e+00,\n",
       "                     -1.65335715e+00, -1.67397643e+00, -1.69773052e+00, -1.70474809e+00,\n",
       "                     -1.72722095e+00, -1.77070606e+00, -1.79175947e+00, -1.82161243e+00,\n",
       "                     -1.89711998e+00, -1.90954250e+00, -1.94591015e+00, -1.96944065e+00,\n",
       "                     -2.03688193e+00, -2.07944154e+00, -2.14006616e+00, -2.16905370e+00,\n",
       "                     -2.19722458e+00, -2.51230562e+00, -2.53897387e+00, -2.56494936e+00,\n",
       "                     -2.67414865e+00, -2.70805020e+00, -2.83321334e+00, -2.99573227e+00,\n",
       "                     -4.07753744e+00, -3.45387764e+01]), auc_score=0.5679875963962718, privacy_risk=0.5451097990153521, accuracy=0.5449538553140816, tpr_ind=0.5652565256525652, tnr_ind=0.5249630723781389, test_train_ratio=1.0156015601560155, dataset_size=[3333, 3385]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00763583, 0.0082232 , 0.010279  , 0.01174743,\n",
       "                     0.01409692, 0.01409692, 0.0143906 , 0.01615272, 0.01997063,\n",
       "                     0.020558  , 0.02848752, 0.03024963, 0.03935389, 0.04375918,\n",
       "                     0.05198238, 0.05491924, 0.06343612, 0.06578561, 0.06666667,\n",
       "                     0.07048458, 0.07518355, 0.07929515, 0.08223201, 0.0866373 ,\n",
       "                     0.0928047 , 0.10543319, 0.11835536, 0.12834068, 0.1318649 ,\n",
       "                     0.13627019, 0.14214391, 0.16593245, 0.169163  , 0.1732746 ,\n",
       "                     0.17503671, 0.18883994, 0.19030837, 0.19353891, 0.20381791,\n",
       "                     0.21116006, 0.21997063, 0.22114537, 0.24698972, 0.24845815,\n",
       "                     0.25051395, 0.25550661, 0.25697504, 0.25991189, 0.26255507,\n",
       "                     0.27048458, 0.30367107, 0.31571219, 0.31923642, 0.33127753,\n",
       "                     0.33891336, 0.34860499, 0.35535977, 0.36152717, 0.36446402,\n",
       "                     0.36593245, 0.36886931, 0.3712188 , 0.3732746 , 0.37709251,\n",
       "                     0.38707783, 0.39207048, 0.39618209, 0.40381791, 0.41145374,\n",
       "                     0.43201175, 0.43847283, 0.44434655, 0.45256975, 0.45491924,\n",
       "                     0.47723935, 0.48164464, 0.4948605 , 0.50837004, 0.51395007,\n",
       "                     0.51982379, 0.53480176, 0.54948605, 0.55036711, 0.55447871,\n",
       "                     0.55565345, 0.56328928, 0.59941263, 0.63318649, 0.64317181,\n",
       "                     0.65433186, 0.65785609, 0.66461087, 0.67283407, 0.7051395 ,\n",
       "                     0.71013216, 0.71453744, 0.71512482, 0.73274596, 0.73333333,\n",
       "                     0.75095448, 0.76240822, 0.76534508, 0.77268722, 0.77562408,\n",
       "                     0.80440529, 0.80499266, 0.81762115, 0.82320117, 0.82907489,\n",
       "                     0.83436123, 0.84052863, 0.85110132, 0.85491924, 0.85580029,\n",
       "                     0.86284875, 0.87400881, 0.87459618, 0.87665198, 0.8784141 ,\n",
       "                     0.8845815 , 0.8907489 , 0.89544787, 0.89809104, 0.89926579,\n",
       "                     0.9051395 , 0.91629956, 0.91659325, 0.92187959, 0.93773862,\n",
       "                     0.94214391, 0.94361233, 0.94625551, 0.94860499, 0.94860499,\n",
       "                     0.95066079, 0.95066079, 0.95212922, 0.95359765, 0.95418502,\n",
       "                     0.95653451, 0.96475771, 0.96651982, 0.96945668, 0.97063142,\n",
       "                     0.97063142, 0.97151248, 0.97474302, 0.97650514, 1.        ]), tpr=array([0.        , 0.02143073, 0.0241473 , 0.02656203, 0.02807123,\n",
       "                     0.03048596, 0.03259885, 0.0344099 , 0.03682463, 0.04135225,\n",
       "                     0.04346514, 0.05131301, 0.05433142, 0.06248113, 0.06821612,\n",
       "                     0.08028977, 0.0827045 , 0.09960761, 0.10111681, 0.10353154,\n",
       "                     0.10866284, 0.11439783, 0.12103833, 0.12556595, 0.13190462,\n",
       "                     0.1412617 , 0.1530335 , 0.16661636, 0.17386055, 0.18351947,\n",
       "                     0.18985813, 0.19710232, 0.22456988, 0.22909749, 0.23453064,\n",
       "                     0.2393601 , 0.25626321, 0.25747057, 0.26320555, 0.27195895,\n",
       "                     0.27829762, 0.28554181, 0.28795653, 0.31451856, 0.31753698,\n",
       "                     0.32115907, 0.32538485, 0.32810142, 0.33685481, 0.34198612,\n",
       "                     0.34953215, 0.38001811, 0.38665862, 0.39058255, 0.40507093,\n",
       "                     0.41412617, 0.42318141, 0.42710534, 0.43344401, 0.43585874,\n",
       "                     0.43917899, 0.44340477, 0.44793239, 0.4509508 , 0.45668578,\n",
       "                     0.47057048, 0.47479626, 0.47781467, 0.48264413, 0.49079384,\n",
       "                     0.50860248, 0.51765771, 0.52610927, 0.53425898, 0.5387866 ,\n",
       "                     0.55961364, 0.56534863, 0.57923332, 0.5922125 , 0.59674011,\n",
       "                     0.60096589, 0.61515243, 0.63054633, 0.63265922, 0.63779052,\n",
       "                     0.64050709, 0.64503471, 0.68336855, 0.72321159, 0.73166315,\n",
       "                     0.7401147 , 0.74222759, 0.74735889, 0.75701781, 0.78056142,\n",
       "                     0.78357984, 0.79142771, 0.79263507, 0.81044371, 0.81195291,\n",
       "                     0.81980078, 0.83096891, 0.83277996, 0.83881678, 0.84153335,\n",
       "                     0.86869906, 0.86990643, 0.88198008, 0.88922427, 0.8931482 ,\n",
       "                     0.89495925, 0.90129792, 0.91005131, 0.91276788, 0.91488077,\n",
       "                     0.92001207, 0.92695442, 0.92785995, 0.92906731, 0.93208572,\n",
       "                     0.94234832, 0.94627226, 0.94838515, 0.95110172, 0.9517054 ,\n",
       "                     0.95321461, 0.96347721, 0.96377905, 0.96619378, 0.9758527 ,\n",
       "                     0.97826743, 0.97977664, 0.98038032, 0.98188953, 0.98219137,\n",
       "                     0.98400241, 0.98430426, 0.98520978, 0.98641714, 0.98732267,\n",
       "                     0.98943556, 0.99335949, 0.99396318, 0.99607606, 0.99637791,\n",
       "                     0.99667975, 0.99818895, 0.99969816, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.05360516e-01, -1.17783036e-01,\n",
       "                     -1.82321557e-01, -2.23143551e-01, -2.51314428e-01, -2.87682072e-01,\n",
       "                     -3.18453731e-01, -3.36472237e-01, -3.56674944e-01, -4.05465108e-01,\n",
       "                     -4.70003629e-01, -5.10825624e-01, -5.21296924e-01, -5.30628251e-01,\n",
       "                     -5.59615788e-01, -5.69768159e-01, -5.87786665e-01, -6.28608659e-01,\n",
       "                     -6.32522559e-01, -6.39079959e-01, -6.46627165e-01, -6.59245629e-01,\n",
       "                     -6.69049629e-01, -6.76886660e-01, -6.80243776e-01, -6.93147181e-01,\n",
       "                     -7.13766468e-01, -7.23918839e-01, -7.39667196e-01, -7.53771802e-01,\n",
       "                     -7.56998653e-01, -7.57685702e-01, -7.73189888e-01, -7.82759339e-01,\n",
       "                     -7.86832665e-01, -8.10930216e-01, -8.16761137e-01, -8.22358912e-01,\n",
       "                     -8.26678573e-01, -8.47297860e-01, -8.64997437e-01, -8.69770716e-01,\n",
       "                     -8.75468737e-01, -8.82389180e-01, -8.87303195e-01, -8.93817876e-01,\n",
       "                     -8.95384047e-01, -9.04456274e-01, -9.08258560e-01, -9.10332422e-01,\n",
       "                     -9.16290732e-01, -9.31558204e-01, -9.32820034e-01, -9.42608040e-01,\n",
       "                     -9.55511445e-01, -9.61411167e-01, -9.62810748e-01, -9.65080896e-01,\n",
       "                     -9.69400557e-01, -9.71860583e-01, -9.80829253e-01, -9.93251773e-01,\n",
       "                     -1.00680474e+00, -1.00764051e+00, -1.02450432e+00, -1.02961942e+00,\n",
       "                     -1.03407377e+00, -1.03489647e+00, -1.04045637e+00, -1.04145387e+00,\n",
       "                     -1.04982212e+00, -1.06087196e+00, -1.07613943e+00, -1.07909947e+00,\n",
       "                     -1.08091271e+00, -1.09133953e+00, -1.09861229e+00, -1.12059120e+00,\n",
       "                     -1.12214279e+00, -1.12658614e+00, -1.13076940e+00, -1.14513230e+00,\n",
       "                     -1.15577070e+00, -1.17007125e+00, -1.20397280e+00, -1.20554637e+00,\n",
       "                     -1.22199131e+00, -1.25276297e+00, -1.26291534e+00, -1.27296568e+00,\n",
       "                     -1.27766052e+00, -1.27919623e+00, -1.28519824e+00, -1.30833282e+00,\n",
       "                     -1.31661444e+00, -1.32175584e+00, -1.32963433e+00, -1.33500107e+00,\n",
       "                     -1.36687628e+00, -1.37951467e+00, -1.38629436e+00, -1.41098697e+00,\n",
       "                     -1.41369334e+00, -1.43508453e+00, -1.44691898e+00, -1.47017585e+00,\n",
       "                     -1.47590652e+00, -1.47810191e+00, -1.50407740e+00, -1.50935445e+00,\n",
       "                     -1.51550609e+00, -1.51634749e+00, -1.51982575e+00, -1.52349548e+00,\n",
       "                     -1.53733462e+00, -1.54044504e+00, -1.55814462e+00, -1.58923521e+00,\n",
       "                     -1.59760345e+00, -1.60943791e+00, -1.63760879e+00, -1.65292302e+00,\n",
       "                     -1.70474809e+00, -1.75785792e+00, -1.76190651e+00, -1.79175947e+00,\n",
       "                     -1.87180218e+00, -1.92333583e+00, -1.94591015e+00, -2.00148000e+00,\n",
       "                     -2.01490302e+00, -2.05412373e+00, -2.07944154e+00, -2.10006083e+00,\n",
       "                     -2.19722458e+00, -2.23359222e+00, -2.25129180e+00, -2.33537492e+00,\n",
       "                     -2.38482319e+00, -2.39789527e+00, -2.44234704e+00, -2.48490665e+00,\n",
       "                     -2.56494936e+00, -2.77258872e+00, -2.78501124e+00, -3.49042852e+00,\n",
       "                     -4.23410650e+00, -3.45387764e+01]), auc_score=0.5644728438186595, privacy_risk=0.5450125501240386, accuracy=0.5425721941053885, tpr_ind=0.7232115907032901, tnr_ind=0.3668135095447871, test_train_ratio=1.0277693932991248, dataset_size=[3313, 3405]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.01195815, 0.01255605, 0.01375187, 0.01524664,\n",
       "                     0.01943199, 0.02780269, 0.03258595, 0.0328849 , 0.03497758,\n",
       "                     0.03527653, 0.04304933, 0.04484305, 0.05500747, 0.05949178,\n",
       "                     0.0612855 , 0.06995516, 0.07713004, 0.07922272, 0.08340807,\n",
       "                     0.09387145, 0.11599402, 0.14050822, 0.1509716 , 0.15575486,\n",
       "                     0.15844544, 0.16203288, 0.18086697, 0.18744395, 0.19013453,\n",
       "                     0.22242152, 0.22690583, 0.22929746, 0.23348281, 0.23976084,\n",
       "                     0.24783259, 0.26248132, 0.26547085, 0.26995516, 0.27533632,\n",
       "                     0.27862481, 0.27952167, 0.28998505, 0.29955157, 0.31210762,\n",
       "                     0.31659193, 0.33273543, 0.34618834, 0.36263079, 0.36651719,\n",
       "                     0.37458894, 0.38176383, 0.38594918, 0.39372197, 0.39940209,\n",
       "                     0.42660688, 0.51240658, 0.5309417 , 0.54110613, 0.55366218,\n",
       "                     0.5554559 , 0.56173393, 0.56831091, 0.57189836, 0.57698057,\n",
       "                     0.58684604, 0.59372197, 0.5961136 , 0.59730942, 0.59970105,\n",
       "                     0.60239163, 0.60747384, 0.61345291, 0.61763827, 0.65799701,\n",
       "                     0.66576981, 0.67144993, 0.67533632, 0.67982063, 0.69327354,\n",
       "                     0.6935725 , 0.71449925, 0.72077728, 0.72705531, 0.73452915,\n",
       "                     0.7387145 , 0.73991031, 0.74349776, 0.74349776, 0.75306428,\n",
       "                     0.76472347, 0.76890882, 0.77727952, 0.77907324, 0.78236173,\n",
       "                     0.78475336, 0.79073244, 0.79431988, 0.79940209, 0.80059791,\n",
       "                     0.81434978, 0.81733931, 0.82600897, 0.82690583, 0.82869955,\n",
       "                     0.83348281, 0.85381166, 0.8573991 , 0.85979073, 0.86307922,\n",
       "                     0.86487294, 0.86935725, 0.87832586, 0.88281016, 0.88281016,\n",
       "                     0.9019432 , 0.90523169, 0.92017937, 0.92107623, 0.92286996,\n",
       "                     0.93183857, 0.93213752, 0.93423019, 0.93901345, 0.94439462,\n",
       "                     0.94499253, 0.95007474, 0.95156951, 0.95336323, 0.95605381,\n",
       "                     0.95695067, 0.95814649, 0.96023916, 0.96143498, 0.96352765,\n",
       "                     0.96591928, 0.96831091, 0.97010463, 1.        ]), tpr=array([0.        , 0.02816484, 0.03083309, 0.03261192, 0.03528017,\n",
       "                     0.03883783, 0.05306849, 0.05632968, 0.05781204, 0.06018381,\n",
       "                     0.06285206, 0.06996739, 0.074118  , 0.0836051 , 0.09072043,\n",
       "                     0.09398162, 0.10435814, 0.11651349, 0.11947821, 0.12422176,\n",
       "                     0.13430181, 0.15950193, 0.18559146, 0.19656092, 0.20189742,\n",
       "                     0.2042692 , 0.20871628, 0.22146457, 0.2265046 , 0.22976579,\n",
       "                     0.2603024 , 0.26919656, 0.27394011, 0.2772013 , 0.28313074,\n",
       "                     0.29172843, 0.30862733, 0.31099911, 0.31603913, 0.32226505,\n",
       "                     0.32493329, 0.32671213, 0.33916395, 0.34627928, 0.35962052,\n",
       "                     0.36851468, 0.38155944, 0.39638304, 0.40883487, 0.41150311,\n",
       "                     0.4201008 , 0.43255262, 0.43640676, 0.44352209, 0.45123036,\n",
       "                     0.47643048, 0.56626149, 0.58108509, 0.5967981 , 0.60924993,\n",
       "                     0.61340053, 0.62051586, 0.62585236, 0.63029944, 0.63771124,\n",
       "                     0.6486807 , 0.65223836, 0.65549956, 0.65846428, 0.66083605,\n",
       "                     0.66380077, 0.66943374, 0.67654907, 0.67951379, 0.72013045,\n",
       "                     0.72605989, 0.73258227, 0.73406463, 0.73762229, 0.74977765,\n",
       "                     0.75096353, 0.76845538, 0.77646012, 0.78535428, 0.79246961,\n",
       "                     0.79750964, 0.80047436, 0.80581085, 0.80670027, 0.8158909 ,\n",
       "                     0.82211681, 0.82448859, 0.82982508, 0.83130744, 0.83456863,\n",
       "                     0.83723688, 0.84316632, 0.84702046, 0.85235695, 0.85413578,\n",
       "                     0.86599466, 0.86866291, 0.87815001, 0.88319004, 0.8846724 ,\n",
       "                     0.89119478, 0.91343018, 0.9163949 , 0.91817373, 0.92024904,\n",
       "                     0.9217314 , 0.92706789, 0.93092203, 0.93359028, 0.93477616,\n",
       "                     0.95286095, 0.9555292 , 0.96560925, 0.96649867, 0.96768455,\n",
       "                     0.97479988, 0.97509635, 0.9777646 , 0.98043285, 0.98636229,\n",
       "                     0.98695523, 0.98873406, 0.98991995, 0.99110584, 0.9925882 ,\n",
       "                     0.99288467, 0.99318114, 0.99703528, 0.99733175, 0.99762822,\n",
       "                     0.99940706, 0.99970353, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.05360516e-01, -1.54150680e-01,\n",
       "                     -2.87682072e-01, -3.48306694e-01, -4.05465108e-01, -4.35318071e-01,\n",
       "                     -4.70003629e-01, -4.85507816e-01, -5.10825624e-01, -5.35518236e-01,\n",
       "                     -5.38996501e-01, -5.41597282e-01, -5.59615788e-01, -5.97837001e-01,\n",
       "                     -6.19039208e-01, -6.30233355e-01, -6.41853886e-01, -6.61398482e-01,\n",
       "                     -6.78332095e-01, -6.93147181e-01, -7.15620036e-01, -7.19815428e-01,\n",
       "                     -7.20546155e-01, -7.53771802e-01, -7.57685702e-01, -7.60588461e-01,\n",
       "                     -7.77704569e-01, -7.80158558e-01, -7.85806011e-01, -7.88457360e-01,\n",
       "                     -8.10930216e-01, -8.20980552e-01, -8.32909123e-01, -8.37396789e-01,\n",
       "                     -8.39750655e-01, -8.64997437e-01, -8.80358723e-01, -8.87303195e-01,\n",
       "                     -8.93817876e-01, -9.16290732e-01, -9.44461609e-01, -9.49080555e-01,\n",
       "                     -9.55511445e-01, -9.68250471e-01, -9.69400557e-01, -9.70778917e-01,\n",
       "                     -9.71860583e-01, -9.80829253e-01, -9.89412997e-01, -9.89718200e-01,\n",
       "                     -9.90398704e-01, -9.96333440e-01, -1.00458334e+00, -1.02118055e+00,\n",
       "                     -1.02796789e+00, -1.02961942e+00, -1.03365439e+00, -1.04145387e+00,\n",
       "                     -1.04982212e+00, -1.05605267e+00, -1.06087196e+00, -1.07613943e+00,\n",
       "                     -1.08518927e+00, -1.09861229e+00, -1.12601126e+00, -1.12846525e+00,\n",
       "                     -1.13140211e+00, -1.13943428e+00, -1.16315081e+00, -1.18269541e+00,\n",
       "                     -1.19139402e+00, -1.19392247e+00, -1.20251188e+00, -1.20896035e+00,\n",
       "                     -1.21302264e+00, -1.22377543e+00, -1.22866542e+00, -1.24225499e+00,\n",
       "                     -1.25276297e+00, -1.25518135e+00, -1.25804003e+00, -1.26224171e+00,\n",
       "                     -1.27629347e+00, -1.27766052e+00, -1.28093385e+00, -1.28401551e+00,\n",
       "                     -1.29928298e+00, -1.31094492e+00, -1.31218639e+00, -1.32175584e+00,\n",
       "                     -1.32913595e+00, -1.33500107e+00, -1.33977435e+00, -1.35812348e+00,\n",
       "                     -1.36097655e+00, -1.36687628e+00, -1.37230812e+00, -1.38629436e+00,\n",
       "                     -1.39871688e+00, -1.41369334e+00, -1.41706602e+00, -1.42946653e+00,\n",
       "                     -1.43508453e+00, -1.46283444e+00, -1.49065438e+00, -1.50407740e+00,\n",
       "                     -1.54044504e+00, -1.55059741e+00, -1.56861592e+00, -1.58696506e+00,\n",
       "                     -1.60943791e+00, -1.65292302e+00, -1.65822808e+00, -1.68213974e+00,\n",
       "                     -1.69459572e+00, -1.73113485e+00, -1.73460106e+00, -1.74919985e+00,\n",
       "                     -1.75642010e+00, -1.79175947e+00, -1.86321843e+00, -1.92990981e+00,\n",
       "                     -2.10413415e+00, -2.14006616e+00, -2.19722458e+00, -2.27726729e+00,\n",
       "                     -2.30258509e+00, -2.34180581e+00, -2.39789527e+00, -2.48490665e+00,\n",
       "                     -2.62243645e+00, -2.94443898e+00, -3.04452244e+00, -3.37872453e+00,\n",
       "                     -3.46573590e+00, -3.68887945e+00, -3.45387764e+01]), auc_score=0.547807237373019, privacy_risk=0.5316012544886257, accuracy=0.5327478416195296, tpr_ind=0.806700266824785, tnr_ind=0.25650224215246636, test_train_ratio=0.991698784464868, dataset_size=[3373, 3345]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00511586, 0.00752332, 0.00842612, 0.01324105,\n",
       "                     0.01504664, 0.01564851, 0.01865784, 0.0228709 , 0.02527836,\n",
       "                     0.03039422, 0.03129702, 0.03310262, 0.03551008, 0.04002407,\n",
       "                     0.04724646, 0.04814926, 0.04814926, 0.06108938, 0.0686127 ,\n",
       "                     0.07794162, 0.08004815, 0.08185375, 0.0923864 , 0.09599759,\n",
       "                     0.10442371, 0.10622931, 0.1107433 , 0.15467951, 0.1591935 ,\n",
       "                     0.16250376, 0.16581402, 0.16792055, 0.17333735, 0.1829672 ,\n",
       "                     0.18868492, 0.19289798, 0.19741198, 0.20192597, 0.20884743,\n",
       "                     0.21185676, 0.21516702, 0.2305146 , 0.25820042, 0.26662654,\n",
       "                     0.27565453, 0.28046946, 0.29581703, 0.30243756, 0.30544689,\n",
       "                     0.30905808, 0.31868793, 0.32861872, 0.33463738, 0.3421607 ,\n",
       "                     0.34757749, 0.34998495, 0.35329522, 0.35811014, 0.36473067,\n",
       "                     0.36713813, 0.38549503, 0.38730063, 0.39271742, 0.40866687,\n",
       "                     0.41408366, 0.42100512, 0.42371351, 0.43033404, 0.44598255,\n",
       "                     0.44989467, 0.48058983, 0.48540475, 0.51098405, 0.52121577,\n",
       "                     0.52452603, 0.54198014, 0.56154078, 0.56605477, 0.57357809,\n",
       "                     0.57658742, 0.59223593, 0.59855552, 0.60547698, 0.61239844,\n",
       "                     0.61962082, 0.62533855, 0.63226001, 0.63888053, 0.6789046 ,\n",
       "                     0.67920554, 0.68612699, 0.71260909, 0.71712308, 0.72314174,\n",
       "                     0.72494734, 0.726452  , 0.73066506, 0.75774902, 0.76226302,\n",
       "                     0.76858261, 0.77821246, 0.78332832, 0.79837496, 0.80619922,\n",
       "                     0.81251881, 0.81492627, 0.82967198, 0.83177851, 0.83328318,\n",
       "                     0.84020463, 0.85254288, 0.85495035, 0.85795967, 0.85976527,\n",
       "                     0.86307553, 0.86728859, 0.87842311, 0.87842311, 0.88444177,\n",
       "                     0.90460427, 0.91603972, 0.91844719, 0.91934998, 0.92536864,\n",
       "                     0.93560036, 0.93800782, 0.93891062, 0.94131809, 0.94222088,\n",
       "                     0.94252182, 0.94492928, 0.94703581, 0.94733674, 0.95275354,\n",
       "                     0.95486007, 0.95576286, 0.95937406, 0.96027686, 0.96208246,\n",
       "                     0.96268432, 0.96418899, 0.96479085, 0.96599458, 0.96719831,\n",
       "                     1.        ]), tpr=array([0.        , 0.01767305, 0.02120766, 0.02415317, 0.03122239,\n",
       "                     0.03446244, 0.0365243 , 0.04005891, 0.04300442, 0.04506627,\n",
       "                     0.05007364, 0.05301915, 0.0544919 , 0.05832106, 0.06539028,\n",
       "                     0.07334315, 0.07540501, 0.07658321, 0.09425626, 0.10486009,\n",
       "                     0.11369661, 0.11693667, 0.12047128, 0.13166421, 0.13431517,\n",
       "                     0.14403535, 0.14874816, 0.15493373, 0.20795287, 0.21148748,\n",
       "                     0.21443299, 0.22002946, 0.22268041, 0.22916053, 0.23976436,\n",
       "                     0.24506627, 0.25154639, 0.2544919 , 0.25802651, 0.26421208,\n",
       "                     0.26921944, 0.27216495, 0.28954345, 0.33107511, 0.34050074,\n",
       "                     0.34698085, 0.35316642, 0.36612666, 0.37466863, 0.37879234,\n",
       "                     0.38114875, 0.38998527, 0.40147275, 0.40736377, 0.41620029,\n",
       "                     0.42444772, 0.43092784, 0.43446244, 0.43888071, 0.44801178,\n",
       "                     0.45213549, 0.46804124, 0.4718704 , 0.47982327, 0.49543446,\n",
       "                     0.50073638, 0.50603829, 0.51163476, 0.51605302, 0.52901325,\n",
       "                     0.53195876, 0.55846834, 0.56583211, 0.59116348, 0.60618557,\n",
       "                     0.61060383, 0.62945508, 0.64712813, 0.65243004, 0.66303387,\n",
       "                     0.66568483, 0.67864507, 0.68306333, 0.69278351, 0.69837997,\n",
       "                     0.70721649, 0.71281296, 0.71811487, 0.72459499, 0.76023564,\n",
       "                     0.76082474, 0.76730486, 0.79204713, 0.79558174, 0.8005891 ,\n",
       "                     0.80235641, 0.80441826, 0.80677467, 0.83829161, 0.84094256,\n",
       "                     0.84447717, 0.8533137 , 0.85655376, 0.86686303, 0.87511046,\n",
       "                     0.88100147, 0.88365243, 0.89837997, 0.90044183, 0.90279823,\n",
       "                     0.90721649, 0.91369661, 0.91634757, 0.91899853, 0.92106038,\n",
       "                     0.92371134, 0.92665685, 0.93254786, 0.93343152, 0.93578792,\n",
       "                     0.95287187, 0.96377025, 0.96642121, 0.96759941, 0.97113402,\n",
       "                     0.97614138, 0.97702504, 0.97761414, 0.97849779, 0.98114875,\n",
       "                     0.98173785, 0.98468336, 0.98586156, 0.98674521, 0.99234168,\n",
       "                     0.99322533, 0.99381443, 0.99469809, 0.99499264, 0.99587629,\n",
       "                     0.99646539, 0.99734904, 0.9982327 , 0.9994109 , 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.54150680e-01, -1.82321557e-01,\n",
       "                     -2.23143551e-01, -2.41162057e-01, -2.51314428e-01, -2.87682072e-01,\n",
       "                     -3.36472237e-01, -3.56674944e-01, -3.85662481e-01, -4.05465108e-01,\n",
       "                     -4.70003629e-01, -4.79573080e-01, -4.85507816e-01, -5.10825624e-01,\n",
       "                     -5.38996501e-01, -5.59615788e-01, -5.69094532e-01, -5.75364145e-01,\n",
       "                     -5.87786665e-01, -5.97837001e-01, -6.06135804e-01, -6.10909082e-01,\n",
       "                     -6.35988767e-01, -6.46627165e-01, -6.61398482e-01, -6.69049629e-01,\n",
       "                     -6.93147181e-01, -7.33969175e-01, -7.41937345e-01, -7.44440475e-01,\n",
       "                     -7.47214402e-01, -7.59105148e-01, -7.60286483e-01, -7.73189888e-01,\n",
       "                     -7.80158558e-01, -7.88457360e-01, -8.10930216e-01, -8.26678573e-01,\n",
       "                     -8.30348302e-01, -8.32909123e-01, -8.35117442e-01, -8.38137491e-01,\n",
       "                     -8.38329190e-01, -8.40783179e-01, -8.47297860e-01, -8.50539354e-01,\n",
       "                     -8.52211875e-01, -8.57450232e-01, -8.64997437e-01, -8.75468737e-01,\n",
       "                     -8.79733136e-01, -8.96088025e-01, -9.02867712e-01, -9.16290732e-01,\n",
       "                     -9.34309237e-01, -9.49080555e-01, -9.55511445e-01, -9.60461950e-01,\n",
       "                     -9.71860583e-01, -9.80829253e-01, -9.90398704e-01, -9.94622575e-01,\n",
       "                     -9.99521386e-01, -1.00144854e+00, -1.02165125e+00, -1.02585293e+00,\n",
       "                     -1.02961942e+00, -1.03609193e+00, -1.06471074e+00, -1.07992016e+00,\n",
       "                     -1.08518927e+00, -1.09861229e+00, -1.10512697e+00, -1.12059120e+00,\n",
       "                     -1.12938395e+00, -1.13140211e+00, -1.13497993e+00, -1.15267951e+00,\n",
       "                     -1.17007125e+00, -1.17865500e+00, -1.20397280e+00, -1.21302264e+00,\n",
       "                     -1.21444410e+00, -1.22377543e+00, -1.22994829e+00, -1.23676263e+00,\n",
       "                     -1.23969089e+00, -1.25158163e+00, -1.25276297e+00, -1.26566637e+00,\n",
       "                     -1.27296568e+00, -1.27629347e+00, -1.27766052e+00, -1.29928298e+00,\n",
       "                     -1.31218639e+00, -1.32175584e+00, -1.32610773e+00, -1.32913595e+00,\n",
       "                     -1.34373475e+00, -1.35239281e+00, -1.38629436e+00, -1.40047900e+00,\n",
       "                     -1.41272762e+00, -1.42310833e+00, -1.44036158e+00, -1.44926916e+00,\n",
       "                     -1.45528723e+00, -1.47590652e+00, -1.49664242e+00, -1.50407740e+00,\n",
       "                     -1.51634749e+00, -1.54044504e+00, -1.55059741e+00, -1.58696506e+00,\n",
       "                     -1.60943791e+00, -1.64865863e+00, -1.67397643e+00, -1.68175857e+00,\n",
       "                     -1.68576018e+00, -1.68739945e+00, -1.71479843e+00, -1.74919985e+00,\n",
       "                     -1.79175947e+00, -1.81117756e+00, -1.84582669e+00, -1.87180218e+00,\n",
       "                     -1.89711998e+00, -1.91364929e+00, -1.94591015e+00, -2.01490302e+00,\n",
       "                     -2.04769284e+00, -2.07944154e+00, -2.13696539e+00, -2.15948425e+00,\n",
       "                     -2.19722458e+00, -2.39789527e+00, -2.48490665e+00, -2.53897387e+00,\n",
       "                     -2.60268969e+00, -2.68557735e+00, -2.79320801e+00, -2.97041447e+00,\n",
       "                     -3.27714473e+00, -3.45387764e+01]), auc_score=0.564798563322441, privacy_risk=0.5447278906288433, accuracy=0.5459958320928848, tpr_ind=0.6630338733431517, tnr_ind=0.42642190791453505, test_train_ratio=0.9787923416789396, dataset_size=[3395, 3323]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.00684728, 0.00952664, 0.01041977, 0.0116106 ,\n",
       "                     0.01428997, 0.01637392, 0.02441203, 0.02619827, 0.0348318 ,\n",
       "                     0.03780887, 0.04138136, 0.04763322, 0.05239655, 0.05358738,\n",
       "                     0.05805299, 0.06251861, 0.06579339, 0.06936588, 0.07144984,\n",
       "                     0.08335814, 0.09228937, 0.10598392, 0.11551057, 0.12325097,\n",
       "                     0.13515927, 0.13724323, 0.14170884, 0.14230426, 0.15004466,\n",
       "                     0.15212861, 0.1557011 , 0.15838047, 0.16046442, 0.16671628,\n",
       "                     0.17028878, 0.24620423, 0.25513546, 0.25841024, 0.31854719,\n",
       "                     0.32122656, 0.32479905, 0.3581423 , 0.36022626, 0.36796666,\n",
       "                     0.37868413, 0.38285204, 0.39178327, 0.39922596, 0.40190533,\n",
       "                     0.40369157, 0.40994344, 0.41381364, 0.42185174, 0.4242334 ,\n",
       "                     0.4513248 , 0.45876749, 0.48407264, 0.48615659, 0.49091992,\n",
       "                     0.49895802, 0.50372135, 0.51443882, 0.54123251, 0.55135457,\n",
       "                     0.56921703, 0.57249181, 0.57755284, 0.58023221, 0.59273593,\n",
       "                     0.59988092, 0.60910985, 0.61387318, 0.62488836, 0.6263769 ,\n",
       "                     0.63709437, 0.6457279 , 0.64632331, 0.67103305, 0.67639178,\n",
       "                     0.68026198, 0.68591843, 0.69306341, 0.69693361, 0.69752903,\n",
       "                     0.72968145, 0.73325394, 0.73474248, 0.74010122, 0.75290265,\n",
       "                     0.76749032, 0.78356654, 0.79666567, 0.80678773, 0.83119976,\n",
       "                     0.8365585 , 0.84310807, 0.84638285, 0.8481691 , 0.86156594,\n",
       "                     0.86305448, 0.86543614, 0.88865734, 0.89788628, 0.89937481,\n",
       "                     0.90056564, 0.90175648, 0.90771063, 0.90890146, 0.91187854,\n",
       "                     0.91485561, 0.91693957, 0.91961893, 0.9220006 , 0.92378684,\n",
       "                     0.92527538, 0.93361119, 0.93867222, 0.93926764, 0.94135159,\n",
       "                     0.94343555, 0.94671033, 0.94760345, 0.95087824, 0.95147365,\n",
       "                     0.95296219, 0.9532599 , 0.9532599 , 0.95683239, 0.95683239,\n",
       "                     0.95742781, 0.95832093, 0.96040488, 0.96457279, 0.96665674,\n",
       "                     1.        ]), tpr=array([0.        , 0.02232807, 0.02679369, 0.03036618, 0.03245013,\n",
       "                     0.03691575, 0.0389997 , 0.05269425, 0.05864841, 0.06906818,\n",
       "                     0.0738315 , 0.07740399, 0.08514439, 0.09407562, 0.09615957,\n",
       "                     0.10151831, 0.10628163, 0.11074725, 0.11431974, 0.11818994,\n",
       "                     0.13426615, 0.14170884, 0.15748735, 0.16582316, 0.17237273,\n",
       "                     0.18636499, 0.18904436, 0.19291456, 0.1947008 , 0.20333433,\n",
       "                     0.20601369, 0.21256326, 0.21732659, 0.22030366, 0.22476928,\n",
       "                     0.22804406, 0.30544805, 0.31289074, 0.31824948, 0.38195892,\n",
       "                     0.38582912, 0.39356951, 0.42542423, 0.42750819, 0.43822566,\n",
       "                     0.45370646, 0.45668354, 0.46829414, 0.47543912, 0.48109556,\n",
       "                     0.48437035, 0.49270616, 0.49538553, 0.49955344, 0.50401905,\n",
       "                     0.53438523, 0.54629354, 0.56534683, 0.56713308, 0.57398035,\n",
       "                     0.58291158, 0.58827032, 0.60434653, 0.62578148, 0.63649896,\n",
       "                     0.65138434, 0.65525454, 0.66091099, 0.66388806, 0.67788032,\n",
       "                     0.68264364, 0.69038404, 0.69514737, 0.70646026, 0.70735338,\n",
       "                     0.71449836, 0.72878833, 0.72938375, 0.75320036, 0.75915451,\n",
       "                     0.76391783, 0.76838345, 0.77344448, 0.77880322, 0.78118488,\n",
       "                     0.80321524, 0.80470378, 0.80797857, 0.8133373 , 0.82286395,\n",
       "                     0.83685621, 0.85055076, 0.85739804, 0.86454302, 0.89014588,\n",
       "                     0.89461149, 0.8987794 , 0.90026794, 0.90294731, 0.91574873,\n",
       "                     0.9181304 , 0.92051206, 0.94284013, 0.95028282, 0.95206907,\n",
       "                     0.95355761, 0.95474844, 0.95951176, 0.96219113, 0.96397737,\n",
       "                     0.96725216, 0.96933611, 0.97112236, 0.97231319, 0.97409943,\n",
       "                     0.97529026, 0.98243525, 0.98600774, 0.98630545, 0.98809169,\n",
       "                     0.98898482, 0.98958023, 0.99017565, 0.99255731, 0.99315272,\n",
       "                     0.99345043, 0.99374814, 0.99404585, 0.99523668, 0.99553439,\n",
       "                     0.9961298 , 0.99642751, 0.99791605, 0.99970229, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.82321557e-01, -2.23143551e-01,\n",
       "                     -2.51314428e-01, -2.87682072e-01, -3.56674944e-01, -4.05465108e-01,\n",
       "                     -4.38254931e-01, -4.70003629e-01, -4.85507816e-01, -5.10825624e-01,\n",
       "                     -5.26093096e-01, -5.30628251e-01, -5.38996501e-01, -5.43615447e-01,\n",
       "                     -5.59615788e-01, -5.87786665e-01, -6.06135804e-01, -6.13104473e-01,\n",
       "                     -6.26136470e-01, -6.31271777e-01, -6.93147181e-01, -7.10846758e-01,\n",
       "                     -7.15620036e-01, -7.44972248e-01, -7.47214402e-01, -7.67255153e-01,\n",
       "                     -7.73189888e-01, -7.75838896e-01, -7.98507696e-01, -8.00777845e-01,\n",
       "                     -8.10930216e-01, -8.32909123e-01, -8.47297860e-01, -8.60201265e-01,\n",
       "                     -8.73864888e-01, -8.75468737e-01, -8.93817876e-01, -8.95515669e-01,\n",
       "                     -9.00786545e-01, -9.16290732e-01, -9.40299272e-01, -9.44461609e-01,\n",
       "                     -9.49080555e-01, -9.54031060e-01, -9.55511445e-01, -9.61411167e-01,\n",
       "                     -9.80829253e-01, -9.87386654e-01, -1.00330211e+00, -1.01160091e+00,\n",
       "                     -1.02165125e+00, -1.02450432e+00, -1.02961942e+00, -1.03101900e+00,\n",
       "                     -1.03850836e+00, -1.03961395e+00, -1.04145387e+00, -1.06919840e+00,\n",
       "                     -1.07613943e+00, -1.07992016e+00, -1.08618977e+00, -1.09861229e+00,\n",
       "                     -1.10782894e+00, -1.11841492e+00, -1.12393010e+00, -1.14990558e+00,\n",
       "                     -1.16315081e+00, -1.16713224e+00, -1.17865500e+00, -1.18455472e+00,\n",
       "                     -1.19770319e+00, -1.19869575e+00, -1.20397280e+00, -1.21639532e+00,\n",
       "                     -1.23474446e+00, -1.25276297e+00, -1.26694760e+00, -1.28093385e+00,\n",
       "                     -1.28785429e+00, -1.29928298e+00, -1.30992138e+00, -1.31432086e+00,\n",
       "                     -1.32175584e+00, -1.32714669e+00, -1.33500107e+00, -1.33977435e+00,\n",
       "                     -1.34373475e+00, -1.35454566e+00, -1.36478816e+00, -1.36985563e+00,\n",
       "                     -1.38629436e+00, -1.42711636e+00, -1.45644935e+00, -1.46633707e+00,\n",
       "                     -1.50407740e+00, -1.52605630e+00, -1.54044504e+00, -1.57633796e+00,\n",
       "                     -1.58412010e+00, -1.60943791e+00, -1.62004809e+00, -1.63315444e+00,\n",
       "                     -1.64222774e+00, -1.64865863e+00, -1.65822808e+00, -1.70474809e+00,\n",
       "                     -1.71479843e+00, -1.73460106e+00, -1.76098781e+00, -1.76766192e+00,\n",
       "                     -1.79175947e+00, -1.83258146e+00, -1.84582669e+00, -1.87180218e+00,\n",
       "                     -1.87819198e+00, -1.92181260e+00, -1.94591015e+00, -2.01490302e+00,\n",
       "                     -2.03688193e+00, -2.07944154e+00, -2.19722458e+00, -2.29000631e+00,\n",
       "                     -2.35137526e+00, -2.39789527e+00, -2.48490665e+00, -2.56494936e+00,\n",
       "                     -2.60268969e+00, -2.63905733e+00, -2.67414865e+00, -2.77258872e+00,\n",
       "                     -2.82137889e+00, -2.87167962e+00, -2.99573227e+00, -3.45387764e+01]), auc_score=0.5633517272760388, privacy_risk=0.5449538553140816, accuracy=0.5449538553140816, tpr_ind=0.6043465317058648, tnr_ind=0.4855611789222983, test_train_ratio=1.0, dataset_size=[3359, 3359]),\n",
       "              MIA_Attack_Result(name='entire_dataset_label_1.0', fpr=array([0.        , 0.01170468, 0.015006  , 0.015006  , 0.01710684,\n",
       "                     0.01920768, 0.02070828, 0.02430972, 0.02611044, 0.04351741,\n",
       "                     0.04741897, 0.05012005, 0.05342137, 0.05642257, 0.05822329,\n",
       "                     0.06032413, 0.06332533, 0.06602641, 0.06632653, 0.07052821,\n",
       "                     0.07472989, 0.07893157, 0.08313325, 0.08703481, 0.09213685,\n",
       "                     0.09933974, 0.10264106, 0.10504202, 0.1107443 , 0.11794718,\n",
       "                     0.13265306, 0.13385354, 0.14105642, 0.1437575 , 0.14465786,\n",
       "                     0.14915966, 0.1542617 , 0.15666267, 0.15936375, 0.16896759,\n",
       "                     0.17316927, 0.17767107, 0.18067227, 0.18757503, 0.20438175,\n",
       "                     0.21008403, 0.21518607, 0.21878752, 0.2620048 , 0.2635054 ,\n",
       "                     0.2680072 , 0.27280912, 0.29291717, 0.29411765, 0.29771909,\n",
       "                     0.29951981, 0.30132053, 0.32593037, 0.34213685, 0.3517407 ,\n",
       "                     0.35714286, 0.36854742, 0.37845138, 0.39915966, 0.40786315,\n",
       "                     0.40906363, 0.41206483, 0.41476591, 0.43367347, 0.44117647,\n",
       "                     0.47388956, 0.48619448, 0.49369748, 0.49579832, 0.50780312,\n",
       "                     0.51620648, 0.51710684, 0.57382953, 0.58793517, 0.59993998,\n",
       "                     0.60714286, 0.61434574, 0.61944778, 0.63295318, 0.64435774,\n",
       "                     0.64705882, 0.66326531, 0.66926771, 0.67857143, 0.68817527,\n",
       "                     0.69327731, 0.69927971, 0.73979592, 0.74909964, 0.77070828,\n",
       "                     0.77130852, 0.77791116, 0.78151261, 0.80312125, 0.81722689,\n",
       "                     0.82292917, 0.83103241, 0.83643457, 0.83763505, 0.84903962,\n",
       "                     0.85654262, 0.87364946, 0.91806723, 0.92346939, 0.92376951,\n",
       "                     0.92436975, 0.92767107, 0.93667467, 0.94327731, 0.94417767,\n",
       "                     0.94567827, 0.94567827, 0.95108043, 0.95168067, 0.95228091,\n",
       "                     0.95318127, 0.95378151, 0.95438175, 0.95648259, 0.95678271,\n",
       "                     0.95888355, 0.96158463, 0.96218487, 0.96218487, 0.96278511,\n",
       "                     0.96578631, 0.96968788, 0.97088836, 1.        ]), tpr=array([0.        , 0.02215003, 0.02923804, 0.03071471, 0.03662138,\n",
       "                     0.04016539, 0.04252806, 0.04548139, 0.04873006, 0.06408742,\n",
       "                     0.07058476, 0.07590077, 0.08210278, 0.08357944, 0.08594211,\n",
       "                     0.08919079, 0.09362079, 0.09864146, 0.1007088 , 0.10809214,\n",
       "                     0.11399882, 0.11931483, 0.12640284, 0.13230951, 0.13703485,\n",
       "                     0.14737153, 0.15209687, 0.15682221, 0.16272888, 0.17277023,\n",
       "                     0.19078559, 0.19373892, 0.20378027, 0.20850561, 0.21057295,\n",
       "                     0.21411695, 0.21884229, 0.2232723 , 0.22740697, 0.23951565,\n",
       "                     0.24483166, 0.24985233, 0.25339634, 0.25959835, 0.27170703,\n",
       "                     0.27820437, 0.28558771, 0.28913172, 0.33313644, 0.33549911,\n",
       "                     0.33992912, 0.34376846, 0.35853514, 0.36237448, 0.36503249,\n",
       "                     0.36916716, 0.37064383, 0.40076787, 0.42055523, 0.42911991,\n",
       "                     0.43354991, 0.44595393, 0.45865328, 0.47696397, 0.48405198,\n",
       "                     0.48670998, 0.48966332, 0.49291199, 0.51269935, 0.52126403,\n",
       "                     0.56290608, 0.5744241 , 0.58003544, 0.58269344, 0.59273479,\n",
       "                     0.60218547, 0.60425281, 0.64648553, 0.65918488, 0.6742469 ,\n",
       "                     0.67897224, 0.68340224, 0.68871825, 0.69935027, 0.71323095,\n",
       "                     0.71559362, 0.72976964, 0.73419965, 0.74217366, 0.753101  ,\n",
       "                     0.75812168, 0.76343768, 0.80714708, 0.81512109, 0.83047844,\n",
       "                     0.83195511, 0.83756645, 0.84199646, 0.86030715, 0.87152983,\n",
       "                     0.8738925 , 0.88422918, 0.88806852, 0.88924985, 0.89604253,\n",
       "                     0.9028352 , 0.91966923, 0.96101595, 0.96337862, 0.96426462,\n",
       "                     0.96515062, 0.96869462, 0.9746013 , 0.98109864, 0.98287064,\n",
       "                     0.98316598, 0.98375665, 0.98759598, 0.98877732, 0.98907265,\n",
       "                     0.98995865, 0.99025399, 0.99173066, 0.99320732, 0.99468399,\n",
       "                     0.99586533, 0.99675133, 0.997342  , 0.998228  , 0.99852333,\n",
       "                     0.999114  , 0.99970467, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.54150680e-01, -1.82321557e-01,\n",
       "                     -2.23143551e-01, -2.87682072e-01, -3.18453731e-01, -3.36472237e-01,\n",
       "                     -3.74693449e-01, -4.05465108e-01, -4.35318071e-01, -4.41832752e-01,\n",
       "                     -4.51985124e-01, -4.70003629e-01, -4.85507816e-01, -4.92476485e-01,\n",
       "                     -5.10825624e-01, -5.34082486e-01, -5.38996501e-01, -5.42324291e-01,\n",
       "                     -5.59615788e-01, -5.75364145e-01, -5.83146285e-01, -5.87786665e-01,\n",
       "                     -5.94707108e-01, -6.19039208e-01, -6.28608659e-01, -6.61398482e-01,\n",
       "                     -6.67829373e-01, -6.78332095e-01, -6.93147181e-01, -7.41937345e-01,\n",
       "                     -7.50305594e-01, -7.53771802e-01, -7.62140052e-01, -7.73189888e-01,\n",
       "                     -7.82759339e-01, -7.88457360e-01, -7.94929875e-01, -7.97287440e-01,\n",
       "                     -7.98507696e-01, -8.04372816e-01, -8.10930216e-01, -8.26678573e-01,\n",
       "                     -8.29722716e-01, -8.40783179e-01, -8.41567186e-01, -8.47297860e-01,\n",
       "                     -8.53986849e-01, -8.64997437e-01, -8.75468737e-01, -9.00786545e-01,\n",
       "                     -9.16290732e-01, -9.31558204e-01, -9.38269639e-01, -9.44461609e-01,\n",
       "                     -9.55511445e-01, -9.62275845e-01, -9.71457113e-01, -9.76509592e-01,\n",
       "                     -9.80829253e-01, -9.89718200e-01, -9.92390075e-01, -1.00276433e+00,\n",
       "                     -1.01160091e+00, -1.02165125e+00, -1.02961942e+00, -1.03609193e+00,\n",
       "                     -1.03705440e+00, -1.06352097e+00, -1.07226346e+00, -1.09861229e+00,\n",
       "                     -1.11600403e+00, -1.13497993e+00, -1.13707857e+00, -1.13943428e+00,\n",
       "                     -1.14513230e+00, -1.15083755e+00, -1.15145477e+00, -1.16192457e+00,\n",
       "                     -1.17865500e+00, -1.18377010e+00, -1.18716569e+00, -1.20397280e+00,\n",
       "                     -1.20609820e+00, -1.21639532e+00, -1.22866542e+00, -1.24319352e+00,\n",
       "                     -1.27887411e+00, -1.28692189e+00, -1.29392104e+00, -1.29928298e+00,\n",
       "                     -1.30906301e+00, -1.31928365e+00, -1.32687094e+00, -1.33500107e+00,\n",
       "                     -1.35962611e+00, -1.36948724e+00, -1.38629436e+00, -1.39936644e+00,\n",
       "                     -1.41706602e+00, -1.42825856e+00, -1.44238383e+00, -1.50407740e+00,\n",
       "                     -1.51846613e+00, -1.52794488e+00, -1.55537069e+00, -1.59504917e+00,\n",
       "                     -1.60943791e+00, -1.67397643e+00, -1.73460106e+00, -1.79175947e+00,\n",
       "                     -1.80828877e+00, -1.82161243e+00, -1.84582669e+00, -1.94591015e+00,\n",
       "                     -2.01490302e+00, -2.02001812e+00, -2.04769284e+00, -2.07944154e+00,\n",
       "                     -2.19722458e+00, -2.30258509e+00, -2.34180581e+00, -2.39789527e+00,\n",
       "                     -2.54944517e+00, -2.58399755e+00, -2.68557735e+00, -2.89037176e+00,\n",
       "                     -2.92673940e+00, -2.94443898e+00, -2.99573227e+00, -3.09104245e+00,\n",
       "                     -3.66356165e+00, -3.45387764e+01]), auc_score=0.5610551958527061, privacy_risk=0.5445082640262248, accuracy=0.544656147662995, tpr_ind=0.5629060838747785, tnr_ind=0.526110444177671, test_train_ratio=0.9840519787359716, dataset_size=[3386, 3332])],\n",
       "             'subpopulation_0.0_label_0.0_mia_auc': [0.5180941760779475,\n",
       "              0.5140725283758576,\n",
       "              0.5123259196029148,\n",
       "              0.5451478560477945,\n",
       "              0.5537431769119661,\n",
       "              0.5097559741906114,\n",
       "              0.5257279834597353,\n",
       "              0.5293391700837515,\n",
       "              0.5357620542786404,\n",
       "              0.5298729758189218,\n",
       "              0.5203217986846139,\n",
       "              0.5278650492126606,\n",
       "              0.5265257585335019,\n",
       "              0.5418052783322245,\n",
       "              0.5326215801868154,\n",
       "              0.5150002055797507,\n",
       "              0.5363116176317212,\n",
       "              0.5306369992477258,\n",
       "              0.520726351725469,\n",
       "              0.5153097527038137],\n",
       "             'subpopulation_0.0_label_0.0_mia_privacy_risk': [0.5246868178798519,\n",
       "              0.5173812007967372,\n",
       "              0.5217946286021403,\n",
       "              0.5454734396484962,\n",
       "              0.5437965605631043,\n",
       "              0.512880193728483,\n",
       "              0.5232526342078725,\n",
       "              0.5326116555578424,\n",
       "              0.5317415899094724,\n",
       "              0.5272902772902773,\n",
       "              0.517506613275855,\n",
       "              0.5241725192962937,\n",
       "              0.5246483881163084,\n",
       "              0.5356493362481386,\n",
       "              0.526529531696986,\n",
       "              0.5180878552971576,\n",
       "              0.5311394817434507,\n",
       "              0.5349135832906623,\n",
       "              0.523702852948342,\n",
       "              0.5247525456960344],\n",
       "             'subpopulation_0.0_label_0.0_mia_ppv': [0.530596436870643,\n",
       "              0.52,\n",
       "              0.5215827338129496,\n",
       "              0.5408366533864541,\n",
       "              0.5385556915544675,\n",
       "              0.5098389982110912,\n",
       "              0.5248091603053435,\n",
       "              0.5008710801393729,\n",
       "              0.5092073658927141,\n",
       "              0.5119565217391304,\n",
       "              0.5117540687160941,\n",
       "              0.5125881168177241,\n",
       "              0.5234899328859061,\n",
       "              0.5057915057915059,\n",
       "              0.5261194029850746,\n",
       "              0.52375,\n",
       "              0.5332480818414322,\n",
       "              0.5292397660818713,\n",
       "              0.49623545516769335,\n",
       "              0.5009746588693956],\n",
       "             'subpopulation_0.0_label_0.0_mia_attacker_advantage': [0.04937363575970388,\n",
       "              0.034762401593474324,\n",
       "              0.04358925720428064,\n",
       "              0.0909468792969923,\n",
       "              0.08759312112620854,\n",
       "              0.025760387456965905,\n",
       "              0.04650526841574487,\n",
       "              0.0652233111156848,\n",
       "              0.06348317981894469,\n",
       "              0.05458055458055455,\n",
       "              0.03501322655171002,\n",
       "              0.04834503859258743,\n",
       "              0.04929677623261697,\n",
       "              0.0712986724962772,\n",
       "              0.05305906339397193,\n",
       "              0.036175710594315236,\n",
       "              0.06227896348690143,\n",
       "              0.0698271665813246,\n",
       "              0.0474057058966838,\n",
       "              0.04950509139206871],\n",
       "             'subpopulation_0.0_label_0.0_mia_result': [MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.70557717, 0.72373541, 0.78210117, 0.78599222,\n",
       "                     0.81971466, 0.83527886, 0.88845655, 0.89753567, 0.92996109,\n",
       "                     0.93255512, 0.93774319, 0.94682231, 0.94811933, 0.95330739,\n",
       "                     0.95590143, 0.95849546, 0.95849546, 0.96108949, 0.9766537 ,\n",
       "                     0.97795071, 0.98184176, 1.        ]), tpr=array([0.        , 0.73170732, 0.7597561 , 0.82560976, 0.83536585,\n",
       "                     0.85365854, 0.86219512, 0.91341463, 0.92682927, 0.95243902,\n",
       "                     0.95853659, 0.96341463, 0.97439024, 0.97439024, 0.9804878 ,\n",
       "                     0.98536585, 0.98536585, 0.98780488, 0.98780488, 0.99756098,\n",
       "                     0.99756098, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.25596144e-02, -1.05360516e-01,\n",
       "                     -1.17783036e-01, -1.25163143e-01, -1.33531393e-01, -1.54150680e-01,\n",
       "                     -1.67054085e-01, -1.74353387e-01, -1.82321557e-01, -2.23143551e-01,\n",
       "                     -2.87682072e-01, -3.34369186e-01, -3.36472237e-01, -4.05465108e-01,\n",
       "                     -4.90622916e-01, -5.59615788e-01, -6.28608659e-01, -6.93147181e-01,\n",
       "                     -8.10930216e-01, -1.09861229e+00, -3.45387764e+01]), auc_score=0.5180941760779475, privacy_risk=0.5246868178798519, accuracy=0.5246868178798519, tpr_ind=0.8353658536585366, tnr_ind=0.2140077821011673, test_train_ratio=0.9402439024390243, dataset_size=[820, 771]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.48205128, 0.56025641, 0.66153846, 0.69358974,\n",
       "                     0.72948718, 0.73974359, 0.86025641, 0.88076923, 0.88076923,\n",
       "                     0.89230769, 0.9025641 , 0.91025641, 0.91538462, 0.93974359,\n",
       "                     0.94230769, 0.9474359 , 0.95897436, 0.96025641, 0.96153846,\n",
       "                     0.96410256, 0.96666667, 0.96923077, 0.97051282, 0.97179487,\n",
       "                     0.97820513, 0.97948718, 1.        ]), tpr=array([0.        , 0.49321825, 0.58199753, 0.6892725 , 0.7188656 ,\n",
       "                     0.74722565, 0.76202219, 0.87916153, 0.90382244, 0.90505549,\n",
       "                     0.9161529 , 0.92478422, 0.93711467, 0.94204686, 0.96424168,\n",
       "                     0.972873  , 0.98027127, 0.99013564, 0.99136868, 0.99630086,\n",
       "                     0.99630086, 0.99630086, 0.99630086, 0.99876695, 0.99876695,\n",
       "                     1.        , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.37933221e-02, -3.39015517e-02,\n",
       "                     -4.08219945e-02, -4.25596144e-02, -8.00427077e-02, -8.08520966e-02,\n",
       "                     -9.53101798e-02, -1.00083459e-01, -1.05360516e-01, -1.33531393e-01,\n",
       "                     -1.82321557e-01, -2.23143551e-01, -2.45122458e-01, -2.51314428e-01,\n",
       "                     -2.87682072e-01, -3.18453731e-01, -3.72404246e-01, -4.05465108e-01,\n",
       "                     -4.70003629e-01, -4.75423697e-01, -6.24154309e-01, -6.93147181e-01,\n",
       "                     -7.21318058e-01, -1.09861229e+00, -1.38629436e+00, -3.45387764e+01]), auc_score=0.5140725283758576, privacy_risk=0.5173812007967372, accuracy=0.5173812007967372, tpr_ind=0.9963008631319359, tnr_ind=0.038461538461538464, test_train_ratio=0.9617755856966708, dataset_size=[811, 780]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.64276569, 0.68886044, 0.74263764, 0.7759283 ,\n",
       "                     0.8028169 , 0.80921895, 0.82330346, 0.85147247, 0.85403329,\n",
       "                     0.88476312, 0.90012804, 0.90140845, 0.91165173, 0.91421255,\n",
       "                     0.91805378, 0.91933419, 0.92701665, 0.93085787, 0.93341869,\n",
       "                     0.93597951, 0.93725992, 0.9603073 , 0.9603073 , 0.96542894,\n",
       "                     0.96798976, 0.97951344, 0.98079385, 1.        ]), tpr=array([0.        , 0.64814815, 0.71111111, 0.78024691, 0.80864198,\n",
       "                     0.8308642 , 0.84691358, 0.8617284 , 0.89506173, 0.89506173,\n",
       "                     0.91975309, 0.93333333, 0.93333333, 0.94938272, 0.95432099,\n",
       "                     0.95679012, 0.95925926, 0.96296296, 0.96419753, 0.96790123,\n",
       "                     0.96790123, 0.97283951, 0.98518519, 0.98641975, 0.98888889,\n",
       "                     0.98888889, 0.99876543, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.94180859e-02, -3.50913198e-02,\n",
       "                     -4.25596144e-02, -5.40672213e-02, -7.41079722e-02, -8.00427077e-02,\n",
       "                     -1.05360516e-01, -1.17783036e-01, -1.39761942e-01, -1.67054085e-01,\n",
       "                     -1.82321557e-01, -2.07639365e-01, -2.23143551e-01, -2.44453338e-01,\n",
       "                     -2.60726262e-01, -2.87682072e-01, -2.94799540e-01, -3.14493330e-01,\n",
       "                     -3.56674944e-01, -3.67724780e-01, -4.05465108e-01, -5.54310736e-01,\n",
       "                     -5.59615788e-01, -6.50587566e-01, -6.93147181e-01, -1.09861229e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5123259196029148, privacy_risk=0.5217946286021403, accuracy=0.5217946286021403, tpr_ind=0.8950617283950617, tnr_ind=0.14852752880921896, test_train_ratio=0.9641975308641976, dataset_size=[810, 781]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.40127389, 0.58726115, 0.6522293 , 0.71974522,\n",
       "                     0.7566879 , 0.86751592, 0.91210191, 0.91974522, 0.9388535 ,\n",
       "                     0.9566879 , 0.97070064, 1.        ]), tpr=array([0.        , 0.44168734, 0.67369727, 0.74317618, 0.80397022,\n",
       "                     0.82506203, 0.91066998, 0.95657568, 0.96153846, 0.97890819,\n",
       "                     0.98883375, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.06383982e-02, -3.50913198e-02,\n",
       "                     -4.00053346e-02, -5.71584138e-02, -9.66268357e-02, -1.02654154e-01,\n",
       "                     -2.23143551e-01, -2.51314428e-01, -4.05465108e-01, -6.93147181e-01,\n",
       "                     -3.45387764e+01]), auc_score=0.5451478560477945, privacy_risk=0.5454734396484962, accuracy=0.5454734396484962, tpr_ind=0.7431761786600496, tnr_ind=0.34777070063694265, test_train_ratio=0.9739454094292804, dataset_size=[806, 785]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.47007481, 0.51246883, 0.65087282, 0.68329177,\n",
       "                     0.78802993, 0.8117207 , 0.82418953, 0.87780549, 0.88653367,\n",
       "                     0.89276808, 0.90897756, 0.93142145, 0.93640898, 0.94513716,\n",
       "                     0.95012469, 0.98753117, 0.98877805, 1.        ]), tpr=array([0.        , 0.55766793, 0.5982256 , 0.71736375, 0.74524715,\n",
       "                     0.85678074, 0.87198986, 0.88593156, 0.92648923, 0.93536122,\n",
       "                     0.94930292, 0.96831432, 0.97972117, 0.98352345, 0.98859316,\n",
       "                     0.98859316, 1.        , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.07716587e-02, -4.16726964e-02,\n",
       "                     -4.44517626e-02, -5.52626787e-02, -8.00427077e-02, -8.70113770e-02,\n",
       "                     -1.17783036e-01, -1.33531393e-01, -1.67054085e-01, -1.82321557e-01,\n",
       "                     -2.00670695e-01, -2.87682072e-01, -4.05465108e-01, -5.75364145e-01,\n",
       "                     -6.93147181e-01, -7.28238500e-01, -3.45387764e+01]), auc_score=0.5537431769119661, privacy_risk=0.5437965605631043, accuracy=0.5437965605631043, tpr_ind=0.5576679340937896, tnr_ind=0.529925187032419, test_train_ratio=1.0164765525982256, dataset_size=[789, 802]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.33868974, 0.44622991, 0.88257108, 0.90729295,\n",
       "                     0.95302843, 0.96662546, 0.97280593, 0.97527812, 0.98269468,\n",
       "                     0.98393078, 0.98516687, 0.98640297, 0.99258344, 1.        ]), tpr=array([0.        , 0.36445013, 0.44501279, 0.89514066, 0.91943734,\n",
       "                     0.97186701, 0.97826087, 0.98721228, 0.99232737, 0.99744246,\n",
       "                     0.99744246, 0.99872123, 0.99872123, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.65200156e-02, -6.06246218e-02,\n",
       "                     -1.46603474e-01, -1.57628944e-01, -1.82321557e-01, -2.51314428e-01,\n",
       "                     -4.05465108e-01, -6.93147181e-01, -7.00582159e-01, -7.48409859e-01,\n",
       "                     -9.34309237e-01, -1.09861229e+00, -3.45387764e+01]), auc_score=0.5097559741906114, privacy_risk=0.512880193728483, accuracy=0.512880193728483, tpr_ind=0.36445012787723785, tnr_ind=0.6613102595797281, test_train_ratio=1.0345268542199488, dataset_size=[782, 809]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.63682864, 0.69948849, 0.75319693, 0.79283887,\n",
       "                     0.80306905, 0.82097187, 0.82352941, 0.86061381, 0.87595908,\n",
       "                     0.89002558, 0.90153453, 0.92199488, 0.92455243, 0.9398977 ,\n",
       "                     0.94373402, 0.94501279, 0.94501279, 0.94629156, 0.9629156 ,\n",
       "                     0.96419437, 1.        ]), tpr=array([0.        , 0.67985167, 0.72311496, 0.78862794, 0.80964153,\n",
       "                     0.82818294, 0.85166873, 0.86279357, 0.90482077, 0.91965389,\n",
       "                     0.93448702, 0.94561187, 0.9592089 , 0.9592089 , 0.98640297,\n",
       "                     0.98640297, 0.98640297, 0.98763906, 0.98763906, 1.        ,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.81708770e-02, -3.70412717e-02,\n",
       "                     -5.71584138e-02, -6.45385211e-02, -1.00083459e-01, -1.05360516e-01,\n",
       "                     -1.11225635e-01, -1.54150680e-01, -2.23143551e-01, -2.87682072e-01,\n",
       "                     -3.10154928e-01, -3.97682968e-01, -4.05465108e-01, -4.76924072e-01,\n",
       "                     -6.08589793e-01, -6.39079959e-01, -6.49344558e-01, -6.93147181e-01,\n",
       "                     -1.09861229e+00, -3.45387764e+01]), auc_score=0.5257279834597353, privacy_risk=0.5232526342078725, accuracy=0.5232526342078725, tpr_ind=0.9864029666254636, tnr_ind=0.06010230179028133, test_train_ratio=0.9666254635352287, dataset_size=[809, 782]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.53614458, 0.58915663, 0.65301205, 0.69036145,\n",
       "                     0.73373494, 0.76144578, 0.78554217, 0.78915663, 0.87108434,\n",
       "                     0.88313253, 0.88795181, 0.89036145, 0.92650602, 0.92771084,\n",
       "                     0.93614458, 0.93614458, 0.9373494 , 0.93855422, 0.94819277,\n",
       "                     0.94939759, 0.95421687, 0.95662651, 0.9626506 , 0.96506024,\n",
       "                     1.        ]), tpr=array([0.        , 0.56504599, 0.63600526, 0.68725361, 0.75558476,\n",
       "                     0.79632063, 0.82128778, 0.84494087, 0.84494087, 0.91327201,\n",
       "                     0.92904074, 0.94086728, 0.94218134, 0.97503285, 0.97766097,\n",
       "                     0.98423127, 0.98554534, 0.98554534, 0.9868594 , 0.99211564,\n",
       "                     0.99211564, 0.99211564, 0.99605782, 1.        , 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.83491387e-02, -2.53178080e-02,\n",
       "                     -5.60894667e-02, -9.23733201e-02, -1.00083459e-01, -1.05360516e-01,\n",
       "                     -1.17783036e-01, -1.26293725e-01, -1.54150680e-01, -2.00670695e-01,\n",
       "                     -2.75705881e-01, -2.87682072e-01, -3.22287602e-01, -3.36472237e-01,\n",
       "                     -3.46870944e-01, -3.62905494e-01, -3.76477571e-01, -4.05465108e-01,\n",
       "                     -4.48024723e-01, -4.59532329e-01, -6.93147181e-01, -8.47297860e-01,\n",
       "                     -1.38629436e+00, -3.45387764e+01]), auc_score=0.5293391700837515, privacy_risk=0.5326116555578424, accuracy=0.5326116555578424, tpr_ind=0.7555847568988173, tnr_ind=0.3096385542168675, test_train_ratio=1.090670170827858, dataset_size=[761, 830]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.75399754, 0.80073801, 0.84255843, 0.8597786 ,\n",
       "                     0.87453875, 0.88560886, 0.900369  , 0.93849938, 0.95079951,\n",
       "                     0.95325953, 0.96555966, 0.96924969, 1.        ]), tpr=array([0.        , 0.81748072, 0.85989717, 0.8933162 , 0.91645244,\n",
       "                     0.93059126, 0.93958869, 0.9562982 , 0.97943445, 0.99228792,\n",
       "                     0.99228792, 0.99871465, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.88405000e-02, -7.41079722e-02,\n",
       "                     -1.54150680e-01, -1.67054085e-01, -2.51314428e-01, -2.68263987e-01,\n",
       "                     -2.87682072e-01, -4.05465108e-01, -6.21688217e-01, -6.93147181e-01,\n",
       "                     -1.38629436e+00, -3.45387764e+01]), auc_score=0.5357620542786404, privacy_risk=0.5317415899094724, accuracy=0.5317415899094724, tpr_ind=0.8174807197943444, tnr_ind=0.24600246002460024, test_train_ratio=1.044987146529563, dataset_size=[778, 813]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.43488943, 0.55159705, 0.59336609, 0.79361179,\n",
       "                     0.80958231, 0.84029484, 0.84766585, 0.88452088, 0.91646192,\n",
       "                     0.92260442, 0.93734644, 0.93857494, 0.96191646, 0.96314496,\n",
       "                     0.96314496, 0.96683047, 0.96805897, 0.96805897, 0.96928747,\n",
       "                     0.97174447, 0.97174447, 0.97420147, 1.        ]), tpr=array([0.        , 0.45688546, 0.60617761, 0.64607465, 0.84169884,\n",
       "                     0.85714286, 0.88545689, 0.8983269 , 0.93564994, 0.96010296,\n",
       "                     0.96396396, 0.97425997, 0.97425997, 0.99356499, 0.99356499,\n",
       "                     0.996139  , 0.996139  , 0.996139  , 0.997426  , 0.997426  ,\n",
       "                     0.998713  , 1.        , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.55333020e-02, -3.17486983e-02,\n",
       "                     -7.59859070e-02, -8.00427077e-02, -8.70113770e-02, -9.53101798e-02,\n",
       "                     -1.29211731e-01, -1.46603474e-01, -2.87682072e-01, -3.18453731e-01,\n",
       "                     -3.80772496e-01, -3.82992252e-01, -4.05465108e-01, -4.70003629e-01,\n",
       "                     -4.73287704e-01, -4.96436886e-01, -5.16216472e-01, -5.32216814e-01,\n",
       "                     -5.35302370e-01, -6.93147181e-01, -7.50305594e-01, -3.45387764e+01]), auc_score=0.5298729758189218, privacy_risk=0.5272902772902773, accuracy=0.5272902772902773, tpr_ind=0.6061776061776062, tnr_ind=0.4484029484029484, test_train_ratio=1.0476190476190477, dataset_size=[777, 814]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.33877039, 0.90840652, 0.93350063, 0.96988708,\n",
       "                     0.96988708, 0.97365119, 0.97365119, 0.97867001, 1.        ]), tpr=array([0.        , 0.35642317, 0.94332494, 0.96851385, 0.99244332,\n",
       "                     0.99370277, 0.99748111, 0.99874055, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.42930824e-02, -1.39761942e-01,\n",
       "                     -1.46603474e-01, -3.79489622e-01, -5.23385818e-01, -6.93147181e-01,\n",
       "                     -1.09861229e+00, -3.45387764e+01]), auc_score=0.5203217986846139, privacy_risk=0.517506613275855, accuracy=0.517506613275855, tpr_ind=0.9685138539042821, tnr_ind=0.06649937264742785, test_train_ratio=1.0037783375314862, dataset_size=[794, 797]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.60273973, 0.68368618, 0.73972603, 0.88542964,\n",
       "                     0.9003736 , 0.91033624, 0.91531756, 0.92403487, 0.9377335 ,\n",
       "                     0.94520548, 0.9501868 , 0.95516812, 0.95765878, 0.96388543,\n",
       "                     0.96637609, 0.97135741, 0.9750934 , 0.97758406, 1.        ]), tpr=array([0.        , 0.64593909, 0.72715736, 0.78807107, 0.91624365,\n",
       "                     0.93020305, 0.94162437, 0.94796954, 0.95939086, 0.96954315,\n",
       "                     0.97588832, 0.9784264 , 0.98096447, 0.98350254, 0.98984772,\n",
       "                     0.98984772, 0.99619289, 1.        , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.58095360e-02, -8.00427077e-02,\n",
       "                     -8.53598490e-02, -8.70113770e-02, -1.05360516e-01, -1.82321557e-01,\n",
       "                     -2.00670695e-01, -2.23143551e-01, -2.41510428e-01, -2.90229845e-01,\n",
       "                     -3.34202088e-01, -4.05465108e-01, -4.70003629e-01, -5.59615788e-01,\n",
       "                     -5.87786665e-01, -6.93147181e-01, -8.10930216e-01, -3.45387764e+01]), auc_score=0.5278650492126606, privacy_risk=0.5241725192962937, accuracy=0.5241725192962937, tpr_ind=0.7880710659898477, tnr_ind=0.2602739726027397, test_train_ratio=1.0190355329949239, dataset_size=[788, 803]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.     , 0.3725 , 0.44375, 0.66625, 0.715  , 0.81875, 0.84125,\n",
       "                     0.8975 , 0.93875, 0.94625, 0.955  , 0.95625, 0.95625, 0.96   ,\n",
       "                     0.96125, 0.96875, 0.97   , 0.97125, 1.     ]), tpr=array([0.        , 0.39949431, 0.49304678, 0.71049305, 0.7471555 ,\n",
       "                     0.83565107, 0.86219975, 0.91529709, 0.97092288, 0.97724399,\n",
       "                     0.98735777, 0.988622  , 0.98988622, 0.99115044, 0.99115044,\n",
       "                     0.99747155, 1.        , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.34230203e-02, -3.42890735e-02,\n",
       "                     -6.66913745e-02, -6.89928715e-02, -9.09717782e-02, -1.12477983e-01,\n",
       "                     -1.27833372e-01, -1.82321557e-01, -2.23143551e-01, -3.97860509e-01,\n",
       "                     -4.48024723e-01, -5.69094532e-01, -6.28608659e-01, -6.93147181e-01,\n",
       "                     -9.16290732e-01, -9.38269639e-01, -3.45387764e+01]), auc_score=0.5265257585335019, privacy_risk=0.5246483881163084, accuracy=0.5246483881163084, tpr_ind=0.49304677623261695, tnr_ind=0.55625, test_train_ratio=1.011378002528445, dataset_size=[791, 800]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.45988024, 0.60958084, 0.73293413, 0.83712575,\n",
       "                     0.90179641, 0.90658683, 0.90898204, 0.91017964, 0.9257485 ,\n",
       "                     0.9257485 , 0.94131737, 0.95209581, 0.95209581, 0.95449102,\n",
       "                     0.95688623, 0.95808383, 0.95808383, 0.95928144, 0.96047904,\n",
       "                     0.96167665, 0.96407186, 0.97125749, 0.97245509, 1.        ]), tpr=array([0.        , 0.51984127, 0.66269841, 0.8042328 , 0.89153439,\n",
       "                     0.92592593, 0.93650794, 0.94312169, 0.94312169, 0.95899471,\n",
       "                     0.96031746, 0.98280423, 0.98677249, 0.98809524, 0.98941799,\n",
       "                     0.98941799, 0.99074074, 0.99206349, 0.99206349, 0.99470899,\n",
       "                     0.99470899, 0.99470899, 1.        , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.73989742e-02, -7.21032939e-02,\n",
       "                     -8.70113770e-02, -1.09199292e-01, -1.17783036e-01, -1.82321557e-01,\n",
       "                     -2.07639365e-01, -2.23143551e-01, -2.52702354e-01, -2.57829109e-01,\n",
       "                     -2.87682072e-01, -3.60002734e-01, -3.79489622e-01, -4.22856851e-01,\n",
       "                     -4.36717652e-01, -4.82851772e-01, -5.27354926e-01, -5.36304709e-01,\n",
       "                     -5.52068582e-01, -6.15185639e-01, -6.93147181e-01, -7.64972915e-01,\n",
       "                     -3.45387764e+01]), auc_score=0.5418052783322245, privacy_risk=0.5356493362481386, accuracy=0.5356493362481386, tpr_ind=0.8042328042328042, tnr_ind=0.26706586826347306, test_train_ratio=1.1044973544973544, dataset_size=[756, 835]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.64713376, 0.72993631, 0.75541401, 0.78598726,\n",
       "                     0.78726115, 0.8433121 , 0.86624204, 0.88789809, 0.90191083,\n",
       "                     0.91464968, 0.91592357, 0.91592357, 0.91847134, 0.91974522,\n",
       "                     0.91974522, 0.94267516, 0.94267516, 0.94649682, 0.94904459,\n",
       "                     0.95159236, 0.95286624, 0.95286624, 0.95414013, 0.96942675,\n",
       "                     0.97070064, 0.97197452, 1.        ]), tpr=array([0.        , 0.69975186, 0.77171216, 0.80645161, 0.83622829,\n",
       "                     0.83622829, 0.89205955, 0.91811414, 0.93300248, 0.94913151,\n",
       "                     0.95905707, 0.96774194, 0.96898263, 0.96898263, 0.97022333,\n",
       "                     0.97270471, 0.98138958, 0.98635236, 0.98759305, 0.98759305,\n",
       "                     0.98759305, 0.98759305, 0.98883375, 0.99007444, 0.99875931,\n",
       "                     0.99875931, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.70944334e-02, -6.89928715e-02,\n",
       "                     -8.00427077e-02, -1.21360857e-01, -1.25163143e-01, -1.33531393e-01,\n",
       "                     -1.54150680e-01, -2.07639365e-01, -2.23143551e-01, -2.87682072e-01,\n",
       "                     -3.25422400e-01, -3.61013346e-01, -3.94165553e-01, -4.05465108e-01,\n",
       "                     -4.51985124e-01, -4.59532329e-01, -4.84962113e-01, -5.38996501e-01,\n",
       "                     -5.69533225e-01, -5.97837001e-01, -6.28608659e-01, -6.63294217e-01,\n",
       "                     -6.93147181e-01, -9.80829253e-01, -1.09861229e+00, -3.45387764e+01]), auc_score=0.5326215801868154, privacy_risk=0.526529531696986, accuracy=0.526529531696986, tpr_ind=0.9689826302729528, tnr_ind=0.0840764331210191, test_train_ratio=0.9739454094292804, dataset_size=[806, 785]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.49224806, 0.58268734, 0.76744186, 0.8630491 ,\n",
       "                     0.90310078, 0.94186047, 0.95348837, 0.95607235, 0.95994832,\n",
       "                     0.96382429, 0.96382429, 1.        ]), tpr=array([0.        , 0.5128519 , 0.59608323, 0.79069767, 0.88372093,\n",
       "                     0.92411261, 0.96572827, 0.97429621, 0.98164015, 0.99020808,\n",
       "                     0.99510404, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.45987994e-02, -3.09622256e-02,\n",
       "                     -6.37158144e-02, -8.70113770e-02, -1.11225635e-01, -1.33531393e-01,\n",
       "                     -2.87682072e-01, -3.56674944e-01, -4.05465108e-01, -6.93147181e-01,\n",
       "                     -3.45387764e+01]), auc_score=0.5150002055797507, privacy_risk=0.5180878552971576, accuracy=0.5180878552971576, tpr_ind=1.0, tnr_ind=0.03617571059431524, test_train_ratio=0.9473684210526315, dataset_size=[817, 774]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.46027743, 0.7074401 , 0.89659521, 0.89911728,\n",
       "                     0.89911728, 0.90416141, 0.90668348, 0.90668348, 0.91172762,\n",
       "                     0.91172762, 0.92812106, 0.93820933, 0.93947037, 0.93947037,\n",
       "                     0.9445145 , 0.96343001, 0.96469105, 1.        ]), tpr=array([0.        , 0.52255639, 0.73558897, 0.94360902, 0.94611529,\n",
       "                     0.94862155, 0.95488722, 0.95739348, 0.95864662, 0.96240602,\n",
       "                     0.96365915, 0.97368421, 0.97994987, 0.98245614, 0.98496241,\n",
       "                     0.98746867, 1.        , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.46855580e-02, -7.53980175e-02,\n",
       "                     -1.17783036e-01, -1.25163143e-01, -1.82321557e-01, -2.02940844e-01,\n",
       "                     -2.41162057e-01, -2.87682072e-01, -3.10154928e-01, -3.18453731e-01,\n",
       "                     -3.36472237e-01, -4.05465108e-01, -4.41832752e-01, -5.26093096e-01,\n",
       "                     -6.93147181e-01, -1.09861229e+00, -3.45387764e+01]), auc_score=0.5363116176317212, privacy_risk=0.5311394817434507, accuracy=0.5311394817434507, tpr_ind=0.5225563909774437, tnr_ind=0.5397225725094578, test_train_ratio=0.993734335839599, dataset_size=[798, 793]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.57052097, 0.613723  , 0.69758577, 0.77890724,\n",
       "                     0.8094028 , 0.82083863, 0.85133418, 0.8703939 , 0.93900889,\n",
       "                     0.94917408, 0.95298602, 0.95425667, 0.95552732, 0.95552732,\n",
       "                     0.95806861, 0.95933926, 0.96060991, 0.96188056, 0.96188056,\n",
       "                     0.96315121, 0.9707751 , 0.97204574, 0.97458704, 1.        ]), tpr=array([0.        , 0.6119403 , 0.67537313, 0.76741294, 0.82462687,\n",
       "                     0.85572139, 0.86442786, 0.88059701, 0.89552239, 0.960199  ,\n",
       "                     0.97263682, 0.97636816, 0.97761194, 0.97761194, 0.98507463,\n",
       "                     0.98507463, 0.98631841, 0.99004975, 0.99253731, 0.99502488,\n",
       "                     0.99502488, 0.99875622, 0.99875622, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.84662808e-02, -5.26437335e-02,\n",
       "                     -6.31789016e-02, -7.69610411e-02, -1.33531393e-01, -1.43100844e-01,\n",
       "                     -1.54150680e-01, -1.59630146e-01, -1.82321557e-01, -2.87682072e-01,\n",
       "                     -3.41749294e-01, -3.52220594e-01, -4.05465108e-01, -4.58953793e-01,\n",
       "                     -4.70003629e-01, -5.10825624e-01, -5.55946059e-01, -5.68849464e-01,\n",
       "                     -6.30233355e-01, -6.93147181e-01, -7.98507696e-01, -1.09861229e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5306369992477258, privacy_risk=0.5349135832906623, accuracy=0.5349135832906623, tpr_ind=0.7674129353233831, tnr_ind=0.30241423125794153, test_train_ratio=0.9788557213930348, dataset_size=[804, 787]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.69221411, 0.78953771, 0.81873479, 0.84428224,\n",
       "                     0.85279805, 0.87104623, 0.87104623, 0.89416058, 0.89537713,\n",
       "                     0.9136253 , 0.92579075, 0.92579075, 0.9270073 , 0.93187348,\n",
       "                     0.94038929, 0.95255474, 0.95377129, 0.96472019, 0.96472019,\n",
       "                     0.96836983, 0.97201946, 1.        ]), tpr=array([0.        , 0.72171651, 0.82444733, 0.85955787, 0.87646294,\n",
       "                     0.89206762, 0.90637191, 0.9076723 , 0.93628088, 0.94278283,\n",
       "                     0.95838752, 0.96749025, 0.97139142, 0.97139142, 0.97139142,\n",
       "                     0.97919376, 0.9869961 , 0.9869961 , 0.99349805, 0.99479844,\n",
       "                     0.99869961, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -6.13689464e-02, -7.14589640e-02,\n",
       "                     -7.41079722e-02, -8.00427077e-02, -8.70113770e-02, -1.33531393e-01,\n",
       "                     -1.67054085e-01, -1.82321557e-01, -2.23143551e-01, -2.51314428e-01,\n",
       "                     -2.87682072e-01, -3.05381650e-01, -3.65113813e-01, -4.05465108e-01,\n",
       "                     -5.10825624e-01, -5.70544858e-01, -5.87786665e-01, -6.16774202e-01,\n",
       "                     -6.93147181e-01, -1.09861229e+00, -3.45387764e+01]), auc_score=0.520726351725469, privacy_risk=0.523702852948342, accuracy=0.523702852948342, tpr_ind=0.9427828348504551, tnr_ind=0.10462287104622871, test_train_ratio=1.068920676202861, dataset_size=[769, 822]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_0.0', fpr=array([0.        , 0.53006135, 0.58282209, 0.62822086, 0.68711656,\n",
       "                     0.7595092 , 0.78895706, 0.84907975, 0.85276074, 0.8797546 ,\n",
       "                     0.8993865 , 0.92883436, 0.93374233, 0.95705521, 0.96196319,\n",
       "                     0.96319018, 0.96564417, 1.        ]), tpr=array([0.        , 0.54510309, 0.59407216, 0.66237113, 0.70618557,\n",
       "                     0.78221649, 0.80798969, 0.8685567 , 0.87886598, 0.91365979,\n",
       "                     0.93041237, 0.97164948, 0.98324742, 0.9935567 , 0.99871134,\n",
       "                     0.99871134, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.59754864e-02, -5.50597772e-02,\n",
       "                     -5.71584138e-02, -8.13456395e-02, -9.53101798e-02, -1.01096117e-01,\n",
       "                     -1.17783036e-01, -1.38150338e-01, -1.43100844e-01, -1.71850257e-01,\n",
       "                     -2.87682072e-01, -4.05465108e-01, -6.93147181e-01, -8.26678573e-01,\n",
       "                     -1.38629436e+00, -3.45387764e+01]), auc_score=0.5153097527038137, privacy_risk=0.5247525456960344, accuracy=0.5247525456960344, tpr_ind=0.9832474226804123, tnr_ind=0.06625766871165645, test_train_ratio=1.050257731958763, dataset_size=[776, 815])],\n",
       "             'subpopulation_0.0_label_1.0_mia_auc': [0.9095015055202409,\n",
       "              0.8180458624127618,\n",
       "              0.9155000000000001,\n",
       "              0.9095568783068783,\n",
       "              0.8391666666666666,\n",
       "              0.7629752066115703,\n",
       "              0.8718843469591224,\n",
       "              0.8658414185346269,\n",
       "              0.8858424725822531,\n",
       "              0.7612732095490717,\n",
       "              0.7475198412698414,\n",
       "              0.9099368560983715,\n",
       "              0.8298576630254884,\n",
       "              0.8919232042370077,\n",
       "              0.8453249336870027,\n",
       "              0.8935,\n",
       "              0.8914650537634409,\n",
       "              0.8880968169761273,\n",
       "              0.9109090909090909,\n",
       "              0.7719973235195717],\n",
       "             'subpopulation_0.0_label_1.0_mia_privacy_risk': [0.8591502174640349,\n",
       "              0.7758391492190096,\n",
       "              0.865,\n",
       "              0.828042328042328,\n",
       "              0.7733333333333333,\n",
       "              0.7181818181818181,\n",
       "              0.8484546360917248,\n",
       "              0.8263633322181332,\n",
       "              0.8389830508474576,\n",
       "              0.7115384615384616,\n",
       "              0.6699735449735449,\n",
       "              0.847457627118644,\n",
       "              0.7404832836809003,\n",
       "              0.7997351870241642,\n",
       "              0.8202917771883289,\n",
       "              0.8316666666666667,\n",
       "              0.8161962365591398,\n",
       "              0.8232758620689655,\n",
       "              0.8272727272727273,\n",
       "              0.7775175644028103],\n",
       "             'subpopulation_0.0_label_1.0_mia_ppv': [0.95,\n",
       "              0.8500000000000001,\n",
       "              0.9166666666666667,\n",
       "              0.9310344827586208,\n",
       "              0.8571428571428572,\n",
       "              0.8095238095238094,\n",
       "              0.8749999999999999,\n",
       "              0.8620689655172414,\n",
       "              0.8620689655172413,\n",
       "              0.75,\n",
       "              0.8500000000000001,\n",
       "              0.875,\n",
       "              0.8666666666666667,\n",
       "              1.0,\n",
       "              0.8333333333333333,\n",
       "              0.888888888888889,\n",
       "              0.9166666666666667,\n",
       "              0.9047619047619048,\n",
       "              0.9411764705882353,\n",
       "              0.7666666666666666],\n",
       "             'subpopulation_0.0_label_1.0_mia_attacker_advantage': [0.7183004349280695,\n",
       "              0.5516782984380193,\n",
       "              0.73,\n",
       "              0.656084656084656,\n",
       "              0.5466666666666666,\n",
       "              0.4363636363636364,\n",
       "              0.6969092721834496,\n",
       "              0.6527266644362664,\n",
       "              0.6779661016949152,\n",
       "              0.42307692307692313,\n",
       "              0.3399470899470899,\n",
       "              0.6949152542372881,\n",
       "              0.4809665673618007,\n",
       "              0.5994703740483285,\n",
       "              0.6405835543766578,\n",
       "              0.6633333333333333,\n",
       "              0.6323924731182795,\n",
       "              0.646551724137931,\n",
       "              0.6545454545454545,\n",
       "              0.5550351288056206],\n",
       "             'subpopulation_0.0_label_1.0_mia_result': [MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.02040816, 0.02040816, 0.04081633, 0.04081633,\n",
       "                     0.04081633, 0.04081633, 0.06122449, 0.06122449, 0.12244898,\n",
       "                     0.12244898, 0.16326531, 0.18367347, 0.18367347, 0.20408163,\n",
       "                     0.20408163, 0.26530612, 0.28571429, 1.        ]), tpr=array([0.        , 0.24590164, 0.31147541, 0.31147541, 0.44262295,\n",
       "                     0.45901639, 0.52459016, 0.57377049, 0.59016393, 0.60655738,\n",
       "                     0.67213115, 0.70491803, 0.81967213, 0.83606557, 0.86885246,\n",
       "                     0.8852459 , 0.98360656, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.05465108e-01, -5.75364145e-01,\n",
       "                     -6.93147181e-01, -9.29535959e-01, -1.25276297e+00, -1.38629436e+00,\n",
       "                     -1.60943791e+00, -1.79175947e+00, -1.83258146e+00, -1.87180218e+00,\n",
       "                     -1.94591015e+00, -2.07944154e+00, -2.14006616e+00, -2.19722458e+00,\n",
       "                     -2.30258509e+00, -3.17805383e+00, -3.45387764e+01]), auc_score=0.9095015055202409, privacy_risk=0.8591502174640349, accuracy=0.8591502174640349, tpr_ind=0.9836065573770492, tnr_ind=0.7346938775510204, test_train_ratio=0.8032786885245902, dataset_size=[61, 49]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.05882353, 0.07843137, 0.07843137, 0.07843137,\n",
       "                     0.09803922, 0.11764706, 0.11764706, 0.11764706, 0.11764706,\n",
       "                     0.15686275, 0.23529412, 0.23529412, 0.29411765, 0.29411765,\n",
       "                     0.31372549, 0.39215686, 0.39215686, 0.41176471, 0.43137255,\n",
       "                     0.47058824, 1.        ]), tpr=array([0.        , 0.28813559, 0.3220339 , 0.33898305, 0.37288136,\n",
       "                     0.37288136, 0.40677966, 0.42372881, 0.47457627, 0.50847458,\n",
       "                     0.54237288, 0.62711864, 0.6440678 , 0.6779661 , 0.71186441,\n",
       "                     0.74576271, 0.88135593, 0.91525424, 0.93220339, 0.98305085,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.05465108e-01, -6.65748206e-01,\n",
       "                     -6.93147181e-01, -8.54691609e-01, -1.09861229e+00, -1.16820558e+00,\n",
       "                     -1.29928298e+00, -1.38629436e+00, -1.50407740e+00, -1.52605630e+00,\n",
       "                     -1.60943791e+00, -1.79175947e+00, -2.30258509e+00, -2.39789527e+00,\n",
       "                     -2.55528745e+00, -3.17805383e+00, -3.21887582e+00, -3.40119738e+00,\n",
       "                     -4.29045944e+00, -3.45387764e+01]), auc_score=0.8180458624127618, privacy_risk=0.7758391492190096, accuracy=0.7758391492190096, tpr_ind=0.9830508474576272, tnr_ind=0.5686274509803921, test_train_ratio=0.864406779661017, dataset_size=[59, 51]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.01666667, 0.01666667, 0.06666667, 0.06666667,\n",
       "                     0.06666667, 0.06666667, 0.06666667, 0.1       , 0.1       ,\n",
       "                     0.1       , 0.1       , 0.15      , 0.15      , 0.15      ,\n",
       "                     0.18333333, 0.2       , 0.23333333, 0.26666667, 0.33333333,\n",
       "                     1.        ]), tpr=array([0.  , 0.18, 0.22, 0.38, 0.42, 0.52, 0.56, 0.6 , 0.6 , 0.64, 0.7 ,\n",
       "                     0.74, 0.8 , 0.86, 0.88, 0.9 , 0.92, 0.94, 0.98, 1.  , 1.  ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.05465108e-01, -6.93147181e-01,\n",
       "                     -8.54415328e-01, -1.09861229e+00, -1.30992138e+00, -1.38629436e+00,\n",
       "                     -1.47181653e+00, -1.60943791e+00, -1.67397643e+00, -1.87180218e+00,\n",
       "                     -2.03688193e+00, -2.30258509e+00, -2.56494936e+00, -2.63905733e+00,\n",
       "                     -2.94443898e+00, -3.17805383e+00, -3.36729583e+00, -3.95124372e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.9155000000000001, privacy_risk=0.865, accuracy=0.865, tpr_ind=0.88, tnr_ind=0.85, test_train_ratio=1.2, dataset_size=[50, 60]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.03571429, 0.03571429, 0.05357143, 0.05357143,\n",
       "                     0.07142857, 0.07142857, 0.08928571, 0.21428571, 0.25      ,\n",
       "                     0.30357143, 0.33928571, 0.55357143, 1.        ]), tpr=array([0.        , 0.33333333, 0.5       , 0.5       , 0.57407407,\n",
       "                     0.64814815, 0.66666667, 0.74074074, 0.87037037, 0.88888889,\n",
       "                     0.92592593, 0.96296296, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -6.93147181e-01, -7.88457360e-01,\n",
       "                     -1.09861229e+00, -1.50407740e+00, -1.60943791e+00, -2.32727771e+00,\n",
       "                     -2.38482319e+00, -2.89037176e+00, -3.23867845e+00, -3.36729583e+00,\n",
       "                     -4.54859983e+00, -3.45387764e+01]), auc_score=0.9095568783068783, privacy_risk=0.828042328042328, accuracy=0.828042328042328, tpr_ind=0.8703703703703703, tnr_ind=0.7857142857142857, test_train_ratio=1.037037037037037, dataset_size=[54, 56]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.03333333, 0.03333333, 0.06666667, 0.08333333,\n",
       "                     0.13333333, 0.15      , 0.15      , 0.18333333, 0.21666667,\n",
       "                     0.21666667, 0.25      , 0.28333333, 0.3       , 0.35      ,\n",
       "                     0.36666667, 0.43333333, 0.51666667, 1.        ]), tpr=array([0.  , 0.22, 0.24, 0.44, 0.44, 0.48, 0.5 , 0.54, 0.6 , 0.64, 0.66,\n",
       "                     0.74, 0.76, 0.78, 0.88, 0.9 , 0.98, 1.  , 1.  ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -6.06135804e-01, -6.93147181e-01,\n",
       "                     -1.04145387e+00, -1.09861229e+00, -1.38629436e+00, -1.70474809e+00,\n",
       "                     -1.79175947e+00, -1.87180218e+00, -2.07944154e+00, -2.19722458e+00,\n",
       "                     -2.48490665e+00, -2.56494936e+00, -2.92316158e+00, -3.13549422e+00,\n",
       "                     -3.19867312e+00, -3.49650756e+00, -3.45387764e+01]), auc_score=0.8391666666666666, privacy_risk=0.7733333333333333, accuracy=0.7733333333333333, tpr_ind=0.98, tnr_ind=0.5666666666666667, test_train_ratio=1.2, dataset_size=[50, 60]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.03636364, 0.07272727, 0.07272727, 0.07272727,\n",
       "                     0.07272727, 0.09090909, 0.09090909, 0.10909091, 0.18181818,\n",
       "                     0.27272727, 0.50909091, 0.61818182, 1.        ]), tpr=array([0.        , 0.14545455, 0.18181818, 0.25454545, 0.27272727,\n",
       "                     0.30909091, 0.30909091, 0.34545455, 0.36363636, 0.49090909,\n",
       "                     0.54545455, 0.94545455, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.05465108e-01, -6.93147181e-01,\n",
       "                     -8.69037847e-01, -1.09861229e+00, -1.25276297e+00, -1.50407740e+00,\n",
       "                     -1.79175947e+00, -1.92529086e+00, -1.99243016e+00, -2.83321334e+00,\n",
       "                     -3.09104245e+00, -3.45387764e+01]), auc_score=0.7629752066115703, privacy_risk=0.7181818181818181, accuracy=0.7181818181818181, tpr_ind=0.9454545454545454, tnr_ind=0.4909090909090909, test_train_ratio=1.0, dataset_size=[55, 55]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.07843137, 0.11764706, 0.11764706, 0.11764706,\n",
       "                     0.11764706, 0.11764706, 0.15686275, 0.19607843, 0.23529412,\n",
       "                     0.23529412, 0.23529412, 0.23529412, 0.29411765, 0.35294118,\n",
       "                     0.35294118, 1.        ]), tpr=array([0.        , 0.22033898, 0.38983051, 0.40677966, 0.59322034,\n",
       "                     0.66101695, 0.71186441, 0.76271186, 0.79661017, 0.86440678,\n",
       "                     0.88135593, 0.91525424, 0.93220339, 0.94915254, 0.98305085,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -6.93147181e-01, -7.50305594e-01,\n",
       "                     -1.09861229e+00, -1.32175584e+00, -1.38629436e+00, -1.60943791e+00,\n",
       "                     -1.94591015e+00, -2.25129180e+00, -2.30258509e+00, -2.35137526e+00,\n",
       "                     -2.77258872e+00, -2.89037176e+00, -3.31418600e+00, -3.58351894e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.8718843469591224, privacy_risk=0.8484546360917248, accuracy=0.8484546360917248, tpr_ind=0.9322033898305084, tnr_ind=0.7647058823529411, test_train_ratio=0.864406779661017, dataset_size=[59, 51]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.06122449, 0.06122449, 0.08163265, 0.08163265,\n",
       "                     0.10204082, 0.10204082, 0.10204082, 0.12244898, 0.14285714,\n",
       "                     0.16326531, 0.18367347, 0.18367347, 0.2244898 , 0.2244898 ,\n",
       "                     0.26530612, 0.34693878, 0.3877551 , 0.44897959, 1.        ]), tpr=array([0.        , 0.27868852, 0.29508197, 0.36065574, 0.40983607,\n",
       "                     0.40983607, 0.42622951, 0.45901639, 0.49180328, 0.62295082,\n",
       "                     0.62295082, 0.6557377 , 0.68852459, 0.80327869, 0.86885246,\n",
       "                     0.91803279, 0.96721311, 0.98360656, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.67724780e-01, -5.59615788e-01,\n",
       "                     -6.93147181e-01, -7.25937003e-01, -9.98528830e-01, -1.09861229e+00,\n",
       "                     -1.25276297e+00, -1.38629436e+00, -1.42310833e+00, -1.70474809e+00,\n",
       "                     -1.94591015e+00, -2.13162729e+00, -2.35137526e+00, -2.42774824e+00,\n",
       "                     -2.90872090e+00, -3.68887945e+00, -4.00733319e+00, -3.45387764e+01]), auc_score=0.8658414185346269, privacy_risk=0.8263633322181332, accuracy=0.8263633322181332, tpr_ind=0.9180327868852459, tnr_ind=0.7346938775510204, test_train_ratio=0.8032786885245902, dataset_size=[61, 49]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.06779661, 0.06779661, 0.06779661, 0.11864407,\n",
       "                     0.11864407, 0.18644068, 0.20338983, 0.27118644, 0.27118644,\n",
       "                     0.30508475, 0.3220339 , 1.        ]), tpr=array([0.        , 0.31372549, 0.37254902, 0.49019608, 0.58823529,\n",
       "                     0.70588235, 0.78431373, 0.82352941, 0.8627451 , 0.92156863,\n",
       "                     0.96078431, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.87682072e-01, -6.93147181e-01,\n",
       "                     -1.09861229e+00, -1.38629436e+00, -1.44691898e+00, -1.50407740e+00,\n",
       "                     -1.87180218e+00, -1.94591015e+00, -2.63905733e+00, -2.86220088e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.8858424725822531, privacy_risk=0.8389830508474576, accuracy=0.8389830508474576, tpr_ind=1.0, tnr_ind=0.6779661016949152, test_train_ratio=1.1568627450980393, dataset_size=[51, 59]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.06896552, 0.06896552, 0.10344828, 0.10344828,\n",
       "                     0.15517241, 0.18965517, 0.22413793, 0.24137931, 0.27586207,\n",
       "                     0.29310345, 0.31034483, 0.32758621, 0.5       , 0.53448276,\n",
       "                     0.60344828, 1.        ]), tpr=array([0.        , 0.21153846, 0.23076923, 0.23076923, 0.26923077,\n",
       "                     0.40384615, 0.46153846, 0.48076923, 0.53846154, 0.61538462,\n",
       "                     0.63461538, 0.67307692, 0.69230769, 0.92307692, 0.94230769,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -6.93147181e-01, -8.47297860e-01,\n",
       "                     -9.80829253e-01, -1.14513230e+00, -1.29928298e+00, -1.38629436e+00,\n",
       "                     -1.99243016e+00, -2.11021320e+00, -2.39789527e+00, -2.48490665e+00,\n",
       "                     -2.56494936e+00, -2.61495978e+00, -3.46573590e+00, -3.68051120e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.7612732095490717, privacy_risk=0.7115384615384616, accuracy=0.7115384615384616, tpr_ind=0.9230769230769231, tnr_ind=0.5, test_train_ratio=1.1153846153846154, dataset_size=[52, 58]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.05357143, 0.07142857, 0.08928571, 0.10714286,\n",
       "                     0.125     , 0.16071429, 0.17857143, 0.73214286, 1.        ]), tpr=array([0.        , 0.31481481, 0.35185185, 0.37037037, 0.40740741,\n",
       "                     0.40740741, 0.46296296, 0.51851852, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.05465108e-01, -6.93147181e-01,\n",
       "                     -8.97741373e-01, -9.16290732e-01, -1.99243016e+00, -2.03688193e+00,\n",
       "                     -2.94038218e+00, -3.45387764e+01]), auc_score=0.7475198412698414, privacy_risk=0.6699735449735449, accuracy=0.6699735449735449, tpr_ind=0.5185185185185185, tnr_ind=0.8214285714285714, test_train_ratio=1.037037037037037, dataset_size=[54, 56]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.03389831, 0.05084746, 0.06779661, 0.06779661,\n",
       "                     0.06779661, 0.08474576, 0.08474576, 0.08474576, 0.16949153,\n",
       "                     0.27118644, 0.30508475, 1.        ]), tpr=array([0.        , 0.2745098 , 0.33333333, 0.41176471, 0.47058824,\n",
       "                     0.50980392, 0.50980392, 0.62745098, 0.68627451, 0.8627451 ,\n",
       "                     0.94117647, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -6.93147181e-01, -8.10930216e-01,\n",
       "                     -9.80829253e-01, -1.25846099e+00, -1.52939520e+00, -1.70474809e+00,\n",
       "                     -2.48490665e+00, -2.50325579e+00, -2.56494936e+00, -3.10608033e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.9099368560983715, privacy_risk=0.847457627118644, accuracy=0.847457627118644, tpr_ind=1.0, tnr_ind=0.6949152542372882, test_train_ratio=1.1568627450980393, dataset_size=[51, 59]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.05263158, 0.05263158, 0.07017544, 0.07017544,\n",
       "                     0.07017544, 0.07017544, 0.12280702, 0.22807018, 0.26315789,\n",
       "                     0.36842105, 0.42105263, 0.57894737, 0.59649123, 1.        ]), tpr=array([0.        , 0.26415094, 0.32075472, 0.41509434, 0.43396226,\n",
       "                     0.47169811, 0.49056604, 0.60377358, 0.69811321, 0.73584906,\n",
       "                     0.83018868, 0.86792453, 0.98113208, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.10825624e-01, -6.93147181e-01,\n",
       "                     -1.11399721e+00, -1.60943791e+00, -1.79175947e+00, -2.12026354e+00,\n",
       "                     -2.24070969e+00, -2.44234704e+00, -2.70805020e+00, -2.74084002e+00,\n",
       "                     -3.39002408e+00, -4.31748811e+00, -3.45387764e+01]), auc_score=0.8298576630254884, privacy_risk=0.7404832836809003, accuracy=0.7404832836809003, tpr_ind=0.6037735849056604, tnr_ind=0.8771929824561403, test_train_ratio=1.0754716981132075, dataset_size=[53, 57]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.        , 0.        , 0.        , 0.05263158,\n",
       "                     0.05263158, 0.07017544, 0.12280702, 0.12280702, 0.14035088,\n",
       "                     0.19298246, 0.35087719, 0.45614035, 1.        ]), tpr=array([0.        , 0.30188679, 0.32075472, 0.39622642, 0.39622642,\n",
       "                     0.43396226, 0.52830189, 0.58490566, 0.62264151, 0.67924528,\n",
       "                     0.79245283, 0.94339623, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.10825624e-01, -6.93147181e-01,\n",
       "                     -8.91998039e-01, -1.38629436e+00, -1.48160454e+00, -1.60943791e+00,\n",
       "                     -2.19722458e+00, -2.26868354e+00, -2.48490665e+00, -2.66549059e+00,\n",
       "                     -3.61091791e+00, -3.45387764e+01]), auc_score=0.8919232042370077, privacy_risk=0.7997351870241642, accuracy=0.7997351870241642, tpr_ind=0.7924528301886793, tnr_ind=0.8070175438596491, test_train_ratio=1.0754716981132075, dataset_size=[53, 57]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.09615385, 0.11538462, 0.11538462, 0.13461538,\n",
       "                     0.13461538, 0.13461538, 0.13461538, 0.15384615, 0.15384615,\n",
       "                     0.19230769, 0.28846154, 0.28846154, 0.28846154, 0.30769231,\n",
       "                     0.34615385, 0.40384615, 1.        ]), tpr=array([0.        , 0.29310345, 0.29310345, 0.32758621, 0.44827586,\n",
       "                     0.51724138, 0.5862069 , 0.60344828, 0.60344828, 0.67241379,\n",
       "                     0.72413793, 0.75862069, 0.81034483, 0.9137931 , 0.94827586,\n",
       "                     0.98275862, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.54150680e-01, -4.05465108e-01,\n",
       "                     -6.93147181e-01, -9.99405639e-01, -1.01160091e+00, -1.09861229e+00,\n",
       "                     -1.19392247e+00, -1.60943791e+00, -1.67397643e+00, -1.94591015e+00,\n",
       "                     -2.07944154e+00, -2.14006616e+00, -2.56494936e+00, -2.70805020e+00,\n",
       "                     -4.07753744e+00, -3.45387764e+01]), auc_score=0.8453249336870027, privacy_risk=0.8202917771883289, accuracy=0.8202917771883289, tpr_ind=0.9482758620689655, tnr_ind=0.6923076923076923, test_train_ratio=0.896551724137931, dataset_size=[58, 52]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.06666667, 0.06666667, 0.06666667, 0.06666667,\n",
       "                     0.06666667, 0.06666667, 0.15      , 0.16666667, 0.21666667,\n",
       "                     0.4       , 0.5       , 1.        ]), tpr=array([0.  , 0.4 , 0.48, 0.52, 0.58, 0.62, 0.64, 0.72, 0.78, 0.88, 0.98,\n",
       "                     1.  , 1.  ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -6.93147181e-01, -1.09861229e+00,\n",
       "                     -1.20397280e+00, -1.38629436e+00, -2.07944154e+00, -2.25129180e+00,\n",
       "                     -2.48490665e+00, -2.78501124e+00, -3.49042852e+00, -4.23410650e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.8935, privacy_risk=0.8316666666666667, accuracy=0.8316666666666667, tpr_ind=0.88, tnr_ind=0.7833333333333333, test_train_ratio=1.2, dataset_size=[50, 60]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.04166667, 0.08333333, 0.08333333, 0.08333333,\n",
       "                     0.08333333, 0.08333333, 0.10416667, 0.125     , 0.27083333,\n",
       "                     0.4375    , 1.        ]), tpr=array([0.        , 0.35483871, 0.51612903, 0.5483871 , 0.61290323,\n",
       "                     0.66129032, 0.67741935, 0.67741935, 0.69354839, 0.90322581,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -6.93147181e-01, -1.09861229e+00,\n",
       "                     -1.25276297e+00, -1.29928298e+00, -1.38629436e+00, -1.69459572e+00,\n",
       "                     -1.79175947e+00, -2.62243645e+00, -3.37872453e+00, -3.45387764e+01]), auc_score=0.8914650537634409, privacy_risk=0.8161962365591398, accuracy=0.8161962365591398, tpr_ind=0.9032258064516129, tnr_ind=0.7291666666666666, test_train_ratio=0.7741935483870968, dataset_size=[62, 48]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.03846154, 0.03846154, 0.05769231, 0.05769231,\n",
       "                     0.05769231, 0.07692308, 0.07692308, 0.09615385, 0.09615385,\n",
       "                     0.09615385, 0.09615385, 0.09615385, 0.15384615, 0.17307692,\n",
       "                     0.17307692, 0.17307692, 0.21153846, 0.25      , 0.32692308,\n",
       "                     0.40384615, 1.        ]), tpr=array([0.        , 0.29310345, 0.32758621, 0.32758621, 0.37931034,\n",
       "                     0.39655172, 0.39655172, 0.43103448, 0.43103448, 0.48275862,\n",
       "                     0.51724138, 0.53448276, 0.56896552, 0.72413793, 0.75862069,\n",
       "                     0.79310345, 0.81034483, 0.84482759, 0.89655172, 0.96551724,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.05465108e-01, -5.87786665e-01,\n",
       "                     -6.93147181e-01, -8.52211875e-01, -8.96088025e-01, -9.16290732e-01,\n",
       "                     -9.99521386e-01, -1.09861229e+00, -1.23969089e+00, -1.38629436e+00,\n",
       "                     -1.79175947e+00, -1.91364929e+00, -1.94591015e+00, -2.01490302e+00,\n",
       "                     -2.07944154e+00, -2.60268969e+00, -2.79320801e+00, -2.97041447e+00,\n",
       "                     -3.27714473e+00, -3.45387764e+01]), auc_score=0.8880968169761273, privacy_risk=0.8232758620689655, accuracy=0.8232758620689655, tpr_ind=0.896551724137931, tnr_ind=0.75, test_train_ratio=0.896551724137931, dataset_size=[58, 52]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.01818182, 0.03636364, 0.03636364, 0.03636364,\n",
       "                     0.03636364, 0.05454545, 0.05454545, 0.07272727, 0.07272727,\n",
       "                     0.07272727, 0.10909091, 0.10909091, 0.2       , 0.21818182,\n",
       "                     0.21818182, 0.25454545, 0.38181818, 1.        ]), tpr=array([0.        , 0.29090909, 0.32727273, 0.34545455, 0.4       ,\n",
       "                     0.41818182, 0.49090909, 0.56363636, 0.61818182, 0.63636364,\n",
       "                     0.67272727, 0.72727273, 0.74545455, 0.81818182, 0.83636364,\n",
       "                     0.87272727, 0.90909091, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.05465108e-01, -6.06135804e-01,\n",
       "                     -6.93147181e-01, -7.75838896e-01, -8.10930216e-01, -9.16290732e-01,\n",
       "                     -1.09861229e+00, -1.38629436e+00, -1.50407740e+00, -1.60943791e+00,\n",
       "                     -1.79175947e+00, -1.87180218e+00, -2.48490665e+00, -2.63905733e+00,\n",
       "                     -2.67414865e+00, -2.82137889e+00, -3.45387764e+01]), auc_score=0.9109090909090909, privacy_risk=0.8272727272727273, accuracy=0.8272727272727273, tpr_ind=0.8727272727272727, tnr_ind=0.7818181818181819, test_train_ratio=1.0, dataset_size=[55, 55]),\n",
       "              MIA_Attack_Result(name='subpopulation_0.0_label_1.0', fpr=array([0.        , 0.12244898, 0.12244898, 0.14285714, 0.14285714,\n",
       "                     0.2244898 , 0.2244898 , 0.28571429, 0.28571429, 0.32653061,\n",
       "                     0.32653061, 0.36734694, 0.36734694, 0.3877551 , 0.42857143,\n",
       "                     0.42857143, 0.51020408, 1.        ]), tpr=array([0.        , 0.26229508, 0.31147541, 0.31147541, 0.37704918,\n",
       "                     0.44262295, 0.49180328, 0.59016393, 0.62295082, 0.68852459,\n",
       "                     0.70491803, 0.78688525, 0.81967213, 0.90163934, 0.93442623,\n",
       "                     0.98360656, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.87682072e-01, -5.75364145e-01,\n",
       "                     -6.93147181e-01, -1.09861229e+00, -1.38629436e+00, -1.84582669e+00,\n",
       "                     -2.01490302e+00, -2.04769284e+00, -2.19722458e+00, -2.34180581e+00,\n",
       "                     -2.39789527e+00, -2.54944517e+00, -2.89037176e+00, -2.92673940e+00,\n",
       "                     -3.66356165e+00, -3.45387764e+01]), auc_score=0.7719973235195717, privacy_risk=0.7775175644028103, accuracy=0.7775175644028103, tpr_ind=0.9836065573770492, tnr_ind=0.5714285714285714, test_train_ratio=0.8032786885245902, dataset_size=[61, 49])],\n",
       "             'subpopulation_1.0_label_0.0_mia_auc': [0.5317007693897373,\n",
       "              0.5203839449916432,\n",
       "              0.5167122983542529,\n",
       "              0.5190596630024594,\n",
       "              0.5201407622763031,\n",
       "              0.5243208724409446,\n",
       "              0.5315815270391129,\n",
       "              0.525549955534261,\n",
       "              0.5302910346639769,\n",
       "              0.5289884701041716,\n",
       "              0.5226743914428249,\n",
       "              0.5216242848644743,\n",
       "              0.5261211831140387,\n",
       "              0.5277694418698611,\n",
       "              0.5336885381561776,\n",
       "              0.5263270730897194,\n",
       "              0.5328481546180253,\n",
       "              0.5260663204337775,\n",
       "              0.5259742676146142,\n",
       "              0.5246586434103111],\n",
       "             'subpopulation_1.0_label_0.0_mia_privacy_risk': [0.5248381882248665,\n",
       "              0.515243487374397,\n",
       "              0.5126790685732647,\n",
       "              0.5155514708526049,\n",
       "              0.5152224919019899,\n",
       "              0.5189044755554866,\n",
       "              0.521634977003353,\n",
       "              0.5183983875903639,\n",
       "              0.522590345905258,\n",
       "              0.5236955792248186,\n",
       "              0.5181947322023432,\n",
       "              0.5174994655451525,\n",
       "              0.5223287694161689,\n",
       "              0.5200321516848665,\n",
       "              0.5274241051863386,\n",
       "              0.5189430178812103,\n",
       "              0.5229333651561008,\n",
       "              0.5235056295345462,\n",
       "              0.5180511418007145,\n",
       "              0.5168765280955075],\n",
       "             'subpopulation_1.0_label_0.0_mia_ppv': [0.544127405441274,\n",
       "              0.5493827160493827,\n",
       "              0.5313059033989266,\n",
       "              0.5217391304347826,\n",
       "              0.5538160469667319,\n",
       "              0.5668380462724937,\n",
       "              0.6025316455696201,\n",
       "              0.557935735150925,\n",
       "              0.5540740740740742,\n",
       "              0.5488029465930019,\n",
       "              0.5334323922734027,\n",
       "              0.5484189723320159,\n",
       "              0.5250536864710093,\n",
       "              0.5754838709677419,\n",
       "              0.5679702048417132,\n",
       "              0.5511182108626198,\n",
       "              0.5576271186440678,\n",
       "              0.5428571428571428,\n",
       "              0.5552380952380952,\n",
       "              0.5422264875239923],\n",
       "             'subpopulation_1.0_label_0.0_mia_attacker_advantage': [0.049676376449732884,\n",
       "              0.030486974748793805,\n",
       "              0.025358137146529625,\n",
       "              0.031102941705209775,\n",
       "              0.03044498380397964,\n",
       "              0.037808951110973155,\n",
       "              0.04326995400670597,\n",
       "              0.03679677518072799,\n",
       "              0.04518069181051593,\n",
       "              0.04739115844963715,\n",
       "              0.03638946440468649,\n",
       "              0.03499893109030494,\n",
       "              0.044657538832337695,\n",
       "              0.04006430336973288,\n",
       "              0.05484821037267712,\n",
       "              0.03788603576242067,\n",
       "              0.045866730312201676,\n",
       "              0.047011259069092426,\n",
       "              0.03610228360142892,\n",
       "              0.033753056191015096],\n",
       "             'subpopulation_1.0_label_0.0_mia_result': [MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.02885982, 0.03127666, 0.03426216, 0.04193915,\n",
       "                     0.04364515, 0.04449815, 0.04634632, 0.04819448, 0.05032698,\n",
       "                     0.06596531, 0.07165198, 0.07222064, 0.0881433 , 0.09056014,\n",
       "                     0.09766847, 0.11600796, 0.12340063, 0.12439579, 0.12766562,\n",
       "                     0.14259312, 0.14827978, 0.15382428, 0.15780495, 0.17401194,\n",
       "                     0.17742394, 0.18097811, 0.1886551 , 0.20969576, 0.21182826,\n",
       "                     0.21580893, 0.26030708, 0.26343475, 0.26841058, 0.27224908,\n",
       "                     0.27750924, 0.28276941, 0.30125107, 0.32826272, 0.33750355,\n",
       "                     0.34475405, 0.34916122, 0.35371055, 0.36849588, 0.39067387,\n",
       "                     0.39508103, 0.41000853, 0.41612169, 0.42991186, 0.44441285,\n",
       "                     0.45479102, 0.46545351, 0.46986068, 0.48393517, 0.48578334,\n",
       "                     0.503412  , 0.507677  , 0.52317316, 0.55189082, 0.55843048,\n",
       "                     0.56383281, 0.56553881, 0.57335798, 0.57890247, 0.58302531,\n",
       "                     0.60506113, 0.61657663, 0.63321012, 0.65112312, 0.65808928,\n",
       "                     0.66334945, 0.66733011, 0.67131078, 0.67671311, 0.69661643,\n",
       "                     0.70727893, 0.70884276, 0.71268126, 0.72064259, 0.73102076,\n",
       "                     0.74296275, 0.74708558, 0.74751208, 0.75319875, 0.75504691,\n",
       "                     0.75646858, 0.77594541, 0.77694057, 0.77992607, 0.7857549 ,\n",
       "                     0.79627523, 0.79670173, 0.80082457, 0.8028149 , 0.80381007,\n",
       "                     0.81077623, 0.81191356, 0.83110606, 0.83352289, 0.83920955,\n",
       "                     0.84390105, 0.85015638, 0.85840205, 0.86522604, 0.87773671,\n",
       "                     0.87972704, 0.88512937, 0.88953654, 0.89451237, 0.89621837,\n",
       "                     0.89934603, 0.90005687, 0.90446403, 0.91882286, 0.92280353,\n",
       "                     0.92721069, 0.92777936, 0.92948536, 0.93716235, 0.94029002,\n",
       "                     0.95180552, 0.95308502, 0.95834518, 0.95990901, 0.96346318,\n",
       "                     0.96460051, 0.96588001, 0.96929201, 0.97199318, 0.97611601,\n",
       "                     0.97839067, 0.97981234, 0.98578334, 0.98692067, 0.98777367,\n",
       "                     0.98791584, 0.99004834, 0.990617  , 0.99075917, 0.99161217,\n",
       "                     1.        ]), tpr=array([0.        , 0.03300471, 0.03643378, 0.03957708, 0.04829261,\n",
       "                     0.05057865, 0.05257894, 0.05415059, 0.05715102, 0.05972282,\n",
       "                     0.07543935, 0.08258323, 0.08372625, 0.10172882, 0.10858694,\n",
       "                     0.11715959, 0.13316188, 0.14073439, 0.14230604, 0.14587798,\n",
       "                     0.16030862, 0.16716674, 0.17173882, 0.175025  , 0.19459923,\n",
       "                     0.20031433, 0.20445778, 0.21474496, 0.23774825, 0.23974854,\n",
       "                     0.2431776 , 0.28875554, 0.29475639, 0.30118588, 0.30647235,\n",
       "                     0.31261609, 0.32004572, 0.33676239, 0.36319474, 0.37319617,\n",
       "                     0.37976854, 0.38591227, 0.39077011, 0.40448636, 0.42620374,\n",
       "                     0.43034719, 0.44463495, 0.44977854, 0.46549507, 0.4799257 ,\n",
       "                     0.48964138, 0.50107158, 0.50450064, 0.51678811, 0.52050293,\n",
       "                     0.54150593, 0.54607801, 0.55922275, 0.59251322, 0.59794256,\n",
       "                     0.60494356, 0.60780111, 0.61665952, 0.62366052, 0.62694671,\n",
       "                     0.64752107, 0.65766538, 0.67652522, 0.69438491, 0.70224318,\n",
       "                     0.70924418, 0.71510216, 0.71995999, 0.72638948, 0.74510644,\n",
       "                     0.75125018, 0.75410773, 0.75796542, 0.7651093 , 0.77325332,\n",
       "                     0.78696957, 0.79125589, 0.79225604, 0.79597085, 0.79768538,\n",
       "                     0.79911416, 0.81783112, 0.81897414, 0.82168881, 0.82597514,\n",
       "                     0.83569081, 0.83740534, 0.84197743, 0.84526361, 0.84669238,\n",
       "                     0.85397914, 0.85497928, 0.8726961 , 0.87483926, 0.87926847,\n",
       "                     0.88398343, 0.88769824, 0.89412773, 0.90255751, 0.91298757,\n",
       "                     0.91527361, 0.91998857, 0.92513216, 0.92884698, 0.92984712,\n",
       "                     0.93213316, 0.93356194, 0.93756251, 0.9484212 , 0.950993  ,\n",
       "                     0.95442206, 0.95599371, 0.95727961, 0.96185169, 0.964995  ,\n",
       "                     0.97285326, 0.97371053, 0.97785398, 0.97928275, 0.98099729,\n",
       "                     0.98199743, 0.98285469, 0.98528361, 0.98742678, 0.99085584,\n",
       "                     0.99257037, 0.99328475, 0.99671382, 0.99728533, 0.99814259,\n",
       "                     0.99842835, 0.99942849, 0.99957137, 0.99985712, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.08219945e-02, -4.44517626e-02,\n",
       "                     -4.80092192e-02, -6.06246218e-02, -6.89928715e-02, -8.70113770e-02,\n",
       "                     -9.09717782e-02, -1.05360516e-01, -1.11703990e-01, -1.13328685e-01,\n",
       "                     -1.17783036e-01, -1.33531393e-01, -1.36132174e-01, -1.54150680e-01,\n",
       "                     -1.56698452e-01, -1.56842471e-01, -1.67054085e-01, -1.82321557e-01,\n",
       "                     -1.88900528e-01, -1.89242000e-01, -2.23143551e-01, -2.31801614e-01,\n",
       "                     -2.33310669e-01, -2.42946179e-01, -2.43622083e-01, -2.45122458e-01,\n",
       "                     -2.46471804e-01, -2.51314428e-01, -2.55933374e-01, -2.65494157e-01,\n",
       "                     -2.69663567e-01, -2.70874954e-01, -2.80902385e-01, -2.81851152e-01,\n",
       "                     -2.82862786e-01, -2.87682072e-01, -2.93072921e-01, -2.94799540e-01,\n",
       "                     -2.98492989e-01, -2.99242895e-01, -3.02280872e-01, -3.03186259e-01,\n",
       "                     -3.08838272e-01, -3.21583624e-01, -3.22083499e-01, -3.28504067e-01,\n",
       "                     -3.29957556e-01, -3.33639374e-01, -3.34369186e-01, -3.36472237e-01,\n",
       "                     -3.48306694e-01, -3.49673748e-01, -3.52821375e-01, -3.56674944e-01,\n",
       "                     -3.62905494e-01, -3.68560551e-01, -3.69044477e-01, -3.69747026e-01,\n",
       "                     -3.70859579e-01, -3.71563556e-01, -3.83725121e-01, -3.84845821e-01,\n",
       "                     -3.90866309e-01, -3.91478866e-01, -4.00759217e-01, -4.05465108e-01,\n",
       "                     -4.08128226e-01, -4.11507423e-01, -4.12244795e-01, -4.13562318e-01,\n",
       "                     -4.24883194e-01, -4.27444015e-01, -4.28107585e-01, -4.28454626e-01,\n",
       "                     -4.38254931e-01, -4.41832752e-01, -4.44685821e-01, -4.45585102e-01,\n",
       "                     -4.46287103e-01, -4.48950220e-01, -4.51985124e-01, -4.55475529e-01,\n",
       "                     -4.59532329e-01, -4.70003629e-01, -4.81388951e-01, -4.85507816e-01,\n",
       "                     -4.89548225e-01, -4.90622916e-01, -5.02091944e-01, -5.10825624e-01,\n",
       "                     -5.23248144e-01, -5.28067430e-01, -5.30628251e-01, -5.34082486e-01,\n",
       "                     -5.38996501e-01, -5.45694449e-01, -5.50046337e-01, -5.59615788e-01,\n",
       "                     -5.63935449e-01, -5.70544858e-01, -5.75364145e-01, -5.76422906e-01,\n",
       "                     -5.92342481e-01, -5.94707108e-01, -5.97837001e-01, -6.06135804e-01,\n",
       "                     -6.13104473e-01, -6.19039208e-01, -6.28608659e-01, -6.41853886e-01,\n",
       "                     -6.75128675e-01, -6.93147181e-01, -7.20546155e-01, -7.33969175e-01,\n",
       "                     -7.37598943e-01, -7.47214402e-01, -7.53771802e-01, -7.59105148e-01,\n",
       "                     -7.63351439e-01, -7.73189888e-01, -7.75838896e-01, -7.88457360e-01,\n",
       "                     -8.10930216e-01, -8.26678573e-01, -8.47297860e-01, -8.55666110e-01,\n",
       "                     -8.75468737e-01, -9.16290732e-01, -9.80829253e-01, -1.02961942e+00,\n",
       "                     -1.09861229e+00, -1.17865500e+00, -1.20397280e+00, -1.25276297e+00,\n",
       "                     -1.38629436e+00, -1.60943791e+00, -1.70474809e+00, -2.48490665e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5317007693897373, privacy_risk=0.5248381882248665, accuracy=0.5248381882248665, tpr_ind=0.7263894842120303, tnr_ind=0.32328689223770257, test_train_ratio=1.0050007143877697, dataset_size=[6999, 7034]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.0295892 , 0.0323183 , 0.03878196, 0.04409652,\n",
       "                     0.04639471, 0.05242746, 0.08330939, 0.08417122, 0.08718759,\n",
       "                     0.09178397, 0.09681126, 0.11419132, 0.11763861, 0.1226659 ,\n",
       "                     0.15340419, 0.1577133 , 0.17020971, 0.17351336, 0.20180982,\n",
       "                     0.2102844 , 0.23642631, 0.24016087, 0.25237001, 0.25840276,\n",
       "                     0.2612755 , 0.27463373, 0.28526286, 0.29675381, 0.33381212,\n",
       "                     0.33639759, 0.34243034, 0.34788854, 0.35406492, 0.40634875,\n",
       "                     0.41568515, 0.41755243, 0.44153979, 0.44556162, 0.4540362 ,\n",
       "                     0.46049986, 0.46394714, 0.48175812, 0.48190175, 0.48592359,\n",
       "                     0.4890836 , 0.49224361, 0.49626544, 0.50459638, 0.54926745,\n",
       "                     0.56176386, 0.56391841, 0.57296754, 0.57612755, 0.58029302,\n",
       "                     0.60830221, 0.61821316, 0.62122953, 0.62640046, 0.63731686,\n",
       "                     0.65196783, 0.65598966, 0.66015513, 0.66446423, 0.69721344,\n",
       "                     0.72996265, 0.73283539, 0.73427176, 0.73527722, 0.74145361,\n",
       "                     0.74403907, 0.76041367, 0.76702097, 0.79474289, 0.81097386,\n",
       "                     0.81341569, 0.82059753, 0.82835392, 0.83352485, 0.83769032,\n",
       "                     0.85277219, 0.86900316, 0.87029589, 0.88839414, 0.88882505,\n",
       "                     0.89385234, 0.89729963, 0.89902327, 0.90117782, 0.90405056,\n",
       "                     0.90950876, 0.91051422, 0.91281241, 0.91367423, 0.91956334,\n",
       "                     0.92832519, 0.93780523, 0.9474289 , 0.95633439, 0.96638897,\n",
       "                     0.97012353, 0.97673082, 0.9797472 , 0.98175812, 0.98448722,\n",
       "                     0.98463085, 0.98477449, 0.98592359, 0.98779086, 0.98965814,\n",
       "                     0.9906636 , 0.99152542, 0.99195633, 0.9933927 , 0.99396725,\n",
       "                     0.99439816, 1.        ]), tpr=array([0.        , 0.0342243 , 0.03775986, 0.044831  , 0.05275067,\n",
       "                     0.05529628, 0.06293311, 0.09772309, 0.09871305, 0.10154151,\n",
       "                     0.10606703, 0.11200679, 0.1313817 , 0.13435158, 0.14014991,\n",
       "                     0.17550559, 0.17889973, 0.19374912, 0.19770895, 0.22486211,\n",
       "                     0.23235752, 0.25611653, 0.25880356, 0.26884458, 0.27577429,\n",
       "                     0.27916843, 0.29415924, 0.30504879, 0.31523123, 0.3493141 ,\n",
       "                     0.35214255, 0.35695093, 0.36289068, 0.36911328, 0.43247065,\n",
       "                     0.44194598, 0.44420874, 0.46867487, 0.47235186, 0.47928157,\n",
       "                     0.48578702, 0.48974685, 0.50544477, 0.506859  , 0.51138453,\n",
       "                     0.51520294, 0.51760713, 0.52100127, 0.52920379, 0.57078207,\n",
       "                     0.58181304, 0.58464149, 0.59609673, 0.59821807, 0.60330929,\n",
       "                     0.63230095, 0.64333192, 0.64686749, 0.65422147, 0.66680809,\n",
       "                     0.68080894, 0.68476877, 0.69000141, 0.69495121, 0.72366002,\n",
       "                     0.75420733, 0.75760147, 0.76014708, 0.762127  , 0.76849102,\n",
       "                     0.77174374, 0.7851789 , 0.79041154, 0.81813039, 0.83326262,\n",
       "                     0.83481827, 0.84005091, 0.84698063, 0.85037477, 0.85659737,\n",
       "                     0.87639655, 0.89266016, 0.89365012, 0.90835808, 0.90948946,\n",
       "                     0.91359072, 0.91726771, 0.91924763, 0.92136897, 0.92433885,\n",
       "                     0.92914722, 0.93013718, 0.93225852, 0.9333899 , 0.94088531,\n",
       "                     0.94937067, 0.95686607, 0.96379579, 0.96874558, 0.97878659,\n",
       "                     0.98048367, 0.98713053, 0.98995899, 0.99137321, 0.99307029,\n",
       "                     0.9937774 , 0.99406025, 0.99490878, 0.99703012, 0.9981615 ,\n",
       "                     0.9987272 , 0.99915146, 0.99929289, 0.99957573, 0.99971715,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -7.69610411e-02, -9.53101798e-02,\n",
       "                     -1.00083459e-01, -1.05360516e-01, -1.21889818e-01, -1.25880246e-01,\n",
       "                     -1.33531393e-01, -1.39761942e-01, -1.45182010e-01, -1.54150680e-01,\n",
       "                     -1.67615409e-01, -1.74353387e-01, -1.78248231e-01, -1.82321557e-01,\n",
       "                     -1.89242000e-01, -1.90226736e-01, -1.94156014e-01, -2.14775302e-01,\n",
       "                     -2.19362828e-01, -2.23143551e-01, -2.33614851e-01, -2.48179629e-01,\n",
       "                     -2.51314428e-01, -2.55933374e-01, -2.71034839e-01, -2.71315095e-01,\n",
       "                     -2.87682072e-01, -2.99028249e-01, -3.00104592e-01, -3.02280872e-01,\n",
       "                     -3.05381650e-01, -3.10154928e-01, -3.11939050e-01, -3.17095958e-01,\n",
       "                     -3.18453731e-01, -3.23171957e-01, -3.25422400e-01, -3.27687407e-01,\n",
       "                     -3.30241687e-01, -3.31357136e-01, -3.33894916e-01, -3.36472237e-01,\n",
       "                     -3.40926587e-01, -3.41749294e-01, -3.44840486e-01, -3.48306694e-01,\n",
       "                     -3.58397597e-01, -3.66153688e-01, -3.70678992e-01, -3.71563556e-01,\n",
       "                     -3.72404246e-01, -3.82992252e-01, -3.86772975e-01, -3.87417038e-01,\n",
       "                     -3.88223302e-01, -3.92042088e-01, -3.92561703e-01, -4.01712758e-01,\n",
       "                     -4.02092424e-01, -4.05465108e-01, -4.14433778e-01, -4.14943852e-01,\n",
       "                     -4.23366318e-01, -4.26839968e-01, -4.32864082e-01, -4.41832752e-01,\n",
       "                     -4.51985124e-01, -4.70003629e-01, -4.75423697e-01, -4.83075711e-01,\n",
       "                     -4.83426650e-01, -4.83936724e-01, -4.86226465e-01, -4.92476485e-01,\n",
       "                     -4.99955952e-01, -5.02628857e-01, -5.10825624e-01, -5.19875459e-01,\n",
       "                     -5.22189382e-01, -5.33182531e-01, -5.38996501e-01, -5.54106132e-01,\n",
       "                     -5.59615788e-01, -5.64529803e-01, -5.70544858e-01, -5.79818495e-01,\n",
       "                     -5.87786665e-01, -5.93063722e-01, -6.16774202e-01, -6.19039208e-01,\n",
       "                     -6.24154309e-01, -6.28608659e-01, -6.44828603e-01, -6.67829373e-01,\n",
       "                     -6.74098986e-01, -6.93147181e-01, -7.21318058e-01, -7.27752710e-01,\n",
       "                     -7.73189888e-01, -7.94243297e-01, -8.10930216e-01, -8.32909123e-01,\n",
       "                     -8.47297860e-01, -8.75468737e-01, -9.16290732e-01, -9.80829253e-01,\n",
       "                     -1.09861229e+00, -1.17865500e+00, -1.25276297e+00, -1.38629436e+00,\n",
       "                     -1.60943791e+00, -1.70474809e+00, -1.79175947e+00, -2.19722458e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5203839449916432, privacy_risk=0.515243487374397, accuracy=0.515243487374397, tpr_ind=0.6949512091641917, tnr_ind=0.33553576558460213, test_train_ratio=0.9845849243388488, dataset_size=[7071, 6962]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.04125625, 0.04568166, 0.05524625, 0.05695931,\n",
       "                     0.06566738, 0.06652391, 0.07480371, 0.07665953, 0.07822984,\n",
       "                     0.08836545, 0.09293362, 0.09464668, 0.09807281, 0.10135617,\n",
       "                     0.11363312, 0.11891506, 0.12505353, 0.14061385, 0.14375446,\n",
       "                     0.15603141, 0.16088508, 0.16502498, 0.17173448, 0.17915774,\n",
       "                     0.18615275, 0.19029265, 0.19271949, 0.19571734, 0.20242684,\n",
       "                     0.21698787, 0.2194147 , 0.23169165, 0.2385439 , 0.23954318,\n",
       "                     0.28079943, 0.29693076, 0.30164168, 0.30920771, 0.3283369 ,\n",
       "                     0.34032834, 0.34675232, 0.3503212 , 0.36259814, 0.36759458,\n",
       "                     0.37444682, 0.38029979, 0.38187009, 0.39743041, 0.4       ,\n",
       "                     0.40728051, 0.4137045 , 0.46138473, 0.46523911, 0.46866524,\n",
       "                     0.47480371, 0.48636688, 0.50292648, 0.50692363, 0.5283369 ,\n",
       "                     0.52947894, 0.54232691, 0.55902926, 0.56017131, 0.56416845,\n",
       "                     0.56616702, 0.57615989, 0.57901499, 0.58715203, 0.60642398,\n",
       "                     0.61156317, 0.63625981, 0.64468237, 0.67651677, 0.68765168,\n",
       "                     0.72334047, 0.72819415, 0.7557459 , 0.75703069, 0.76188437,\n",
       "                     0.77958601, 0.78486795, 0.78643826, 0.79257673, 0.79329051,\n",
       "                     0.79657388, 0.81498929, 0.82640971, 0.84225553, 0.84639543,\n",
       "                     0.84796574, 0.85039258, 0.85082084, 0.85681656, 0.86067095,\n",
       "                     0.88379729, 0.88836545, 0.89179158, 0.89350464, 0.90521056,\n",
       "                     0.90935046, 0.91791577, 0.92077088, 0.92234118, 0.924197  ,\n",
       "                     0.92890792, 0.94275517, 0.94689507, 0.96202712, 0.96259814,\n",
       "                     0.96316916, 0.96545325, 0.96859386, 0.96916488, 0.97159172,\n",
       "                     0.97259101, 0.97359029, 0.97587438, 0.97701642, 0.97872948,\n",
       "                     0.9805853 , 0.98829408, 0.99129193, 0.99257673, 0.99286224,\n",
       "                     0.993005  , 0.99386153, 1.        ]), tpr=array([0.        , 0.0462436 , 0.05122368, 0.06061468, 0.06374502,\n",
       "                     0.07199772, 0.07398976, 0.08451907, 0.08622652, 0.08779169,\n",
       "                     0.09803643, 0.10145134, 0.1054354 , 0.10998862, 0.11269209,\n",
       "                     0.12464428, 0.13090495, 0.13816164, 0.15808196, 0.16135458,\n",
       "                     0.17174161, 0.17558338, 0.18056346, 0.18653956, 0.19393853,\n",
       "                     0.19877632, 0.20304496, 0.20674445, 0.20830962, 0.21499715,\n",
       "                     0.23321002, 0.23619806, 0.25014229, 0.25654525, 0.25796813,\n",
       "                     0.29709732, 0.31787137, 0.3222823 , 0.32882755, 0.3518782 ,\n",
       "                     0.36169607, 0.36781446, 0.37179852, 0.3850313 , 0.39043825,\n",
       "                     0.39655663, 0.40495162, 0.40722823, 0.42003415, 0.4230222 ,\n",
       "                     0.42985202, 0.43554354, 0.48335231, 0.48648264, 0.49132043,\n",
       "                     0.49743882, 0.50924872, 0.52532726, 0.52731929, 0.54795105,\n",
       "                     0.55022766, 0.56374502, 0.58081958, 0.58238475, 0.58579966,\n",
       "                     0.58793398, 0.59462151, 0.59704041, 0.60330108, 0.6232214 ,\n",
       "                     0.62763233, 0.65239044, 0.6599317 , 0.6883893 , 0.69778031,\n",
       "                     0.73648264, 0.74060899, 0.77063176, 0.77361981, 0.77973819,\n",
       "                     0.79923164, 0.8044963 , 0.80591918, 0.81146841, 0.81260672,\n",
       "                     0.81459875, 0.83693796, 0.84632897, 0.86311895, 0.86624929,\n",
       "                     0.86809903, 0.87009106, 0.87165623, 0.87749004, 0.87962436,\n",
       "                     0.90424018, 0.90793967, 0.91050085, 0.91306204, 0.92586796,\n",
       "                     0.93056346, 0.9395276 , 0.94223108, 0.94322709, 0.94493455,\n",
       "                     0.94891861, 0.96044394, 0.96457029, 0.97638019, 0.97723392,\n",
       "                     0.9786568 , 0.98178714, 0.98349459, 0.98449061, 0.98634035,\n",
       "                     0.98762094, 0.98833238, 0.98975526, 0.99103586, 0.99217416,\n",
       "                     0.99302789, 0.99715424, 0.99857712, 0.99900398, 0.99957314,\n",
       "                     0.99971542, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.81708770e-02, -2.98529631e-02,\n",
       "                     -4.44517626e-02, -6.66913745e-02, -6.89928715e-02, -7.79615415e-02,\n",
       "                     -8.00427077e-02, -8.70113770e-02, -1.05360516e-01, -1.17783036e-01,\n",
       "                     -1.33531393e-01, -1.45182010e-01, -1.46603474e-01, -1.54150680e-01,\n",
       "                     -1.67054085e-01, -1.79048231e-01, -1.82321557e-01, -1.96710294e-01,\n",
       "                     -1.98176929e-01, -2.00670695e-01, -2.05852054e-01, -2.13574100e-01,\n",
       "                     -2.23143551e-01, -2.34839591e-01, -2.36388778e-01, -2.38411023e-01,\n",
       "                     -2.41162057e-01, -2.44196961e-01, -2.44453338e-01, -2.51314428e-01,\n",
       "                     -2.59219608e-01, -2.60726262e-01, -2.62364264e-01, -2.63761889e-01,\n",
       "                     -2.68666806e-01, -2.79584862e-01, -2.82232468e-01, -2.87682072e-01,\n",
       "                     -2.94799540e-01, -2.99242895e-01, -3.05381650e-01, -3.11587593e-01,\n",
       "                     -3.13657559e-01, -3.14493330e-01, -3.16911711e-01, -3.18453731e-01,\n",
       "                     -3.20471895e-01, -3.22773392e-01, -3.33491608e-01, -3.36472237e-01,\n",
       "                     -3.41984229e-01, -3.42944751e-01, -3.44840486e-01, -3.49673748e-01,\n",
       "                     -3.51844017e-01, -3.54016546e-01, -3.56674944e-01, -3.60804337e-01,\n",
       "                     -3.62905494e-01, -3.67724780e-01, -3.71563556e-01, -3.74693449e-01,\n",
       "                     -3.77294231e-01, -3.82992252e-01, -3.83958903e-01, -3.85662481e-01,\n",
       "                     -4.05465108e-01, -4.14943852e-01, -4.16160397e-01, -4.20674527e-01,\n",
       "                     -4.24157241e-01, -4.35023910e-01, -4.35318071e-01, -4.39203248e-01,\n",
       "                     -4.39366660e-01, -4.47234521e-01, -4.51985124e-01, -4.58307589e-01,\n",
       "                     -4.64514137e-01, -4.66619531e-01, -4.70003629e-01, -4.79573080e-01,\n",
       "                     -4.85507816e-01, -4.96436886e-01, -5.08274602e-01, -5.10825624e-01,\n",
       "                     -5.12519104e-01, -5.19875459e-01, -5.26093096e-01, -5.38996501e-01,\n",
       "                     -5.46543706e-01, -5.49107810e-01, -5.50046337e-01, -5.53818670e-01,\n",
       "                     -5.54310736e-01, -5.59615788e-01, -5.75364145e-01, -5.87786665e-01,\n",
       "                     -5.97837001e-01, -6.10455465e-01, -6.10909082e-01, -6.19039208e-01,\n",
       "                     -6.50587566e-01, -6.56779536e-01, -6.93147181e-01, -7.10241614e-01,\n",
       "                     -7.40214691e-01, -7.73189888e-01, -7.88457360e-01, -8.00777845e-01,\n",
       "                     -8.10930216e-01, -8.26678573e-01, -8.36248024e-01, -8.47297860e-01,\n",
       "                     -8.75468737e-01, -9.16290732e-01, -9.80829253e-01, -1.01160091e+00,\n",
       "                     -1.04145387e+00, -1.09861229e+00, -1.38629436e+00, -1.46633707e+00,\n",
       "                     -1.60943791e+00, -1.79175947e+00, -1.94591015e+00, -3.45387764e+01]), auc_score=0.5167122983542529, privacy_risk=0.5126790685732647, accuracy=0.5126790685732647, tpr_ind=0.40722822993739327, tnr_ind=0.6181299072091363, test_train_ratio=0.996727376209448, dataset_size=[7028, 7005]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.04517134, 0.04927782, 0.05210988, 0.05593316,\n",
       "                     0.05876522, 0.06032285, 0.06527896, 0.07419994, 0.07731521,\n",
       "                     0.08113849, 0.09558199, 0.09629   , 0.1009629 , 0.10365336,\n",
       "                     0.10960068, 0.11880487, 0.12163693, 0.12475219, 0.13664684,\n",
       "                     0.13806287, 0.14599264, 0.14854149, 0.17587086, 0.17955253,\n",
       "                     0.18309261, 0.1972529 , 0.20135939, 0.22005098, 0.22670632,\n",
       "                     0.23364486, 0.23661852, 0.24369867, 0.24610592, 0.2550269 ,\n",
       "                     0.29141886, 0.29269329, 0.29920702, 0.30628717, 0.31011045,\n",
       "                     0.31365052, 0.31931464, 0.32441235, 0.33361654, 0.33701501,\n",
       "                     0.3510337 , 0.35514019, 0.37581422, 0.37864628, 0.41291419,\n",
       "                     0.45723591, 0.46063438, 0.47167941, 0.4757859 , 0.47748513,\n",
       "                     0.49461909, 0.49745115, 0.50028321, 0.52180685, 0.52973662,\n",
       "                     0.53511753, 0.54984424, 0.56018125, 0.5624469 , 0.57419994,\n",
       "                     0.59515718, 0.60237893, 0.60818465, 0.64061172, 0.64967431,\n",
       "                     0.65179836, 0.66227698, 0.66525064, 0.66893231, 0.67162277,\n",
       "                     0.67431323, 0.67530445, 0.69031436, 0.69767771, 0.70603229,\n",
       "                     0.70928915, 0.72854715, 0.73746814, 0.75049561, 0.79283489,\n",
       "                     0.79495894, 0.79665817, 0.79892382, 0.80529595, 0.81945624,\n",
       "                     0.83120929, 0.83333333, 0.83616539, 0.84395355, 0.86236194,\n",
       "                     0.86448598, 0.86646842, 0.86802605, 0.87184933, 0.8799207 ,\n",
       "                     0.88586803, 0.88728406, 0.90555084, 0.91107335, 0.91560464,\n",
       "                     0.91772869, 0.92155197, 0.93372982, 0.95808553, 0.96077598,\n",
       "                     0.96233362, 0.96374965, 0.96672331, 0.96927216, 0.97210422,\n",
       "                     0.97394506, 0.97635231, 0.98116681, 0.98399887, 0.98612291,\n",
       "                     0.98739734, 0.99136222, 0.99235344, 0.99391107, 0.99490229,\n",
       "                     0.99589351, 1.        ]), tpr=array([0.        , 0.0499211 , 0.05336394, 0.05738058, 0.06082341,\n",
       "                     0.06412279, 0.06570076, 0.07129537, 0.07932865, 0.08391909,\n",
       "                     0.08721848, 0.10070291, 0.10156362, 0.10730168, 0.11131832,\n",
       "                     0.11648257, 0.1243724 , 0.12781523, 0.13183187, 0.14718118,\n",
       "                     0.14847224, 0.15550136, 0.1592311 , 0.18763449, 0.19064697,\n",
       "                     0.19423325, 0.21029981, 0.21474681, 0.23196098, 0.239277  ,\n",
       "                     0.24702338, 0.25060967, 0.2587864 , 0.26122508, 0.26983216,\n",
       "                     0.30512122, 0.30698609, 0.31387175, 0.32161813, 0.32706929,\n",
       "                     0.3332377 , 0.33926266, 0.3429924 , 0.35375126, 0.35690719,\n",
       "                     0.36981782, 0.37526897, 0.39535217, 0.39994262, 0.43078468,\n",
       "                     0.47812366, 0.4824272 , 0.49304261, 0.49763305, 0.49935447,\n",
       "                     0.5178597 , 0.5223067 , 0.52503228, 0.54812796, 0.55587434,\n",
       "                     0.56060823, 0.57280161, 0.58341701, 0.58585569, 0.59905322,\n",
       "                     0.61956678, 0.62401377, 0.62932147, 0.66633195, 0.67809496,\n",
       "                     0.67995983, 0.69143595, 0.69272701, 0.69674365, 0.69946923,\n",
       "                     0.70119065, 0.70362932, 0.7214173 , 0.72858987, 0.73547554,\n",
       "                     0.73934873, 0.75570219, 0.76473964, 0.77951513, 0.82183331,\n",
       "                     0.82412853, 0.82699756, 0.82943624, 0.83488739, 0.84521589,\n",
       "                     0.85540095, 0.85726582, 0.85984794, 0.86831158, 0.88437814,\n",
       "                     0.88796442, 0.89025965, 0.89183761, 0.89786257, 0.90646966,\n",
       "                     0.90976904, 0.91091665, 0.93444269, 0.93702482, 0.94132836,\n",
       "                     0.94304978, 0.94677952, 0.95667766, 0.97460909, 0.97618706,\n",
       "                     0.97762158, 0.97833883, 0.98092096, 0.98378999, 0.98594176,\n",
       "                     0.98751972, 0.9902453 , 0.99196672, 0.99325778, 0.99411849,\n",
       "                     0.99483575, 0.99727442, 0.99756133, 0.99842203, 0.9997131 ,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.08219945e-02, -6.89928715e-02,\n",
       "                     -8.00427077e-02, -8.33816089e-02, -8.70113770e-02, -9.76384696e-02,\n",
       "                     -1.01782694e-01, -1.17783036e-01, -1.22602322e-01, -1.29534052e-01,\n",
       "                     -1.54150680e-01, -1.61268148e-01, -1.64303051e-01, -1.77681177e-01,\n",
       "                     -1.82321557e-01, -1.89242000e-01, -1.94156014e-01, -1.94705616e-01,\n",
       "                     -2.00670695e-01, -2.02524264e-01, -2.07639365e-01, -2.12991180e-01,\n",
       "                     -2.13574100e-01, -2.15111380e-01, -2.23143551e-01, -2.29574442e-01,\n",
       "                     -2.29788094e-01, -2.42561637e-01, -2.45122458e-01, -2.46860078e-01,\n",
       "                     -2.47408173e-01, -2.57829109e-01, -2.62364264e-01, -2.62989460e-01,\n",
       "                     -2.68263987e-01, -2.71933715e-01, -2.73695830e-01, -2.74436846e-01,\n",
       "                     -2.81851152e-01, -2.87682072e-01, -2.97251523e-01, -2.97632403e-01,\n",
       "                     -3.10154928e-01, -3.12374685e-01, -3.13657559e-01, -3.15852949e-01,\n",
       "                     -3.18453731e-01, -3.26455458e-01, -3.29957556e-01, -3.36472237e-01,\n",
       "                     -3.40325806e-01, -3.40926587e-01, -3.48306694e-01, -3.49673748e-01,\n",
       "                     -3.50202429e-01, -3.51397887e-01, -3.56674944e-01, -3.67724780e-01,\n",
       "                     -3.74693449e-01, -3.77630309e-01, -3.78066134e-01, -3.85662481e-01,\n",
       "                     -3.90866309e-01, -3.93741644e-01, -3.94654192e-01, -3.96415273e-01,\n",
       "                     -4.05465108e-01, -4.13562318e-01, -4.30782916e-01, -4.38254931e-01,\n",
       "                     -4.41832752e-01, -4.51985124e-01, -4.56758402e-01, -4.59532329e-01,\n",
       "                     -4.62623522e-01, -4.62922163e-01, -4.70003629e-01, -4.85507816e-01,\n",
       "                     -4.88352768e-01, -4.89548225e-01, -5.10825624e-01, -5.12765489e-01,\n",
       "                     -5.19600570e-01, -5.23248144e-01, -5.30628251e-01, -5.34082486e-01,\n",
       "                     -5.52068582e-01, -5.59615788e-01, -5.65633860e-01, -5.70544858e-01,\n",
       "                     -5.75364145e-01, -5.76422906e-01, -5.79818495e-01, -5.87786665e-01,\n",
       "                     -5.94707108e-01, -5.97837001e-01, -6.06135804e-01, -6.24154309e-01,\n",
       "                     -6.25705900e-01, -6.28608659e-01, -6.30233355e-01, -6.35988767e-01,\n",
       "                     -6.41853886e-01, -6.50587566e-01, -6.53926467e-01, -6.56242624e-01,\n",
       "                     -6.93147181e-01, -7.37598943e-01, -7.41937345e-01, -7.88457360e-01,\n",
       "                     -7.98507696e-01, -8.10930216e-01, -8.18310324e-01, -8.20980552e-01,\n",
       "                     -8.62223511e-01, -9.16290732e-01, -9.38269639e-01, -9.80829253e-01,\n",
       "                     -1.02961942e+00, -1.09861229e+00, -1.25276297e+00, -1.29928298e+00,\n",
       "                     -1.38629436e+00, -1.79175947e+00, -3.45387764e+01]), auc_score=0.5190596630024594, privacy_risk=0.5155514708526049, accuracy=0.5155514708526049, tpr_ind=0.7214173002438674, tnr_ind=0.3096856414613424, test_train_ratio=1.013054081193516, dataset_size=[6971, 7062]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.02667618, 0.03095578, 0.03252496, 0.03466476,\n",
       "                     0.03880171, 0.04022825, 0.04407989, 0.0510699 , 0.05406562,\n",
       "                     0.05606277, 0.06005706, 0.0639087 , 0.06904422, 0.07289586,\n",
       "                     0.07874465, 0.08231098, 0.10313837, 0.11198288, 0.11740371,\n",
       "                     0.13081312, 0.13223966, 0.17018545, 0.17546362, 0.1767475 ,\n",
       "                     0.17945792, 0.18259629, 0.2232525 , 0.22710414, 0.22924394,\n",
       "                     0.24108417, 0.24721826, 0.27589158, 0.27803138, 0.28516405,\n",
       "                     0.28815977, 0.29671897, 0.30627675, 0.3192582 , 0.32268188,\n",
       "                     0.32767475, 0.3360913 , 0.33708987, 0.33980029, 0.35592011,\n",
       "                     0.38388017, 0.39101284, 0.39500713, 0.45649073, 0.4871612 ,\n",
       "                     0.49001427, 0.49129815, 0.50713267, 0.51440799, 0.51783167,\n",
       "                     0.53323823, 0.54008559, 0.56875892, 0.5700428 , 0.57318117,\n",
       "                     0.58059914, 0.59101284, 0.60299572, 0.61112696, 0.6553495 ,\n",
       "                     0.65677603, 0.66619116, 0.69914408, 0.7042796 , 0.70770328,\n",
       "                     0.7125535 , 0.71940086, 0.73166904, 0.74793153, 0.75292439,\n",
       "                     0.76005706, 0.76148359, 0.78031384, 0.78159772, 0.78345221,\n",
       "                     0.79258203, 0.79828816, 0.80313837, 0.80542083, 0.80927247,\n",
       "                     0.82724679, 0.83880171, 0.8403709 , 0.84607703, 0.85064194,\n",
       "                     0.85335235, 0.85820257, 0.86205421, 0.86718973, 0.88174037,\n",
       "                     0.88473609, 0.89443652, 0.89657632, 0.89771755, 0.90256776,\n",
       "                     0.90584879, 0.90998573, 0.91326676, 0.91569187, 0.91740371,\n",
       "                     0.94022825, 0.94422254, 0.94564907, 0.95178317, 0.95306705,\n",
       "                     0.95378031, 0.95592011, 0.96048502, 0.96476462, 0.96690442,\n",
       "                     0.96961484, 0.97132668, 0.97232525, 0.97417974, 0.97617689,\n",
       "                     0.97631954, 0.9764622 , 0.97917261, 0.98131241, 0.98487874,\n",
       "                     0.98644793, 0.98773181, 0.98830243, 0.98958631, 0.99029957,\n",
       "                     0.99215407, 0.99372325, 0.99415121, 0.99486448, 1.        ]), tpr=array([0.        , 0.0318952 , 0.03616688, 0.04029617, 0.04271679,\n",
       "                     0.04627652, 0.04770041, 0.05225687, 0.05994589, 0.06307846,\n",
       "                     0.06706536, 0.07190659, 0.07461199, 0.08087712, 0.08614552,\n",
       "                     0.0931226 , 0.09483127, 0.11291471, 0.12188523, 0.12758081,\n",
       "                     0.14196212, 0.14452513, 0.18183113, 0.19094404, 0.19336466,\n",
       "                     0.19806351, 0.20091129, 0.24120746, 0.24590631, 0.24789976,\n",
       "                     0.25857895, 0.26626798, 0.29688167, 0.29972946, 0.30613698,\n",
       "                     0.30884238, 0.3178129 , 0.3257867 , 0.33860174, 0.34187669,\n",
       "                     0.34629076, 0.35412217, 0.35682757, 0.3591058 , 0.37790118,\n",
       "                     0.40652143, 0.41278656, 0.41606151, 0.47543785, 0.50576677,\n",
       "                     0.50861455, 0.51032322, 0.5252741 , 0.5319664 , 0.5359533 ,\n",
       "                     0.55531824, 0.56201054, 0.59319379, 0.59476007, 0.59689591,\n",
       "                     0.60316104, 0.61583369, 0.62978784, 0.63719208, 0.68147515,\n",
       "                     0.68361099, 0.6928663 , 0.72732451, 0.73173857, 0.73430158,\n",
       "                     0.74042432, 0.74526556, 0.7566567 , 0.77431297, 0.77858465,\n",
       "                     0.78470739, 0.78712801, 0.80991029, 0.81133419, 0.81389719,\n",
       "                     0.82130144, 0.82471878, 0.82856329, 0.83012957, 0.83610992,\n",
       "                     0.85248469, 0.86814752, 0.86942902, 0.87512459, 0.87911149,\n",
       "                     0.88181689, 0.88665812, 0.89007547, 0.89520148, 0.90844369,\n",
       "                     0.91057952, 0.92111633, 0.92353695, 0.92439129, 0.92894774,\n",
       "                     0.9307988 , 0.93578243, 0.93791827, 0.9401965 , 0.94176278,\n",
       "                     0.96041578, 0.96397551, 0.96596896, 0.96952869, 0.97109497,\n",
       "                     0.9720917 , 0.97465471, 0.97892638, 0.98177417, 0.98376762,\n",
       "                     0.98547629, 0.9867578 , 0.98732735, 0.98860886, 0.98960558,\n",
       "                     0.99031753, 0.99117186, 0.99231098, 0.99373487, 0.99629788,\n",
       "                     0.99700982, 0.99743699, 0.99772177, 0.99829133, 0.99857611,\n",
       "                     0.99928805, 0.99971522, 0.99985761, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.27898228e-02, -3.39015517e-02,\n",
       "                     -5.71584138e-02, -7.69610411e-02, -9.53101798e-02, -1.17783036e-01,\n",
       "                     -1.21889818e-01, -1.27833372e-01, -1.33531393e-01, -1.37201122e-01,\n",
       "                     -1.46603474e-01, -1.47635999e-01, -1.50282203e-01, -1.51230970e-01,\n",
       "                     -1.54150680e-01, -1.59759219e-01, -1.74353387e-01, -1.82321557e-01,\n",
       "                     -1.97063839e-01, -2.00670695e-01, -2.06207042e-01, -2.10564769e-01,\n",
       "                     -2.11309094e-01, -2.17064505e-01, -2.23143551e-01, -2.26670892e-01,\n",
       "                     -2.41162057e-01, -2.51314428e-01, -2.57222865e-01, -2.59511195e-01,\n",
       "                     -2.60573754e-01, -2.62364264e-01, -2.70874954e-01, -2.74436846e-01,\n",
       "                     -2.75705881e-01, -2.78713402e-01, -2.87682072e-01, -2.98492989e-01,\n",
       "                     -3.03682414e-01, -3.10154928e-01, -3.13657559e-01, -3.18453731e-01,\n",
       "                     -3.21204764e-01, -3.24316206e-01, -3.26684230e-01, -3.30241687e-01,\n",
       "                     -3.31664535e-01, -3.35801321e-01, -3.36472237e-01, -3.48306694e-01,\n",
       "                     -3.49985956e-01, -3.54545018e-01, -3.56674944e-01, -3.65459773e-01,\n",
       "                     -3.69360103e-01, -3.69830044e-01, -3.74693449e-01, -3.82992252e-01,\n",
       "                     -3.90197636e-01, -4.01712758e-01, -4.05465108e-01, -4.18204134e-01,\n",
       "                     -4.19302476e-01, -4.27444015e-01, -4.30782916e-01, -4.35318071e-01,\n",
       "                     -4.37213806e-01, -4.41832752e-01, -4.43492504e-01, -4.43931389e-01,\n",
       "                     -4.46287103e-01, -4.47576593e-01, -4.48950220e-01, -4.58307589e-01,\n",
       "                     -4.62623522e-01, -4.66089730e-01, -4.70003629e-01, -4.76924072e-01,\n",
       "                     -4.79573080e-01, -4.85507816e-01, -4.88352768e-01, -4.92476485e-01,\n",
       "                     -4.96436886e-01, -5.07341300e-01, -5.09005787e-01, -5.10825624e-01,\n",
       "                     -5.15813165e-01, -5.17943092e-01, -5.21296924e-01, -5.34082486e-01,\n",
       "                     -5.59615788e-01, -5.75364145e-01, -5.79388295e-01, -5.87786665e-01,\n",
       "                     -5.93774707e-01, -6.00773860e-01, -6.06135804e-01, -6.11801541e-01,\n",
       "                     -6.13104473e-01, -6.19039208e-01, -6.24154309e-01, -6.28608659e-01,\n",
       "                     -6.46627165e-01, -6.93147181e-01, -7.12949808e-01, -7.28238500e-01,\n",
       "                     -7.32367894e-01, -7.37598943e-01, -7.62140052e-01, -7.73189888e-01,\n",
       "                     -7.88457360e-01, -8.10930216e-01, -8.26678573e-01, -8.47297860e-01,\n",
       "                     -8.93817876e-01, -9.16290732e-01, -9.38269639e-01, -9.44461609e-01,\n",
       "                     -9.55511445e-01, -9.80829253e-01, -1.01160091e+00, -1.06471074e+00,\n",
       "                     -1.09861229e+00, -1.16315081e+00, -1.20397280e+00, -1.25276297e+00,\n",
       "                     -1.32175584e+00, -1.38629436e+00, -1.60943791e+00, -1.67397643e+00,\n",
       "                     -1.79175947e+00, -1.94591015e+00, -3.45387764e+01]), auc_score=0.5201407622763031, privacy_risk=0.5152224919019899, accuracy=0.5152224919019899, tpr_ind=0.8138971949309411, tnr_ind=0.21654778887303852, test_train_ratio=0.9981489391997722, dataset_size=[7023, 7010]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.02994866, 0.03137479, 0.0337992 , 0.03822019,\n",
       "                     0.04150029, 0.04249857, 0.04420993, 0.04634912, 0.04806047,\n",
       "                     0.05775813, 0.05918426, 0.07415859, 0.076583  , 0.09355391,\n",
       "                     0.09740445, 0.09768967, 0.10382202, 0.10952653, 0.11309184,\n",
       "                     0.12221905, 0.13918996, 0.1644324 , 0.17170565, 0.17327439,\n",
       "                     0.18924701, 0.20250998, 0.2060753 , 0.21520251, 0.21677125,\n",
       "                     0.25213919, 0.2522818 , 0.2567028 , 0.2601255 , 0.26312037,\n",
       "                     0.27738163, 0.28166001, 0.28422704, 0.28879064, 0.2973474 ,\n",
       "                     0.326583  , 0.33471192, 0.34512265, 0.35339418, 0.35767256,\n",
       "                     0.36979464, 0.37763833, 0.37992014, 0.38377068, 0.38648032,\n",
       "                     0.47375927, 0.48060468, 0.48573873, 0.49087279, 0.49529378,\n",
       "                     0.50328009, 0.50955505, 0.51968055, 0.54948659, 0.55704507,\n",
       "                     0.55946948, 0.56332002, 0.56816885, 0.57972048, 0.58628066,\n",
       "                     0.60096977, 0.60439247, 0.61751284, 0.62036509, 0.63077581,\n",
       "                     0.63976041, 0.65815744, 0.67840844, 0.6982316 , 0.69894467,\n",
       "                     0.71363377, 0.71548774, 0.72290359, 0.72703936, 0.74572162,\n",
       "                     0.74914432, 0.75541928, 0.76041072, 0.7646891 , 0.76754136,\n",
       "                     0.77338848, 0.78123217, 0.78565317, 0.80077011, 0.81003993,\n",
       "                     0.81332002, 0.82059327, 0.8220194 , 0.82800913, 0.83043354,\n",
       "                     0.83585282, 0.83713634, 0.84055904, 0.85154022, 0.85239589,\n",
       "                     0.85539076, 0.86779806, 0.87564176, 0.87692527, 0.88804906,\n",
       "                     0.89318311, 0.89703366, 0.90173987, 0.90501997, 0.90687393,\n",
       "                     0.91300627, 0.92156303, 0.93168853, 0.93625214, 0.93853394,\n",
       "                     0.94566458, 0.94609241, 0.94994295, 0.95507701, 0.95864233,\n",
       "                     0.96292071, 0.96776954, 0.9696235 , 0.9707644 , 0.97432972,\n",
       "                     0.9751854 , 0.97703936, 0.97803765, 0.97832288, 0.979749  ,\n",
       "                     0.98046207, 0.98602396, 0.9875927 , 0.98816315, 0.98844837,\n",
       "                     0.98901882, 0.99044495, 0.99172847, 0.9932972 , 0.99372504,\n",
       "                     0.99401027, 1.        ]), tpr=array([0.        , 0.03731662, 0.04002279, 0.0424441 , 0.04643213,\n",
       "                     0.05013531, 0.05312634, 0.05569007, 0.06053269, 0.06281157,\n",
       "                     0.07463324, 0.07676969, 0.09143997, 0.095428  , 0.11707734,\n",
       "                     0.12078052, 0.12163509, 0.12904145, 0.13388406, 0.13744481,\n",
       "                     0.14442387, 0.16407919, 0.18772255, 0.19455918, 0.19698049,\n",
       "                     0.20979917, 0.22575132, 0.23130608, 0.23942458, 0.24099131,\n",
       "                     0.27246831, 0.27346532, 0.27930494, 0.28315055, 0.28457485,\n",
       "                     0.29910269, 0.30423017, 0.30650904, 0.30921521, 0.317761  ,\n",
       "                     0.34325595, 0.35151688, 0.36575986, 0.37345108, 0.38057257,\n",
       "                     0.39210939, 0.40350377, 0.4050705 , 0.40777667, 0.41162228,\n",
       "                     0.49893178, 0.50505626, 0.51075345, 0.51630822, 0.52143569,\n",
       "                     0.53211793, 0.53809999, 0.54792765, 0.57698334, 0.58339268,\n",
       "                     0.58709586, 0.59307791, 0.59692352, 0.60618146, 0.61558183,\n",
       "                     0.62953995, 0.63224612, 0.64734368, 0.65004985, 0.66187153,\n",
       "                     0.67283863, 0.68978778, 0.71058254, 0.73066515, 0.73194702,\n",
       "                     0.74846888, 0.75074776, 0.75972084, 0.76484831, 0.77980345,\n",
       "                     0.78350662, 0.78763709, 0.79219484, 0.79760718, 0.80188007,\n",
       "                     0.80800456, 0.8158382 , 0.82082324, 0.83307221, 0.841618  ,\n",
       "                     0.84475146, 0.8511608 , 0.85301239, 0.85728529, 0.8607036 ,\n",
       "                     0.86469164, 0.86725538, 0.86939182, 0.87793762, 0.87921948,\n",
       "                     0.88278023, 0.89332004, 0.90101125, 0.90286284, 0.9126905 ,\n",
       "                     0.91867255, 0.92209087, 0.92479704, 0.92793049, 0.92963965,\n",
       "                     0.93391255, 0.9427432 , 0.952286  , 0.95727104, 0.95869534,\n",
       "                     0.96481983, 0.96581684, 0.96838057, 0.97336562, 0.9756445 ,\n",
       "                     0.97863552, 0.98205384, 0.98419029, 0.9851873 , 0.98703888,\n",
       "                     0.98789346, 0.98946019, 0.9904572 , 0.99088449, 0.99230879,\n",
       "                     0.9933058 , 0.99558467, 0.99658168, 0.99686654, 0.99757869,\n",
       "                     0.99800598, 0.99886056, 0.99928785, 0.99971514, 0.99985757,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.12932944e-02, -5.71584138e-02,\n",
       "                     -6.89928715e-02, -7.41079722e-02, -9.09717782e-02, -1.05360516e-01,\n",
       "                     -1.11225635e-01, -1.17783036e-01, -1.24454174e-01, -1.25163143e-01,\n",
       "                     -1.27444947e-01, -1.33531393e-01, -1.40905453e-01, -1.43100844e-01,\n",
       "                     -1.54150680e-01, -1.59630146e-01, -1.62518929e-01, -1.82321557e-01,\n",
       "                     -1.85717146e-01, -1.90740127e-01, -2.06132205e-01, -2.06336433e-01,\n",
       "                     -2.11309094e-01, -2.18689201e-01, -2.23143551e-01, -2.28258652e-01,\n",
       "                     -2.33614851e-01, -2.41162057e-01, -2.47284196e-01, -2.51314428e-01,\n",
       "                     -2.56719847e-01, -2.59511195e-01, -2.62364264e-01, -2.65376315e-01,\n",
       "                     -2.66628663e-01, -2.71933715e-01, -2.74436846e-01, -2.75103290e-01,\n",
       "                     -2.76445999e-01, -2.83362411e-01, -2.85178942e-01, -2.87682072e-01,\n",
       "                     -2.92669614e-01, -3.06031211e-01, -3.09321248e-01, -3.10154928e-01,\n",
       "                     -3.13657559e-01, -3.15081047e-01, -3.16226724e-01, -3.16337328e-01,\n",
       "                     -3.18453731e-01, -3.25422400e-01, -3.28504067e-01, -3.36472237e-01,\n",
       "                     -3.39867826e-01, -3.40604474e-01, -3.48306694e-01, -3.52220594e-01,\n",
       "                     -3.52821375e-01, -3.56674944e-01, -3.67724780e-01, -3.68907512e-01,\n",
       "                     -3.74693449e-01, -3.84845821e-01, -3.87765531e-01, -4.05465108e-01,\n",
       "                     -4.22856851e-01, -4.25346479e-01, -4.26879203e-01, -4.30362660e-01,\n",
       "                     -4.36928378e-01, -4.40311839e-01, -4.41832752e-01, -4.44906840e-01,\n",
       "                     -4.46287103e-01, -4.51985124e-01, -4.59532329e-01, -4.70003629e-01,\n",
       "                     -4.79573080e-01, -4.82851772e-01, -4.85507816e-01, -4.89548225e-01,\n",
       "                     -4.90622916e-01, -5.01479761e-01, -5.03526321e-01, -5.05094949e-01,\n",
       "                     -5.08497334e-01, -5.10825624e-01, -5.19875459e-01, -5.24070851e-01,\n",
       "                     -5.26093096e-01, -5.30628251e-01, -5.35518236e-01, -5.38996501e-01,\n",
       "                     -5.43615447e-01, -5.50046337e-01, -5.59615788e-01, -5.75364145e-01,\n",
       "                     -5.87786665e-01, -5.93774707e-01, -6.06135804e-01, -6.13104473e-01,\n",
       "                     -6.17923759e-01, -6.19039208e-01, -6.28608659e-01, -6.39079959e-01,\n",
       "                     -6.46627165e-01, -6.50587566e-01, -6.59245629e-01, -6.93147181e-01,\n",
       "                     -7.00582159e-01, -7.07331816e-01, -7.41937345e-01, -7.48409859e-01,\n",
       "                     -7.62140052e-01, -7.73189888e-01, -7.88457360e-01, -8.10930216e-01,\n",
       "                     -8.47297860e-01, -8.64997437e-01, -8.75468737e-01, -8.87303195e-01,\n",
       "                     -9.00786545e-01, -9.16290732e-01, -9.34309237e-01, -9.44461609e-01,\n",
       "                     -9.80829253e-01, -9.93251773e-01, -9.98528830e-01, -1.07755888e+00,\n",
       "                     -1.09861229e+00, -1.25276297e+00, -1.28093385e+00, -1.29928298e+00,\n",
       "                     -1.38629436e+00, -1.54044504e+00, -1.60943791e+00, -1.94591015e+00,\n",
       "                     -2.39789527e+00, -3.45387764e+01]), auc_score=0.5243208724409446, privacy_risk=0.5189044755554866, accuracy=0.5189044755554866, tpr_ind=0.7648483122062384, tnr_ind=0.27296063890473476, test_train_ratio=0.9987181313203247, dataset_size=[7021, 7012]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.02233286, 0.02716927, 0.03086771, 0.0428165 ,\n",
       "                     0.04537696, 0.05106686, 0.05163585, 0.05320057, 0.056899  ,\n",
       "                     0.05917496, 0.0601707 , 0.08662873, 0.08876245, 0.09459459,\n",
       "                     0.09843528, 0.11849218, 0.12389758, 0.12674253, 0.14438122,\n",
       "                     0.15675676, 0.15775249, 0.15960171, 0.16571835, 0.16614509,\n",
       "                     0.17339972, 0.17667141, 0.18051209, 0.18990043, 0.1916074 ,\n",
       "                     0.19630156, 0.21465149, 0.2227596 , 0.22389758, 0.25376956,\n",
       "                     0.25547653, 0.30910384, 0.31180654, 0.32076814, 0.32674253,\n",
       "                     0.32887624, 0.36628734, 0.37780939, 0.39089616, 0.40199147,\n",
       "                     0.42475107, 0.42702703, 0.43328592, 0.43698435, 0.44566145,\n",
       "                     0.45049787, 0.45192034, 0.47581792, 0.48136558, 0.48421053,\n",
       "                     0.48477952, 0.51678521, 0.52204836, 0.5230441 , 0.54694168,\n",
       "                     0.55476529, 0.56116643, 0.56756757, 0.57240398, 0.57809388,\n",
       "                     0.58520626, 0.59331437, 0.6514936 , 0.66386913, 0.66671408,\n",
       "                     0.67083926, 0.67140825, 0.67382646, 0.67866287, 0.6859175 ,\n",
       "                     0.7086771 , 0.71223329, 0.72503556, 0.72674253, 0.73271693,\n",
       "                     0.74210526, 0.75192034, 0.79601707, 0.79928876, 0.80526316,\n",
       "                     0.81308677, 0.8173542 , 0.81906117, 0.83214794, 0.83399716,\n",
       "                     0.83627312, 0.84025605, 0.84694168, 0.86472262, 0.86614509,\n",
       "                     0.86970128, 0.87069701, 0.8742532 , 0.87652916, 0.87965861,\n",
       "                     0.88762447, 0.88876245, 0.89089616, 0.89388336, 0.90512091,\n",
       "                     0.90981508, 0.91678521, 0.93869132, 0.94068279, 0.94480797,\n",
       "                     0.94665718, 0.94793741, 0.95078236, 0.95490754, 0.95803698,\n",
       "                     0.96614509, 0.96941679, 0.96998578, 0.97169275, 0.97354196,\n",
       "                     0.97482219, 0.97553343, 0.97738265, 0.97809388, 0.98008535,\n",
       "                     0.98051209, 0.98648649, 0.98890469, 0.98947368, 0.99004267,\n",
       "                     0.9913229 , 0.99146515, 0.99317212, 1.        ]), tpr=array([0.        , 0.03398543, 0.03741254, 0.04069684, 0.05354848,\n",
       "                     0.05668999, 0.06582893, 0.06725689, 0.06982722, 0.07325432,\n",
       "                     0.07653863, 0.07910895, 0.10309867, 0.10638298, 0.11109524,\n",
       "                     0.11495074, 0.1373697 , 0.14322433, 0.14679423, 0.16650007,\n",
       "                     0.18163644, 0.18292161, 0.18606312, 0.19063259, 0.19334571,\n",
       "                     0.20134228, 0.20505498, 0.20976724, 0.21862059, 0.22219049,\n",
       "                     0.22675996, 0.24203913, 0.25174925, 0.25317721, 0.28116521,\n",
       "                     0.28344995, 0.33871198, 0.3414251 , 0.35113523, 0.35713266,\n",
       "                     0.36084535, 0.40282736, 0.41439383, 0.42867343, 0.43738398,\n",
       "                     0.46280166, 0.46508639, 0.47136941, 0.47493931, 0.48522062,\n",
       "                     0.48979009, 0.49221762, 0.51635014, 0.52149079, 0.52420391,\n",
       "                     0.52520348, 0.55561902, 0.56004569, 0.56161645, 0.58703413,\n",
       "                     0.59631586, 0.60088533, 0.60802513, 0.61416536, 0.61873483,\n",
       "                     0.62773097, 0.63658432, 0.69241754, 0.70327003, 0.70698272,\n",
       "                     0.71040982, 0.71198058, 0.7148365 , 0.71897758, 0.72668856,\n",
       "                     0.74825075, 0.75224904, 0.76581465, 0.7675282 , 0.774668  ,\n",
       "                     0.78494931, 0.79380266, 0.83721262, 0.84063973, 0.8450664 ,\n",
       "                     0.85277738, 0.85677567, 0.85863201, 0.87076967, 0.87219763,\n",
       "                     0.87533914, 0.88190775, 0.88590604, 0.90061402, 0.90261317,\n",
       "                     0.90532629, 0.90604027, 0.908325  , 0.90989576, 0.91075253,\n",
       "                     0.91603598, 0.91703556, 0.91832072, 0.92089105, 0.93088676,\n",
       "                     0.93588462, 0.94188205, 0.95916036, 0.96187348, 0.96872769,\n",
       "                     0.97044124, 0.97201199, 0.97315436, 0.97629587, 0.9788662 ,\n",
       "                     0.98315008, 0.98500643, 0.98557761, 0.98643439, 0.98800514,\n",
       "                     0.98900471, 0.9895759 , 0.99086106, 0.99171784, 0.99271741,\n",
       "                     0.99385977, 0.99728688, 0.99842924, 0.99871484, 0.99914322,\n",
       "                     0.99957161, 0.99971441, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -8.00427077e-02, -8.33816089e-02,\n",
       "                     -8.51578083e-02, -8.70113770e-02, -8.96121587e-02, -9.53101798e-02,\n",
       "                     -1.05360516e-01, -1.17783036e-01, -1.22602322e-01, -1.54150680e-01,\n",
       "                     -1.59239749e-01, -1.60342650e-01, -1.67054085e-01, -1.69899037e-01,\n",
       "                     -1.74862812e-01, -1.78248231e-01, -1.82321557e-01, -1.84734103e-01,\n",
       "                     -1.88591170e-01, -2.00670695e-01, -2.04794413e-01, -2.23143551e-01,\n",
       "                     -2.33614851e-01, -2.37328186e-01, -2.38411023e-01, -2.41162057e-01,\n",
       "                     -2.42313467e-01, -2.46860078e-01, -2.47836164e-01, -2.54424851e-01,\n",
       "                     -2.57829109e-01, -2.62364264e-01, -2.63148886e-01, -2.71933715e-01,\n",
       "                     -2.72056755e-01, -2.74436846e-01, -2.80301965e-01, -2.87682072e-01,\n",
       "                     -2.97251523e-01, -2.97834444e-01, -3.06031211e-01, -3.07484700e-01,\n",
       "                     -3.07966744e-01, -3.11277893e-01, -3.18453731e-01, -3.26684230e-01,\n",
       "                     -3.36472237e-01, -3.38454398e-01, -3.40926587e-01, -3.44840486e-01,\n",
       "                     -3.46564837e-01, -3.48306694e-01, -3.51397887e-01, -3.56674944e-01,\n",
       "                     -3.72049111e-01, -3.72675285e-01, -3.74693449e-01, -3.75044511e-01,\n",
       "                     -3.79489622e-01, -3.84411699e-01, -3.92042088e-01, -3.97682968e-01,\n",
       "                     -4.05465108e-01, -4.10742165e-01, -4.16160397e-01, -4.19853846e-01,\n",
       "                     -4.22856851e-01, -4.30782916e-01, -4.32864082e-01, -4.35318071e-01,\n",
       "                     -4.38254931e-01, -4.39366660e-01, -4.41832752e-01, -4.42305677e-01,\n",
       "                     -4.51985124e-01, -4.56758402e-01, -4.59532329e-01, -4.70003629e-01,\n",
       "                     -4.76924072e-01, -4.78035801e-01, -4.81451015e-01, -4.85507816e-01,\n",
       "                     -4.97838428e-01, -5.10825624e-01, -5.17943092e-01, -5.26093096e-01,\n",
       "                     -5.27162043e-01, -5.30628251e-01, -5.46543706e-01, -5.53385238e-01,\n",
       "                     -5.59615788e-01, -5.74757165e-01, -5.79818495e-01, -5.81921545e-01,\n",
       "                     -5.87786665e-01, -5.94707108e-01, -5.97837001e-01, -6.06135804e-01,\n",
       "                     -6.08589793e-01, -6.19039208e-01, -6.35988767e-01, -6.39079959e-01,\n",
       "                     -6.41853886e-01, -6.49344558e-01, -6.81170990e-01, -6.93147181e-01,\n",
       "                     -7.19122667e-01, -7.23918839e-01, -7.33969175e-01, -7.37598943e-01,\n",
       "                     -7.53771802e-01, -7.59105148e-01, -7.73189888e-01, -7.88457360e-01,\n",
       "                     -8.02346473e-01, -8.10930216e-01, -8.47297860e-01, -8.60201265e-01,\n",
       "                     -8.87303195e-01, -9.16290732e-01, -9.38269639e-01, -9.80829253e-01,\n",
       "                     -9.98528830e-01, -1.01160091e+00, -1.09861229e+00, -1.25276297e+00,\n",
       "                     -1.38629436e+00, -1.46633707e+00, -1.60943791e+00, -1.79175947e+00,\n",
       "                     -2.56494936e+00, -3.45387764e+01]), auc_score=0.5315815270391129, privacy_risk=0.521634977003353, accuracy=0.521634977003353, tpr_ind=0.6365843210052835, tnr_ind=0.40668563300142246, test_train_ratio=1.0038554905040697, dataset_size=[7003, 7030]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.02874626, 0.0448271 , 0.04881173, 0.05151558,\n",
       "                     0.05507329, 0.05763484, 0.05905792, 0.06460794, 0.06788103,\n",
       "                     0.0707272 , 0.08780418, 0.09235805, 0.0932119 , 0.09648499,\n",
       "                     0.10260424, 0.10459656, 0.11626583, 0.13931977, 0.1451544 ,\n",
       "                     0.17290451, 0.17603529, 0.17973531, 0.18898534, 0.19481998,\n",
       "                     0.19567383, 0.20563541, 0.21887007, 0.23338551, 0.24092785,\n",
       "                     0.24590864, 0.25345097, 0.27949338, 0.28219724, 0.29173189,\n",
       "                     0.29827807, 0.30411271, 0.32844742, 0.3315782 , 0.34509748,\n",
       "                     0.35278213, 0.3608937 , 0.36217447, 0.36715526, 0.39817845,\n",
       "                     0.40031308, 0.41610929, 0.42735164, 0.46719795, 0.46748257,\n",
       "                     0.47374413, 0.47886723, 0.48455956, 0.48640956, 0.49950192,\n",
       "                     0.51686353, 0.52412125, 0.54987904, 0.55144443, 0.55884446,\n",
       "                     0.56012523, 0.57577914, 0.58004838, 0.58232532, 0.58972535,\n",
       "                     0.60182155, 0.60722926, 0.61221005, 0.61434467, 0.64237939,\n",
       "                     0.6442294 , 0.66216024, 0.6648641 , 0.6667141 , 0.66913334,\n",
       "                     0.69674114, 0.70542194, 0.71666429, 0.71865661, 0.72434894,\n",
       "                     0.72634126, 0.73416821, 0.73786822, 0.74469902, 0.75508752,\n",
       "                     0.76262986, 0.76376832, 0.79706845, 0.79991462, 0.81030312,\n",
       "                     0.82254163, 0.82524548, 0.84573787, 0.8548456 , 0.8566956 ,\n",
       "                     0.85897253, 0.86665718, 0.86808026, 0.87163797, 0.88231109,\n",
       "                     0.88658033, 0.88956881, 0.89725345, 0.89910346, 0.899815  ,\n",
       "                     0.90693041, 0.91575352, 0.91959584, 0.92187278, 0.92827665,\n",
       "                     0.93140743, 0.9326882 , 0.93368436, 0.94193824, 0.94350363,\n",
       "                     0.94677672, 0.95175751, 0.95531521, 0.95645368, 0.95759214,\n",
       "                     0.95972677, 0.96015369, 0.96257293, 0.96470756, 0.9654191 ,\n",
       "                     0.96684218, 0.96798065, 0.9689768 , 0.96983065, 0.97153835,\n",
       "                     0.97651914, 0.97836915, 0.98021915, 0.98249609, 0.9844884 ,\n",
       "                     0.98491533, 0.98719226, 0.98904227, 0.98946919, 0.99074996,\n",
       "                     1.        ]), tpr=array([0.        , 0.03625464, 0.05266914, 0.0582358 , 0.06294605,\n",
       "                     0.06737083, 0.07022552, 0.07265201, 0.08178704, 0.08492721,\n",
       "                     0.08678276, 0.10505281, 0.110334  , 0.11204682, 0.11618613,\n",
       "                     0.12175278, 0.12460748, 0.13516985, 0.15558093, 0.16214673,\n",
       "                     0.18969455, 0.1915501 , 0.19568941, 0.20667999, 0.21181844,\n",
       "                     0.21395946, 0.22323723, 0.23722524, 0.25363974, 0.26206109,\n",
       "                     0.26791322, 0.27462175, 0.30402512, 0.30673708, 0.31558664,\n",
       "                     0.32258065, 0.32757636, 0.35226948, 0.35555238, 0.36782758,\n",
       "                     0.37796175, 0.38438481, 0.3863831 , 0.39152155, 0.422495  ,\n",
       "                     0.42592064, 0.44262061, 0.45246931, 0.49443334, 0.49514702,\n",
       "                     0.50485298, 0.51056238, 0.51570083, 0.51769912, 0.532829  ,\n",
       "                     0.54653154, 0.5549529 , 0.58392806, 0.58549814, 0.59035113,\n",
       "                     0.59220668, 0.60305452, 0.60690836, 0.61104767, 0.6201827 ,\n",
       "                     0.63202969, 0.63759635, 0.64230659, 0.64530403, 0.67656295,\n",
       "                     0.6784185 , 0.69683129, 0.69940051, 0.70268341, 0.70568084,\n",
       "                     0.72937482, 0.74165001, 0.7502141 , 0.75264059, 0.75892092,\n",
       "                     0.76106195, 0.76762775, 0.77205253, 0.77833286, 0.79089352,\n",
       "                     0.79745932, 0.7990294 , 0.83385669, 0.83671139, 0.84570368,\n",
       "                     0.85740794, 0.85926349, 0.87796175, 0.88424208, 0.8868113 ,\n",
       "                     0.88952327, 0.89737368, 0.89851556, 0.9023694 , 0.91250357,\n",
       "                     0.91721382, 0.91906937, 0.92706252, 0.92934627, 0.93063089,\n",
       "                     0.93748216, 0.9450471 , 0.94704539, 0.94932915, 0.95546674,\n",
       "                     0.9577505 , 0.95960605, 0.9610334 , 0.96916928, 0.9704539 ,\n",
       "                     0.97259492, 0.97644876, 0.97901798, 0.97973166, 0.98058807,\n",
       "                     0.98272909, 0.98372823, 0.98515558, 0.98644019, 0.98743934,\n",
       "                     0.98815301, 0.98858122, 0.98943762, 0.9905795 , 0.99186412,\n",
       "                     0.99471881, 0.99586069, 0.9967171 , 0.99757351, 0.99800171,\n",
       "                     0.99857265, 0.99914359, 0.9995718 , 0.99971453, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -6.72522270e-02, -7.41079722e-02,\n",
       "                     -8.70113770e-02, -9.23733201e-02, -9.53101798e-02, -1.11225635e-01,\n",
       "                     -1.17783036e-01, -1.27833372e-01, -1.43100844e-01, -1.45182010e-01,\n",
       "                     -1.50282203e-01, -1.54150680e-01, -1.59064695e-01, -1.65079750e-01,\n",
       "                     -1.82321557e-01, -1.84571277e-01, -1.96210669e-01, -1.96710294e-01,\n",
       "                     -1.96895325e-01, -2.07639365e-01, -2.16223108e-01, -2.20542770e-01,\n",
       "                     -2.23143551e-01, -2.36388778e-01, -2.44453338e-01, -2.51314428e-01,\n",
       "                     -2.52280145e-01, -2.53195896e-01, -2.56719847e-01, -2.60726262e-01,\n",
       "                     -2.70545790e-01, -2.74436846e-01, -2.75705881e-01, -2.82566972e-01,\n",
       "                     -2.87682072e-01, -2.93445777e-01, -2.98492989e-01, -2.99242895e-01,\n",
       "                     -3.01668314e-01, -3.04211374e-01, -3.05381650e-01, -3.08301360e-01,\n",
       "                     -3.10462101e-01, -3.18453731e-01, -3.19230430e-01, -3.22287602e-01,\n",
       "                     -3.32577392e-01, -3.36472237e-01, -3.44840486e-01, -3.46870944e-01,\n",
       "                     -3.48306694e-01, -3.56674944e-01, -3.60441427e-01, -3.62905494e-01,\n",
       "                     -3.65113813e-01, -3.73769377e-01, -3.74693449e-01, -3.76477571e-01,\n",
       "                     -3.79489622e-01, -3.87765531e-01, -3.93042588e-01, -3.93904286e-01,\n",
       "                     -4.05465108e-01, -4.09473130e-01, -4.13975798e-01, -4.15515444e-01,\n",
       "                     -4.21213465e-01, -4.25058802e-01, -4.30782916e-01, -4.33492420e-01,\n",
       "                     -4.41832752e-01, -4.48024723e-01, -4.51985124e-01, -4.52532619e-01,\n",
       "                     -4.58307589e-01, -4.59532329e-01, -4.62623522e-01, -4.64305608e-01,\n",
       "                     -4.70003629e-01, -4.75423697e-01, -4.78035801e-01, -4.78490243e-01,\n",
       "                     -4.85507816e-01, -4.88846717e-01, -4.92476485e-01, -4.94296322e-01,\n",
       "                     -5.00775288e-01, -5.10825624e-01, -5.13261679e-01, -5.26093096e-01,\n",
       "                     -5.31974448e-01, -5.33298480e-01, -5.43615447e-01, -5.52068582e-01,\n",
       "                     -5.57015006e-01, -5.59615788e-01, -5.75364145e-01, -5.81507209e-01,\n",
       "                     -5.97837001e-01, -6.13104473e-01, -6.19039208e-01, -6.28608659e-01,\n",
       "                     -6.35988767e-01, -6.39658496e-01, -6.44828603e-01, -6.56779536e-01,\n",
       "                     -6.61398482e-01, -6.93147181e-01, -7.23918839e-01, -7.30887509e-01,\n",
       "                     -7.41937345e-01, -7.44440475e-01, -7.47214402e-01, -7.57685702e-01,\n",
       "                     -7.64606145e-01, -7.73189888e-01, -7.88457360e-01, -8.47297860e-01,\n",
       "                     -8.75468737e-01, -8.87303195e-01, -9.16290732e-01, -9.38269639e-01,\n",
       "                     -9.44461609e-01, -9.55511445e-01, -9.80829253e-01, -1.04145387e+00,\n",
       "                     -1.05605267e+00, -1.06087196e+00, -1.09861229e+00, -1.17865500e+00,\n",
       "                     -1.20397280e+00, -1.25276297e+00, -1.38629436e+00, -1.44691898e+00,\n",
       "                     -1.50407740e+00, -1.54044504e+00, -1.60943791e+00, -1.79175947e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.525549955534261, privacy_risk=0.5183983875903639, accuracy=0.5183983875903639, tpr_ind=0.8367113902369397, tnr_ind=0.20008538494378825, test_train_ratio=1.0029974307736227, dataset_size=[7006, 7027]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.03065463, 0.03308982, 0.04025211, 0.0461252 ,\n",
       "                     0.05171179, 0.05629566, 0.06130927, 0.06603638, 0.07821229,\n",
       "                     0.08050423, 0.0850881 , 0.08809626, 0.09210715, 0.09554505,\n",
       "                     0.10070191, 0.10342358, 0.10571551, 0.10743446, 0.11015614,\n",
       "                     0.11459676, 0.11789142, 0.12605644, 0.1293511 , 0.15184071,\n",
       "                     0.1611517 , 0.16530583, 0.18707922, 0.19151984, 0.20040109,\n",
       "                     0.20340925, 0.20684716, 0.20985532, 0.21572841, 0.21916631,\n",
       "                     0.22417992, 0.2266151 , 0.23277467, 0.23563959, 0.26486177,\n",
       "                     0.26801318, 0.28477296, 0.29694886, 0.32889271, 0.34063888,\n",
       "                     0.34379029, 0.34751468, 0.35052285, 0.35209855, 0.35439049,\n",
       "                     0.38432889, 0.39392637, 0.39979946, 0.44434895, 0.46497636,\n",
       "                     0.46784128, 0.47099269, 0.48932818, 0.49391205, 0.5027933 ,\n",
       "                     0.52958029, 0.54046698, 0.54490761, 0.54848876, 0.55364561,\n",
       "                     0.55951869, 0.56839994, 0.58114883, 0.59346798, 0.63486607,\n",
       "                     0.64145538, 0.64331758, 0.64560951, 0.65090961, 0.6549205 ,\n",
       "                     0.65635296, 0.65979086, 0.70161868, 0.70477009, 0.70863773,\n",
       "                     0.77911474, 0.77968772, 0.78455809, 0.80303681, 0.81034236,\n",
       "                     0.81378026, 0.81621544, 0.81779115, 0.82323449, 0.82652915,\n",
       "                     0.82767512, 0.83569689, 0.85489185, 0.85718378, 0.85976221,\n",
       "                     0.86663802, 0.8690732 , 0.87179487, 0.8865492 , 0.89013035,\n",
       "                     0.89457098, 0.89944134, 0.90474144, 0.91734708, 0.92150122,\n",
       "                     0.92293368, 0.92450938, 0.92780404, 0.94384759, 0.94585303,\n",
       "                     0.95487752, 0.96003438, 0.96318579, 0.96418851, 0.96562097,\n",
       "                     0.96705343, 0.9681994 , 0.97650766, 0.97794012, 0.98166452,\n",
       "                     0.98195101, 0.98352672, 0.98553216, 0.98682137, 0.98710786,\n",
       "                     0.98768085, 0.98982954, 0.99140524, 0.99197823, 0.99255121,\n",
       "                     0.99384042, 0.99484315, 0.99555938, 1.        ]), tpr=array([0.        , 0.03672717, 0.03970505, 0.04849688, 0.05388542,\n",
       "                     0.05899036, 0.06310267, 0.06990925, 0.075865  , 0.08876914,\n",
       "                     0.09415769, 0.09926262, 0.10280771, 0.10862167, 0.11315939,\n",
       "                     0.11939875, 0.12237663, 0.12620533, 0.1287578 , 0.1327283 ,\n",
       "                     0.13882587, 0.14307998, 0.15357345, 0.1591038 , 0.18377765,\n",
       "                     0.19469654, 0.19781622, 0.21766875, 0.22220647, 0.23000567,\n",
       "                     0.23440159, 0.23766307, 0.2423426 , 0.25      , 0.25595576,\n",
       "                     0.26077708, 0.26403857, 0.27098695, 0.2765173 , 0.30431083,\n",
       "                     0.30657969, 0.32231991, 0.33210437, 0.36613727, 0.38003403,\n",
       "                     0.38499716, 0.38910947, 0.39152014, 0.39307998, 0.3976177 ,\n",
       "                     0.42753829, 0.43718094, 0.44498015, 0.484827  , 0.50269427,\n",
       "                     0.50609756, 0.50992626, 0.52864436, 0.53389109, 0.54126489,\n",
       "                     0.56168463, 0.56976744, 0.57302893, 0.57714124, 0.58210437,\n",
       "                     0.58905275, 0.60153148, 0.61557005, 0.62691435, 0.66605218,\n",
       "                     0.67370959, 0.67612025, 0.68009075, 0.68647192, 0.69001702,\n",
       "                     0.69228588, 0.69554736, 0.7386557 , 0.74064095, 0.74305162,\n",
       "                     0.8105502 , 0.81125922, 0.81593874, 0.83267158, 0.83933636,\n",
       "                     0.84245604, 0.8445831 , 0.84727737, 0.85408395, 0.85748724,\n",
       "                     0.85847986, 0.86783891, 0.88400454, 0.88513897, 0.88698242,\n",
       "                     0.89719229, 0.90059558, 0.90343165, 0.91591038, 0.91860465,\n",
       "                     0.92229155, 0.92697107, 0.93108338, 0.94242768, 0.94512195,\n",
       "                     0.94653999, 0.94824163, 0.95022689, 0.96157119, 0.96440726,\n",
       "                     0.97220647, 0.97759501, 0.97958026, 0.98043108, 0.9809983 ,\n",
       "                     0.98255814, 0.98355077, 0.98780488, 0.9885139 , 0.9924844 ,\n",
       "                     0.99290981, 0.99404424, 0.99532048, 0.99574589, 0.9963131 ,\n",
       "                     0.99659671, 0.99787294, 0.99858196, 0.99900737, 0.99929098,\n",
       "                     0.99943279, 0.99971639, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.65200156e-02, -4.72528849e-02,\n",
       "                     -5.12932944e-02, -5.40672213e-02, -6.66913745e-02, -8.00427077e-02,\n",
       "                     -9.09717782e-02, -9.43106795e-02, -1.00083459e-01, -1.05360516e-01,\n",
       "                     -1.13328685e-01, -1.15069330e-01, -1.17783036e-01, -1.27833372e-01,\n",
       "                     -1.33531393e-01, -1.38150338e-01, -1.54150680e-01, -1.64303051e-01,\n",
       "                     -1.70625517e-01, -1.82321557e-01, -1.84571277e-01, -1.86585956e-01,\n",
       "                     -1.97530975e-01, -1.99489360e-01, -2.04794413e-01, -2.11649172e-01,\n",
       "                     -2.23143551e-01, -2.26773319e-01, -2.29574442e-01, -2.31801614e-01,\n",
       "                     -2.41162057e-01, -2.45122458e-01, -2.51314428e-01, -2.57829109e-01,\n",
       "                     -2.65703166e-01, -2.67062785e-01, -2.68263987e-01, -2.70961426e-01,\n",
       "                     -2.71933715e-01, -2.74076420e-01, -2.76753002e-01, -2.87682072e-01,\n",
       "                     -2.90229845e-01, -2.94799540e-01, -2.96265816e-01, -3.02280872e-01,\n",
       "                     -3.10154928e-01, -3.18453731e-01, -3.21465134e-01, -3.34369186e-01,\n",
       "                     -3.36472237e-01, -3.40531096e-01, -3.45501643e-01, -3.48306694e-01,\n",
       "                     -3.67724780e-01, -3.74693449e-01, -3.78066134e-01, -3.79489622e-01,\n",
       "                     -3.82044834e-01, -3.87765531e-01, -3.90866309e-01, -3.93904286e-01,\n",
       "                     -3.95895657e-01, -3.98639143e-01, -4.05465108e-01, -4.08826456e-01,\n",
       "                     -4.13763911e-01, -4.17470054e-01, -4.17735201e-01, -4.24883194e-01,\n",
       "                     -4.28995606e-01, -4.41832752e-01, -4.44685821e-01, -4.46287103e-01,\n",
       "                     -4.48024723e-01, -4.50488789e-01, -4.51985124e-01, -4.62623522e-01,\n",
       "                     -4.66583923e-01, -4.70003629e-01, -4.73784352e-01, -4.76339448e-01,\n",
       "                     -4.80585739e-01, -4.92476485e-01, -5.10825624e-01, -5.21296924e-01,\n",
       "                     -5.23248144e-01, -5.35518236e-01, -5.38996501e-01, -5.46543706e-01,\n",
       "                     -5.57106376e-01, -5.59615788e-01, -5.70544858e-01, -5.75364145e-01,\n",
       "                     -5.83146285e-01, -5.87786665e-01, -5.97837001e-01, -6.10909082e-01,\n",
       "                     -6.13104473e-01, -6.14366303e-01, -6.21688217e-01, -6.21919671e-01,\n",
       "                     -6.39079959e-01, -6.41853886e-01, -6.50587566e-01, -6.56779536e-01,\n",
       "                     -6.93147181e-01, -7.17839793e-01, -7.20054633e-01, -7.31861693e-01,\n",
       "                     -7.62140052e-01, -7.73189888e-01, -8.10930216e-01, -8.20980552e-01,\n",
       "                     -8.26678573e-01, -8.47297860e-01, -8.75468737e-01, -9.16290732e-01,\n",
       "                     -9.80829253e-01, -1.01160091e+00, -1.06087196e+00, -1.09861229e+00,\n",
       "                     -1.17865500e+00, -1.25276297e+00, -1.26851133e+00, -1.38629436e+00,\n",
       "                     -1.46633707e+00, -1.50407740e+00, -1.60943791e+00, -1.79175947e+00,\n",
       "                     -2.01490302e+00, -3.45387764e+01]), auc_score=0.5302910346639769, privacy_risk=0.522590345905258, accuracy=0.522590345905258, tpr_ind=0.4449801474758934, tnr_ind=0.6002005443346226, test_train_ratio=0.9899319342030629, dataset_size=[7052, 6981]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.03507516, 0.04266285, 0.05025054, 0.05268432,\n",
       "                     0.05640659, 0.06571224, 0.06657122, 0.07730852, 0.07845383,\n",
       "                     0.08045812, 0.09005011, 0.09319971, 0.09420186, 0.09778096,\n",
       "                     0.09878311, 0.11009306, 0.12627058, 0.15490336, 0.15719399,\n",
       "                     0.16034359, 0.16463851, 0.16678597, 0.18568361, 0.19742305,\n",
       "                     0.20114531, 0.2297781 , 0.23507516, 0.24352183, 0.2555476 ,\n",
       "                     0.26399427, 0.2781675 , 0.35289907, 0.36120258, 0.36521117,\n",
       "                     0.39556192, 0.39871152, 0.40386543, 0.4067287 , 0.42004295,\n",
       "                     0.44294918, 0.45297065, 0.4591267 , 0.49835361, 0.50221904,\n",
       "                     0.54874732, 0.54931997, 0.55232641, 0.56034359, 0.56635648,\n",
       "                     0.57122405, 0.582534  , 0.59040802, 0.59527559, 0.59856836,\n",
       "                     0.60429492, 0.61102362, 0.65583393, 0.67401575, 0.68503937,\n",
       "                     0.68790265, 0.69076593, 0.69620616, 0.69906943, 0.70207588,\n",
       "                     0.70350752, 0.70765927, 0.70823193, 0.7269864 , 0.7444524 ,\n",
       "                     0.74659986, 0.75189692, 0.75690766, 0.7599141 , 0.76921976,\n",
       "                     0.77780959, 0.78339298, 0.79413028, 0.80730136, 0.82219041,\n",
       "                     0.83593414, 0.83979957, 0.85096636, 0.85268432, 0.88575519,\n",
       "                     0.88904796, 0.89191124, 0.90050107, 0.90107373, 0.90221904,\n",
       "                     0.90408017, 0.90923407, 0.91352899, 0.91424481, 0.91653543,\n",
       "                     0.91782391, 0.92168933, 0.92841804, 0.9305655 , 0.9408733 ,\n",
       "                     0.94330709, 0.94588404, 0.95218325, 0.95390122, 0.95461704,\n",
       "                     0.9567645 , 0.96048676, 0.96292054, 0.96392269, 0.96406586,\n",
       "                     0.96836077, 0.96907659, 0.9706514 , 0.97365784, 0.97408733,\n",
       "                     0.97823908, 0.98181818, 0.98210451, 0.98382248, 0.98511095,\n",
       "                     0.98725841, 0.98754474, 0.98940587, 0.99083751, 0.99141016,\n",
       "                     1.        ]), tpr=array([0.        , 0.0422815 , 0.04965948, 0.05732123, 0.06101022,\n",
       "                     0.06597616, 0.07505675, 0.07761067, 0.08740068, 0.08938706,\n",
       "                     0.09123156, 0.10215664, 0.10570375, 0.10740636, 0.1123723 ,\n",
       "                     0.11393303, 0.12840522, 0.14103292, 0.17125426, 0.17395006,\n",
       "                     0.17707151, 0.18260499, 0.18771283, 0.20871169, 0.21949489,\n",
       "                     0.223042  , 0.25695233, 0.263479  , 0.27369467, 0.28249149,\n",
       "                     0.29171396, 0.30746311, 0.37471623, 0.3822361 , 0.38791146,\n",
       "                     0.42451759, 0.42778093, 0.43388195, 0.43657775, 0.45246879,\n",
       "                     0.47105562, 0.48566969, 0.49347333, 0.53249149, 0.53901816,\n",
       "                     0.59151532, 0.59279228, 0.59562997, 0.60471056, 0.611521  ,\n",
       "                     0.61861521, 0.62755392, 0.63521566, 0.64103292, 0.64344495,\n",
       "                     0.64883655, 0.6546538 , 0.69778661, 0.71282633, 0.7238933 ,\n",
       "                     0.72744041, 0.72985244, 0.73595346, 0.73779796, 0.74120318,\n",
       "                     0.7427639 , 0.74716232, 0.74815551, 0.76844495, 0.78461975,\n",
       "                     0.78802497, 0.79341657, 0.79809875, 0.80008513, 0.8057605 ,\n",
       "                     0.81640182, 0.82150965, 0.83200908, 0.84591373, 0.86180477,\n",
       "                     0.87372304, 0.87585131, 0.88408059, 0.88635074, 0.91756527,\n",
       "                     0.9199773 , 0.92253121, 0.92849035, 0.92919977, 0.9307605 ,\n",
       "                     0.93331442, 0.93785471, 0.94168558, 0.94267877, 0.9442395 ,\n",
       "                     0.94594211, 0.95048241, 0.95530647, 0.95786039, 0.96509648,\n",
       "                     0.96708286, 0.96892736, 0.97502838, 0.97673099, 0.97744041,\n",
       "                     0.98013621, 0.98240636, 0.98396708, 0.98496027, 0.98538593,\n",
       "                     0.98765607, 0.98864926, 0.9900681 , 0.99177072, 0.99248014,\n",
       "                     0.99446652, 0.99531782, 0.99602724, 0.99687855, 0.99758797,\n",
       "                     0.99829739, 0.99858116, 0.99957435, 0.99985812, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.77403280e-02, -5.40672213e-02,\n",
       "                     -7.41079722e-02, -8.22380982e-02, -1.03796794e-01, -1.05360516e-01,\n",
       "                     -1.22602322e-01, -1.33531393e-01, -1.43100844e-01, -1.44830948e-01,\n",
       "                     -1.48420005e-01, -1.54150680e-01, -1.58224005e-01, -1.67054085e-01,\n",
       "                     -1.70817732e-01, -1.74802724e-01, -1.79971379e-01, -1.91055237e-01,\n",
       "                     -2.04794413e-01, -2.07639365e-01, -2.23143551e-01, -2.28534400e-01,\n",
       "                     -2.33614851e-01, -2.46860078e-01, -2.60108746e-01, -2.65703166e-01,\n",
       "                     -2.66628663e-01, -2.67314770e-01, -2.68263987e-01, -2.74076420e-01,\n",
       "                     -2.74943047e-01, -2.78203328e-01, -2.81412459e-01, -2.87682072e-01,\n",
       "                     -2.98492989e-01, -2.99242895e-01, -3.13657559e-01, -3.18453731e-01,\n",
       "                     -3.28809364e-01, -3.35084311e-01, -3.36472237e-01, -3.44234242e-01,\n",
       "                     -3.45745873e-01, -3.51798207e-01, -3.67724780e-01, -3.71563556e-01,\n",
       "                     -3.73716410e-01, -3.77294231e-01, -3.78436436e-01, -3.78653851e-01,\n",
       "                     -3.80463806e-01, -3.80772496e-01, -3.85662481e-01, -3.87765531e-01,\n",
       "                     -3.97301797e-01, -4.05465108e-01, -4.11734721e-01, -4.13975798e-01,\n",
       "                     -4.18710335e-01, -4.24883194e-01, -4.28454626e-01, -4.30782916e-01,\n",
       "                     -4.32864082e-01, -4.35318071e-01, -4.37213806e-01, -4.51985124e-01,\n",
       "                     -4.70003629e-01, -4.73287704e-01, -4.85507816e-01, -4.89548225e-01,\n",
       "                     -4.92476485e-01, -4.96436886e-01, -5.00775288e-01, -5.10825624e-01,\n",
       "                     -5.16216472e-01, -5.32216814e-01, -5.33026334e-01, -5.35302370e-01,\n",
       "                     -5.38996501e-01, -5.50046337e-01, -5.54677506e-01, -5.59615788e-01,\n",
       "                     -5.64797147e-01, -5.67984038e-01, -5.75364145e-01, -5.79818495e-01,\n",
       "                     -5.87786665e-01, -5.97837001e-01, -6.06135804e-01, -6.11801541e-01,\n",
       "                     -6.16186139e-01, -6.19039208e-01, -6.46627165e-01, -6.50587566e-01,\n",
       "                     -6.93147181e-01, -7.22134717e-01, -7.47214402e-01, -7.50305594e-01,\n",
       "                     -7.62140052e-01, -7.67255153e-01, -7.71399377e-01, -7.73189888e-01,\n",
       "                     -7.88457360e-01, -7.93230639e-01, -8.10930216e-01, -8.20980552e-01,\n",
       "                     -8.26678573e-01, -8.47297860e-01, -9.16290732e-01, -9.44461609e-01,\n",
       "                     -9.55511445e-01, -9.80829253e-01, -1.02961942e+00, -1.09861229e+00,\n",
       "                     -1.20397280e+00, -1.22377543e+00, -1.25276297e+00, -1.28093385e+00,\n",
       "                     -1.38629436e+00, -1.50407740e+00, -1.60943791e+00, -1.94591015e+00,\n",
       "                     -2.07944154e+00, -3.45387764e+01]), auc_score=0.5289884701041716, privacy_risk=0.5236955792248186, accuracy=0.5236955792248186, tpr_ind=0.6186152099886493, tnr_ind=0.4287759484609878, test_train_ratio=0.9910612939841089, dataset_size=[7048, 6985]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.03857651, 0.04142349, 0.04327402, 0.04469751,\n",
       "                     0.04854093, 0.05096085, 0.05508897, 0.0572242 , 0.0630605 ,\n",
       "                     0.07359431, 0.08512456, 0.08868327, 0.09466192, 0.10419929,\n",
       "                     0.10761566, 0.11245552, 0.11530249, 0.11558719, 0.14562278,\n",
       "                     0.15188612, 0.16014235, 0.16498221, 0.16725979, 0.1772242 ,\n",
       "                     0.18505338, 0.18903915, 0.2005694 , 0.20896797, 0.21252669,\n",
       "                     0.21580071, 0.21765125, 0.23060498, 0.23316726, 0.24882562,\n",
       "                     0.26135231, 0.286121  , 0.29622776, 0.31715302, 0.32782918,\n",
       "                     0.35274021, 0.35686833, 0.36398577, 0.36825623, 0.37053381,\n",
       "                     0.39017794, 0.39743772, 0.40298932, 0.41096085, 0.41295374,\n",
       "                     0.42149466, 0.43046263, 0.44768683, 0.45423488, 0.45964413,\n",
       "                     0.47145907, 0.48227758, 0.4852669 , 0.48797153, 0.49238434,\n",
       "                     0.49480427, 0.50377224, 0.52227758, 0.52939502, 0.53793594,\n",
       "                     0.54149466, 0.54761566, 0.55259786, 0.57309609, 0.58733096,\n",
       "                     0.59957295, 0.61537367, 0.61992883, 0.6233452 , 0.64213523,\n",
       "                     0.64498221, 0.64811388, 0.65409253, 0.65893238, 0.66177936,\n",
       "                     0.69580071, 0.70690391, 0.71217082, 0.71686833, 0.71871886,\n",
       "                     0.72441281, 0.74676157, 0.76683274, 0.79074733, 0.83302491,\n",
       "                     0.84284698, 0.85338078, 0.86021352, 0.86391459, 0.86419929,\n",
       "                     0.86604982, 0.8683274 , 0.87487544, 0.87715302, 0.89594306,\n",
       "                     0.89978648, 0.91088968, 0.91174377, 0.91345196, 0.91772242,\n",
       "                     0.92967972, 0.9316726 , 0.93565836, 0.93992883, 0.94220641,\n",
       "                     0.95843416, 0.96142349, 0.96483986, 0.9652669 , 0.96640569,\n",
       "                     0.96768683, 0.97081851, 0.97409253, 0.97508897, 0.97736655,\n",
       "                     0.97879004, 0.97921708, 0.97964413, 0.98035587, 0.9880427 ,\n",
       "                     0.98989324, 0.99217082, 0.99245552, 1.        ]), tpr=array([0.        , 0.04352169, 0.04651826, 0.04894406, 0.05122717,\n",
       "                     0.05507991, 0.05793379, 0.06207192, 0.06478311, 0.06992009,\n",
       "                     0.08290525, 0.09346461, 0.09760274, 0.10459475, 0.11486872,\n",
       "                     0.11800799, 0.12571347, 0.12871005, 0.12942352, 0.15896119,\n",
       "                     0.16652397, 0.17608447, 0.18079338, 0.18407534, 0.19392123,\n",
       "                     0.20176941, 0.20804795, 0.21846461, 0.22930936, 0.23444635,\n",
       "                     0.23901256, 0.24101027, 0.25371005, 0.25513699, 0.26726598,\n",
       "                     0.27953767, 0.3005137 , 0.31050228, 0.33476027, 0.34760274,\n",
       "                     0.37485731, 0.37728311, 0.38484589, 0.39041096, 0.39397831,\n",
       "                     0.4159532 , 0.42565639, 0.43222032, 0.44063927, 0.44406393,\n",
       "                     0.45419521, 0.46418379, 0.47859589, 0.48373288, 0.4902968 ,\n",
       "                     0.50456621, 0.51612443, 0.51855023, 0.52026256, 0.52497146,\n",
       "                     0.52696918, 0.53581621, 0.55379566, 0.56178653, 0.57163242,\n",
       "                     0.57519977, 0.58105023, 0.58590183, 0.6081621 , 0.61800799,\n",
       "                     0.63113584, 0.64355023, 0.64740297, 0.65097032, 0.67422945,\n",
       "                     0.67679795, 0.68107877, 0.68735731, 0.69335046, 0.69606164,\n",
       "                     0.730879  , 0.74329338, 0.74643265, 0.75028539, 0.7524258 ,\n",
       "                     0.75870434, 0.77910959, 0.79794521, 0.81949201, 0.85744863,\n",
       "                     0.8630137 , 0.87186073, 0.88027968, 0.88313356, 0.88413242,\n",
       "                     0.88627283, 0.88855594, 0.89554795, 0.89768836, 0.91552511,\n",
       "                     0.91894977, 0.9279395 , 0.92893836, 0.93122146, 0.93478881,\n",
       "                     0.9472032 , 0.94877283, 0.95262557, 0.95690639, 0.96018836,\n",
       "                     0.97417237, 0.97688356, 0.98002283, 0.980879  , 0.98230594,\n",
       "                     0.98344749, 0.98601598, 0.98772831, 0.98915525, 0.99143836,\n",
       "                     0.9928653 , 0.99329338, 0.99386416, 0.99472032, 0.99814498,\n",
       "                     0.99900114, 0.99985731, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.65200156e-02, -5.71584138e-02,\n",
       "                     -6.06246218e-02, -7.14589640e-02, -9.53101798e-02, -9.84400728e-02,\n",
       "                     -1.00083459e-01, -1.05360516e-01, -1.14113307e-01, -1.14775515e-01,\n",
       "                     -1.29211731e-01, -1.33531393e-01, -1.54150680e-01, -1.67054085e-01,\n",
       "                     -1.69899037e-01, -1.74353387e-01, -1.82321557e-01, -1.84734103e-01,\n",
       "                     -1.88591170e-01, -1.89756535e-01, -1.92371893e-01, -1.96710294e-01,\n",
       "                     -2.08544752e-01, -2.12174520e-01, -2.23143551e-01, -2.31329136e-01,\n",
       "                     -2.43977638e-01, -2.45122458e-01, -2.47836164e-01, -2.51314428e-01,\n",
       "                     -2.56295759e-01, -2.62364264e-01, -2.66878945e-01, -2.73040522e-01,\n",
       "                     -2.77425572e-01, -2.84104251e-01, -2.84736562e-01, -2.87682072e-01,\n",
       "                     -2.88990117e-01, -3.02280872e-01, -3.06374205e-01, -3.06730267e-01,\n",
       "                     -3.07484700e-01, -3.10154928e-01, -3.13091788e-01, -3.14493330e-01,\n",
       "                     -3.16911711e-01, -3.18453731e-01, -3.22287602e-01, -3.26215736e-01,\n",
       "                     -3.26521906e-01, -3.28504067e-01, -3.30241687e-01, -3.36472237e-01,\n",
       "                     -3.41749294e-01, -3.44840486e-01, -3.48306694e-01, -3.53640040e-01,\n",
       "                     -3.56674944e-01, -3.61501985e-01, -3.67724780e-01, -3.69097464e-01,\n",
       "                     -3.71063681e-01, -3.79489622e-01, -3.80772496e-01, -3.85662481e-01,\n",
       "                     -4.05465108e-01, -4.10284395e-01, -4.12685356e-01, -4.16893804e-01,\n",
       "                     -4.17735201e-01, -4.18710335e-01, -4.23702696e-01, -4.41832752e-01,\n",
       "                     -4.48950220e-01, -4.49916871e-01, -4.51985124e-01, -4.56758402e-01,\n",
       "                     -4.61256468e-01, -4.61345567e-01, -4.64305608e-01, -4.65363250e-01,\n",
       "                     -4.70003629e-01, -4.92476485e-01, -5.00987175e-01, -5.10825624e-01,\n",
       "                     -5.20054430e-01, -5.23385818e-01, -5.26093096e-01, -5.26825965e-01,\n",
       "                     -5.27632742e-01, -5.30628251e-01, -5.38996501e-01, -5.50046337e-01,\n",
       "                     -5.59615788e-01, -5.62526998e-01, -5.87786665e-01, -5.92221262e-01,\n",
       "                     -6.06135804e-01, -6.10455465e-01, -6.19039208e-01, -6.28608659e-01,\n",
       "                     -6.31271777e-01, -6.40037355e-01, -6.46627165e-01, -6.55406853e-01,\n",
       "                     -6.59245629e-01, -6.71168274e-01, -6.93147181e-01, -7.44440475e-01,\n",
       "                     -7.59105148e-01, -7.73189888e-01, -7.88457360e-01, -8.10930216e-01,\n",
       "                     -8.23200309e-01, -8.47297860e-01, -8.75468737e-01, -9.16290732e-01,\n",
       "                     -9.55511445e-01, -9.80829253e-01, -1.01160091e+00, -1.04145387e+00,\n",
       "                     -1.09861229e+00, -1.29928298e+00, -1.79175947e+00, -2.30258509e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5226743914428249, privacy_risk=0.5181947322023432, accuracy=0.5181947322023432, tpr_ind=0.7432933789954338, tnr_ind=0.2930960854092527, test_train_ratio=1.002425799086758, dataset_size=[7008, 7025]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.04197211, 0.04829668, 0.05059652, 0.05663361,\n",
       "                     0.05749605, 0.06568923, 0.07072014, 0.07503234, 0.09400604,\n",
       "                     0.09544344, 0.09616214, 0.1003306 , 0.13971539, 0.1425902 ,\n",
       "                     0.14776484, 0.15207704, 0.15811413, 0.16831968, 0.1913181 ,\n",
       "                     0.20109242, 0.22667817, 0.23271525, 0.2386086 , 0.24536438,\n",
       "                     0.25298261, 0.25715107, 0.25988213, 0.30472905, 0.31162858,\n",
       "                     0.32111542, 0.33419577, 0.34569498, 0.35978152, 0.37128072,\n",
       "                     0.38737962, 0.39701021, 0.39859135, 0.39945379, 0.39974127,\n",
       "                     0.40577835, 0.41871496, 0.42920799, 0.44588185, 0.44746299,\n",
       "                     0.44875665, 0.4654305 , 0.49949691, 0.50150927, 0.52120167,\n",
       "                     0.53615064, 0.53845048, 0.54764985, 0.55670548, 0.56101768,\n",
       "                     0.57093575, 0.57596665, 0.58387236, 0.58559724, 0.64381199,\n",
       "                     0.64898663, 0.66278568, 0.67356619, 0.67557855, 0.69656461,\n",
       "                     0.7026017 , 0.70562024, 0.70777634, 0.72401897, 0.73781803,\n",
       "                     0.73954291, 0.74917349, 0.7506109 , 0.76009774, 0.76254133,\n",
       "                     0.77245939, 0.7767716 , 0.78683341, 0.79387667, 0.80408222,\n",
       "                     0.80710076, 0.8094006 , 0.81126923, 0.83656749, 0.84662929,\n",
       "                     0.8516602 , 0.85927842, 0.86143453, 0.86761535, 0.87437114,\n",
       "                     0.87839586, 0.88802645, 0.89765704, 0.9047003 , 0.9068564 ,\n",
       "                     0.91217479, 0.91274975, 0.91447463, 0.91706195, 0.92137416,\n",
       "                     0.92281156, 0.92496766, 0.9265488 , 0.93172344, 0.93287336,\n",
       "                     0.93905419, 0.94466005, 0.94566624, 0.94897226, 0.95400316,\n",
       "                     0.95845911, 0.97369556, 0.97427052, 0.97498922, 0.97556418,\n",
       "                     0.97700158, 0.9803076 , 0.98476355, 0.98605721, 0.98648843,\n",
       "                     0.98648843, 0.98778209, 0.98993819, 0.99094437, 0.99166307,\n",
       "                     0.99209429, 0.99223803, 0.99281299, 0.99367543, 1.        ]), tpr=array([0.        , 0.04564726, 0.05483324, 0.05780102, 0.0651498 ,\n",
       "                     0.06656303, 0.07843414, 0.0830978 , 0.08592425, 0.10161108,\n",
       "                     0.10344828, 0.10429621, 0.10924251, 0.15390051, 0.1575749 ,\n",
       "                     0.1625212 , 0.16661956, 0.17396834, 0.18159977, 0.20279819,\n",
       "                     0.21368005, 0.2419446 , 0.24844545, 0.25678349, 0.26314302,\n",
       "                     0.27190503, 0.27868852, 0.28236292, 0.32306388, 0.32956473,\n",
       "                     0.34101187, 0.35528547, 0.36899378, 0.38355003, 0.39344262,\n",
       "                     0.41011871, 0.41986998, 0.42269644, 0.42425099, 0.42538157,\n",
       "                     0.43131713, 0.44460147, 0.45463539, 0.47215941, 0.47357264,\n",
       "                     0.47597513, 0.49448841, 0.53010175, 0.53208027, 0.54720181,\n",
       "                     0.56147541, 0.56373657, 0.57433578, 0.5812606 , 0.58592425,\n",
       "                     0.59581685, 0.59977388, 0.60698135, 0.60994912, 0.66775014,\n",
       "                     0.67410967, 0.69163369, 0.69841718, 0.70138496, 0.72131148,\n",
       "                     0.727671  , 0.73162804, 0.73544375, 0.75169587, 0.76568683,\n",
       "                     0.76837196, 0.77487281, 0.7772753 , 0.7897117 , 0.79423403,\n",
       "                     0.80342001, 0.80850763, 0.81543245, 0.82278123, 0.8343697 ,\n",
       "                     0.83776145, 0.84157716, 0.84313171, 0.8691351 , 0.88114754,\n",
       "                     0.88665913, 0.8933013 , 0.8951385 , 0.90107405, 0.90799887,\n",
       "                     0.91195591, 0.91972866, 0.92707744, 0.93188242, 0.93329565,\n",
       "                     0.93555681, 0.93640475, 0.93824194, 0.94036179, 0.94361221,\n",
       "                     0.94587337, 0.94827586, 0.95025438, 0.95703787, 0.95887507,\n",
       "                     0.96311475, 0.96693047, 0.96806105, 0.96975692, 0.97201809,\n",
       "                     0.97696439, 0.98615037, 0.98671566, 0.98770492, 0.98855285,\n",
       "                     0.99010741, 0.99236857, 0.99547767, 0.99618428, 0.99660825,\n",
       "                     0.9968909 , 0.99759751, 0.99844545, 0.99929339, 0.99943471,\n",
       "                     0.99957603, 0.99971735, 0.99985868, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.52674721e-02, -4.65200156e-02,\n",
       "                     -5.60894667e-02, -9.53101798e-02, -1.12477983e-01, -1.14410351e-01,\n",
       "                     -1.39761942e-01, -1.42500063e-01, -1.43100844e-01, -1.54150680e-01,\n",
       "                     -1.58224005e-01, -1.68513584e-01, -1.75890666e-01, -1.82321557e-01,\n",
       "                     -1.88052232e-01, -2.23143551e-01, -2.30523659e-01, -2.36388778e-01,\n",
       "                     -2.41162057e-01, -2.41510428e-01, -2.44196961e-01, -2.53195896e-01,\n",
       "                     -2.53780521e-01, -2.54892250e-01, -2.55933374e-01, -2.68263987e-01,\n",
       "                     -2.71933715e-01, -2.82232468e-01, -2.87682072e-01, -2.90154262e-01,\n",
       "                     -2.90229845e-01, -2.92524697e-01, -2.94799540e-01, -2.98219578e-01,\n",
       "                     -2.98492989e-01, -3.00104592e-01, -3.10154928e-01, -3.18453731e-01,\n",
       "                     -3.22773392e-01, -3.31902541e-01, -3.32439973e-01, -3.34202088e-01,\n",
       "                     -3.36472237e-01, -3.44840486e-01, -3.50549351e-01, -3.51103899e-01,\n",
       "                     -3.56674944e-01, -3.57609087e-01, -3.61613226e-01, -3.62905494e-01,\n",
       "                     -3.64643114e-01, -3.70859579e-01, -3.74693449e-01, -3.76477571e-01,\n",
       "                     -3.81367557e-01, -3.85662481e-01, -3.89464767e-01, -3.96459726e-01,\n",
       "                     -3.98030130e-01, -4.05465108e-01, -4.19258430e-01, -4.21213465e-01,\n",
       "                     -4.21878138e-01, -4.27444015e-01, -4.28995606e-01, -4.41832752e-01,\n",
       "                     -4.53564903e-01, -4.54736157e-01, -4.56758402e-01, -4.61818045e-01,\n",
       "                     -4.62623522e-01, -4.64305608e-01, -4.66089730e-01, -4.70003629e-01,\n",
       "                     -4.76924072e-01, -4.77627554e-01, -4.79573080e-01, -4.83629881e-01,\n",
       "                     -4.85507816e-01, -4.88352768e-01, -4.92476485e-01, -4.98797048e-01,\n",
       "                     -5.06108634e-01, -5.10825624e-01, -5.19300251e-01, -5.26093096e-01,\n",
       "                     -5.38996501e-01, -5.50830958e-01, -5.59615788e-01, -5.77634293e-01,\n",
       "                     -5.81355775e-01, -5.84513340e-01, -5.87786665e-01, -5.94707108e-01,\n",
       "                     -6.06135804e-01, -6.13104473e-01, -6.24154309e-01, -6.25705900e-01,\n",
       "                     -6.28608659e-01, -6.32522559e-01, -6.56779536e-01, -6.93147181e-01,\n",
       "                     -7.30887509e-01, -7.41937345e-01, -7.47214402e-01, -7.53771802e-01,\n",
       "                     -7.73189888e-01, -7.82759339e-01, -7.88457360e-01, -8.09219352e-01,\n",
       "                     -8.10930216e-01, -8.26678573e-01, -8.47297860e-01, -8.60201265e-01,\n",
       "                     -9.16290732e-01, -1.09861229e+00, -1.16315081e+00, -1.20397280e+00,\n",
       "                     -1.25276297e+00, -1.38629436e+00, -1.42711636e+00, -1.50407740e+00,\n",
       "                     -1.60943791e+00, -1.79175947e+00, -1.94591015e+00, -2.07944154e+00,\n",
       "                     -2.30258509e+00, -3.45387764e+01]), auc_score=0.5216242848644743, privacy_risk=0.5174994655451525, accuracy=0.5174994655451525, tpr_ind=0.8866591294516676, tnr_ind=0.14833980163863733, test_train_ratio=0.9831825890333522, dataset_size=[7076, 6957]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.03639196, 0.03979043, 0.04163127, 0.04602096,\n",
       "                     0.05041065, 0.05210988, 0.06145568, 0.06414613, 0.06669499,\n",
       "                     0.0720759 , 0.09940527, 0.10846786, 0.11285755, 0.11399037,\n",
       "                     0.11512319, 0.16156896, 0.16496743, 0.17148117, 0.18790711,\n",
       "                     0.21580289, 0.2259983 , 0.23137921, 0.24214104, 0.24369867,\n",
       "                     0.24723874, 0.26323988, 0.27640895, 0.28221467, 0.30331351,\n",
       "                     0.30982724, 0.32143869, 0.32979326, 0.33333333, 0.33800623,\n",
       "                     0.34041348, 0.35627301, 0.35797225, 0.35981308, 0.41772869,\n",
       "                     0.42849051, 0.43103937, 0.43387142, 0.46601529, 0.46672331,\n",
       "                     0.46941376, 0.47621071, 0.48725573, 0.48966298, 0.49447749,\n",
       "                     0.52973662, 0.5335599 , 0.53964882, 0.54262249, 0.54517134,\n",
       "                     0.55649958, 0.59997168, 0.60280374, 0.63225715, 0.64698386,\n",
       "                     0.66751628, 0.6680827 , 0.67133956, 0.67884452, 0.67955253,\n",
       "                     0.69059756, 0.70150099, 0.70560748, 0.70744831, 0.72868876,\n",
       "                     0.73647692, 0.73803455, 0.77003682, 0.77088643, 0.77343529,\n",
       "                     0.79864061, 0.80260549, 0.80557916, 0.81053526, 0.81704899,\n",
       "                     0.81973945, 0.82172189, 0.82766922, 0.83531577, 0.85230813,\n",
       "                     0.85372416, 0.85952988, 0.8603795 , 0.86193713, 0.8656188 ,\n",
       "                     0.86859247, 0.87057491, 0.87553101, 0.88020391, 0.88091192,\n",
       "                     0.89025772, 0.8990371 , 0.90116114, 0.93188898, 0.93429623,\n",
       "                     0.94010195, 0.94123478, 0.94463325, 0.94604928, 0.94647409,\n",
       "                     0.94873973, 0.95086378, 0.95412065, 0.95596148, 0.95836873,\n",
       "                     0.95978476, 0.96077598, 0.96346644, 0.96445766, 0.96743132,\n",
       "                     0.97309544, 0.97550269, 0.97734353, 0.97805154, 0.97960918,\n",
       "                     0.98286604, 0.98371566, 0.98824696, 0.98824696, 0.99008779,\n",
       "                     0.9905126 , 0.99122062, 0.99221184, 0.99235344, 0.99291985,\n",
       "                     1.        ]), tpr=array([0.        , 0.03729737, 0.04117056, 0.04317888, 0.04676517,\n",
       "                     0.05192942, 0.05522881, 0.06684837, 0.0697174 , 0.07430785,\n",
       "                     0.08033281, 0.10859274, 0.11777363, 0.12207718, 0.1240855 ,\n",
       "                     0.12666762, 0.17831014, 0.18189643, 0.18992971, 0.21044326,\n",
       "                     0.23669488, 0.24501506, 0.24989241, 0.26007746, 0.26165543,\n",
       "                     0.26423756, 0.28130828, 0.293932  , 0.29967006, 0.32247884,\n",
       "                     0.33108593, 0.34528762, 0.353034  , 0.35547267, 0.35991967,\n",
       "                     0.36149763, 0.3784249 , 0.38115048, 0.3834457 , 0.43910486,\n",
       "                     0.44928992, 0.4523024 , 0.45488452, 0.49017358, 0.49160809,\n",
       "                     0.49505093, 0.50394491, 0.51470377, 0.51671209, 0.52331086,\n",
       "                     0.56706355, 0.56964567, 0.57853966, 0.58126524, 0.58427772,\n",
       "                     0.596758  , 0.64352317, 0.64596184, 0.67106584, 0.68612825,\n",
       "                     0.70434658, 0.70721561, 0.71037154, 0.71869172, 0.71969588,\n",
       "                     0.73045474, 0.7409267 , 0.74465643, 0.74809927, 0.76502654,\n",
       "                     0.77435088, 0.77693301, 0.80734471, 0.80849233, 0.81236551,\n",
       "                     0.84220341, 0.84636351, 0.85023669, 0.85468369, 0.86099555,\n",
       "                     0.86300387, 0.8652991 , 0.86945919, 0.87361928, 0.88796442,\n",
       "                     0.88925549, 0.89470664, 0.8954239 , 0.89700186, 0.90030125,\n",
       "                     0.90288337, 0.90474824, 0.90876488, 0.91450294, 0.915794  ,\n",
       "                     0.9252618 , 0.93444269, 0.93702482, 0.95940324, 0.96141156,\n",
       "                     0.96528475, 0.96643236, 0.96858413, 0.96958829, 0.970449  ,\n",
       "                     0.97202697, 0.97274423, 0.97475255, 0.97604361, 0.97719122,\n",
       "                     0.97876919, 0.97977335, 0.98106441, 0.98178167, 0.98335963,\n",
       "                     0.98651556, 0.98780663, 0.98952804, 0.9902453 , 0.99225362,\n",
       "                     0.99411849, 0.9946923 , 0.99713097, 0.99756133, 0.99842203,\n",
       "                     0.99856549, 0.99885239, 0.99956965, 0.9997131 , 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -3.63676442e-02, -6.89928715e-02,\n",
       "                     -7.69610411e-02, -8.00427077e-02, -8.33816089e-02, -9.41872151e-02,\n",
       "                     -9.53101798e-02, -1.17783036e-01, -1.33531393e-01, -1.54875580e-01,\n",
       "                     -1.58605030e-01, -1.82321557e-01, -1.94156014e-01, -2.00670695e-01,\n",
       "                     -2.05205851e-01, -2.15111380e-01, -2.23143551e-01, -2.24541176e-01,\n",
       "                     -2.28593156e-01, -2.30016431e-01, -2.34839591e-01, -2.37129793e-01,\n",
       "                     -2.41162057e-01, -2.45122458e-01, -2.51314428e-01, -2.58861634e-01,\n",
       "                     -2.62364264e-01, -2.68633877e-01, -2.75103290e-01, -2.87682072e-01,\n",
       "                     -3.01475395e-01, -3.02280872e-01, -3.03682414e-01, -3.10154928e-01,\n",
       "                     -3.10719741e-01, -3.13657559e-01, -3.18453731e-01, -3.21261407e-01,\n",
       "                     -3.22287602e-01, -3.22773392e-01, -3.28504067e-01, -3.35310121e-01,\n",
       "                     -3.36472237e-01, -3.48306694e-01, -3.50202429e-01, -3.55340721e-01,\n",
       "                     -3.56674944e-01, -3.61013346e-01, -3.61907134e-01, -3.67724780e-01,\n",
       "                     -3.83725121e-01, -3.87765531e-01, -3.89464767e-01, -3.97860509e-01,\n",
       "                     -4.05465108e-01, -4.24883194e-01, -4.26201007e-01, -4.33635985e-01,\n",
       "                     -4.33927573e-01, -4.38254931e-01, -4.48024723e-01, -4.50416496e-01,\n",
       "                     -4.51985124e-01, -4.53196511e-01, -4.54472687e-01, -4.55475529e-01,\n",
       "                     -4.59532329e-01, -4.65757338e-01, -4.70003629e-01, -4.76924072e-01,\n",
       "                     -4.84055383e-01, -4.85507816e-01, -4.88352768e-01, -4.91407538e-01,\n",
       "                     -5.03905181e-01, -5.10825624e-01, -5.17256514e-01, -5.33298480e-01,\n",
       "                     -5.38996501e-01, -5.59615788e-01, -5.64529803e-01, -5.69094532e-01,\n",
       "                     -5.70979547e-01, -5.75364145e-01, -5.81921545e-01, -5.87786665e-01,\n",
       "                     -5.97837001e-01, -6.02175402e-01, -6.06135804e-01, -6.13104473e-01,\n",
       "                     -6.19039208e-01, -6.28608659e-01, -6.35988767e-01, -6.46627165e-01,\n",
       "                     -6.53301272e-01, -6.64976304e-01, -6.93147181e-01, -7.28238500e-01,\n",
       "                     -7.47214402e-01, -7.53771802e-01, -7.57685702e-01, -7.62140052e-01,\n",
       "                     -7.73189888e-01, -7.80158558e-01, -7.88457360e-01, -7.94929875e-01,\n",
       "                     -7.98507696e-01, -8.10930216e-01, -8.20980552e-01, -8.26678573e-01,\n",
       "                     -8.47297860e-01, -8.75468737e-01, -8.97941593e-01, -9.16290732e-01,\n",
       "                     -9.38269639e-01, -9.49080555e-01, -9.55511445e-01, -9.71860583e-01,\n",
       "                     -9.90398704e-01, -1.01160091e+00, -1.09861229e+00, -1.20397280e+00,\n",
       "                     -1.25276297e+00, -1.38629436e+00, -1.50407740e+00, -1.60943791e+00,\n",
       "                     -1.79175947e+00, -2.39789527e+00, -3.45387764e+01]), auc_score=0.5261211831140387, privacy_risk=0.5223287694161689, accuracy=0.5223287694161689, tpr_ind=0.8502366948787835, tnr_ind=0.19442084395355425, test_train_ratio=1.013054081193516, dataset_size=[6971, 7062]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.02970012, 0.03777393, 0.04108997, 0.04685698,\n",
       "                     0.04743368, 0.04901961, 0.05204729, 0.05449827, 0.05536332,\n",
       "                     0.0578143 , 0.05911188, 0.06127451, 0.06358131, 0.07525952,\n",
       "                     0.0777105 , 0.09198385, 0.09616494, 0.10236448, 0.10596886,\n",
       "                     0.11663783, 0.12456747, 0.12860438, 0.14590542, 0.14850058,\n",
       "                     0.19088812, 0.19694348, 0.19953864, 0.20689158, 0.2266436 ,\n",
       "                     0.24322376, 0.25100923, 0.26427336, 0.26542676, 0.27479815,\n",
       "                     0.27753749, 0.28373702, 0.28604383, 0.29685698, 0.3078143 ,\n",
       "                     0.31459054, 0.31934833, 0.32093426, 0.32670127, 0.33592849,\n",
       "                     0.35683391, 0.3638985 , 0.36908881, 0.37139562, 0.39359862,\n",
       "                     0.40095156, 0.40239331, 0.41219723, 0.42027105, 0.4222895 ,\n",
       "                     0.45472895, 0.45602653, 0.48673587, 0.51239908, 0.51643599,\n",
       "                     0.52623991, 0.54065744, 0.54757785, 0.55089389, 0.55507497,\n",
       "                     0.56358131, 0.57843137, 0.59328143, 0.59731834, 0.60250865,\n",
       "                     0.60697809, 0.6115917 , 0.61894464, 0.62067474, 0.62226067,\n",
       "                     0.62846021, 0.63365052, 0.65253749, 0.65960208, 0.66623414,\n",
       "                     0.66955017, 0.68036332, 0.68699539, 0.69694348, 0.70083622,\n",
       "                     0.70343137, 0.72130911, 0.72217416, 0.7254902 , 0.72678777,\n",
       "                     0.74581892, 0.75821799, 0.76528258, 0.78114187, 0.78575548,\n",
       "                     0.78979239, 0.79512687, 0.79714533, 0.81084198, 0.81372549,\n",
       "                     0.81444637, 0.82035755, 0.82540369, 0.82670127, 0.838812  ,\n",
       "                     0.84126298, 0.85596886, 0.85798731, 0.86245675, 0.87456747,\n",
       "                     0.88177624, 0.8855248 , 0.88811995, 0.89114764, 0.89489619,\n",
       "                     0.90152826, 0.90253749, 0.90556517, 0.91234141, 0.93713956,\n",
       "                     0.94362745, 0.94968281, 0.95862168, 0.96035179, 0.96770473,\n",
       "                     0.96828143, 0.96957901, 0.97188581, 0.97289504, 0.97592272,\n",
       "                     0.97635525, 0.98241061, 0.98385236, 0.98587082, 0.98615917,\n",
       "                     0.9888985 , 0.98961938, 0.99077278, 0.99134948, 0.99207036,\n",
       "                     0.99394464, 0.99423299, 1.        ]), tpr=array([0.        , 0.03917148, 0.04959842, 0.05283923, 0.06087079,\n",
       "                     0.06284345, 0.06453431, 0.06608426, 0.06904326, 0.0704523 ,\n",
       "                     0.07312949, 0.07538397, 0.07749753, 0.08144286, 0.0918698 ,\n",
       "                     0.09454699, 0.11371002, 0.11850077, 0.12596872, 0.12949133,\n",
       "                     0.14287727, 0.15020431, 0.15569959, 0.17148091, 0.17556714,\n",
       "                     0.21628857, 0.22262928, 0.22488375, 0.23192898, 0.25292377,\n",
       "                     0.26870509, 0.27673665, 0.28927716, 0.29223616, 0.30336762,\n",
       "                     0.305763  , 0.30956742, 0.31238552, 0.32267155, 0.33563478,\n",
       "                     0.34296181, 0.35071157, 0.35381147, 0.35987037, 0.37043821,\n",
       "                     0.38875581, 0.39819642, 0.40425532, 0.40707341, 0.43201353,\n",
       "                     0.44018599, 0.44173594, 0.45202198, 0.46033535, 0.46216711,\n",
       "                     0.49133437, 0.49387065, 0.52317881, 0.54656897, 0.55150063,\n",
       "                     0.56080034, 0.57263633, 0.5779907 , 0.58193603, 0.58602226,\n",
       "                     0.59405383, 0.61068057, 0.6237847 , 0.62787093, 0.63350712,\n",
       "                     0.63660702, 0.64153868, 0.65196562, 0.65365647, 0.65577004,\n",
       "                     0.66239256, 0.66859236, 0.68705087, 0.69494152, 0.69959138,\n",
       "                     0.70494575, 0.71128646, 0.71804988, 0.72974496, 0.73256305,\n",
       "                     0.73636748, 0.75369875, 0.75468508, 0.75736227, 0.75905312,\n",
       "                     0.77779343, 0.78836128, 0.79639284, 0.81217416, 0.8165422 ,\n",
       "                     0.82076934, 0.82386924, 0.82654643, 0.84176413, 0.84500493,\n",
       "                     0.84641398, 0.85162745, 0.85571368, 0.85670001, 0.86783148,\n",
       "                     0.87050867, 0.88516274, 0.88657179, 0.89023531, 0.90178949,\n",
       "                     0.90953924, 0.91193462, 0.9144709 , 0.917289  , 0.92067071,\n",
       "                     0.92644779, 0.92799775, 0.92997041, 0.93560659, 0.95364238,\n",
       "                     0.96082852, 0.96618289, 0.97266451, 0.97463717, 0.98125969,\n",
       "                     0.98210511, 0.98280964, 0.9846414 , 0.98633225, 0.98929125,\n",
       "                     0.98999577, 0.99309567, 0.99351839, 0.99506834, 0.99577286,\n",
       "                     0.99732281, 0.99788643, 0.99873186, 0.99915457, 0.99943638,\n",
       "                     0.9998591 , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.34230203e-02, -4.25596144e-02,\n",
       "                     -6.78225963e-02, -6.89928715e-02, -8.00427077e-02, -8.70113770e-02,\n",
       "                     -9.09717782e-02, -9.53101798e-02, -1.00083459e-01, -1.17783036e-01,\n",
       "                     -1.25163143e-01, -1.33531393e-01, -1.38586163e-01, -1.46603474e-01,\n",
       "                     -1.49940147e-01, -1.62518929e-01, -1.72842813e-01, -1.82321557e-01,\n",
       "                     -1.91055237e-01, -1.91891008e-01, -2.07639365e-01, -2.08754814e-01,\n",
       "                     -2.16223108e-01, -2.16895700e-01, -2.18689201e-01, -2.23143551e-01,\n",
       "                     -2.31111721e-01, -2.32495657e-01, -2.44345759e-01, -2.47408173e-01,\n",
       "                     -2.47562079e-01, -2.51314428e-01, -2.52702354e-01, -2.57829109e-01,\n",
       "                     -2.59511195e-01, -2.62364264e-01, -2.63417450e-01, -2.65703166e-01,\n",
       "                     -2.68263987e-01, -2.69332934e-01, -2.76253377e-01, -2.81851152e-01,\n",
       "                     -2.87682072e-01, -2.91520849e-01, -2.95117051e-01, -2.99242895e-01,\n",
       "                     -3.00104592e-01, -3.04489191e-01, -3.09004842e-01, -3.10154928e-01,\n",
       "                     -3.14710745e-01, -3.16911711e-01, -3.25422400e-01, -3.26763422e-01,\n",
       "                     -3.28504067e-01, -3.28888608e-01, -3.30429922e-01, -3.36472237e-01,\n",
       "                     -3.42944751e-01, -3.48306694e-01, -3.51397887e-01, -3.56674944e-01,\n",
       "                     -3.60002734e-01, -3.63667979e-01, -3.65113813e-01, -3.65240307e-01,\n",
       "                     -3.70373788e-01, -3.71563556e-01, -3.74693449e-01, -3.76477571e-01,\n",
       "                     -3.78066134e-01, -3.79489622e-01, -3.82992252e-01, -3.83958903e-01,\n",
       "                     -3.90197636e-01, -3.97802235e-01, -4.05465108e-01, -4.15515444e-01,\n",
       "                     -4.22856851e-01, -4.27444015e-01, -4.32864082e-01, -4.36717652e-01,\n",
       "                     -4.38254931e-01, -4.41832752e-01, -4.45311017e-01, -4.51985124e-01,\n",
       "                     -4.56758402e-01, -4.59532329e-01, -4.66237146e-01, -4.70003629e-01,\n",
       "                     -4.82851772e-01, -4.96436886e-01, -4.97838428e-01, -5.10825624e-01,\n",
       "                     -5.19875459e-01, -5.21296924e-01, -5.27354926e-01, -5.28067430e-01,\n",
       "                     -5.30628251e-01, -5.32216814e-01, -5.36304709e-01, -5.38996501e-01,\n",
       "                     -5.43207033e-01, -5.52068582e-01, -5.59615788e-01, -5.87786665e-01,\n",
       "                     -5.92051064e-01, -5.97227059e-01, -5.97837001e-01, -6.00773860e-01,\n",
       "                     -6.06135804e-01, -6.15185639e-01, -6.28608659e-01, -6.43136760e-01,\n",
       "                     -6.46627165e-01, -6.56779536e-01, -6.67829373e-01, -6.93147181e-01,\n",
       "                     -7.31613461e-01, -7.31861693e-01, -7.35706795e-01, -7.62140052e-01,\n",
       "                     -7.64972915e-01, -7.73189888e-01, -7.88457360e-01, -8.02346473e-01,\n",
       "                     -8.10930216e-01, -8.47297860e-01, -8.75468737e-01, -9.16290732e-01,\n",
       "                     -9.80829253e-01, -1.00330211e+00, -1.02961942e+00, -1.09861229e+00,\n",
       "                     -1.25276297e+00, -1.38629436e+00, -1.54044504e+00, -1.60943791e+00,\n",
       "                     -1.79175947e+00, -2.56494936e+00, -3.45387764e+01]), auc_score=0.5277694418698611, privacy_risk=0.5200321516848665, accuracy=0.5200321516848665, tpr_ind=0.460335352966042, tnr_ind=0.5797289504036909, test_train_ratio=0.9773143581795125, dataset_size=[7097, 6936]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.03313812, 0.03628053, 0.04570776, 0.04870733,\n",
       "                     0.05013569, 0.0532781 , 0.05799172, 0.06127696, 0.06470504,\n",
       "                     0.06599057, 0.06870447, 0.07413227, 0.07956006, 0.0824168 ,\n",
       "                     0.08470219, 0.08870161, 0.08998714, 0.12426796, 0.12926725,\n",
       "                     0.12998143, 0.14069419, 0.1636909 , 0.20739894, 0.21525496,\n",
       "                     0.22325382, 0.22582488, 0.22825311, 0.25682045, 0.26039137,\n",
       "                     0.26296243, 0.26839023, 0.26996143, 0.27396086, 0.28510213,\n",
       "                     0.29181545, 0.33052421, 0.34223682, 0.35066419, 0.36523354,\n",
       "                     0.3833738 , 0.38680189, 0.38908727, 0.39951436, 0.41294101,\n",
       "                     0.41379803, 0.41794029, 0.43008142, 0.43550921, 0.43950864,\n",
       "                     0.44336523, 0.44865019, 0.46979003, 0.47264676, 0.47936009,\n",
       "                     0.48821597, 0.4922154 , 0.4937866 , 0.49892872, 0.50335666,\n",
       "                     0.50707042, 0.52692473, 0.53178117, 0.57791744, 0.58091701,\n",
       "                     0.58648764, 0.59005856, 0.60091416, 0.62662477, 0.66233395,\n",
       "                     0.66861877, 0.6866162 , 0.69390087, 0.69475789, 0.70047136,\n",
       "                     0.70247108, 0.71332667, 0.71418369, 0.72532495, 0.72661048,\n",
       "                     0.7313241 , 0.73975146, 0.74646479, 0.75217826, 0.7748893 ,\n",
       "                     0.77617483, 0.7803171 , 0.78174546, 0.78760177, 0.81545494,\n",
       "                     0.81788316, 0.82259677, 0.83059563, 0.83273818, 0.84573632,\n",
       "                     0.85259249, 0.85473504, 0.85844879, 0.86101985, 0.8643051 ,\n",
       "                     0.86516212, 0.874018  , 0.8767319 , 0.88001714, 0.88644479,\n",
       "                     0.8923011 , 0.90401371, 0.9047279 , 0.90558492, 0.90701328,\n",
       "                     0.91701186, 0.91929724, 0.92229681, 0.93315241, 0.95057849,\n",
       "                     0.9537209 , 0.95557777, 0.958006  , 0.95843451, 0.96457649,\n",
       "                     0.96671904, 0.96800457, 0.96914726, 0.96986145, 0.97057563,\n",
       "                     0.97314669, 0.97343237, 0.9747179 , 0.97528924, 0.97757463,\n",
       "                     0.98143122, 0.98243108, 0.98471647, 0.98857306, 0.99057278,\n",
       "                     0.99057278, 0.99071561, 0.99171547, 0.99242965, 0.99285816,\n",
       "                     0.99357235, 1.        ]), tpr=array([0.        , 0.04337315, 0.04607509, 0.05517634, 0.05901593,\n",
       "                     0.06072241, 0.06569966, 0.0705347 , 0.07508532, 0.07949374,\n",
       "                     0.08148464, 0.08432878, 0.08959044, 0.09726962, 0.10054039,\n",
       "                     0.10295791, 0.11106371, 0.11390785, 0.15273038, 0.15799204,\n",
       "                     0.1592719 , 0.16751991, 0.19695677, 0.23848123, 0.2480091 ,\n",
       "                     0.25568828, 0.25938567, 0.26094994, 0.28896473, 0.29294653,\n",
       "                     0.2963595 , 0.30162116, 0.30304323, 0.30816268, 0.31953925,\n",
       "                     0.33233788, 0.3710182 , 0.38580774, 0.39505119, 0.40742321,\n",
       "                     0.42790102, 0.43074516, 0.43387372, 0.44510808, 0.45989761,\n",
       "                     0.4616041 , 0.46558589, 0.47767349, 0.48364619, 0.48819681,\n",
       "                     0.49374289, 0.49786689, 0.51962457, 0.52232651, 0.5282992 ,\n",
       "                     0.53981797, 0.5463595 , 0.54863481, 0.5524744 , 0.55659841,\n",
       "                     0.55972696, 0.57380546, 0.57807167, 0.6149033 , 0.61817406,\n",
       "                     0.62556883, 0.62940842, 0.64192264, 0.66723549, 0.69439704,\n",
       "                     0.6995165 , 0.7197099 , 0.7258248 , 0.72767349, 0.73435722,\n",
       "                     0.73563709, 0.74488055, 0.745876  , 0.76023891, 0.76166098,\n",
       "                     0.7682025 , 0.77773038, 0.78484073, 0.79067122, 0.8105802 ,\n",
       "                     0.81285552, 0.81783276, 0.8205347 , 0.82721843, 0.85352673,\n",
       "                     0.85637088, 0.86006826, 0.86817406, 0.87044937, 0.88011945,\n",
       "                     0.88694539, 0.88993174, 0.89249147, 0.8951934 , 0.89846416,\n",
       "                     0.89960182, 0.90571672, 0.90699659, 0.91040956, 0.91609784,\n",
       "                     0.92064846, 0.93159841, 0.93245165, 0.93444255, 0.935438  ,\n",
       "                     0.94254835, 0.94425484, 0.94610353, 0.9556314 , 0.97056314,\n",
       "                     0.97226962, 0.9738339 , 0.97525597, 0.97653584, 0.9817975 ,\n",
       "                     0.98350398, 0.98421502, 0.98535267, 0.98720137, 0.98762799,\n",
       "                     0.98961889, 0.99032992, 0.99118316, 0.99175199, 0.99246303,\n",
       "                     0.99445392, 0.99516496, 0.9960182 , 0.9980091 , 0.99886234,\n",
       "                     0.99900455, 0.99914676, 0.99928896, 0.99957338, 0.99985779,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.12932944e-02, -6.06246218e-02,\n",
       "                     -7.14589640e-02, -8.00427077e-02, -8.22380982e-02, -8.45573880e-02,\n",
       "                     -1.17783036e-01, -1.21360857e-01, -1.33531393e-01, -1.39761942e-01,\n",
       "                     -1.50282203e-01, -1.54150680e-01, -1.60342650e-01, -1.62518929e-01,\n",
       "                     -1.76456437e-01, -1.82321557e-01, -1.86585956e-01, -1.95744577e-01,\n",
       "                     -2.00670695e-01, -2.02236866e-01, -2.12458651e-01, -2.23143551e-01,\n",
       "                     -2.26124179e-01, -2.30523659e-01, -2.38411023e-01, -2.41162057e-01,\n",
       "                     -2.50185760e-01, -2.51314428e-01, -2.55933374e-01, -2.60283098e-01,\n",
       "                     -2.62364264e-01, -2.66628663e-01, -2.71933715e-01, -2.79313823e-01,\n",
       "                     -2.85842146e-01, -2.87682072e-01, -2.91520849e-01, -2.96265816e-01,\n",
       "                     -2.98044859e-01, -3.00104592e-01, -3.10154928e-01, -3.12683375e-01,\n",
       "                     -3.18453731e-01, -3.25422400e-01, -3.31357136e-01, -3.36472237e-01,\n",
       "                     -3.39867826e-01, -3.40926587e-01, -3.43771539e-01, -3.46276237e-01,\n",
       "                     -3.49459432e-01, -3.51397887e-01, -3.56674944e-01, -3.59141036e-01,\n",
       "                     -3.61013346e-01, -3.62905494e-01, -3.67724780e-01, -3.70373788e-01,\n",
       "                     -3.74693449e-01, -3.81613892e-01, -3.82992252e-01, -3.88592547e-01,\n",
       "                     -3.90866309e-01, -3.92561703e-01, -3.93042588e-01, -3.94165553e-01,\n",
       "                     -4.05465108e-01, -4.10687052e-01, -4.23814247e-01, -4.24070296e-01,\n",
       "                     -4.28454626e-01, -4.30782916e-01, -4.40311839e-01, -4.41832752e-01,\n",
       "                     -4.50585543e-01, -4.51985124e-01, -4.59021213e-01, -4.59532329e-01,\n",
       "                     -4.61818045e-01, -4.68136215e-01, -4.70003629e-01, -4.76082675e-01,\n",
       "                     -4.84962113e-01, -4.85507816e-01, -4.87703206e-01, -4.89548225e-01,\n",
       "                     -4.93657820e-01, -4.96671876e-01, -5.00775288e-01, -5.03103578e-01,\n",
       "                     -5.10825624e-01, -5.23248144e-01, -5.25424423e-01, -5.35518236e-01,\n",
       "                     -5.38996501e-01, -5.43615447e-01, -5.52068582e-01, -5.53385238e-01,\n",
       "                     -5.59615788e-01, -5.69533225e-01, -5.75364145e-01, -5.83146285e-01,\n",
       "                     -5.87786665e-01, -5.94707108e-01, -5.97837001e-01, -6.06135804e-01,\n",
       "                     -6.19039208e-01, -6.28608659e-01, -6.31271777e-01, -6.50587566e-01,\n",
       "                     -6.53926467e-01, -6.63294217e-01, -6.93147181e-01, -7.33969175e-01,\n",
       "                     -7.37598943e-01, -7.41937345e-01, -7.47214402e-01, -7.58529940e-01,\n",
       "                     -7.73189888e-01, -7.88457360e-01, -8.10930216e-01, -8.36248024e-01,\n",
       "                     -8.47297860e-01, -9.16290732e-01, -9.55511445e-01, -9.80829253e-01,\n",
       "                     -1.01160091e+00, -1.02961942e+00, -1.09861229e+00, -1.16315081e+00,\n",
       "                     -1.20397280e+00, -1.25276297e+00, -1.38629436e+00, -1.60943791e+00,\n",
       "                     -1.79175947e+00, -1.94591015e+00, -2.01490302e+00, -2.07944154e+00,\n",
       "                     -2.48490665e+00, -3.45387764e+01]), auc_score=0.5336885381561776, privacy_risk=0.5274241051863386, accuracy=0.5274241051863386, tpr_ind=0.5486348122866894, tnr_ind=0.5062133980859878, test_train_ratio=0.9955915813424346, dataset_size=[7032, 7001]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.03160755, 0.03275172, 0.03432494, 0.03861556,\n",
       "                     0.04018879, 0.05778032, 0.06593249, 0.06836384, 0.07279748,\n",
       "                     0.07379863, 0.07823227, 0.08395309, 0.08581236, 0.09110412,\n",
       "                     0.09739703, 0.11885011, 0.12542906, 0.12557208, 0.14530892,\n",
       "                     0.14917048, 0.14988558, 0.15560641, 0.16075515, 0.16819222,\n",
       "                     0.18664188, 0.19050343, 0.19279176, 0.19336384, 0.20351831,\n",
       "                     0.21209954, 0.21495995, 0.21782037, 0.23112128, 0.24213387,\n",
       "                     0.2444222 , 0.24899886, 0.263873  , 0.28632723, 0.28847254,\n",
       "                     0.32551487, 0.32808924, 0.33566934, 0.3368135 , 0.35368993,\n",
       "                     0.36498856, 0.36727689, 0.38973112, 0.39130435, 0.3993135 ,\n",
       "                     0.40217391, 0.43020595, 0.44279176, 0.44808352, 0.45165904,\n",
       "                     0.46081236, 0.4701087 , 0.51315789, 0.55520595, 0.55863844,\n",
       "                     0.56121281, 0.56764874, 0.56879291, 0.58338101, 0.59682494,\n",
       "                     0.60240275, 0.60655034, 0.61970824, 0.63343822, 0.64087529,\n",
       "                     0.66004005, 0.66433066, 0.67133867, 0.67934783, 0.68950229,\n",
       "                     0.7020881 , 0.70981121, 0.71338673, 0.71553204, 0.71810641,\n",
       "                     0.72611556, 0.73155034, 0.73426773, 0.73884439, 0.74270595,\n",
       "                     0.74742563, 0.74899886, 0.75572082, 0.75829519, 0.76487414,\n",
       "                     0.77188215, 0.78360984, 0.78604119, 0.79076087, 0.81350114,\n",
       "                     0.81993707, 0.82308352, 0.82837529, 0.83209382, 0.83395309,\n",
       "                     0.83595538, 0.83709954, 0.85154462, 0.85411899, 0.85798055,\n",
       "                     0.8604119 , 0.86684783, 0.87028032, 0.87142449, 0.8805778 ,\n",
       "                     0.88372426, 0.88658467, 0.888873  , 0.90860984, 0.91304348,\n",
       "                     0.9173341 , 0.92405606, 0.92877574, 0.93778604, 0.94493707,\n",
       "                     0.95094394, 0.95351831, 0.95509153, 0.95780892, 0.9625286 ,\n",
       "                     0.96410183, 0.96553204, 0.96710526, 0.97354119, 0.97454233,\n",
       "                     0.98169336, 0.98283753, 0.98727117, 0.98827231, 0.9909897 ,\n",
       "                     0.9909897 , 0.99241991, 0.99299199, 0.99356407, 0.99385011,\n",
       "                     0.99485126, 0.99499428, 0.99528032, 0.99542334, 1.        ]), tpr=array([0.        , 0.0359324 , 0.03806278, 0.03976708, 0.04601619,\n",
       "                     0.04899872, 0.06746201, 0.07726175, 0.08123846, 0.08478909,\n",
       "                     0.08592529, 0.09203238, 0.09686124, 0.09870757, 0.10325238,\n",
       "                     0.11006959, 0.13662832, 0.14287743, 0.14358756, 0.1668797 ,\n",
       "                     0.17028831, 0.17156654, 0.1769635 , 0.18108223, 0.18846755,\n",
       "                     0.20749893, 0.21303792, 0.2151683 , 0.21673058, 0.2286607 ,\n",
       "                     0.23732424, 0.24087488, 0.24541968, 0.26004829, 0.27055816,\n",
       "                     0.27354069, 0.2797898 , 0.29129385, 0.31032524, 0.31217157,\n",
       "                     0.35307485, 0.35705156, 0.36585712, 0.36756143, 0.38318421,\n",
       "                     0.39397813, 0.39596648, 0.41925863, 0.42082091, 0.4309047 ,\n",
       "                     0.43473938, 0.46371254, 0.47550064, 0.48174975, 0.48430621,\n",
       "                     0.49439   , 0.50433177, 0.54921176, 0.59139327, 0.59536998,\n",
       "                     0.59821048, 0.60346542, 0.6055958 , 0.6207925 , 0.63471098,\n",
       "                     0.63882971, 0.6432325 , 0.65487857, 0.66780287, 0.6730578 ,\n",
       "                     0.69208919, 0.69620793, 0.70345121, 0.71083653, 0.71864792,\n",
       "                     0.73398665, 0.74094589, 0.74506462, 0.74762108, 0.75117171,\n",
       "                     0.76253373, 0.76722057, 0.769635  , 0.77318563, 0.77645221,\n",
       "                     0.77900866, 0.78085499, 0.78568385, 0.78866638, 0.7954836 ,\n",
       "                     0.80215878, 0.81266866, 0.81550916, 0.82019599, 0.84149979,\n",
       "                     0.84675472, 0.85030535, 0.85627042, 0.85811674, 0.86095725,\n",
       "                     0.86337168, 0.86536003, 0.88268712, 0.8842494 , 0.88879421,\n",
       "                     0.89262889, 0.89788382, 0.90129243, 0.90200256, 0.91151825,\n",
       "                     0.91421673, 0.91719926, 0.91961369, 0.9342423 , 0.93807698,\n",
       "                     0.94134356, 0.94617242, 0.94972305, 0.95554609, 0.96094305,\n",
       "                     0.96520381, 0.96804431, 0.97003267, 0.97287317, 0.9752876 ,\n",
       "                     0.97741798, 0.97841216, 0.97898026, 0.98508735, 0.9859395 ,\n",
       "                     0.98991621, 0.99176253, 0.99431899, 0.99517114, 0.99701747,\n",
       "                     0.99744354, 0.9982957 , 0.99872177, 0.99900582, 0.99928987,\n",
       "                     0.99957392, 0.99971595, 0.99985797, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -6.45385211e-02, -8.00427077e-02,\n",
       "                     -8.70113770e-02, -9.09717782e-02, -9.53101798e-02, -9.66268357e-02,\n",
       "                     -1.01782694e-01, -1.13328685e-01, -1.17783036e-01, -1.30620182e-01,\n",
       "                     -1.37201122e-01, -1.43100844e-01, -1.45182010e-01, -1.54150680e-01,\n",
       "                     -1.57963113e-01, -1.67054085e-01, -1.82321557e-01, -1.88400603e-01,\n",
       "                     -1.89242000e-01, -2.00670695e-01, -2.12561442e-01, -2.16223108e-01,\n",
       "                     -2.23143551e-01, -2.26124179e-01, -2.28258652e-01, -2.36388778e-01,\n",
       "                     -2.41162057e-01, -2.42012036e-01, -2.45834963e-01, -2.46860078e-01,\n",
       "                     -2.47836164e-01, -2.48072934e-01, -2.49811798e-01, -2.51314428e-01,\n",
       "                     -2.58861634e-01, -2.59511195e-01, -2.61215499e-01, -2.68263987e-01,\n",
       "                     -2.71933715e-01, -2.78713402e-01, -2.79584862e-01, -2.87682072e-01,\n",
       "                     -2.89952221e-01, -2.94239473e-01, -3.05381650e-01, -3.07305344e-01,\n",
       "                     -3.10154928e-01, -3.12031101e-01, -3.15081047e-01, -3.23787077e-01,\n",
       "                     -3.26091521e-01, -3.26684230e-01, -3.28504067e-01, -3.32439973e-01,\n",
       "                     -3.36472237e-01, -3.49051019e-01, -3.56001316e-01, -3.56674944e-01,\n",
       "                     -3.71563556e-01, -3.78066134e-01, -3.82992252e-01, -3.89766199e-01,\n",
       "                     -3.91766264e-01, -3.93904286e-01, -3.94654192e-01, -4.05465108e-01,\n",
       "                     -4.09121419e-01, -4.14433778e-01, -4.15366179e-01, -4.16893804e-01,\n",
       "                     -4.24883194e-01, -4.30782916e-01, -4.35318071e-01, -4.35862585e-01,\n",
       "                     -4.38913042e-01, -4.39366660e-01, -4.41832752e-01, -4.44685821e-01,\n",
       "                     -4.54255272e-01, -4.54736157e-01, -4.62623522e-01, -4.70003629e-01,\n",
       "                     -4.75423697e-01, -4.76924072e-01, -4.79573080e-01, -4.80972661e-01,\n",
       "                     -4.81838087e-01, -4.85507816e-01, -4.93657820e-01, -4.99955952e-01,\n",
       "                     -5.00775288e-01, -5.10825624e-01, -5.14817645e-01, -5.16216472e-01,\n",
       "                     -5.18793793e-01, -5.25010259e-01, -5.26093096e-01, -5.30628251e-01,\n",
       "                     -5.34082486e-01, -5.38996501e-01, -5.43086486e-01, -5.46543706e-01,\n",
       "                     -5.59615788e-01, -5.75364145e-01, -5.78736829e-01, -5.83146285e-01,\n",
       "                     -5.87786665e-01, -6.07491736e-01, -6.10909082e-01, -6.19039208e-01,\n",
       "                     -6.32522559e-01, -6.33129171e-01, -6.35988767e-01, -6.48695418e-01,\n",
       "                     -6.63294217e-01, -6.72944473e-01, -6.93147181e-01, -7.06219262e-01,\n",
       "                     -7.09676483e-01, -7.17839793e-01, -7.28238500e-01, -7.41937345e-01,\n",
       "                     -7.50305594e-01, -7.57685702e-01, -7.62140052e-01, -8.10930216e-01,\n",
       "                     -8.33919734e-01, -8.47297860e-01, -8.87303195e-01, -9.00786545e-01,\n",
       "                     -9.16290732e-01, -9.80829253e-01, -1.09861229e+00, -1.20397280e+00,\n",
       "                     -1.25276297e+00, -1.29928298e+00, -1.38629436e+00, -1.50407740e+00,\n",
       "                     -1.60943791e+00, -1.79175947e+00, -2.19722458e+00, -2.30258509e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5263270730897194, privacy_risk=0.5189430178812103, accuracy=0.5189430178812103, tpr_ind=0.6347109785541827, tnr_ind=0.403175057208238, test_train_ratio=0.9930407612555034, dataset_size=[7041, 6992]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.03426703, 0.03711076, 0.04180293, 0.04350917,\n",
       "                     0.04621072, 0.04706384, 0.04834352, 0.05417318, 0.0594341 ,\n",
       "                     0.06227783, 0.06796531, 0.06881843, 0.0874449 , 0.09412768,\n",
       "                     0.09967297, 0.1144604 , 0.1177307 , 0.11957913, 0.14090715,\n",
       "                     0.14503057, 0.17688042, 0.17915541, 0.18484288, 0.18882411,\n",
       "                     0.19820845, 0.20048344, 0.20403811, 0.20673966, 0.2127115 ,\n",
       "                     0.24555666, 0.25508318, 0.25693161, 0.26731125, 0.27897057,\n",
       "                     0.28451585, 0.30413764, 0.30541732, 0.3121001 , 0.31522821,\n",
       "                     0.32390161, 0.32603441, 0.32973127, 0.33143751, 0.34082184,\n",
       "                     0.34423432, 0.35077492, 0.36470923, 0.3725295 , 0.37565761,\n",
       "                     0.38290914, 0.39016067, 0.4006825 , 0.41020901, 0.42599175,\n",
       "                     0.42627613, 0.44120574, 0.44731978, 0.44902602, 0.45514005,\n",
       "                     0.46267596, 0.51329447, 0.51642258, 0.52538035, 0.53206313,\n",
       "                     0.53504905, 0.53789279, 0.53917247, 0.5421584 , 0.54542869,\n",
       "                     0.5529646 , 0.55922082, 0.56433954, 0.57187544, 0.57727854,\n",
       "                     0.58182852, 0.58993317, 0.60358311, 0.61581118, 0.70027015,\n",
       "                     0.72259349, 0.72742784, 0.73254657, 0.73567468, 0.7461965 ,\n",
       "                     0.75259491, 0.75529646, 0.76297455, 0.77207451, 0.78416039,\n",
       "                     0.79226504, 0.80179155, 0.80662591, 0.81615242, 0.81686336,\n",
       "                     0.8218399 , 0.82653206, 0.83022892, 0.8326461 , 0.84316792,\n",
       "                     0.8498507 , 0.8542585 , 0.85568036, 0.85937722, 0.86307408,\n",
       "                     0.88909427, 0.89350206, 0.89620361, 0.90317077, 0.90530357,\n",
       "                     0.90743637, 0.91070667, 0.91568321, 0.93018626, 0.94127684,\n",
       "                     0.94653775, 0.94952367, 0.95094554, 0.95549552, 0.96132518,\n",
       "                     0.96303142, 0.96729703, 0.97142045, 0.97582824, 0.97810323,\n",
       "                     0.97881416, 0.98080478, 0.98180009, 0.98265321, 0.98862505,\n",
       "                     0.98947817, 0.9913266 , 0.99161098, 1.        ]), tpr=array([0.        , 0.04142857, 0.047     , 0.05142857, 0.05428571,\n",
       "                     0.05685714, 0.05842857, 0.05985714, 0.06657143, 0.07171429,\n",
       "                     0.07671429, 0.08328571, 0.08514286, 0.10571429, 0.11328571,\n",
       "                     0.12028571, 0.13671429, 0.13942857, 0.14142857, 0.164     ,\n",
       "                     0.16942857, 0.20757143, 0.21      , 0.21542857, 0.22285714,\n",
       "                     0.23285714, 0.23557143, 0.23928571, 0.24228571, 0.24728571,\n",
       "                     0.28414286, 0.29457143, 0.29685714, 0.30457143, 0.31885714,\n",
       "                     0.32285714, 0.34028571, 0.34242857, 0.35      , 0.35542857,\n",
       "                     0.36371429, 0.36742857, 0.37185714, 0.37385714, 0.381     ,\n",
       "                     0.384     , 0.39214286, 0.40414286, 0.41085714, 0.41457143,\n",
       "                     0.42085714, 0.42971429, 0.44057143, 0.45028571, 0.47142857,\n",
       "                     0.47214286, 0.48657143, 0.49071429, 0.49242857, 0.49985714,\n",
       "                     0.50657143, 0.55214286, 0.55542857, 0.56328571, 0.56942857,\n",
       "                     0.57257143, 0.575     , 0.578     , 0.58128571, 0.58485714,\n",
       "                     0.59514286, 0.60214286, 0.60628571, 0.61114286, 0.61757143,\n",
       "                     0.62128571, 0.63214286, 0.64585714, 0.65857143, 0.73628571,\n",
       "                     0.75785714, 0.76428571, 0.77014286, 0.77328571, 0.78342857,\n",
       "                     0.79042857, 0.79257143, 0.80242857, 0.81414286, 0.82442857,\n",
       "                     0.83142857, 0.84171429, 0.84714286, 0.85657143, 0.85785714,\n",
       "                     0.85942857, 0.86371429, 0.86714286, 0.86871429, 0.87942857,\n",
       "                     0.88485714, 0.88857143, 0.89057143, 0.89342857, 0.89857143,\n",
       "                     0.91614286, 0.918     , 0.92085714, 0.92785714, 0.93028571,\n",
       "                     0.93157143, 0.93428571, 0.93985714, 0.953     , 0.96371429,\n",
       "                     0.96842857, 0.97057143, 0.97185714, 0.977     , 0.98128571,\n",
       "                     0.98257143, 0.98514286, 0.98842857, 0.98985714, 0.99228571,\n",
       "                     0.99314286, 0.99385714, 0.99428571, 0.99514286, 0.99857143,\n",
       "                     0.99928571, 0.99971429, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -2.53178080e-02, -3.17486983e-02,\n",
       "                     -4.87901642e-02, -5.40672213e-02, -8.70113770e-02, -9.53101798e-02,\n",
       "                     -1.01096117e-01, -1.05360516e-01, -1.08213585e-01, -1.17783036e-01,\n",
       "                     -1.25163143e-01, -1.30053128e-01, -1.56842471e-01, -1.68622712e-01,\n",
       "                     -1.89541805e-01, -1.91055237e-01, -1.94156014e-01, -1.94900339e-01,\n",
       "                     -2.02940844e-01, -2.05764950e-01, -2.11309094e-01, -2.12561442e-01,\n",
       "                     -2.23143551e-01, -2.28841572e-01, -2.33614851e-01, -2.38411023e-01,\n",
       "                     -2.41162057e-01, -2.51314428e-01, -2.55182905e-01, -2.63417450e-01,\n",
       "                     -2.71933715e-01, -2.73695830e-01, -2.77631737e-01, -2.78713402e-01,\n",
       "                     -2.83575290e-01, -2.87682072e-01, -2.92387963e-01, -2.94239473e-01,\n",
       "                     -2.96265816e-01, -2.97251523e-01, -3.03682414e-01, -3.05381650e-01,\n",
       "                     -3.07484700e-01, -3.10154928e-01, -3.13657559e-01, -3.14115330e-01,\n",
       "                     -3.24239668e-01, -3.25422400e-01, -3.26684230e-01, -3.27212911e-01,\n",
       "                     -3.32705754e-01, -3.34369186e-01, -3.35506520e-01, -3.36472237e-01,\n",
       "                     -3.40706541e-01, -3.46276237e-01, -3.48306694e-01, -3.52821375e-01,\n",
       "                     -3.54545018e-01, -3.57301707e-01, -3.61013346e-01, -3.62114667e-01,\n",
       "                     -3.65934269e-01, -3.74693449e-01, -3.85662481e-01, -3.89464767e-01,\n",
       "                     -3.90866309e-01, -3.92042088e-01, -4.05465108e-01, -4.12244795e-01,\n",
       "                     -4.16893804e-01, -4.24883194e-01, -4.27444015e-01, -4.30782916e-01,\n",
       "                     -4.35318071e-01, -4.39598114e-01, -4.41832752e-01, -4.42751448e-01,\n",
       "                     -4.46551968e-01, -4.56017387e-01, -4.60815203e-01, -4.64305608e-01,\n",
       "                     -4.64707942e-01, -4.64888529e-01, -4.70003629e-01, -4.75423697e-01,\n",
       "                     -4.76082675e-01, -4.76924072e-01, -4.77627554e-01, -4.85507816e-01,\n",
       "                     -4.89548225e-01, -4.92476485e-01, -5.10825624e-01, -5.26093096e-01,\n",
       "                     -5.30628251e-01, -5.35518236e-01, -5.46543706e-01, -5.65313809e-01,\n",
       "                     -5.67106460e-01, -5.70544858e-01, -5.79818495e-01, -5.87786665e-01,\n",
       "                     -6.06135804e-01, -6.08350644e-01, -6.13104473e-01, -6.15185639e-01,\n",
       "                     -6.29968279e-01, -6.32522559e-01, -6.35988767e-01, -6.66478933e-01,\n",
       "                     -6.67171694e-01, -6.71168274e-01, -6.93147181e-01, -7.08185058e-01,\n",
       "                     -7.25937003e-01, -7.47214402e-01, -7.60286483e-01, -7.73189888e-01,\n",
       "                     -7.98507696e-01, -8.47297860e-01, -8.71838969e-01, -8.75468737e-01,\n",
       "                     -8.80358723e-01, -9.16290732e-01, -9.55511445e-01, -9.80829253e-01,\n",
       "                     -1.04145387e+00, -1.09861229e+00, -1.22377543e+00, -1.38629436e+00,\n",
       "                     -2.30258509e+00, -3.45387764e+01]), auc_score=0.5328481546180253, privacy_risk=0.5229333651561008, accuracy=0.5229333651561008, tpr_ind=0.47214285714285714, tnr_ind=0.5737238731693445, test_train_ratio=1.0047142857142857, dataset_size=[7000, 7033]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.04404475, 0.04829344, 0.05310862, 0.05395836,\n",
       "                     0.05707407, 0.05891517, 0.06203087, 0.08299108, 0.08426568,\n",
       "                     0.08695652, 0.09191333, 0.09403767, 0.09517066, 0.09658689,\n",
       "                     0.11103243, 0.11839683, 0.12165416, 0.1256196 , 0.14785441,\n",
       "                     0.18651749, 0.19317377, 0.19515649, 0.20591984, 0.21045178,\n",
       "                     0.21441722, 0.2173913 , 0.22234811, 0.22532219, 0.23424444,\n",
       "                     0.2407591 , 0.24614077, 0.24982297, 0.27248265, 0.27559836,\n",
       "                     0.28381249, 0.29655856, 0.31043762, 0.31411981, 0.32502478,\n",
       "                     0.32955672, 0.33479677, 0.38011613, 0.3823821 , 0.38280697,\n",
       "                     0.38464807, 0.39059623, 0.39371194, 0.42316952, 0.42755984,\n",
       "                     0.4279847 , 0.4673559 , 0.47514516, 0.48095171, 0.48633338,\n",
       "                     0.49511401, 0.50021243, 0.50913468, 0.51310013, 0.52542133,\n",
       "                     0.52910353, 0.5431242 , 0.54963886, 0.56705849, 0.58631922,\n",
       "                     0.59170089, 0.60784591, 0.63135533, 0.6404192 , 0.66831893,\n",
       "                     0.67115139, 0.68403909, 0.68800453, 0.69324458, 0.69791814,\n",
       "                     0.70429118, 0.71420479, 0.72369353, 0.72624274, 0.73913043,\n",
       "                     0.74210452, 0.75088514, 0.75385923, 0.75711656, 0.76136525,\n",
       "                     0.7660388 , 0.77510268, 0.77807676, 0.78444979, 0.7912477 ,\n",
       "                     0.79351367, 0.79464665, 0.80087806, 0.81192466, 0.82013879,\n",
       "                     0.83047727, 0.85370344, 0.86460841, 0.86800736, 0.87098145,\n",
       "                     0.8743804 , 0.87848747, 0.88061181, 0.88585186, 0.89066704,\n",
       "                     0.90058065, 0.90369636, 0.90497097, 0.90780343, 0.90978615,\n",
       "                     0.911344  , 0.93867724, 0.94221782, 0.94405892, 0.94745787,\n",
       "                     0.94901572, 0.95397253, 0.95737148, 0.95892933, 0.96261153,\n",
       "                     0.96586886, 0.97663221, 0.97705707, 0.97776519, 0.98144739,\n",
       "                     0.98413822, 0.98527121, 0.9858377 , 0.98725393, 0.98824529,\n",
       "                     0.98824529, 0.98966152, 0.99178587, 0.99192749, 0.9932021 ,\n",
       "                     0.99546806, 0.9963178 , 1.        ]), tpr=array([0.        , 0.05177854, 0.05765921, 0.06267929, 0.06425703,\n",
       "                     0.06855995, 0.07085485, 0.07415376, 0.09452094, 0.09652897,\n",
       "                     0.10040161, 0.10786001, 0.11029834, 0.11187608, 0.11417097,\n",
       "                     0.12664945, 0.133821  , 0.13654618, 0.14242685, 0.16580608,\n",
       "                     0.20238095, 0.20740103, 0.20926563, 0.22131383, 0.22705106,\n",
       "                     0.23207114, 0.23580034, 0.24053356, 0.24512335, 0.25616753,\n",
       "                     0.26362593, 0.26749857, 0.27079748, 0.29417671, 0.2983362 ,\n",
       "                     0.30737235, 0.31985083, 0.33519793, 0.33950086, 0.35183592,\n",
       "                     0.35671256, 0.36029834, 0.40275387, 0.40590935, 0.40863454,\n",
       "                     0.41092943, 0.41724039, 0.42168675, 0.45266781, 0.46069994,\n",
       "                     0.4614171 , 0.50473322, 0.51233505, 0.51864601, 0.52524383,\n",
       "                     0.53557085, 0.54202524, 0.55321285, 0.55823293, 0.57243259,\n",
       "                     0.5753012 , 0.58648881, 0.59193919, 0.61001147, 0.62923121,\n",
       "                     0.63367757, 0.64845095, 0.67226047, 0.67928858, 0.70438898,\n",
       "                     0.70711417, 0.71858864, 0.72246127, 0.72733792, 0.73192771,\n",
       "                     0.73637407, 0.74942628, 0.7560241 , 0.75917958, 0.77194492,\n",
       "                     0.77524383, 0.78241538, 0.78585772, 0.7885829 , 0.79345955,\n",
       "                     0.79905336, 0.80536431, 0.80952381, 0.81741251, 0.8234366 ,\n",
       "                     0.82501434, 0.82773953, 0.83304647, 0.84150889, 0.84954102,\n",
       "                     0.85556512, 0.88209983, 0.89300057, 0.89486517, 0.89802065,\n",
       "                     0.90189329, 0.90404475, 0.90576592, 0.90949512, 0.91250717,\n",
       "                     0.91838784, 0.92197361, 0.92340792, 0.92641997, 0.92799771,\n",
       "                     0.92986231, 0.95524957, 0.95811819, 0.96026965, 0.96457258,\n",
       "                     0.96572002, 0.97030981, 0.97174412, 0.973035  , 0.97647734,\n",
       "                     0.9804934 , 0.98709122, 0.98752151, 0.98823867, 0.99082042,\n",
       "                     0.99297189, 0.99411933, 0.99454963, 0.99512335, 0.9962708 ,\n",
       "                     0.99670109, 0.99727481, 0.99784854, 0.9981354 , 0.99856569,\n",
       "                     0.99942628, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -7.06175672e-02, -8.22380982e-02,\n",
       "                     -8.70113770e-02, -9.53101798e-02, -1.17783036e-01, -1.22602322e-01,\n",
       "                     -1.25577307e-01, -1.33531393e-01, -1.38150338e-01, -1.43100844e-01,\n",
       "                     -1.62518929e-01, -1.67054085e-01, -1.71850257e-01, -1.78482780e-01,\n",
       "                     -1.82321557e-01, -1.91055237e-01, -1.98450939e-01, -2.04567166e-01,\n",
       "                     -2.04939645e-01, -2.05852054e-01, -2.07639365e-01, -2.13574100e-01,\n",
       "                     -2.23143551e-01, -2.28841572e-01, -2.38411023e-01, -2.41162057e-01,\n",
       "                     -2.47836164e-01, -2.51314428e-01, -2.53448901e-01, -2.59511195e-01,\n",
       "                     -2.65703166e-01, -2.67541965e-01, -2.70290330e-01, -2.75705881e-01,\n",
       "                     -2.79024010e-01, -2.82998223e-01, -2.87682072e-01, -2.99242895e-01,\n",
       "                     -3.02280872e-01, -3.07484700e-01, -3.08577108e-01, -3.10154928e-01,\n",
       "                     -3.13657559e-01, -3.18453731e-01, -3.26684230e-01, -3.27212911e-01,\n",
       "                     -3.28504067e-01, -3.31357136e-01, -3.36472237e-01, -3.36945162e-01,\n",
       "                     -3.41749294e-01, -3.42944751e-01, -3.45745873e-01, -3.48306694e-01,\n",
       "                     -3.52220594e-01, -3.52821375e-01, -3.56674944e-01, -3.67724780e-01,\n",
       "                     -3.71563556e-01, -3.79489622e-01, -3.87765531e-01, -3.89464767e-01,\n",
       "                     -3.90427231e-01, -3.94654192e-01, -4.02223614e-01, -4.05465108e-01,\n",
       "                     -4.12244795e-01, -4.14943852e-01, -4.22856851e-01, -4.38254931e-01,\n",
       "                     -4.41832752e-01, -4.43931389e-01, -4.46287103e-01, -4.57833094e-01,\n",
       "                     -4.58953793e-01, -4.61818045e-01, -4.64305608e-01, -4.70003629e-01,\n",
       "                     -4.75423697e-01, -4.82426149e-01, -4.85507816e-01, -4.89548225e-01,\n",
       "                     -4.98991166e-01, -5.10825624e-01, -5.19875459e-01, -5.24524468e-01,\n",
       "                     -5.35961597e-01, -5.38996501e-01, -5.46543706e-01, -5.52068582e-01,\n",
       "                     -5.55946059e-01, -5.57191544e-01, -5.64529803e-01, -5.66395475e-01,\n",
       "                     -5.66541556e-01, -5.68849464e-01, -5.70544858e-01, -5.72519193e-01,\n",
       "                     -5.75364145e-01, -5.87786665e-01, -6.06135804e-01, -6.13104473e-01,\n",
       "                     -6.19039208e-01, -6.30233355e-01, -6.31271777e-01, -6.41853886e-01,\n",
       "                     -6.44357016e-01, -6.46627165e-01, -6.53926467e-01, -6.93147181e-01,\n",
       "                     -7.17839793e-01, -7.25937003e-01, -7.41937345e-01, -7.53771802e-01,\n",
       "                     -7.82759339e-01, -7.88457360e-01, -7.98507696e-01, -8.10930216e-01,\n",
       "                     -8.26678573e-01, -8.34797698e-01, -8.47297860e-01, -8.75468737e-01,\n",
       "                     -9.16290732e-01, -9.55511445e-01, -9.65080896e-01, -9.80829253e-01,\n",
       "                     -1.09861229e+00, -1.13943428e+00, -1.20397280e+00, -1.25276297e+00,\n",
       "                     -1.38629436e+00, -1.50407740e+00, -1.54044504e+00, -1.60943791e+00,\n",
       "                     -1.94591015e+00, -3.45387764e+01]), auc_score=0.5260663204337775, privacy_risk=0.5235056295345462, accuracy=0.5235056295345462, tpr_ind=0.5724325874928284, tnr_ind=0.474578671576264, test_train_ratio=1.0127653471026965, dataset_size=[6972, 7061]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.03118741, 0.03390558, 0.04649499, 0.04806867,\n",
       "                     0.05350501, 0.05350501, 0.05550787, 0.06509299, 0.06638054,\n",
       "                     0.06680973, 0.06995708, 0.0739628 , 0.0751073 , 0.08741059,\n",
       "                     0.10572246, 0.109299  , 0.11173104, 0.11416309, 0.11745351,\n",
       "                     0.12188841, 0.12360515, 0.12918455, 0.13934192, 0.14091559,\n",
       "                     0.14406295, 0.14663805, 0.15622318, 0.19713877, 0.19942775,\n",
       "                     0.20658083, 0.23133047, 0.23633763, 0.24034335, 0.24592275,\n",
       "                     0.25336195, 0.29313305, 0.3018598 , 0.31201717, 0.32947067,\n",
       "                     0.34878398, 0.36165951, 0.36824034, 0.37238913, 0.37482117,\n",
       "                     0.40515021, 0.40729614, 0.41387697, 0.42088698, 0.42575107,\n",
       "                     0.42889843, 0.43733906, 0.46866953, 0.46967096, 0.48927039,\n",
       "                     0.49742489, 0.49957082, 0.51316166, 0.51745351, 0.52532189,\n",
       "                     0.53004292, 0.5434907 , 0.54763948, 0.55336195, 0.55822604,\n",
       "                     0.56895565, 0.58025751, 0.59985694, 0.61502146, 0.62002861,\n",
       "                     0.62904149, 0.63533619, 0.63633763, 0.65379113, 0.66280401,\n",
       "                     0.69155937, 0.69427754, 0.69656652, 0.69942775, 0.70729614,\n",
       "                     0.71044349, 0.71387697, 0.71988555, 0.7286123 , 0.73018598,\n",
       "                     0.74191702, 0.75035765, 0.75236052, 0.77811159, 0.78369099,\n",
       "                     0.78569385, 0.83075823, 0.83705293, 0.84191702, 0.89771102,\n",
       "                     0.89942775, 0.90257511, 0.9037196 , 0.90643777, 0.91058655,\n",
       "                     0.91173104, 0.91545064, 0.91630901, 0.91773963, 0.91988555,\n",
       "                     0.92832618, 0.93218884, 0.93919886, 0.94864092, 0.95107296,\n",
       "                     0.95951359, 0.95994278, 0.96251788, 0.96494993, 0.96623748,\n",
       "                     0.96967096, 0.97052933, 0.9739628 , 0.97725322, 0.97896996,\n",
       "                     0.98082976, 0.98469242, 0.98597997, 0.99098712, 0.99155937,\n",
       "                     0.99213162, 0.9925608 , 0.99298999, 0.99413448, 1.        ]), tpr=array([0.        , 0.03833594, 0.04103365, 0.05523215, 0.05736192,\n",
       "                     0.06446117, 0.06588102, 0.06857873, 0.07865966, 0.08093142,\n",
       "                     0.08277723, 0.08561692, 0.09115434, 0.09200625, 0.10194519,\n",
       "                     0.12082919, 0.12537271, 0.12835439, 0.13190402, 0.13673151,\n",
       "                     0.14425671, 0.14823229, 0.15405367, 0.16427659, 0.16669033,\n",
       "                     0.16967201, 0.17322164, 0.18784609, 0.23100951, 0.23384921,\n",
       "                     0.23825075, 0.26167826, 0.26636377, 0.26891949, 0.27488286,\n",
       "                     0.28198211, 0.32216385, 0.33295471, 0.34232571, 0.36149368,\n",
       "                     0.38094562, 0.39400824, 0.40124947, 0.405651  , 0.40763879,\n",
       "                     0.4367457 , 0.43986937, 0.44682664, 0.45335794, 0.45903734,\n",
       "                     0.46500071, 0.47238393, 0.50134886, 0.50205878, 0.51867102,\n",
       "                     0.52676416, 0.52775806, 0.54025273, 0.54550618, 0.55388329,\n",
       "                     0.55899475, 0.57376118, 0.57688485, 0.58270623, 0.58653983,\n",
       "                     0.60116428, 0.61152918, 0.6311231 , 0.64617351, 0.65114298,\n",
       "                     0.65937811, 0.66562544, 0.66718728, 0.68379952, 0.69416442,\n",
       "                     0.72028965, 0.72412324, 0.72767287, 0.72994463, 0.73690189,\n",
       "                     0.7395996 , 0.74414312, 0.74982252, 0.75876757, 0.76103933,\n",
       "                     0.77282408, 0.78091722, 0.78247906, 0.80619054, 0.81087605,\n",
       "                     0.81357376, 0.8575891 , 0.8612807 , 0.86625018, 0.91779071,\n",
       "                     0.91992049, 0.92276019, 0.92460599, 0.92673577, 0.93056936,\n",
       "                     0.93213119, 0.9368167 , 0.93781059, 0.93994037, 0.94136022,\n",
       "                     0.94874343, 0.95200909, 0.95612665, 0.9632259 , 0.96634957,\n",
       "                     0.97302286, 0.97458469, 0.97600454, 0.97770836, 0.97941218,\n",
       "                     0.98125799, 0.98196791, 0.9849496 , 0.98750532, 0.9886412 ,\n",
       "                     0.99006105, 0.99304274, 0.99460457, 0.99772824, 0.9981542 ,\n",
       "                     0.99886412, 0.99914809, 0.99957405, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -5.12932944e-02, -5.82689081e-02,\n",
       "                     -6.45385211e-02, -7.69610411e-02, -9.53101798e-02, -1.00083459e-01,\n",
       "                     -1.06767975e-01, -1.17783036e-01, -1.33531393e-01, -1.39761942e-01,\n",
       "                     -1.43100844e-01, -1.54150680e-01, -1.58224005e-01, -1.65896677e-01,\n",
       "                     -1.71850257e-01, -1.74353387e-01, -1.82321557e-01, -1.87211542e-01,\n",
       "                     -1.88591170e-01, -1.94156014e-01, -1.98450939e-01, -2.00670695e-01,\n",
       "                     -2.11309094e-01, -2.13574100e-01, -2.15111380e-01, -2.17301276e-01,\n",
       "                     -2.20508504e-01, -2.23143551e-01, -2.29574442e-01, -2.31592606e-01,\n",
       "                     -2.41162057e-01, -2.45122458e-01, -2.51314428e-01, -2.62364264e-01,\n",
       "                     -2.65349746e-01, -2.74436846e-01, -2.87682072e-01, -2.93222253e-01,\n",
       "                     -2.94954832e-01, -2.98492989e-01, -3.02280872e-01, -3.03682414e-01,\n",
       "                     -3.05381650e-01, -3.08201803e-01, -3.10154928e-01, -3.12872321e-01,\n",
       "                     -3.14493330e-01, -3.18453731e-01, -3.22773392e-01, -3.25422400e-01,\n",
       "                     -3.30854244e-01, -3.36472237e-01, -3.43771539e-01, -3.51397887e-01,\n",
       "                     -3.56674944e-01, -3.58945092e-01, -3.59374001e-01, -3.65113813e-01,\n",
       "                     -3.67724780e-01, -3.72888938e-01, -3.74693449e-01, -3.80772496e-01,\n",
       "                     -3.93042588e-01, -3.95708933e-01, -4.00888441e-01, -4.05465108e-01,\n",
       "                     -4.11734721e-01, -4.14943852e-01, -4.16893804e-01, -4.20502985e-01,\n",
       "                     -4.35318071e-01, -4.36323096e-01, -4.36928378e-01, -4.41056053e-01,\n",
       "                     -4.41832752e-01, -4.44685821e-01, -4.46287103e-01, -4.51985124e-01,\n",
       "                     -4.56758402e-01, -4.66089730e-01, -4.70003629e-01, -4.81838087e-01,\n",
       "                     -4.85507816e-01, -4.86434171e-01, -4.89548225e-01, -4.92476485e-01,\n",
       "                     -4.95134294e-01, -5.10825624e-01, -5.21296924e-01, -5.24919387e-01,\n",
       "                     -5.26093096e-01, -5.38996501e-01, -5.40143685e-01, -5.50046337e-01,\n",
       "                     -5.59615788e-01, -5.70544858e-01, -5.87786665e-01, -5.95983432e-01,\n",
       "                     -5.97837001e-01, -6.16774202e-01, -6.19039208e-01, -6.24154309e-01,\n",
       "                     -6.41853886e-01, -6.43876132e-01, -6.71168274e-01, -6.75755438e-01,\n",
       "                     -6.93147181e-01, -7.59105148e-01, -7.64972915e-01, -7.80158558e-01,\n",
       "                     -7.88457360e-01, -8.10930216e-01, -8.47297860e-01, -8.69037847e-01,\n",
       "                     -8.75468737e-01, -8.87303195e-01, -8.93817876e-01, -9.16290732e-01,\n",
       "                     -9.55511445e-01, -9.80829253e-01, -1.03609193e+00, -1.09861229e+00,\n",
       "                     -1.20397280e+00, -1.38629436e+00, -1.50407740e+00, -1.60943791e+00,\n",
       "                     -1.79175947e+00, -3.45387764e+01]), auc_score=0.5259742676146142, privacy_risk=0.5180511418007145, accuracy=0.5180511418007145, tpr_ind=0.46500070992474796, tnr_ind=0.571101573676681, test_train_ratio=0.9924747976714469, dataset_size=[7043, 6990]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_0.0', fpr=array([0.        , 0.03957859, 0.04612756, 0.04982916, 0.05167995,\n",
       "                     0.05737472, 0.06193052, 0.06534738, 0.06634396, 0.06791002,\n",
       "                     0.06876424, 0.08072323, 0.0808656 , 0.09424829, 0.10763098,\n",
       "                     0.11531891, 0.11660023, 0.11759681, 0.12058656, 0.19860478,\n",
       "                     0.22508542, 0.23832574, 0.24943052, 0.25042711, 0.2559795 ,\n",
       "                     0.27263667, 0.27462984, 0.28915148, 0.31264237, 0.31833713,\n",
       "                     0.32844533, 0.33300114, 0.35449886, 0.36375285, 0.41685649,\n",
       "                     0.42397494, 0.43294419, 0.44661162, 0.45615034, 0.46113326,\n",
       "                     0.47907175, 0.48078018, 0.50056948, 0.51181663, 0.51722665,\n",
       "                     0.52078588, 0.52491458, 0.54171412, 0.55210706, 0.60364465,\n",
       "                     0.60634966, 0.61546128, 0.62414579, 0.62699317, 0.63055239,\n",
       "                     0.63895216, 0.67425968, 0.68436788, 0.69803531, 0.70145216,\n",
       "                     0.70373007, 0.70501139, 0.71212984, 0.72964123, 0.73917995,\n",
       "                     0.75170843, 0.75484055, 0.76267084, 0.78103645, 0.80111048,\n",
       "                     0.80210706, 0.80452733, 0.80595103, 0.80865604, 0.8184795 ,\n",
       "                     0.82161162, 0.82360478, 0.82431663, 0.8547836 , 0.8570615 ,\n",
       "                     0.86574601, 0.87072893, 0.88069476, 0.88425399, 0.88681663,\n",
       "                     0.8892369 , 0.89236902, 0.89906036, 0.90105353, 0.90447039,\n",
       "                     0.90760251, 0.90874146, 0.90959567, 0.91201595, 0.91899203,\n",
       "                     0.92070046, 0.92838838, 0.93451025, 0.93835421, 0.94006264,\n",
       "                     0.94205581, 0.94718109, 0.95045558, 0.95230638, 0.95472665,\n",
       "                     0.9558656 , 0.95914009, 0.96255695, 0.96341116, 0.96526196,\n",
       "                     0.96753986, 0.96896355, 0.96924829, 0.97038724, 0.97266515,\n",
       "                     0.97522779, 0.97907175, 0.98519362, 0.98619021, 0.988041  ,\n",
       "                     0.98875285, 0.98875285, 0.99117312, 0.99131549, 0.99259681,\n",
       "                     1.        ]), tpr=array([0.        , 0.04594093, 0.05193323, 0.05735483, 0.05992296,\n",
       "                     0.06577258, 0.07276359, 0.0770438 , 0.07832786, 0.08061064,\n",
       "                     0.08160936, 0.09373662, 0.09459267, 0.11085747, 0.12541019,\n",
       "                     0.13397061, 0.13596804, 0.1378228 , 0.14238836, 0.2208589 ,\n",
       "                     0.25124839, 0.26309031, 0.27478956, 0.27678699, 0.28277928,\n",
       "                     0.29861607, 0.30218291, 0.31873306, 0.3439863 , 0.35026395,\n",
       "                     0.358111  , 0.36010843, 0.38065345, 0.3912113 , 0.44828078,\n",
       "                     0.45512912, 0.46154944, 0.47538879, 0.48537595, 0.49065487,\n",
       "                     0.50720502, 0.50991582, 0.52560993, 0.53759452, 0.54344414,\n",
       "                     0.54829505, 0.5534313 , 0.56941076, 0.58267941, 0.62676559,\n",
       "                     0.62890569, 0.6386075 , 0.64888001, 0.65159081, 0.65715509,\n",
       "                     0.66714225, 0.70580682, 0.71365387, 0.73106007, 0.73391354,\n",
       "                     0.73648167, 0.73876445, 0.74475674, 0.76002283, 0.77043801,\n",
       "                     0.78056784, 0.78413468, 0.79098302, 0.80667713, 0.83021829,\n",
       "                     0.83135968, 0.8344985 , 0.83649593, 0.83934941, 0.85004994,\n",
       "                     0.85276074, 0.85575688, 0.85732629, 0.88600371, 0.88828649,\n",
       "                     0.89299472, 0.89713226, 0.90469396, 0.90854615, 0.91068626,\n",
       "                     0.91368241, 0.91682123, 0.92395492, 0.92638037, 0.92894849,\n",
       "                     0.9316593 , 0.93365673, 0.93479812, 0.93736624, 0.94278784,\n",
       "                     0.94435725, 0.95248966, 0.95719789, 0.95990869, 0.96204879,\n",
       "                     0.96404623, 0.96832644, 0.9701812 , 0.97246397, 0.97517478,\n",
       "                     0.97717221, 0.97931231, 0.98188044, 0.98259381, 0.98430589,\n",
       "                     0.98573263, 0.98673135, 0.98744471, 0.98787274, 0.98958482,\n",
       "                     0.99101156, 0.99272364, 0.99643316, 0.99714653, 0.99771722,\n",
       "                     0.99814524, 0.99857326, 0.99928663, 0.99942931, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -4.65200156e-02, -5.12932944e-02,\n",
       "                     -5.40672213e-02, -7.06175672e-02, -7.84716154e-02, -9.53101798e-02,\n",
       "                     -1.05360516e-01, -1.17783036e-01, -1.33531393e-01, -1.42316222e-01,\n",
       "                     -1.54150680e-01, -1.76456437e-01, -1.79048231e-01, -1.82321557e-01,\n",
       "                     -1.94156014e-01, -2.07639365e-01, -2.23143551e-01, -2.26773319e-01,\n",
       "                     -2.37129793e-01, -2.44598486e-01, -2.47241103e-01, -2.51314428e-01,\n",
       "                     -2.69663567e-01, -2.74076420e-01, -2.77631737e-01, -2.83362411e-01,\n",
       "                     -2.87682072e-01, -2.93347810e-01, -2.96731908e-01, -3.05381650e-01,\n",
       "                     -3.08301360e-01, -3.11055424e-01, -3.14810740e-01, -3.18453731e-01,\n",
       "                     -3.20471895e-01, -3.23128821e-01, -3.26215736e-01, -3.40325806e-01,\n",
       "                     -3.46276237e-01, -3.51397887e-01, -3.55765440e-01, -3.56674944e-01,\n",
       "                     -3.63965377e-01, -3.65459773e-01, -3.67724780e-01, -3.75251330e-01,\n",
       "                     -3.80055393e-01, -3.80340903e-01, -3.82992252e-01, -3.85662481e-01,\n",
       "                     -3.86772975e-01, -3.87765531e-01, -3.96881364e-01, -4.05465108e-01,\n",
       "                     -4.18904528e-01, -4.23483614e-01, -4.37725970e-01, -4.38254931e-01,\n",
       "                     -4.41832752e-01, -4.46287103e-01, -4.51985124e-01, -4.57069880e-01,\n",
       "                     -4.63130750e-01, -4.64707942e-01, -4.70003629e-01, -4.72604411e-01,\n",
       "                     -4.75669367e-01, -4.81303184e-01, -4.85507816e-01, -4.92476485e-01,\n",
       "                     -4.96436886e-01, -5.00775288e-01, -5.10825624e-01, -5.21296924e-01,\n",
       "                     -5.38996501e-01, -5.46543706e-01, -5.54628246e-01, -5.59615788e-01,\n",
       "                     -5.63935449e-01, -5.64529803e-01, -5.73002869e-01, -5.75364145e-01,\n",
       "                     -5.87786665e-01, -5.93063722e-01, -5.97837001e-01, -5.98836501e-01,\n",
       "                     -6.00773860e-01, -6.06135804e-01, -6.10909082e-01, -6.19039208e-01,\n",
       "                     -6.28608659e-01, -6.35988767e-01, -6.39079959e-01, -6.46627165e-01,\n",
       "                     -6.93147181e-01, -7.08185058e-01, -7.19122667e-01, -7.25937003e-01,\n",
       "                     -7.62140052e-01, -7.73189888e-01, -8.02346473e-01, -8.10930216e-01,\n",
       "                     -8.16761137e-01, -8.26678573e-01, -8.47297860e-01, -8.70828358e-01,\n",
       "                     -8.75468737e-01, -8.82389180e-01, -9.16290732e-01, -9.44461609e-01,\n",
       "                     -9.55511445e-01, -9.80829253e-01, -1.01160091e+00, -1.02961942e+00,\n",
       "                     -1.04145387e+00, -1.09861229e+00, -1.16315081e+00, -1.25276297e+00,\n",
       "                     -1.29928298e+00, -1.38629436e+00, -1.60943791e+00, -1.79175947e+00,\n",
       "                     -1.94591015e+00, -3.45387764e+01]), auc_score=0.5246586434103111, privacy_risk=0.5168765280955075, accuracy=0.5168765280955075, tpr_ind=0.7387644457126552, tnr_ind=0.2949886104783599, test_train_ratio=1.002140105578542, dataset_size=[7009, 7024])],\n",
       "             'subpopulation_1.0_label_1.0_mia_auc': [0.5506074111368129,\n",
       "              0.5432597008140455,\n",
       "              0.5620491985370065,\n",
       "              0.5557865144863272,\n",
       "              0.5467083855827444,\n",
       "              0.5650020817426361,\n",
       "              0.5478574438459565,\n",
       "              0.5520617468147885,\n",
       "              0.5512374246763074,\n",
       "              0.5620877501164312,\n",
       "              0.550742948958415,\n",
       "              0.561628421991638,\n",
       "              0.549430203032662,\n",
       "              0.5628894277040686,\n",
       "              0.563532612803265,\n",
       "              0.5582727844514777,\n",
       "              0.5421426835503057,\n",
       "              0.5607766950087706,\n",
       "              0.5569148335864078,\n",
       "              0.5594834634560816],\n",
       "             'subpopulation_1.0_label_1.0_mia_privacy_risk': [0.5378003997161296,\n",
       "              0.5305564873420622,\n",
       "              0.544674158744409,\n",
       "              0.5411786585946834,\n",
       "              0.5307762428077192,\n",
       "              0.5456039046071781,\n",
       "              0.5330477080356162,\n",
       "              0.5371101142063208,\n",
       "              0.5364446667436163,\n",
       "              0.5404475282686942,\n",
       "              0.5374633976088041,\n",
       "              0.5438305929057718,\n",
       "              0.5340738329910117,\n",
       "              0.5464295350527879,\n",
       "              0.5422687306898629,\n",
       "              0.5410288935095539,\n",
       "              0.5288890983602879,\n",
       "              0.542499688740429,\n",
       "              0.5414648910411622,\n",
       "              0.5437427256841464],\n",
       "             'subpopulation_1.0_label_1.0_mia_ppv': [0.6699999999999999,\n",
       "              0.6829268292682927,\n",
       "              0.6258992805755396,\n",
       "              0.6891891891891891,\n",
       "              0.6883116883116883,\n",
       "              0.6556776556776557,\n",
       "              0.6179775280898876,\n",
       "              0.5873015873015873,\n",
       "              0.6490066225165563,\n",
       "              0.6648936170212766,\n",
       "              0.6777777777777778,\n",
       "              0.6785714285714286,\n",
       "              0.7105263157894737,\n",
       "              0.6666666666666666,\n",
       "              0.6774193548387097,\n",
       "              0.7142857142857143,\n",
       "              0.6721311475409836,\n",
       "              0.7413793103448276,\n",
       "              0.7283950617283951,\n",
       "              0.6792452830188679],\n",
       "             'subpopulation_1.0_label_1.0_mia_attacker_advantage': [0.07560079943225906,\n",
       "              0.06111297468412441,\n",
       "              0.089348317488818,\n",
       "              0.08235731718936667,\n",
       "              0.061552485615438246,\n",
       "              0.09120780921435628,\n",
       "              0.06609541607123226,\n",
       "              0.07422022841264153,\n",
       "              0.0728893334872327,\n",
       "              0.0808950565373886,\n",
       "              0.07492679521760826,\n",
       "              0.08766118581154381,\n",
       "              0.06814766598202338,\n",
       "              0.09285907010557592,\n",
       "              0.08453746137972579,\n",
       "              0.0820577870191076,\n",
       "              0.0577781967205756,\n",
       "              0.08499937748085784,\n",
       "              0.08292978208232438,\n",
       "              0.08748545136829283],\n",
       "             'subpopulation_1.0_label_1.0_mia_result': [MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00994875, 0.01296352, 0.01477238, 0.01537534,\n",
       "                     0.02200784, 0.02230932, 0.0238167 , 0.02592704, 0.03768465,\n",
       "                     0.04039795, 0.04492011, 0.05155261, 0.05637624, 0.0608984 ,\n",
       "                     0.06270727, 0.06572204, 0.06933976, 0.07145011, 0.0807959 ,\n",
       "                     0.08290624, 0.09677419, 0.10702442, 0.1178776 , 0.12028942,\n",
       "                     0.12390715, 0.13053964, 0.13747362, 0.15345191, 0.1615918 ,\n",
       "                     0.16309919, 0.16792282, 0.17063612, 0.17696714, 0.18962918,\n",
       "                     0.19776907, 0.20018089, 0.21525475, 0.22761532, 0.23545372,\n",
       "                     0.24148327, 0.24811577, 0.25625565, 0.26379258, 0.28308713,\n",
       "                     0.28459451, 0.29424178, 0.29514622, 0.2993669 , 0.30509497,\n",
       "                     0.30961712, 0.3271028 , 0.33222792, 0.3364486 , 0.33886042,\n",
       "                     0.35483871, 0.357552  , 0.36177269, 0.36659632, 0.36750075,\n",
       "                     0.37322882, 0.39192041, 0.40096473, 0.41031052, 0.41513416,\n",
       "                     0.41875188, 0.42417847, 0.44196563, 0.45040699, 0.4582454 ,\n",
       "                     0.46517938, 0.47000301, 0.47663551, 0.49110642, 0.51070244,\n",
       "                     0.52125415, 0.54085017, 0.54356346, 0.55110039, 0.5589388 ,\n",
       "                     0.55984323, 0.56707869, 0.57160084, 0.5987338 , 0.60777811,\n",
       "                     0.61230027, 0.63641845, 0.64154356, 0.65269822, 0.65571299,\n",
       "                     0.66234549, 0.67380163, 0.6873681 , 0.70666265, 0.71088333,\n",
       "                     0.72083208, 0.72595719, 0.74555321, 0.7509798 , 0.75520048,\n",
       "                     0.76123003, 0.76514923, 0.77148025, 0.78896593, 0.79770877,\n",
       "                     0.80826048, 0.81640036, 0.82454025, 0.83056979, 0.83418752,\n",
       "                     0.85890865, 0.86162195, 0.86312933, 0.88272535, 0.89056376,\n",
       "                     0.89327706, 0.89659331, 0.90744649, 0.90985831, 0.91498342,\n",
       "                     0.91860115, 0.92854989, 0.92945433, 0.92945433, 0.93488092,\n",
       "                     0.94060898, 0.94603557, 0.94935182, 0.95960205, 0.96110944,\n",
       "                     0.96472716, 0.97527887, 0.97678625, 0.97980103, 0.98070546,\n",
       "                     0.98191137, 0.98432318, 0.98492614, 0.98522762, 1.        ]), tpr=array([0.        , 0.02035855, 0.023701  , 0.02643573, 0.02765117,\n",
       "                     0.03403221, 0.0355515 , 0.03980553, 0.04254026, 0.05712549,\n",
       "                     0.05986022, 0.06593741, 0.07687633, 0.08325737, 0.09024613,\n",
       "                     0.092677  , 0.09541173, 0.09996961, 0.10361592, 0.11394713,\n",
       "                     0.11607414, 0.13521726, 0.14281373, 0.15375266, 0.15679125,\n",
       "                     0.16043756, 0.16833789, 0.17411121, 0.1972045 , 0.20540869,\n",
       "                     0.20814342, 0.21239745, 0.2142206 , 0.2209055 , 0.23002127,\n",
       "                     0.23822546, 0.24217563, 0.26010331, 0.27408083, 0.28471589,\n",
       "                     0.29079307, 0.29838955, 0.30568216, 0.30902461, 0.33637192,\n",
       "                     0.33789122, 0.34883014, 0.35095716, 0.3558189 , 0.3625038 ,\n",
       "                     0.36493467, 0.37830447, 0.38407779, 0.3877241 , 0.38924339,\n",
       "                     0.41385597, 0.41567912, 0.41780614, 0.42236402, 0.42357946,\n",
       "                     0.42874506, 0.44515345, 0.45487694, 0.46338499, 0.46794287,\n",
       "                     0.47128532, 0.47827408, 0.49954421, 0.50683683, 0.51230629,\n",
       "                     0.51868733, 0.5262838 , 0.53479186, 0.55393497, 0.57398967,\n",
       "                     0.58462473, 0.60559101, 0.60893345, 0.61592221, 0.62473412,\n",
       "                     0.62746885, 0.63415375, 0.63931936, 0.67092069, 0.68337891,\n",
       "                     0.68763294, 0.70677606, 0.71011851, 0.72105743, 0.72409602,\n",
       "                     0.73381951, 0.7420237 , 0.75417806, 0.767244  , 0.77149802,\n",
       "                     0.78304467, 0.78638712, 0.80309936, 0.81343057, 0.81707688,\n",
       "                     0.82163476, 0.82649651, 0.83378912, 0.85293224, 0.86478274,\n",
       "                     0.86994834, 0.87420237, 0.87784868, 0.8821027 , 0.88605287,\n",
       "                     0.9155272 , 0.91765421, 0.91886964, 0.9325433 , 0.93862048,\n",
       "                     0.94105135, 0.9443938 , 0.95533273, 0.95715588, 0.95958675,\n",
       "                     0.96262534, 0.96900638, 0.97052568, 0.97113339, 0.97386813,\n",
       "                     0.97964145, 0.98268004, 0.98480705, 0.99027651, 0.99058037,\n",
       "                     0.99240352, 0.99635369, 0.99696141, 0.99756913, 0.99787299,\n",
       "                     0.9984807 , 0.99939228, 0.99969614, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -8.70113770e-02, -2.00670695e-01,\n",
       "                     -2.23143551e-01, -2.87682072e-01, -3.36472237e-01, -3.56674944e-01,\n",
       "                     -3.67724780e-01, -4.05465108e-01, -4.41832752e-01, -4.70003629e-01,\n",
       "                     -5.10825624e-01, -5.38996501e-01, -5.53385238e-01, -5.59615788e-01,\n",
       "                     -5.75364145e-01, -5.87786665e-01, -6.06135804e-01, -6.16774202e-01,\n",
       "                     -6.19039208e-01, -6.27549898e-01, -6.31271777e-01, -6.35988767e-01,\n",
       "                     -6.41853886e-01, -6.50587566e-01, -6.53926467e-01, -6.66478933e-01,\n",
       "                     -6.93147181e-01, -7.11496319e-01, -7.47214402e-01, -7.62140052e-01,\n",
       "                     -7.73189888e-01, -7.80158558e-01, -7.88457360e-01, -7.98507696e-01,\n",
       "                     -8.02346473e-01, -8.05264479e-01, -8.25318954e-01, -8.26678573e-01,\n",
       "                     -8.32909123e-01, -8.41567186e-01, -8.47297860e-01, -8.60201265e-01,\n",
       "                     -8.66166345e-01, -8.75468737e-01, -8.82389180e-01, -8.87303195e-01,\n",
       "                     -8.90972924e-01, -8.97941593e-01, -9.16290732e-01, -9.29535959e-01,\n",
       "                     -9.47381319e-01, -9.49080555e-01, -9.55511445e-01, -9.62137120e-01,\n",
       "                     -9.80829253e-01, -9.98528830e-01, -1.00552187e+00, -1.01160091e+00,\n",
       "                     -1.01693426e+00, -1.02165125e+00, -1.02290047e+00, -1.02450432e+00,\n",
       "                     -1.02961942e+00, -1.03609193e+00, -1.05416053e+00, -1.05480967e+00,\n",
       "                     -1.05605267e+00, -1.06087196e+00, -1.08261195e+00, -1.08518927e+00,\n",
       "                     -1.08663610e+00, -1.09330724e+00, -1.09861229e+00, -1.10809103e+00,\n",
       "                     -1.12718566e+00, -1.12846525e+00, -1.14117190e+00, -1.14356368e+00,\n",
       "                     -1.17007125e+00, -1.17163742e+00, -1.17411984e+00, -1.17569203e+00,\n",
       "                     -1.17677706e+00, -1.18958407e+00, -1.20397280e+00, -1.21302264e+00,\n",
       "                     -1.22050211e+00, -1.22377543e+00, -1.25276297e+00, -1.25804003e+00,\n",
       "                     -1.25988044e+00, -1.26923781e+00, -1.27296568e+00, -1.28966753e+00,\n",
       "                     -1.29098418e+00, -1.32538561e+00, -1.34117393e+00, -1.34373475e+00,\n",
       "                     -1.35239281e+00, -1.35454566e+00, -1.36524095e+00, -1.37029402e+00,\n",
       "                     -1.38629436e+00, -1.40089316e+00, -1.40399394e+00, -1.40691365e+00,\n",
       "                     -1.43848011e+00, -1.44238383e+00, -1.45597428e+00, -1.48807706e+00,\n",
       "                     -1.50407740e+00, -1.52121368e+00, -1.52605630e+00, -1.53147637e+00,\n",
       "                     -1.53393036e+00, -1.56977266e+00, -1.57553636e+00, -1.60943791e+00,\n",
       "                     -1.75785792e+00, -1.75949861e+00, -1.79175947e+00, -1.87180218e+00,\n",
       "                     -1.92990981e+00, -1.93075834e+00, -1.94591015e+00, -2.06142304e+00,\n",
       "                     -2.07944154e+00, -2.19722458e+00, -2.23359222e+00, -2.24723500e+00,\n",
       "                     -2.30258509e+00, -2.44234704e+00, -2.48490665e+00, -2.83321334e+00,\n",
       "                     -3.06027079e+00, -3.13549422e+00, -3.21887582e+00, -3.45387764e+01]), auc_score=0.5506074111368129, privacy_risk=0.5378003997161296, accuracy=0.5378003997161296, tpr_ind=0.6833789121847462, tnr_ind=0.39222188724751283, test_train_ratio=1.0079003342449104, dataset_size=[3291, 3317]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00769686, 0.01036116, 0.01154529, 0.01272943,\n",
       "                     0.01391356, 0.01539372, 0.01687389, 0.02013025, 0.02545885,\n",
       "                     0.02634695, 0.02812315, 0.02930728, 0.03226761, 0.03582001,\n",
       "                     0.04085258, 0.06009473, 0.06542333, 0.08318532, 0.09443458,\n",
       "                     0.10686797, 0.1187093 , 0.13499112, 0.14653641, 0.14801658,\n",
       "                     0.15216104, 0.15275311, 0.16459443, 0.16933097, 0.17169923,\n",
       "                     0.17525163, 0.18146832, 0.18768502, 0.18886915, 0.21047957,\n",
       "                     0.21166371, 0.23771462, 0.2714624 , 0.27975133, 0.2838958 ,\n",
       "                     0.29129663, 0.29692126, 0.29869745, 0.31409118, 0.35820012,\n",
       "                     0.36234458, 0.37625814, 0.38069864, 0.38602724, 0.38780343,\n",
       "                     0.39165187, 0.3955003 , 0.43605684, 0.47158082, 0.47424512,\n",
       "                     0.48342214, 0.49052694, 0.50296033, 0.52013025, 0.52782712,\n",
       "                     0.53137951, 0.54766134, 0.57371226, 0.58052102, 0.58318532,\n",
       "                     0.59561871, 0.59709888, 0.61042037, 0.64239195, 0.64860864,\n",
       "                     0.65275311, 0.65600947, 0.660746  , 0.66844287, 0.669627  ,\n",
       "                     0.68383659, 0.68590882, 0.69153345, 0.69982238, 0.70248668,\n",
       "                     0.72824156, 0.73149793, 0.73978686, 0.78537596, 0.78981646,\n",
       "                     0.79366489, 0.79928952, 0.80017762, 0.82652457, 0.83510953,\n",
       "                     0.84043813, 0.84961516, 0.85287152, 0.85701599, 0.86471285,\n",
       "                     0.86767318, 0.88543517, 0.89076377, 0.90171699, 0.90349319,\n",
       "                     0.91296625, 0.91474245, 0.93635287, 0.94049734, 0.9410894 ,\n",
       "                     0.9526347 , 0.95766726, 0.95973949, 0.96033156, 0.96033156,\n",
       "                     0.97158082, 0.97454115, 0.97454115, 0.97750148, 0.98075784,\n",
       "                     0.98253404, 1.        ]), tpr=array([0.        , 0.01733746, 0.02229102, 0.02383901, 0.02662539,\n",
       "                     0.02786378, 0.03065015, 0.03374613, 0.03931889, 0.04860681,\n",
       "                     0.05170279, 0.05263158, 0.05479876, 0.05975232, 0.06377709,\n",
       "                     0.07151703, 0.08916409, 0.09349845, 0.11702786, 0.12817337,\n",
       "                     0.14334365, 0.15913313, 0.17678019, 0.19164087, 0.19380805,\n",
       "                     0.19783282, 0.1996904 , 0.20866873, 0.21393189, 0.21764706,\n",
       "                     0.22105263, 0.22724458, 0.23405573, 0.23591331, 0.25975232,\n",
       "                     0.26130031, 0.28637771, 0.31609907, 0.325387  , 0.33034056,\n",
       "                     0.34024768, 0.34767802, 0.3498452 , 0.37058824, 0.40835913,\n",
       "                     0.41547988, 0.43374613, 0.4380805 , 0.44643963, 0.44891641,\n",
       "                     0.45201238, 0.45603715, 0.49164087, 0.5247678 , 0.53034056,\n",
       "                     0.53622291, 0.54055728, 0.55572755, 0.56934985, 0.57708978,\n",
       "                     0.58080495, 0.59226006, 0.62229102, 0.62755418, 0.62972136,\n",
       "                     0.64086687, 0.64365325, 0.65448916, 0.69473684, 0.70247678,\n",
       "                     0.70557276, 0.70773994, 0.71114551, 0.71517028, 0.71640867,\n",
       "                     0.73003096, 0.73343653, 0.73900929, 0.74489164, 0.74798762,\n",
       "                     0.76842105, 0.77027864, 0.77801858, 0.82879257, 0.83374613,\n",
       "                     0.83839009, 0.84210526, 0.84427245, 0.87027864, 0.87770898,\n",
       "                     0.88513932, 0.89535604, 0.89752322, 0.90185759, 0.90804954,\n",
       "                     0.90959752, 0.92260062, 0.92662539, 0.94086687, 0.94272446,\n",
       "                     0.9495356 , 0.95108359, 0.96656347, 0.96904025, 0.97027864,\n",
       "                     0.97801858, 0.98018576, 0.98173375, 0.98266254, 0.98297214,\n",
       "                     0.99318885, 0.99535604, 0.99597523, 0.99783282, 0.9993808 ,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.17783036e-01, -1.82321557e-01,\n",
       "                     -2.00670695e-01, -2.23143551e-01, -2.87682072e-01, -3.36472237e-01,\n",
       "                     -3.67724780e-01, -4.05465108e-01, -4.70003629e-01, -5.10825624e-01,\n",
       "                     -5.38996501e-01, -5.59615788e-01, -5.70544858e-01, -5.87786665e-01,\n",
       "                     -6.01339631e-01, -6.19039208e-01, -6.59699246e-01, -6.65748206e-01,\n",
       "                     -6.93147181e-01, -7.12565266e-01, -7.19122667e-01, -7.43919506e-01,\n",
       "                     -7.62140052e-01, -7.67255153e-01, -7.73189888e-01, -7.75838896e-01,\n",
       "                     -8.04372816e-01, -8.10930216e-01, -8.20980552e-01, -8.32909123e-01,\n",
       "                     -8.40783179e-01, -8.47297860e-01, -8.54691609e-01, -8.75468737e-01,\n",
       "                     -8.83665505e-01, -8.99483614e-01, -9.02867712e-01, -9.16290732e-01,\n",
       "                     -9.28713252e-01, -9.32820034e-01, -9.44461609e-01, -9.54362680e-01,\n",
       "                     -9.58030338e-01, -9.58850346e-01, -9.59415159e-01, -9.71860583e-01,\n",
       "                     -9.80829253e-01, -1.01160091e+00, -1.02961942e+00, -1.04596856e+00,\n",
       "                     -1.05718625e+00, -1.06374346e+00, -1.07992016e+00, -1.08091271e+00,\n",
       "                     -1.09861229e+00, -1.10539198e+00, -1.10615949e+00, -1.12492960e+00,\n",
       "                     -1.12601126e+00, -1.13401422e+00, -1.13571604e+00, -1.13707857e+00,\n",
       "                     -1.14513230e+00, -1.16820558e+00, -1.17007125e+00, -1.17203976e+00,\n",
       "                     -1.18219900e+00, -1.19996478e+00, -1.22377543e+00, -1.23214368e+00,\n",
       "                     -1.23969089e+00, -1.24171313e+00, -1.25276297e+00, -1.25923548e+00,\n",
       "                     -1.26566637e+00, -1.26851133e+00, -1.27506873e+00, -1.28093385e+00,\n",
       "                     -1.28680881e+00, -1.29928298e+00, -1.30291275e+00, -1.31686585e+00,\n",
       "                     -1.32175584e+00, -1.33500107e+00, -1.34373475e+00, -1.34992672e+00,\n",
       "                     -1.35300838e+00, -1.38629436e+00, -1.43706669e+00, -1.43796637e+00,\n",
       "                     -1.48807706e+00, -1.50407740e+00, -1.51512723e+00, -1.56861592e+00,\n",
       "                     -1.60943791e+00, -1.62470538e+00, -1.64362928e+00, -1.73460106e+00,\n",
       "                     -1.75314463e+00, -1.75785792e+00, -1.79175947e+00, -1.81237876e+00,\n",
       "                     -1.83258146e+00, -1.86872051e+00, -1.94591015e+00, -2.00148000e+00,\n",
       "                     -2.03688193e+00, -2.07944154e+00, -2.13470422e+00, -2.16496372e+00,\n",
       "                     -2.30258509e+00, -2.35137526e+00, -2.39789527e+00, -2.60268969e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5432597008140455, privacy_risk=0.5305564873420622, accuracy=0.5305564873420622, tpr_ind=0.44891640866873067, tnr_ind=0.6121965660153937, test_train_ratio=1.0458204334365324, dataset_size=[3230, 3378]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.01082707, 0.01323308, 0.01473684, 0.01503759,\n",
       "                     0.0156391 , 0.01774436, 0.02285714, 0.03458647, 0.03789474,\n",
       "                     0.03909774, 0.04150376, 0.0481203 , 0.04932331, 0.05233083,\n",
       "                     0.05443609, 0.0562406 , 0.06135338, 0.06556391, 0.06736842,\n",
       "                     0.06887218, 0.09654135, 0.10646617, 0.1281203 , 0.13353383,\n",
       "                     0.13744361, 0.13834586, 0.14406015, 0.15729323, 0.16150376,\n",
       "                     0.17984962, 0.18496241, 0.18977444, 0.19157895, 0.22887218,\n",
       "                     0.23218045, 0.23879699, 0.24030075, 0.24240602, 0.24571429,\n",
       "                     0.24691729, 0.26947368, 0.28270677, 0.30736842, 0.30887218,\n",
       "                     0.31067669, 0.31729323, 0.31879699, 0.32481203, 0.35157895,\n",
       "                     0.36030075, 0.36511278, 0.39548872, 0.39969925, 0.44661654,\n",
       "                     0.45894737, 0.48601504, 0.49413534, 0.52390977, 0.52962406,\n",
       "                     0.54556391, 0.54917293, 0.55097744, 0.55548872, 0.56030075,\n",
       "                     0.56210526, 0.56541353, 0.58586466, 0.59909774, 0.60360902,\n",
       "                     0.62255639, 0.62406015, 0.64210526, 0.65142857, 0.6562406 ,\n",
       "                     0.66105263, 0.6637594 , 0.70977444, 0.71488722, 0.71909774,\n",
       "                     0.72300752, 0.73172932, 0.73293233, 0.73954887, 0.74586466,\n",
       "                     0.75157895, 0.76090226, 0.76661654, 0.77052632, 0.77744361,\n",
       "                     0.79639098, 0.7993985 , 0.80180451, 0.81353383, 0.83699248,\n",
       "                     0.83819549, 0.84511278, 0.86165414, 0.86345865, 0.87759398,\n",
       "                     0.88210526, 0.88240602, 0.88601504, 0.88902256, 0.89112782,\n",
       "                     0.89443609, 0.89714286, 0.90225564, 0.90556391, 0.90977444,\n",
       "                     0.9118797 , 0.92902256, 0.93413534, 0.93684211, 0.94075188,\n",
       "                     0.94225564, 0.94345865, 0.94676692, 0.94917293, 0.95428571,\n",
       "                     0.95639098, 0.95759398, 0.96210526, 0.96240602, 0.96721805,\n",
       "                     0.9681203 , 0.97082707, 0.97112782, 1.        ]), tpr=array([0.        , 0.01675297, 0.02040816, 0.02193116, 0.02436796,\n",
       "                     0.02650015, 0.02954615, 0.03868413, 0.0563509 , 0.05970149,\n",
       "                     0.06396588, 0.06853488, 0.07310387, 0.07523606, 0.07889126,\n",
       "                     0.08406945, 0.08681084, 0.09137984, 0.09960402, 0.10325921,\n",
       "                     0.10539141, 0.13310996, 0.14224794, 0.1669205 , 0.17484009,\n",
       "                     0.17819068, 0.18001828, 0.18489187, 0.20103564, 0.20925982,\n",
       "                     0.23119098, 0.23545538, 0.23971977, 0.24550716, 0.28449589,\n",
       "                     0.28784648, 0.29698447, 0.29942126, 0.30246726, 0.30520865,\n",
       "                     0.30977764, 0.333841  , 0.34724337, 0.37892172, 0.38166311,\n",
       "                     0.38318611, 0.3904965 , 0.39232409, 0.39902528, 0.42369784,\n",
       "                     0.43131282, 0.43496802, 0.47121535, 0.47608894, 0.52177886,\n",
       "                     0.53274444, 0.56594578, 0.57447457, 0.60219312, 0.60706671,\n",
       "                     0.62899787, 0.63569906, 0.63813585, 0.64483704, 0.64696924,\n",
       "                     0.65031983, 0.65184283, 0.6682912 , 0.68169357, 0.68382577,\n",
       "                     0.70301553, 0.70484313, 0.7194639 , 0.73012489, 0.73560768,\n",
       "                     0.73987207, 0.74261346, 0.78434359, 0.78921718, 0.79500457,\n",
       "                     0.79744136, 0.80779775, 0.80962534, 0.81632653, 0.82089552,\n",
       "                     0.82515991, 0.8355163 , 0.83856229, 0.84313128, 0.85013707,\n",
       "                     0.86658544, 0.87115443, 0.87420043, 0.8879074 , 0.91318916,\n",
       "                     0.91410295, 0.91836735, 0.92720073, 0.92902833, 0.93968931,\n",
       "                     0.9436491 , 0.9445629 , 0.9466951 , 0.94913189, 0.95187329,\n",
       "                     0.95583308, 0.95887907, 0.96131587, 0.96314347, 0.96801706,\n",
       "                     0.96954005, 0.97806884, 0.98111483, 0.98355163, 0.98781602,\n",
       "                     0.98872982, 0.99025282, 0.99147122, 0.99238501, 0.99482181,\n",
       "                     0.99512641, 0.99543101, 0.9972586 , 0.9975632 , 0.9987816 ,\n",
       "                     0.9990862 , 0.9996954 , 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.54150680e-01, -1.82321557e-01,\n",
       "                     -2.23143551e-01, -2.51314428e-01, -2.62364264e-01, -2.87682072e-01,\n",
       "                     -4.05465108e-01, -4.35318071e-01, -4.51985124e-01, -4.70003629e-01,\n",
       "                     -5.10825624e-01, -5.38996501e-01, -5.59615788e-01, -5.67984038e-01,\n",
       "                     -5.75364145e-01, -5.87786665e-01, -5.95983432e-01, -6.06135804e-01,\n",
       "                     -6.19039208e-01, -6.48195793e-01, -6.76340062e-01, -6.93147181e-01,\n",
       "                     -7.30887509e-01, -7.37598943e-01, -7.73189888e-01, -7.82759339e-01,\n",
       "                     -7.83298278e-01, -7.98507696e-01, -8.10930216e-01, -8.26678573e-01,\n",
       "                     -8.47297860e-01, -8.54415328e-01, -8.55080001e-01, -8.60201265e-01,\n",
       "                     -8.61482495e-01, -8.64997437e-01, -8.75468737e-01, -8.93817876e-01,\n",
       "                     -9.02867712e-01, -9.13755876e-01, -9.16290732e-01, -9.20129508e-01,\n",
       "                     -9.38269639e-01, -9.55511445e-01, -9.65080896e-01, -9.80829253e-01,\n",
       "                     -9.86494991e-01, -9.90045908e-01, -1.00063188e+00, -1.01160091e+00,\n",
       "                     -1.01996916e+00, -1.03407377e+00, -1.03437002e+00, -1.04145387e+00,\n",
       "                     -1.04199339e+00, -1.06224464e+00, -1.06887032e+00, -1.07755888e+00,\n",
       "                     -1.07992016e+00, -1.09861229e+00, -1.13943428e+00, -1.14306405e+00,\n",
       "                     -1.14513230e+00, -1.15745279e+00, -1.16315081e+00, -1.17007125e+00,\n",
       "                     -1.17865500e+00, -1.18958407e+00, -1.19440335e+00, -1.20397280e+00,\n",
       "                     -1.21020335e+00, -1.21533656e+00, -1.22050211e+00, -1.23214368e+00,\n",
       "                     -1.23676263e+00, -1.23911446e+00, -1.25276297e+00, -1.26025364e+00,\n",
       "                     -1.28785429e+00, -1.29392104e+00, -1.29928298e+00, -1.30340670e+00,\n",
       "                     -1.30992138e+00, -1.31218639e+00, -1.31782656e+00, -1.33500107e+00,\n",
       "                     -1.35239281e+00, -1.36524095e+00, -1.38629436e+00, -1.40282366e+00,\n",
       "                     -1.41098697e+00, -1.44561094e+00, -1.46169238e+00, -1.46633707e+00,\n",
       "                     -1.47181653e+00, -1.47689126e+00, -1.50407740e+00, -1.52846885e+00,\n",
       "                     -1.52939520e+00, -1.54044504e+00, -1.55059741e+00, -1.55814462e+00,\n",
       "                     -1.56397554e+00, -1.60943791e+00, -1.64865863e+00, -1.68175857e+00,\n",
       "                     -1.70474809e+00, -1.71604765e+00, -1.72276660e+00, -1.79175947e+00,\n",
       "                     -1.80828877e+00, -1.87180218e+00, -1.94591015e+00, -1.99243016e+00,\n",
       "                     -2.00148000e+00, -2.07944154e+00, -2.19722458e+00, -2.30258509e+00,\n",
       "                     -2.48490665e+00, -2.56494936e+00, -2.59026717e+00, -2.70805020e+00,\n",
       "                     -2.74084002e+00, -3.13549422e+00, -3.52636052e+00, -3.58351894e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5620491985370065, privacy_risk=0.544674158744409, accuracy=0.544674158744409, tpr_ind=0.6448370392933293, tnr_ind=0.44451127819548875, test_train_ratio=1.0127931769722816, dataset_size=[3283, 3325]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00703794, 0.00979192, 0.01591187, 0.01927785,\n",
       "                     0.02050184, 0.02753978, 0.02876377, 0.03182375, 0.03427173,\n",
       "                     0.03947368, 0.04651163, 0.0498776 , 0.05599755, 0.0624235 ,\n",
       "                     0.06793146, 0.06976744, 0.07374541, 0.07619339, 0.10924113,\n",
       "                     0.12117503, 0.12576499, 0.12943696, 0.1373929 , 0.14014688,\n",
       "                     0.18237454, 0.18421053, 0.18849449, 0.20073439, 0.20899633,\n",
       "                     0.2126683 , 0.21664627, 0.22062424, 0.24112607, 0.25428397,\n",
       "                     0.25642595, 0.25826193, 0.27417381, 0.29375765, 0.3004896 ,\n",
       "                     0.30569155, 0.30783354, 0.3121175 , 0.36383109, 0.38219094,\n",
       "                     0.39596083, 0.41554468, 0.41982864, 0.42656059, 0.43604651,\n",
       "                     0.45807834, 0.46052632, 0.4623623 , 0.46419829, 0.47062424,\n",
       "                     0.47123623, 0.48255814, 0.48378213, 0.49816401, 0.53121175,\n",
       "                     0.5370257 , 0.53977968, 0.55813953, 0.56976744, 0.57374541,\n",
       "                     0.58231334, 0.59822521, 0.60434517, 0.61107711, 0.63372093,\n",
       "                     0.63555692, 0.63922889, 0.66064871, 0.6621787 , 0.66615667,\n",
       "                     0.67839657, 0.68329253, 0.72123623, 0.73898409, 0.74143207,\n",
       "                     0.75397797, 0.75917993, 0.76805386, 0.77233782, 0.78090575,\n",
       "                     0.78243574, 0.78824969, 0.79436965, 0.79834761, 0.80569155,\n",
       "                     0.81089351, 0.8127295 , 0.84118727, 0.84516524, 0.84791922,\n",
       "                     0.85281518, 0.85801714, 0.86444308, 0.87148103, 0.87851897,\n",
       "                     0.88096695, 0.89198286, 0.89259486, 0.89473684, 0.90973072,\n",
       "                     0.91462668, 0.91952264, 0.91982864, 0.92931457, 0.92992656,\n",
       "                     0.93359853, 0.93941248, 0.94277846, 0.94492044, 0.94645043,\n",
       "                     0.94736842, 0.95379437, 0.95501836, 0.95807834, 0.9626683 ,\n",
       "                     0.96603427, 0.96695226, 0.96909425, 0.97215422, 0.97368421,\n",
       "                     1.        ]), tpr=array([0.        , 0.01526946, 0.01826347, 0.02634731, 0.03113772,\n",
       "                     0.03263473, 0.04281437, 0.04550898, 0.04850299, 0.05269461,\n",
       "                     0.05808383, 0.06586826, 0.07005988, 0.0757485 , 0.08323353,\n",
       "                     0.08982036, 0.09161677, 0.09491018, 0.09850299, 0.13592814,\n",
       "                     0.15508982, 0.16227545, 0.16556886, 0.17365269, 0.17844311,\n",
       "                     0.22155689, 0.22365269, 0.22964072, 0.24520958, 0.25568862,\n",
       "                     0.25838323, 0.26227545, 0.26826347, 0.29461078, 0.30838323,\n",
       "                     0.31257485, 0.31556886, 0.33173653, 0.34790419, 0.35628743,\n",
       "                     0.35988024, 0.36407186, 0.36736527, 0.42754491, 0.44820359,\n",
       "                     0.46077844, 0.48233533, 0.48742515, 0.49640719, 0.50538922,\n",
       "                     0.52724551, 0.53023952, 0.53233533, 0.53562874, 0.54041916,\n",
       "                     0.54191617, 0.55508982, 0.55718563, 0.56976048, 0.60838323,\n",
       "                     0.61377246, 0.61826347, 0.63892216, 0.65209581, 0.65449102,\n",
       "                     0.66467066, 0.67634731, 0.68083832, 0.68802395, 0.70868263,\n",
       "                     0.71107784, 0.71497006, 0.73113772, 0.73263473, 0.73652695,\n",
       "                     0.74550898, 0.7491018 , 0.78772455, 0.81257485, 0.81616766,\n",
       "                     0.83173653, 0.83592814, 0.84580838, 0.84820359, 0.85598802,\n",
       "                     0.85868263, 0.86287425, 0.86706587, 0.87065868, 0.8757485 ,\n",
       "                     0.88023952, 0.88143713, 0.90359281, 0.90898204, 0.91047904,\n",
       "                     0.91526946, 0.91736527, 0.92185629, 0.9260479 , 0.93532934,\n",
       "                     0.93772455, 0.94610778, 0.94790419, 0.9494012 , 0.96347305,\n",
       "                     0.96526946, 0.96856287, 0.96916168, 0.9760479 , 0.97784431,\n",
       "                     0.97934132, 0.98263473, 0.98473054, 0.98622754, 0.98832335,\n",
       "                     0.98862275, 0.99251497, 0.99341317, 0.99461078, 0.99640719,\n",
       "                     0.99760479, 0.99790419, 0.99850299, 0.9997006 , 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.82321557e-01, -2.87682072e-01,\n",
       "                     -3.18453731e-01, -3.36472237e-01, -4.05465108e-01, -4.41832752e-01,\n",
       "                     -4.70003629e-01, -4.96436886e-01, -5.10825624e-01, -5.48565952e-01,\n",
       "                     -5.79818495e-01, -5.81921545e-01, -5.87786665e-01, -5.97837001e-01,\n",
       "                     -6.06135804e-01, -6.46627165e-01, -6.50587566e-01, -6.93147181e-01,\n",
       "                     -7.31466045e-01, -7.33969175e-01, -7.37598943e-01, -7.47214402e-01,\n",
       "                     -7.53771802e-01, -7.60286483e-01, -7.62140052e-01, -7.65467842e-01,\n",
       "                     -7.67255153e-01, -7.88457360e-01, -7.98507696e-01, -8.02346473e-01,\n",
       "                     -8.10930216e-01, -8.20980552e-01, -8.25318954e-01, -8.26678573e-01,\n",
       "                     -8.32909123e-01, -8.39329691e-01, -8.47297860e-01, -8.57450232e-01,\n",
       "                     -8.82389180e-01, -8.87303195e-01, -8.97941593e-01, -9.03271019e-01,\n",
       "                     -9.13387972e-01, -9.16290732e-01, -9.49080555e-01, -9.50976290e-01,\n",
       "                     -9.55511445e-01, -9.80829253e-01, -9.92744288e-01, -9.93251773e-01,\n",
       "                     -9.98528830e-01, -1.00330211e+00, -1.01160091e+00, -1.02961942e+00,\n",
       "                     -1.03609193e+00, -1.04982212e+00, -1.08261195e+00, -1.09861229e+00,\n",
       "                     -1.11696143e+00, -1.12059120e+00, -1.12247977e+00, -1.12846525e+00,\n",
       "                     -1.13943428e+00, -1.15577070e+00, -1.15671992e+00, -1.16315081e+00,\n",
       "                     -1.17865500e+00, -1.20397280e+00, -1.21639532e+00, -1.21924028e+00,\n",
       "                     -1.22050211e+00, -1.22377543e+00, -1.24171313e+00, -1.24319352e+00,\n",
       "                     -1.25276297e+00, -1.26923781e+00, -1.27825288e+00, -1.29928298e+00,\n",
       "                     -1.30625165e+00, -1.31218639e+00, -1.31567679e+00, -1.32175584e+00,\n",
       "                     -1.35702398e+00, -1.35812348e+00, -1.38629436e+00, -1.40399394e+00,\n",
       "                     -1.42711636e+00, -1.42946653e+00, -1.43508453e+00, -1.44691898e+00,\n",
       "                     -1.46425590e+00, -1.46633707e+00, -1.48160454e+00, -1.51787072e+00,\n",
       "                     -1.51982575e+00, -1.52605630e+00, -1.53532994e+00, -1.58329263e+00,\n",
       "                     -1.58412010e+00, -1.60943791e+00, -1.64222774e+00, -1.64865863e+00,\n",
       "                     -1.65111061e+00, -1.67397643e+00, -1.69644929e+00, -1.70474809e+00,\n",
       "                     -1.73204023e+00, -1.73460106e+00, -1.75785792e+00, -1.79175947e+00,\n",
       "                     -1.81528997e+00, -1.88706965e+00, -1.90423745e+00, -1.94591015e+00,\n",
       "                     -2.10787948e+00, -2.15948425e+00, -2.19722458e+00, -2.33537492e+00,\n",
       "                     -2.37490575e+00, -2.48490665e+00, -2.52572864e+00, -2.70805020e+00,\n",
       "                     -3.21887582e+00, -3.45387764e+01]), auc_score=0.5557865144863272, privacy_risk=0.5411786585946834, accuracy=0.5411786585946834, tpr_ind=0.6646706586826348, tnr_ind=0.4176866585067319, test_train_ratio=0.9784431137724551, dataset_size=[3340, 3268]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00727493, 0.00879054, 0.00909366, 0.01121552,\n",
       "                     0.01606547, 0.01727796, 0.01879357, 0.02030918, 0.02303728,\n",
       "                     0.02515914, 0.0342528 , 0.03910276, 0.04122461, 0.0424371 ,\n",
       "                     0.04274022, 0.04364959, 0.0451652 , 0.04698393, 0.05031828,\n",
       "                     0.05456199, 0.05819945, 0.06395878, 0.07911488, 0.08608669,\n",
       "                     0.08881479, 0.09214914, 0.10275841, 0.10639588, 0.11336769,\n",
       "                     0.14428615, 0.14458927, 0.14671112, 0.14974235, 0.15792664,\n",
       "                     0.16035162, 0.16520158, 0.16671719, 0.17035465, 0.18490452,\n",
       "                     0.19096696, 0.21248863, 0.22067293, 0.22612913, 0.23461655,\n",
       "                     0.23855714, 0.24371022, 0.25068202, 0.253107  , 0.27826614,\n",
       "                     0.30130343, 0.30736587, 0.3091846 , 0.31221582, 0.31979388,\n",
       "                     0.32919066, 0.33222189, 0.33616247, 0.36101849, 0.36192786,\n",
       "                     0.36738406, 0.37284025, 0.39527129, 0.40891179, 0.41406487,\n",
       "                     0.41830858, 0.41921794, 0.42437102, 0.47014247, 0.47893301,\n",
       "                     0.48469233, 0.52591694, 0.53228251, 0.54956047, 0.56259473,\n",
       "                     0.56896029, 0.57199151, 0.5759321 , 0.60806305, 0.61533798,\n",
       "                     0.63019097, 0.63534404, 0.640194  , 0.64898454, 0.65050015,\n",
       "                     0.65474386, 0.68414671, 0.73416187, 0.73537436, 0.7387087 ,\n",
       "                     0.75992725, 0.77781146, 0.77872082, 0.77993331, 0.78781449,\n",
       "                     0.79145196, 0.79508942, 0.80630494, 0.81388299, 0.81994544,\n",
       "                     0.82479539, 0.82964535, 0.83055471, 0.85328888, 0.85813883,\n",
       "                     0.86147317, 0.86147317, 0.86511064, 0.88966353, 0.89148227,\n",
       "                     0.89784783, 0.89936344, 0.90360715, 0.92331009, 0.92391634,\n",
       "                     0.93240376, 0.93604122, 0.93937557, 0.95089421, 0.95240982,\n",
       "                     0.95453168, 0.95665353, 0.95877539, 0.96059412, 0.96332222,\n",
       "                     0.96514095, 0.96756593, 0.96999091, 0.97908457, 0.97969082,\n",
       "                     0.98060018, 0.98211579, 0.98272204, 0.98423765, 1.        ]), tpr=array([0.        , 0.01601692, 0.01783016, 0.01934119, 0.02326987,\n",
       "                     0.02931399, 0.03112723, 0.0344515 , 0.03596253, 0.03807797,\n",
       "                     0.04140224, 0.05228166, 0.05802357, 0.06225446, 0.06527652,\n",
       "                     0.06769417, 0.07101843, 0.07524932, 0.07706256, 0.08099124,\n",
       "                     0.08582653, 0.09126624, 0.0988214 , 0.10939861, 0.11574494,\n",
       "                     0.11816259, 0.12178906, 0.12994862, 0.13448172, 0.14233908,\n",
       "                     0.18162587, 0.18464793, 0.18887882, 0.19280749, 0.20187368,\n",
       "                     0.20519794, 0.21335751, 0.21486854, 0.21909943, 0.23723179,\n",
       "                     0.24085827, 0.26291931, 0.27138108, 0.27682079, 0.28407374,\n",
       "                     0.28800242, 0.29374433, 0.3019039 , 0.30371714, 0.32577818,\n",
       "                     0.34874584, 0.35690541, 0.35902085, 0.36415836, 0.36869145,\n",
       "                     0.37836204, 0.38168631, 0.38349955, 0.41220913, 0.41523119,\n",
       "                     0.42278634, 0.42792384, 0.44907827, 0.46267755, 0.46841946,\n",
       "                     0.47567241, 0.47869447, 0.48383197, 0.52372318, 0.53430039,\n",
       "                     0.53671804, 0.58567543, 0.593835  , 0.60864309, 0.62194016,\n",
       "                     0.62828649, 0.63040193, 0.63191296, 0.66152916, 0.66787549,\n",
       "                     0.68600786, 0.68963433, 0.69567845, 0.70897552, 0.71048655,\n",
       "                     0.7129042 , 0.73859172, 0.78815352, 0.79087338, 0.79601088,\n",
       "                     0.81928075, 0.83439105, 0.83620429, 0.83831973, 0.84436386,\n",
       "                     0.84768812, 0.85010577, 0.85917196, 0.86461167, 0.87065579,\n",
       "                     0.87246902, 0.87669991, 0.87851315, 0.89785434, 0.90268963,\n",
       "                     0.90933817, 0.91054699, 0.91326685, 0.93502569, 0.93653672,\n",
       "                     0.93895437, 0.94016319, 0.94469628, 0.96282865, 0.96403747,\n",
       "                     0.97068601, 0.97310366, 0.97673013, 0.98337866, 0.98398308,\n",
       "                     0.98640073, 0.98821396, 0.9903294 , 0.99123602, 0.99274705,\n",
       "                     0.99395588, 0.9948625 , 0.99697794, 0.99818676, 0.99848897,\n",
       "                     0.99909338, 0.99939559, 0.99969779, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.54150680e-01, -1.82321557e-01,\n",
       "                     -2.07639365e-01, -2.23143551e-01, -2.87682072e-01, -3.10154928e-01,\n",
       "                     -3.36472237e-01, -3.56674944e-01, -3.74693449e-01, -4.05465108e-01,\n",
       "                     -4.22856851e-01, -4.51985124e-01, -4.70003629e-01, -4.85507816e-01,\n",
       "                     -4.92476485e-01, -4.96436886e-01, -5.10825624e-01, -5.26093096e-01,\n",
       "                     -5.59615788e-01, -5.75364145e-01, -5.87786665e-01, -6.06135804e-01,\n",
       "                     -6.19039208e-01, -6.28608659e-01, -6.50587566e-01, -6.55406853e-01,\n",
       "                     -6.59245629e-01, -6.73729095e-01, -6.93147181e-01, -7.41937345e-01,\n",
       "                     -7.62140052e-01, -7.67255153e-01, -7.73189888e-01, -7.80158558e-01,\n",
       "                     -7.81700578e-01, -7.88457360e-01, -7.94929875e-01, -8.03495238e-01,\n",
       "                     -8.10930216e-01, -8.21528347e-01, -8.26678573e-01, -8.47297860e-01,\n",
       "                     -8.82389180e-01, -9.00786545e-01, -9.05708623e-01, -9.08855753e-01,\n",
       "                     -9.16290732e-01, -9.19026712e-01, -9.21540088e-01, -9.38269639e-01,\n",
       "                     -9.44461609e-01, -9.50976290e-01, -9.55511445e-01, -9.65080896e-01,\n",
       "                     -9.69400557e-01, -9.80829253e-01, -9.87386654e-01, -9.93251773e-01,\n",
       "                     -1.00063188e+00, -1.01693426e+00, -1.01936292e+00, -1.02165125e+00,\n",
       "                     -1.02585293e+00, -1.02663879e+00, -1.02961942e+00, -1.03798767e+00,\n",
       "                     -1.04145387e+00, -1.04982212e+00, -1.05605267e+00, -1.07149905e+00,\n",
       "                     -1.07361099e+00, -1.09861229e+00, -1.10615949e+00, -1.12986483e+00,\n",
       "                     -1.14513230e+00, -1.16315081e+00, -1.17393430e+00, -1.17498527e+00,\n",
       "                     -1.18377010e+00, -1.20397280e+00, -1.20896035e+00, -1.21975667e+00,\n",
       "                     -1.22377543e+00, -1.25276297e+00, -1.25444223e+00, -1.26488433e+00,\n",
       "                     -1.26851133e+00, -1.27766052e+00, -1.28381569e+00, -1.29198368e+00,\n",
       "                     -1.29928298e+00, -1.31218639e+00, -1.32175584e+00, -1.33977435e+00,\n",
       "                     -1.35454566e+00, -1.38629436e+00, -1.41369334e+00, -1.42310833e+00,\n",
       "                     -1.42711636e+00, -1.43848011e+00, -1.46633707e+00, -1.47232870e+00,\n",
       "                     -1.47590652e+00, -1.48366853e+00, -1.50407740e+00, -1.54044504e+00,\n",
       "                     -1.59545167e+00, -1.60943791e+00, -1.63413053e+00, -1.65822808e+00,\n",
       "                     -1.66139765e+00, -1.68020698e+00, -1.70474809e+00, -1.72114190e+00,\n",
       "                     -1.79175947e+00, -1.83258146e+00, -1.91290385e+00, -1.94591015e+00,\n",
       "                     -1.96360973e+00, -1.96944065e+00, -1.98591548e+00, -1.99243016e+00,\n",
       "                     -2.05412373e+00, -2.07944154e+00, -2.12026354e+00, -2.16496372e+00,\n",
       "                     -2.19722458e+00, -2.39789527e+00, -2.60268969e+00, -2.89037176e+00,\n",
       "                     -3.40119738e+00, -3.43398720e+00, -3.45387764e+01]), auc_score=0.5467083855827444, privacy_risk=0.5307762428077192, accuracy=0.5307762428077192, tpr_ind=0.5938349954669084, tnr_ind=0.46771749014852987, test_train_ratio=0.9969779389543669, dataset_size=[3309, 3299]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.0091047 , 0.01062215, 0.01092564, 0.01365706,\n",
       "                     0.015478  , 0.0185129 , 0.01881639, 0.02124431, 0.02245827,\n",
       "                     0.02367223, 0.02852807, 0.03125948, 0.0339909 , 0.03550835,\n",
       "                     0.03915023, 0.04218513, 0.0430956 , 0.04522003, 0.04946889,\n",
       "                     0.05128983, 0.05402124, 0.0616085 , 0.06707132, 0.07496206,\n",
       "                     0.08042489, 0.08163885, 0.09286798, 0.09681335, 0.10500759,\n",
       "                     0.12382398, 0.14537178, 0.15295903, 0.15660091, 0.16084977,\n",
       "                     0.16449165, 0.16783005, 0.1754173 , 0.19271624, 0.19544765,\n",
       "                     0.21153263, 0.2276176 , 0.23641882, 0.23823976, 0.25037936,\n",
       "                     0.25341426, 0.25735964, 0.26282246, 0.26646434, 0.27132018,\n",
       "                     0.27526555, 0.27981791, 0.2831563 , 0.29104704, 0.30652504,\n",
       "                     0.31259484, 0.32261002, 0.33323217, 0.33687405, 0.34264036,\n",
       "                     0.35022762, 0.35508346, 0.35933232, 0.37420334, 0.37936267,\n",
       "                     0.39059181, 0.39423369, 0.415478  , 0.41699545, 0.44036419,\n",
       "                     0.46737481, 0.48983308, 0.50288316, 0.51320182, 0.51593323,\n",
       "                     0.53596358, 0.53930197, 0.55235205, 0.55842185, 0.56843703,\n",
       "                     0.57298938, 0.57723824, 0.58088012, 0.5875569 , 0.61517451,\n",
       "                     0.62336874, 0.62913505, 0.64188164, 0.64734446, 0.65402124,\n",
       "                     0.65827011, 0.66616085, 0.73626707, 0.74051593, 0.74385432,\n",
       "                     0.74567527, 0.75599393, 0.76327769, 0.76661608, 0.77298938,\n",
       "                     0.7875569 , 0.79544765, 0.81305008, 0.82003035, 0.82367223,\n",
       "                     0.82792109, 0.83216995, 0.84036419, 0.84248862, 0.84400607,\n",
       "                     0.84704097, 0.84734446, 0.86585736, 0.86616085, 0.87223065,\n",
       "                     0.87526555, 0.88983308, 0.9016692 , 0.90349014, 0.907739  ,\n",
       "                     0.91654021, 0.92746586, 0.9323217 , 0.93444613, 0.9383915 ,\n",
       "                     0.94203338, 0.94203338, 0.94415781, 0.95569044, 0.95751138,\n",
       "                     0.96145675, 0.96358118, 0.96752656, 0.96813354, 0.96965099,\n",
       "                     0.97177542, 0.9723824 , 0.97481032, 0.97602428, 0.97754173,\n",
       "                     0.97875569, 1.        ]), tpr=array([0.        , 0.0153939 , 0.01841232, 0.02022336, 0.02384546,\n",
       "                     0.02716571, 0.03259885, 0.03501358, 0.03893752, 0.04044673,\n",
       "                     0.0446725 , 0.05402958, 0.05765168, 0.06278298, 0.06429218,\n",
       "                     0.06761244, 0.07274374, 0.07546031, 0.08119529, 0.0842137 ,\n",
       "                     0.09055237, 0.10051313, 0.10896468, 0.11500151, 0.12767884,\n",
       "                     0.13401751, 0.13643224, 0.15122246, 0.15454271, 0.16540899,\n",
       "                     0.1859342 , 0.20464835, 0.21309991, 0.21642016, 0.22245699,\n",
       "                     0.22758829, 0.23392695, 0.24479324, 0.26260187, 0.26592212,\n",
       "                     0.27950498, 0.29761545, 0.30365228, 0.30576517, 0.31934802,\n",
       "                     0.32266828, 0.32629037, 0.3323272 , 0.3374585 , 0.34379716,\n",
       "                     0.34651373, 0.35587081, 0.36039843, 0.37247208, 0.38967703,\n",
       "                     0.39661938, 0.40748566, 0.41593722, 0.4216722 , 0.42891639,\n",
       "                     0.43495321, 0.44038636, 0.44521582, 0.46423181, 0.47057048,\n",
       "                     0.48143676, 0.48415334, 0.50377302, 0.50528222, 0.52882584,\n",
       "                     0.55297314, 0.57229097, 0.58466647, 0.59794748, 0.60096589,\n",
       "                     0.61696348, 0.61968005, 0.63356474, 0.64261998, 0.65137338,\n",
       "                     0.65499547, 0.66042861, 0.66374887, 0.66948385, 0.69514036,\n",
       "                     0.70359191, 0.70872321, 0.71777845, 0.72200423, 0.72653184,\n",
       "                     0.73105946, 0.73588892, 0.80470872, 0.80772714, 0.80984002,\n",
       "                     0.81104739, 0.81980078, 0.82855418, 0.83368548, 0.83911862,\n",
       "                     0.84907938, 0.85481437, 0.87201932, 0.8777543 , 0.87956535,\n",
       "                     0.88107455, 0.88439481, 0.89375189, 0.89465741, 0.89707214,\n",
       "                     0.90069423, 0.90129792, 0.92001207, 0.9209176 , 0.92544522,\n",
       "                     0.92846363, 0.93691518, 0.94355569, 0.94476305, 0.94808331,\n",
       "                     0.95955327, 0.96830667, 0.97132508, 0.97283429, 0.97464534,\n",
       "                     0.97736191, 0.97766375, 0.97887111, 0.98581346, 0.98702083,\n",
       "                     0.9912466 , 0.99185029, 0.99517054, 0.99577422, 0.99698159,\n",
       "                     0.99758527, 0.99818895, 0.99879264, 0.99939632, 0.99969816,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -9.53101798e-02, -1.54150680e-01,\n",
       "                     -2.23143551e-01, -2.41162057e-01, -2.87682072e-01, -3.18453731e-01,\n",
       "                     -3.25422400e-01, -3.36472237e-01, -4.05465108e-01, -4.16160397e-01,\n",
       "                     -4.59532329e-01, -4.62623522e-01, -4.70003629e-01, -4.92476485e-01,\n",
       "                     -4.98991166e-01, -5.10825624e-01, -5.21296924e-01, -5.30628251e-01,\n",
       "                     -5.38996501e-01, -5.46543706e-01, -5.59615788e-01, -5.87786665e-01,\n",
       "                     -6.06135804e-01, -6.19039208e-01, -6.28608659e-01, -6.40779195e-01,\n",
       "                     -6.46627165e-01, -6.79160939e-01, -6.85767073e-01, -6.93147181e-01,\n",
       "                     -7.28238500e-01, -7.37598943e-01, -7.41937345e-01, -7.50305594e-01,\n",
       "                     -7.62140052e-01, -7.73189888e-01, -7.74492820e-01, -7.80158558e-01,\n",
       "                     -7.88457360e-01, -8.03495238e-01, -8.10930216e-01, -8.26678573e-01,\n",
       "                     -8.47297860e-01, -8.60201265e-01, -8.69037847e-01, -8.75468737e-01,\n",
       "                     -8.80358723e-01, -8.87303195e-01, -8.93817876e-01, -8.96746136e-01,\n",
       "                     -9.02867712e-01, -9.16290732e-01, -9.19793362e-01, -9.24948795e-01,\n",
       "                     -9.27340568e-01, -9.30475367e-01, -9.47381319e-01, -9.49080555e-01,\n",
       "                     -9.55511445e-01, -9.59775844e-01, -9.65080896e-01, -9.80829253e-01,\n",
       "                     -9.98528830e-01, -1.01160091e+00, -1.02165125e+00, -1.02410976e+00,\n",
       "                     -1.02961942e+00, -1.03236290e+00, -1.03850836e+00, -1.05060307e+00,\n",
       "                     -1.05711256e+00, -1.05999745e+00, -1.06471074e+00, -1.09861229e+00,\n",
       "                     -1.13497993e+00, -1.14117190e+00, -1.16315081e+00, -1.17599895e+00,\n",
       "                     -1.17865500e+00, -1.20397280e+00, -1.21302264e+00, -1.21444410e+00,\n",
       "                     -1.22377543e+00, -1.24250647e+00, -1.24432410e+00, -1.25276297e+00,\n",
       "                     -1.27296568e+00, -1.28093385e+00, -1.29928298e+00, -1.30494872e+00,\n",
       "                     -1.30524603e+00, -1.30833282e+00, -1.31218639e+00, -1.32175584e+00,\n",
       "                     -1.32405205e+00, -1.33318454e+00, -1.37147928e+00, -1.38629436e+00,\n",
       "                     -1.39384157e+00, -1.39936644e+00, -1.42078054e+00, -1.42500887e+00,\n",
       "                     -1.42711636e+00, -1.43508453e+00, -1.45225233e+00, -1.45636192e+00,\n",
       "                     -1.46633707e+00, -1.47590652e+00, -1.48538526e+00, -1.50407740e+00,\n",
       "                     -1.51831251e+00, -1.54044504e+00, -1.56861592e+00, -1.58923521e+00,\n",
       "                     -1.60943791e+00, -1.62745642e+00, -1.65822808e+00, -1.67964217e+00,\n",
       "                     -1.68053383e+00, -1.75069798e+00, -1.77495235e+00, -1.79175947e+00,\n",
       "                     -1.89711998e+00, -1.91364929e+00, -1.94591015e+00, -2.01490302e+00,\n",
       "                     -2.02929176e+00, -2.07944154e+00, -2.12311661e+00, -2.14006616e+00,\n",
       "                     -2.14539951e+00, -2.19722458e+00, -2.25129180e+00, -2.30258509e+00,\n",
       "                     -2.44234704e+00, -2.63905733e+00, -2.70805020e+00, -2.89037176e+00,\n",
       "                     -2.99573227e+00, -3.45387764e+01]), auc_score=0.5650020817426361, privacy_risk=0.5456039046071781, accuracy=0.5456039046071781, tpr_ind=0.4705704799275581, tnr_ind=0.6206373292867982, test_train_ratio=0.99456685783278, dataset_size=[3313, 3295]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.01027811, 0.01299879, 0.01481258, 0.01632406,\n",
       "                     0.01874244, 0.02055623, 0.02237001, 0.02871826, 0.03748489,\n",
       "                     0.03960097, 0.04081016, 0.04292624, 0.04504232, 0.04625151,\n",
       "                     0.04927449, 0.05320435, 0.05592503, 0.05713422, 0.0598549 ,\n",
       "                     0.06711004, 0.0716445 , 0.07859734, 0.08010883, 0.08131802,\n",
       "                     0.08434099, 0.09613059, 0.10066505, 0.1314994 , 0.13905683,\n",
       "                     0.14873035, 0.16324063, 0.16928658, 0.17472793, 0.17654172,\n",
       "                     0.18712213, 0.18833132, 0.18984281, 0.191052  , 0.19256348,\n",
       "                     0.19407497, 0.19830713, 0.2258162 , 0.23488513, 0.24667473,\n",
       "                     0.25392987, 0.25544135, 0.26844015, 0.27206771, 0.27841596,\n",
       "                     0.28657799, 0.29141475, 0.29564692, 0.35519952, 0.36487304,\n",
       "                     0.37484885, 0.38754534, 0.39056832, 0.4041717 , 0.40749698,\n",
       "                     0.44437727, 0.45133011, 0.45798065, 0.45949214, 0.46160822,\n",
       "                     0.46584039, 0.47128174, 0.48518742, 0.53295042, 0.54625151,\n",
       "                     0.55592503, 0.56076179, 0.56559855, 0.57073761, 0.57587666,\n",
       "                     0.58464329, 0.6073156 , 0.61064087, 0.61396614, 0.63875453,\n",
       "                     0.63935913, 0.64207981, 0.64752116, 0.66837969, 0.67261185,\n",
       "                     0.67775091, 0.69316808, 0.69558646, 0.70495768, 0.70707376,\n",
       "                     0.72793229, 0.73458283, 0.74667473, 0.75513906, 0.78839178,\n",
       "                     0.79171705, 0.7971584 , 0.80139057, 0.80350665, 0.84038694,\n",
       "                     0.84068924, 0.85852479, 0.86033857, 0.8685006 , 0.87273277,\n",
       "                     0.87726723, 0.88029021, 0.88694075, 0.89147521, 0.8929867 ,\n",
       "                     0.89903265, 0.90356711, 0.90779927, 0.90961306, 0.91203144,\n",
       "                     0.91928658, 0.92986699, 0.93168077, 0.93651753, 0.94770254,\n",
       "                     0.94981862, 0.9519347 , 0.9528416 , 0.96281741, 0.96795647,\n",
       "                     0.96886336, 0.97097944, 0.97158404, 0.97158404, 0.9764208 ,\n",
       "                     0.9767231 , 0.98367594, 0.98579202, 0.9885127 , 1.        ]), tpr=array([0.        , 0.01666667, 0.02030303, 0.02242424, 0.02393939,\n",
       "                     0.02757576, 0.03060606, 0.03242424, 0.03848485, 0.0530303 ,\n",
       "                     0.05727273, 0.06090909, 0.06393939, 0.06818182, 0.07      ,\n",
       "                     0.0730303 , 0.07757576, 0.08      , 0.08151515, 0.08636364,\n",
       "                     0.09727273, 0.10363636, 0.11121212, 0.11393939, 0.11757576,\n",
       "                     0.12151515, 0.1369697 , 0.1430303 , 0.17969697, 0.19212121,\n",
       "                     0.20181818, 0.22090909, 0.22575758, 0.22818182, 0.23      ,\n",
       "                     0.23939394, 0.24090909, 0.24363636, 0.24757576, 0.24878788,\n",
       "                     0.25333333, 0.25666667, 0.28090909, 0.28727273, 0.29757576,\n",
       "                     0.30242424, 0.30454545, 0.32242424, 0.32515152, 0.33090909,\n",
       "                     0.34181818, 0.34787879, 0.35242424, 0.40939394, 0.42090909,\n",
       "                     0.43424242, 0.44333333, 0.44545455, 0.46212121, 0.4669697 ,\n",
       "                     0.49242424, 0.50151515, 0.50636364, 0.50969697, 0.51151515,\n",
       "                     0.51545455, 0.51969697, 0.53181818, 0.59363636, 0.60333333,\n",
       "                     0.6130303 , 0.61787879, 0.62424242, 0.63151515, 0.63606061,\n",
       "                     0.64515152, 0.66969697, 0.67121212, 0.67545455, 0.70454545,\n",
       "                     0.70545455, 0.70787879, 0.71242424, 0.73363636, 0.73575758,\n",
       "                     0.73969697, 0.74848485, 0.75151515, 0.75666667, 0.75848485,\n",
       "                     0.77818182, 0.78484848, 0.79575758, 0.80454545, 0.83545455,\n",
       "                     0.83818182, 0.84242424, 0.84909091, 0.85090909, 0.88757576,\n",
       "                     0.88909091, 0.9069697 , 0.90787879, 0.91393939, 0.92333333,\n",
       "                     0.92606061, 0.92818182, 0.93333333, 0.93606061, 0.93818182,\n",
       "                     0.94272727, 0.94424242, 0.94666667, 0.94818182, 0.94878788,\n",
       "                     0.95545455, 0.96393939, 0.96545455, 0.96787879, 0.9769697 ,\n",
       "                     0.97848485, 0.98030303, 0.98151515, 0.99030303, 0.99121212,\n",
       "                     0.99212121, 0.9930303 , 0.99363636, 0.99393939, 0.99575758,\n",
       "                     0.99636364, 0.99878788, 0.99939394, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -8.00427077e-02, -1.33531393e-01,\n",
       "                     -1.82321557e-01, -2.23143551e-01, -2.62364264e-01, -2.87682072e-01,\n",
       "                     -3.36472237e-01, -4.05465108e-01, -4.51985124e-01, -4.59532329e-01,\n",
       "                     -4.70003629e-01, -4.96436886e-01, -5.10825624e-01, -5.30628251e-01,\n",
       "                     -5.50046337e-01, -5.59615788e-01, -5.87786665e-01, -5.94707108e-01,\n",
       "                     -6.06135804e-01, -6.19039208e-01, -6.31271777e-01, -6.35988767e-01,\n",
       "                     -6.50587566e-01, -6.53926467e-01, -6.63294217e-01, -6.67829373e-01,\n",
       "                     -6.93147181e-01, -7.05268541e-01, -7.38956717e-01, -7.47214402e-01,\n",
       "                     -7.50305594e-01, -7.53771802e-01, -7.73189888e-01, -7.85520501e-01,\n",
       "                     -7.88457360e-01, -7.98507696e-01, -8.02346473e-01, -8.10930216e-01,\n",
       "                     -8.18310324e-01, -8.20980552e-01, -8.27459518e-01, -8.47297860e-01,\n",
       "                     -8.55666110e-01, -8.64997437e-01, -8.87303195e-01, -8.92275856e-01,\n",
       "                     -8.93817876e-01, -9.05708623e-01, -9.16290732e-01, -9.36093359e-01,\n",
       "                     -9.55511445e-01, -9.62036754e-01, -9.67584026e-01, -9.69400557e-01,\n",
       "                     -9.80829253e-01, -9.98528830e-01, -1.00330211e+00, -1.01160091e+00,\n",
       "                     -1.02876872e+00, -1.02961942e+00, -1.03407377e+00, -1.03609193e+00,\n",
       "                     -1.04145387e+00, -1.04596856e+00, -1.04982212e+00, -1.06471074e+00,\n",
       "                     -1.07044141e+00, -1.07755888e+00, -1.08814099e+00, -1.09861229e+00,\n",
       "                     -1.11436065e+00, -1.12601126e+00, -1.14209740e+00, -1.15267951e+00,\n",
       "                     -1.16237891e+00, -1.16315081e+00, -1.16760516e+00, -1.16899309e+00,\n",
       "                     -1.20397280e+00, -1.21639532e+00, -1.22377543e+00, -1.22796831e+00,\n",
       "                     -1.23214368e+00, -1.24171313e+00, -1.24782469e+00, -1.25276297e+00,\n",
       "                     -1.27766052e+00, -1.29928298e+00, -1.31867417e+00, -1.32779815e+00,\n",
       "                     -1.32913595e+00, -1.33318454e+00, -1.35644140e+00, -1.35812348e+00,\n",
       "                     -1.38629436e+00, -1.40876722e+00, -1.42711636e+00, -1.43469090e+00,\n",
       "                     -1.43508453e+00, -1.46372610e+00, -1.46633707e+00, -1.48160454e+00,\n",
       "                     -1.49326648e+00, -1.51634749e+00, -1.51982575e+00, -1.53623451e+00,\n",
       "                     -1.54044504e+00, -1.55059741e+00, -1.55462968e+00, -1.56861592e+00,\n",
       "                     -1.60943791e+00, -1.68639895e+00, -1.70474809e+00, -1.76098781e+00,\n",
       "                     -1.77978328e+00, -1.79175947e+00, -1.81237876e+00, -1.82991124e+00,\n",
       "                     -1.85629799e+00, -1.87180218e+00, -1.90954250e+00, -1.91590790e+00,\n",
       "                     -1.94591015e+00, -2.15948425e+00, -2.19722458e+00, -2.30258509e+00,\n",
       "                     -2.39789527e+00, -2.45673577e+00, -2.48490665e+00, -2.50552594e+00,\n",
       "                     -2.52572864e+00, -2.56494936e+00, -3.45387764e+01]), auc_score=0.5478574438459565, privacy_risk=0.5330477080356162, accuracy=0.5330477080356162, tpr_ind=0.7054545454545454, tnr_ind=0.3606408706166868, test_train_ratio=1.0024242424242424, dataset_size=[3300, 3308]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.01347626, 0.01562021, 0.01592649, 0.018683  ,\n",
       "                     0.02358346, 0.02603369, 0.02725881, 0.03215926, 0.03522205,\n",
       "                     0.03767228, 0.04931087, 0.05298622, 0.05451761, 0.05696784,\n",
       "                     0.05880551, 0.05972435, 0.06217458, 0.0661562 , 0.07013783,\n",
       "                     0.07258806, 0.07503828, 0.07779479, 0.07932619, 0.08422665,\n",
       "                     0.09035222, 0.09310873, 0.09525268, 0.11056662, 0.11393568,\n",
       "                     0.11607963, 0.12067381, 0.13016845, 0.13323124, 0.13537519,\n",
       "                     0.14701378, 0.16140888, 0.16202144, 0.16355283, 0.17825421,\n",
       "                     0.18070444, 0.18744257, 0.2042879 , 0.20796325, 0.2101072 ,\n",
       "                     0.22082695, 0.22480858, 0.22725881, 0.23522205, 0.25880551,\n",
       "                     0.26156202, 0.27871363, 0.29372129, 0.30045942, 0.35160796,\n",
       "                     0.35436447, 0.3611026 , 0.37641654, 0.38774885, 0.39448698,\n",
       "                     0.40091884, 0.40336907, 0.40918836, 0.4101072 , 0.41776417,\n",
       "                     0.4330781 , 0.46003063, 0.46401225, 0.46830015, 0.46983155,\n",
       "                     0.4863706 , 0.48759571, 0.52128637, 0.52281776, 0.5280245 ,\n",
       "                     0.53261868, 0.54333844, 0.55528331, 0.55834609, 0.56171516,\n",
       "                     0.57243492, 0.57304747, 0.5797856 , 0.58009188, 0.61071975,\n",
       "                     0.61531394, 0.62725881, 0.63950995, 0.64257274, 0.65145482,\n",
       "                     0.65880551, 0.66646248, 0.66860643, 0.70107198, 0.71332312,\n",
       "                     0.72312404, 0.72679939, 0.75375191, 0.76018377, 0.76324655,\n",
       "                     0.76875957, 0.77519142, 0.78652374, 0.78958652, 0.80551302,\n",
       "                     0.80949464, 0.81531394, 0.82174579, 0.82205207, 0.84471669,\n",
       "                     0.84869832, 0.8517611 , 0.856049  , 0.86952527, 0.88116386,\n",
       "                     0.88514548, 0.88606432, 0.88943338, 0.89770291, 0.90168453,\n",
       "                     0.90290965, 0.91454824, 0.91822358, 0.92863706, 0.93476263,\n",
       "                     0.93568147, 0.93935681, 0.94150077, 0.943951  , 0.94915773,\n",
       "                     0.95865237, 0.95926493, 0.96018377, 0.96814701, 0.96906585,\n",
       "                     0.96967841, 0.97243492, 0.97335375, 0.97488515, 0.98070444,\n",
       "                     1.        ]), tpr=array([0.        , 0.01794795, 0.02093928, 0.02213581, 0.02542626,\n",
       "                     0.02961412, 0.03350284, 0.03619503, 0.04068202, 0.04486988,\n",
       "                     0.04995513, 0.06192043, 0.06700568, 0.07149267, 0.07478313,\n",
       "                     0.07627879, 0.07867185, 0.08196231, 0.08615016, 0.09063715,\n",
       "                     0.09362848, 0.09991026, 0.10230332, 0.10409812, 0.1103799 ,\n",
       "                     0.11965301, 0.12473826, 0.12772958, 0.14657493, 0.14986539,\n",
       "                     0.15405325, 0.1591385 , 0.1720012 , 0.17648818, 0.18037691,\n",
       "                     0.19473527, 0.20759797, 0.20999103, 0.21417888, 0.22853724,\n",
       "                     0.2318277 , 0.23990428, 0.2566557 , 0.26293748, 0.26473228,\n",
       "                     0.27699671, 0.28118456, 0.28507329, 0.2943464 , 0.32186659,\n",
       "                     0.32455878, 0.34101107, 0.35357463, 0.35746336, 0.40412803,\n",
       "                     0.40622196, 0.4148968 , 0.43134909, 0.43942567, 0.44510918,\n",
       "                     0.45348489, 0.45617709, 0.46395453, 0.46694586, 0.47711636,\n",
       "                     0.49207299, 0.52049058, 0.52408017, 0.52796889, 0.53096022,\n",
       "                     0.55189949, 0.55399342, 0.58869279, 0.59198325, 0.5970685 ,\n",
       "                     0.60305115, 0.61561472, 0.62518696, 0.62937481, 0.63326354,\n",
       "                     0.64403231, 0.6458271 , 0.65061322, 0.65210888, 0.67962908,\n",
       "                     0.68740652, 0.69997009, 0.71373018, 0.71552498, 0.72001197,\n",
       "                     0.72509722, 0.73347293, 0.73407119, 0.76877057, 0.77684714,\n",
       "                     0.79000897, 0.79270117, 0.81633264, 0.82022136, 0.82171702,\n",
       "                     0.82650314, 0.83398145, 0.84295543, 0.84534849, 0.86299731,\n",
       "                     0.8665869 , 0.87137302, 0.87735567, 0.87915046, 0.89829494,\n",
       "                     0.9024828 , 0.90607239, 0.91115764, 0.92102902, 0.92940473,\n",
       "                     0.93478911, 0.93598564, 0.93867783, 0.94436135, 0.94645528,\n",
       "                     0.94735268, 0.95991624, 0.96290757, 0.97218068, 0.97666766,\n",
       "                     0.97786419, 0.97995812, 0.98145378, 0.98205205, 0.98384684,\n",
       "                     0.98982949, 0.99042776, 0.99132516, 0.99371822, 0.99431648,\n",
       "                     0.99491475, 0.99581214, 0.99670954, 0.99760694, 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.82321557e-01, -2.23143551e-01,\n",
       "                     -2.41162057e-01, -2.51314428e-01, -2.68263987e-01, -2.87682072e-01,\n",
       "                     -3.36472237e-01, -3.56674944e-01, -3.67724780e-01, -4.05465108e-01,\n",
       "                     -4.24883194e-01, -4.27444015e-01, -4.35318071e-01, -4.70003629e-01,\n",
       "                     -4.85507816e-01, -4.92476485e-01, -4.96436886e-01, -5.10825624e-01,\n",
       "                     -5.30628251e-01, -5.38996501e-01, -5.59615788e-01, -6.06135804e-01,\n",
       "                     -6.19039208e-01, -6.26455806e-01, -6.32522559e-01, -6.41853886e-01,\n",
       "                     -6.44357016e-01, -6.46627165e-01, -6.56779536e-01, -6.63294217e-01,\n",
       "                     -6.93147181e-01, -7.25937003e-01, -7.30887509e-01, -7.43919506e-01,\n",
       "                     -7.49659391e-01, -7.53771802e-01, -7.62140052e-01, -7.73189888e-01,\n",
       "                     -7.80158558e-01, -7.98507696e-01, -8.18835396e-01, -8.26678573e-01,\n",
       "                     -8.47297860e-01, -8.50776125e-01, -8.57450232e-01, -8.69037847e-01,\n",
       "                     -8.83500909e-01, -8.85383194e-01, -8.93817876e-01, -9.12647741e-01,\n",
       "                     -9.16290732e-01, -9.31558204e-01, -9.41608540e-01, -9.44461609e-01,\n",
       "                     -9.50192284e-01, -9.55511445e-01, -9.66843011e-01, -9.67584026e-01,\n",
       "                     -9.71860583e-01, -9.80829253e-01, -9.90398704e-01, -9.93251773e-01,\n",
       "                     -9.98528830e-01, -1.00063188e+00, -1.01064352e+00, -1.01160091e+00,\n",
       "                     -1.01856958e+00, -1.02961942e+00, -1.04480958e+00, -1.04982212e+00,\n",
       "                     -1.06054034e+00, -1.06784063e+00, -1.07880966e+00, -1.08180517e+00,\n",
       "                     -1.09064412e+00, -1.09861229e+00, -1.12214279e+00, -1.12393010e+00,\n",
       "                     -1.13497993e+00, -1.15267951e+00, -1.15923691e+00, -1.16315081e+00,\n",
       "                     -1.16518678e+00, -1.18455472e+00, -1.18958407e+00, -1.19523912e+00,\n",
       "                     -1.20397280e+00, -1.22377543e+00, -1.22722967e+00, -1.23214368e+00,\n",
       "                     -1.25276297e+00, -1.26256697e+00, -1.28913061e+00, -1.29721473e+00,\n",
       "                     -1.29928298e+00, -1.32091160e+00, -1.32687094e+00, -1.33500107e+00,\n",
       "                     -1.33828514e+00, -1.34547237e+00, -1.35239281e+00, -1.35454566e+00,\n",
       "                     -1.36919993e+00, -1.38629436e+00, -1.40179855e+00, -1.42310833e+00,\n",
       "                     -1.42711636e+00, -1.43953888e+00, -1.47181653e+00, -1.48538526e+00,\n",
       "                     -1.49752000e+00, -1.50070471e+00, -1.50407740e+00, -1.52846885e+00,\n",
       "                     -1.55814462e+00, -1.60943791e+00, -1.61990921e+00, -1.63760879e+00,\n",
       "                     -1.67397643e+00, -1.72191590e+00, -1.72276660e+00, -1.72506809e+00,\n",
       "                     -1.78058617e+00, -1.79175947e+00, -1.88273125e+00, -1.91692261e+00,\n",
       "                     -1.94591015e+00, -1.96944065e+00, -2.00148000e+00, -2.01490302e+00,\n",
       "                     -2.12026354e+00, -2.19722458e+00, -2.25129180e+00, -2.39789527e+00,\n",
       "                     -2.42774824e+00, -2.48490665e+00, -2.63905733e+00, -2.73274281e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5520617468147885, privacy_risk=0.5371101142063208, accuracy=0.5371101142063208, tpr_ind=0.7137301824708345, tnr_ind=0.36049004594180706, test_train_ratio=0.9766676637750523, dataset_size=[3343, 3265]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00723327, 0.00964436, 0.0111513 , 0.01175407,\n",
       "                     0.01235684, 0.01356239, 0.01597348, 0.02200121, 0.02260398,\n",
       "                     0.02320675, 0.02380952, 0.02622061, 0.02893309, 0.03074141,\n",
       "                     0.03435805, 0.04008439, 0.04128993, 0.053044  , 0.05485232,\n",
       "                     0.05877034, 0.06088005, 0.06208559, 0.06570223, 0.07685353,\n",
       "                     0.09041591, 0.09433394, 0.11030741, 0.11362266, 0.11603376,\n",
       "                     0.11784207, 0.12145871, 0.14556962, 0.15310428, 0.16214587,\n",
       "                     0.16666667, 0.17299578, 0.1925859 , 0.19740808, 0.20283303,\n",
       "                     0.21940928, 0.21971067, 0.22182037, 0.24894515, 0.2676311 ,\n",
       "                     0.26943942, 0.27335744, 0.2808921 , 0.28390597, 0.28782399,\n",
       "                     0.2920434 , 0.30289331, 0.32459313, 0.32760699, 0.32881254,\n",
       "                     0.4138035 , 0.41651597, 0.41832429, 0.47016275, 0.4801085 ,\n",
       "                     0.48462929, 0.48734177, 0.4954792 , 0.50241109, 0.5045208 ,\n",
       "                     0.50964436, 0.55063291, 0.56027728, 0.57142857, 0.58137432,\n",
       "                     0.58981314, 0.59312839, 0.59493671, 0.59674503, 0.60488246,\n",
       "                     0.62356841, 0.63080169, 0.63351417, 0.65159735, 0.65611814,\n",
       "                     0.65852923, 0.67510549, 0.70735383, 0.71609403, 0.72543701,\n",
       "                     0.75165763, 0.7543701 , 0.75647981, 0.75919228, 0.76250753,\n",
       "                     0.76793249, 0.77998794, 0.80349608, 0.81012658, 0.82820976,\n",
       "                     0.83031947, 0.85021097, 0.85262206, 0.85774563, 0.86106088,\n",
       "                     0.86377336, 0.86799277, 0.8716094 , 0.87432188, 0.87582881,\n",
       "                     0.87643159, 0.87974684, 0.88245931, 0.89240506, 0.893912  ,\n",
       "                     0.90174804, 0.91470766, 0.91862568, 0.92314647, 0.92555756,\n",
       "                     0.92796866, 0.93520193, 0.93761302, 0.94002411, 0.94364075,\n",
       "                     0.94605184, 0.9490657 , 0.95238095, 0.9556962 , 0.95991561,\n",
       "                     0.96112116, 0.96624473, 0.96654611, 0.97016275, 0.97197107,\n",
       "                     0.97679325, 0.97980711, 0.98071127, 1.        ]), tpr=array([0.        , 0.0118541 , 0.01580547, 0.01884498, 0.02006079,\n",
       "                     0.02218845, 0.02522796, 0.02978723, 0.03677812, 0.03829787,\n",
       "                     0.04103343, 0.04285714, 0.04802432, 0.05227964, 0.05379939,\n",
       "                     0.06018237, 0.0662614 , 0.06838906, 0.08054711, 0.08328267,\n",
       "                     0.08753799, 0.08905775, 0.09118541, 0.09604863, 0.10851064,\n",
       "                     0.12613982, 0.1325228 , 0.15653495, 0.16048632, 0.16382979,\n",
       "                     0.16656535, 0.17173252, 0.19270517, 0.20030395, 0.20881459,\n",
       "                     0.21550152, 0.22036474, 0.24224924, 0.24711246, 0.25288754,\n",
       "                     0.26990881, 0.27294833, 0.27477204, 0.3006079 , 0.31519757,\n",
       "                     0.31671733, 0.3218845 , 0.33191489, 0.33586626, 0.33890578,\n",
       "                     0.34316109, 0.35197568, 0.37386018, 0.37993921, 0.38085106,\n",
       "                     0.4668693 , 0.46990881, 0.47234043, 0.52492401, 0.52887538,\n",
       "                     0.53161094, 0.53586626, 0.54346505, 0.54802432, 0.55075988,\n",
       "                     0.55927052, 0.60273556, 0.61519757, 0.63039514, 0.643769  ,\n",
       "                     0.65106383, 0.656231  , 0.66048632, 0.66382979, 0.67203647,\n",
       "                     0.69240122, 0.69969605, 0.70486322, 0.7231003 , 0.72674772,\n",
       "                     0.72978723, 0.74559271, 0.78024316, 0.78693009, 0.79513678,\n",
       "                     0.81945289, 0.8231003 , 0.82431611, 0.82613982, 0.82917933,\n",
       "                     0.83282675, 0.84285714, 0.86717325, 0.87386018, 0.88449848,\n",
       "                     0.88601824, 0.90455927, 0.90820669, 0.91276596, 0.91489362,\n",
       "                     0.91793313, 0.92158055, 0.92613982, 0.92887538, 0.93069909,\n",
       "                     0.9331307 , 0.93738602, 0.93981763, 0.94984802, 0.95136778,\n",
       "                     0.95653495, 0.96808511, 0.97051672, 0.97507599, 0.9768997 ,\n",
       "                     0.97933131, 0.98085106, 0.98176292, 0.98297872, 0.98389058,\n",
       "                     0.98571429, 0.98693009, 0.98844985, 0.9893617 , 0.99057751,\n",
       "                     0.99179331, 0.99452888, 0.99574468, 0.99696049, 0.99756839,\n",
       "                     0.99878419, 0.99969605, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.43100844e-01, -1.82321557e-01,\n",
       "                     -2.23143551e-01, -2.51314428e-01, -2.62364264e-01, -2.87682072e-01,\n",
       "                     -3.30241687e-01, -3.36472237e-01, -3.67724780e-01, -4.05465108e-01,\n",
       "                     -4.24883194e-01, -4.51985124e-01, -4.70003629e-01, -5.10825624e-01,\n",
       "                     -5.30628251e-01, -5.38996501e-01, -5.59615788e-01, -5.75364145e-01,\n",
       "                     -5.79818495e-01, -5.87786665e-01, -6.19039208e-01, -6.28608659e-01,\n",
       "                     -6.55875786e-01, -6.66944808e-01, -6.69049629e-01, -6.93147181e-01,\n",
       "                     -7.30887509e-01, -7.37598943e-01, -7.47214402e-01, -7.50305594e-01,\n",
       "                     -7.69839801e-01, -7.70108222e-01, -7.78669354e-01, -7.80158558e-01,\n",
       "                     -7.82759339e-01, -7.98507696e-01, -8.10930216e-01, -8.16761137e-01,\n",
       "                     -8.26678573e-01, -8.32909123e-01, -8.47297860e-01, -8.50653568e-01,\n",
       "                     -8.64997437e-01, -8.75468737e-01, -8.80358723e-01, -8.97941593e-01,\n",
       "                     -9.00786545e-01, -9.16290732e-01, -9.44461609e-01, -9.63437510e-01,\n",
       "                     -9.70357953e-01, -9.74559640e-01, -9.80829253e-01, -9.86554880e-01,\n",
       "                     -9.93251773e-01, -1.01160091e+00, -1.01422490e+00, -1.01856958e+00,\n",
       "                     -1.02165125e+00, -1.02450432e+00, -1.02961942e+00, -1.05314991e+00,\n",
       "                     -1.06087196e+00, -1.07451474e+00, -1.07502629e+00, -1.08221848e+00,\n",
       "                     -1.09192330e+00, -1.09861229e+00, -1.11240561e+00, -1.11803037e+00,\n",
       "                     -1.12214279e+00, -1.12846525e+00, -1.13497993e+00, -1.14716551e+00,\n",
       "                     -1.15267951e+00, -1.15577070e+00, -1.16315081e+00, -1.17865500e+00,\n",
       "                     -1.22377543e+00, -1.23053983e+00, -1.24268732e+00, -1.25276297e+00,\n",
       "                     -1.25804003e+00, -1.29129663e+00, -1.29928298e+00, -1.32175584e+00,\n",
       "                     -1.34373475e+00, -1.36097655e+00, -1.36524095e+00, -1.37868976e+00,\n",
       "                     -1.38629436e+00, -1.41981705e+00, -1.42825856e+00, -1.43508453e+00,\n",
       "                     -1.43820222e+00, -1.44691898e+00, -1.45083288e+00, -1.45528723e+00,\n",
       "                     -1.48160454e+00, -1.50407740e+00, -1.52605630e+00, -1.54044504e+00,\n",
       "                     -1.57553636e+00, -1.58412010e+00, -1.59504917e+00, -1.60943791e+00,\n",
       "                     -1.65678403e+00, -1.68639895e+00, -1.71008144e+00, -1.71900011e+00,\n",
       "                     -1.77070606e+00, -1.78058617e+00, -1.79175947e+00, -1.85238409e+00,\n",
       "                     -1.88706965e+00, -1.94591015e+00, -2.04769284e+00, -2.07944154e+00,\n",
       "                     -2.12026354e+00, -2.19722458e+00, -2.21920348e+00, -2.23359222e+00,\n",
       "                     -2.30258509e+00, -2.35137526e+00, -2.40794561e+00, -2.44234704e+00,\n",
       "                     -2.56494936e+00, -2.74084002e+00, -2.99573227e+00, -3.07577498e+00,\n",
       "                     -3.09104245e+00, -3.45387764e+01]), auc_score=0.5512374246763074, privacy_risk=0.5364446667436163, accuracy=0.5364446667436163, tpr_ind=0.7802431610942249, tnr_ind=0.29264617239300783, test_train_ratio=1.0085106382978724, dataset_size=[3290, 3318]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.01116476, 0.01237176, 0.01478576, 0.01901026,\n",
       "                     0.01901026, 0.02263126, 0.02564876, 0.02745926, 0.03017502,\n",
       "                     0.03319252, 0.03711527, 0.03832227, 0.04405552, 0.04707302,\n",
       "                     0.05190103, 0.05612553, 0.05612553, 0.05733253, 0.06125528,\n",
       "                     0.06427278, 0.06970428, 0.07181654, 0.07362704, 0.08388654,\n",
       "                     0.08750754, 0.08901629, 0.1010863 , 0.1053108 , 0.11406156,\n",
       "                     0.12281231, 0.12703681, 0.12884731, 0.13126132, 0.13880507,\n",
       "                     0.14484007, 0.15117683, 0.15328908, 0.15449608, 0.16203983,\n",
       "                     0.16566083, 0.17169584, 0.22208811, 0.22450211, 0.23687387,\n",
       "                     0.23958962, 0.25558238, 0.28334339, 0.3008449 , 0.31834641,\n",
       "                     0.32830416, 0.34067592, 0.34791792, 0.35093543, 0.35817743,\n",
       "                     0.36028968, 0.36541943, 0.38805069, 0.41611346, 0.41641521,\n",
       "                     0.42275196, 0.42335546, 0.42788171, 0.43029572, 0.43663247,\n",
       "                     0.43904647, 0.44357272, 0.45805673, 0.47465299, 0.51659626,\n",
       "                     0.52112251, 0.52595051, 0.52836451, 0.53439952, 0.54133977,\n",
       "                     0.54737477, 0.55642728, 0.56306578, 0.56879903, 0.57121304,\n",
       "                     0.57242004, 0.61979481, 0.62341581, 0.65841883, 0.66535908,\n",
       "                     0.67833434, 0.6943271 , 0.7076041 , 0.71031986, 0.71726011,\n",
       "                     0.71846711, 0.75226313, 0.75739288, 0.76342788, 0.81955341,\n",
       "                     0.82649366, 0.83433917, 0.83856367, 0.84429692, 0.84852142,\n",
       "                     0.87748944, 0.88080869, 0.88986119, 0.9007242 , 0.9061557 ,\n",
       "                     0.9085697 , 0.90887145, 0.91007846, 0.92727821, 0.93512372,\n",
       "                     0.94206397, 0.94538322, 0.94689197, 0.94809897, 0.95021123,\n",
       "                     0.95654798, 0.95775498, 0.96197948, 0.96288473, 0.96741098,\n",
       "                     0.97012674, 0.97223899, 0.97736874, 0.97887749, 1.        ]), tpr=array([0.        , 0.02155434, 0.02367942, 0.0273224 , 0.03582271,\n",
       "                     0.03794778, 0.04250152, 0.04644809, 0.05100182, 0.05464481,\n",
       "                     0.05889496, 0.06739526, 0.0701275 , 0.07619915, 0.08105647,\n",
       "                     0.08439587, 0.09168185, 0.09289617, 0.09562842, 0.09987857,\n",
       "                     0.10595021, 0.1129326 , 0.1147541 , 0.11900425, 0.13418336,\n",
       "                     0.1387371 , 0.14359441, 0.1608986 , 0.16697025, 0.17789921,\n",
       "                     0.18761384, 0.19095325, 0.19398907, 0.19581056, 0.20279296,\n",
       "                     0.21098968, 0.21554341, 0.21827565, 0.21948998, 0.2295082 ,\n",
       "                     0.23375835, 0.23770492, 0.28840316, 0.29204614, 0.30510018,\n",
       "                     0.30843959, 0.32665452, 0.35063752, 0.3715847 , 0.38737098,\n",
       "                     0.39496053, 0.41013965, 0.41803279, 0.42076503, 0.42714026,\n",
       "                     0.43442623, 0.43897996, 0.45992714, 0.48603522, 0.48724954,\n",
       "                     0.49241044, 0.49423194, 0.49817851, 0.50030358, 0.50728597,\n",
       "                     0.51001821, 0.51396478, 0.52610808, 0.54250152, 0.58864602,\n",
       "                     0.59471767, 0.60018215, 0.60261081, 0.60837887, 0.61596843,\n",
       "                     0.62477231, 0.63175471, 0.63843352, 0.6472374 , 0.64996964,\n",
       "                     0.65118397, 0.69854281, 0.70431087, 0.73861566, 0.74529447,\n",
       "                     0.75774135, 0.77322404, 0.7859745 , 0.78809957, 0.79265331,\n",
       "                     0.79508197, 0.82119004, 0.82513661, 0.83029751, 0.87583485,\n",
       "                     0.88646023, 0.89253188, 0.89829994, 0.90497875, 0.9092289 ,\n",
       "                     0.93078324, 0.93290832, 0.93897996, 0.95051609, 0.95324833,\n",
       "                     0.95598057, 0.95749848, 0.95871281, 0.97146327, 0.97662417,\n",
       "                     0.98239223, 0.98299939, 0.98482089, 0.98542805, 0.98664238,\n",
       "                     0.99028537, 0.9914997 , 0.99423194, 0.9948391 , 0.99696418,\n",
       "                     0.99787492, 0.99848209, 0.99939284, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.33531393e-01, -1.54150680e-01,\n",
       "                     -2.23143551e-01, -2.51314428e-01, -2.87682072e-01, -3.25422400e-01,\n",
       "                     -3.36472237e-01, -3.48306694e-01, -3.56674944e-01, -4.05465108e-01,\n",
       "                     -4.41832752e-01, -4.70003629e-01, -4.85507816e-01, -4.92476485e-01,\n",
       "                     -5.10825624e-01, -5.59615788e-01, -5.75364145e-01, -5.79818495e-01,\n",
       "                     -5.87786665e-01, -6.02175402e-01, -6.06135804e-01, -6.19039208e-01,\n",
       "                     -6.20576488e-01, -6.24154309e-01, -6.28608659e-01, -6.39079959e-01,\n",
       "                     -6.41853886e-01, -6.64976304e-01, -6.93147181e-01, -7.37598943e-01,\n",
       "                     -7.41937345e-01, -7.73189888e-01, -7.76528789e-01, -7.81700578e-01,\n",
       "                     -7.88457360e-01, -7.98507696e-01, -8.10930216e-01, -8.20980552e-01,\n",
       "                     -8.26678573e-01, -8.36248024e-01, -8.40430881e-01, -8.47297860e-01,\n",
       "                     -8.53920401e-01, -8.60201265e-01, -8.75468737e-01, -8.80663554e-01,\n",
       "                     -8.83887308e-01, -8.85038188e-01, -9.08258560e-01, -9.16290732e-01,\n",
       "                     -9.31558204e-01, -9.38269639e-01, -9.44461609e-01, -9.49080555e-01,\n",
       "                     -9.55511445e-01, -9.75379648e-01, -9.80829253e-01, -1.01160091e+00,\n",
       "                     -1.03798767e+00, -1.04145387e+00, -1.04596856e+00, -1.04982212e+00,\n",
       "                     -1.05416053e+00, -1.06087196e+00, -1.07263680e+00, -1.08180517e+00,\n",
       "                     -1.08618977e+00, -1.09861229e+00, -1.11514159e+00, -1.13497993e+00,\n",
       "                     -1.13943428e+00, -1.14990558e+00, -1.15057203e+00, -1.15449275e+00,\n",
       "                     -1.15496523e+00, -1.15745279e+00, -1.16530366e+00, -1.17007125e+00,\n",
       "                     -1.17865500e+00, -1.21544521e+00, -1.22994829e+00, -1.23361752e+00,\n",
       "                     -1.25276297e+00, -1.25624123e+00, -1.27218105e+00, -1.29928298e+00,\n",
       "                     -1.31218639e+00, -1.35239281e+00, -1.35454566e+00, -1.38629436e+00,\n",
       "                     -1.40534256e+00, -1.41528190e+00, -1.42551507e+00, -1.42825856e+00,\n",
       "                     -1.44691898e+00, -1.45001018e+00, -1.45225233e+00, -1.45528723e+00,\n",
       "                     -1.47389242e+00, -1.51982575e+00, -1.56861592e+00, -1.58816051e+00,\n",
       "                     -1.60943791e+00, -1.67397643e+00, -1.68639895e+00, -1.74919985e+00,\n",
       "                     -1.80359393e+00, -1.83022575e+00, -1.85135157e+00, -1.87180218e+00,\n",
       "                     -1.92181260e+00, -1.94591015e+00, -1.98100147e+00, -2.00372972e+00,\n",
       "                     -2.07944154e+00, -2.15948425e+00, -2.30258509e+00, -2.31676973e+00,\n",
       "                     -2.53897387e+00, -2.63905733e+00, -2.94443898e+00, -3.29583687e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5620877501164312, privacy_risk=0.5404475282686942, accuracy=0.5404475282686942, tpr_ind=0.7043108682452944, tnr_ind=0.37658418829209417, test_train_ratio=1.0060716454159078, dataset_size=[3294, 3314]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00880656, 0.01062861, 0.013058  , 0.01488005,\n",
       "                     0.0167021 , 0.02550865, 0.02945642, 0.03370787, 0.03522624,\n",
       "                     0.03978135, 0.04342545, 0.04433647, 0.04585484, 0.05223201,\n",
       "                     0.05526875, 0.05982387, 0.06043122, 0.0677194 , 0.07440024,\n",
       "                     0.10567871, 0.11084118, 0.11964774, 0.1248102 , 0.1272396 ,\n",
       "                     0.1545703 , 0.15730337, 0.16094746, 0.16185849, 0.17673854,\n",
       "                     0.18250835, 0.20649863, 0.20983905, 0.22016398, 0.22411175,\n",
       "                     0.2259338 , 0.22805952, 0.23018524, 0.24597631, 0.25751594,\n",
       "                     0.26358943, 0.31491042, 0.34193744, 0.36197996, 0.3935621 ,\n",
       "                     0.39993927, 0.40327968, 0.40601275, 0.4090495 , 0.42150015,\n",
       "                     0.46948072, 0.47099909, 0.48010932, 0.48648649, 0.49013058,\n",
       "                     0.49498937, 0.51989068, 0.52232007, 0.52717886, 0.53902217,\n",
       "                     0.55329487, 0.5660492 , 0.58487701, 0.59246887, 0.59884604,\n",
       "                     0.60461585, 0.61251139, 0.61919223, 0.63042818, 0.63528697,\n",
       "                     0.63650167, 0.63893107, 0.64378986, 0.6456119 , 0.65381111,\n",
       "                     0.66443972, 0.67172791, 0.68053447, 0.69146675, 0.70088066,\n",
       "                     0.71120559, 0.71302763, 0.71879745, 0.72638931, 0.73276647,\n",
       "                     0.74734285, 0.74977224, 0.75250531, 0.75554206, 0.75948983,\n",
       "                     0.78894625, 0.79987853, 0.82083207, 0.8299423 , 0.84451868,\n",
       "                     0.85362891, 0.86061342, 0.86213179, 0.87124203, 0.87184938,\n",
       "                     0.87336775, 0.87367142, 0.88187063, 0.88642575, 0.89067719,\n",
       "                     0.89826906, 0.9025205 , 0.90494989, 0.90616459, 0.90889766,\n",
       "                     0.91193441, 0.92620711, 0.92651078, 0.92711813, 0.93379897,\n",
       "                     0.93805041, 0.94442757, 0.94837534, 0.95262678, 0.9596113 ,\n",
       "                     0.96234437, 0.96416641, 0.96507744, 0.96750683, 0.96872153,\n",
       "                     0.97054358, 0.97175828, 0.97358032, 0.97570604, 1.        ]), tpr=array([0.        , 0.01840121, 0.02111614, 0.02564103, 0.02835596,\n",
       "                     0.0331825 , 0.04766214, 0.05098039, 0.05309201, 0.0546003 ,\n",
       "                     0.05942685, 0.06666667, 0.07088989, 0.07571644, 0.0826546 ,\n",
       "                     0.08567119, 0.0892911 , 0.09140271, 0.09894419, 0.10527903,\n",
       "                     0.13484163, 0.14147813, 0.14992459, 0.15746606, 0.16048265,\n",
       "                     0.18401207, 0.19064857, 0.19487179, 0.19668175, 0.21266968,\n",
       "                     0.21870287, 0.24917044, 0.25279035, 0.26395173, 0.26757164,\n",
       "                     0.27088989, 0.27239819, 0.27662142, 0.28898944, 0.30196078,\n",
       "                     0.31010558, 0.3653092 , 0.39638009, 0.42292609, 0.45098039,\n",
       "                     0.45942685, 0.46214178, 0.46696833, 0.47088989, 0.48627451,\n",
       "                     0.52941176, 0.53273002, 0.53996983, 0.54751131, 0.55263952,\n",
       "                     0.55565611, 0.58159879, 0.58552036, 0.58974359, 0.60331825,\n",
       "                     0.61749623, 0.6280543 , 0.65158371, 0.65641026, 0.66214178,\n",
       "                     0.66576169, 0.67511312, 0.6826546 , 0.69954751, 0.70769231,\n",
       "                     0.70950226, 0.71372549, 0.71523379, 0.7173454 , 0.72730015,\n",
       "                     0.73936652, 0.74479638, 0.74901961, 0.76078431, 0.76892911,\n",
       "                     0.77707391, 0.77978884, 0.78642534, 0.79155354, 0.79909502,\n",
       "                     0.81598793, 0.81870287, 0.82292609, 0.82865762, 0.83046757,\n",
       "                     0.84977376, 0.85882353, 0.87571644, 0.8826546 , 0.89683258,\n",
       "                     0.90497738, 0.91282051, 0.91372549, 0.92156863, 0.92277526,\n",
       "                     0.9254902 , 0.92850679, 0.93484163, 0.94057315, 0.9438914 ,\n",
       "                     0.94781297, 0.95263952, 0.95414781, 0.95625943, 0.96048265,\n",
       "                     0.9638009 , 0.97647059, 0.97677225, 0.97797888, 0.98099548,\n",
       "                     0.98220211, 0.98582202, 0.98793363, 0.98914027, 0.9918552 ,\n",
       "                     0.99517345, 0.99638009, 0.99698341, 0.99788839, 0.9984917 ,\n",
       "                     0.99909502, 0.99939668, 0.99969834, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.05360516e-01, -1.82321557e-01,\n",
       "                     -2.87682072e-01, -3.18453731e-01, -4.05465108e-01, -4.35318071e-01,\n",
       "                     -4.51985124e-01, -4.70003629e-01, -4.85507816e-01, -5.10825624e-01,\n",
       "                     -5.38996501e-01, -5.59615788e-01, -5.78077851e-01, -5.87786665e-01,\n",
       "                     -6.06135804e-01, -6.19039208e-01, -6.31271777e-01, -6.44357016e-01,\n",
       "                     -6.93147181e-01, -7.15620036e-01, -7.28238500e-01, -7.32367894e-01,\n",
       "                     -7.41937345e-01, -7.49236647e-01, -7.59105148e-01, -7.62140052e-01,\n",
       "                     -7.73189888e-01, -7.83298278e-01, -7.88457360e-01, -8.05414482e-01,\n",
       "                     -8.10930216e-01, -8.43429384e-01, -8.47297860e-01, -8.60201265e-01,\n",
       "                     -8.75468737e-01, -8.87303195e-01, -8.91598119e-01, -8.92760234e-01,\n",
       "                     -8.93817876e-01, -8.97741373e-01, -9.02605279e-01, -9.16290732e-01,\n",
       "                     -9.31232312e-01, -9.44461609e-01, -9.80829253e-01, -9.88611393e-01,\n",
       "                     -9.90398704e-01, -9.95428052e-01, -9.95580063e-01, -1.00330211e+00,\n",
       "                     -1.01160091e+00, -1.01523068e+00, -1.01693426e+00, -1.02961942e+00,\n",
       "                     -1.06310560e+00, -1.07263680e+00, -1.07451474e+00, -1.07613943e+00,\n",
       "                     -1.08432633e+00, -1.08904284e+00, -1.09861229e+00, -1.13943428e+00,\n",
       "                     -1.14990558e+00, -1.15267951e+00, -1.17118298e+00, -1.17557333e+00,\n",
       "                     -1.17865500e+00, -1.19279950e+00, -1.20397280e+00, -1.21109027e+00,\n",
       "                     -1.22377543e+00, -1.23214368e+00, -1.23969089e+00, -1.25276297e+00,\n",
       "                     -1.26851133e+00, -1.27296568e+00, -1.27808078e+00, -1.27887411e+00,\n",
       "                     -1.28913061e+00, -1.29928298e+00, -1.30340670e+00, -1.30992138e+00,\n",
       "                     -1.31372367e+00, -1.32175584e+00, -1.32913595e+00, -1.33123458e+00,\n",
       "                     -1.33222714e+00, -1.34373475e+00, -1.38238046e+00, -1.38629436e+00,\n",
       "                     -1.39518331e+00, -1.39710528e+00, -1.41771056e+00, -1.43155095e+00,\n",
       "                     -1.45143366e+00, -1.46633707e+00, -1.48683559e+00, -1.50407740e+00,\n",
       "                     -1.51634749e+00, -1.52605630e+00, -1.53018854e+00, -1.57734960e+00,\n",
       "                     -1.60943791e+00, -1.65455835e+00, -1.67006253e+00, -1.72276660e+00,\n",
       "                     -1.74296931e+00, -1.75539183e+00, -1.76098781e+00, -1.77978328e+00,\n",
       "                     -1.79175947e+00, -1.83258146e+00, -1.85629799e+00, -1.87180218e+00,\n",
       "                     -1.94591015e+00, -2.07944154e+00, -2.11021320e+00, -2.22161603e+00,\n",
       "                     -2.22707754e+00, -2.30258509e+00, -2.35137526e+00, -2.36712361e+00,\n",
       "                     -2.39789527e+00, -2.67414865e+00, -2.83321334e+00, -2.89037176e+00,\n",
       "                     -3.09104245e+00, -3.45387764e+01]), auc_score=0.550742948958415, privacy_risk=0.5374633976088041, accuracy=0.5374633976088041, tpr_ind=0.7393665158371041, tnr_ind=0.3355602793805041, test_train_ratio=0.9933634992458522, dataset_size=[3315, 3293]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00805489, 0.01163484, 0.01282816, 0.01431981,\n",
       "                     0.01551313, 0.01670644, 0.02058473, 0.02177804, 0.02416468,\n",
       "                     0.02565632, 0.02684964, 0.02953461, 0.03729117, 0.0426611 ,\n",
       "                     0.04832936, 0.05041766, 0.05250597, 0.0528043 , 0.07130072,\n",
       "                     0.08114558, 0.08860382, 0.09099045, 0.09367542, 0.099642  ,\n",
       "                     0.10590692, 0.10918854, 0.12171838, 0.12589499, 0.12947494,\n",
       "                     0.13245823, 0.13812649, 0.14081146, 0.14379475, 0.1452864 ,\n",
       "                     0.14797136, 0.15184964, 0.16079952, 0.17064439, 0.18645585,\n",
       "                     0.19331742, 0.20554893, 0.21599045, 0.21867542, 0.22553699,\n",
       "                     0.23597852, 0.24463007, 0.27416468, 0.27863962, 0.2825179 ,\n",
       "                     0.28460621, 0.2977327 , 0.30877088, 0.31563246, 0.32189737,\n",
       "                     0.33383055, 0.34158711, 0.35590692, 0.36247017, 0.36903341,\n",
       "                     0.37201671, 0.39200477, 0.41109785, 0.41646778, 0.42034606,\n",
       "                     0.424821  , 0.44480907, 0.45107399, 0.45883055, 0.47404535,\n",
       "                     0.48120525, 0.53878282, 0.54116945, 0.54713604, 0.5477327 ,\n",
       "                     0.55877088, 0.56264916, 0.56861575, 0.57786396, 0.58144391,\n",
       "                     0.59606205, 0.60739857, 0.60859189, 0.65692124, 0.67362768,\n",
       "                     0.67840095, 0.67869928, 0.69391408, 0.70346062, 0.71121718,\n",
       "                     0.71599045, 0.7174821 , 0.71927208, 0.72076372, 0.72941527,\n",
       "                     0.74194511, 0.74910501, 0.75894988, 0.77267303, 0.78192124,\n",
       "                     0.79087112, 0.79594272, 0.82249403, 0.825179  , 0.83114558,\n",
       "                     0.83770883, 0.84158711, 0.849642  , 0.8547136 , 0.87798329,\n",
       "                     0.88394988, 0.89856802, 0.90602625, 0.91020286, 0.91109785,\n",
       "                     0.91348449, 0.91646778, 0.93794749, 0.93973747, 0.94182578,\n",
       "                     0.94361575, 0.95077566, 0.95286396, 0.95465394, 0.9603222 ,\n",
       "                     0.9603222 , 0.96569212, 0.96718377, 0.96986874, 1.        ]), tpr=array([0.        , 0.01750614, 0.02027027, 0.02242015, 0.0242629 ,\n",
       "                     0.02579853, 0.02702703, 0.03347666, 0.03931204, 0.04391892,\n",
       "                     0.04545455, 0.04760442, 0.0509828 , 0.06449631, 0.07186732,\n",
       "                     0.0764742 , 0.0789312 , 0.08169533, 0.08323096, 0.10810811,\n",
       "                     0.12100737, 0.12684275, 0.13114251, 0.13390663, 0.14312039,\n",
       "                     0.15325553, 0.15755528, 0.1722973 , 0.17628993, 0.18089681,\n",
       "                     0.18519656, 0.19133907, 0.1953317 , 0.19871007, 0.2002457 ,\n",
       "                     0.20423833, 0.20669533, 0.21498771, 0.22757985, 0.24078624,\n",
       "                     0.24723587, 0.25829238, 0.26750614, 0.27027027, 0.28009828,\n",
       "                     0.28808354, 0.30528256, 0.34183047, 0.34398034, 0.34920147,\n",
       "                     0.35380835, 0.36947174, 0.37929975, 0.38851351, 0.39527027,\n",
       "                     0.40724816, 0.41308354, 0.42905405, 0.43212531, 0.44041769,\n",
       "                     0.44379607, 0.46130221, 0.48157248, 0.48617936, 0.49078624,\n",
       "                     0.49815725, 0.52088452, 0.5242629 , 0.53194103, 0.5509828 ,\n",
       "                     0.55773956, 0.61885749, 0.62192875, 0.62929975, 0.63329238,\n",
       "                     0.64312039, 0.64772727, 0.65448403, 0.66461916, 0.66676904,\n",
       "                     0.68028256, 0.69441032, 0.69625307, 0.72880835, 0.74570025,\n",
       "                     0.74785012, 0.74907862, 0.76412776, 0.77272727, 0.78409091,\n",
       "                     0.78900491, 0.78992629, 0.79115479, 0.79330467, 0.80067568,\n",
       "                     0.81326781, 0.82063882, 0.83138821, 0.84152334, 0.8519656 ,\n",
       "                     0.86025799, 0.86486486, 0.89250614, 0.89496314, 0.8992629 ,\n",
       "                     0.90479115, 0.90878378, 0.91400491, 0.91799754, 0.93458231,\n",
       "                     0.94103194, 0.95331695, 0.95761671, 0.96160934, 0.96345209,\n",
       "                     0.96560197, 0.96713759, 0.98495086, 0.98679361, 0.98710074,\n",
       "                     0.98771499, 0.99293612, 0.99385749, 0.995086  , 0.99815725,\n",
       "                     0.99846437, 0.99938575, 0.99969287, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.05360516e-01, -1.33531393e-01,\n",
       "                     -1.54150680e-01, -1.82321557e-01, -2.23143551e-01, -2.51314428e-01,\n",
       "                     -2.74436846e-01, -2.87682072e-01, -3.36472237e-01, -3.56674944e-01,\n",
       "                     -3.74693449e-01, -4.05465108e-01, -5.10825624e-01, -5.50046337e-01,\n",
       "                     -5.59615788e-01, -5.75364145e-01, -5.87786665e-01, -5.89157467e-01,\n",
       "                     -6.06135804e-01, -6.10909082e-01, -6.19039208e-01, -6.35988767e-01,\n",
       "                     -6.41853886e-01, -6.46627165e-01, -6.56779536e-01, -6.93147181e-01,\n",
       "                     -7.30887509e-01, -7.57685702e-01, -7.62140052e-01, -7.65467842e-01,\n",
       "                     -7.67255153e-01, -7.80158558e-01, -7.88457360e-01, -8.02346473e-01,\n",
       "                     -8.10930216e-01, -8.15036998e-01, -8.19027426e-01, -8.23767363e-01,\n",
       "                     -8.47297860e-01, -8.59132318e-01, -8.75468737e-01, -8.93817876e-01,\n",
       "                     -9.03711950e-01, -9.16290732e-01, -9.23408200e-01, -9.34609312e-01,\n",
       "                     -9.44461609e-01, -9.50976290e-01, -9.55511445e-01, -9.58523495e-01,\n",
       "                     -9.65080896e-01, -9.68250471e-01, -9.69400557e-01, -9.80829253e-01,\n",
       "                     -9.87386654e-01, -9.90398704e-01, -9.93251773e-01, -9.94622575e-01,\n",
       "                     -1.00330211e+00, -1.00680474e+00, -1.00884229e+00, -1.02961942e+00,\n",
       "                     -1.05314991e+00, -1.05605267e+00, -1.06657293e+00, -1.06784063e+00,\n",
       "                     -1.07158362e+00, -1.09861229e+00, -1.11365017e+00, -1.11687006e+00,\n",
       "                     -1.13140211e+00, -1.13943428e+00, -1.14862271e+00, -1.15923691e+00,\n",
       "                     -1.16315081e+00, -1.17163742e+00, -1.18562367e+00, -1.18958407e+00,\n",
       "                     -1.19254411e+00, -1.20179652e+00, -1.20397280e+00, -1.21709389e+00,\n",
       "                     -1.21841349e+00, -1.23214368e+00, -1.25276297e+00, -1.25846099e+00,\n",
       "                     -1.26291534e+00, -1.26427941e+00, -1.28785429e+00, -1.29928298e+00,\n",
       "                     -1.32175584e+00, -1.34992672e+00, -1.35454566e+00, -1.35533214e+00,\n",
       "                     -1.36524095e+00, -1.37190562e+00, -1.37868976e+00, -1.37891425e+00,\n",
       "                     -1.38629436e+00, -1.40282366e+00, -1.43508453e+00, -1.44691898e+00,\n",
       "                     -1.48807706e+00, -1.49165488e+00, -1.49549365e+00, -1.49752000e+00,\n",
       "                     -1.52939520e+00, -1.53916872e+00, -1.54044504e+00, -1.55814462e+00,\n",
       "                     -1.58045038e+00, -1.60943791e+00, -1.76358859e+00, -1.79175947e+00,\n",
       "                     -1.82454929e+00, -1.86381279e+00, -1.92181260e+00, -1.94591015e+00,\n",
       "                     -2.01490302e+00, -2.01881692e+00, -2.03688193e+00, -2.22462355e+00,\n",
       "                     -2.24070969e+00, -2.39789527e+00, -2.90872090e+00, -3.09104245e+00,\n",
       "                     -4.18965474e+00, -3.45387764e+01]), auc_score=0.561628421991638, privacy_risk=0.5438305929057718, accuracy=0.5438305929057718, tpr_ind=0.6962530712530712, tnr_ind=0.3914081145584726, test_train_ratio=1.0294840294840295, dataset_size=[3256, 3352]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00676507, 0.00830258, 0.0098401 , 0.01168512,\n",
       "                     0.01506765, 0.01568266, 0.01722017, 0.02060271, 0.02121771,\n",
       "                     0.0301353 , 0.03167282, 0.03659287, 0.04428044, 0.04643296,\n",
       "                     0.0504305 , 0.05473555, 0.0602706 , 0.06365314, 0.06642066,\n",
       "                     0.07164822, 0.07287823, 0.07564576, 0.07902829, 0.08210332,\n",
       "                     0.08763838, 0.08948339, 0.09194342, 0.09348093, 0.09563346,\n",
       "                     0.10116851, 0.10455105, 0.11254613, 0.11562116, 0.15897909,\n",
       "                     0.16574416, 0.17896679, 0.19372694, 0.19495695, 0.20418204,\n",
       "                     0.20910209, 0.21063961, 0.21432964, 0.21771218, 0.2195572 ,\n",
       "                     0.22078721, 0.2303198 , 0.23277983, 0.25461255, 0.26353014,\n",
       "                     0.26660517, 0.27214022, 0.27552276, 0.28075031, 0.28567036,\n",
       "                     0.29305043, 0.29520295, 0.33425584, 0.33763838, 0.33886839,\n",
       "                     0.37607626, 0.38345633, 0.39637146, 0.41205412, 0.41912669,\n",
       "                     0.42189422, 0.43511685, 0.44864699, 0.45141451, 0.46094711,\n",
       "                     0.46432964, 0.46617466, 0.48247232, 0.49323493, 0.52337023,\n",
       "                     0.52583026, 0.57872079, 0.59132841, 0.59501845, 0.59717097,\n",
       "                     0.60670357, 0.60916359, 0.64514145, 0.6500615 , 0.65098401,\n",
       "                     0.66113161, 0.6700492 , 0.67281673, 0.67373924, 0.70633456,\n",
       "                     0.70725707, 0.70787208, 0.71525215, 0.76445264, 0.76506765,\n",
       "                     0.76814268, 0.7804428 , 0.78075031, 0.78413284, 0.78536285,\n",
       "                     0.7899754 , 0.80442804, 0.80811808, 0.82349323, 0.82779828,\n",
       "                     0.83640836, 0.84778598, 0.849631  , 0.850246  , 0.85824108,\n",
       "                     0.86162362, 0.86408364, 0.88314883, 0.89606396, 0.90159902,\n",
       "                     0.90590406, 0.93573186, 0.93665437, 0.93726937, 0.9400369 ,\n",
       "                     0.94434194, 0.96248462, 0.96432964, 0.96494465, 0.96617466,\n",
       "                     0.97170972, 0.97355474, 0.97539975, 0.97662977, 0.97755228,\n",
       "                     0.97908979, 1.        ]), tpr=array([0.        , 0.01609058, 0.01907032, 0.02145411, 0.02294398,\n",
       "                     0.02890346, 0.03098927, 0.03188319, 0.0363528 , 0.03843862,\n",
       "                     0.04856973, 0.05065554, 0.05721097, 0.06406436, 0.06644815,\n",
       "                     0.07210965, 0.07628129, 0.08611442, 0.090882  , 0.09296782,\n",
       "                     0.0965435 , 0.09922527, 0.1033969 , 0.10637664, 0.10965435,\n",
       "                     0.1147199 , 0.11650775, 0.12038141, 0.12246722, 0.12485101,\n",
       "                     0.12991657, 0.13259833, 0.14153754, 0.14600715, 0.19249106,\n",
       "                     0.19755662, 0.21513707, 0.23301549, 0.23539928, 0.24582837,\n",
       "                     0.25297974, 0.25625745, 0.26072706, 0.26638856, 0.26907032,\n",
       "                     0.27026222, 0.27920143, 0.28128725, 0.30423123, 0.31108462,\n",
       "                     0.31764005, 0.32121573, 0.32419547, 0.33343266, 0.33969011,\n",
       "                     0.34505364, 0.35071514, 0.39004768, 0.39511323, 0.3966031 ,\n",
       "                     0.43593564, 0.43921335, 0.45083433, 0.47169249, 0.47586412,\n",
       "                     0.48033373, 0.49284863, 0.5056615 , 0.5068534 , 0.51668653,\n",
       "                     0.52056019, 0.5238379 , 0.54439809, 0.5613826 , 0.58909416,\n",
       "                     0.59177592, 0.64034565, 0.65286055, 0.65584029, 0.65852205,\n",
       "                     0.66716329, 0.66954708, 0.70917759, 0.71513707, 0.71692491,\n",
       "                     0.72646007, 0.73420739, 0.73718713, 0.73837902, 0.76758045,\n",
       "                     0.76966627, 0.77205006, 0.78009535, 0.8238975 , 0.82568534,\n",
       "                     0.82777116, 0.84058403, 0.84177592, 0.84505364, 0.84684148,\n",
       "                     0.85250298, 0.86233611, 0.86799762, 0.88259833, 0.88617402,\n",
       "                     0.89392133, 0.90405244, 0.90554231, 0.90643623, 0.91209774,\n",
       "                     0.9147795 , 0.91924911, 0.93325387, 0.94398093, 0.94815256,\n",
       "                     0.94994041, 0.97437426, 0.97556615, 0.97646007, 0.97824791,\n",
       "                     0.98152563, 0.99135876, 0.9931466 , 0.9943385 , 0.99493445,\n",
       "                     0.99731824, 0.99791418, 0.9988081 , 0.99940405, 0.99970203,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -9.53101798e-02, -1.17783036e-01,\n",
       "                     -1.82321557e-01, -2.23143551e-01, -2.51314428e-01, -2.87682072e-01,\n",
       "                     -3.36472237e-01, -3.56674944e-01, -4.05465108e-01, -4.51985124e-01,\n",
       "                     -4.64305608e-01, -4.75423697e-01, -4.85507816e-01, -4.89548225e-01,\n",
       "                     -4.96436886e-01, -5.10825624e-01, -5.23248144e-01, -5.38996501e-01,\n",
       "                     -5.59615788e-01, -5.75364145e-01, -5.79818495e-01, -5.87786665e-01,\n",
       "                     -5.97837001e-01, -6.00773860e-01, -6.06135804e-01, -6.13104473e-01,\n",
       "                     -6.19039208e-01, -6.28608659e-01, -6.32522559e-01, -6.35988767e-01,\n",
       "                     -6.41853886e-01, -6.59245629e-01, -6.93147181e-01, -7.22134717e-01,\n",
       "                     -7.34646911e-01, -7.41937345e-01, -7.53771802e-01, -7.62140052e-01,\n",
       "                     -7.73189888e-01, -7.80158558e-01, -7.88457360e-01, -7.93230639e-01,\n",
       "                     -7.98507696e-01, -8.10930216e-01, -8.18310324e-01, -8.26678573e-01,\n",
       "                     -8.32344311e-01, -8.34797698e-01, -8.40783179e-01, -8.47297860e-01,\n",
       "                     -8.75468737e-01, -8.83500909e-01, -9.06721281e-01, -9.16290732e-01,\n",
       "                     -9.26762032e-01, -9.46143695e-01, -9.50976290e-01, -9.55511445e-01,\n",
       "                     -9.57839735e-01, -9.69400557e-01, -9.80829253e-01, -9.87946721e-01,\n",
       "                     -9.98528830e-01, -1.00552187e+00, -1.00726251e+00, -1.00948451e+00,\n",
       "                     -1.01160091e+00, -1.01435195e+00, -1.01856958e+00, -1.03609193e+00,\n",
       "                     -1.04400815e+00, -1.04454507e+00, -1.05838749e+00, -1.06087196e+00,\n",
       "                     -1.09861229e+00, -1.11399721e+00, -1.13140211e+00, -1.13497993e+00,\n",
       "                     -1.14356368e+00, -1.17865500e+00, -1.19186978e+00, -1.19392247e+00,\n",
       "                     -1.20397280e+00, -1.20709293e+00, -1.21924028e+00, -1.22377543e+00,\n",
       "                     -1.25276297e+00, -1.25567418e+00, -1.27296568e+00, -1.28785429e+00,\n",
       "                     -1.28913061e+00, -1.29183416e+00, -1.29928298e+00, -1.31218639e+00,\n",
       "                     -1.32020425e+00, -1.32175584e+00, -1.33977435e+00, -1.34373475e+00,\n",
       "                     -1.34602046e+00, -1.38629436e+00, -1.42500887e+00, -1.44571778e+00,\n",
       "                     -1.46633707e+00, -1.47810191e+00, -1.50407740e+00, -1.52605630e+00,\n",
       "                     -1.54044504e+00, -1.55537069e+00, -1.56397554e+00, -1.58240924e+00,\n",
       "                     -1.58793171e+00, -1.60386687e+00, -1.60943791e+00, -1.64222774e+00,\n",
       "                     -1.68459063e+00, -1.70474809e+00, -1.73460106e+00, -1.79175947e+00,\n",
       "                     -1.91959284e+00, -1.94157175e+00, -2.07944154e+00, -2.19722458e+00,\n",
       "                     -2.39789527e+00, -2.40919483e+00, -2.52572864e+00, -2.56494936e+00,\n",
       "                     -2.60268969e+00, -2.70805020e+00, -3.33220451e+00, -3.45387764e+01]), auc_score=0.549430203032662, privacy_risk=0.5340738329910117, accuracy=0.5340738329910117, tpr_ind=0.5613825983313468, tnr_ind=0.5067650676506765, test_train_ratio=0.9690107270560191, dataset_size=[3356, 3252]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00837571, 0.00927311, 0.01316183, 0.01495663,\n",
       "                     0.01794795, 0.02333234, 0.02632366, 0.03170805, 0.03230631,\n",
       "                     0.03649417, 0.03739156, 0.04457074, 0.04636554, 0.05264732,\n",
       "                     0.05593778, 0.06012564, 0.06192043, 0.06401436, 0.07897098,\n",
       "                     0.08226144, 0.09422674, 0.10170506, 0.11247383, 0.13969488,\n",
       "                     0.14687407, 0.15106192, 0.15315585, 0.16123243, 0.16721508,\n",
       "                     0.17080467, 0.17618905, 0.17888124, 0.19204308, 0.21567454,\n",
       "                     0.2207598 , 0.22255459, 0.24259647, 0.24648519, 0.26533054,\n",
       "                     0.26712534, 0.27310799, 0.28028717, 0.28208196, 0.28656895,\n",
       "                     0.30421777, 0.30870476, 0.31169608, 0.3173796 , 0.32336225,\n",
       "                     0.3422076 , 0.35477116, 0.36404427, 0.38378702, 0.38468442,\n",
       "                     0.38737661, 0.38857314, 0.40831588, 0.41609333, 0.41878552,\n",
       "                     0.43374215, 0.43852827, 0.44570745, 0.45617709, 0.46036494,\n",
       "                     0.47143284, 0.48638947, 0.49326952, 0.50074783, 0.50194436,\n",
       "                     0.50344002, 0.51540532, 0.52019144, 0.5243793 , 0.52826802,\n",
       "                     0.53215675, 0.54083159, 0.55967694, 0.56625785, 0.57433443,\n",
       "                     0.57792402, 0.58929106, 0.59826503, 0.61142686, 0.61411905,\n",
       "                     0.63027221, 0.6595872 , 0.66287765, 0.68710739, 0.69039785,\n",
       "                     0.69907269, 0.71043972, 0.71223452, 0.7203111 , 0.74573736,\n",
       "                     0.74872869, 0.75381394, 0.76129225, 0.77265929, 0.78133413,\n",
       "                     0.78911158, 0.7912055 , 0.79629076, 0.80167514, 0.80885432,\n",
       "                     0.81633264, 0.81992223, 0.82171702, 0.82171702, 0.83428059,\n",
       "                     0.83757104, 0.84624589, 0.85163027, 0.86419384, 0.87346695,\n",
       "                     0.87915046, 0.8794496 , 0.88274005, 0.90607239, 0.90996111,\n",
       "                     0.91714029, 0.925516  , 0.9282082 , 0.93538738, 0.93957523,\n",
       "                     0.94436135, 0.94735268, 0.95752318, 0.95782232, 0.9641041 ,\n",
       "                     0.96559976, 0.96679629, 0.96709542, 0.96799282, 0.96829195,\n",
       "                     0.96889022, 0.97128328, 0.97128328, 0.97337721, 0.97487287,\n",
       "                     0.97816333, 1.        ]), tpr=array([0.        , 0.01531394, 0.01898928, 0.02358346, 0.02603369,\n",
       "                     0.02940276, 0.03491577, 0.03797856, 0.04471669, 0.0474732 ,\n",
       "                     0.0532925 , 0.05482389, 0.06462481, 0.06676876, 0.07534456,\n",
       "                     0.07993874, 0.0848392 , 0.08667688, 0.08882083, 0.10535988,\n",
       "                     0.11026034, 0.12557427, 0.1381317 , 0.15497703, 0.1941807 ,\n",
       "                     0.2058193 , 0.20980092, 0.21286371, 0.22419602, 0.23062787,\n",
       "                     0.23583461, 0.24042879, 0.24471669, 0.25849923, 0.27901991,\n",
       "                     0.28545176, 0.28790199, 0.31179173, 0.31607963, 0.33353752,\n",
       "                     0.33506891, 0.34180704, 0.34977029, 0.35191424, 0.3568147 ,\n",
       "                     0.3797856 , 0.38376723, 0.38836141, 0.39448698, 0.40061256,\n",
       "                     0.42266462, 0.43369066, 0.4474732 , 0.47166922, 0.47381317,\n",
       "                     0.47718224, 0.47840735, 0.49954058, 0.50413476, 0.50750383,\n",
       "                     0.52159265, 0.5295559 , 0.53690658, 0.54272588, 0.54793262,\n",
       "                     0.55650842, 0.57611026, 0.58254211, 0.58928025, 0.5914242 ,\n",
       "                     0.59326187, 0.60367534, 0.6085758 , 0.61163859, 0.61715161,\n",
       "                     0.62113323, 0.63369066, 0.64961715, 0.65727412, 0.66125574,\n",
       "                     0.66493109, 0.66983155, 0.6805513 , 0.68882083, 0.69310873,\n",
       "                     0.71301685, 0.73782542, 0.73996937, 0.76447167, 0.76600306,\n",
       "                     0.77274119, 0.78101072, 0.78223583, 0.78866769, 0.80796325,\n",
       "                     0.8101072 , 0.81470138, 0.82174579, 0.83522205, 0.84287902,\n",
       "                     0.84716692, 0.84931087, 0.85451761, 0.85941807, 0.86799387,\n",
       "                     0.87473201, 0.87656968, 0.87901991, 0.8805513 , 0.88759571,\n",
       "                     0.88943338, 0.89709035, 0.90199081, 0.91148545, 0.92343032,\n",
       "                     0.92741194, 0.92863706, 0.93200613, 0.95344564, 0.95558959,\n",
       "                     0.96355283, 0.96630934, 0.96967841, 0.97580398, 0.97733538,\n",
       "                     0.98039816, 0.98223583, 0.98897397, 0.9898928 , 0.99326187,\n",
       "                     0.99448698, 0.99509954, 0.9957121 , 0.99632466, 0.99663093,\n",
       "                     0.99724349, 0.99785605, 0.99816233, 0.99938744, 0.99969372,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -8.00427077e-02, -1.82321557e-01,\n",
       "                     -2.23143551e-01, -2.41162057e-01, -2.87682072e-01, -3.36472237e-01,\n",
       "                     -4.05465108e-01, -4.41832752e-01, -4.56758402e-01, -4.70003629e-01,\n",
       "                     -5.10825624e-01, -5.38996501e-01, -5.59615788e-01, -5.87786665e-01,\n",
       "                     -5.94707108e-01, -6.06135804e-01, -6.19039208e-01, -6.26136470e-01,\n",
       "                     -6.28608659e-01, -6.52325186e-01, -6.55875786e-01, -6.56105909e-01,\n",
       "                     -6.93147181e-01, -7.19122667e-01, -7.30887509e-01, -7.41937345e-01,\n",
       "                     -7.45790914e-01, -7.62140052e-01, -7.77704569e-01, -7.88457360e-01,\n",
       "                     -7.94929875e-01, -7.98507696e-01, -7.99253687e-01, -8.05625164e-01,\n",
       "                     -8.10930216e-01, -8.47297860e-01, -8.57450232e-01, -8.69603618e-01,\n",
       "                     -8.75468737e-01, -8.79249460e-01, -8.85038188e-01, -8.87303195e-01,\n",
       "                     -8.90972924e-01, -8.91998039e-01, -9.00786545e-01, -9.02867712e-01,\n",
       "                     -9.16290732e-01, -9.36093359e-01, -9.38269639e-01, -9.59775844e-01,\n",
       "                     -9.80829253e-01, -9.87138422e-01, -9.98528830e-01, -1.00330211e+00,\n",
       "                     -1.01160091e+00, -1.02338887e+00, -1.02961942e+00, -1.03609193e+00,\n",
       "                     -1.03889305e+00, -1.04596856e+00, -1.05605267e+00, -1.06471074e+00,\n",
       "                     -1.07880966e+00, -1.09861229e+00, -1.11411648e+00, -1.12986483e+00,\n",
       "                     -1.14306405e+00, -1.14513230e+00, -1.15267951e+00, -1.15577070e+00,\n",
       "                     -1.15923691e+00, -1.16315081e+00, -1.17007125e+00, -1.17272026e+00,\n",
       "                     -1.18426773e+00, -1.18455472e+00, -1.18784342e+00, -1.19625076e+00,\n",
       "                     -1.20397280e+00, -1.21639532e+00, -1.22377543e+00, -1.23676263e+00,\n",
       "                     -1.25276297e+00, -1.26803044e+00, -1.27197753e+00, -1.27296568e+00,\n",
       "                     -1.27745558e+00, -1.28093385e+00, -1.30340670e+00, -1.30933332e+00,\n",
       "                     -1.32175584e+00, -1.32492541e+00, -1.33750420e+00, -1.34992672e+00,\n",
       "                     -1.35239281e+00, -1.36431545e+00, -1.37486567e+00, -1.38629436e+00,\n",
       "                     -1.40399394e+00, -1.42138568e+00, -1.44345277e+00, -1.44691898e+00,\n",
       "                     -1.45528723e+00, -1.46283444e+00, -1.46633707e+00, -1.47590652e+00,\n",
       "                     -1.48160454e+00, -1.49923477e+00, -1.50407740e+00, -1.51732262e+00,\n",
       "                     -1.51787072e+00, -1.52885743e+00, -1.57288032e+00, -1.57818537e+00,\n",
       "                     -1.60943791e+00, -1.62745642e+00, -1.63482715e+00, -1.63760879e+00,\n",
       "                     -1.66915715e+00, -1.67397643e+00, -1.74523945e+00, -1.74919985e+00,\n",
       "                     -1.79175947e+00, -1.84054963e+00, -1.89711998e+00, -1.97155258e+00,\n",
       "                     -1.99243016e+00, -2.04475598e+00, -2.07944154e+00, -2.14006616e+00,\n",
       "                     -2.19722458e+00, -2.35137526e+00, -2.39789527e+00, -2.44234704e+00,\n",
       "                     -2.56494936e+00, -2.70805020e+00, -2.72457950e+00, -3.17805383e+00,\n",
       "                     -4.31748811e+00, -3.45387764e+01]), auc_score=0.5628894277040686, privacy_risk=0.5464295350527879, accuracy=0.5464295350527879, tpr_ind=0.6336906584992343, tnr_ind=0.4591684116063416, test_train_ratio=1.0238897396630935, dataset_size=[3265, 3343]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.0120012 , 0.0120012 , 0.01530153, 0.01770177,\n",
       "                     0.01860186, 0.02040204, 0.02040204, 0.02430243, 0.03150315,\n",
       "                     0.03540354, 0.03720372, 0.0420042 , 0.04230423, 0.04410441,\n",
       "                     0.04560456, 0.04620462, 0.05010501, 0.05070507, 0.05160516,\n",
       "                     0.05520552, 0.05550555, 0.05910591, 0.06810681, 0.07020702,\n",
       "                     0.07380738, 0.0780078 , 0.08250825, 0.10891089, 0.12391239,\n",
       "                     0.12541254, 0.12721272, 0.13591359, 0.13711371, 0.14191419,\n",
       "                     0.1440144 , 0.15931593, 0.16771677, 0.17731773, 0.18421842,\n",
       "                     0.18511851, 0.19081908, 0.19171917, 0.19921992, 0.20252025,\n",
       "                     0.20642064, 0.21272127, 0.21932193, 0.23312331, 0.23492349,\n",
       "                     0.24362436, 0.24662466, 0.24992499, 0.28982898, 0.30183018,\n",
       "                     0.30513051, 0.31233123, 0.31563156, 0.34563456, 0.3510351 ,\n",
       "                     0.36273627, 0.37563756, 0.38493849, 0.38673867, 0.40084008,\n",
       "                     0.40294029, 0.41164116, 0.41164116, 0.41764176, 0.41974197,\n",
       "                     0.4230423 , 0.44974497, 0.45484548, 0.48034803, 0.51185119,\n",
       "                     0.52715272, 0.53075308, 0.53525353, 0.53855386, 0.57875788,\n",
       "                     0.58235824, 0.59705971, 0.59855986, 0.6009601 , 0.60366037,\n",
       "                     0.60756076, 0.61656166, 0.62736274, 0.63426343, 0.63666367,\n",
       "                     0.65856586, 0.66306631, 0.67116712, 0.67476748, 0.68016802,\n",
       "                     0.69576958, 0.69756976, 0.69876988, 0.7149715 , 0.72517252,\n",
       "                     0.7269727 , 0.73147315, 0.74347435, 0.75427543, 0.75757576,\n",
       "                     0.76867687, 0.79387939, 0.80708071, 0.81818182, 0.82238224,\n",
       "                     0.8229823 , 0.82688269, 0.83138314, 0.83408341, 0.85088509,\n",
       "                     0.85268527, 0.85478548, 0.86018602, 0.86588659, 0.89138914,\n",
       "                     0.9129913 , 0.91989199, 0.92229223, 0.9249925 , 0.94269427,\n",
       "                     0.94569457, 0.94839484, 0.94929493, 0.95109511, 0.95769577,\n",
       "                     0.95919592, 0.96039604, 0.96459646, 0.9669967 , 0.96849685,\n",
       "                     0.97119712, 0.97209721, 0.97329733, 0.97449745, 0.97689769,\n",
       "                     0.97809781, 1.        ]), tpr=array([0.        , 0.02229008, 0.02564885, 0.02992366, 0.03389313,\n",
       "                     0.03572519, 0.03725191, 0.03847328, 0.04396947, 0.05465649,\n",
       "                     0.0589313 , 0.06229008, 0.07083969, 0.07358779, 0.07572519,\n",
       "                     0.07877863, 0.08122137, 0.08763359, 0.08885496, 0.0940458 ,\n",
       "                     0.09709924, 0.0989313 , 0.10320611, 0.11603053, 0.11908397,\n",
       "                     0.12244275, 0.12610687, 0.13007634, 0.1621374 , 0.18167939,\n",
       "                     0.18534351, 0.18870229, 0.2021374 , 0.20427481, 0.20793893,\n",
       "                     0.20946565, 0.22839695, 0.23633588, 0.24610687, 0.2519084 ,\n",
       "                     0.2540458 , 0.26412214, 0.2659542 , 0.27114504, 0.27541985,\n",
       "                     0.27938931, 0.28396947, 0.29435115, 0.30870229, 0.31206107,\n",
       "                     0.32366412, 0.32885496, 0.33282443, 0.36916031, 0.37832061,\n",
       "                     0.38198473, 0.38870229, 0.39175573, 0.41832061, 0.4259542 ,\n",
       "                     0.4351145 , 0.44732824, 0.45557252, 0.45740458, 0.47541985,\n",
       "                     0.47664122, 0.48793893, 0.48946565, 0.49740458, 0.49954198,\n",
       "                     0.50656489, 0.52946565, 0.53526718, 0.5648855 , 0.59206107,\n",
       "                     0.60519084, 0.60916031, 0.61679389, 0.62015267, 0.65770992,\n",
       "                     0.66198473, 0.67603053, 0.67908397, 0.68305344, 0.68671756,\n",
       "                     0.68885496, 0.69496183, 0.70564885, 0.71114504, 0.71358779,\n",
       "                     0.73312977, 0.73679389, 0.74167939, 0.74564885, 0.75083969,\n",
       "                     0.76122137, 0.76458015, 0.76610687, 0.77801527, 0.78687023,\n",
       "                     0.78931298, 0.79145038, 0.80671756, 0.81587786, 0.82259542,\n",
       "                     0.83328244, 0.86076336, 0.86961832, 0.87725191, 0.88061069,\n",
       "                     0.88152672, 0.8848855 , 0.8870229 , 0.88946565, 0.90656489,\n",
       "                     0.90748092, 0.90961832, 0.91389313, 0.91908397, 0.94137405,\n",
       "                     0.95633588, 0.96030534, 0.96091603, 0.96335878, 0.98045802,\n",
       "                     0.98167939, 0.98503817, 0.9859542 , 0.98717557, 0.98992366,\n",
       "                     0.99175573, 0.99267176, 0.99328244, 0.99450382, 0.99572519,\n",
       "                     0.99664122, 0.99755725, 0.9978626 , 0.99847328, 0.99969466,\n",
       "                     1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -8.70113770e-02, -1.33531393e-01,\n",
       "                     -1.43100844e-01, -1.54150680e-01, -1.82321557e-01, -2.23143551e-01,\n",
       "                     -2.87682072e-01, -3.36472237e-01, -3.56674944e-01, -3.74693449e-01,\n",
       "                     -4.05465108e-01, -4.41832752e-01, -4.51985124e-01, -4.70003629e-01,\n",
       "                     -4.85507816e-01, -5.10825624e-01, -5.59615788e-01, -5.67984038e-01,\n",
       "                     -5.87786665e-01, -6.06135804e-01, -6.19039208e-01, -6.31778234e-01,\n",
       "                     -6.41853886e-01, -6.46627165e-01, -6.50587566e-01, -6.53926467e-01,\n",
       "                     -6.93147181e-01, -7.23918839e-01, -7.33969175e-01, -7.37598943e-01,\n",
       "                     -7.59105148e-01, -7.62140052e-01, -7.73189888e-01, -7.88457360e-01,\n",
       "                     -7.98507696e-01, -8.02346473e-01, -8.10930216e-01, -8.16761137e-01,\n",
       "                     -8.26678573e-01, -8.34225779e-01, -8.47297860e-01, -8.55666110e-01,\n",
       "                     -8.57450232e-01, -8.69037847e-01, -8.75468737e-01, -8.80358723e-01,\n",
       "                     -8.94784527e-01, -8.97941593e-01, -9.16290732e-01, -9.27986772e-01,\n",
       "                     -9.31558204e-01, -9.37904208e-01, -9.42608040e-01, -9.49080555e-01,\n",
       "                     -9.52008814e-01, -9.55511445e-01, -9.56385189e-01, -9.70778917e-01,\n",
       "                     -9.80829253e-01, -9.83949380e-01, -9.94622575e-01, -9.98528830e-01,\n",
       "                     -9.99405639e-01, -1.01160091e+00, -1.01405490e+00, -1.02961942e+00,\n",
       "                     -1.03236290e+00, -1.04982212e+00, -1.05416053e+00, -1.06240924e+00,\n",
       "                     -1.06289421e+00, -1.08824950e+00, -1.09861229e+00, -1.12160181e+00,\n",
       "                     -1.12393010e+00, -1.12492960e+00, -1.12846525e+00, -1.13323625e+00,\n",
       "                     -1.14513230e+00, -1.14809235e+00, -1.16315081e+00, -1.17272026e+00,\n",
       "                     -1.17865500e+00, -1.18958407e+00, -1.19392247e+00, -1.19824213e+00,\n",
       "                     -1.20397280e+00, -1.21639532e+00, -1.22101427e+00, -1.22866542e+00,\n",
       "                     -1.23474446e+00, -1.24171313e+00, -1.24432410e+00, -1.25276297e+00,\n",
       "                     -1.26566637e+00, -1.28093385e+00, -1.29928298e+00, -1.31483540e+00,\n",
       "                     -1.32175584e+00, -1.34992672e+00, -1.35583515e+00, -1.36097655e+00,\n",
       "                     -1.37486567e+00, -1.38629436e+00, -1.39183454e+00, -1.41182766e+00,\n",
       "                     -1.43508453e+00, -1.45225233e+00, -1.46633707e+00, -1.47330574e+00,\n",
       "                     -1.48807706e+00, -1.50407740e+00, -1.50803780e+00, -1.54044504e+00,\n",
       "                     -1.55059741e+00, -1.58045038e+00, -1.59760345e+00, -1.60943791e+00,\n",
       "                     -1.65335715e+00, -1.69773052e+00, -1.70474809e+00, -1.72722095e+00,\n",
       "                     -1.77070606e+00, -1.79175947e+00, -1.82161243e+00, -1.89711998e+00,\n",
       "                     -1.90954250e+00, -1.94591015e+00, -1.96944065e+00, -2.03688193e+00,\n",
       "                     -2.07944154e+00, -2.16905370e+00, -2.19722458e+00, -2.51230562e+00,\n",
       "                     -2.53897387e+00, -2.56494936e+00, -2.67414865e+00, -2.83321334e+00,\n",
       "                     -2.99573227e+00, -3.45387764e+01]), auc_score=0.563532612803265, privacy_risk=0.5422687306898629, accuracy=0.5422687306898629, tpr_ind=0.5648854961832062, tnr_ind=0.5196519651965197, test_train_ratio=1.017709923664122, dataset_size=[3275, 3333]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00657698, 0.00717489, 0.00926756, 0.01076233,\n",
       "                     0.01315396, 0.01315396, 0.01345291, 0.01524664, 0.01913303,\n",
       "                     0.01973094, 0.02780269, 0.02959641, 0.03886398, 0.04334828,\n",
       "                     0.05171898, 0.05470852, 0.06337818, 0.06576981, 0.06666667,\n",
       "                     0.07055306, 0.07533632, 0.07952167, 0.08251121, 0.08699552,\n",
       "                     0.09327354, 0.10612855, 0.11928251, 0.12944694, 0.13303438,\n",
       "                     0.13751868, 0.14349776, 0.167713  , 0.17100149, 0.17518685,\n",
       "                     0.17698057, 0.19103139, 0.19252616, 0.19581465, 0.20627803,\n",
       "                     0.21375187, 0.22272048, 0.22391629, 0.25022422, 0.25171898,\n",
       "                     0.25381166, 0.25889387, 0.26038864, 0.26337818, 0.26606876,\n",
       "                     0.27414051, 0.30792227, 0.32017937, 0.32376682, 0.33602392,\n",
       "                     0.34379671, 0.35366218, 0.36053812, 0.36681614, 0.36980568,\n",
       "                     0.37130045, 0.37428999, 0.37668161, 0.37877429, 0.38266069,\n",
       "                     0.39282511, 0.39790732, 0.40209268, 0.40986547, 0.41763827,\n",
       "                     0.43856502, 0.445142  , 0.45112108, 0.45949178, 0.46188341,\n",
       "                     0.48460389, 0.48908819, 0.50254111, 0.51629297, 0.52197309,\n",
       "                     0.52795217, 0.5431988 , 0.55814649, 0.55904335, 0.5632287 ,\n",
       "                     0.56442451, 0.57219731, 0.60896861, 0.64334828, 0.65351271,\n",
       "                     0.66487294, 0.66846039, 0.67533632, 0.68370703, 0.71659193,\n",
       "                     0.72167414, 0.72615845, 0.72675635, 0.74469357, 0.74529148,\n",
       "                     0.7632287 , 0.77488789, 0.77787743, 0.78535127, 0.78834081,\n",
       "                     0.81763827, 0.81823617, 0.83109118, 0.8367713 , 0.84275037,\n",
       "                     0.84813154, 0.85440957, 0.8651719 , 0.8690583 , 0.86995516,\n",
       "                     0.87713004, 0.88849028, 0.88908819, 0.89118087, 0.89297459,\n",
       "                     0.89925262, 0.90553064, 0.9103139 , 0.91300448, 0.9142003 ,\n",
       "                     0.92017937, 0.93153961, 0.93183857, 0.93721973, 0.95336323,\n",
       "                     0.95784753, 0.9593423 , 0.96203288, 0.96442451, 0.96651719,\n",
       "                     0.96651719, 0.96801196, 0.96860987, 0.97100149, 0.9793722 ,\n",
       "                     0.98116592, 0.9838565 , 0.98505232, 0.98505232, 1.        ]), tpr=array([0.        , 0.01562979, 0.01838799, 0.02083972, 0.02237205,\n",
       "                     0.02482378, 0.02696905, 0.02880785, 0.03125958, 0.03585657,\n",
       "                     0.03800184, 0.04596997, 0.04903463, 0.05730922, 0.06313209,\n",
       "                     0.07539074, 0.07784248, 0.0950046 , 0.09653693, 0.09898866,\n",
       "                     0.10419859, 0.11002145, 0.11676371, 0.12136071, 0.12779651,\n",
       "                     0.13729697, 0.14924916, 0.16181428, 0.16916948, 0.1789764 ,\n",
       "                     0.1854122 , 0.19276739, 0.22065584, 0.22525283, 0.23076923,\n",
       "                     0.23567269, 0.25283481, 0.25406068, 0.25988354, 0.26877107,\n",
       "                     0.27520686, 0.28256206, 0.28501379, 0.31198284, 0.3150475 ,\n",
       "                     0.3187251 , 0.32301563, 0.32577383, 0.33466135, 0.33987128,\n",
       "                     0.34753295, 0.37848606, 0.38522832, 0.38921238, 0.40392277,\n",
       "                     0.41311676, 0.42231076, 0.42629482, 0.43273062, 0.43518235,\n",
       "                     0.43855348, 0.44284401, 0.44744101, 0.45050567, 0.45632853,\n",
       "                     0.47042599, 0.47471652, 0.47778118, 0.48268465, 0.49095924,\n",
       "                     0.50904076, 0.51823475, 0.52681581, 0.53509041, 0.5396874 ,\n",
       "                     0.56083359, 0.56665645, 0.58075391, 0.59331903, 0.59791603,\n",
       "                     0.60220656, 0.61661048, 0.63224027, 0.63438553, 0.63959546,\n",
       "                     0.64235366, 0.64603126, 0.6849525 , 0.72540607, 0.73398713,\n",
       "                     0.74256819, 0.74471345, 0.74992338, 0.75973031, 0.78363469,\n",
       "                     0.78669936, 0.79466748, 0.79589335, 0.81397487, 0.8155072 ,\n",
       "                     0.82347533, 0.83481459, 0.83604045, 0.84216978, 0.84492798,\n",
       "                     0.87250996, 0.87373583, 0.88599448, 0.89334968, 0.89733374,\n",
       "                     0.89917254, 0.90560834, 0.91449586, 0.91725406, 0.91939933,\n",
       "                     0.92460926, 0.93165798, 0.93257738, 0.93380325, 0.93686791,\n",
       "                     0.94728777, 0.95127184, 0.9534171 , 0.9561753 , 0.95678823,\n",
       "                     0.95832056, 0.96874042, 0.96904689, 0.97149862, 0.98130555,\n",
       "                     0.98375728, 0.98528961, 0.98590254, 0.98743488, 0.98927367,\n",
       "                     0.98958014, 0.99049954, 0.99141894, 0.9935642 , 0.99754827,\n",
       "                     0.9981612 , 0.99938707, 0.99969353, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.05360516e-01, -1.17783036e-01,\n",
       "                     -1.82321557e-01, -2.23143551e-01, -2.51314428e-01, -2.87682072e-01,\n",
       "                     -3.18453731e-01, -3.36472237e-01, -3.56674944e-01, -4.05465108e-01,\n",
       "                     -4.70003629e-01, -5.10825624e-01, -5.21296924e-01, -5.30628251e-01,\n",
       "                     -5.59615788e-01, -5.69768159e-01, -5.87786665e-01, -6.28608659e-01,\n",
       "                     -6.32522559e-01, -6.39079959e-01, -6.46627165e-01, -6.59245629e-01,\n",
       "                     -6.69049629e-01, -6.76886660e-01, -6.80243776e-01, -6.93147181e-01,\n",
       "                     -7.13766468e-01, -7.23918839e-01, -7.39667196e-01, -7.53771802e-01,\n",
       "                     -7.56998653e-01, -7.57685702e-01, -7.73189888e-01, -7.82759339e-01,\n",
       "                     -7.86832665e-01, -8.10930216e-01, -8.16761137e-01, -8.22358912e-01,\n",
       "                     -8.26678573e-01, -8.47297860e-01, -8.64997437e-01, -8.69770716e-01,\n",
       "                     -8.75468737e-01, -8.82389180e-01, -8.87303195e-01, -8.93817876e-01,\n",
       "                     -8.95384047e-01, -9.04456274e-01, -9.08258560e-01, -9.10332422e-01,\n",
       "                     -9.16290732e-01, -9.31558204e-01, -9.32820034e-01, -9.42608040e-01,\n",
       "                     -9.55511445e-01, -9.61411167e-01, -9.62810748e-01, -9.65080896e-01,\n",
       "                     -9.69400557e-01, -9.71860583e-01, -9.80829253e-01, -9.93251773e-01,\n",
       "                     -1.00680474e+00, -1.00764051e+00, -1.02450432e+00, -1.02961942e+00,\n",
       "                     -1.03407377e+00, -1.03489647e+00, -1.04045637e+00, -1.04145387e+00,\n",
       "                     -1.04982212e+00, -1.06087196e+00, -1.07613943e+00, -1.07909947e+00,\n",
       "                     -1.08091271e+00, -1.09133953e+00, -1.09861229e+00, -1.12059120e+00,\n",
       "                     -1.12214279e+00, -1.12658614e+00, -1.13076940e+00, -1.14513230e+00,\n",
       "                     -1.15577070e+00, -1.17007125e+00, -1.20397280e+00, -1.20554637e+00,\n",
       "                     -1.22199131e+00, -1.25276297e+00, -1.26291534e+00, -1.27296568e+00,\n",
       "                     -1.27766052e+00, -1.27919623e+00, -1.28519824e+00, -1.30833282e+00,\n",
       "                     -1.31661444e+00, -1.32175584e+00, -1.32963433e+00, -1.33500107e+00,\n",
       "                     -1.36687628e+00, -1.37951467e+00, -1.38629436e+00, -1.41098697e+00,\n",
       "                     -1.41369334e+00, -1.43508453e+00, -1.44691898e+00, -1.47017585e+00,\n",
       "                     -1.47590652e+00, -1.47810191e+00, -1.50407740e+00, -1.50935445e+00,\n",
       "                     -1.51550609e+00, -1.51634749e+00, -1.51982575e+00, -1.52349548e+00,\n",
       "                     -1.53733462e+00, -1.54044504e+00, -1.55814462e+00, -1.58923521e+00,\n",
       "                     -1.59760345e+00, -1.60943791e+00, -1.63760879e+00, -1.65292302e+00,\n",
       "                     -1.70474809e+00, -1.75785792e+00, -1.76190651e+00, -1.79175947e+00,\n",
       "                     -1.87180218e+00, -1.92333583e+00, -1.94591015e+00, -2.00148000e+00,\n",
       "                     -2.01490302e+00, -2.05412373e+00, -2.10006083e+00, -2.19722458e+00,\n",
       "                     -2.23359222e+00, -2.33537492e+00, -2.38482319e+00, -2.39789527e+00,\n",
       "                     -2.44234704e+00, -2.48490665e+00, -2.56494936e+00, -2.77258872e+00,\n",
       "                     -3.45387764e+01]), auc_score=0.5582727844514777, privacy_risk=0.5410288935095539, accuracy=0.5410288935095539, tpr_ind=0.7254060680355501, tnr_ind=0.3566517189835576, test_train_ratio=1.025130248237818, dataset_size=[3263, 3345]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.01152563, 0.01213224, 0.01334547, 0.014862  ,\n",
       "                     0.01910828, 0.02760085, 0.03245375, 0.03275705, 0.03488019,\n",
       "                     0.0351835 , 0.04306946, 0.04488929, 0.0552017 , 0.05975129,\n",
       "                     0.06157113, 0.070367  , 0.07764635, 0.07976949, 0.08401577,\n",
       "                     0.09463148, 0.11646952, 0.14134061, 0.15195632, 0.15680922,\n",
       "                     0.15953897, 0.16317865, 0.18228693, 0.18895966, 0.19168941,\n",
       "                     0.22444647, 0.22899606, 0.23142251, 0.23566879, 0.24203822,\n",
       "                     0.25022748, 0.26508948, 0.26812254, 0.27267213, 0.27813163,\n",
       "                     0.281468  , 0.28237792, 0.29299363, 0.30269942, 0.31543828,\n",
       "                     0.31998787, 0.33636639, 0.35001517, 0.366697  , 0.37063998,\n",
       "                     0.37882924, 0.38610858, 0.39035487, 0.39824082, 0.40400364,\n",
       "                     0.43160449, 0.51865332, 0.5374583 , 0.5477707 , 0.56050955,\n",
       "                     0.56232939, 0.56869882, 0.57537155, 0.57901122, 0.58416742,\n",
       "                     0.59417652, 0.60115256, 0.60357901, 0.60479224, 0.60721868,\n",
       "                     0.60994844, 0.61510464, 0.62117076, 0.62541705, 0.66636336,\n",
       "                     0.67424932, 0.68001213, 0.68395511, 0.6885047 , 0.70215347,\n",
       "                     0.70245678, 0.7236882 , 0.73005763, 0.73642705, 0.74400971,\n",
       "                     0.74825599, 0.74946921, 0.75310889, 0.76281468, 0.77464362,\n",
       "                     0.7788899 , 0.78738247, 0.78920231, 0.79253867, 0.79496512,\n",
       "                     0.80103124, 0.80467091, 0.80982712, 0.81104034, 0.82499242,\n",
       "                     0.82802548, 0.83682135, 0.83773127, 0.83955111, 0.844404  ,\n",
       "                     0.86502881, 0.86866849, 0.87109493, 0.8744313 , 0.87625114,\n",
       "                     0.88080073, 0.88989991, 0.8944495 , 0.8944495 , 0.91386109,\n",
       "                     0.91689415, 0.93205945, 0.93296937, 0.9347892 , 0.94388838,\n",
       "                     0.94601153, 0.95086442, 0.95632393, 0.95693054, 0.96208675,\n",
       "                     0.96360328, 0.96542311, 0.96815287, 0.96906278, 0.97148923,\n",
       "                     0.97361237, 0.97603882, 0.97785866, 1.        ]), tpr=array([0.        , 0.02204772, 0.02476593, 0.02657807, 0.02929629,\n",
       "                     0.03292057, 0.0474177 , 0.05073996, 0.05225008, 0.05466626,\n",
       "                     0.05738448, 0.06463304, 0.06886137, 0.07852613, 0.08577469,\n",
       "                     0.08909695, 0.09966777, 0.11205074, 0.11507098, 0.11990335,\n",
       "                     0.13017215, 0.15282392, 0.17940199, 0.19057686, 0.19601329,\n",
       "                     0.19842948, 0.20295983, 0.21594684, 0.22108124, 0.2244035 ,\n",
       "                     0.25551193, 0.26457264, 0.26940501, 0.27272727, 0.27876774,\n",
       "                     0.28752643, 0.30474177, 0.30715796, 0.31229236, 0.31863485,\n",
       "                     0.32135307, 0.32316521, 0.3358502 , 0.34309876, 0.35668982,\n",
       "                     0.36575053, 0.37903957, 0.39414074, 0.40682573, 0.40954394,\n",
       "                     0.41830263, 0.43098762, 0.43491392, 0.44216249, 0.4500151 ,\n",
       "                     0.4756871 , 0.56720024, 0.58230142, 0.59830867, 0.61069163,\n",
       "                     0.61491996, 0.62216853, 0.62760495, 0.63213531, 0.6396859 ,\n",
       "                     0.65055874, 0.65418303, 0.65750529, 0.66052552, 0.66294171,\n",
       "                     0.66596195, 0.67170039, 0.67894896, 0.68196919, 0.72334642,\n",
       "                     0.72938689, 0.73603141, 0.73754153, 0.74116581, 0.75354878,\n",
       "                     0.75354878, 0.77136817, 0.7795228 , 0.78858351, 0.79583207,\n",
       "                     0.80096648, 0.80398671, 0.80942314, 0.81878587, 0.82512836,\n",
       "                     0.82754455, 0.83298097, 0.83449109, 0.83781335, 0.84053156,\n",
       "                     0.84657203, 0.85049834, 0.85593476, 0.85744488, 0.86952582,\n",
       "                     0.87224404, 0.88190879, 0.88704319, 0.88855331, 0.89519783,\n",
       "                     0.91784959, 0.92086983, 0.92268197, 0.92479613, 0.92630625,\n",
       "                     0.93174268, 0.93566898, 0.93838719, 0.93959529, 0.95801873,\n",
       "                     0.96073694, 0.97100574, 0.97191181, 0.9731199 , 0.98036847,\n",
       "                     0.98308668, 0.98580489, 0.99184536, 0.99244941, 0.99426155,\n",
       "                     0.99546965, 0.99667774, 0.99818786, 0.99848988, 0.99909393,\n",
       "                     0.99939595, 0.99969798, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.05360516e-01, -1.54150680e-01,\n",
       "                     -2.87682072e-01, -3.48306694e-01, -4.05465108e-01, -4.35318071e-01,\n",
       "                     -4.70003629e-01, -4.85507816e-01, -5.10825624e-01, -5.35518236e-01,\n",
       "                     -5.38996501e-01, -5.41597282e-01, -5.59615788e-01, -5.97837001e-01,\n",
       "                     -6.19039208e-01, -6.30233355e-01, -6.41853886e-01, -6.61398482e-01,\n",
       "                     -6.78332095e-01, -6.93147181e-01, -7.15620036e-01, -7.19815428e-01,\n",
       "                     -7.20546155e-01, -7.53771802e-01, -7.57685702e-01, -7.60588461e-01,\n",
       "                     -7.77704569e-01, -7.80158558e-01, -7.85806011e-01, -7.88457360e-01,\n",
       "                     -8.10930216e-01, -8.20980552e-01, -8.32909123e-01, -8.37396789e-01,\n",
       "                     -8.39750655e-01, -8.64997437e-01, -8.80358723e-01, -8.87303195e-01,\n",
       "                     -8.93817876e-01, -9.16290732e-01, -9.44461609e-01, -9.49080555e-01,\n",
       "                     -9.55511445e-01, -9.68250471e-01, -9.69400557e-01, -9.70778917e-01,\n",
       "                     -9.71860583e-01, -9.80829253e-01, -9.89412997e-01, -9.89718200e-01,\n",
       "                     -9.90398704e-01, -9.96333440e-01, -1.00458334e+00, -1.02118055e+00,\n",
       "                     -1.02796789e+00, -1.02961942e+00, -1.03365439e+00, -1.04145387e+00,\n",
       "                     -1.04982212e+00, -1.05605267e+00, -1.06087196e+00, -1.07613943e+00,\n",
       "                     -1.08518927e+00, -1.09861229e+00, -1.12601126e+00, -1.12846525e+00,\n",
       "                     -1.13140211e+00, -1.13943428e+00, -1.16315081e+00, -1.18269541e+00,\n",
       "                     -1.19139402e+00, -1.19392247e+00, -1.20251188e+00, -1.20896035e+00,\n",
       "                     -1.21302264e+00, -1.22377543e+00, -1.22866542e+00, -1.24225499e+00,\n",
       "                     -1.25276297e+00, -1.25518135e+00, -1.25804003e+00, -1.26224171e+00,\n",
       "                     -1.27629347e+00, -1.27766052e+00, -1.28093385e+00, -1.28401551e+00,\n",
       "                     -1.31094492e+00, -1.31218639e+00, -1.32175584e+00, -1.32913595e+00,\n",
       "                     -1.33500107e+00, -1.33977435e+00, -1.35812348e+00, -1.36097655e+00,\n",
       "                     -1.36687628e+00, -1.37230812e+00, -1.38629436e+00, -1.39871688e+00,\n",
       "                     -1.41369334e+00, -1.41706602e+00, -1.42946653e+00, -1.43508453e+00,\n",
       "                     -1.46283444e+00, -1.49065438e+00, -1.50407740e+00, -1.54044504e+00,\n",
       "                     -1.55059741e+00, -1.56861592e+00, -1.58696506e+00, -1.60943791e+00,\n",
       "                     -1.65292302e+00, -1.65822808e+00, -1.68213974e+00, -1.69459572e+00,\n",
       "                     -1.73113485e+00, -1.73460106e+00, -1.74919985e+00, -1.75642010e+00,\n",
       "                     -1.86321843e+00, -1.92990981e+00, -2.10413415e+00, -2.14006616e+00,\n",
       "                     -2.19722458e+00, -2.27726729e+00, -2.30258509e+00, -2.34180581e+00,\n",
       "                     -2.39789527e+00, -2.94443898e+00, -3.04452244e+00, -3.46573590e+00,\n",
       "                     -3.68887945e+00, -3.45387764e+01]), auc_score=0.5421426835503057, privacy_risk=0.5288890983602879, accuracy=0.5288890983602879, tpr_ind=0.6789489580187255, tnr_ind=0.37882923870185015, test_train_ratio=0.9957716701902748, dataset_size=[3311, 3297]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.00458575, 0.00703149, 0.00794864, 0.01284011,\n",
       "                     0.01467441, 0.01528585, 0.01834301, 0.02262305, 0.02506879,\n",
       "                     0.03026597, 0.03118312, 0.03301743, 0.03546316, 0.04004891,\n",
       "                     0.04738612, 0.04830327, 0.04830327, 0.0614491 , 0.06909202,\n",
       "                     0.07826353, 0.08040355, 0.08223785, 0.09293794, 0.09660654,\n",
       "                     0.10516662, 0.10700092, 0.11158667, 0.15622134, 0.16080709,\n",
       "                     0.16416998, 0.16753286, 0.16967288, 0.17517579, 0.18495873,\n",
       "                     0.19076735, 0.19504739, 0.19963314, 0.20421889, 0.21125038,\n",
       "                     0.21430755, 0.21767044, 0.233262  , 0.26138795, 0.26994803,\n",
       "                     0.27911954, 0.28401101, 0.29960257, 0.30632834, 0.30938551,\n",
       "                     0.31305411, 0.32283705, 0.33292571, 0.33873433, 0.34637725,\n",
       "                     0.35188016, 0.35432589, 0.35768878, 0.36258025, 0.36930602,\n",
       "                     0.37175176, 0.39040049, 0.39223479, 0.39773769, 0.41363497,\n",
       "                     0.41913788, 0.42616937, 0.42892082, 0.43564659, 0.45154387,\n",
       "                     0.45551819, 0.48670131, 0.49159279, 0.51757872, 0.5279731 ,\n",
       "                     0.53133598, 0.54906756, 0.56893916, 0.57352492, 0.58116784,\n",
       "                     0.58422501, 0.60012229, 0.60654234, 0.61357383, 0.62060532,\n",
       "                     0.62794253, 0.63375115, 0.64078264, 0.64750841, 0.68816876,\n",
       "                     0.68847447, 0.69550596, 0.72240905, 0.7269948 , 0.73310914,\n",
       "                     0.73494344, 0.73647203, 0.74075206, 0.76826659, 0.77285234,\n",
       "                     0.77927239, 0.78905533, 0.79425252, 0.80953837, 0.81748701,\n",
       "                     0.82390706, 0.8263528 , 0.84133293, 0.84347294, 0.84500153,\n",
       "                     0.85203302, 0.86456741, 0.86701315, 0.87007031, 0.87190462,\n",
       "                     0.8752675 , 0.87954754, 0.89085906, 0.89085906, 0.8969734 ,\n",
       "                     0.91745644, 0.92907368, 0.93151941, 0.93243656, 0.9385509 ,\n",
       "                     0.94894528, 0.95139101, 0.95230816, 0.9547539 , 0.95719963,\n",
       "                     0.95933965, 0.95964537, 0.96514827, 0.96728829, 0.96820544,\n",
       "                     0.97187404, 0.9727912 , 0.9746255 , 0.97615408, 1.        ]), tpr=array([0.        , 0.01288583, 0.01648187, 0.01947857, 0.02667066,\n",
       "                     0.02996704, 0.03206473, 0.03566077, 0.03865748, 0.04075517,\n",
       "                     0.04584957, 0.04824693, 0.04974528, 0.05364099, 0.06083308,\n",
       "                     0.06892418, 0.07102188, 0.07222056, 0.09020078, 0.10098891,\n",
       "                     0.10997902, 0.1132754 , 0.11687144, 0.12825892, 0.13095595,\n",
       "                     0.14084507, 0.1456398 , 0.15193287, 0.20497453, 0.20857057,\n",
       "                     0.21156728, 0.21726101, 0.21995805, 0.22655079, 0.23733893,\n",
       "                     0.24273299, 0.24932574, 0.25232245, 0.25591849, 0.26221157,\n",
       "                     0.26730596, 0.27030267, 0.28798322, 0.33023674, 0.33982619,\n",
       "                     0.34641894, 0.35271202, 0.36589751, 0.37428828, 0.37848367,\n",
       "                     0.38088103, 0.38987114, 0.40155829, 0.40755169, 0.4165418 ,\n",
       "                     0.42433323, 0.43092598, 0.43452203, 0.43901708, 0.44830686,\n",
       "                     0.45250225, 0.46868445, 0.47258016, 0.48067126, 0.49655379,\n",
       "                     0.50194786, 0.50734192, 0.51303566, 0.51753072, 0.53071621,\n",
       "                     0.53371292, 0.56068325, 0.56817501, 0.59304765, 0.60833084,\n",
       "                     0.61282589, 0.63200479, 0.64998502, 0.65537908, 0.66616722,\n",
       "                     0.66886425, 0.68204975, 0.6865448 , 0.69643392, 0.70212766,\n",
       "                     0.71111777, 0.71681151, 0.72220557, 0.72819898, 0.76445909,\n",
       "                     0.76505844, 0.77165118, 0.79682349, 0.80041954, 0.80551393,\n",
       "                     0.80731196, 0.80940965, 0.81180701, 0.84387174, 0.84656877,\n",
       "                     0.85016482, 0.85915493, 0.86215163, 0.8726401 , 0.88103087,\n",
       "                     0.88702427, 0.88972131, 0.90470482, 0.90680252, 0.90919988,\n",
       "                     0.91369494, 0.92028768, 0.92298472, 0.92568175, 0.92777944,\n",
       "                     0.93047648, 0.93347318, 0.93946659, 0.9403656 , 0.94276296,\n",
       "                     0.96014384, 0.97123165, 0.97392868, 0.97512736, 0.97812406,\n",
       "                     0.98321846, 0.98411747, 0.98471681, 0.98561582, 0.98801319,\n",
       "                     0.98921187, 0.98981121, 0.99550494, 0.99640396, 0.9970033 ,\n",
       "                     0.99790231, 0.99820198, 0.99910099, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.54150680e-01, -1.82321557e-01,\n",
       "                     -2.23143551e-01, -2.41162057e-01, -2.51314428e-01, -2.87682072e-01,\n",
       "                     -3.36472237e-01, -3.56674944e-01, -3.85662481e-01, -4.05465108e-01,\n",
       "                     -4.70003629e-01, -4.79573080e-01, -4.85507816e-01, -5.10825624e-01,\n",
       "                     -5.38996501e-01, -5.59615788e-01, -5.69094532e-01, -5.75364145e-01,\n",
       "                     -5.87786665e-01, -5.97837001e-01, -6.06135804e-01, -6.10909082e-01,\n",
       "                     -6.35988767e-01, -6.46627165e-01, -6.61398482e-01, -6.69049629e-01,\n",
       "                     -6.93147181e-01, -7.33969175e-01, -7.41937345e-01, -7.44440475e-01,\n",
       "                     -7.47214402e-01, -7.59105148e-01, -7.60286483e-01, -7.73189888e-01,\n",
       "                     -7.80158558e-01, -7.88457360e-01, -8.10930216e-01, -8.26678573e-01,\n",
       "                     -8.30348302e-01, -8.32909123e-01, -8.35117442e-01, -8.38137491e-01,\n",
       "                     -8.38329190e-01, -8.40783179e-01, -8.47297860e-01, -8.50539354e-01,\n",
       "                     -8.52211875e-01, -8.57450232e-01, -8.64997437e-01, -8.75468737e-01,\n",
       "                     -8.79733136e-01, -8.96088025e-01, -9.02867712e-01, -9.16290732e-01,\n",
       "                     -9.34309237e-01, -9.49080555e-01, -9.55511445e-01, -9.60461950e-01,\n",
       "                     -9.71860583e-01, -9.80829253e-01, -9.90398704e-01, -9.94622575e-01,\n",
       "                     -9.99521386e-01, -1.00144854e+00, -1.02165125e+00, -1.02585293e+00,\n",
       "                     -1.02961942e+00, -1.03609193e+00, -1.06471074e+00, -1.07992016e+00,\n",
       "                     -1.08518927e+00, -1.09861229e+00, -1.10512697e+00, -1.12059120e+00,\n",
       "                     -1.12938395e+00, -1.13140211e+00, -1.13497993e+00, -1.15267951e+00,\n",
       "                     -1.17007125e+00, -1.17865500e+00, -1.20397280e+00, -1.21302264e+00,\n",
       "                     -1.21444410e+00, -1.22377543e+00, -1.22994829e+00, -1.23676263e+00,\n",
       "                     -1.23969089e+00, -1.25158163e+00, -1.25276297e+00, -1.26566637e+00,\n",
       "                     -1.27296568e+00, -1.27629347e+00, -1.27766052e+00, -1.29928298e+00,\n",
       "                     -1.31218639e+00, -1.32175584e+00, -1.32610773e+00, -1.32913595e+00,\n",
       "                     -1.34373475e+00, -1.35239281e+00, -1.38629436e+00, -1.40047900e+00,\n",
       "                     -1.41272762e+00, -1.42310833e+00, -1.44036158e+00, -1.44926916e+00,\n",
       "                     -1.45528723e+00, -1.47590652e+00, -1.49664242e+00, -1.50407740e+00,\n",
       "                     -1.51634749e+00, -1.54044504e+00, -1.55059741e+00, -1.58696506e+00,\n",
       "                     -1.60943791e+00, -1.64865863e+00, -1.67397643e+00, -1.68175857e+00,\n",
       "                     -1.68576018e+00, -1.68739945e+00, -1.71479843e+00, -1.74919985e+00,\n",
       "                     -1.79175947e+00, -1.81117756e+00, -1.84582669e+00, -1.87180218e+00,\n",
       "                     -1.89711998e+00, -2.01490302e+00, -2.04769284e+00, -2.07944154e+00,\n",
       "                     -2.13696539e+00, -2.15948425e+00, -2.19722458e+00, -2.39789527e+00,\n",
       "                     -2.48490665e+00, -2.53897387e+00, -2.68557735e+00, -3.45387764e+01]), auc_score=0.5607766950087706, privacy_risk=0.542499688740429, accuracy=0.542499688740429, tpr_ind=0.6661672160623314, tnr_ind=0.41883216141852647, test_train_ratio=0.9802217560683248, dataset_size=[3337, 3271]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.0066586 , 0.00938257, 0.01029056, 0.01150121,\n",
       "                     0.01422518, 0.01634383, 0.02421308, 0.02602906, 0.0348063 ,\n",
       "                     0.03783293, 0.04146489, 0.04782082, 0.05266344, 0.05387409,\n",
       "                     0.05841404, 0.062954  , 0.06628329, 0.06991525, 0.0720339 ,\n",
       "                     0.08414044, 0.09322034, 0.10714286, 0.11682809, 0.12469734,\n",
       "                     0.13680387, 0.13892252, 0.14346247, 0.1440678 , 0.15193705,\n",
       "                     0.15405569, 0.15768765, 0.16010896, 0.1622276 , 0.16858354,\n",
       "                     0.1722155 , 0.24939467, 0.25847458, 0.26180387, 0.32294189,\n",
       "                     0.32566586, 0.32929782, 0.36319613, 0.36531477, 0.37318402,\n",
       "                     0.3840799 , 0.38831719, 0.39739709, 0.40496368, 0.40768765,\n",
       "                     0.40950363, 0.41585956, 0.41979419, 0.4279661 , 0.43038741,\n",
       "                     0.45792978, 0.46549637, 0.49122276, 0.4933414 , 0.49818402,\n",
       "                     0.50635593, 0.51119855, 0.52209443, 0.54903148, 0.55932203,\n",
       "                     0.57748184, 0.58081114, 0.58595642, 0.58868039, 0.60139225,\n",
       "                     0.60865617, 0.61803874, 0.62288136, 0.6340799 , 0.63559322,\n",
       "                     0.6464891 , 0.65526634, 0.65587167, 0.68099274, 0.68644068,\n",
       "                     0.6903753 , 0.69612591, 0.70338983, 0.70732446, 0.70792978,\n",
       "                     0.74061743, 0.74424939, 0.74576271, 0.75121065, 0.76422518,\n",
       "                     0.77905569, 0.79539952, 0.80871671, 0.81900726, 0.84382567,\n",
       "                     0.84927361, 0.8559322 , 0.8592615 , 0.86107748, 0.87469734,\n",
       "                     0.87621065, 0.87802663, 0.90163438, 0.91101695, 0.91253027,\n",
       "                     0.91374092, 0.91495157, 0.92100484, 0.9222155 , 0.92524213,\n",
       "                     0.92826877, 0.93038741, 0.93311138, 0.93553269, 0.93734867,\n",
       "                     0.94582324, 0.95096852, 0.95157385, 0.95369249, 0.95581114,\n",
       "                     0.95914044, 0.96004843, 0.96337772, 0.96398305, 0.96549637,\n",
       "                     0.96912833, 0.97003632, 0.97427361, 0.97639225, 1.        ]), tpr=array([0.        , 0.01785714, 0.02239709, 0.02602906, 0.0281477 ,\n",
       "                     0.03268765, 0.0348063 , 0.04812349, 0.05417676, 0.06476998,\n",
       "                     0.06961259, 0.07324455, 0.0811138 , 0.0901937 , 0.09231235,\n",
       "                     0.09776029, 0.10260291, 0.10714286, 0.11047215, 0.11440678,\n",
       "                     0.13075061, 0.13831719, 0.15345036, 0.16192494, 0.16858354,\n",
       "                     0.18280872, 0.18553269, 0.18946731, 0.19128329, 0.19975787,\n",
       "                     0.20248184, 0.20914044, 0.2127724 , 0.21579903, 0.22033898,\n",
       "                     0.22366828, 0.30236077, 0.30992736, 0.3153753 , 0.38014528,\n",
       "                     0.3840799 , 0.3907385 , 0.42312349, 0.42524213, 0.43613801,\n",
       "                     0.45187651, 0.45490315, 0.46670702, 0.47397094, 0.47972155,\n",
       "                     0.48305085, 0.49152542, 0.49424939, 0.49848668, 0.50302663,\n",
       "                     0.53389831, 0.54600484, 0.5653753 , 0.56719128, 0.57415254,\n",
       "                     0.58323245, 0.58868039, 0.60502421, 0.62590799, 0.63680387,\n",
       "                     0.65193705, 0.65587167, 0.66162228, 0.66464891, 0.67887409,\n",
       "                     0.68371671, 0.69158596, 0.69642857, 0.70792978, 0.70883777,\n",
       "                     0.71610169, 0.73062954, 0.73123487, 0.75544794, 0.76150121,\n",
       "                     0.76634383, 0.77088378, 0.77602906, 0.781477  , 0.78389831,\n",
       "                     0.8062954 , 0.80780872, 0.81113801, 0.81658596, 0.82627119,\n",
       "                     0.84049637, 0.85441889, 0.86107748, 0.8683414 , 0.89437046,\n",
       "                     0.89891041, 0.90254237, 0.90405569, 0.90677966, 0.91979419,\n",
       "                     0.9222155 , 0.92372881, 0.94642857, 0.95399516, 0.95581114,\n",
       "                     0.95732446, 0.95853511, 0.96337772, 0.96610169, 0.96791768,\n",
       "                     0.97124697, 0.97336562, 0.97487893, 0.97608959, 0.97790557,\n",
       "                     0.98516949, 0.98880145, 0.98910412, 0.9909201 , 0.99182809,\n",
       "                     0.99243341, 0.99303874, 0.99546005, 0.99606538, 0.99636804,\n",
       "                     0.99757869, 0.99788136, 0.99969734, 1.        , 1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.82321557e-01, -2.23143551e-01,\n",
       "                     -2.51314428e-01, -2.87682072e-01, -3.56674944e-01, -4.05465108e-01,\n",
       "                     -4.38254931e-01, -4.70003629e-01, -4.85507816e-01, -5.10825624e-01,\n",
       "                     -5.26093096e-01, -5.30628251e-01, -5.38996501e-01, -5.43615447e-01,\n",
       "                     -5.59615788e-01, -5.87786665e-01, -6.06135804e-01, -6.13104473e-01,\n",
       "                     -6.26136470e-01, -6.31271777e-01, -6.93147181e-01, -7.10846758e-01,\n",
       "                     -7.15620036e-01, -7.44972248e-01, -7.47214402e-01, -7.67255153e-01,\n",
       "                     -7.73189888e-01, -7.75838896e-01, -7.98507696e-01, -8.00777845e-01,\n",
       "                     -8.10930216e-01, -8.32909123e-01, -8.47297860e-01, -8.60201265e-01,\n",
       "                     -8.73864888e-01, -8.75468737e-01, -8.93817876e-01, -8.95515669e-01,\n",
       "                     -9.00786545e-01, -9.16290732e-01, -9.40299272e-01, -9.44461609e-01,\n",
       "                     -9.49080555e-01, -9.54031060e-01, -9.55511445e-01, -9.61411167e-01,\n",
       "                     -9.80829253e-01, -9.87386654e-01, -1.00330211e+00, -1.01160091e+00,\n",
       "                     -1.02165125e+00, -1.02450432e+00, -1.02961942e+00, -1.03101900e+00,\n",
       "                     -1.03850836e+00, -1.03961395e+00, -1.04145387e+00, -1.06919840e+00,\n",
       "                     -1.07613943e+00, -1.07992016e+00, -1.08618977e+00, -1.09861229e+00,\n",
       "                     -1.10782894e+00, -1.11841492e+00, -1.12393010e+00, -1.14990558e+00,\n",
       "                     -1.16315081e+00, -1.16713224e+00, -1.17865500e+00, -1.18455472e+00,\n",
       "                     -1.19770319e+00, -1.19869575e+00, -1.20397280e+00, -1.21639532e+00,\n",
       "                     -1.23474446e+00, -1.25276297e+00, -1.26694760e+00, -1.28093385e+00,\n",
       "                     -1.28785429e+00, -1.29928298e+00, -1.30992138e+00, -1.31432086e+00,\n",
       "                     -1.32175584e+00, -1.32714669e+00, -1.33500107e+00, -1.33977435e+00,\n",
       "                     -1.34373475e+00, -1.35454566e+00, -1.36478816e+00, -1.36985563e+00,\n",
       "                     -1.38629436e+00, -1.42711636e+00, -1.45644935e+00, -1.46633707e+00,\n",
       "                     -1.50407740e+00, -1.52605630e+00, -1.54044504e+00, -1.57633796e+00,\n",
       "                     -1.58412010e+00, -1.60943791e+00, -1.62004809e+00, -1.63315444e+00,\n",
       "                     -1.64222774e+00, -1.64865863e+00, -1.65822808e+00, -1.70474809e+00,\n",
       "                     -1.71479843e+00, -1.73460106e+00, -1.76098781e+00, -1.76766192e+00,\n",
       "                     -1.79175947e+00, -1.83258146e+00, -1.84582669e+00, -1.87819198e+00,\n",
       "                     -1.92181260e+00, -1.94591015e+00, -2.01490302e+00, -2.03688193e+00,\n",
       "                     -2.07944154e+00, -2.19722458e+00, -2.29000631e+00, -2.35137526e+00,\n",
       "                     -2.39789527e+00, -2.60268969e+00, -2.77258872e+00, -2.87167962e+00,\n",
       "                     -2.99573227e+00, -3.45387764e+01]), auc_score=0.5569148335864078, privacy_risk=0.5414648910411622, accuracy=0.5414648910411622, tpr_ind=0.6050242130750605, tnr_ind=0.47790556900726394, test_train_ratio=1.0, dataset_size=[3304, 3304]),\n",
       "              MIA_Attack_Result(name='subpopulation_1.0_label_1.0', fpr=array([0.        , 0.01005178, 0.01340238, 0.01340238, 0.01553457,\n",
       "                     0.01766677, 0.01918977, 0.02284496, 0.02467256, 0.04233932,\n",
       "                     0.04629912, 0.04904051, 0.05239111, 0.0554371 , 0.0572647 ,\n",
       "                     0.05939689, 0.06244289, 0.06518428, 0.06548888, 0.06975327,\n",
       "                     0.07401767, 0.07797746, 0.08224185, 0.08620164, 0.09137984,\n",
       "                     0.09869022, 0.10204082, 0.10447761, 0.110265  , 0.11757539,\n",
       "                     0.13250076, 0.13371916, 0.14102955, 0.14377094, 0.14468474,\n",
       "                     0.14925373, 0.15443192, 0.15686872, 0.15961011, 0.1693573 ,\n",
       "                     0.17362169, 0.17819068, 0.18123667, 0.18824246, 0.20530003,\n",
       "                     0.21108742, 0.21626561, 0.2199208 , 0.26378313, 0.26530612,\n",
       "                     0.26987511, 0.27474871, 0.29515687, 0.29637527, 0.30003046,\n",
       "                     0.30185806, 0.30368565, 0.32866281, 0.34511118, 0.35485836,\n",
       "                     0.36034115, 0.37191593, 0.38196771, 0.40298507, 0.41181846,\n",
       "                     0.41303686, 0.41608285, 0.41882425, 0.43801401, 0.445629  ,\n",
       "                     0.47883034, 0.49010052, 0.4977155 , 0.4998477 , 0.51203168,\n",
       "                     0.52056046, 0.52147426, 0.57904356, 0.59335973, 0.60554371,\n",
       "                     0.6128541 , 0.62016448, 0.62534267, 0.63904965, 0.65062443,\n",
       "                     0.65336582, 0.66981419, 0.67590618, 0.68534877, 0.69509595,\n",
       "                     0.70027414, 0.70636613, 0.74748705, 0.75692964, 0.7788608 ,\n",
       "                     0.77947   , 0.78617118, 0.78982638, 0.81175754, 0.82607371,\n",
       "                     0.8318611 , 0.84008529, 0.84556808, 0.84678648, 0.85836125,\n",
       "                     0.86597624, 0.88333841, 0.92841913, 0.93390192, 0.93420652,\n",
       "                     0.93481572, 0.93816631, 0.94730429, 0.95400548, 0.95552848,\n",
       "                     0.96101127, 0.96162047, 0.96253427, 0.96314347, 0.96527566,\n",
       "                     0.96740786, 0.97014925, 0.97075845, 0.97380445, 0.97776424,\n",
       "                     1.        ]), tpr=array([0.        , 0.01774436, 0.02496241, 0.02646617, 0.0324812 ,\n",
       "                     0.03518797, 0.03759398, 0.0406015 , 0.04390977, 0.05954887,\n",
       "                     0.06616541, 0.07157895, 0.07789474, 0.0793985 , 0.08180451,\n",
       "                     0.08511278, 0.08962406, 0.09473684, 0.09684211, 0.1043609 ,\n",
       "                     0.11037594, 0.11578947, 0.12300752, 0.12902256, 0.13383459,\n",
       "                     0.1443609 , 0.14917293, 0.15398496, 0.16      , 0.17022556,\n",
       "                     0.18736842, 0.19037594, 0.2006015 , 0.20541353, 0.2075188 ,\n",
       "                     0.21112782, 0.21593985, 0.22045113, 0.22466165, 0.23699248,\n",
       "                     0.24240602, 0.2475188 , 0.25112782, 0.25744361, 0.26977444,\n",
       "                     0.27639098, 0.28390977, 0.2875188 , 0.33233083, 0.33473684,\n",
       "                     0.33924812, 0.34315789, 0.35819549, 0.36210526, 0.36481203,\n",
       "                     0.36902256, 0.37052632, 0.40120301, 0.42135338, 0.43007519,\n",
       "                     0.43458647, 0.44721805, 0.46015038, 0.47879699, 0.48601504,\n",
       "                     0.4887218 , 0.49172932, 0.49503759, 0.51518797, 0.52390977,\n",
       "                     0.56631579, 0.57684211, 0.58255639, 0.58526316, 0.59548872,\n",
       "                     0.60511278, 0.60721805, 0.65022556, 0.66315789, 0.67849624,\n",
       "                     0.68330827, 0.68781955, 0.69323308, 0.70406015, 0.71819549,\n",
       "                     0.7206015 , 0.73503759, 0.73954887, 0.74766917, 0.75879699,\n",
       "                     0.76390977, 0.76932331, 0.81383459, 0.82195489, 0.83759398,\n",
       "                     0.83909774, 0.84481203, 0.84932331, 0.86706767, 0.87849624,\n",
       "                     0.88090226, 0.89142857, 0.89533835, 0.89654135, 0.90345865,\n",
       "                     0.91037594, 0.9275188 , 0.96962406, 0.97203008, 0.97293233,\n",
       "                     0.97383459, 0.97744361, 0.98345865, 0.99007519, 0.99037594,\n",
       "                     0.99428571, 0.99458647, 0.99518797, 0.99548872, 0.99639098,\n",
       "                     0.99759398, 0.99849624, 0.99879699, 0.9993985 , 1.        ,\n",
       "                     1.        ]), thresholds=array([ 1.00000000e+00, -9.99200722e-16, -1.54150680e-01, -1.82321557e-01,\n",
       "                     -2.23143551e-01, -2.87682072e-01, -3.18453731e-01, -3.36472237e-01,\n",
       "                     -3.74693449e-01, -4.05465108e-01, -4.35318071e-01, -4.41832752e-01,\n",
       "                     -4.51985124e-01, -4.70003629e-01, -4.85507816e-01, -4.92476485e-01,\n",
       "                     -5.10825624e-01, -5.34082486e-01, -5.38996501e-01, -5.42324291e-01,\n",
       "                     -5.59615788e-01, -5.75364145e-01, -5.83146285e-01, -5.87786665e-01,\n",
       "                     -5.94707108e-01, -6.19039208e-01, -6.28608659e-01, -6.61398482e-01,\n",
       "                     -6.67829373e-01, -6.78332095e-01, -6.93147181e-01, -7.41937345e-01,\n",
       "                     -7.50305594e-01, -7.53771802e-01, -7.62140052e-01, -7.73189888e-01,\n",
       "                     -7.82759339e-01, -7.88457360e-01, -7.94929875e-01, -7.97287440e-01,\n",
       "                     -7.98507696e-01, -8.04372816e-01, -8.10930216e-01, -8.26678573e-01,\n",
       "                     -8.29722716e-01, -8.40783179e-01, -8.41567186e-01, -8.47297860e-01,\n",
       "                     -8.53986849e-01, -8.64997437e-01, -8.75468737e-01, -9.00786545e-01,\n",
       "                     -9.16290732e-01, -9.31558204e-01, -9.38269639e-01, -9.44461609e-01,\n",
       "                     -9.55511445e-01, -9.62275845e-01, -9.71457113e-01, -9.76509592e-01,\n",
       "                     -9.80829253e-01, -9.89718200e-01, -9.92390075e-01, -1.00276433e+00,\n",
       "                     -1.01160091e+00, -1.02165125e+00, -1.02961942e+00, -1.03609193e+00,\n",
       "                     -1.03705440e+00, -1.06352097e+00, -1.07226346e+00, -1.09861229e+00,\n",
       "                     -1.11600403e+00, -1.13497993e+00, -1.13707857e+00, -1.13943428e+00,\n",
       "                     -1.14513230e+00, -1.15083755e+00, -1.15145477e+00, -1.16192457e+00,\n",
       "                     -1.17865500e+00, -1.18377010e+00, -1.18716569e+00, -1.20397280e+00,\n",
       "                     -1.20609820e+00, -1.21639532e+00, -1.22866542e+00, -1.24319352e+00,\n",
       "                     -1.27887411e+00, -1.28692189e+00, -1.29392104e+00, -1.29928298e+00,\n",
       "                     -1.30906301e+00, -1.31928365e+00, -1.32687094e+00, -1.33500107e+00,\n",
       "                     -1.35962611e+00, -1.36948724e+00, -1.38629436e+00, -1.39936644e+00,\n",
       "                     -1.41706602e+00, -1.42825856e+00, -1.44238383e+00, -1.50407740e+00,\n",
       "                     -1.51846613e+00, -1.52794488e+00, -1.55537069e+00, -1.59504917e+00,\n",
       "                     -1.60943791e+00, -1.67397643e+00, -1.73460106e+00, -1.79175947e+00,\n",
       "                     -1.80828877e+00, -1.82161243e+00, -1.94591015e+00, -2.02001812e+00,\n",
       "                     -2.07944154e+00, -2.19722458e+00, -2.30258509e+00, -2.39789527e+00,\n",
       "                     -2.58399755e+00, -2.68557735e+00, -2.94443898e+00, -2.99573227e+00,\n",
       "                     -3.09104245e+00, -3.45387764e+01]), auc_score=0.5594834634560816, privacy_risk=0.5437427256841464, accuracy=0.5437427256841464, tpr_ind=0.5663157894736842, tnr_ind=0.5211696618946086, test_train_ratio=0.9873684210526316, dataset_size=[3325, 3283])]})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_mia_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "07df1431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['entire_dataset_mia_privacy_risk',\n",
       "       'entire_dataset_label_0.0_mia_privacy_risk',\n",
       "       'entire_dataset_label_1.0_mia_privacy_risk',\n",
       "       'subpopulation_0.0_label_0.0_mia_privacy_risk',\n",
       "       'subpopulation_0.0_label_1.0_mia_privacy_risk',\n",
       "       'subpopulation_1.0_label_0.0_mia_privacy_risk',\n",
       "       'subpopulation_1.0_label_1.0_mia_privacy_risk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7e2f4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = df[['subpopulation_0.0_label_0.0_mia_privacy_risk',\n",
    "       'subpopulation_0.0_label_1.0_mia_privacy_risk',\n",
    "       'subpopulation_1.0_label_0.0_mia_privacy_risk',\n",
    "       'subpopulation_1.0_label_1.0_mia_privacy_risk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "24d711e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subpopulation_0.0_label_0.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_0.0_label_1.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_1.0_label_0.0_mia_privacy_risk</th>\n",
       "      <th>subpopulation_1.0_label_1.0_mia_privacy_risk</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier MIA Attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>orig</th>\n",
       "      <td>0.527101</td>\n",
       "      <td>0.799938</td>\n",
       "      <td>0.519727</td>\n",
       "      <td>0.538967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syn</th>\n",
       "      <td>0.529604</td>\n",
       "      <td>0.740392</td>\n",
       "      <td>0.516075</td>\n",
       "      <td>0.532996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dir</th>\n",
       "      <td>0.527670</td>\n",
       "      <td>0.806501</td>\n",
       "      <td>0.544310</td>\n",
       "      <td>0.546198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rew</th>\n",
       "      <td>0.525226</td>\n",
       "      <td>0.829838</td>\n",
       "      <td>0.517785</td>\n",
       "      <td>0.535869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eg</th>\n",
       "      <td>0.511084</td>\n",
       "      <td>0.675116</td>\n",
       "      <td>0.510303</td>\n",
       "      <td>0.520486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        subpopulation_0.0_label_0.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                                 \n",
       "orig                                                        0.527101   \n",
       "syn                                                         0.529604   \n",
       "dir                                                         0.527670   \n",
       "rew                                                         0.525226   \n",
       "eg                                                          0.511084   \n",
       "\n",
       "                        subpopulation_0.0_label_1.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                                 \n",
       "orig                                                        0.799938   \n",
       "syn                                                         0.740392   \n",
       "dir                                                         0.806501   \n",
       "rew                                                         0.829838   \n",
       "eg                                                          0.675116   \n",
       "\n",
       "                        subpopulation_1.0_label_0.0_mia_privacy_risk  \\\n",
       "Classifier MIA Attacks                                                 \n",
       "orig                                                        0.519727   \n",
       "syn                                                         0.516075   \n",
       "dir                                                         0.544310   \n",
       "rew                                                         0.517785   \n",
       "eg                                                          0.510303   \n",
       "\n",
       "                        subpopulation_1.0_label_1.0_mia_privacy_risk  \n",
       "Classifier MIA Attacks                                                \n",
       "orig                                                        0.538967  \n",
       "syn                                                         0.532996  \n",
       "dir                                                         0.546198  \n",
       "rew                                                         0.535869  \n",
       "eg                                                          0.520486  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "75f230c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Classifier MIA Attacks'>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_groups.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9225fcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  orig       syn       dir       rew        eg\n",
      "--------------------------------------------  --------  --------  --------  --------  --------\n",
      "subpopulation_0.0_label_0.0_mia_privacy_risk  0.527101  0.529604  0.52767   0.525226  0.511084\n",
      "subpopulation_0.0_label_1.0_mia_privacy_risk  0.799938  0.740392  0.806501  0.829838  0.675116\n",
      "subpopulation_1.0_label_0.0_mia_privacy_risk  0.519727  0.516075  0.54431   0.517785  0.510303\n",
      "subpopulation_1.0_label_1.0_mia_privacy_risk  0.538967  0.532996  0.546198  0.535869  0.520486\n"
     ]
    }
   ],
   "source": [
    "# Tabular Format\n",
    "# importing the modules\n",
    "from tabulate import tabulate\n",
    "\n",
    " \n",
    "# displaying the DataFrame\n",
    "print(tabulate(df_groups.T, headers = 'keys', tablefmt = 'simple'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a2e6d",
   "metadata": {},
   "source": [
    "### Visualizing using novel technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6faed82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_error_metrics = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "eg_mia_error_metrics = {k: v for (k,v) in eg_mia_metrics.items() if k.endswith(\"_mia_privacy_risk\")}\n",
    "#orig_mia_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7f5e92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_error_metrics.keys():\n",
    "    for val in orig_mia_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in eg_mia_error_metrics.keys():\n",
    "    for val in eg_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"eg\", key.replace(\"_mia_attacker_advantage\", \"\"), val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5b110698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fairness</th>\n",
       "      <th>MIA</th>\n",
       "      <th>Privacy Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.517117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.517982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.517550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.521300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.524954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.504434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.505321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.502599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.503012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.501923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Fairness                                           MIA  Privacy Risk\n",
       "0       orig               entire_dataset_mia_privacy_risk      0.517117\n",
       "1       orig               entire_dataset_mia_privacy_risk      0.517982\n",
       "2       orig               entire_dataset_mia_privacy_risk      0.517550\n",
       "3       orig               entire_dataset_mia_privacy_risk      0.521300\n",
       "4       orig               entire_dataset_mia_privacy_risk      0.524954\n",
       "..       ...                                           ...           ...\n",
       "695       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.504434\n",
       "696       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.505321\n",
       "697       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.502599\n",
       "698       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.503012\n",
       "699       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.501923\n",
       "\n",
       "[700 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"Privacy Risk\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6e8a5e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fairness</th>\n",
       "      <th>MIA</th>\n",
       "      <th>Privacy Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.517117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.517982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.517550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.521300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orig</td>\n",
       "      <td>entire_dataset_mia_privacy_risk</td>\n",
       "      <td>0.524954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.504434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.505321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.502599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.503012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>eg</td>\n",
       "      <td>subpopulation_1.0_label_1.0_mia_privacy_risk</td>\n",
       "      <td>0.501923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Fairness                                           MIA  Privacy Risk\n",
       "0       orig               entire_dataset_mia_privacy_risk      0.517117\n",
       "1       orig               entire_dataset_mia_privacy_risk      0.517982\n",
       "2       orig               entire_dataset_mia_privacy_risk      0.517550\n",
       "3       orig               entire_dataset_mia_privacy_risk      0.521300\n",
       "4       orig               entire_dataset_mia_privacy_risk      0.524954\n",
       "..       ...                                           ...           ...\n",
       "695       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.504434\n",
       "696       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.505321\n",
       "697       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.502599\n",
       "698       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.503012\n",
       "699       eg  subpopulation_1.0_label_1.0_mia_privacy_risk      0.501923\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only subgroups\n",
    "df_subgroups = df[~((df[\"MIA\"] == \"entire_dataset_label_0.0_mia_privacy_risk\") | (df[\"MIA\"] == \"entire_dataset_label_1.0_mia_privacy_risk\")) ]\n",
    "df_subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0df3d1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1f504a7cb90>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 908.5x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.figure(figsize=(15,8))\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df_subgroups, x=\"MIA\", y=\"Privacy Risk\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Privacy Risk\" )\n",
    "g.set(ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359dc0bf",
   "metadata": {},
   "source": [
    "### ROC curves and AUC scores with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5b7b52ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7fb5d538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['entire_dataset_mia_auc', 'entire_dataset_mia_privacy_risk', 'entire_dataset_mia_ppv', 'entire_dataset_mia_attacker_advantage', 'entire_dataset_mia_result', 'entire_dataset_label_0.0_mia_auc', 'entire_dataset_label_0.0_mia_privacy_risk', 'entire_dataset_label_0.0_mia_ppv', 'entire_dataset_label_0.0_mia_attacker_advantage', 'entire_dataset_label_0.0_mia_result', 'entire_dataset_label_1.0_mia_auc', 'entire_dataset_label_1.0_mia_privacy_risk', 'entire_dataset_label_1.0_mia_ppv', 'entire_dataset_label_1.0_mia_attacker_advantage', 'entire_dataset_label_1.0_mia_result', 'subpopulation_0.0_label_0.0_mia_auc', 'subpopulation_0.0_label_0.0_mia_privacy_risk', 'subpopulation_0.0_label_0.0_mia_ppv', 'subpopulation_0.0_label_0.0_mia_attacker_advantage', 'subpopulation_0.0_label_0.0_mia_result', 'subpopulation_0.0_label_1.0_mia_auc', 'subpopulation_0.0_label_1.0_mia_privacy_risk', 'subpopulation_0.0_label_1.0_mia_ppv', 'subpopulation_0.0_label_1.0_mia_attacker_advantage', 'subpopulation_0.0_label_1.0_mia_result', 'subpopulation_1.0_label_0.0_mia_auc', 'subpopulation_1.0_label_0.0_mia_privacy_risk', 'subpopulation_1.0_label_0.0_mia_ppv', 'subpopulation_1.0_label_0.0_mia_attacker_advantage', 'subpopulation_1.0_label_0.0_mia_result', 'subpopulation_1.0_label_1.0_mia_auc', 'subpopulation_1.0_label_1.0_mia_privacy_risk', 'subpopulation_1.0_label_1.0_mia_ppv', 'subpopulation_1.0_label_1.0_mia_attacker_advantage', 'subpopulation_1.0_label_1.0_mia_result'])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_mia_metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for orig dataset with different subpopulations\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for key in [\"entire_dataset_mia_result\", \n",
    "            \"subpopulation_0.0_label_0.0_mia_result\",\n",
    "            \"subpopulation_0.0_label_1.0_mia_result\", \n",
    "            \"subpopulation_1.0_label_0.0_mia_result\",\n",
    "            \"subpopulation_1.0_label_1.0_mia_result\"]:\n",
    "     # fprs = [mia_res.fpr for mia_res in orig_mia_metrics[key]]\n",
    "    # tprs = [mia_res.tpr for mia_res in orig_mia_metrics[key]]\n",
    "    tprs = []\n",
    "    \n",
    "    # aucs = [mia_res.get_auc() for mia_res in orig_mia_metrics[key]]\n",
    "    aucs = []\n",
    "\n",
    "    # mean_fpr = np.mean(fprs, axis=0)\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "    for mia_res in orig_mia_metrics[key]:\n",
    "        interp_tpr = np.interp(mean_fpr, mia_res.fpr, mia_res.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(mia_res.get_auc())\n",
    "    \n",
    "    #print(mean_fpr)\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    \n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    \n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        #color=\"b\",\n",
    "        label=r\"Mean ROC for %s $\\pm$ 1 std. dev. (AUC = %0.2f $\\pm$ %0.2f)\" % ( key ,mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        #label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve with variability\",\n",
    ")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ff10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entire dataset with different subpopulations\n",
    "# fig, ax = plt.subplots(figsize=(12, 10))\n",
    "fig, ax = plt.subplots(figsize=(24, 18))\n",
    "\n",
    "for mia_metrics, name in zip([orig_mia_metrics, transf_mia_metrics], [\"orig\", \"syn\"]): \n",
    "#                               dir_mia_metrics, reweigh_mia_metrics], [\"orig\", \"syn\", \"dir\", \"reweigh\"] ):\n",
    "    for key in [\"entire_dataset_mia_result\", \n",
    "                \"subpopulation_0.0_label_0.0_mia_result\",\n",
    "                \"subpopulation_0.0_label_1.0_mia_result\", \n",
    "                \"subpopulation_1.0_label_0.0_mia_result\",\n",
    "                \"subpopulation_1.0_label_1.0_mia_result\"]:\n",
    "   \n",
    "        # fprs = [mia_res.fpr for mia_res in orig_mia_metrics[key]]\n",
    "        # tprs = [mia_res.tpr for mia_res in orig_mia_metrics[key]]\n",
    "        tprs = []\n",
    "        # aucs = [mia_res.get_auc() for mia_res in orig_mia_metrics[key]]\n",
    "        aucs = []\n",
    "\n",
    "        # mean_fpr = np.mean(fprs, axis=0)\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "        for mia_res in mia_metrics[key]:\n",
    "            print(mia_res)\n",
    "            interp_tpr = np.interp(mean_fpr, mia_res.fpr, mia_res.tpr)\n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "            aucs.append(mia_res.get_auc())\n",
    "\n",
    "        #print(mean_fpr)\n",
    "        print(tprs)\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std(aucs)\n",
    "\n",
    "        ax.plot(\n",
    "            mean_fpr,\n",
    "            mean_tpr,\n",
    "            #color=\"b\",\n",
    "            label=r\"%s Mean ROC for %s $\\pm$ 1 std. dev. (AUC = %0.2f $\\pm$ %0.2f)\" % (name, key ,mean_auc, std_auc),\n",
    "            lw=2,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        std_tpr = np.std(tprs, axis=0)\n",
    "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        ax.fill_between(\n",
    "            mean_fpr,\n",
    "            tprs_lower,\n",
    "            tprs_upper,\n",
    "            color=\"grey\",\n",
    "            alpha=0.2,\n",
    "            #label=r\"$\\pm$ 1 std. dev.\",\n",
    "        )\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve for MIA attacks against Fairness Approaches\",\n",
    ")\n",
    "ax.legend(loc=\"lower right\")\n",
    "# ax.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entire dataset\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "for mia_res in orig_mia_metrics[\"entire_dataset_mia_result\"]:\n",
    "    plt.plot(mia_res.fpr,mia_res.tpr,label=f\"{mia_res.get_name()} auc={mia_res.get_auc()}\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--', alpha=0.5)\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e701aad9",
   "metadata": {},
   "source": [
    "## MIA Attacks AUC vs Fairness Bar Chart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f18425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "egr_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in eg_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"mia_auc\")}\n",
    "eg_mia_metrics_mean = {k:sum(v)/N for (k,v) in eg_mia_metrics.items() if k.endswith(\"mia_auc\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a025ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b078a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuazlization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "        transf_mia_metrics_mean,\n",
    "        dir_mia_metrics_mean,\n",
    "        reweigh_mia_metrics_mean,\n",
    "        eg_mia_metrics_mean\n",
    "        ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "        transf_mia_error_metrics,\n",
    "        dir_mia_error_metrics,\n",
    "        reweigh_mia_error_metrics,\n",
    "          egr_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn']+ ['dir']+ ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2233661a",
   "metadata": {},
   "source": [
    "###  MIA Attackers Advantage Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f09191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data structures to plot point categorical plot from seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ef741",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "egr_mia_error_metrics = {k: v for (k,v) in eg_mia_metrics.items() if k.endswith(\"attacker_advantage\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87375802",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_metrics_att_ad.keys():\n",
    "    for val in orig_mia_metrics_att_ad[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "for key in egr_mia_error_metrics.keys():\n",
    "    for val in egr_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"egr\", key.replace(\"_mia_attacker_advantage\", \"\"), val])\n",
    "advantage_metrics_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105df8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"attacker_advantage\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac8578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting without scaling y limis to 1\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"attacker_advantage\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's Advantage\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf746e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15,8))\n",
    "\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"attacker_advantage\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's Advantage\" )\n",
    "g.set(ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b0356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(orig_mia_metrics_att_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to display fairness metrics\n",
    "# error metrics\n",
    "orig_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in reweigh_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in dir_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "egr_mia_error_metrics = {k: statistics.stdev(v) for (k,v) in eg_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "\n",
    "# mean value metrics\n",
    "orig_mia_metrics_mean = {k: sum(v)/N for (k,v) in orig_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "transf_mia_metrics_mean = {k: sum(v)/N for (k,v) in transf_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "reweigh_mia_metrics_mean = {k:sum(v)/N for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "dir_mia_metrics_mean = {k:sum(v)/N for (k,v) in dir_mia_metrics.items() if k.endswith(\"attacker_advantage\")}\n",
    "eg_mia_metrics_mean = {k:sum(v)/N for (k,v) in eg_mia_metrics.items() if k.endswith(\"attacker_advantage\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e9be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuazlization of Fairness\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "plt.rcParams.update({'font.size': 8}) # must set in top\n",
    "\n",
    "results = [orig_mia_metrics_mean,\n",
    "        transf_mia_metrics_mean,\n",
    "        dir_mia_metrics_mean,\n",
    "        reweigh_mia_metrics_mean,\n",
    "           eg_mia_metrics_mean\n",
    "        ]\n",
    "\n",
    "\n",
    "errors = [orig_mia_error_metrics,\n",
    "        transf_mia_error_metrics,\n",
    "        dir_mia_error_metrics,\n",
    "        reweigh_mia_error_metrics,\n",
    "          egr_mia_error_metrics\n",
    "         ]\n",
    "\n",
    "index = pd.Series(['orig']+ ['syn']+ ['dir']+ ['rew'] + ['egr'], name='Classifier MIA Attacks')\n",
    "\n",
    "df = pd.DataFrame(results).set_index(index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(figsize=(7,7), ylim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1309a4",
   "metadata": {},
   "source": [
    "## PPV Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mia_metrics_att_ad = {k: v for (k,v) in orig_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "transf_mia_error_metrics = {k: v for (k,v) in transf_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "reweigh_mia_error_metrics = {k: v for (k,v) in reweigh_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "dir_mia_error_metrics = {k: v for (k,v) in dir_mia_metrics.items() if k.endswith(\"mia_ppv\")}\n",
    "egr_mia_error_metrics = {k: v for (k,v) in eg_mia_metrics.items() if k.endswith(\"mia_ppv\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14018577",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_metrics_arrays = []\n",
    "for key in orig_mia_metrics_att_ad.keys():\n",
    "    for val in orig_mia_metrics_att_ad[key]:\n",
    "        advantage_metrics_arrays.append([\"orig\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in transf_mia_error_metrics.keys():\n",
    "    for val in transf_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"syn\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in reweigh_mia_error_metrics.keys():\n",
    "    for val in reweigh_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"reweigh\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in dir_mia_error_metrics.keys():\n",
    "    for val in dir_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"dir\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "for key in egr_mia_error_metrics.keys():\n",
    "    for val in egr_mia_error_metrics[key]:\n",
    "        advantage_metrics_arrays.append([\"egr\", key.replace(\"_mia_ppv\", \"\"), val])\n",
    "advantage_metrics_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95980069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(advantage_metrics_arrays,columns=[\"Fairness\", \"MIA\", \"PPV\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff9b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting without scaling y limis to 1\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "#sns.set_style('ticks')\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df, x=\"MIA\", y=\"PPV\", hue=\"Fairness\",\n",
    "    #palette={\"male\": \"g\", \"female\": \"m\"},\n",
    "    markers=[\"^\", \"o\", \"x\", \"v\", \">\"], linestyles=[\"-\", \"--\", \"-.\", \":\", \"-\"],\n",
    "    kind=\"point\", height=8, aspect=1\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "g.set_axis_labels(\"Classifier Membership Inference Attacks\", \"Attacker's PPV\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38297706",
   "metadata": {},
   "source": [
    "# Dataset Exploration for comparison with Shokri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c85d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame([dataset_orig.features, dataset_orig.labels]).drop_duplicates()\n",
    "\n",
    "df = pd.DataFrame(dataset_orig.features, columns=dataset_orig.feature_names)\n",
    "\n",
    "df[\"labels\"] = dataset_orig.labels\n",
    "df\n",
    "#df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d14528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"age\", \"labels\"]].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f7423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352b318b",
   "metadata": {},
   "source": [
    "## DT Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd7c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_orig_model_metrics(dataset_orig_train, dataset_orig_test, unprivileged_groups, f_label, uf_label, BASELINE, SCALER, ATTACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feceb031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_egr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ad93b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
